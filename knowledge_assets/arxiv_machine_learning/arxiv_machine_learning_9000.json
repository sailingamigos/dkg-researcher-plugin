[
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12455v2",
            "title": "Auto Search Indexer for End-to-End Document Retrieval",
            "updated": "2023-10-30T11:52:47Z",
            "published": "2023-10-19T04:16:48Z",
            "summary": "Generative retrieval, which is a new advanced paradigm for document\nretrieval, has recently attracted research interests, since it encodes all\ndocuments into the model and directly generates the retrieved documents.\nHowever, its power is still underutilized since it heavily relies on the\n\"preprocessed\" document identifiers (docids), thus limiting its retrieval\nperformance and ability to retrieve new documents. In this paper, we propose a\nnovel fully end-to-end retrieval paradigm. It can not only end-to-end learn the\nbest docids for existing and new documents automatically via a semantic\nindexing module, but also perform end-to-end document retrieval via an\nencoder-decoder-based generative model, namely Auto Search Indexer (ASI).\nBesides, we design a reparameterization mechanism to combine the above two\nmodules into a joint optimization framework. Extensive experimental results\ndemonstrate the superiority of our model over advanced baselines on both public\nand industrial datasets and also verify the ability to deal with new documents.",
            "author": [
                "Tianchi Yang",
                "Minghui Song",
                "Zihan Zhang",
                "Haizhen Huang",
                "Weiwei Deng",
                "Feng Sun",
                "Qi Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12455v2",
                "http://arxiv.org/pdf/2310.12455v2"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12452v1",
            "title": "Not Just Learning from Others but Relying on Yourself: A New Perspective\n  on Few-Shot Segmentation in Remote Sensing",
            "updated": "2023-10-19T04:09:10Z",
            "published": "2023-10-19T04:09:10Z",
            "summary": "Few-shot segmentation (FSS) is proposed to segment unknown class targets with\njust a few annotated samples. Most current FSS methods follow the paradigm of\nmining the semantics from the support images to guide the query image\nsegmentation. However, such a pattern of `learning from others' struggles to\nhandle the extreme intra-class variation, preventing FSS from being directly\ngeneralized to remote sensing scenes. To bridge the gap of intra-class\nvariance, we develop a Dual-Mining network named DMNet for cross-image mining\nand self-mining, meaning that it no longer focuses solely on support images but\npays more attention to the query image itself. Specifically, we propose a\nClass-public Region Mining (CPRM) module to effectively suppress irrelevant\nfeature pollution by capturing the common semantics between the support-query\nimage pair. The Class-specific Region Mining (CSRM) module is then proposed to\ncontinuously mine the class-specific semantics of the query image itself in a\n`filtering' and `purifying' manner. In addition, to prevent the co-existence of\nmultiple classes in remote sensing scenes from exacerbating the collapse of FSS\ngeneralization, we also propose a new Known-class Meta Suppressor (KMS) module\nto suppress the activation of known-class objects in the sample. Extensive\nexperiments on the iSAID and LoveDA remote sensing datasets have demonstrated\nthat our method sets the state-of-the-art with a minimum number of model\nparameters. Significantly, our model with the backbone of Resnet-50 achieves\nthe mIoU of 49.58% and 51.34% on iSAID under 1-shot and 5-shot settings,\noutperforming the state-of-the-art method by 1.8% and 1.12%, respectively. The\ncode is publicly available at https://github.com/HanboBizl/DMNet.",
            "author": [
                "Hanbo Bi",
                "Yingchao Feng",
                "Zhiyuan Yan",
                "Yongqiang Mao",
                "Wenhui Diao",
                "Hongqi Wang",
                "Xian Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12452v1",
                "http://arxiv.org/pdf/2310.12452v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12451v1",
            "title": "MTS-LOF: Medical Time-Series Representation Learning via\n  Occlusion-Invariant Features",
            "updated": "2023-10-19T04:08:19Z",
            "published": "2023-10-19T04:08:19Z",
            "summary": "Medical time series data are indispensable in healthcare, providing critical\ninsights for disease diagnosis, treatment planning, and patient management. The\nexponential growth in data complexity, driven by advanced sensor technologies,\nhas presented challenges related to data labeling. Self-supervised learning\n(SSL) has emerged as a transformative approach to address these challenges,\neliminating the need for extensive human annotation. In this study, we\nintroduce a novel framework for Medical Time Series Representation Learning,\nknown as MTS-LOF. MTS-LOF leverages the strengths of contrastive learning and\nMasked Autoencoder (MAE) methods, offering a unique approach to representation\nlearning for medical time series data. By combining these techniques, MTS-LOF\nenhances the potential of healthcare applications by providing more\nsophisticated, context-rich representations. Additionally, MTS-LOF employs a\nmulti-masking strategy to facilitate occlusion-invariant feature learning. This\napproach allows the model to create multiple views of the data by masking\nportions of it. By minimizing the discrepancy between the representations of\nthese masked patches and the fully visible patches, MTS-LOF learns to capture\nrich contextual information within medical time series datasets. The results of\nexperiments conducted on diverse medical time series datasets demonstrate the\nsuperiority of MTS-LOF over other methods. These findings hold promise for\nsignificantly enhancing healthcare applications by improving representation\nlearning. Furthermore, our work delves into the integration of joint-embedding\nSSL and MAE techniques, shedding light on the intricate interplay between\ntemporal and structural dependencies in healthcare data. This understanding is\ncrucial, as it allows us to grasp the complexities of healthcare data analysis.",
            "author": [
                "Huayu Li",
                "Ana S. Carreon-Rascon",
                "Xiwen Chen",
                "Geng Yuan",
                "Ao Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12451v1",
                "http://arxiv.org/pdf/2310.12451v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12449v1",
            "title": "A Machine Learning Approach to Robustly Determine Orientation Fields and\n  Analyze Defects in Active Nematics",
            "updated": "2023-10-19T04:01:36Z",
            "published": "2023-10-19T04:01:36Z",
            "summary": "Active nematics are dense systems of rodlike particles that consume energy to\ndrive motion at the level of the individual particles. They are found in a\nvariety of natural systems, such as biological tissues, and artificial\nmaterials such as suspensions of self-propelled colloidal particles or\nsynthetic microswimmers. Active nematics have attracted significant attention\nin recent years because of their spectacular nonequilibrium collective\nspatiotemporal dynamics, which may enable applications in fields such as\nrobotics, drug delivery, and materials science. The orientation field, which\nmeasures the direction and degree of alignment of the local nematic director,\nis a crucial characteristic of an active nematic and is essential for detecting\nand studying topological defects. However, determining the orientation field is\na significant challenge in many experimental systems. Although orientation\nfields can be derived from images of active nematics using traditional imaging\nprocessing methods, the results and accuracy of such methods are highly\nsensitive to the settings of the algorithm. These settings must be tuned from\nimage-to-image due to experimental noise, intrinsic noise of the imaging\ntechnology, and perturbations caused by changes in experimental conditions.\nThis sensitivity currently limits the automatic analysis of active nematics. To\novercome this limitation, we have developed a machine learning model for\nextracting reliable orientation fields from raw experimental images, which\nenables accurate automatic analysis of topological defects. Application of the\nalgorithm to experimental data demonstrates that the approach is robust and\nhighly generalizable to experimental settings that were unseen in the training\ndata. These results suggest that it will be a useful tool for investigating\nactive nematics, and the approach may be generalized to other active matter\nsystems.",
            "author": [
                "Yunrui Li",
                "Zahra Zarei",
                "Phu N. Tran",
                "Yifei Wang",
                "Aparna Baskaran",
                "Seth Fraden",
                "Michael F. Hagan",
                "Pengyu Hong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12449v1",
                "http://arxiv.org/pdf/2310.12449v1"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12447v1",
            "title": "Constrained Reweighting of Distributions: an Optimal Transport Approach",
            "updated": "2023-10-19T03:54:31Z",
            "published": "2023-10-19T03:54:31Z",
            "summary": "We commonly encounter the problem of identifying an optimally weight adjusted\nversion of the empirical distribution of observed data, adhering to predefined\nconstraints on the weights. Such constraints often manifest as restrictions on\nthe moments, tail behaviour, shapes, number of modes, etc., of the resulting\nweight adjusted empirical distribution. In this article, we substantially\nenhance the flexibility of such methodology by introducing a nonparametrically\nimbued distributional constraints on the weights, and developing a general\nframework leveraging the maximum entropy principle and tools from optimal\ntransport. The key idea is to ensure that the maximum entropy weight adjusted\nempirical distribution of the observed data is close to a pre-specified\nprobability distribution in terms of the optimal transport metric while\nallowing for subtle departures. The versatility of the framework is\ndemonstrated in the context of three disparate applications where data\nre-weighting is warranted to satisfy side constraints on the optimization\nproblem at the heart of the statistical task: namely, portfolio allocation,\nsemi-parametric inference for complex surveys, and ensuring algorithmic\nfairness in machine learning algorithms.",
            "author": [
                "Abhisek Chakraborty",
                "Anirban Bhattacharya",
                "Debdeep Pati"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12447v1",
                "http://arxiv.org/pdf/2310.12447v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12446v1",
            "title": "Can Electromagnetic Information Theory Improve Wireless Systems? A\n  Channel Estimation Example",
            "updated": "2023-10-19T03:53:41Z",
            "published": "2023-10-19T03:53:41Z",
            "summary": "Electromagnetic information theory (EIT) is an emerging interdisciplinary\nsubject that integrates classical Maxwell electromagnetics and Shannon\ninformation theory. The goal of EIT is to uncover the information transmission\nmechanisms from an electromagnetic (EM) perspective in wireless systems.\nExisting works on EIT are mainly focused on the analysis of degrees-of-freedom\n(DoF), system capacity, and characteristics of the electromagnetic channel.\nHowever, these works do not clarify how EIT can improve wireless communication\nsystems. To answer this question, in this paper, we provide a novel\ndemonstration of the application of EIT. By integrating EM knowledge into the\nclassical MMSE channel estimator, we observe for the first time that EIT is\ncapable of improving the channel estimation performace. Specifically, the EM\nknowledge is first encoded into a spatio-temporal correlation function (STCF),\nwhich we term as the EM kernel. This EM kernel plays the role of side\ninformation to the channel estimator. Since the EM kernel takes the form of\nGaussian processes (GP), we propose the EIT-based Gaussian process regression\n(EIT-GPR) to derive the channel estimations. In addition, since the EM kernel\nallows parameter tuning, we propose EM kernel learning to fit the EM kernel to\nchannel observations. Simulation results show that the application of EIT to\nthe channel estimator enables it to outperform traditional isotropic MMSE\nalgorithm, thus proving the practical values of EIT.",
            "author": [
                "Jieao Zhu",
                "Xiaofeng Su",
                "Zhongzhichao Wan",
                "Linglong Dai",
                "Tie Jun Cui"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12446v1",
                "http://arxiv.org/pdf/2310.12446v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12442v1",
            "title": "Efficient Long-Range Transformers: You Need to Attend More, but Not\n  Necessarily at Every Layer",
            "updated": "2023-10-19T03:32:05Z",
            "published": "2023-10-19T03:32:05Z",
            "summary": "Pretrained transformer models have demonstrated remarkable performance across\nvarious natural language processing tasks. These models leverage the attention\nmechanism to capture long- and short-range dependencies in the sequence.\nHowever, the (full) attention mechanism incurs high computational cost -\nquadratic in the sequence length, which is not affordable in tasks with long\nsequences, e.g., inputs with 8k tokens. Although sparse attention can be used\nto improve computational efficiency, as suggested in existing work, it has\nlimited modeling capacity and often fails to capture complicated dependencies\nin long sequences. To tackle this challenge, we propose MASFormer, an\neasy-to-implement transformer variant with Mixed Attention Spans. Specifically,\nMASFormer is equipped with full attention to capture long-range dependencies,\nbut only at a small number of layers. For the remaining layers, MASformer only\nemploys sparse attention to capture short-range dependencies. Our experiments\non natural language modeling and generation tasks show that a decoder-only\nMASFormer model of 1.3B parameters can achieve competitive performance to\nvanilla transformers with full attention while significantly reducing\ncomputational cost (up to 75%). Additionally, we investigate the effectiveness\nof continual training with long sequence data and how sequence length impacts\ndownstream generation performance, which may be of independent interest.",
            "author": [
                "Qingru Zhang",
                "Dhananjay Ram",
                "Cole Hawkins",
                "Sheng Zha",
                "Tuo Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12442v1",
                "http://arxiv.org/pdf/2310.12442v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12437v1",
            "title": "Optimal Excess Risk Bounds for Empirical Risk Minimization on $p$-norm\n  Linear Regression",
            "updated": "2023-10-19T03:21:28Z",
            "published": "2023-10-19T03:21:28Z",
            "summary": "We study the performance of empirical risk minimization on the $p$-norm\nlinear regression problem for $p \\in (1, \\infty)$. We show that, in the\nrealizable case, under no moment assumptions, and up to a\ndistribution-dependent constant, $O(d)$ samples are enough to exactly recover\nthe target. Otherwise, for $p \\in [2, \\infty)$, and under weak moment\nassumptions on the target and the covariates, we prove a high probability\nexcess risk bound on the empirical risk minimizer whose leading term matches,\nup to a constant that depends only on $p$, the asymptotically exact rate. We\nextend this result to the case $p \\in (1, 2)$ under mild assumptions that\nguarantee the existence of the Hessian of the risk at its minimizer.",
            "author": [
                "Ayoub El Hanchi",
                "Murat A. Erdogdu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12437v1",
                "http://arxiv.org/pdf/2310.12437v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12436v1",
            "title": "Learning prediction function of prior measures for statistical inverse\n  problems of partial differential equations",
            "updated": "2023-10-19T03:17:33Z",
            "published": "2023-10-19T03:17:33Z",
            "summary": "In this paper, we view the statistical inverse problems of partial\ndifferential equations (PDEs) as PDE-constrained regression and focus on\nlearning the prediction function of the prior probability measures. From this\nperspective, we propose general generalization bounds for learning\ninfinite-dimensionally defined prior measures in the style of the probability\napproximately correct Bayesian learning theory. The theoretical framework is\nrigorously defined on infinite-dimensional separable function space, which\nmakes the theories intimately connected to the usual infinite-dimensional\nBayesian inverse approach. Inspired by the concept of $\\alpha$-differential\nprivacy, a generalized condition (containing the usual Gaussian measures\nemployed widely in the statistical inverse problems of PDEs) has been proposed,\nwhich allows the learned prior measures to depend on the measured data (the\nprediction function with measured data as input and the prior measure as output\ncan be introduced). After illustrating the general theories, the specific\nsettings of linear and nonlinear problems have been given and can be easily\ncasted into our general theories to obtain concrete generalization bounds.\nBased on the obtained generalization bounds, infinite-dimensionally\nwell-defined practical algorithms are formulated. Finally, numerical examples\nof the backward diffusion and Darcy flow problems are provided to demonstrate\nthe potential applications of the proposed approach in learning the prediction\nfunction of the prior probability measures.",
            "author": [
                "Junxiong Jia",
                "Deyu Meng",
                "Zongben Xu",
                "Fang Yao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12436v1",
                "http://arxiv.org/pdf/2310.12436v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "stat.TH",
                "62F15, 65N21"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12432v1",
            "title": "CAT: Closed-loop Adversarial Training for Safe End-to-End Driving",
            "updated": "2023-10-19T02:49:31Z",
            "published": "2023-10-19T02:49:31Z",
            "summary": "Driving safety is a top priority for autonomous vehicles. Orthogonal to prior\nwork handling accident-prone traffic events by algorithm designs at the policy\nlevel, we investigate a Closed-loop Adversarial Training (CAT) framework for\nsafe end-to-end driving in this paper through the lens of environment\naugmentation. CAT aims to continuously improve the safety of driving agents by\ntraining the agent on safety-critical scenarios that are dynamically generated\nover time. A novel resampling technique is developed to turn log-replay\nreal-world driving scenarios into safety-critical ones via probabilistic\nfactorization, where the adversarial traffic generation is modeled as the\nmultiplication of standard motion prediction sub-problems. Consequently, CAT\ncan launch more efficient physical attacks compared to existing safety-critical\nscenario generation methods and yields a significantly less computational cost\nin the iterative learning pipeline. We incorporate CAT into the MetaDrive\nsimulator and validate our approach on hundreds of driving scenarios imported\nfrom real-world driving datasets. Experimental results demonstrate that CAT can\neffectively generate adversarial scenarios countering the agent being trained.\nAfter training, the agent can achieve superior driving safety in both\nlog-replay and safety-critical traffic scenarios on the held-out test set. Code\nand data are available at https://metadriverse.github.io/cat.",
            "author": [
                "Linrui Zhang",
                "Zhenghao Peng",
                "Quanyi Li",
                "Bolei Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12432v1",
                "http://arxiv.org/pdf/2310.12432v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12431v1",
            "title": "Segment Anything Meets Universal Adversarial Perturbation",
            "updated": "2023-10-19T02:49:24Z",
            "published": "2023-10-19T02:49:24Z",
            "summary": "As Segment Anything Model (SAM) becomes a popular foundation model in\ncomputer vision, its adversarial robustness has become a concern that cannot be\nignored. This works investigates whether it is possible to attack SAM with\nimage-agnostic Universal Adversarial Perturbation (UAP). In other words, we\nseek a single perturbation that can fool the SAM to predict invalid masks for\nmost (if not all) images. We demonstrate convetional image-centric attack\nframework is effective for image-independent attacks but fails for universal\nadversarial attack. To this end, we propose a novel perturbation-centric\nframework that results in a UAP generation method based on self-supervised\ncontrastive learning (CL), where the UAP is set to the anchor sample and the\npositive sample is augmented from the UAP. The representations of negative\nsamples are obtained from the image encoder in advance and saved in a memory\nbank. The effectiveness of our proposed CL-based UAP generation method is\nvalidated by both quantitative and qualitative results. On top of the ablation\nstudy to understand various components in our proposed method, we shed light on\nthe roles of positive and negative samples in making the generated UAP\neffective for attacking SAM.",
            "author": [
                "Dongshen Han",
                "Sheng Zheng",
                "Chaoning Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12431v1",
                "http://arxiv.org/pdf/2310.12431v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12430v1",
            "title": "DocXChain: A Powerful Open-Source Toolchain for Document Parsing and\n  Beyond",
            "updated": "2023-10-19T02:49:09Z",
            "published": "2023-10-19T02:49:09Z",
            "summary": "In this report, we introduce DocXChain, a powerful open-source toolchain for\ndocument parsing, which is designed and developed to automatically convert the\nrich information embodied in unstructured documents, such as text, tables and\ncharts, into structured representations that are readable and manipulable by\nmachines. Specifically, basic capabilities, including text detection, text\nrecognition, table structure recognition and layout analysis, are provided.\nUpon these basic capabilities, we also build a set of fully functional\npipelines for document parsing, i.e., general text reading, table parsing, and\ndocument structurization, to drive various applications related to documents in\nreal-world scenarios. Moreover, DocXChain is concise, modularized and flexible,\nsuch that it can be readily integrated with existing tools, libraries or models\n(such as LangChain and ChatGPT), to construct more powerful systems that can\naccomplish more complicated and challenging tasks. The code of DocXChain is\npublicly available\nat:~\\url{https://github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/Applications/DocXChain}",
            "author": [
                "Cong Yao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12430v1",
                "http://arxiv.org/pdf/2310.12430v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12428v1",
            "title": "Towards Enhanced Local Explainability of Random Forests: a\n  Proximity-Based Approach",
            "updated": "2023-10-19T02:42:20Z",
            "published": "2023-10-19T02:42:20Z",
            "summary": "We initiate a novel approach to explain the out of sample performance of\nrandom forest (RF) models by exploiting the fact that any RF can be formulated\nas an adaptive weighted K nearest-neighbors model. Specifically, we use the\nproximity between points in the feature space learned by the RF to re-write\nrandom forest predictions exactly as a weighted average of the target labels of\ntraining data points. This linearity facilitates a local notion of\nexplainability of RF predictions that generates attributions for any model\nprediction across observations in the training set, and thereby complements\nestablished methods like SHAP, which instead generates attributions for a model\nprediction across dimensions of the feature space. We demonstrate this approach\nin the context of a bond pricing model trained on US corporate bond trades, and\ncompare our approach to various existing approaches to model explainability.",
            "author": [
                "Joshua Rosaler",
                "Dhruv Desai",
                "Bhaskarjit Sarmah",
                "Dimitrios Vamvourellis",
                "Deran Onay",
                "Dhagash Mehta",
                "Stefano Pasquali"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12428v1",
                "http://arxiv.org/pdf/2310.12428v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.AI",
                "cs.LG",
                "q-fin.ST",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12425v2",
            "title": "Automated Repair of Declarative Software Specifications in the Era of\n  Large Language Models",
            "updated": "2023-11-07T17:06:06Z",
            "published": "2023-10-19T02:30:42Z",
            "summary": "The growing adoption of declarative software specification languages, coupled\nwith their inherent difficulty in debugging, has underscored the need for\neffective and automated repair techniques applicable to such languages.\nResearchers have recently explored various methods to automatically repair\ndeclarative software specifications, such as template-based repair,\nfeedback-driven iterative repair, and bounded exhaustive approaches. The latest\ndevelopments in large language models provide new opportunities for the\nautomatic repair of declarative specifications. In this study, we assess the\neffectiveness of utilizing OpenAI's ChatGPT to repair software specifications\nwritten in the Alloy declarative language. Unlike imperative languages,\nspecifications in Alloy are not executed but rather translated into logical\nformulas and evaluated using backend constraint solvers to identify\nspecification instances and counterexamples to assertions. Our evaluation\nfocuses on ChatGPT's ability to improve the correctness and completeness of\nAlloy declarative specifications through automatic repairs. We analyze the\nresults produced by ChatGPT and compare them with those of leading automatic\nAlloy repair methods. Our study revealed that while ChatGPT falls short in\ncomparison to existing techniques, it was able to successfully repair bugs that\nno other technique could address. Our analysis also identified errors in\nChatGPT's generated repairs, including improper operator usage, type errors,\nhigher-order logic misuse, and relational arity mismatches. Additionally, we\nobserved instances of hallucinations in ChatGPT-generated repairs and\ninconsistency in its results. Our study provides valuable insights for software\npractitioners, researchers, and tool builders considering ChatGPT for\ndeclarative specification repairs.",
            "author": [
                "Md Rashedul Hasan",
                "Jiawei Li",
                "Iftekhar Ahmed",
                "Hamid Bagheri"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12425v2",
                "http://arxiv.org/pdf/2310.12425v2"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12421v2",
            "title": "Detecting and Mitigating Algorithmic Bias in Binary Classification using\n  Causal Modeling",
            "updated": "2023-11-09T00:27:00Z",
            "published": "2023-10-19T02:21:04Z",
            "summary": "This paper proposes the use of causal modeling to detect and mitigate\nalgorithmic bias. We provide a brief description of causal modeling and a\ngeneral overview of our approach. We then use the Adult dataset, which is\navailable for download from the UC Irvine Machine Learning Repository, to\ndevelop (1) a prediction model, which is treated as a black box, and (2) a\ncausal model for bias mitigation. In this paper, we focus on gender bias and\nthe problem of binary classification. We show that gender bias in the\nprediction model is statistically significant at the 0.05 level. We demonstrate\nthe effectiveness of the causal model in mitigating gender bias by\ncross-validation. Furthermore, we show that the overall classification accuracy\nis improved slightly. Our novel approach is intuitive, easy-to-use, and can be\nimplemented using existing statistical software tools such as \"lavaan\" in R.\nHence, it enhances explainability and promotes trust.",
            "author": [
                "Wendy Hui",
                "Wai Kwong Lau"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12421v2",
                "http://arxiv.org/pdf/2310.12421v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13022v1",
            "title": "Uncertainty-aware Parameter-Efficient Self-training for Semi-supervised\n  Language Understanding",
            "updated": "2023-10-19T02:18:29Z",
            "published": "2023-10-19T02:18:29Z",
            "summary": "The recent success of large pre-trained language models (PLMs) heavily hinges\non massive labeled data, which typically produces inferior performance in\nlow-resource scenarios. To remedy this dilemma, we study self-training as one\nof the predominant semi-supervised learning (SSL) approaches, which utilizes\nlarge-scale unlabeled data to generate synthetic examples. However, too many\nnoisy labels will hurt the model performance, and the self-training procedure\nrequires multiple training iterations making it more expensive if all the model\nparameters of the PLM are updated. This paper presents UPET, a novel\nUncertainty-aware Parameter-Efficient self-Training framework to effectively\nand efficiently address the labeled data scarcity issue. Specifically, we\nincorporate Monte Carlo (MC) dropout in Bayesian neural network (BNN) to\nperform uncertainty estimation for the teacher model and then judiciously\nselect reliable pseudo-labeled examples based on confidence and certainty.\nDuring the student training, we introduce multiple parameter-efficient learning\n(PEL) paradigms that allow the optimization of only a small percentage of\nparameters. We also propose a novel Easy-Hard Contrastive Tuning to enhance the\nrobustness and generalization. Extensive experiments over multiple downstream\ntasks demonstrate that UPET achieves a substantial improvement in terms of\nperformance and efficiency. Our codes and data are released at https:\n//github.com/wjn1996/UPET.",
            "author": [
                "Jianing Wang",
                "Qiushi Sun",
                "Nuo Chen",
                "Chengyu Wang",
                "Jun Huang",
                "Ming Gao",
                "Xiang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13022v1",
                "http://arxiv.org/pdf/2310.13022v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15179v1",
            "title": "Reducing Uncertainty in Sea-level Rise Prediction: A\n  Spatial-variability-aware Approach",
            "updated": "2023-10-19T02:13:38Z",
            "published": "2023-10-19T02:13:38Z",
            "summary": "Given multi-model ensemble climate projections, the goal is to accurately and\nreliably predict future sea-level rise while lowering the uncertainty. This\nproblem is important because sea-level rise affects millions of people in\ncoastal communities and beyond due to climate change's impacts on polar ice\nsheets and the ocean. This problem is challenging due to spatial variability\nand unknowns such as possible tipping points (e.g., collapse of Greenland or\nWest Antarctic ice-shelf), climate feedback loops (e.g., clouds, permafrost\nthawing), future policy decisions, and human actions. Most existing climate\nmodeling approaches use the same set of weights globally, during either\nregression or deep learning to combine different climate projections. Such\napproaches are inadequate when different regions require different weighting\nschemes for accurate and reliable sea-level rise predictions. This paper\nproposes a zonal regression model which addresses spatial variability and model\ninter-dependency. Experimental results show more reliable predictions using the\nweights learned via this approach on a regional scale.",
            "author": [
                "Subhankar Ghosh",
                "Shuai An",
                "Arun Sharma",
                "Jayant Gupta",
                "Shashi Shekhar",
                "Aneesh Subramanian"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15179v1",
                "http://arxiv.org/pdf/2310.15179v1"
            ],
            "primary_category": "physics.ao-ph",
            "category": [
                "physics.ao-ph",
                "cs.AI",
                "cs.LG",
                "math.DS",
                "stat.OT",
                "J.2; I.2.m; I.2.6; I.2.1; I.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12408v1",
            "title": "Provable Guarantees for Neural Networks via Gradient Feature Learning",
            "updated": "2023-10-19T01:45:37Z",
            "published": "2023-10-19T01:45:37Z",
            "summary": "Neural networks have achieved remarkable empirical performance, while the\ncurrent theoretical analysis is not adequate for understanding their success,\ne.g., the Neural Tangent Kernel approach fails to capture their key feature\nlearning ability, while recent analyses on feature learning are typically\nproblem-specific. This work proposes a unified analysis framework for two-layer\nnetworks trained by gradient descent. The framework is centered around the\nprinciple of feature learning from gradients, and its effectiveness is\ndemonstrated by applications in several prototypical problems, such as mixtures\nof Gaussians and parity functions. The framework also sheds light on\ninteresting network learning phenomena such as feature learning beyond kernels\nand the lottery ticket hypothesis.",
            "author": [
                "Zhenmei Shi",
                "Junyi Wei",
                "Yingyu Liang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12408v1",
                "http://arxiv.org/pdf/2310.12408v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12407v1",
            "title": "Classification-Aided Robust Multiple Target Tracking Using Neural\n  Enhanced Message Passing",
            "updated": "2023-10-19T01:41:11Z",
            "published": "2023-10-19T01:41:11Z",
            "summary": "We address the challenge of tracking an unknown number of targets in strong\nclutter environments using measurements from a radar sensor. Leveraging the\nrange-Doppler spectra information, we identify the measurement classes, which\nserve as additional information to enhance clutter rejection and data\nassociation, thus bolstering the robustness of target tracking. We first\nintroduce a novel neural enhanced message passing approach, where the beliefs\nobtained by the unified message passing are fed into the neural network as\nadditional information. The output beliefs are then utilized to refine the\noriginal beliefs. Then, we propose a classification-aided robust multiple\ntarget tracking algorithm, employing the neural enhanced message passing\ntechnique. This algorithm is comprised of three modules: a message-passing\nmodule, a neural network module, and a Dempster-Shafer module. The\nmessage-passing module is used to represent the statistical model by the factor\ngraph and infers target kinematic states, visibility states, and data\nassociations based on the spatial measurement information. The neural network\nmodule is employed to extract features from range-Doppler spectra and derive\nbeliefs on whether a measurement is target-generated or clutter-generated. The\nDempster-Shafer module is used to fuse the beliefs obtained from both the\nfactor graph and the neural network. As a result, our proposed algorithm adopts\na model-and-data-driven framework, effectively enhancing clutter suppression\nand data association, leading to significant improvements in multiple target\ntracking performance. We validate the effectiveness of our approach using both\nsimulated and real data scenarios, demonstrating its capability to handle\nchallenging tracking scenarios in practical radar applications.",
            "author": [
                "Xianglong Bai",
                "Zengfu Wang",
                "Quan Pan",
                "Tao Yun",
                "Hua Lan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12407v1",
                "http://arxiv.org/pdf/2310.12407v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12405v1",
            "title": "LoMAE: Low-level Vision Masked Autoencoders for Low-dose CT Denoising",
            "updated": "2023-10-19T01:34:30Z",
            "published": "2023-10-19T01:34:30Z",
            "summary": "Low-dose computed tomography (LDCT) offers reduced X-ray radiation exposure\nbut at the cost of compromised image quality, characterized by increased noise\nand artifacts. Recently, transformer models emerged as a promising avenue to\nenhance LDCT image quality. However, the success of such models relies on a\nlarge amount of paired noisy and clean images, which are often scarce in\nclinical settings. In the fields of computer vision and natural language\nprocessing, masked autoencoders (MAE) have been recognized as an effective\nlabel-free self-pretraining method for transformers, due to their exceptional\nfeature representation ability. However, the original pretraining and\nfine-tuning design fails to work in low-level vision tasks like denoising. In\nresponse to this challenge, we redesign the classical encoder-decoder learning\nmodel and facilitate a simple yet effective low-level vision MAE, referred to\nas LoMAE, tailored to address the LDCT denoising problem. Moreover, we\nintroduce an MAE-GradCAM method to shed light on the latent learning mechanisms\nof the MAE/LoMAE. Additionally, we explore the LoMAE's robustness and\ngenerability across a variety of noise levels. Experiments results show that\nthe proposed LoMAE can enhance the transformer's denoising performance and\ngreatly relieve the dependence on the ground truth clean data. It also\ndemonstrates remarkable robustness and generalizability over a spectrum of\nnoise levels.",
            "author": [
                "Dayang Wang",
                "Yongshun Xu",
                "Shuo Han",
                "Zhan Wu",
                "Li Zhou",
                "Bahareh Morovati",
                "Hengyong Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12405v1",
                "http://arxiv.org/pdf/2310.12405v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12404v1",
            "title": "Loop Copilot: Conducting AI Ensembles for Music Generation and Iterative\n  Editing",
            "updated": "2023-10-19T01:20:12Z",
            "published": "2023-10-19T01:20:12Z",
            "summary": "Creating music is iterative, requiring varied methods at each stage. However,\nexisting AI music systems fall short in orchestrating multiple subsystems for\ndiverse needs. To address this gap, we introduce Loop Copilot, a novel system\nthat enables users to generate and iteratively refine music through an\ninteractive, multi-round dialogue interface. The system uses a large language\nmodel to interpret user intentions and select appropriate AI models for task\nexecution. Each backend model is specialized for a specific task, and their\noutputs are aggregated to meet the user's requirements. To ensure musical\ncoherence, essential attributes are maintained in a centralized table. We\nevaluate the effectiveness of the proposed system through semi-structured\ninterviews and questionnaires, highlighting its utility not only in\nfacilitating music creation but also its potential for broader applications.",
            "author": [
                "Yixiao Zhang",
                "Akira Maezawa",
                "Gus Xia",
                "Kazuhiko Yamamoto",
                "Simon Dixon"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12404v1",
                "http://arxiv.org/pdf/2310.12404v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CL",
                "cs.HC",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12403v2",
            "title": "Cooperative Minibatching in Graph Neural Networks",
            "updated": "2023-10-22T02:01:01Z",
            "published": "2023-10-19T01:15:24Z",
            "summary": "Significant computational resources are required to train Graph Neural\nNetworks (GNNs) at a large scale, and the process is highly data-intensive. One\nof the most effective ways to reduce resource requirements is minibatch\ntraining coupled with graph sampling. GNNs have the unique property that items\nin a minibatch have overlapping data. However, the commonly implemented\nIndependent Minibatching approach assigns each Processing Element (PE) its own\nminibatch to process, leading to duplicated computations and input data access\nacross PEs. This amplifies the Neighborhood Explosion Phenomenon (NEP), which\nis the main bottleneck limiting scaling. To reduce the effects of NEP in the\nmulti-PE setting, we propose a new approach called Cooperative Minibatching.\nOur approach capitalizes on the fact that the size of the sampled subgraph is a\nconcave function of the batch size, leading to significant reductions in the\namount of work per seed vertex as batch sizes increase. Hence, it is favorable\nfor processors equipped with a fast interconnect to work on a large minibatch\ntogether as a single larger processor, instead of working on separate smaller\nminibatches, even though global batch size is identical. We also show how to\ntake advantage of the same phenomenon in serial execution by generating\ndependent consecutive minibatches. Our experimental evaluations show up to 4x\nbandwidth savings for fetching vertex embeddings, by simply increasing this\ndependency without harming model convergence. Combining our proposed\napproaches, we achieve up to 64% speedup over Independent Minibatching on\nsingle-node multi-GPU systems.",
            "author": [
                "Muhammed Fatih Balin",
                "Dominique LaSalle",
                "\u00dcmit V. \u00c7ataly\u00fcrek"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12403v2",
                "http://arxiv.org/pdf/2310.12403v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12395v1",
            "title": "Closed-Form Diffusion Models",
            "updated": "2023-10-19T00:45:05Z",
            "published": "2023-10-19T00:45:05Z",
            "summary": "Score-based generative models (SGMs) sample from a target distribution by\niteratively transforming noise using the score function of the perturbed\ntarget. For any finite training set, this score function can be evaluated in\nclosed form, but the resulting SGM memorizes its training data and does not\ngenerate novel samples. In practice, one approximates the score by training a\nneural network via score-matching. The error in this approximation promotes\ngeneralization, but neural SGMs are costly to train and sample, and the\neffective regularization this error provides is not well-understood\ntheoretically. In this work, we instead explicitly smooth the closed-form score\nto obtain an SGM that generates novel samples without training. We analyze our\nmodel and propose an efficient nearest-neighbor-based estimator of its score\nfunction. Using this estimator, our method achieves sampling times competitive\nwith neural SGMs while running on consumer-grade CPUs.",
            "author": [
                "Christopher Scarvelis",
                "Haitz S\u00e1ez de Oc\u00e1riz Borde",
                "Justin Solomon"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12395v1",
                "http://arxiv.org/pdf/2310.12395v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12393v1",
            "title": "Deep Learning Techniques for Video Instance Segmentation: A Survey",
            "updated": "2023-10-19T00:27:30Z",
            "published": "2023-10-19T00:27:30Z",
            "summary": "Video instance segmentation, also known as multi-object tracking and\nsegmentation, is an emerging computer vision research area introduced in 2019,\naiming at detecting, segmenting, and tracking instances in videos\nsimultaneously. By tackling the video instance segmentation tasks through\neffective analysis and utilization of visual information in videos, a range of\ncomputer vision-enabled applications (e.g., human action recognition, medical\nimage processing, autonomous vehicle navigation, surveillance, etc) can be\nimplemented. As deep-learning techniques take a dominant role in various\ncomputer vision areas, a plethora of deep-learning-based video instance\nsegmentation schemes have been proposed. This survey offers a multifaceted view\nof deep-learning schemes for video instance segmentation, covering various\narchitectural paradigms, along with comparisons of functional performance,\nmodel complexity, and computational overheads. In addition to the common\narchitectural designs, auxiliary techniques for improving the performance of\ndeep-learning models for video instance segmentation are compiled and\ndiscussed. Finally, we discuss a range of major challenges and directions for\nfurther investigations to help advance this promising research field.",
            "author": [
                "Chenhao Xu",
                "Chang-Tsun Li",
                "Yongjian Hu",
                "Chee Peng Lim",
                "Douglas Creighton"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12393v1",
                "http://arxiv.org/pdf/2310.12393v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12389v2",
            "title": "Quantum Computing for MIMO Beam Selection Problem: Model and Optical\n  Experimental Solution",
            "updated": "2023-10-29T11:22:49Z",
            "published": "2023-10-19T00:12:20Z",
            "summary": "Massive multiple-input multiple-output (MIMO) has gained widespread\npopularity in recent years due to its ability to increase data rates, improve\nsignal quality, and provide better coverage in challenging environments. In\nthis paper, we investigate the MIMO beam selection (MBS) problem, which is\nproven to be NP-hard and computationally intractable. To deal with this\nproblem, quantum computing that can provide faster and more efficient solutions\nto large-scale combinatorial optimization is considered. MBS is formulated in a\nquadratic unbounded binary optimization form and solved with Coherent Ising\nMachine (CIM) physical machine. We compare the performance of our solution with\ntwo classic heuristics, simulated annealing and Tabu search. The results\ndemonstrate an average performance improvement by a factor of 261.23 and 20.6,\nrespectively, which shows that CIM-based solution performs significantly better\nin terms of selecting the optimal subset of beams. This work shows great\npromise for practical 5G operation and promotes the application of quantum\ncomputing in solving computationally hard problems in communication.",
            "author": [
                "Yuhong Huang",
                "Wenxin Li",
                "Chengkang Pan",
                "Shuai Hou",
                "Xian Lu",
                "Chunfeng Cui",
                "Jingwei Wen",
                "Jiaqi Xu",
                "Chongyu Cao",
                "Yin Ma",
                "Hai Wei",
                "Kai Wen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12389v2",
                "http://arxiv.org/pdf/2310.12389v2"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12387v1",
            "title": "Learning to Solve Climate Sensor Placement Problems with a Transformer",
            "updated": "2023-10-18T23:58:54Z",
            "published": "2023-10-18T23:58:54Z",
            "summary": "The optimal placement of sensors for environmental monitoring and disaster\nmanagement is a challenging problem due to its NP-hard nature. Traditional\nmethods for sensor placement involve exact, approximation, or heuristic\napproaches, with the latter being the most widely used. However, heuristic\nmethods are limited by expert intuition and experience. Deep learning (DL) has\nemerged as a promising approach for generating heuristic algorithms\nautomatically. In this paper, we introduce a novel sensor placement approach\nfocused on learning improvement heuristics using deep reinforcement learning\n(RL) methods. Our approach leverages an RL formulation for learning improvement\nheuristics, driven by an actor-critic algorithm for training the policy\nnetwork. We compare our method with several state-of-the-art approaches by\nconducting comprehensive experiments, demonstrating the effectiveness and\nsuperiority of our proposed approach in producing high-quality solutions. Our\nwork presents a promising direction for applying advanced DL and RL techniques\nto challenging climate sensor placement problems.",
            "author": [
                "Chen Wang",
                "Victoria Huang",
                "Gang Chen",
                "Hui Ma",
                "Bryce Chen",
                "Jochen Schmidt"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12387v1",
                "http://arxiv.org/pdf/2310.12387v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12386v1",
            "title": "Online Learning and Planning in Cognitive Hierarchies",
            "updated": "2023-10-18T23:53:51Z",
            "published": "2023-10-18T23:53:51Z",
            "summary": "Complex robot behaviour typically requires the integration of multiple\nrobotic and Artificial Intelligence (AI) techniques and components. Integrating\nsuch disparate components into a coherent system, while also ensuring global\nproperties and behaviours, is a significant challenge for cognitive robotics.\nUsing a formal framework to model the interactions between components can be an\nimportant step in dealing with this challenge. In this paper we extend an\nexisting formal framework [Clark et al., 2016] to model complex integrated\nreasoning behaviours of robotic systems; from symbolic planning through to\nonline learning of policies and transition systems. Furthermore the new\nframework allows for a more flexible modelling of the interactions between\ndifferent reasoning components.",
            "author": [
                "Bernhard Hengst",
                "Maurice Pagnucco",
                "David Rajaratnam",
                "Claude Sammut",
                "Michael Thielscher"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12386v1",
                "http://arxiv.org/pdf/2310.12386v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13020v1",
            "title": "Quantum batteries -- The future of energy storage?",
            "updated": "2023-10-18T23:23:24Z",
            "published": "2023-10-18T23:23:24Z",
            "summary": "According to the International Energy Agency, each human uses more than 80 GJ\nof energy per year; this is equivalent to leaving a washing machine\ncontinuously running for one year for every person on Earth. This consumption\nis expected to increase by 28% by 2040 (from 2015 levels). The majority (86%)\nof this energy comes from fossil fuels. This dependence on fossil fuels comes\nwith major environmental costs, with climate change arguably being the greatest\nchallenge facing our era. Renewable energy offers a possible solution. However,\nrenewable energy sources, like solar and wind are not continuous sources, and\ntherefore energy storage technology or batteries, remain an urgent challenge\nfor further worldwide adoption of renewable energy. Alongside the need for\nefficient batteries to store renewable energy, the portability of batteries\nmakes them an essential component in mobile technologies, including electric\nvehicles. Current batteries operate on the basis of well-understood\nelectrochemical principles which were developed two centuries ago. While there\nis an ongoing intense effort aimed at improving their performance through\noptimization of the materials and the device architecture, it is worth\nexploring completely novel and disruptive approaches towards energy storage.\nQuantum batteries are energy storage devices that utilise quantum mechanics to\nenhance performance or functionality. While they are still in their infancy\nwith only proof-of-principle demonstrations achieved, their radically\ninnovative design principles offer a potential solution to future energy\nchallenges.",
            "author": [
                "James Q. Quach",
                "Giulio Cerullo",
                "Tersilla Virgili"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.joule.2023.09.003",
                "http://arxiv.org/abs/2310.13020v1",
                "http://arxiv.org/pdf/2310.13020v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12375v1",
            "title": "Nearly Optimal Bounds for Sample-Based Testing and Learning of\n  $k$-Monotone Functions",
            "updated": "2023-10-18T23:06:48Z",
            "published": "2023-10-18T23:06:48Z",
            "summary": "We study monotonicity testing of functions $f \\colon \\{0,1\\}^d \\to \\{0,1\\}$\nusing sample-based algorithms, which are only allowed to observe the value of\n$f$ on points drawn independently from the uniform distribution. A classic\nresult by Bshouty-Tamon (J. ACM 1996) proved that monotone functions can be\nlearned with $\\exp(O(\\min\\{\\frac{1}{\\varepsilon}\\sqrt{d},d\\}))$ samples and it\nis not hard to show that this bound extends to testing. Prior to our work the\nonly lower bound for this problem was $\\Omega(\\sqrt{\\exp(d)/\\varepsilon})$ in\nthe small $\\varepsilon$ parameter regime, when $\\varepsilon = O(d^{-3/2})$, due\nto Goldreich-Goldwasser-Lehman-Ron-Samorodnitsky (Combinatorica 2000). Thus,\nthe sample complexity of monotonicity testing was wide open for $\\varepsilon\n\\gg d^{-3/2}$. We resolve this question, obtaining a tight lower bound of\n$\\exp(\\Omega(\\min\\{\\frac{1}{\\varepsilon}\\sqrt{d},d\\}))$ for all $\\varepsilon$\nat most a sufficiently small constant. In fact, we prove a much more general\nresult, showing that the sample complexity of $k$-monotonicity testing and\nlearning for functions $f \\colon \\{0,1\\}^d \\to [r]$ is\n$\\exp(\\Theta(\\min\\{\\frac{rk}{\\varepsilon}\\sqrt{d},d\\}))$. For testing with\none-sided error we show that the sample complexity is $\\exp(\\Theta(d))$.\n  Beyond the hypercube, we prove nearly tight bounds (up to polylog factors of\n$d,k,r,1/\\varepsilon$ in the exponent) of\n$\\exp(\\widetilde{\\Theta}(\\min\\{\\frac{rk}{\\varepsilon}\\sqrt{d},d\\}))$ on the\nsample complexity of testing and learning measurable $k$-monotone functions $f\n\\colon \\mathbb{R}^d \\to [r]$ under product distributions. Our upper bound\nimproves upon the previous bound of\n$\\exp(\\widetilde{O}(\\min\\{\\frac{k}{\\varepsilon^2}\\sqrt{d},d\\}))$ by\nHarms-Yoshida (ICALP 2022) for Boolean functions ($r=2$).",
            "author": [
                "Hadley Black"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12375v1",
                "http://arxiv.org/pdf/2310.12375v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12373v1",
            "title": "Adaptive Fine-tuning based Transfer Learning for the Identification of\n  MGMT Promoter Methylation Status",
            "updated": "2023-10-18T22:58:51Z",
            "published": "2023-10-18T22:58:51Z",
            "summary": "Glioblastoma Multiforme (GBM) is an aggressive form of malignant brain tumor\nwith a generally poor prognosis. Treatment usually includes a mix of surgical\nresection, radiation therapy, and akylating chemotherapy but, even with these\nintensive treatments, the 2-year survival rate is still very low.\nO6-methylguanine-DNA methyltransferase (MGMT) promoter methylation has been\nshown to be a predictive bio-marker for resistance to chemotherapy, but it is\ninvasive and time-consuming to determine the methylation status. Due to this,\nthere has been effort to predict the MGMT methylation status through analyzing\nMRI scans using machine learning, which only requires pre-operative scans that\nare already part of standard-of-care for GBM patients. We developed a 3D\nSpotTune network with adaptive fine-tuning capability to improve the\nperformance of conventional transfer learning in the identification of MGMT\npromoter methylation status. Using the pretrained weights of MedicalNet coupled\nwith the SpotTune network, we compared its performance with two equivalent\nnetworks: one that is initialized with MedicalNet weights, but with no adaptive\nfine-tuning and one initialized with random weights. These three networks are\ntrained and evaluated using the UPENN-GBM dataset, a public GBM dataset\nprovided by the University of Pennsylvania. The SpotTune network showed better\nperformance than the network with randomly initialized weights and the\npre-trained MedicalNet with no adaptive fine-tuning. SpotTune enables transfer\nlearning to be adaptive to individual patients, resulting in improved\nperformance in predicting MGMT promoter methylation status in GBM using MRIs as\ncompared to conventional transfer learning without adaptive fine-tuning.",
            "author": [
                "Erich Schmitz",
                "Yunhui Guo",
                "Jing Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12373v1",
                "http://arxiv.org/pdf/2310.12373v1"
            ],
            "primary_category": "physics.med-ph",
            "category": [
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12370v1",
            "title": "No-Regret Learning in Bilateral Trade via Global Budget Balance",
            "updated": "2023-10-18T22:34:32Z",
            "published": "2023-10-18T22:34:32Z",
            "summary": "Bilateral trade revolves around the challenge of facilitating transactions\nbetween two strategic agents -- a seller and a buyer -- both of whom have a\nprivate valuations for the item. We study the online version of the problem, in\nwhich at each time step a new seller and buyer arrive. The learner's task is to\nset a price for each agent, without any knowledge about their valuations. The\nsequence of sellers and buyers is chosen by an oblivious adversary. In this\nsetting, known negative results rule out the possibility of designing\nalgorithms with sublinear regret when the learner has to guarantee budget\nbalance for each iteration. In this paper, we introduce the notion of global\nbudget balance, which requires the agent to be budget balance only over the\nentire time horizon. By requiring global budget balance, we provide the first\nno-regret algorithms for bilateral trade with adversarial inputs under various\nfeedback models. First, we show that in the full-feedback model the learner can\nguarantee $\\tilde{O}(\\sqrt{T})$ regret against the best fixed prices in\nhindsight, which is order-wise optimal. Then, in the case of partial feedback\nmodels, we provide an algorithm guaranteeing a $\\tilde{O}(T^{3/4})$ regret\nupper bound with one-bit feedback, which we complement with a nearly-matching\nlower bound. Finally, we investigate how these results vary when measuring\nregret using an alternative benchmark.",
            "author": [
                "Martino Bernasconi",
                "Matteo Castiglioni",
                "Andrea Celli",
                "Federico Fusco"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12370v1",
                "http://arxiv.org/pdf/2310.12370v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12362v1",
            "title": "REMARK-LLM: A Robust and Efficient Watermarking Framework for Generative\n  Large Language Models",
            "updated": "2023-10-18T22:14:37Z",
            "published": "2023-10-18T22:14:37Z",
            "summary": "We present REMARK-LLM, a novel efficient, and robust watermarking framework\ndesigned for texts generated by large language models (LLMs). Synthesizing\nhuman-like content using LLMs necessitates vast computational resources and\nextensive datasets, encapsulating critical intellectual property (IP). However,\nthe generated content is prone to malicious exploitation, including spamming\nand plagiarism. To address the challenges, REMARK-LLM proposes three new\ncomponents: (i) a learning-based message encoding module to infuse binary\nsignatures into LLM-generated texts; (ii) a reparameterization module to\ntransform the dense distributions from the message encoding to the sparse\ndistribution of the watermarked textual tokens; (iii) a decoding module\ndedicated for signature extraction; Furthermore, we introduce an optimized beam\nsearch algorithm to guarantee the coherence and consistency of the generated\ncontent. REMARK-LLM is rigorously trained to encourage the preservation of\nsemantic integrity in watermarked content, while ensuring effective watermark\nretrieval. Extensive evaluations on multiple unseen datasets highlight\nREMARK-LLM proficiency and transferability in inserting 2 times more signature\nbits into the same texts when compared to prior art, all while maintaining\nsemantic integrity. Furthermore, REMARK-LLM exhibits better resilience against\na spectrum of watermark detection and removal attacks.",
            "author": [
                "Ruisi Zhang",
                "Shehzeen Samarah Hussain",
                "Paarth Neekhara",
                "Farinaz Koushanfar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12362v1",
                "http://arxiv.org/pdf/2310.12362v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12360v1",
            "title": "GRI: Graph-based Relative Isomorphism of Word Embedding Spaces",
            "updated": "2023-10-18T22:10:47Z",
            "published": "2023-10-18T22:10:47Z",
            "summary": "Automated construction of bilingual dictionaries using monolingual embedding\nspaces is a core challenge in machine translation. The end performance of these\ndictionaries relies upon the geometric similarity of individual spaces, i.e.,\ntheir degree of isomorphism. Existing attempts aimed at controlling the\nrelative isomorphism of different spaces fail to incorporate the impact of\nsemantically related words in the training objective. To address this, we\npropose GRI that combines the distributional training objectives with attentive\ngraph convolutions to unanimously consider the impact of semantically similar\nwords required to define/compute the relative isomorphism of multiple spaces.\nExperimental evaluation shows that GRI outperforms the existing research by\nimproving the average P@1 by a relative score of up to 63.6%. We release the\ncodes for GRI at https://github.com/asif6827/GRI.",
            "author": [
                "Muhammad Asif Ali",
                "Yan Hu",
                "Jianbin Qin",
                "Di Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12360v1",
                "http://arxiv.org/pdf/2310.12360v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12359v1",
            "title": "MARVEL: Multi-Agent Reinforcement-Learning for Large-Scale Variable\n  Speed Limits",
            "updated": "2023-10-18T22:09:29Z",
            "published": "2023-10-18T22:09:29Z",
            "summary": "Variable speed limit (VSL) control is a promising traffic management strategy\nfor enhancing safety and mobility. This work introduces MARVEL, a multi-agent\nreinforcement learning (MARL) framework for implementing large-scale VSL\ncontrol on freeway corridors using only commonly available data. The agents\nlearn through a reward structure that incorporates adaptability to traffic\nconditions, safety, and mobility; enabling coordination among the agents. The\nproposed framework scales to cover corridors with many gantries thanks to a\nparameter sharing among all VSL agents. The agents are trained in a\nmicrosimulation environment based on a short freeway stretch with 8 gantries\nspanning 7 miles and tested with 34 gantries spanning 17 miles of I-24 near\nNashville, TN. MARVEL improves traffic safety by 63.4% compared to the no\ncontrol scenario and enhances traffic mobility by 14.6% compared to a\nstate-of-the-practice algorithm that has been deployed on I-24. An\nexplainability analysis is undertaken to explore the learned policy under\ndifferent traffic conditions and the results provide insights into the\ndecision-making process of agents. Finally, we test the policy learned from the\nsimulation-based experiments on real input data from I-24 to illustrate the\npotential deployment capability of the learned policy.",
            "author": [
                "Yuhang Zhang",
                "Marcos Quinones-Grueiro",
                "Zhiyao Zhang",
                "Yanbing Wang",
                "William Barbour",
                "Gautam Biswas",
                "Daniel Work"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12359v1",
                "http://arxiv.org/pdf/2310.12359v1"
            ],
            "primary_category": "cs.MA",
            "category": [
                "cs.MA",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12353v1",
            "title": "Networkwide Traffic State Forecasting Using Exogenous Information: A\n  Multi-Dimensional Graph Attention-Based Approach",
            "updated": "2023-10-18T21:57:20Z",
            "published": "2023-10-18T21:57:20Z",
            "summary": "Traffic state forecasting is crucial for traffic management and control\nstrategies, as well as user- and system-level decision making in the\ntransportation network. While traffic forecasting has been approached with a\nvariety of techniques over the last couple of decades, most approaches simply\nrely on endogenous traffic variables for state prediction, despite the evidence\nthat exogenous factors can significantly impact traffic conditions. This paper\nproposes a multi-dimensional spatio-temporal graph attention-based traffic\nprediction approach (M-STGAT), which predicts traffic based on past\nobservations of speed, along with lane closure events, temperature, and\nvisibility across the transportation network. The approach is based on a graph\nattention network architecture, which also learns based on the structure of the\ntransportation network on which these variables are observed. Numerical\nexperiments are performed using traffic speed and lane closure data from the\nCalifornia Department of Transportation (Caltrans) Performance Measurement\nSystem (PeMS). The corresponding weather data were downloaded from the National\nOceanic and Atmospheric Administration (NOOA) Automated Surface Observing\nSystems (ASOS). For comparison, the numerical experiments implement three\nalternative models which do not allow for the multi-dimensional input. The\nM-STGAT is shown to outperform the three alternative models, when performing\ntests using our primary data set for prediction with a 30-, 45-, and 60-minute\nprediction horizon, in terms of three error measures: Mean Absolute Error\n(MAE), Root Mean Square Error (RMSE) and Mean Absolute Percentage Error (MAPE).\nHowever, the model's transferability can vary for different transfer data sets\nand this aspect may require further investigation.",
            "author": [
                "Syed Islam",
                "Monika Filipovska"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12353v1",
                "http://arxiv.org/pdf/2310.12353v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12352v1",
            "title": "knn-seq: Efficient, Extensible kNN-MT Framework",
            "updated": "2023-10-18T21:56:04Z",
            "published": "2023-10-18T21:56:04Z",
            "summary": "k-nearest-neighbor machine translation (kNN-MT) boosts the translation\nquality of a pre-trained neural machine translation (NMT) model by utilizing\ntranslation examples during decoding. Translation examples are stored in a\nvector database, called a datastore, which contains one entry for each target\ntoken from the parallel data it is made from. Due to its size, it is\ncomputationally expensive both to construct and to retrieve examples from the\ndatastore. In this paper, we present an efficient and extensible kNN-MT\nframework, knn-seq, for researchers and developers that is carefully designed\nto run efficiently, even with a billion-scale large datastore. knn-seq is\ndeveloped as a plug-in on fairseq and easy to switch models and kNN indexes.\nExperimental results show that our implemented kNN-MT achieves a comparable\ngain to the original kNN-MT, and the billion-scale datastore construction took\n2.21 hours in the WMT'19 German-to-English translation task. We publish our\nknn-seq as an MIT-licensed open-source project and the code is available on\nhttps://github.com/naist-nlp/knn-seq . The demo video is available on\nhttps://youtu.be/zTDzEOq80m0 .",
            "author": [
                "Hiroyuki Deguchi",
                "Hayate Hirano",
                "Tomoki Hoshino",
                "Yuto Nishida",
                "Justin Vasselli",
                "Taro Watanabe"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12352v1",
                "http://arxiv.org/pdf/2310.12352v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12350v2",
            "title": "Equipping Federated Graph Neural Networks with Structure-aware Group\n  Fairness",
            "updated": "2023-10-25T22:29:50Z",
            "published": "2023-10-18T21:51:42Z",
            "summary": "Graph Neural Networks (GNNs) have been widely used for various types of graph\ndata processing and analytical tasks in different domains. Training GNNs over\ncentralized graph data can be infeasible due to privacy concerns and regulatory\nrestrictions. Thus, federated learning (FL) becomes a trending solution to\naddress this challenge in a distributed learning paradigm. However, as GNNs may\ninherit historical bias from training data and lead to discriminatory\npredictions, the bias of local models can be easily propagated to the global\nmodel in distributed settings. This poses a new challenge in mitigating bias in\nfederated GNNs. To address this challenge, we propose $\\text{F}^2$GNN, a Fair\nFederated Graph Neural Network, that enhances group fairness of federated GNNs.\nAs bias can be sourced from both data and learning algorithms, $\\text{F}^2$GNN\naims to mitigate both types of bias under federated settings. First, we provide\ntheoretical insights on the connection between data bias in a training graph\nand statistical fairness metrics of the trained GNN models. Based on the\ntheoretical analysis, we design $\\text{F}^2$GNN which contains two key\ncomponents: a fairness-aware local model update scheme that enhances group\nfairness of the local models on the client side, and a fairness-weighted global\nmodel update scheme that takes both data bias and fairness metrics of local\nmodels into consideration in the aggregation process. We evaluate\n$\\text{F}^2$GNN empirically versus a number of baseline methods, and\ndemonstrate that $\\text{F}^2$GNN outperforms these baselines in terms of both\nfairness and model accuracy.",
            "author": [
                "Nan Cui",
                "Xiuling Wang",
                "Wendy Hui Wang",
                "Violet Chen",
                "Yue Ning"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12350v2",
                "http://arxiv.org/pdf/2310.12350v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12347v2",
            "title": "VisGrader: Automatic Grading of D3 Visualizations",
            "updated": "2023-10-20T01:40:07Z",
            "published": "2023-10-18T21:45:30Z",
            "summary": "Manually grading D3 data visualizations is a challenging endeavor, and is\nespecially difficult for large classes with hundreds of students. Grading an\ninteractive visualization requires a combination of interactive, quantitative,\nand qualitative evaluation that are conventionally done manually and are\ndifficult to scale up as the visualization complexity, data size, and number of\nstudents increase. We present VisGrader, a first-of-its kind automatic grading\nmethod for D3 visualizations that scalably and precisely evaluates the data\nbindings, visual encodings, interactions, and design specifications used in a\nvisualization. Our method enhances students learning experience, enabling them\nto submit their code frequently and receive rapid feedback to better inform\niteration and improvement to their code and visualization design. We have\nsuccessfully deployed our method and auto-graded D3 submissions from more than\n4000 students in a visualization course at Georgia Tech, and received positive\nfeedback for expanding its adoption.",
            "author": [
                "Matthew Hull",
                "Vivian Pednekar",
                "Hannah Murray",
                "Nimisha Roy",
                "Emmanuel Tung",
                "Susanta Routray",
                "Connor Guerin",
                "Justin Chen",
                "Zijie J. Wang",
                "Seongmin Lee",
                "Mahdi Roozbahani",
                "Duen Horng Chau"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12347v2",
                "http://arxiv.org/pdf/2310.12347v2"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12346v1",
            "title": "Tracking electricity losses and their perceived causes using nighttime\n  light and social media",
            "updated": "2023-10-18T21:44:39Z",
            "published": "2023-10-18T21:44:39Z",
            "summary": "Urban environments are intricate systems where the breakdown of critical\ninfrastructure can impact both the economic and social well-being of\ncommunities. Electricity systems hold particular significance, as they are\nessential for other infrastructure, and disruptions can trigger widespread\nconsequences. Typically, assessing electricity availability requires\nground-level data, a challenge in conflict zones and regions with limited\naccess. This study shows how satellite imagery, social media, and information\nextraction can monitor blackouts and their perceived causes. Night-time light\ndata (in March 2019 for Caracas, Venezuela) is used to indicate blackout\nregions. Twitter data is used to determine sentiment and topic trends, while\nstatistical analysis and topic modeling delved into public perceptions\nregarding blackout causes. The findings show an inverse relationship between\nnighttime light intensity. Tweets mentioning the Venezuelan President displayed\nheightened negativity and a greater prevalence of blame-related terms,\nsuggesting a perception of government accountability for the outages.",
            "author": [
                "Samuel W Kerber",
                "Nicholas A Duncan",
                "Guillaume F LHer",
                "Morgan Bazilian",
                "Chris Elvidge",
                "Mark R Deinert"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12346v1",
                "http://arxiv.org/pdf/2310.12346v1"
            ],
            "primary_category": "physics.soc-ph",
            "category": [
                "physics.soc-ph",
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12345v1",
            "title": "ClusT3: Information Invariant Test-Time Training",
            "updated": "2023-10-18T21:43:37Z",
            "published": "2023-10-18T21:43:37Z",
            "summary": "Deep Learning models have shown remarkable performance in a broad range of\nvision tasks. However, they are often vulnerable against domain shifts at\ntest-time. Test-time training (TTT) methods have been developed in an attempt\nto mitigate these vulnerabilities, where a secondary task is solved at training\ntime simultaneously with the main task, to be later used as an self-supervised\nproxy task at test-time. In this work, we propose a novel unsupervised TTT\ntechnique based on the maximization of Mutual Information between multi-scale\nfeature maps and a discrete latent representation, which can be integrated to\nthe standard training as an auxiliary clustering task. Experimental results\ndemonstrate competitive classification performance on different popular\ntest-time adaptation benchmarks.",
            "author": [
                "Gustavo A. Vargas Hakim",
                "David Osowiechi",
                "Mehrdad Noori",
                "Milad Cheraghalikhani",
                "Ismail Ben Ayed",
                "Christian Desrosiers"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12345v1",
                "http://arxiv.org/pdf/2310.12345v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12344v1",
            "title": "LACMA: Language-Aligning Contrastive Learning with Meta-Actions for\n  Embodied Instruction Following",
            "updated": "2023-10-18T21:43:07Z",
            "published": "2023-10-18T21:43:07Z",
            "summary": "End-to-end Transformers have demonstrated an impressive success rate for\nEmbodied Instruction Following when the environment has been seen in training.\nHowever, they tend to struggle when deployed in an unseen environment. This\nlack of generalizability is due to the agent's insensitivity to subtle changes\nin natural language instructions. To mitigate this issue, we propose explicitly\naligning the agent's hidden states with the instructions via contrastive\nlearning. Nevertheless, the semantic gap between high-level language\ninstructions and the agent's low-level action space remains an obstacle.\nTherefore, we further introduce a novel concept of meta-actions to bridge the\ngap. Meta-actions are ubiquitous action patterns that can be parsed from the\noriginal action sequence. These patterns represent higher-level semantics that\nare intuitively aligned closer to the instructions. When meta-actions are\napplied as additional training signals, the agent generalizes better to unseen\nenvironments. Compared to a strong multi-modal Transformer baseline, we achieve\na significant 4.5% absolute gain in success rate in unseen environments of\nALFRED Embodied Instruction Following. Additional analysis shows that the\ncontrastive objective and meta-actions are complementary in achieving the best\nresults, and the resulting agent better aligns its states with corresponding\ninstructions, making it more suitable for real-world embodied agents. The code\nis available at: https://github.com/joeyy5588/LACMA.",
            "author": [
                "Cheng-Fu Yang",
                "Yen-Chun Chen",
                "Jianwei Yang",
                "Xiyang Dai",
                "Lu Yuan",
                "Yu-Chiang Frank Wang",
                "Kai-Wei Chang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12344v1",
                "http://arxiv.org/pdf/2310.12344v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12343v1",
            "title": "New Environment Adaptation with Few Shots for OFDM Receiver and mmWave\n  Beamforming",
            "updated": "2023-10-18T21:42:37Z",
            "published": "2023-10-18T21:42:37Z",
            "summary": "Few-shot learning (FSL) enables adaptation to new tasks with only limited\ntraining data. In wireless communications, channel environments can vary\ndrastically; therefore, FSL techniques can quickly adjust transceiver\naccordingly. In this paper, we develop two FSL frameworks that fit in wireless\ntransceiver design. Both frameworks are base on optimization programs that can\nbe solved by well-known algorithms like the inexact alternating direction\nmethod of multipliers (iADMM) and the inexact alternating direction method\n(iADM). As examples, we demonstrate how the proposed two FSL frameworks are\nused for the OFDM receiver and beamforming (BF) for the millimeter wave\n(mmWave) system. The numerical experiments confirm their desirable performance\nin both applications compared to other popular approaches, such as transfer\nlearning (TL) and model-agnostic meta-learning.",
            "author": [
                "Ouya Wang",
                "Shenglong Zhou",
                "Geoffrey Ye Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12343v1",
                "http://arxiv.org/pdf/2310.12343v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12334v2",
            "title": "Improving Representation Learning for Histopathologic Images with\n  Cluster Constraints",
            "updated": "2023-11-14T12:04:24Z",
            "published": "2023-10-18T21:20:44Z",
            "summary": "Recent advances in whole-slide image (WSI) scanners and computational\ncapabilities have significantly propelled the application of artificial\nintelligence in histopathology slide analysis. While these strides are\npromising, current supervised learning approaches for WSI analysis come with\nthe challenge of exhaustively labeling high-resolution slides - a process that\nis both labor-intensive and time-consuming. In contrast, self-supervised\nlearning (SSL) pretraining strategies are emerging as a viable alternative,\ngiven that they don't rely on explicit data annotations. These SSL strategies\nare quickly bridging the performance disparity with their supervised\ncounterparts. In this context, we introduce an SSL framework. This framework\naims for transferable representation learning and semantically meaningful\nclustering by synergizing invariance loss and clustering loss in WSI analysis.\nNotably, our approach outperforms common SSL methods in downstream\nclassification and clustering tasks, as evidenced by tests on the Camelyon16\nand a pancreatic cancer dataset.",
            "author": [
                "Weiyi Wu",
                "Chongyang Gao",
                "Joseph DiPalma",
                "Soroush Vosoughi",
                "Saeed Hassanpour"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12334v2",
                "http://arxiv.org/pdf/2310.12334v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12324v1",
            "title": "Opportunities for Adaptive Experiments to Enable Continuous Improvement\n  that Trades-off Instructor and Researcher Incentives",
            "updated": "2023-10-18T20:54:59Z",
            "published": "2023-10-18T20:54:59Z",
            "summary": "Randomized experimental comparisons of alternative pedagogical strategies\ncould provide useful empirical evidence in instructors' decision-making.\nHowever, traditional experiments do not have a clear and simple pathway to\nusing data rapidly to try to increase the chances that students in an\nexperiment get the best conditions. Drawing inspiration from the use of machine\nlearning and experimentation in product development at leading technology\ncompanies, we explore how adaptive experimentation might help in continuous\ncourse improvement. In adaptive experiments, as different arms/conditions are\ndeployed to students, data is analyzed and used to change the experience for\nfuture students. This can be done using machine learning algorithms to identify\nwhich actions are more promising for improving student experience or outcomes.\nThis algorithm can then dynamically deploy the most effective conditions to\nfuture students, resulting in better support for students' needs. We illustrate\nthe approach with a case study providing a side-by-side comparison of\ntraditional and adaptive experimentation of self-explanation prompts in online\nhomework problems in a CS1 course. This provides a first step in exploring the\nfuture of how this methodology can be useful in bridging research and practice\nin doing continuous improvement.",
            "author": [
                "Ilya Musabirov",
                "Angela Zavaleta-Bernuy",
                "Pan Chen",
                "Michael Liut",
                "Joseph Jay Williams"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12324v1",
                "http://arxiv.org/pdf/2310.12324v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12309v1",
            "title": "A Unifying Framework for Learning Argumentation Semantics",
            "updated": "2023-10-18T20:18:05Z",
            "published": "2023-10-18T20:18:05Z",
            "summary": "Argumentation is a very active research field of Artificial Intelligence\nconcerned with the representation and evaluation of arguments used in dialogues\nbetween humans and/or artificial agents. Acceptability semantics of formal\nargumentation systems define the criteria for the acceptance or rejection of\narguments. Several software systems, known as argumentation solvers, have been\ndeveloped to compute the accepted/rejected arguments using such criteria. These\ninclude systems that learn to identify the accepted arguments using\nnon-interpretable methods. In this paper we present a novel framework, which\nuses an Inductive Logic Programming approach to learn the acceptability\nsemantics for several abstract and structured argumentation frameworks in an\ninterpretable way. Through an empirical evaluation we show that our framework\noutperforms existing argumentation solvers, thus opening up new future research\ndirections in the area of formal argumentation and human-machine dialogues.",
            "author": [
                "Zlatina Mileva",
                "Antonis Bikakis",
                "Fabio Aurelio D'Asaro",
                "Mark Law",
                "Alessandra Russo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12309v1",
                "http://arxiv.org/pdf/2310.12309v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12304v1",
            "title": "Preference Optimization for Molecular Language Models",
            "updated": "2023-10-18T20:11:46Z",
            "published": "2023-10-18T20:11:46Z",
            "summary": "Molecular language modeling is an effective approach to generating novel\nchemical structures. However, these models do not \\emph{a priori} encode\ncertain preferences a chemist may desire. We investigate the use of fine-tuning\nusing Direct Preference Optimization to better align generated molecules with\nchemist preferences. Our findings suggest that this approach is simple,\nefficient, and highly effective.",
            "author": [
                "Ryan Park",
                "Ryan Theisen",
                "Navriti Sahni",
                "Marcel Patek",
                "Anna Cicho\u0144ska",
                "Rayees Rahman"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12304v1",
                "http://arxiv.org/pdf/2310.12304v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12303v1",
            "title": "Document-Level Language Models for Machine Translation",
            "updated": "2023-10-18T20:10:07Z",
            "published": "2023-10-18T20:10:07Z",
            "summary": "Despite the known limitations, most machine translation systems today still\noperate on the sentence-level. One reason for this is, that most parallel\ntraining data is only sentence-level aligned, without document-level meta\ninformation available. In this work, we set out to build context-aware\ntranslation systems utilizing document-level monolingual data instead. This can\nbe achieved by combining any existing sentence-level translation model with a\ndocument-level language model. We improve existing approaches by leveraging\nrecent advancements in model combination. Additionally, we propose novel\nweighting techniques that make the system combination more flexible and\nsignificantly reduce computational overhead. In a comprehensive evaluation on\nfour diverse translation tasks, we show that our extensions improve\ndocument-targeted scores substantially and are also computationally more\nefficient. However, we also find that in most scenarios, back-translation gives\neven better results, at the cost of having to re-train the translation system.\nFinally, we explore language model fusion in the light of recent advancements\nin large language models. Our findings suggest that there might be strong\npotential in utilizing large language models via model combination.",
            "author": [
                "Frithjof Petrick",
                "Christian Herold",
                "Pavel Petrushkov",
                "Shahram Khadivi",
                "Hermann Ney"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12303v1",
                "http://arxiv.org/pdf/2310.12303v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12300v1",
            "title": "Measuring Pointwise $\\mathcal{V}$-Usable Information In-Context-ly",
            "updated": "2023-10-18T20:07:41Z",
            "published": "2023-10-18T20:07:41Z",
            "summary": "In-context learning (ICL) is a new learning paradigm that has gained\npopularity along with the development of large language models. In this work,\nwe adapt a recently proposed hardness metric, pointwise $\\mathcal{V}$-usable\ninformation (PVI), to an in-context version (in-context PVI). Compared to the\noriginal PVI, in-context PVI is more efficient in that it requires only a few\nexemplars and does not require fine-tuning. We conducted a comprehensive\nempirical analysis to evaluate the reliability of in-context PVI. Our findings\nindicate that in-context PVI estimates exhibit similar characteristics to the\noriginal PVI. Specific to the in-context setting, we show that in-context PVI\nestimates remain consistent across different exemplar selections and numbers of\nshots. The variance of in-context PVI estimates across different exemplar\nselections is insignificant, which suggests that in-context PVI are stable.\nFurthermore, we demonstrate how in-context PVI can be employed to identify\nchallenging instances. Our work highlights the potential of in-context PVI and\nprovides new insights into the capabilities of ICL.",
            "author": [
                "Sheng Lu",
                "Shan Chen",
                "Yingya Li",
                "Danielle Bitterman",
                "Guergana Savova",
                "Iryna Gurevych"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12300v1",
                "http://arxiv.org/pdf/2310.12300v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12298v2",
            "title": "Jorge: Approximate Preconditioning for GPU-efficient Second-order\n  Optimization",
            "updated": "2023-10-27T03:59:42Z",
            "published": "2023-10-18T19:58:54Z",
            "summary": "Despite their better convergence properties compared to first-order\noptimizers, second-order optimizers for deep learning have been less popular\ndue to their significant computational costs. The primary efficiency bottleneck\nin such optimizers is matrix inverse calculations in the preconditioning step,\nwhich are expensive to compute on GPUs. In this paper, we introduce Jorge, a\nsecond-order optimizer that promises the best of both worlds -- rapid\nconvergence benefits of second-order methods, and high computational efficiency\ntypical of first-order methods. We address the primary computational bottleneck\nof computing matrix inverses by completely eliminating them using an\napproximation of the preconditioner computation. This makes Jorge extremely\nefficient on GPUs in terms of wall-clock time. Further, we describe an approach\nto determine Jorge's hyperparameters directly from a well-tuned SGD baseline,\nthereby significantly minimizing tuning efforts. Our empirical evaluations\ndemonstrate the distinct advantages of using Jorge, outperforming\nstate-of-the-art optimizers such as SGD, AdamW, and Shampoo across multiple\ndeep learning models, both in terms of sample efficiency and wall-clock time.",
            "author": [
                "Siddharth Singh",
                "Zachary Sating",
                "Abhinav Bhatele"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12298v2",
                "http://arxiv.org/pdf/2310.12298v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12294v1",
            "title": "Open-Set Multivariate Time-Series Anomaly Detection",
            "updated": "2023-10-18T19:55:11Z",
            "published": "2023-10-18T19:55:11Z",
            "summary": "Numerous methods for time series anomaly detection (TSAD) methods have\nemerged in recent years. Most existing methods are unsupervised and assume the\navailability of normal training samples only, while few supervised methods have\nshown superior performance by incorporating labeled anomalous samples in the\ntraining phase. However, certain anomaly types are inherently challenging for\nunsupervised methods to differentiate from normal data, while supervised\nmethods are constrained to detecting anomalies resembling those present during\ntraining, failing to generalize to unseen anomaly classes. This paper is the\nfirst attempt in providing a novel approach for the open-set TSAD problem, in\nwhich a small number of labeled anomalies from a limited class of anomalies are\nvisible in the training phase, with the objective of detecting both seen and\nunseen anomaly classes in the test phase. The proposed method, called\nMultivariate Open-Set timeseries Anomaly Detection (MOSAD) consists of three\nprimary modules: a Feature Extractor to extract meaningful time-series\nfeatures; a Multi-head Network consisting of Generative-, Deviation-, and\nContrastive heads for capturing both seen and unseen anomaly classes; and an\nAnomaly Scoring module leveraging the insights of the three heads to detect\nanomalies. Extensive experiments on three real-world datasets consistently show\nthat our approach surpasses existing methods under various experimental\nsettings, thus establishing a new state-of-the-art performance in the TSAD\nfield.",
            "author": [
                "Thomas Lai",
                "Thi Kieu Khanh Ho",
                "Narges Armanfard"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12294v1",
                "http://arxiv.org/pdf/2310.12294v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12292v1",
            "title": "Multi-domain analysis and prediction of the light emitted by an\n  inductively coupled plasma jet",
            "updated": "2023-10-18T19:47:25Z",
            "published": "2023-10-18T19:47:25Z",
            "summary": "Inductively coupled plasma wind tunnels are crucial for replicating\nhypersonic flight conditions in ground testing. Achieving the desired\nconditions (e.g., stagnation-point heat fluxes and enthalpies during\natmospheric reentry) requires a careful selection of operating inputs, such as\nmass flow, gas composition, nozzle geometry, torch power, chamber pressure, and\nprobing location along the plasma jet. The study presented herein focuses on\nthe influence of the torch power and chamber pressure on the plasma jet\ndynamics within the 350 kW Plasmatron X ICP facility at the University of\nIllinois at Urbana-Champaign. A multi-domain analysis of the jet behavior under\nselected power-pressure conditions is presented in terms of emitted light\nmeasurements collected using high-speed imaging. We then use Gaussian Process\nRegression to develop a data-informed learning framework for predicting\nPlasmatron X jet profiles at unseen pressure and power test conditions.\nUnderstanding the physics behind the dynamics of high-enthalpy flows,\nparticularly plasma jets, is the key to properly design material testing,\nperform diagnostics, and develop accurate simulation models",
            "author": [
                "Lorenzo Capponi",
                "Alberto Padovan",
                "Gregory S. Elliott",
                "Marco Panesi",
                "Daniel J. Bodony",
                "Francesco Panerai"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12292v1",
                "http://arxiv.org/pdf/2310.12292v1"
            ],
            "primary_category": "physics.plasm-ph",
            "category": [
                "physics.plasm-ph",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12290v1",
            "title": "Fact-based Agent modeling for Multi-Agent Reinforcement Learning",
            "updated": "2023-10-18T19:43:38Z",
            "published": "2023-10-18T19:43:38Z",
            "summary": "In multi-agent systems, agents need to interact and collaborate with other\nagents in environments. Agent modeling is crucial to facilitate agent\ninteractions and make adaptive cooperation strategies. However, it is\nchallenging for agents to model the beliefs, behaviors, and intentions of other\nagents in non-stationary environment where all agent policies are learned\nsimultaneously. In addition, the existing methods realize agent modeling\nthrough behavior cloning which assume that the local information of other\nagents can be accessed during execution or training. However, this assumption\nis infeasible in unknown scenarios characterized by unknown agents, such as\ncompetition teams, unreliable communication and federated learning due to\nprivacy concerns. To eliminate this assumption and achieve agent modeling in\nunknown scenarios, Fact-based Agent modeling (FAM) method is proposed in which\nfact-based belief inference (FBI) network models other agents in partially\nobservable environment only based on its local information. The reward and\nobservation obtained by agents after taking actions are called facts, and FAM\nuses facts as reconstruction target to learn the policy representation of other\nagents through a variational autoencoder. We evaluate FAM on various Multiagent\nParticle Environment (MPE) and compare the results with several\nstate-of-the-art MARL algorithms. Experimental results show that compared with\nbaseline methods, FAM can effectively improve the efficiency of agent policy\nlearning by making adaptive cooperation strategies in multi-agent reinforcement\nlearning tasks, while achieving higher returns in complex\ncompetitive-cooperative mixed scenarios.",
            "author": [
                "Baofu Fang",
                "Caiming Zheng",
                "Hao Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12290v1",
                "http://arxiv.org/pdf/2310.12290v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12289v1",
            "title": "Deep Incremental Learning of Imbalanced Data for Just-In-Time Software\n  Defect Prediction",
            "updated": "2023-10-18T19:42:34Z",
            "published": "2023-10-18T19:42:34Z",
            "summary": "This work stems from three observations on prior Just-In-Time Software Defect\nPrediction (JIT-SDP) models. First, prior studies treat the JIT-SDP problem\nsolely as a classification problem. Second, prior JIT-SDP studies do not\nconsider that class balancing processing may change the underlying\ncharacteristics of software changeset data. Third, only a single source of\nconcept drift, the class imbalance evolution is addressed in prior JIT-SDP\nincremental learning models.\n  We propose an incremental learning framework called CPI-JIT for JIT-SDP.\nFirst, in addition to a classification modeling component, the framework\nincludes a time-series forecast modeling component in order to learn temporal\ninterdependent relationship in the changesets. Second, the framework features a\npurposefully designed over-sampling balancing technique based on SMOTE and\nPrincipal Curves called SMOTE-PC. SMOTE-PC preserves the underlying\ndistribution of software changeset data.\n  In this framework, we propose an incremental deep neural network model called\nDeepICP. Via an evaluation using \\numprojs software projects, we show that: 1)\nSMOTE-PC improves the model's predictive performance; 2) to some software\nprojects it can be beneficial for defect prediction to harness temporal\ninterdependent relationship of software changesets; and 3) principal curves\nsummarize the underlying distribution of changeset data and reveals a new\nsource of concept drift that the DeepICP model is proposed to adapt to.",
            "author": [
                "Yunhua Zhao",
                "Hui Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12289v1",
                "http://arxiv.org/pdf/2310.12289v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12285v1",
            "title": "Sparse high-dimensional linear mixed modeling with a partitioned\n  empirical Bayes ECM algorithm",
            "updated": "2023-10-18T19:34:56Z",
            "published": "2023-10-18T19:34:56Z",
            "summary": "High-dimensional longitudinal data is increasingly used in a wide range of\nscientific studies. However, there are few statistical methods for\nhigh-dimensional linear mixed models (LMMs), as most Bayesian variable\nselection or penalization methods are designed for independent observations.\nAdditionally, the few available software packages for high-dimensional LMMs\nsuffer from scalability issues. This work presents an efficient and accurate\nBayesian framework for high-dimensional LMMs. We use empirical Bayes estimators\nof hyperparameters for increased flexibility and an\nExpectation-Conditional-Minimization (ECM) algorithm for computationally\nefficient maximum a posteriori probability (MAP) estimation of parameters. The\nnovelty of the approach lies in its partitioning and parameter expansion as\nwell as its fast and scalable computation. We illustrate Linear Mixed Modeling\nwith PaRtitiOned empirical Bayes ECM (LMM-PROBE) in simulation studies\nevaluating fixed and random effects estimation along with computation time. A\nreal-world example is provided using data from a study of lupus in children,\nwhere we identify genes and clinical factors associated with a new lupus\nbiomarker and predict the biomarker over time.",
            "author": [
                "Anja Zgodic",
                "Ray Bai",
                "Jiajia Zhang",
                "Alexander C. McLain"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12285v1",
                "http://arxiv.org/pdf/2310.12285v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.CO",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12284v1",
            "title": "Channel Estimation via Loss Field: Accurate Site-Trained Modeling for\n  Shadowing Prediction",
            "updated": "2023-10-18T19:32:32Z",
            "published": "2023-10-18T19:32:32Z",
            "summary": "Future mobile ad hoc networks will share spectrum between many users.\nChannels will be assigned on the fly to guarantee signal and interference power\nrequirements for requested links. Channel losses must be re-estimated between\nmany pairs of users as they move and as environmental conditions change.\nComputational complexity must be low, precluding the use of some accurate but\ncomputationally intensive site-specific channel models. Channel model errors\nmust be low, precluding the use of standard statistical channel models. We\npropose a new channel model, CELF, which uses channel loss measurements from a\ndeployed network in the area and a Bayesian linear regression method to\nestimate a site-specific loss field for the area. The loss field is explainable\nas the site's 'shadowing' of the radio propagation across the area of interest,\nbut it requires no site-specific terrain or building information. Then, for any\narbitrary pair of transmitter and receiver positions, CELF sums the loss field\nnear the link line to estimate its channel loss. We use extensive measurements\nto show that CELF lowers the variance of channel estimates by up to 56%. It\noutperforms 3 popular machine learning methods in variance reduction and\ntraining efficiency.",
            "author": [
                "Jie Wang",
                "Meles G. Weldegebriel",
                "Neal Patwari"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12284v1",
                "http://arxiv.org/pdf/2310.12284v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12281v1",
            "title": "Enhancing the Performance of Automated Grade Prediction in MOOC using\n  Graph Representation Learning",
            "updated": "2023-10-18T19:27:39Z",
            "published": "2023-10-18T19:27:39Z",
            "summary": "In recent years, Massive Open Online Courses (MOOCs) have gained significant\ntraction as a rapidly growing phenomenon in online learning. Unlike traditional\nclassrooms, MOOCs offer a unique opportunity to cater to a diverse audience\nfrom different backgrounds and geographical locations. Renowned universities\nand MOOC-specific providers, such as Coursera, offer MOOC courses on various\nsubjects. Automated assessment tasks like grade and early dropout predictions\nare necessary due to the high enrollment and limited direct interaction between\nteachers and learners. However, current automated assessment approaches\noverlook the structural links between different entities involved in the\ndownstream tasks, such as the students and courses. Our hypothesis suggests\nthat these structural relationships, manifested through an interaction graph,\ncontain valuable information that can enhance the performance of the task at\nhand. To validate this, we construct a unique knowledge graph for a large MOOC\ndataset, which will be publicly available to the research community.\nFurthermore, we utilize graph embedding techniques to extract latent structural\ninformation encoded in the interactions between entities in the dataset. These\ntechniques do not require ground truth labels and can be utilized for various\ntasks. Finally, by combining entity-specific features, behavioral features, and\nextracted structural features, we enhance the performance of predictive machine\nlearning models in student assignment grade prediction. Our experiments\ndemonstrate that structural features can significantly improve the predictive\nperformance of downstream assessment tasks. The code and data are available in\n\\url{https://github.com/DSAatUSU/MOOPer_grade_prediction}",
            "author": [
                "Soheila Farokhi",
                "Aswani Yaramala",
                "Jiangtao Huang",
                "Muhammad F. A. Khan",
                "Xiaojun Qi",
                "Hamid Karimi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12281v1",
                "http://arxiv.org/pdf/2310.12281v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12278v1",
            "title": "Enhanced production of $\u039b_{b}^{0}$ baryons in high-multiplicity\n  $pp$ collisions at $\\sqrt{s} = 13$ TeV",
            "updated": "2023-10-18T19:25:18Z",
            "published": "2023-10-18T19:25:18Z",
            "summary": "The production rate of $\\Lambda_{b}^{0}$ baryons relative to $B^{0}$ mesons\nin $pp$ collisions at a center-of-mass energy $\\sqrt{s} = 13$ TeV is measured\nby the LHCb experiment. The ratio of $\\Lambda_{b}^{0}$ to $B^{0}$ production\ncross-sections shows a significant dependence on both the transverse momentum\nand the measured charged-particle multiplicity. At low multiplicity, the ratio\nmeasured at LHCb is consistent with the value measured in $e^{+}e^{-}$\ncollisions, and increases by a factor of $\\sim2$ with increasing multiplicity.\nAt relatively low transverse momentum, the ratio of $\\Lambda_{b}^{0}$ to\n$B^{0}$ cross-sections is higher than what is measured in $e^{+}e^{-}$\ncollisions, but converges with the $e^{+}e^{-}$ ratio as the momentum\nincreases. These results imply that the evolution of heavy $b$ quarks into\nfinal-state hadrons is influenced by the density of the hadronic environment\nproduced in the collision. Comparisons with a statistical hadronization model\nand implications for the mechanisms enforcing quark confinement are discussed.",
            "author": [
                "LHCb collaboration",
                "R. Aaij",
                "A. S. W. Abdelmotteleb",
                "C. Abellan Beteta",
                "F. Abudin\u00e9n",
                "T. Ackernley",
                "B. Adeva",
                "M. Adinolfi",
                "P. Adlarson",
                "C. Agapopoulou",
                "C. A. Aidala",
                "Z. Ajaltouni",
                "S. Akar",
                "K. Akiba",
                "P. Albicocco",
                "J. Albrecht",
                "F. Alessio",
                "M. Alexander",
                "A. Alfonso Albero",
                "Z. Aliouche",
                "P. Alvarez Cartelle",
                "R. Amalric",
                "S. Amato",
                "J. L. Amey",
                "Y. Amhis",
                "L. An",
                "L. Anderlini",
                "M. Andersson",
                "A. Andreianov",
                "P. Andreola",
                "M. Andreotti",
                "D. Andreou",
                "A. A. Anelli",
                "D. Ao",
                "F. Archilli",
                "M. Argenton",
                "S. Arguedas Cuendis",
                "A. Artamonov",
                "M. Artuso",
                "E. Aslanides",
                "M. Atzeni",
                "B. Audurier",
                "D. Bacher",
                "I. Bachiller Perea",
                "S. Bachmann",
                "M. Bachmayer",
                "J. J. Back",
                "A. Bailly-reyre",
                "P. Baladron Rodriguez",
                "V. Balagura",
                "W. Baldini",
                "J. Baptista de Souza Leite",
                "M. Barbetti",
                "I. R. Barbosa",
                "R. J. Barlow",
                "S. Barsuk",
                "W. Barter",
                "M. Bartolini",
                "F. Baryshnikov",
                "J. M. Basels",
                "G. Bassi",
                "B. Batsukh",
                "A. Battig",
                "A. Bay",
                "A. Beck",
                "M. Becker",
                "F. Bedeschi",
                "I. B. Bediaga",
                "A. Beiter",
                "S. Belin",
                "V. Bellee",
                "K. Belous",
                "I. Belov",
                "I. Belyaev",
                "G. Benane",
                "G. Bencivenni",
                "E. Ben-Haim",
                "A. Berezhnoy",
                "J. L. M. Berkey",
                "R. Bernet",
                "S. Bernet Andres",
                "H. C. Bernstein",
                "C. Bertella",
                "A. Bertolin",
                "C. Betancourt",
                "F. Betti",
                "J. Bex",
                "Ia. Bezshyiko",
                "J. Bhom",
                "M. S. Bieker",
                "N. V. Biesuz",
                "P. Billoir",
                "A. Biolchini",
                "M. Birch",
                "F. C. R. Bishop",
                "A. Bitadze",
                "A. Bizzeti",
                "M. P. Blago",
                "T. Blake",
                "F. Blanc",
                "J. E. Blank",
                "S. Blusk",
                "D. Bobulska",
                "V. Bocharnikov",
                "J. A. Boelhauve",
                "O. Boente Garcia",
                "T. Boettcher",
                "A. Bohare",
                "A. Boldyrev",
                "C. S. Bolognani",
                "R. Bolzonella",
                "N. Bondar",
                "F. Borgato",
                "S. Borghi",
                "M. Borsato",
                "J. T. Borsuk",
                "S. A. Bouchiba",
                "T. J. V. Bowcock",
                "A. Boyer",
                "C. Bozzi",
                "M. J. Bradley",
                "S. Braun",
                "A. Brea Rodriguez",
                "N. Breer",
                "J. Brodzicka",
                "A. Brossa Gonzalo",
                "J. Brown",
                "D. Brundu",
                "A. Buonaura",
                "L. Buonincontri",
                "A. T. Burke",
                "C. Burr",
                "A. Bursche",
                "A. Butkevich",
                "J. S. Butter",
                "J. Buytaert",
                "W. Byczynski",
                "S. Cadeddu",
                "H. Cai",
                "R. Calabrese",
                "L. Calefice",
                "S. Cali",
                "M. Calvi",
                "M. Calvo Gomez",
                "J. Cambon Bouzas",
                "P. Campana",
                "D. H. Campora Perez",
                "A. F. Campoverde Quezada",
                "S. Capelli",
                "L. Capriotti",
                "R. Caravaca-Mora",
                "A. Carbone",
                "L. Carcedo Salgado",
                "R. Cardinale",
                "A. Cardini",
                "P. Carniti",
                "L. Carus",
                "A. Casais Vidal",
                "R. Caspary",
                "G. Casse",
                "J. Castro Godinez",
                "M. Cattaneo",
                "G. Cavallero",
                "V. Cavallini",
                "S. Celani",
                "J. Cerasoli",
                "D. Cervenkov",
                "S. Cesare",
                "A. J. Chadwick",
                "I. Chahrour",
                "M. Charles",
                "Ph. Charpentier",
                "C. A. Chavez Barajas",
                "M. Chefdeville",
                "C. Chen",
                "S. Chen",
                "A. Chernov",
                "S. Chernyshenko",
                "V. Chobanova",
                "S. Cholak",
                "M. Chrzaszcz",
                "A. Chubykin",
                "V. Chulikov",
                "P. Ciambrone",
                "M. F. Cicala",
                "X. Cid Vidal",
                "G. Ciezarek",
                "P. Cifra",
                "P. E. L. Clarke",
                "M. Clemencic",
                "H. V. Cliff",
                "J. Closier",
                "J. L. Cobbledick",
                "C. Cocha Toapaxi",
                "V. Coco",
                "J. Cogan",
                "E. Cogneras",
                "L. Cojocariu",
                "P. Collins",
                "T. Colombo",
                "A. Comerma-Montells",
                "L. Congedo",
                "A. Contu",
                "N. Cooke",
                "I. Corredoira",
                "A. Correia",
                "G. Corti",
                "J. J. Cottee Meldrum",
                "B. Couturier",
                "D. C. Craik",
                "M. Cruz Torres",
                "R. Currie",
                "C. L. Da Silva",
                "S. Dadabaev",
                "L. Dai",
                "X. Dai",
                "E. Dall'Occo",
                "J. Dalseno",
                "C. D'Ambrosio",
                "J. Daniel",
                "A. Danilina",
                "P. d'Argent",
                "A. Davidson",
                "J. E. Davies",
                "A. Davis",
                "O. De Aguiar Francisco",
                "C. De Angelis",
                "J. de Boer",
                "K. De Bruyn",
                "S. De Capua",
                "M. De Cian",
                "U. De Freitas Carneiro Da Graca",
                "E. De Lucia",
                "J. M. De Miranda",
                "L. De Paula",
                "M. De Serio",
                "D. De Simone",
                "P. De Simone",
                "F. De Vellis",
                "J. A. de Vries",
                "F. Debernardis",
                "D. Decamp",
                "V. Dedu",
                "L. Del Buono",
                "B. Delaney",
                "H. -P. Dembinski",
                "J. Deng",
                "V. Denysenko",
                "O. Deschamps",
                "F. Dettori",
                "B. Dey",
                "P. Di Nezza",
                "I. Diachkov",
                "S. Didenko",
                "S. Ding",
                "V. Dobishuk",
                "A. D. Docheva",
                "A. Dolmatov",
                "C. Dong",
                "A. M. Donohoe",
                "F. Dordei",
                "A. C. dos Reis",
                "L. Douglas",
                "A. G. Downes",
                "W. Duan",
                "P. Duda",
                "M. W. Dudek",
                "L. Dufour",
                "V. Duk",
                "P. Durante",
                "M. M. Duras",
                "J. M. Durham",
                "D. Dutta",
                "A. Dziurda",
                "A. Dzyuba",
                "S. Easo",
                "E. Eckstein",
                "U. Egede",
                "A. Egorychev",
                "V. Egorychev",
                "C. Eirea Orro",
                "S. Eisenhardt",
                "E. Ejopu",
                "S. Ek-In",
                "L. Eklund",
                "M. Elashri",
                "J. Ellbracht",
                "S. Ely",
                "A. Ene",
                "E. Epple",
                "S. Escher",
                "J. Eschle",
                "S. Esen",
                "T. Evans",
                "F. Fabiano",
                "L. N. Falcao",
                "Y. Fan",
                "B. Fang",
                "L. Fantini",
                "M. Faria",
                "K. Farmer",
                "D. Fazzini",
                "L. Felkowski",
                "M. Feng",
                "M. Feo",
                "M. Fernandez Gomez",
                "A. D. Fernez",
                "F. Ferrari",
                "F. Ferreira Rodrigues",
                "S. Ferreres Sole",
                "M. Ferrillo",
                "M. Ferro-Luzzi",
                "S. Filippov",
                "R. A. Fini",
                "M. Fiorini",
                "M. Firlej",
                "K. M. Fischer",
                "D. S. Fitzgerald",
                "C. Fitzpatrick",
                "T. Fiutowski",
                "F. Fleuret",
                "M. Fontana",
                "F. Fontanelli",
                "L. F. Foreman",
                "R. Forty",
                "D. Foulds-Holt",
                "M. Franco Sevilla",
                "M. Frank",
                "E. Franzoso",
                "G. Frau",
                "C. Frei",
                "D. A. Friday",
                "L. Frontini",
                "J. Fu",
                "Q. Fuehring",
                "Y. Fujii",
                "T. Fulghesu",
                "E. Gabriel",
                "G. Galati",
                "M. D. Galati",
                "A. Gallas Torreira",
                "D. Galli",
                "S. Gambetta",
                "M. Gandelman",
                "P. Gandini",
                "H. Gao",
                "R. Gao",
                "Y. Gao",
                "Y. Gao",
                "Y. Gao",
                "M. Garau",
                "L. M. Garcia Martin",
                "P. Garcia Moreno",
                "J. Garc\u00eda Pardi\u00f1as",
                "B. Garcia Plana",
                "K. G. Garg",
                "L. Garrido",
                "C. Gaspar",
                "R. E. Geertsema",
                "L. L. Gerken",
                "E. Gersabeck",
                "M. Gersabeck",
                "T. Gershon",
                "Z. Ghorbanimoghaddam",
                "L. Giambastiani",
                "F. I. Giasemis",
                "V. Gibson",
                "H. K. Giemza",
                "A. L. Gilman",
                "M. Giovannetti",
                "A. Giovent\u00f9",
                "P. Gironella Gironell",
                "C. Giugliano",
                "M. A. Giza",
                "E. L. Gkougkousis",
                "F. C. Glaser",
                "V. V. Gligorov",
                "C. G\u00f6bel",
                "E. Golobardes",
                "D. Golubkov",
                "A. Golutvin",
                "A. Gomes",
                "S. Gomez Fernandez",
                "F. Goncalves Abrantes",
                "M. Goncerz",
                "G. Gong",
                "J. A. Gooding",
                "I. V. Gorelov",
                "C. Gotti",
                "J. P. Grabowski",
                "L. A. Granado Cardoso",
                "E. Graug\u00e9s",
                "E. Graverini",
                "L. Grazette",
                "G. Graziani",
                "A. T. Grecu",
                "L. M. Greeven",
                "N. A. Grieser",
                "L. Grillo",
                "S. Gromov",
                "C. Gu",
                "M. Guarise",
                "M. Guittiere",
                "V. Guliaeva",
                "P. A. G\u00fcnther",
                "A. -K. Guseinov",
                "E. Gushchin",
                "Y. Guz",
                "T. Gys",
                "T. Hadavizadeh",
                "C. Hadjivasiliou",
                "G. Haefeli",
                "C. Haen",
                "J. Haimberger",
                "M. Hajheidari",
                "T. Halewood-leagas",
                "M. M. Halvorsen",
                "P. M. Hamilton",
                "J. Hammerich",
                "Q. Han",
                "X. Han",
                "S. Hansmann-Menzemer",
                "L. Hao",
                "N. Harnew",
                "T. Harrison",
                "M. Hartmann",
                "C. Hasse",
                "J. He",
                "K. Heijhoff",
                "F. Hemmer",
                "C. Henderson",
                "R. D. L. Henderson",
                "A. M. Hennequin",
                "K. Hennessy",
                "L. Henry",
                "J. Herd",
                "J. Heuel",
                "A. Hicheur",
                "D. Hill",
                "S. E. Hollitt",
                "J. Horswill",
                "R. Hou",
                "Y. Hou",
                "N. Howarth",
                "J. Hu",
                "J. Hu",
                "W. Hu",
                "X. Hu",
                "W. Huang",
                "W. Hulsbergen",
                "R. J. Hunter",
                "M. Hushchyn",
                "D. Hutchcroft",
                "M. Idzik",
                "D. Ilin",
                "P. Ilten",
                "A. Inglessi",
                "A. Iniukhin",
                "A. Ishteev",
                "K. Ivshin",
                "R. Jacobsson",
                "H. Jage",
                "S. J. Jaimes Elles",
                "S. Jakobsen",
                "E. Jans",
                "B. K. Jashal",
                "A. Jawahery",
                "V. Jevtic",
                "E. Jiang",
                "X. Jiang",
                "Y. Jiang",
                "Y. J. Jiang",
                "M. John",
                "D. Johnson",
                "C. R. Jones",
                "T. P. Jones",
                "S. Joshi",
                "B. Jost",
                "N. Jurik",
                "I. Juszczak",
                "D. Kaminaris",
                "S. Kandybei",
                "Y. Kang",
                "M. Karacson",
                "D. Karpenkov",
                "M. Karpov",
                "A. M. Kauniskangas",
                "J. W. Kautz",
                "F. Keizer",
                "D. M. Keller",
                "M. Kenzie",
                "T. Ketel",
                "B. Khanji",
                "A. Kharisova",
                "S. Kholodenko",
                "G. Khreich",
                "T. Kirn",
                "V. S. Kirsebom",
                "O. Kitouni",
                "S. Klaver",
                "N. Kleijne",
                "K. Klimaszewski",
                "M. R. Kmiec",
                "S. Koliiev",
                "L. Kolk",
                "A. Konoplyannikov",
                "P. Kopciewicz",
                "P. Koppenburg",
                "M. Korolev",
                "I. Kostiuk",
                "O. Kot",
                "S. Kotriakhova",
                "A. Kozachuk",
                "P. Kravchenko",
                "L. Kravchuk",
                "M. Kreps",
                "S. Kretzschmar",
                "P. Krokovny",
                "W. Krupa",
                "W. Krzemien",
                "J. Kubat",
                "S. Kubis",
                "W. Kucewicz",
                "M. Kucharczyk",
                "V. Kudryavtsev",
                "E. Kulikova",
                "A. Kupsc",
                "B. K. Kutsenko",
                "D. Lacarrere",
                "G. Lafferty",
                "A. Lai",
                "A. Lampis",
                "D. Lancierini",
                "C. Landesa Gomez",
                "J. J. Lane",
                "R. Lane",
                "C. Langenbruch",
                "J. Langer",
                "O. Lantwin",
                "T. Latham",
                "F. Lazzari",
                "C. Lazzeroni",
                "R. Le Gac",
                "S. H. Lee",
                "R. Lef\u00e8vre",
                "A. Leflat",
                "S. Legotin",
                "M. Lehuraux",
                "O. Leroy",
                "T. Lesiak",
                "B. Leverington",
                "A. Li",
                "H. Li",
                "K. Li",
                "L. Li",
                "P. Li",
                "P. -R. Li",
                "S. Li",
                "T. Li",
                "T. Li",
                "Y. Li",
                "Y. Li",
                "Z. Li",
                "Z. Lian",
                "X. Liang",
                "C. Lin",
                "T. Lin",
                "R. Lindner",
                "V. Lisovskyi",
                "R. Litvinov",
                "G. Liu",
                "H. Liu",
                "K. Liu",
                "Q. Liu",
                "S. Liu",
                "Y. Liu",
                "Y. Liu",
                "Y. L. Liu",
                "A. Lobo Salvia",
                "A. Loi",
                "J. Lomba Castro",
                "T. Long",
                "J. H. Lopes",
                "A. Lopez Huertas",
                "S. L\u00f3pez Soli\u00f1o",
                "G. H. Lovell",
                "C. Lucarelli",
                "D. Lucchesi",
                "S. Luchuk",
                "M. Lucio Martinez",
                "V. Lukashenko",
                "Y. Luo",
                "A. Lupato",
                "E. Luppi",
                "K. Lynch",
                "X. -R. Lyu",
                "G. M. Ma",
                "R. Ma",
                "S. Maccolini",
                "F. Machefert",
                "F. Maciuc",
                "I. Mackay",
                "L. R. Madhan Mohan",
                "M. M. Madurai",
                "A. Maevskiy",
                "D. Magdalinski",
                "D. Maisuzenko",
                "M. W. Majewski",
                "J. J. Malczewski",
                "S. Malde",
                "B. Malecki",
                "L. Malentacca",
                "A. Malinin",
                "T. Maltsev",
                "G. Manca",
                "G. Mancinelli",
                "C. Mancuso",
                "R. Manera Escalero",
                "D. Manuzzi",
                "D. Marangotto",
                "J. F. Marchand",
                "R. Marchevski",
                "U. Marconi",
                "S. Mariani",
                "C. Marin Benito",
                "J. Marks",
                "A. M. Marshall",
                "P. J. Marshall",
                "G. Martelli",
                "G. Martellotti",
                "L. Martinazzoli",
                "M. Martinelli",
                "D. Martinez Santos",
                "F. Martinez Vidal",
                "A. Massafferri",
                "M. Materok",
                "R. Matev",
                "A. Mathad",
                "V. Matiunin",
                "C. Matteuzzi",
                "K. R. Mattioli",
                "A. Mauri",
                "E. Maurice",
                "J. Mauricio",
                "P. Mayencourt",
                "M. Mazurek",
                "M. McCann",
                "L. Mcconnell",
                "T. H. McGrath",
                "N. T. McHugh",
                "A. McNab",
                "R. McNulty",
                "B. Meadows",
                "G. Meier",
                "D. Melnychuk",
                "M. Merk",
                "A. Merli",
                "L. Meyer Garcia",
                "D. Miao",
                "H. Miao",
                "M. Mikhasenko",
                "D. A. Milanes",
                "A. Minotti",
                "E. Minucci",
                "T. Miralles",
                "S. E. Mitchell",
                "B. Mitreska",
                "D. S. Mitzel",
                "A. Modak",
                "A. M\u00f6dden",
                "R. A. Mohammed",
                "R. D. Moise",
                "S. Mokhnenko",
                "T. Momb\u00e4cher",
                "M. Monk",
                "I. A. Monroy",
                "S. Monteil",
                "A. Morcillo Gomez",
                "G. Morello",
                "M. J. Morello",
                "M. P. Morgenthaler",
                "J. Moron",
                "A. B. Morris",
                "A. G. Morris",
                "R. Mountain",
                "H. Mu",
                "Z. M. Mu",
                "E. Muhammad",
                "F. Muheim",
                "M. Mulder",
                "K. M\u00fcller",
                "F. Mu\u00f1oz-Rojas",
                "R. Murta",
                "P. Naik",
                "T. Nakada",
                "R. Nandakumar",
                "T. Nanut",
                "I. Nasteva",
                "M. Needham",
                "N. Neri",
                "S. Neubert",
                "N. Neufeld",
                "P. Neustroev",
                "R. Newcombe",
                "J. Nicolini",
                "D. Nicotra",
                "E. M. Niel",
                "N. Nikitin",
                "P. Nogga",
                "N. S. Nolte",
                "C. Normand",
                "J. Novoa Fernandez",
                "G. Nowak",
                "C. Nunez",
                "H. N. Nur",
                "A. Oblakowska-Mucha",
                "V. Obraztsov",
                "T. Oeser",
                "S. Okamura",
                "R. Oldeman",
                "F. Oliva",
                "M. Olocco",
                "C. J. G. Onderwater",
                "R. H. O'Neil",
                "J. M. Otalora Goicochea",
                "T. Ovsiannikova",
                "P. Owen",
                "A. Oyanguren",
                "O. Ozcelik",
                "K. O. Padeken",
                "B. Pagare",
                "P. R. Pais",
                "T. Pajero",
                "A. Palano",
                "M. Palutan",
                "G. Panshin",
                "L. Paolucci",
                "A. Papanestis",
                "M. Pappagallo",
                "L. L. Pappalardo",
                "C. Pappenheimer",
                "C. Parkes",
                "B. Passalacqua",
                "G. Passaleva",
                "D. Passaro",
                "A. Pastore",
                "M. Patel",
                "J. Patoc",
                "C. Patrignani",
                "C. J. Pawley",
                "A. Pellegrino",
                "M. Pepe Altarelli",
                "S. Perazzini",
                "D. Pereima",
                "A. Pereiro Castro",
                "P. Perret",
                "A. Perro",
                "K. Petridis",
                "A. Petrolini",
                "S. Petrucci",
                "H. Pham",
                "L. Pica",
                "M. Piccini",
                "B. Pietrzyk",
                "G. Pietrzyk",
                "D. Pinci",
                "F. Pisani",
                "M. Pizzichemi",
                "V. Placinta",
                "M. Plo Casasus",
                "F. Polci",
                "M. Poli Lener",
                "A. Poluektov",
                "N. Polukhina",
                "I. Polyakov",
                "E. Polycarpo",
                "S. Ponce",
                "D. Popov",
                "S. Poslavskii",
                "K. Prasanth",
                "L. Promberger",
                "C. Prouve",
                "V. Pugatch",
                "V. Puill",
                "G. Punzi",
                "H. R. Qi",
                "W. Qian",
                "N. Qin",
                "S. Qu",
                "R. Quagliani",
                "R. I. Rabadan Trejo",
                "B. Rachwal",
                "J. H. Rademacker",
                "M. Rama",
                "M. Ram\u00edrez Garc\u00eda",
                "M. Ramos Pernas",
                "M. S. Rangel",
                "F. Ratnikov",
                "G. Raven",
                "M. Rebollo De Miguel",
                "F. Redi",
                "J. Reich",
                "F. Reiss",
                "Z. Ren",
                "P. K. Resmi",
                "R. Ribatti",
                "G. R. Ricart",
                "D. Riccardi",
                "S. Ricciardi",
                "K. Richardson",
                "M. Richardson-Slipper",
                "K. Rinnert",
                "P. Robbe",
                "G. Robertson",
                "E. Rodrigues",
                "E. Rodriguez Fernandez",
                "J. A. Rodriguez Lopez",
                "E. Rodriguez Rodriguez",
                "A. Rogovskiy",
                "D. L. Rolf",
                "A. Rollings",
                "P. Roloff",
                "V. Romanovskiy",
                "M. Romero Lamas",
                "A. Romero Vidal",
                "G. Romolini",
                "F. Ronchetti",
                "M. Rotondo",
                "S. R. Roy",
                "M. S. Rudolph",
                "T. Ruf",
                "M. Ruiz Diaz",
                "R. A. Ruiz Fernandez",
                "J. Ruiz Vidal",
                "A. Ryzhikov",
                "J. Ryzka",
                "J. J. Saborido Silva",
                "R. Sadek",
                "N. Sagidova",
                "N. Sahoo",
                "B. Saitta",
                "M. Salomoni",
                "C. Sanchez Gras",
                "I. Sanderswood",
                "R. Santacesaria",
                "C. Santamarina Rios",
                "M. Santimaria",
                "L. Santoro",
                "E. Santovetti",
                "A. Saputi",
                "D. Saranin",
                "G. Sarpis",
                "M. Sarpis",
                "A. Sarti",
                "C. Satriano",
                "A. Satta",
                "M. Saur",
                "D. Savrina",
                "H. Sazak",
                "L. G. Scantlebury Smead",
                "A. Scarabotto",
                "S. Schael",
                "S. Scherl",
                "A. M. Schertz",
                "M. Schiller",
                "H. Schindler",
                "M. Schmelling",
                "B. Schmidt",
                "S. Schmitt",
                "H. Schmitz",
                "O. Schneider",
                "A. Schopper",
                "N. Schulte",
                "S. Schulte",
                "M. H. Schune",
                "R. Schwemmer",
                "G. Schwering",
                "B. Sciascia",
                "A. Sciuccati",
                "S. Sellam",
                "A. Semennikov",
                "M. Senghi Soares",
                "A. Sergi",
                "N. Serra",
                "L. Sestini",
                "A. Seuthe",
                "Y. Shang",
                "D. M. Shangase",
                "M. Shapkin",
                "I. Shchemerov",
                "L. Shchutska",
                "T. Shears",
                "L. Shekhtman",
                "Z. Shen",
                "S. Sheng",
                "V. Shevchenko",
                "B. Shi",
                "E. B. Shields",
                "Y. Shimizu",
                "E. Shmanin",
                "R. Shorkin",
                "J. D. Shupperd",
                "R. Silva Coutinho",
                "G. Simi",
                "S. Simone",
                "N. Skidmore",
                "R. Skuza",
                "T. Skwarnicki",
                "M. W. Slater",
                "J. C. Smallwood",
                "E. Smith",
                "K. Smith",
                "M. Smith",
                "A. Snoch",
                "L. Soares Lavra",
                "M. D. Sokoloff",
                "F. J. P. Soler",
                "A. Solomin",
                "A. Solovev",
                "I. Solovyev",
                "R. Song",
                "Y. Song",
                "Y. Song",
                "Y. S. Song",
                "F. L. Souza De Almeida",
                "B. Souza De Paula",
                "E. Spadaro Norella",
                "E. Spedicato",
                "J. G. Speer",
                "E. Spiridenkov",
                "P. Spradlin",
                "V. Sriskaran",
                "F. Stagni",
                "M. Stahl",
                "S. Stahl",
                "S. Stanislaus",
                "E. N. Stein",
                "O. Steinkamp",
                "O. Stenyakin",
                "H. Stevens",
                "D. Strekalina",
                "Y. Su",
                "F. Suljik",
                "J. Sun",
                "L. Sun",
                "Y. Sun",
                "P. N. Swallow",
                "K. Swientek",
                "F. Swystun",
                "A. Szabelski",
                "T. Szumlak",
                "M. Szymanski",
                "Y. Tan",
                "S. Taneja",
                "M. D. Tat",
                "A. Terentev",
                "F. Terzuoli",
                "F. Teubert",
                "E. Thomas",
                "D. J. D. Thompson",
                "H. Tilquin",
                "V. Tisserand",
                "S. T'Jampens",
                "M. Tobin",
                "L. Tomassetti",
                "G. Tonani",
                "X. Tong",
                "D. Torres Machado",
                "L. Toscano",
                "D. Y. Tou",
                "C. Trippl",
                "G. Tuci",
                "N. Tuning",
                "L. H. Uecker",
                "A. Ukleja",
                "D. J. Unverzagt",
                "E. Ursov",
                "A. Usachov",
                "A. Ustyuzhanin",
                "U. Uwer",
                "V. Vagnoni",
                "A. Valassi",
                "G. Valenti",
                "N. Valls Canudas",
                "H. Van Hecke",
                "E. van Herwijnen",
                "C. B. Van Hulse",
                "R. Van Laak",
                "M. van Veghel",
                "R. Vazquez Gomez",
                "P. Vazquez Regueiro",
                "C. V\u00e1zquez Sierra",
                "S. Vecchi",
                "J. J. Velthuis",
                "M. Veltri",
                "A. Venkateswaran",
                "M. Vesterinen",
                "D. Vieira",
                "M. Vieites Diaz",
                "X. Vilasis-Cardona",
                "E. Vilella Figueras",
                "A. Villa",
                "P. Vincent",
                "F. C. Volle",
                "D. vom Bruch",
                "V. Vorobyev",
                "N. Voropaev",
                "K. Vos",
                "G. Vouters",
                "C. Vrahas",
                "J. Walsh",
                "E. J. Walton",
                "G. Wan",
                "C. Wang",
                "G. Wang",
                "J. Wang",
                "J. Wang",
                "J. Wang",
                "J. Wang",
                "M. Wang",
                "N. W. Wang",
                "R. Wang",
                "X. Wang",
                "X. W. Wang",
                "Y. Wang",
                "Z. Wang",
                "Z. Wang",
                "Z. Wang",
                "J. A. Ward",
                "N. K. Watson",
                "D. Websdale",
                "Y. Wei",
                "B. D. C. Westhenry",
                "D. J. White",
                "M. Whitehead",
                "A. R. Wiederhold",
                "D. Wiedner",
                "G. Wilkinson",
                "M. K. Wilkinson",
                "M. Williams",
                "M. R. J. Williams",
                "R. Williams",
                "F. F. Wilson",
                "W. Wislicki",
                "M. Witek",
                "L. Witola",
                "C. P. Wong",
                "G. Wormser",
                "S. A. Wotton",
                "H. Wu",
                "J. Wu",
                "Y. Wu",
                "K. Wyllie",
                "S. Xian",
                "Z. Xiang",
                "Y. Xie",
                "A. Xu",
                "J. Xu",
                "L. Xu",
                "L. Xu",
                "M. Xu",
                "Z. Xu",
                "Z. Xu",
                "Z. Xu",
                "D. Yang",
                "S. Yang",
                "X. Yang",
                "Y. Yang",
                "Z. Yang",
                "Z. Yang",
                "V. Yeroshenko",
                "H. Yeung",
                "H. Yin",
                "C. Y. Yu",
                "J. Yu",
                "X. Yuan",
                "E. Zaffaroni",
                "M. Zavertyaev",
                "M. Zdybal",
                "M. Zeng",
                "C. Zhang",
                "D. Zhang",
                "J. Zhang",
                "L. Zhang",
                "S. Zhang",
                "S. Zhang",
                "Y. Zhang",
                "Y. Zhang",
                "Y. Z. Zhang",
                "Y. Zhao",
                "A. Zharkova",
                "A. Zhelezov",
                "X. Z. Zheng",
                "Y. Zheng",
                "T. Zhou",
                "X. Zhou",
                "Y. Zhou",
                "V. Zhovkovska",
                "L. Z. Zhu",
                "X. Zhu",
                "X. Zhu",
                "Z. Zhu",
                "V. Zhukov",
                "J. Zhuo",
                "Q. Zou",
                "D. Zuliani",
                "G. Zunica"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12278v1",
                "http://arxiv.org/pdf/2310.12278v1"
            ],
            "primary_category": "hep-ex",
            "category": [
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12274v1",
            "title": "An Image is Worth Multiple Words: Learning Object Level Concepts using\n  Multi-Concept Prompt Learning",
            "updated": "2023-10-18T19:18:19Z",
            "published": "2023-10-18T19:18:19Z",
            "summary": "Textural Inversion, a prompt learning method, learns a singular embedding for\na new \"word\" to represent image style and appearance, allowing it to be\nintegrated into natural language sentences to generate novel synthesised\nimages. However, identifying and integrating multiple object-level concepts\nwithin one scene poses significant challenges even when embeddings for\nindividual concepts are attainable. This is further confirmed by our empirical\ntests. To address this challenge, we introduce a framework for Multi-Concept\nPrompt Learning (MCPL), where multiple new \"words\" are simultaneously learned\nfrom a single sentence-image pair. To enhance the accuracy of word-concept\ncorrelation, we propose three regularisation techniques: Attention Masking\n(AttnMask) to concentrate learning on relevant areas; Prompts Contrastive Loss\n(PromptCL) to separate the embeddings of different concepts; and Bind adjective\n(Bind adj.) to associate new \"words\" with known words. We evaluate via image\ngeneration, editing, and attention visualisation with diverse images. Extensive\nquantitative comparisons demonstrate that our method can learn more\nsemantically disentangled concepts with enhanced word-concept correlation.\nAdditionally, we introduce a novel dataset and evaluation protocol tailored for\nthis new task of learning object-level concepts.",
            "author": [
                "Chen Jin",
                "Ryutaro Tanno",
                "Amrutha Saseendran",
                "Tom Diethe",
                "Philip Teare"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12274v1",
                "http://arxiv.org/pdf/2310.12274v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.GR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12263v1",
            "title": "Plan-Guided Reinforcement Learning for Whole-Body Manipulation",
            "updated": "2023-10-18T18:57:42Z",
            "published": "2023-10-18T18:57:42Z",
            "summary": "Synthesizing complex whole-body manipulation behaviors has fundamental\nchallenges due to the rapidly growing combinatorics inherent to contact\ninteraction planning. While model-based methods have shown promising results in\nsolving long-horizon manipulation tasks, they often work under strict\nassumptions, such as known model parameters, oracular observation of the\nenvironment state, and simplified dynamics, resulting in plans that cannot\neasily transfer to hardware. Learning-based approaches, such as imitation\nlearning (IL) and reinforcement learning (RL), have been shown to be robust\nwhen operating over in-distribution states; however, they need heavy human\nsupervision. Specifically, model-free RL requires a tedious reward-shaping\nprocess. IL methods, on the other hand, rely on human demonstrations that\ninvolve advanced teleoperation methods. In this work, we propose a plan-guided\nreinforcement learning (PGRL) framework to combine the advantages of\nmodel-based planning and reinforcement learning. Our method requires minimal\nhuman supervision because it relies on plans generated by model-based planners\nto guide the exploration in RL. In exchange, RL derives a more robust policy\nthanks to domain randomization. We test this approach on a whole-body\nmanipulation task on Punyo, an upper-body humanoid robot with compliant,\nair-filled arm coverings, to pivot and lift a large box. Our preliminary\nresults indicate that the proposed methodology is promising to address\nchallenges that remain difficult for either model- or learning-based strategies\nalone.",
            "author": [
                "Mengchao Zhang",
                "Jose Barreiros",
                "Aykut Ozgun Onol"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12263v1",
                "http://arxiv.org/pdf/2310.12263v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12262v1",
            "title": "Improving SCGAN's Similarity Constraint and Learning a Better\n  Disentangled Representation",
            "updated": "2023-10-18T18:57:13Z",
            "published": "2023-10-18T18:57:13Z",
            "summary": "SCGAN adds a similarity constraint between generated images and conditions as\na regularization term on generative adversarial networks. Similarity constraint\nworks as a tutor to instruct the generator network to comprehend the difference\nof representations based on conditions. We understand how SCGAN works on a\ndeeper level. This understanding makes us realize that the similarity\nconstraint functions like the contrastive loss function. We believe that a\nmodel with high understanding and intelligence measures the similarity between\nimages based on their structure and high level features, just like humans do.\nTwo major changes we applied to SCGAN in order to make a modified model are\nusing SSIM to measure similarity between images and applying contrastive loss\nprinciples to the similarity constraint. The modified model performs better\nusing FID and FactorVAE metrics. The modified model also has better\ngeneralisability compared to other models. Keywords Generative Adversarial\nNets, Unsupervised Learning, Disentangled Representation Learning, Contrastive\nDisentanglement, SSIM",
            "author": [
                "Iman Yazdanpanah"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12262v1",
                "http://arxiv.org/pdf/2310.12262v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13019v3",
            "title": "Tailoring Adversarial Attacks on Deep Neural Networks for Targeted Class\n  Manipulation Using DeepFool Algorithm",
            "updated": "2023-11-17T19:39:43Z",
            "published": "2023-10-18T18:50:39Z",
            "summary": "Deep neural networks (DNNs) have significantly advanced various domains, but\ntheir vulnerability to adversarial attacks poses serious concerns.\nUnderstanding these vulnerabilities and developing effective defense mechanisms\nis crucial. DeepFool, an algorithm proposed by Moosavi-Dezfooli et al. (2016),\nfinds minimal perturbations to misclassify input images. However, DeepFool\nlacks a targeted approach, making it less effective in specific attack\nscenarios. Also, in previous related works, researchers primarily focus on\nsuccess, not considering how much an image is getting distorted; the integrity\nof the image quality, and the confidence level to misclassifying. So, in this\npaper, we propose Enhanced Targeted DeepFool, an augmented version of DeepFool\nthat allows targeting specific classes for misclassification and also introduce\na minimum confidence score requirement hyperparameter to enhance flexibility.\nOur experiments demonstrate the effectiveness and efficiency of the proposed\nmethod across different deep neural network architectures while preserving\nimage integrity as much and perturbation rate as less as possible. By using our\napproach, the behavior of models can be manipulated arbitrarily using the\nperturbed images, as we can specify both the target class and the associated\nconfidence score, unlike other DeepFool-derivative works, such as Targeted\nDeepFool by Gajjar et al. (2022). Results show that one of the deep\nconvolutional neural network architectures, AlexNet, and one of the\nstate-of-the-art model Vision Transformer exhibit high robustness to getting\nfooled. This approach can have larger implication, as our tuning of confidence\nlevel can expose the robustness of image recognition models. Our code will be\nmade public upon acceptance of the paper.",
            "author": [
                "S. M. Fazle Rabby Labib",
                "Joyanta Jyoti Mondal",
                "Meem Arafat Manab"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13019v3",
                "http://arxiv.org/pdf/2310.13019v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12254v1",
            "title": "Charge Manipulation Attacks Against Smart Electric Vehicle Charging\n  Stations and Deep Learning-based Detection Mechanisms",
            "updated": "2023-10-18T18:38:59Z",
            "published": "2023-10-18T18:38:59Z",
            "summary": "The widespread deployment of \"smart\" electric vehicle charging stations\n(EVCSs) will be a key step toward achieving green transportation. The\nconnectivity features of smart EVCSs can be utilized to schedule EV charging\noperations while respecting user preferences, thus avoiding synchronous\ncharging from a large number of customers and relieving grid congestion.\nHowever, the communication and connectivity requirements involved in smart\ncharging raise cybersecurity concerns. In this work, we investigate charge\nmanipulation attacks (CMAs) against EV charging, in which an attacker\nmanipulates the information exchanged during smart charging operations. The\nobjective of CMAs is to shift the EV aggregator's demand across different times\nof the day. The proposed CMAs can bypass existing protection mechanisms in EV\ncommunication protocols. We quantify the impact of CMAs on the EV aggregator's\neconomic profit by modeling their participation in the day-ahead (DA) and\nreal-time (RT) electricity markets. Finally, we propose an unsupervised deep\nlearning-based mechanism to detect CMAs by monitoring the parameters involved\nin EV charging. We extensively analyze the attack impact and the efficiency of\nthe proposed detection on real-world EV charging datasets. The results\nhighlight the vulnerabilities of smart charging operations and the need for a\nmonitoring mechanism to detect malicious CMAs.",
            "author": [
                "Hamidreza Jahangir",
                "Subhash Lakshminarayana",
                "H. Vincent Poor"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12254v1",
                "http://arxiv.org/pdf/2310.12254v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12248v1",
            "title": "A PAC Learning Algorithm for LTL and Omega-regular Objectives in MDPs",
            "updated": "2023-10-18T18:33:41Z",
            "published": "2023-10-18T18:33:41Z",
            "summary": "Linear temporal logic (LTL) and omega-regular objectives -- a superset of LTL\n-- have seen recent use as a way to express non-Markovian objectives in\nreinforcement learning. We introduce a model-based probably approximately\ncorrect (PAC) learning algorithm for omega-regular objectives in Markov\ndecision processes. Unlike prior approaches, our algorithm learns from sampled\ntrajectories of the system and does not require prior knowledge of the system's\ntopology.",
            "author": [
                "Mateo Perez",
                "Fabio Somenzi",
                "Ashutosh Trivedi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12248v1",
                "http://arxiv.org/pdf/2310.12248v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12247v2",
            "title": "Achieving optimal complexity guarantees for a class of bilevel convex\n  optimization problems",
            "updated": "2023-11-17T18:06:14Z",
            "published": "2023-10-18T18:33:26Z",
            "summary": "We design and analyze a novel accelerated gradient-based algorithm for a\nclass of bilevel optimization problems. These problems have various\napplications arising from machine learning and image processing, where optimal\nsolutions of the two levels are interdependent. That is, achieving the optimal\nsolution of an upper-level problem depends on the solution set of a lower-level\noptimization problem. We significantly improve existing iteration complexity to\n$\\mathcal{O}(\\epsilon^{-0.5})$ for both suboptimality and infeasibility error\nmetrics, where $\\epsilon>0$ denotes an arbitrary scalar. In addition, contrary\nto existing methods that require solving the optimization problem sequentially\n(initially solving an optimization problem to approximate the solution of the\nlower-level problem followed by a second algorithm), our algorithm concurrently\nsolves the optimization problem. To the best of our knowledge, the proposed\nalgorithm has the fastest known iteration complexity, which matches the optimal\ncomplexity for single-level optimization. We conduct numerical experiments on\nsparse linear regression problems to demonstrate the efficacy of our approach.",
            "author": [
                "Sepideh Samadi",
                "Daniel Burbano",
                "Farzad Yousefian"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12247v2",
                "http://arxiv.org/pdf/2310.12247v2"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12244v1",
            "title": "A Unified Approach to Domain Incremental Learning with Memory: Theory\n  and Algorithm",
            "updated": "2023-10-18T18:30:07Z",
            "published": "2023-10-18T18:30:07Z",
            "summary": "Domain incremental learning aims to adapt to a sequence of domains with\naccess to only a small subset of data (i.e., memory) from previous domains.\nVarious methods have been proposed for this problem, but it is still unclear\nhow they are related and when practitioners should choose one method over\nanother. In response, we propose a unified framework, dubbed Unified Domain\nIncremental Learning (UDIL), for domain incremental learning with memory. Our\nUDIL **unifies** various existing methods, and our theoretical analysis shows\nthat UDIL always achieves a tighter generalization error bound compared to\nthese methods. The key insight is that different existing methods correspond to\nour bound with different **fixed** coefficients; based on insights from this\nunification, our UDIL allows **adaptive** coefficients during training, thereby\nalways achieving the tightest bound. Empirical results show that our UDIL\noutperforms the state-of-the-art domain incremental learning methods on both\nsynthetic and real-world datasets. Code will be available at\nhttps://github.com/Wang-ML-Lab/unified-continual-learning.",
            "author": [
                "Haizhou Shi",
                "Hao Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12244v1",
                "http://arxiv.org/pdf/2310.12244v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12243v1",
            "title": "REVAMP: Automated Simulations of Adversarial Attacks on Arbitrary\n  Objects in Realistic Scenes",
            "updated": "2023-10-18T18:28:44Z",
            "published": "2023-10-18T18:28:44Z",
            "summary": "Deep Learning models, such as those used in an autonomous vehicle are\nvulnerable to adversarial attacks where an attacker could place an adversarial\nobject in the environment, leading to mis-classification. Generating these\nadversarial objects in the digital space has been extensively studied, however\nsuccessfully transferring these attacks from the digital realm to the physical\nrealm has proven challenging when controlling for real-world environmental\nfactors. In response to these limitations, we introduce REVAMP, an easy-to-use\nPython library that is the first-of-its-kind tool for creating attack scenarios\nwith arbitrary objects and simulating realistic environmental factors,\nlighting, reflection, and refraction. REVAMP enables researchers and\npractitioners to swiftly explore various scenarios within the digital realm by\noffering a wide range of configurable options for designing experiments and\nusing differentiable rendering to reproduce physically plausible adversarial\nobjects. We will demonstrate and invite the audience to try REVAMP to produce\nan adversarial texture on a chosen object while having control over various\nscene parameters. The audience will choose a scene, an object to attack, the\ndesired attack class, and the number of camera positions to use. Then, in real\ntime, we show how this altered texture causes the chosen object to be\nmis-classified, showcasing the potential of REVAMP in real-world scenarios.\nREVAMP is open-source and available at https://github.com/poloclub/revamp.",
            "author": [
                "Matthew Hull",
                "Zijie J. Wang",
                "Duen Horng Chau"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12243v1",
                "http://arxiv.org/pdf/2310.12243v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12238v1",
            "title": "Few-Shot In-Context Imitation Learning via Implicit Graph Alignment",
            "updated": "2023-10-18T18:26:01Z",
            "published": "2023-10-18T18:26:01Z",
            "summary": "Consider the following problem: given a few demonstrations of a task across a\nfew different objects, how can a robot learn to perform that same task on new,\npreviously unseen objects? This is challenging because the large variety of\nobjects within a class makes it difficult to infer the task-relevant\nrelationship between the new objects and the objects in the demonstrations. We\naddress this by formulating imitation learning as a conditional alignment\nproblem between graph representations of objects. Consequently, we show that\nthis conditioning allows for in-context learning, where a robot can perform a\ntask on a set of new objects immediately after the demonstrations, without any\nprior knowledge about the object class or any further training. In our\nexperiments, we explore and validate our design choices, and we show that our\nmethod is highly effective for few-shot learning of several real-world,\neveryday tasks, whilst outperforming baselines. Videos are available on our\nproject webpage at https://www.robot-learning.uk/implicit-graph-alignment.",
            "author": [
                "Vitalis Vosylius",
                "Edward Johns"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12238v1",
                "http://arxiv.org/pdf/2310.12238v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12236v1",
            "title": "Direct Neural Machine Translation with Task-level Mixture of Experts\n  models",
            "updated": "2023-10-18T18:19:45Z",
            "published": "2023-10-18T18:19:45Z",
            "summary": "Direct neural machine translation (direct NMT) is a type of NMT system that\ntranslates text between two non-English languages. Direct NMT systems often\nface limitations due to the scarcity of parallel data between non-English\nlanguage pairs. Several approaches have been proposed to address this\nlimitation, such as multilingual NMT and pivot NMT (translation between two\nlanguages via English). Task-level Mixture of expert models (Task-level MoE),\nan inference-efficient variation of Transformer-based models, has shown\npromising NMT performance for a large number of language pairs. In Task-level\nMoE, different language groups can use different routing strategies to optimize\ncross-lingual learning and inference speed. In this work, we examine Task-level\nMoE's applicability in direct NMT and propose a series of high-performing\ntraining and evaluation configurations, through which Task-level MoE-based\ndirect NMT systems outperform bilingual and pivot-based models for a large\nnumber of low and high-resource direct pairs, and translation directions. Our\nTask-level MoE with 16 experts outperforms bilingual NMT, Pivot NMT models for\n7 language pairs, while pivot-based models still performed better in 9 pairs\nand directions.",
            "author": [
                "Isidora Chara Tourni",
                "Subhajit Naskar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12236v1",
                "http://arxiv.org/pdf/2310.12236v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12209v1",
            "title": "Fast Parameter Inference on Pulsar Timing Arrays with Normalizing Flows",
            "updated": "2023-10-18T18:00:04Z",
            "published": "2023-10-18T18:00:04Z",
            "summary": "Pulsar timing arrays (PTAs) perform Bayesian posterior inference with\nexpensive MCMC methods. Given a dataset of ~10-100 pulsars and O(10^3) timing\nresiduals each, producing a posterior distribution for the stochastic\ngravitational wave background (SGWB) can take days to a week. The computational\nbottleneck arises because the likelihood evaluation required for MCMC is\nextremely costly when considering the dimensionality of the search space.\nFortunately, generating simulated data is fast, so modern simulation-based\ninference techniques can be brought to bear on the problem. In this paper, we\ndemonstrate how conditional normalizing flows trained on simulated data can be\nused for extremely fast and accurate estimation of the SGWB posteriors,\nreducing the sampling time from weeks to a matter of seconds.",
            "author": [
                "David Shih",
                "Marat Freytsis",
                "Stephen R. Taylor",
                "Jeff A. Dror",
                "Nolan Smyth"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12209v1",
                "http://arxiv.org/pdf/2310.12209v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "astro-ph.HE",
                "cs.LG",
                "gr-qc",
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12153v1",
            "title": "Probabilistic Sampling of Balanced K-Means using Adiabatic Quantum\n  Computing",
            "updated": "2023-10-18T17:59:45Z",
            "published": "2023-10-18T17:59:45Z",
            "summary": "Adiabatic quantum computing (AQC) is a promising quantum computing approach\nfor discrete and often NP-hard optimization problems. Current AQCs allow to\nimplement problems of research interest, which has sparked the development of\nquantum representations for many machine learning and computer vision tasks.\nDespite requiring multiple measurements from the noisy AQC, current approaches\nonly utilize the best measurement, discarding information contained in the\nremaining ones. In this work, we explore the potential of using this\ninformation for probabilistic balanced k-means clustering. Instead of\ndiscarding non-optimal solutions, we propose to use them to compute calibrated\nposterior probabilities with little additional compute cost. This allows us to\nidentify ambiguous solutions and data points, which we demonstrate on a D-Wave\nAQC on synthetic and real data.",
            "author": [
                "Jan-Nico Zaech",
                "Martin Danelljan",
                "Luc Van Gool"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12153v1",
                "http://arxiv.org/pdf/2310.12153v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12152v1",
            "title": "Learning from Rich Semantics and Coarse Locations for Long-tailed Object\n  Detection",
            "updated": "2023-10-18T17:59:41Z",
            "published": "2023-10-18T17:59:41Z",
            "summary": "Long-tailed object detection (LTOD) aims to handle the extreme data imbalance\nin real-world datasets, where many tail classes have scarce instances. One\npopular strategy is to explore extra data with image-level labels, yet it\nproduces limited results due to (1) semantic ambiguity -- an image-level label\nonly captures a salient part of the image, ignoring the remaining rich\nsemantics within the image; and (2) location sensitivity -- the label highly\ndepends on the locations and crops of the original image, which may change\nafter data transformations like random cropping. To remedy this, we propose\nRichSem, a simple but effective method, which is robust to learn rich semantics\nfrom coarse locations without the need of accurate bounding boxes. RichSem\nleverages rich semantics from images, which are then served as additional soft\nsupervision for training detectors. Specifically, we add a semantic branch to\nour detector to learn these soft semantics and enhance feature representations\nfor long-tailed object detection. The semantic branch is only used for training\nand is removed during inference. RichSem achieves consistent improvements on\nboth overall and rare-category of LVIS under different backbones and detectors.\nOur method achieves state-of-the-art performance without requiring complex\ntraining and testing procedures. Moreover, we show the effectiveness of our\nmethod on other long-tailed datasets with additional experiments. Code is\navailable at \\url{https://github.com/MengLcool/RichSem}.",
            "author": [
                "Lingchen Meng",
                "Xiyang Dai",
                "Jianwei Yang",
                "Dongdong Chen",
                "Yinpeng Chen",
                "Mengchen Liu",
                "Yi-Ling Chen",
                "Zuxuan Wu",
                "Lu Yuan",
                "Yu-Gang Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12152v1",
                "http://arxiv.org/pdf/2310.12152v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12145v1",
            "title": "Fairer and More Accurate Tabular Models Through NAS",
            "updated": "2023-10-18T17:56:24Z",
            "published": "2023-10-18T17:56:24Z",
            "summary": "Making models algorithmically fairer in tabular data has been long studied,\nwith techniques typically oriented towards fixes which usually take a neural\nmodel with an undesirable outcome and make changes to how the data are\ningested, what the model weights are, or how outputs are processed. We employ\nan emergent and different strategy where we consider updating the model's\narchitecture and training hyperparameters to find an entirely new model with\nbetter outcomes from the beginning of the debiasing procedure. In this work, we\npropose using multi-objective Neural Architecture Search (NAS) and\nHyperparameter Optimization (HPO) in the first application to the very\nchallenging domain of tabular data. We conduct extensive exploration of\narchitectural and hyperparameter spaces (MLP, ResNet, and FT-Transformer)\nacross diverse datasets, demonstrating the dependence of accuracy and fairness\nmetrics of model predictions on hyperparameter combinations. We show that\nmodels optimized solely for accuracy with NAS often fail to inherently address\nfairness concerns. We propose a novel approach that jointly optimizes\narchitectural and training hyperparameters in a multi-objective constraint of\nboth accuracy and fairness. We produce architectures that consistently Pareto\ndominate state-of-the-art bias mitigation methods either in fairness, accuracy\nor both, all of this while being Pareto-optimal over hyperparameters achieved\nthrough single-objective (accuracy) optimization runs. This research\nunderscores the promise of automating fairness and accuracy optimization in\ndeep learning models.",
            "author": [
                "Richeek Das",
                "Samuel Dooley"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12145v1",
                "http://arxiv.org/pdf/2310.12145v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CY",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12144v1",
            "title": "Dynamic financial processes identification using sparse regressive\n  reservoir computers",
            "updated": "2023-10-18T17:55:12Z",
            "published": "2023-10-18T17:55:12Z",
            "summary": "In this document, we present key findings in structured matrix approximation\ntheory, with applications to the regressive representation of dynamic financial\nprocesses. Initially, we explore a comprehensive approach involving generic\nnonlinear time delay embedding for time series data extracted from a financial\nor economic system under examination. Subsequently, we employ sparse\nleast-squares and structured matrix approximation methods to discern\napproximate representations of the output coupling matrices. These\nrepresentations play a pivotal role in establishing the regressive models\ncorresponding to the recursive structures inherent in a given financial system.\nThe document further introduces prototypical algorithms that leverage the\naforementioned techniques. These algorithms are demonstrated through\napplications in approximate identification and predictive simulation of dynamic\nfinancial and economic processes, encompassing scenarios that may or may not\nexhibit chaotic behavior.",
            "author": [
                "Fredy Vides",
                "Idelfonso B. R. Nogueira",
                "Lendy Banegas",
                "Evelyn Flores"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12144v1",
                "http://arxiv.org/pdf/2310.12144v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12143v1",
            "title": "Simple Mechanisms for Representing, Indexing and Manipulating Concepts",
            "updated": "2023-10-18T17:54:29Z",
            "published": "2023-10-18T17:54:29Z",
            "summary": "Deep networks typically learn concepts via classifiers, which involves\nsetting up a model and training it via gradient descent to fit the\nconcept-labeled data. We will argue instead that learning a concept could be\ndone by looking at its moment statistics matrix to generate a concrete\nrepresentation or signature of that concept. These signatures can be used to\ndiscover structure across the set of concepts and could recursively produce\nhigher-level concepts by learning this structure from those signatures. When\nthe concepts are `intersected', signatures of the concepts can be used to find\na common theme across a number of related `intersected' concepts. This process\ncould be used to keep a dictionary of concepts so that inputs could correctly\nidentify and be routed to the set of concepts involved in the (latent)\ngeneration of the input.",
            "author": [
                "Yuanzhi Li",
                "Raghu Meka",
                "Rina Panigrahy",
                "Kulin Shah"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12143v1",
                "http://arxiv.org/pdf/2310.12143v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12140v1",
            "title": "Online Estimation with Rolling Validation: Adaptive Nonparametric\n  Estimation with Stream Data",
            "updated": "2023-10-18T17:52:57Z",
            "published": "2023-10-18T17:52:57Z",
            "summary": "Online nonparametric estimators are gaining popularity due to their efficient\ncomputation and competitive generalization abilities. An important example\nincludes variants of stochastic gradient descent. These algorithms often take\none sample point at a time and instantly update the parameter estimate of\ninterest. In this work we consider model selection and hyperparameter tuning\nfor such online algorithms. We propose a weighted rolling-validation procedure,\nan online variant of leave-one-out cross-validation, that costs minimal extra\ncomputation for many typical stochastic gradient descent estimators. Similar to\nbatch cross-validation, it can boost base estimators to achieve a better,\nadaptive convergence rate. Our theoretical analysis is straightforward, relying\nmainly on some general statistical stability assumptions. The simulation study\nunderscores the significance of diverging weights in rolling validation in\npractice and demonstrates its sensitivity even when there is only a slim\ndifference between candidate estimators.",
            "author": [
                "Tianyu Zhang",
                "Jing Lei"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12140v1",
                "http://arxiv.org/pdf/2310.12140v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "stat.ME",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12135v1",
            "title": "Pseudointelligence: A Unifying Framework for Language Model Evaluation",
            "updated": "2023-10-18T17:48:05Z",
            "published": "2023-10-18T17:48:05Z",
            "summary": "With large language models surpassing human performance on an increasing\nnumber of benchmarks, we must take a principled approach for targeted\nevaluation of model capabilities. Inspired by pseudorandomness, we propose\npseudointelligence, which captures the maxim that \"(perceived) intelligence\nlies in the eye of the beholder\". That is, that claims of intelligence are\nmeaningful only when their evaluator is taken into account. Concretely, we\npropose a complexity-theoretic framework of model evaluation cast as a dynamic\ninteraction between a model and a learned evaluator. We demonstrate that this\nframework can be used to reason about two case studies in language model\nevaluation, as well as analyze existing evaluation methods.",
            "author": [
                "Shikhar Murty",
                "Orr Paradise",
                "Pratyusha Sharma"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12135v1",
                "http://arxiv.org/pdf/2310.12135v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13018v2",
            "title": "Getting aligned on representational alignment",
            "updated": "2023-11-02T17:49:18Z",
            "published": "2023-10-18T17:47:58Z",
            "summary": "Biological and artificial information processing systems form representations\nthat they can use to categorize, reason, plan, navigate, and make decisions.\nHow can we measure the extent to which the representations formed by these\ndiverse systems agree? Do similarities in representations then translate into\nsimilar behavior? How can a system's representations be modified to better\nmatch those of another system? These questions pertaining to the study of\nrepresentational alignment are at the heart of some of the most active research\nareas in cognitive science, neuroscience, and machine learning. For example,\ncognitive scientists measure the representational alignment of multiple\nindividuals to identify shared cognitive priors, neuroscientists align fMRI\nresponses from multiple individuals into a shared representational space for\ngroup-level analyses, and ML researchers distill knowledge from teacher models\ninto student models by increasing their alignment. Unfortunately, there is\nlimited knowledge transfer between research communities interested in\nrepresentational alignment, so progress in one field often ends up being\nrediscovered independently in another. Thus, greater cross-field communication\nwould be advantageous. To improve communication between these fields, we\npropose a unifying framework that can serve as a common language between\nresearchers studying representational alignment. We survey the literature from\nall three fields and demonstrate how prior work fits into this framework.\nFinally, we lay out open problems in representational alignment where progress\ncan benefit all three of these fields. We hope that our work can catalyze\ncross-disciplinary collaboration and accelerate progress for all communities\nstudying and developing information processing systems. We note that this is a\nworking paper and encourage readers to reach out with their suggestions for\nfuture revisions.",
            "author": [
                "Ilia Sucholutsky",
                "Lukas Muttenthaler",
                "Adrian Weller",
                "Andi Peng",
                "Andreea Bobu",
                "Been Kim",
                "Bradley C. Love",
                "Erin Grant",
                "Iris Groen",
                "Jascha Achterberg",
                "Joshua B. Tenenbaum",
                "Katherine M. Collins",
                "Katherine L. Hermann",
                "Kerem Oktar",
                "Klaus Greff",
                "Martin N. Hebart",
                "Nori Jacoby",
                "Qiuyi Zhang",
                "Raja Marjieh",
                "Robert Geirhos",
                "Sherol Chen",
                "Simon Kornblith",
                "Sunayana Rane",
                "Talia Konkle",
                "Thomas P. O'Connell",
                "Thomas Unterthiner",
                "Andrew K. Lampinen",
                "Klaus-Robert M\u00fcller",
                "Mariya Toneva",
                "Thomas L. Griffiths"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13018v2",
                "http://arxiv.org/pdf/2310.13018v2"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cs.AI",
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12131v1",
            "title": "Automated Attribute Extraction from Legal Proceedings",
            "updated": "2023-10-18T17:41:28Z",
            "published": "2023-10-18T17:41:28Z",
            "summary": "The escalating number of pending cases is a growing concern world-wide.\nRecent advancements in digitization have opened up possibilities for leveraging\nartificial intelligence (AI) tools in the processing of legal documents.\nAdopting a structured representation for legal documents, as opposed to a mere\nbag-of-words flat text representation, can significantly enhance processing\ncapabilities. With the aim of achieving this objective, we put forward a set of\ndiverse attributes for criminal case proceedings. We use a state-of-the-art\nsequence labeling framework to automatically extract attributes from the legal\ndocuments. Moreover, we demonstrate the efficacy of the extracted attributes in\na downstream task, namely legal judgment prediction.",
            "author": [
                "Subinay Adhikary",
                "Sagnik Das",
                "Sagnik Saha",
                "Procheta Sen",
                "Dwaipayan Roy",
                "Kripabandhu Ghosh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12131v1",
                "http://arxiv.org/pdf/2310.12131v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12128v1",
            "title": "DiagrammerGPT: Generating Open-Domain, Open-Platform Diagrams via LLM\n  Planning",
            "updated": "2023-10-18T17:37:10Z",
            "published": "2023-10-18T17:37:10Z",
            "summary": "Text-to-image (T2I) generation has seen significant growth over the past few\nyears. Despite this, there has been little work on generating diagrams with T2I\nmodels. A diagram is a symbolic/schematic representation that explains\ninformation using structurally rich and spatially complex visualizations (e.g.,\na dense combination of related objects, text labels, directional arrows,\nconnection lines, etc.). Existing state-of-the-art T2I models often fail at\ndiagram generation because they lack fine-grained object layout control when\nmany objects are densely connected via complex relations such as arrows/lines\nand also often fail to render comprehensible text labels. To address this gap,\nwe present DiagrammerGPT, a novel two-stage text-to-diagram generation\nframework that leverages the layout guidance capabilities of LLMs (e.g., GPT-4)\nto generate more accurate open-domain, open-platform diagrams. In the first\nstage, we use LLMs to generate and iteratively refine 'diagram plans' (in a\nplanner-auditor feedback loop) which describe all the entities (objects and\ntext labels), their relationships (arrows or lines), and their bounding box\nlayouts. In the second stage, we use a diagram generator, DiagramGLIGEN, and a\ntext label rendering module to generate diagrams following the diagram plans.\nTo benchmark the text-to-diagram generation task, we introduce AI2D-Caption, a\ndensely annotated diagram dataset built on top of the AI2D dataset. We show\nquantitatively and qualitatively that our DiagrammerGPT framework produces more\naccurate diagrams, outperforming existing T2I models. We also provide\ncomprehensive analysis including open-domain diagram generation, vector graphic\ndiagram generation in different platforms, human-in-the-loop diagram plan\nediting, and multimodal planner/auditor LLMs (e.g., GPT-4Vision). We hope our\nwork can inspire further research on diagram generation via T2I models and\nLLMs.",
            "author": [
                "Abhay Zala",
                "Han Lin",
                "Jaemin Cho",
                "Mohit Bansal"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12128v1",
                "http://arxiv.org/pdf/2310.12128v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12127v2",
            "title": "A Tale of Pronouns: Interpretability Informs Gender Bias Mitigation for\n  Fairer Instruction-Tuned Machine Translation",
            "updated": "2023-10-25T13:43:49Z",
            "published": "2023-10-18T17:36:55Z",
            "summary": "Recent instruction fine-tuned models can solve multiple NLP tasks when\nprompted to do so, with machine translation (MT) being a prominent use case.\nHowever, current research often focuses on standard performance benchmarks,\nleaving compelling fairness and ethical considerations behind. In MT, this\nmight lead to misgendered translations, resulting, among other harms, in the\nperpetuation of stereotypes and prejudices. In this work, we address this gap\nby investigating whether and to what extent such models exhibit gender bias in\nmachine translation and how we can mitigate it. Concretely, we compute\nestablished gender bias metrics on the WinoMT corpus from English to German and\nSpanish. We discover that IFT models default to male-inflected translations,\neven disregarding female occupational stereotypes. Next, using interpretability\nmethods, we unveil that models systematically overlook the pronoun indicating\nthe gender of a target occupation in misgendered translations. Finally, based\non this finding, we propose an easy-to-implement and effective bias mitigation\nsolution based on few-shot learning that leads to significantly fairer\ntranslations.",
            "author": [
                "Giuseppe Attanasio",
                "Flor Miriam Plaza-del-Arco",
                "Debora Nozza",
                "Anne Lauscher"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12127v2",
                "http://arxiv.org/pdf/2310.12127v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12126v1",
            "title": "SHARCS: Efficient Transformers through Routing with Dynamic Width\n  Sub-networks",
            "updated": "2023-10-18T17:35:15Z",
            "published": "2023-10-18T17:35:15Z",
            "summary": "We introduce SHARCS for adaptive inference that takes into account the\nhardness of input samples. SHARCS can train a router on any transformer\nnetwork, enabling the model to direct different samples to sub-networks with\nvarying widths. Our experiments demonstrate that: (1) SHARCS outperforms or\ncomplements existing per-sample adaptive inference methods across various\nclassification tasks in terms of accuracy vs. FLOPs; (2) SHARCS generalizes\nacross different architectures and can be even applied to compressed and\nefficient transformer encoders to further improve their efficiency; (3) SHARCS\ncan provide a 2 times inference speed up at an insignificant drop in accuracy.",
            "author": [
                "Mohammadreza Salehi",
                "Sachin Mehta",
                "Aditya Kusupati",
                "Ali Farhadi",
                "Hannaneh Hajishirzi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12126v1",
                "http://arxiv.org/pdf/2310.12126v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12122v1",
            "title": "The Circular Atwood Machine",
            "updated": "2023-10-18T17:22:23Z",
            "published": "2023-10-18T17:22:23Z",
            "summary": "The Atwood Machine, a classic apparatus in physics education, has\nhistorically been pivotal in demonstrating Newtonian mechanics, specifically\nNewton's Second Law. This study introduces an innovative adaptation, the\ncircular Atwood machine, aimed at exploring circular motion and angular\ndynamics and integrating emerging technologies, specifically smartphone\nsensors. Through a rotating disc subjected to controlled external torque, the\nexperiment delves into the relationship between the torque applied and the\nresulting angular momentum. The study not only presents the theoretical\nframework but also outlines a practical setup using readily available\nmaterials, emphasizing the potential for contemporary technology to enhance the\ncomprehension and teaching of fundamental physical concepts.",
            "author": [
                "Mart\u00edn Monteiro",
                "Cecilia Stari",
                "Arturo C. Marti"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12122v1",
                "http://arxiv.org/pdf/2310.12122v1"
            ],
            "primary_category": "physics.ed-ph",
            "category": [
                "physics.ed-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12121v1",
            "title": "Automatic prediction of mortality in patients with mental illness using\n  electronic health records",
            "updated": "2023-10-18T17:21:01Z",
            "published": "2023-10-18T17:21:01Z",
            "summary": "Mental disorders impact the lives of millions of people globally, not only\nimpeding their day-to-day lives but also markedly reducing life expectancy.\nThis paper addresses the persistent challenge of predicting mortality in\npatients with mental diagnoses using predictive machine-learning models with\nelectronic health records (EHR). Data from patients with mental disease\ndiagnoses were extracted from the well-known clinical MIMIC-III data set\nutilizing demographic, prescription, and procedural information. Four machine\nlearning algorithms (Logistic Regression, Random Forest, Support Vector\nMachine, and K-Nearest Neighbors) were used, with results indicating that\nRandom Forest and Support Vector Machine models outperformed others, with AUC\nscores of 0.911. Feature importance analysis revealed that drug prescriptions,\nparticularly Morphine Sulfate, play a pivotal role in prediction. We applied a\nvariety of machine learning algorithms to predict 30-day mortality followed by\nfeature importance analysis. This study can be used to assist hospital workers\nin identifying at-risk patients to reduce excess mortality.",
            "author": [
                "Sean Kim",
                "Samuel Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12121v1",
                "http://arxiv.org/pdf/2310.12121v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12118v1",
            "title": "Harnessing Dataset Cartography for Improved Compositional Generalization\n  in Transformers",
            "updated": "2023-10-18T17:14:41Z",
            "published": "2023-10-18T17:14:41Z",
            "summary": "Neural networks have revolutionized language modeling and excelled in various\ndownstream tasks. However, the extent to which these models achieve\ncompositional generalization comparable to human cognitive abilities remains a\ntopic of debate. While existing approaches in the field have mainly focused on\nnovel architectures and alternative learning paradigms, we introduce a\npioneering method harnessing the power of dataset cartography (Swayamdipta et\nal., 2020). By strategically identifying a subset of compositional\ngeneralization data using this approach, we achieve a remarkable improvement in\nmodel accuracy, yielding enhancements of up to 10% on CFQ and COGS datasets.\nNotably, our technique incorporates dataset cartography as a curriculum\nlearning criterion, eliminating the need for hyperparameter tuning while\nconsistently achieving superior performance. Our findings highlight the\nuntapped potential of dataset cartography in unleashing the full capabilities\nof compositional generalization within Transformer models. Our code is\navailable at https://github.com/cyberiada/cartography-for-compositionality.",
            "author": [
                "Osman Batur \u0130nce",
                "Tanin Zeraati",
                "Semih Yagcioglu",
                "Yadollah Yaghoobzadeh",
                "Erkut Erdem",
                "Aykut Erdem"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12118v1",
                "http://arxiv.org/pdf/2310.12118v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12115v1",
            "title": "MMD-based Variable Importance for Distributional Random Forest",
            "updated": "2023-10-18T17:12:29Z",
            "published": "2023-10-18T17:12:29Z",
            "summary": "Distributional Random Forest (DRF) is a flexible forest-based method to\nestimate the full conditional distribution of a multivariate output of interest\ngiven input variables. In this article, we introduce a variable importance\nalgorithm for DRFs, based on the well-established drop and relearn principle\nand MMD distance. While traditional importance measures only detect variables\nwith an influence on the output mean, our algorithm detects variables impacting\nthe output distribution more generally. We show that the introduced importance\nmeasure is consistent, exhibits high empirical performance on both real and\nsimulated data, and outperforms competitors. In particular, our algorithm is\nhighly efficient to select variables through recursive feature elimination, and\ncan therefore provide small sets of variables to build accurate estimates of\nconditional output distributions.",
            "author": [
                "Cl\u00e9ment B\u00e9nard",
                "Jeffrey N\u00e4f",
                "Julie Josse"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12115v1",
                "http://arxiv.org/pdf/2310.12115v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12113v1",
            "title": "CAPGrasp: An $\\mathbb{R}^3\\times \\text{SO(2)-equivariant}$ Continuous\n  Approach-Constrained Generative Grasp Sampler",
            "updated": "2023-10-18T17:07:37Z",
            "published": "2023-10-18T17:07:37Z",
            "summary": "We propose CAPGrasp, an $\\mathbb{R}^3\\times \\text{SO(2)-equivariant}$ 6-DoF\ncontinuous approach-constrained generative grasp sampler. It includes a novel\nlearning strategy for training CAPGrasp that eliminates the need to curate\nmassive conditionally labeled datasets and a constrained grasp refinement\ntechnique that improves grasp poses while respecting the grasp approach\ndirectional constraints. The experimental results demonstrate that CAPGrasp is\nmore than three times as sample efficient as unconstrained grasp samplers while\nachieving up to 38% grasp success rate improvement. CAPGrasp also achieves\n4-10% higher grasp success rates than constrained but noncontinuous grasp\nsamplers. Overall, CAPGrasp is a sample-efficient solution when grasps must\noriginate from specific directions, such as grasping in confined spaces.",
            "author": [
                "Zehang Weng",
                "Haofei Lu",
                "Jens Lundell",
                "Danica Kragic"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12113v1",
                "http://arxiv.org/pdf/2310.12113v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12112v1",
            "title": "A Cautionary Tale: On the Role of Reference Data in Empirical Privacy\n  Defenses",
            "updated": "2023-10-18T17:07:07Z",
            "published": "2023-10-18T17:07:07Z",
            "summary": "Within the realm of privacy-preserving machine learning, empirical privacy\ndefenses have been proposed as a solution to achieve satisfactory levels of\ntraining data privacy without a significant drop in model utility. Most\nexisting defenses against membership inference attacks assume access to\nreference data, defined as an additional dataset coming from the same (or a\nsimilar) underlying distribution as training data. Despite the common use of\nreference data, previous works are notably reticent about defining and\nevaluating reference data privacy. As gains in model utility and/or training\ndata privacy may come at the expense of reference data privacy, it is essential\nthat all three aspects are duly considered. In this paper, we first examine the\navailability of reference data and its privacy treatment in previous works and\ndemonstrate its necessity for fairly comparing defenses. Second, we propose a\nbaseline defense that enables the utility-privacy tradeoff with respect to both\ntraining and reference data to be easily understood. Our method is formulated\nas an empirical risk minimization with a constraint on the generalization\nerror, which, in practice, can be evaluated as a weighted empirical risk\nminimization (WERM) over the training and reference datasets. Although we\nconceived of WERM as a simple baseline, our experiments show that,\nsurprisingly, it outperforms the most well-studied and current state-of-the-art\nempirical privacy defenses using reference data for nearly all relative privacy\nlevels of reference and training data. Our investigation also reveals that\nthese existing methods are unable to effectively trade off reference data\nprivacy for model utility and/or training data privacy. Overall, our work\nhighlights the need for a proper evaluation of the triad model utility /\ntraining data privacy / reference data privacy when comparing privacy defenses.",
            "author": [
                "Caelin G. Kaplan",
                "Chuan Xu",
                "Othmane Marfoq",
                "Giovanni Neglia",
                "Anderson Santana de Oliveira"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12112v1",
                "http://arxiv.org/pdf/2310.12112v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12109v1",
            "title": "Monarch Mixer: A Simple Sub-Quadratic GEMM-Based Architecture",
            "updated": "2023-10-18T17:06:22Z",
            "published": "2023-10-18T17:06:22Z",
            "summary": "Machine learning models are increasingly being scaled in both sequence length\nand model dimension to reach longer contexts and better performance. However,\nexisting architectures such as Transformers scale quadratically along both\nthese axes. We ask: are there performant architectures that can scale\nsub-quadratically along sequence length and model dimension? We introduce\nMonarch Mixer (M2), a new architecture that uses the same sub-quadratic\nprimitive along both sequence length and model dimension: Monarch matrices, a\nsimple class of expressive structured matrices that captures many linear\ntransforms, achieves high hardware efficiency on GPUs, and scales\nsub-quadratically. As a proof of concept, we explore the performance of M2 in\nthree domains: non-causal BERT-style language modeling, ViT-style image\nclassification, and causal GPT-style language modeling. For non-causal\nBERT-style modeling, M2 matches BERT-base and BERT-large in downstream GLUE\nquality with up to 27% fewer parameters, and achieves up to 9.1$\\times$ higher\nthroughput at sequence length 4K. On ImageNet, M2 outperforms ViT-b by 1% in\naccuracy, with only half the parameters. Causal GPT-style models introduce a\ntechnical challenge: enforcing causality via masking introduces a quadratic\nbottleneck. To alleviate this bottleneck, we develop a novel theoretical view\nof Monarch matrices based on multivariate polynomial evaluation and\ninterpolation, which lets us parameterize M2 to be causal while remaining\nsub-quadratic. Using this parameterization, M2 matches GPT-style Transformers\nat 360M parameters in pretraining perplexity on The PILE--showing for the first\ntime that it may be possible to match Transformer quality without attention or\nMLPs.",
            "author": [
                "Daniel Y. Fu",
                "Simran Arora",
                "Jessica Grogan",
                "Isys Johnson",
                "Sabri Eyuboglu",
                "Armin W. Thomas",
                "Benjamin Spector",
                "Michael Poli",
                "Atri Rudra",
                "Christopher R\u00e9"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12109v1",
                "http://arxiv.org/pdf/2310.12109v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12107v1",
            "title": "An Online Learning Theory of Brokerage",
            "updated": "2023-10-18T17:01:32Z",
            "published": "2023-10-18T17:01:32Z",
            "summary": "We investigate brokerage between traders from an online learning perspective.\nAt any round $t$, two traders arrive with their private valuations, and the\nbroker proposes a trading price. Unlike other bilateral trade problems already\nstudied in the online learning literature, we focus on the case where there are\nno designated buyer and seller roles: each trader will attempt to either buy or\nsell depending on the current price of the good.\n  We assume the agents' valuations are drawn i.i.d. from a fixed but unknown\ndistribution. If the distribution admits a density bounded by some constant\n$M$, then, for any time horizon $T$:\n  $\\bullet$ If the agents' valuations are revealed after each interaction, we\nprovide an algorithm achieving regret $M \\log T$ and show this rate is optimal,\nup to constant factors.\n  $\\bullet$ If only their willingness to sell or buy at the proposed price is\nrevealed after each interaction, we provide an algorithm achieving regret\n$\\sqrt{M T}$ and show this rate is optimal, up to constant factors.\n  Finally, if we drop the bounded density assumption, we show that the optimal\nrate degrades to $\\sqrt{T}$ in the first case, and the problem becomes\nunlearnable in the second.",
            "author": [
                "Nata\u0161a Boli\u0107",
                "Tommaso Cesari",
                "Roberto Colomboni"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12107v1",
                "http://arxiv.org/pdf/2310.12107v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12106v1",
            "title": "Advances in compilation for quantum hardware -- A demonstration of magic\n  state distillation and repeat-until-success protocols",
            "updated": "2023-10-18T16:57:36Z",
            "published": "2023-10-18T16:57:36Z",
            "summary": "Fault-tolerant protocols enable large and precise quantum algorithms. Many\nsuch protocols rely on a feed-forward processing of data, enabled by a hybrid\nof quantum and classical logic. Representing the control structure of such\nprograms can be a challenge. Here we explore two such fault-tolerant\nsubroutines and analyze the performance of the subroutines using Quantum\nIntermediate Representation (QIR) as their underlying intermediate\nrepresentation. First, we look at QIR's ability to leverage the LLVM compiler\ntoolchain to unroll the quantum iteration logic required to perform magic state\ndistillation on the $[[5,1,3]]$ quantum error-correcting code as originally\nintroduced by Bravyi and Kitaev [Phys. Rev. A 71, 022316 (2005)]. This allows\nus to not only realize the first implementation of a real-time magic state\ndistillation protocol on quantum hardware, but also demonstrate QIR's ability\nto optimize complex program structures without degrading machine performance.\nNext, we investigate a different fault-tolerant protocol that was first\nintroduced by Paetznick and Svore [arXiv:1311.1074 (2013)], that reduces the\namount of non-Clifford gates needed for a particular algorithm. We look at four\ndifferent implementations of this two-stage repeat-until-success algorithm to\nanalyze the performance changes as the results of programming choices. We find\nthe QIR offers a viable representation for a compiled high-level program that\nperforms nearly as well as a hand-optimized version written directly in quantum\nassembly. Both of these results demonstrate QIR's ability to accurately and\nefficiently expand the complexity of fault-tolerant protocols that can be\nrealized today on quantum hardware.",
            "author": [
                "Natalie C. Brown",
                "John Peter Campora III",
                "Cassandra Granade",
                "Bettina Heim",
                "Stefan Wernli",
                "Ciaran Ryan-Anderson",
                "Dominic Lucchetti",
                "Adam Paetznick",
                "Martin Roetteler",
                "Krysta Svore",
                "Alex Chernoguzov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12106v1",
                "http://arxiv.org/pdf/2310.12106v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12103v1",
            "title": "Quality Diversity through Human Feedback",
            "updated": "2023-10-18T16:46:16Z",
            "published": "2023-10-18T16:46:16Z",
            "summary": "Reinforcement learning from human feedback (RLHF) has exhibited the potential\nto enhance the performance of foundation models for qualitative tasks. Despite\nits promise, its efficacy is often restricted when conceptualized merely as a\nmechanism to maximize learned reward models of averaged human preferences,\nespecially in areas such as image generation which demand diverse model\nresponses. Meanwhile, quality diversity (QD) algorithms, dedicated to seeking\ndiverse, high-quality solutions, are often constrained by the dependency on\nmanually defined diversity metrics. Interestingly, such limitations of RLHF and\nQD can be overcome by blending insights from both. This paper introduces\nQuality Diversity through Human Feedback (QDHF), which employs human feedback\nfor inferring diversity metrics, expanding the applicability of QD algorithms.\nEmpirical results reveal that QDHF outperforms existing QD methods regarding\nautomatic diversity discovery, and matches the search capabilities of QD with\nhuman-constructed metrics. Notably, when deployed for a latent space\nillumination task, QDHF markedly enhances the diversity of images generated by\na Diffusion model. The study concludes with an in-depth analysis of QDHF's\nsample efficiency and the quality of its derived diversity metrics, emphasizing\nits promise for enhancing exploration and diversity in optimization for\ncomplex, open-ended tasks.",
            "author": [
                "Li Ding",
                "Jenny Zhang",
                "Jeff Clune",
                "Lee Spector",
                "Joel Lehman"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12103v1",
                "http://arxiv.org/pdf/2310.12103v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12100v1",
            "title": "Non-Intrusive Adaptation: Input-Centric Parameter-efficient Fine-Tuning\n  for Versatile Multimodal Modeling",
            "updated": "2023-10-18T16:43:08Z",
            "published": "2023-10-18T16:43:08Z",
            "summary": "Large language models (LLMs) and vision language models (VLMs) demonstrate\nexcellent performance on a wide range of tasks by scaling up parameter counts\nfrom O(10^9) to O(10^{12}) levels and further beyond. These large scales make\nit impossible to adapt and deploy fully specialized models given a task of\ninterest. Parameter-efficient fine-tuning (PEFT) emerges as a promising\ndirection to tackle the adaptation and serving challenges for such large\nmodels. We categorize PEFT techniques into two types: intrusive and\nnon-intrusive. Intrusive PEFT techniques directly change a model's internal\narchitecture. Though more flexible, they introduce significant complexities for\ntraining and serving. Non-intrusive PEFT techniques leave the internal\narchitecture unchanged and only adapt model-external parameters, such as\nembeddings for input. In this work, we describe AdaLink as a non-intrusive PEFT\ntechnique that achieves competitive performance compared to SoTA intrusive PEFT\n(LoRA) and full model fine-tuning (FT) on various tasks. We evaluate using both\ntext-only and multimodal tasks, with experiments that account for both\nparameter-count scaling and training regime (with and without instruction\ntuning).",
            "author": [
                "Yaqing Wang",
                "Jialin Wu",
                "Tanmaya Dabral",
                "Jiageng Zhang",
                "Geoff Brown",
                "Chun-Ta Lu",
                "Frederick Liu",
                "Yi Liang",
                "Bo Pang",
                "Michael Bendersky",
                "Radu Soricut"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12100v1",
                "http://arxiv.org/pdf/2310.12100v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CV",
                "cs.LG",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13017v1",
            "title": "Position Interpolation Improves ALiBi Extrapolation",
            "updated": "2023-10-18T16:41:47Z",
            "published": "2023-10-18T16:41:47Z",
            "summary": "Linear position interpolation helps pre-trained models using rotary position\nembeddings (RoPE) to extrapolate to longer sequence lengths. We propose using\nlinear position interpolation to extend the extrapolation range of models using\nAttention with Linear Biases (ALiBi). We find position interpolation\nsignificantly improves extrapolation capability on upstream language modelling\nand downstream summarization and retrieval tasks.",
            "author": [
                "Faisal Al-Khateeb",
                "Nolan Dey",
                "Daria Soboleva",
                "Joel Hestness"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13017v1",
                "http://arxiv.org/pdf/2310.13017v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12095v1",
            "title": "On the latent dimension of deep autoencoders for reduced order modeling\n  of PDEs parametrized by random fields",
            "updated": "2023-10-18T16:38:23Z",
            "published": "2023-10-18T16:38:23Z",
            "summary": "Deep Learning is having a remarkable impact on the design of Reduced Order\nModels (ROMs) for Partial Differential Equations (PDEs), where it is exploited\nas a powerful tool for tackling complex problems for which classical methods\nmight fail. In this respect, deep autoencoders play a fundamental role, as they\nprovide an extremely flexible tool for reducing the dimensionality of a given\nproblem by leveraging on the nonlinear capabilities of neural networks. Indeed,\nstarting from this paradigm, several successful approaches have already been\ndeveloped, which are here referred to as Deep Learning-based ROMs (DL-ROMs).\nNevertheless, when it comes to stochastic problems parameterized by random\nfields, the current understanding of DL-ROMs is mostly based on empirical\nevidence: in fact, their theoretical analysis is currently limited to the case\nof PDEs depending on a finite number of (deterministic) parameters. The purpose\nof this work is to extend the existing literature by providing some theoretical\ninsights about the use of DL-ROMs in the presence of stochasticity generated by\nrandom fields. In particular, we derive explicit error bounds that can guide\ndomain practitioners when choosing the latent dimension of deep autoencoders.\nWe evaluate the practical usefulness of our theory by means of numerical\nexperiments, showing how our analysis can significantly impact the performance\nof DL-ROMs.",
            "author": [
                "Nicola Rares Franco",
                "Daniel Fraulin",
                "Andrea Manzoni",
                "Paolo Zunino"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12095v1",
                "http://arxiv.org/pdf/2310.12095v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12092v1",
            "title": "HSTR-Net: Reference Based Video Super-resolution for Aerial Surveillance\n  with Dual Cameras",
            "updated": "2023-10-18T16:37:01Z",
            "published": "2023-10-18T16:37:01Z",
            "summary": "Aerial surveillance requires high spatio-temporal resolution (HSTR) video for\nmore accurate detection and tracking of objects. This is especially true for\nwide-area surveillance (WAS), where the surveyed region is large and the\nobjects of interest are small. This paper proposes a dual camera system for the\ngeneration of HSTR video using reference-based super-resolution (RefSR). One\ncamera captures high spatial resolution low frame rate (HSLF) video while the\nother captures low spatial resolution high frame rate (LSHF) video\nsimultaneously for the same scene. A novel deep learning architecture is\nproposed to fuse HSLF and LSHF video feeds and synthesize HSTR video frames at\nthe output. The proposed model combines optical flow estimation and\n(channel-wise and spatial) attention mechanisms to capture the fine motion and\nintricate dependencies between frames of the two video feeds. Simulations show\nthat the proposed model provides significant improvement over existing\nreference-based SR techniques in terms of PSNR and SSIM metrics. The method\nalso exhibits sufficient frames per second (FPS) for WAS when deployed on a\npower-constrained drone equipped with dual cameras.",
            "author": [
                "H. Umut Suluhan",
                "Hasan F. Ates",
                "Bahadir K. Gunturk"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12092v1",
                "http://arxiv.org/pdf/2310.12092v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12086v1",
            "title": "Unveiling the Siren's Song: Towards Reliable Fact-Conflicting\n  Hallucination Detection",
            "updated": "2023-10-18T16:27:49Z",
            "published": "2023-10-18T16:27:49Z",
            "summary": "Large Language Models (LLMs), such as ChatGPT/GPT-4, have garnered widespread\nattention owing to their myriad of practical applications, yet their adoption\nhas been constrained by issues of fact-conflicting hallucinations across web\nplatforms. The assessment of factuality in text, produced by LLMs, remains\ninadequately explored, extending not only to the judgment of vanilla facts but\nalso encompassing the evaluation of factual errors emerging in complex\ninferential tasks like multi-hop, and etc. In response, we introduce FactCHD, a\nfact-conflicting hallucination detection benchmark meticulously designed for\nLLMs. Functioning as a pivotal tool in evaluating factuality within\n\"Query-Respons\" contexts, our benchmark assimilates a large-scale dataset,\nencapsulating a broad spectrum of factuality patterns, such as vanilla,\nmulti-hops, comparison, and set-operation patterns. A distinctive feature of\nour benchmark is its incorporation of fact-based chains of evidence, thereby\nfacilitating comprehensive and conducive factual reasoning throughout the\nassessment process. We evaluate multiple LLMs, demonstrating the effectiveness\nof the benchmark and current methods fall short of faithfully detecting factual\nerrors. Furthermore, we present TRUTH-TRIANGULATOR that synthesizes reflective\nconsiderations by tool-enhanced ChatGPT and LoRA-tuning based on Llama2, aiming\nto yield more credible detection through the amalgamation of predictive results\nand evidence. The benchmark dataset and source code will be made available in\nhttps://github.com/zjunlp/FactCHD.",
            "author": [
                "Xiang Chen",
                "Duanzheng Song",
                "Honghao Gui",
                "Chengxi Wang",
                "Ningyu Zhang",
                "Fei Huang",
                "Chengfei Lv",
                "Dan Zhang",
                "Huajun Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12086v1",
                "http://arxiv.org/pdf/2310.12086v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CV",
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12083v1",
            "title": "Contributing Components of Metabolic Energy Models to Metabolic Cost\n  Estimations in Gait",
            "updated": "2023-10-18T16:24:23Z",
            "published": "2023-10-18T16:24:23Z",
            "summary": "Objective: As metabolic cost is a primary factor influencing humans' gait, we\nwant to deepen our understanding of metabolic energy expenditure models.\nTherefore, this paper identifies the parameters and input variables, such as\nmuscle or joint states, that contribute to accurate metabolic cost estimations.\nMethods: We explored the parameters of four metabolic energy expenditure models\nin a Monte Carlo sensitivity analysis. Then, we analysed the model parameters\nby their calculated sensitivity indices, physiological context, and the\nresulting metabolic rates during the gait cycle. The parameter combination with\nthe highest accuracy in the Monte Carlo simulations represented a\nquasi-optimized model. In the second step, we investigated the importance of\ninput parameters and variables by analysing the accuracy of neural networks\ntrained with different input features. Results: Power-related parameters were\nmost influential in the sensitivity analysis and the neural network-based\nfeature selection. We observed that the quasi-optimized models produced\nnegative metabolic rates, contradicting muscle physiology. Neural network-based\nmodels showed promising abilities but have been unable to match the accuracy of\ntraditional metabolic energy expenditure models. Conclusion: We showed that\npower-related metabolic energy expenditure model parameters and inputs are most\ninfluential during gait. Furthermore, our results suggest that neural\nnetwork-based metabolic energy expenditure models are viable. However, bigger\ndatasets are required to achieve better accuracy. Significance: As there is a\nneed for more accurate metabolic energy expenditure models, we explored which\nmusculoskeletal parameters are essential when developing a model to estimate\nmetabolic energy.",
            "author": [
                "Markus Gambietz",
                "Marlies Nitschke",
                "J\u00f6rg Miehling",
                "Anne Koelewijn"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TBME.2023.3331271",
                "http://arxiv.org/abs/2310.12083v1",
                "http://arxiv.org/pdf/2310.12083v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12079v1",
            "title": "Differential Equation Scaling Limits of Shaped and Unshaped Neural\n  Networks",
            "updated": "2023-10-18T16:15:10Z",
            "published": "2023-10-18T16:15:10Z",
            "summary": "Recent analyses of neural networks with shaped activations (i.e. the\nactivation function is scaled as the network size grows) have led to scaling\nlimits described by differential equations. However, these results do not a\npriori tell us anything about \"ordinary\" unshaped networks, where the\nactivation is unchanged as the network size grows. In this article, we find\nsimilar differential equation based asymptotic characterization for two types\nof unshaped networks.\n  Firstly, we show that the following two architectures converge to the same\ninfinite-depth-and-width limit at initialization: (i) a fully connected ResNet\nwith a $d^{-1/2}$ factor on the residual branch, where $d$ is the network\ndepth. (ii) a multilayer perceptron (MLP) with depth $d \\ll$ width $n$ and\nshaped ReLU activation at rate $d^{-1/2}$.\n  Secondly, for an unshaped MLP at initialization, we derive the first order\nasymptotic correction to the layerwise correlation. In particular, if\n$\\rho_\\ell$ is the correlation at layer $\\ell$, then $q_t = \\ell^2 (1 -\n\\rho_\\ell)$ with $t = \\frac{\\ell}{n}$ converges to an SDE with a singularity at\n$t=0$.\n  These results together provide a connection between shaped and unshaped\nnetwork architectures, and opens up the possibility of studying the effect of\nnormalization methods and how it connects with shaping activation functions.",
            "author": [
                "Mufan Bill Li",
                "Mihai Nica"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12079v1",
                "http://arxiv.org/pdf/2310.12079v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12077v1",
            "title": "One-Shot Imitation Learning: A Pose Estimation Perspective",
            "updated": "2023-10-18T16:13:35Z",
            "published": "2023-10-18T16:13:35Z",
            "summary": "In this paper, we study imitation learning under the challenging setting of:\n(1) only a single demonstration, (2) no further data collection, and (3) no\nprior task or object knowledge. We show how, with these constraints, imitation\nlearning can be formulated as a combination of trajectory transfer and unseen\nobject pose estimation. To explore this idea, we provide an in-depth study on\nhow state-of-the-art unseen object pose estimators perform for one-shot\nimitation learning on ten real-world tasks, and we take a deep dive into the\neffects that camera calibration, pose estimation error, and spatial\ngeneralisation have on task success rates. For videos, please visit\nhttps://www.robot-learning.uk/pose-estimation-perspective.",
            "author": [
                "Pietro Vitiello",
                "Kamil Dreczkowski",
                "Edward Johns"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12077v1",
                "http://arxiv.org/pdf/2310.12077v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12069v2",
            "title": "Transformers for scientific data: a pedagogical review for astronomers",
            "updated": "2023-10-19T02:24:59Z",
            "published": "2023-10-18T16:02:32Z",
            "summary": "The deep learning architecture associated with ChatGPT and related generative\nAI products is known as transformers. Initially applied to Natural Language\nProcessing, transformers and the self-attention mechanism they exploit have\ngained widespread interest across the natural sciences. The goal of this\npedagogical and informal review is to introduce transformers to scientists. The\nreview includes the mathematics underlying the attention mechanism, a\ndescription of the original transformer architecture, and a section on\napplications to time series and imaging data in astronomy. We include a\nFrequently Asked Questions section for readers who are curious about generative\nAI or interested in getting started with transformers for their research\nproblem.",
            "author": [
                "Dimitrios Tanoglidis",
                "Bhuvnesh Jain",
                "Helen Qu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12069v2",
                "http://arxiv.org/pdf/2310.12069v2"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12063v1",
            "title": "Black-Box Training Data Identification in GANs via Detector Networks",
            "updated": "2023-10-18T15:53:20Z",
            "published": "2023-10-18T15:53:20Z",
            "summary": "Since their inception Generative Adversarial Networks (GANs) have been\npopular generative models across images, audio, video, and tabular data. In\nthis paper we study whether given access to a trained GAN, as well as fresh\nsamples from the underlying distribution, if it is possible for an attacker to\nefficiently identify if a given point is a member of the GAN's training data.\nThis is of interest for both reasons related to copyright, where a user may\nwant to determine if their copyrighted data has been used to train a GAN, and\nin the study of data privacy, where the ability to detect training set\nmembership is known as a membership inference attack. Unlike the majority of\nprior work this paper investigates the privacy implications of using GANs in\nblack-box settings, where the attack only has access to samples from the\ngenerator, rather than access to the discriminator as well. We introduce a\nsuite of membership inference attacks against GANs in the black-box setting and\nevaluate our attacks on image GANs trained on the CIFAR10 dataset and tabular\nGANs trained on genomic data. Our most successful attack, called The Detector,\ninvolve training a second network to score samples based on their likelihood of\nbeing generated by the GAN, as opposed to a fresh sample from the distribution.\nWe prove under a simple model of the generator that the detector is an\napproximately optimal membership inference attack. Across a wide range of\ntabular and image datasets, attacks, and GAN architectures, we find that\nadversaries can orchestrate non-trivial privacy attacks when provided with\naccess to samples from the generator. At the same time, the attack success\nachievable against GANs still appears to be lower compared to other generative\nand discriminative models; this leaves the intriguing open question of whether\nGANs are in fact more private, or if it is a matter of developing stronger\nattacks.",
            "author": [
                "Lukman Olagoke",
                "Salil Vadhan",
                "Seth Neel"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12063v1",
                "http://arxiv.org/pdf/2310.12063v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19814v1",
            "title": "Learning Gradient Fields for Scalable and Generalizable Irregular\n  Packing",
            "updated": "2023-10-18T15:52:55Z",
            "published": "2023-10-18T15:52:55Z",
            "summary": "The packing problem, also known as cutting or nesting, has diverse\napplications in logistics, manufacturing, layout design, and atlas generation.\nIt involves arranging irregularly shaped pieces to minimize waste while\navoiding overlap. Recent advances in machine learning, particularly\nreinforcement learning, have shown promise in addressing the packing problem.\nIn this work, we delve deeper into a novel machine learning-based approach that\nformulates the packing problem as conditional generative modeling. To tackle\nthe challenges of irregular packing, including object validity constraints and\ncollision avoidance, our method employs the score-based diffusion model to\nlearn a series of gradient fields. These gradient fields encode the\ncorrelations between constraint satisfaction and the spatial relationships of\npolygons, learned from teacher examples. During the testing phase, packing\nsolutions are generated using a coarse-to-fine refinement mechanism guided by\nthe learned gradient fields. To enhance packing feasibility and optimality, we\nintroduce two key architectural designs: multi-scale feature extraction and\ncoarse-to-fine relation extraction. We conduct experiments on two typical\nindustrial packing domains, considering translations only. Empirically, our\napproach demonstrates spatial utilization rates comparable to, or even\nsurpassing, those achieved by the teacher algorithm responsible for training\ndata generation. Additionally, it exhibits some level of generalization to\nshape variations. We are hopeful that this method could pave the way for new\npossibilities in solving the packing problem.",
            "author": [
                "Tianyang Xue",
                "Mingdong Wu",
                "Lin Lu",
                "Haoxuan Wang",
                "Hao Dong",
                "Baoquan Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19814v1",
                "http://arxiv.org/pdf/2310.19814v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12062v1",
            "title": "On the use of Vision-Language models for Visual Sentiment Analysis: a\n  study on CLIP",
            "updated": "2023-10-18T15:50:48Z",
            "published": "2023-10-18T15:50:48Z",
            "summary": "This work presents a study on how to exploit the CLIP embedding space to\nperform Visual Sentiment Analysis. We experiment with two architectures built\non top of the CLIP embedding space, which we denote by CLIP-E. We train the\nCLIP-E models with WEBEmo, the largest publicly available and manually labeled\nbenchmark for Visual Sentiment Analysis, and perform two sets of experiments.\nFirst, we test on WEBEmo and compare the CLIP-E architectures with\nstate-of-the-art (SOTA) models and with CLIP Zero-Shot. Second, we perform\ncross dataset evaluation, and test the CLIP-E architectures trained with WEBEmo\non other Visual Sentiment Analysis benchmarks. Our results show that the CLIP-E\napproaches outperform SOTA models in WEBEmo fine grained categorization, and\nthey also generalize better when tested on datasets that have not been seen\nduring training. Interestingly, we observed that for the FI dataset, CLIP\nZero-Shot produces better accuracies than SOTA models and CLIP-E trained on\nWEBEmo. These results motivate several questions that we discuss in this paper,\nsuch as how we should design new benchmarks and evaluate Visual Sentiment\nAnalysis, and whether we should keep designing tailored Deep Learning models\nfor Visual Sentiment Analysis or focus our efforts on better using the\nknowledge encoded in large vision-language models such as CLIP for this task.",
            "author": [
                "Cristina Bustos",
                "Carles Civit",
                "Brian Du",
                "Albert Sole-Ribalta",
                "Agata Lapedriza"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12062v1",
                "http://arxiv.org/pdf/2310.12062v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12060v2",
            "title": "Robust Class-Conditional Distribution Alignment for Partial Domain\n  Adaptation",
            "updated": "2023-10-19T00:48:14Z",
            "published": "2023-10-18T15:49:46Z",
            "summary": "Unwanted samples from private source categories in the learning objective of\na partial domain adaptation setup can lead to negative transfer and reduce\nclassification performance. Existing methods, such as re-weighting or\naggregating target predictions, are vulnerable to this issue, especially during\ninitial training stages, and do not adequately address class-level feature\nalignment. Our proposed approach seeks to overcome these limitations by delving\ndeeper than just the first-order moments to derive distinct and compact\ncategorical distributions. We employ objectives that optimize the intra and\ninter-class distributions in a domain-invariant fashion and design a robust\npseudo-labeling for efficient target supervision. Our approach incorporates a\ncomplement entropy objective module to reduce classification uncertainty and\nflatten incorrect category predictions. The experimental findings and ablation\nanalysis of the proposed modules demonstrate the superior performance of our\nproposed model compared to benchmarks.",
            "author": [
                "Sandipan Choudhuri",
                "Arunabha Sen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12060v2",
                "http://arxiv.org/pdf/2310.12060v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09235v1",
            "title": "Scalable Diffusion for Materials Generation",
            "updated": "2023-10-18T15:49:39Z",
            "published": "2023-10-18T15:49:39Z",
            "summary": "Generative models trained on internet-scale data are capable of generating\nnovel and realistic texts, images, and videos. A natural next question is\nwhether these models can advance science, for example by generating novel\nstable materials. Traditionally, models with explicit structures (e.g., graphs)\nhave been used in modeling structural relationships in scientific data (e.g.,\natoms and bonds in crystals), but generating structures can be difficult to\nscale to large and complex systems. Another challenge in generating materials\nis the mismatch between standard generative modeling metrics and downstream\napplications. For instance, common metrics such as the reconstruction error do\nnot correlate well with the downstream goal of discovering stable materials. In\nthis work, we tackle the scalability challenge by developing a unified crystal\nrepresentation that can represent any crystal structure (UniMat), followed by\ntraining a diffusion probabilistic model on these UniMat representations. Our\nempirical results suggest that despite the lack of explicit structure modeling,\nUniMat can generate high fidelity crystal structures from larger and more\ncomplex chemical systems, outperforming previous graph-based approaches under\nvarious generative modeling metrics. To better connect the generation quality\nof materials to downstream applications, such as discovering novel stable\nmaterials, we propose additional metrics for evaluating generative models of\nmaterials, including per-composition formation energy and stability with\nrespect to convex hulls through decomposition energy from Density Function\nTheory (DFT). Lastly, we show that conditional generation with UniMat can scale\nto previously established crystal datasets with up to millions of crystals\nstructures, outperforming random structure search (the current leading method\nfor structure discovery) in discovering new stable materials.",
            "author": [
                "Mengjiao Yang",
                "KwangHwan Cho",
                "Amil Merchant",
                "Pieter Abbeel",
                "Dale Schuurmans",
                "Igor Mordatch",
                "Ekin Dogus Cubuk"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09235v1",
                "http://arxiv.org/pdf/2311.09235v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12055v1",
            "title": "Understanding Reward Ambiguity Through Optimal Transport Theory in\n  Inverse Reinforcement Learning",
            "updated": "2023-10-18T15:42:53Z",
            "published": "2023-10-18T15:42:53Z",
            "summary": "In inverse reinforcement learning (IRL), the central objective is to infer\nunderlying reward functions from observed expert behaviors in a way that not\nonly explains the given data but also generalizes to unseen scenarios. This\nensures robustness against reward ambiguity where multiple reward functions can\nequally explain the same expert behaviors. While significant efforts have been\nmade in addressing this issue, current methods often face challenges with\nhigh-dimensional problems and lack a geometric foundation. This paper harnesses\nthe optimal transport (OT) theory to provide a fresh perspective on these\nchallenges. By utilizing the Wasserstein distance from OT, we establish a\ngeometric framework that allows for quantifying reward ambiguity and\nidentifying a central representation or centroid of reward functions. These\ninsights pave the way for robust IRL methodologies anchored in geometric\ninterpretations, offering a structured approach to tackle reward ambiguity in\nhigh-dimensional settings.",
            "author": [
                "Ali Baheri"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12055v1",
                "http://arxiv.org/pdf/2310.12055v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SY",
                "eess.SY",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12054v1",
            "title": "Simultaneous Learning of Contact and Continuous Dynamics",
            "updated": "2023-10-18T15:40:57Z",
            "published": "2023-10-18T15:40:57Z",
            "summary": "Robotic manipulation can greatly benefit from the data efficiency,\nrobustness, and predictability of model-based methods if robots can quickly\ngenerate models of novel objects they encounter. This is especially difficult\nwhen effects like complex joint friction lack clear first-principles models and\nare usually ignored by physics simulators. Further, numerically-stiff contact\ndynamics can make common model-building approaches struggle. We propose a\nmethod to simultaneously learn contact and continuous dynamics of a novel,\npossibly multi-link object by observing its motion through contact-rich\ntrajectories. We formulate a system identification process with a loss that\ninfers unmeasured contact forces, penalizing their violation of physical\nconstraints and laws of motion given current model parameters. Our loss is\nunlike prediction-based losses used in differentiable simulation. Using a new\ndataset of real articulated object trajectories and an existing cube toss\ndataset, our method outperforms differentiable simulation and end-to-end\nalternatives with more data efficiency. See our project page for code,\ndatasets, and media: https://sites.google.com/view/continuous-contact-nets/home",
            "author": [
                "Bibit Bianchini",
                "Mathew Halm",
                "Michael Posa"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12054v1",
                "http://arxiv.org/pdf/2310.12054v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12052v1",
            "title": "Machine Learning-based Nutrient Application's Timeline Recommendation\n  for Smart Agriculture: A Large-Scale Data Mining Approach",
            "updated": "2023-10-18T15:37:19Z",
            "published": "2023-10-18T15:37:19Z",
            "summary": "This study addresses the vital role of data analytics in monitoring\nfertiliser applications in crop cultivation. Inaccurate fertiliser application\ndecisions can lead to costly consequences, hinder food production, and cause\nenvironmental harm. We propose a solution to predict nutrient application by\ndetermining required fertiliser quantities for an entire season. The proposed\nsolution recommends adjusting fertiliser amounts based on weather conditions\nand soil characteristics to promote cost-effective and environmentally friendly\nagriculture. The collected dataset is high-dimensional and heterogeneous. Our\nresearch examines large-scale heterogeneous datasets in the context of the\ndecision-making process, encompassing data collection and analysis. We also\nstudy the impact of fertiliser applications combined with weather data on crop\nyield, using the winter wheat crop as a case study. By understanding local\ncontextual and geographic factors, we aspire to stabilise or even reduce the\ndemand for agricultural nutrients while enhancing crop development. The\nproposed approach is proven to be efficient and scalable, as it is validated\nusing a real-world and large dataset.",
            "author": [
                "Usama Ikhlaq",
                "Tahar Kechadi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12052v1",
                "http://arxiv.org/pdf/2310.12052v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "I.2.6; J.3; H.2.8"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12046v2",
            "title": "Applications of ML-Based Surrogates in Bayesian Approaches to Inverse\n  Problems",
            "updated": "2023-10-23T21:43:52Z",
            "published": "2023-10-18T15:32:30Z",
            "summary": "Neural networks have become a powerful tool as surrogate models to provide\nnumerical solutions for scientific problems with increased computational\nefficiency. This efficiency can be advantageous for numerically challenging\nproblems where time to solution is important or when evaluation of many similar\nanalysis scenarios is required. One particular area of scientific interest is\nthe setting of inverse problems, where one knows the forward dynamics of a\nsystem are described by a partial differential equation and the task is to\ninfer properties of the system given (potentially noisy) observations of these\ndynamics. We consider the inverse problem of inferring the location of a wave\nsource on a square domain, given a noisy solution to the 2-D acoustic wave\nequation. Under the assumption of Gaussian noise, a likelihood function for\nsource location can be formulated, which requires one forward simulation of the\nsystem per evaluation. Using a standard neural network as a surrogate model\nmakes it computationally feasible to evaluate this likelihood several times,\nand so Markov Chain Monte Carlo methods can be used to evaluate the posterior\ndistribution of the source location. We demonstrate that this method can\naccurately infer source-locations from noisy data.",
            "author": [
                "Pelin Ersin",
                "Emma Hayes",
                "Peter Matthews",
                "Paramjyoti Mohapatra",
                "Elisa Negrini",
                "Karl Schulz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12046v2",
                "http://arxiv.org/pdf/2310.12046v2"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17658v2",
            "title": "Is Channel Independent strategy optimal for Time Series Forecasting?",
            "updated": "2023-11-15T10:12:14Z",
            "published": "2023-10-18T15:24:34Z",
            "summary": "There has been an emergence of various models for long-term time series\nforecasting. Recent studies have demonstrated that a single linear layer, using\nChannel Dependent (CD) or Channel Independent (CI) modeling, can even\noutperform a large number of sophisticated models. However, current research\nprimarily considers CD and CI as two complementary yet mutually exclusive\napproaches, unable to harness these two extremes simultaneously. And it is also\na challenging issue that both CD and CI are static strategies that cannot be\ndetermined to be optimal for a specific dataset without extensive experiments.\nIn this paper, we reconsider whether the current CI strategy is the best\nsolution for time series forecasting. First, we propose a simple yet effective\nstrategy called CSC, which stands for $\\mathbf{C}$hannel\n$\\mathbf{S}$elf-$\\mathbf{C}$lustering strategy, for linear models. Our Channel\nSelf-Clustering (CSC) enhances CI strategy's performance improvements while\nreducing parameter size, for exmpale by over 10 times on electricity dataset,\nand significantly cutting training time. Second, we further propose Channel\nRearrangement (CR), a method for deep models inspired by the self-clustering.\nCR attains competitive performance against baselines. Finally, we also discuss\nwhether it is best to forecast the future values using the historical values of\nthe same channel as inputs. We hope our findings and methods could inspire new\nsolutions beyond CD/CI.",
            "author": [
                "Yuan Peiwen",
                "Zhu Changsheng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17658v2",
                "http://arxiv.org/pdf/2310.17658v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12036v2",
            "title": "A General Theoretical Paradigm to Understand Learning from Human\n  Preferences",
            "updated": "2023-11-22T00:02:49Z",
            "published": "2023-10-18T15:21:28Z",
            "summary": "The prevalent deployment of learning from human preferences through\nreinforcement learning (RLHF) relies on two important approximations: the first\nassumes that pairwise preferences can be substituted with pointwise rewards.\nThe second assumes that a reward model trained on these pointwise rewards can\ngeneralize from collected data to out-of-distribution data sampled by the\npolicy. Recently, Direct Preference Optimisation (DPO) has been proposed as an\napproach that bypasses the second approximation and learn directly a policy\nfrom collected data without the reward modelling stage. However, this method\nstill heavily relies on the first approximation.\n  In this paper we try to gain a deeper theoretical understanding of these\npractical algorithms. In particular we derive a new general objective called\n$\\Psi$PO for learning from human preferences that is expressed in terms of\npairwise preferences and therefore bypasses both approximations. This new\ngeneral objective allows us to perform an in-depth analysis of the behavior of\nRLHF and DPO (as special cases of $\\Psi$PO) and to identify their potential\npitfalls. We then consider another special case for $\\Psi$PO by setting $\\Psi$\nsimply to Identity, for which we can derive an efficient optimisation\nprocedure, prove performance guarantees and demonstrate its empirical\nsuperiority to DPO on some illustrative examples.",
            "author": [
                "Mohammad Gheshlaghi Azar",
                "Mark Rowland",
                "Bilal Piot",
                "Daniel Guo",
                "Daniele Calandriello",
                "Michal Valko",
                "R\u00e9mi Munos"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12036v2",
                "http://arxiv.org/pdf/2310.12036v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12033v1",
            "title": "Conformal Drug Property Prediction with Density Estimation under\n  Covariate Shift",
            "updated": "2023-10-18T15:17:10Z",
            "published": "2023-10-18T15:17:10Z",
            "summary": "In drug discovery, it is vital to confirm the predictions of pharmaceutical\nproperties from computational models using costly wet-lab experiments. Hence,\nobtaining reliable uncertainty estimates is crucial for prioritizing drug\nmolecules for subsequent experimental validation. Conformal Prediction (CP) is\na promising tool for creating such prediction sets for molecular properties\nwith a coverage guarantee. However, the exchangeability assumption of CP is\noften challenged with covariate shift in drug discovery tasks: Most datasets\ncontain limited labeled data, which may not be representative of the vast\nchemical space from which molecules are drawn. To address this limitation, we\npropose a method called CoDrug that employs an energy-based model leveraging\nboth training data and unlabelled data, and Kernel Density Estimation (KDE) to\nassess the densities of a molecule set. The estimated densities are then used\nto weigh the molecule samples while building prediction sets and rectifying for\ndistribution shift. In extensive experiments involving realistic distribution\ndrifts in various small-molecule drug discovery tasks, we demonstrate the\nability of CoDrug to provide valid prediction sets and its utility in\naddressing the distribution shift arising from de novo drug design models. On\naverage, using CoDrug can reduce the coverage gap by over 35% when compared to\nconformal prediction sets not adjusted for covariate shift.",
            "author": [
                "Siddhartha Laghuvarapu",
                "Zhen Lin",
                "Jimeng Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12033v1",
                "http://arxiv.org/pdf/2310.12033v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12032v1",
            "title": "Exact and efficient solutions of the LMC Multitask Gaussian Process\n  model",
            "updated": "2023-10-18T15:16:24Z",
            "published": "2023-10-18T15:16:24Z",
            "summary": "The Linear Model of Co-regionalization (LMC) is a very general model of\nmultitask gaussian process for regression or classification. While its\nexpressivity and conceptual simplicity are appealing, naive implementations\nhave cubic complexity in the number of datapoints and number of tasks, making\napproximations mandatory for most applications. However, recent work has shown\nthat under some conditions the latent processes of the model can be decoupled,\nleading to a complexity that is only linear in the number of said processes. We\nhere extend these results, showing from the most general assumptions that the\nonly condition necessary to an efficient exact computation of the LMC is a mild\nhypothesis on the noise model. We introduce a full parametrization of the\nresulting \\emph{projected LMC} model, and an expression of the marginal\nlikelihood enabling efficient optimization. We perform a parametric study on\nsynthetic data to show the excellent performance of our approach, compared to\nan unrestricted exact LMC and approximations of the latter. Overall, the\nprojected LMC appears as a credible and simpler alternative to state-of-the art\nmodels, which greatly facilitates some computations such as leave-one-out\ncross-validation and fantasization.",
            "author": [
                "Olivier Truffinet",
                "Karim Ammar",
                "Jean-Philippe Argaud",
                "Bertrand Bouriquet"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12032v1",
                "http://arxiv.org/pdf/2310.12032v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML",
                "I.2.6"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12031v1",
            "title": "SegmATRon: Embodied Adaptive Semantic Segmentation for Indoor\n  Environment",
            "updated": "2023-10-18T15:15:13Z",
            "published": "2023-10-18T15:15:13Z",
            "summary": "This paper presents an adaptive transformer model named SegmATRon for\nembodied image semantic segmentation. Its distinctive feature is the adaptation\nof model weights during inference on several images using a hybrid\nmulticomponent loss function. We studied this model on datasets collected in\nthe photorealistic Habitat and the synthetic AI2-THOR Simulators. We showed\nthat obtaining additional images using the agent's actions in an indoor\nenvironment can improve the quality of semantic segmentation. The code of the\nproposed approach and datasets are publicly available at\nhttps://github.com/wingrune/SegmATRon.",
            "author": [
                "Tatiana Zemskova",
                "Margarita Kichik",
                "Dmitry Yudin",
                "Aleksei Staroverov",
                "Aleksandr Panov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12031v1",
                "http://arxiv.org/pdf/2310.12031v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12026v1",
            "title": "Nonparametric Discrete Choice Experiments with Machine Learning Guided\n  Adaptive Design",
            "updated": "2023-10-18T15:01:53Z",
            "published": "2023-10-18T15:01:53Z",
            "summary": "Designing products to meet consumers' preferences is essential for a\nbusiness's success. We propose the Gradient-based Survey (GBS), a discrete\nchoice experiment for multiattribute product design. The experiment elicits\nconsumer preferences through a sequence of paired comparisons for partial\nprofiles. GBS adaptively constructs paired comparison questions based on the\nrespondents' previous choices. Unlike the traditional random utility\nmaximization paradigm, GBS is robust to model misspecification by not requiring\na parametric utility model. Cross-pollinating the machine learning and\nexperiment design, GBS is scalable to products with hundreds of attributes and\ncan design personalized products for heterogeneous consumers. We demonstrate\nthe advantage of GBS in accuracy and sample efficiency compared to the existing\nparametric and nonparametric methods in simulations.",
            "author": [
                "Mingzhang Yin",
                "Ruijiang Gao",
                "Weiran Lin",
                "Steven M. Shugan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12026v1",
                "http://arxiv.org/pdf/2310.12026v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12019v1",
            "title": "DesignQuizzer: A Community-Powered Conversational Agent for Learning\n  Visual Design",
            "updated": "2023-10-18T14:52:44Z",
            "published": "2023-10-18T14:52:44Z",
            "summary": "Online design communities, where members exchange free-form views on others'\ndesigns, offer a space for beginners to learn visual design. However, the\ncontent of these communities is often unorganized for learners, containing many\nredundancies and irrelevant comments. In this paper, we propose a computational\napproach for leveraging online design communities to run a conversational agent\nthat assists informal learning of visual elements (e.g., color and space). Our\nmethod extracts critiques, suggestions, and rationales on visual elements from\ncomments. We present DesignQuizzer, which asks questions about visual design in\nUI examples and provides structured comment summaries. Two user studies\ndemonstrate the engagement and usefulness of DesignQuizzer compared with the\nbaseline (reading reddit.com/r/UI_design). We also showcase how effectively\nnovices can apply what they learn with DesignQuizzer in a design critique task\nand a visual design task. We discuss how to use our approach with other\ncommunities and offer design considerations for community-powered learning\nsupport tools.",
            "author": [
                "Zhenhui Peng",
                "Qiaoyi Chen",
                "Zhiyu Shen",
                "Xiaojuan Ma",
                "Antti Oulasvirta"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12019v1",
                "http://arxiv.org/pdf/2310.12019v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12010v1",
            "title": "A Note on Improving Variational Estimation for Multidimensional Item\n  Response Theory",
            "updated": "2023-10-18T14:41:35Z",
            "published": "2023-10-18T14:41:35Z",
            "summary": "Survey instruments and assessments are frequently used in many domains of\nsocial science. When the constructs that these assessments try to measure\nbecome multifaceted, multidimensional item response theory (MIRT) provides a\nunified framework and convenient statistical tool for item analysis,\ncalibration, and scoring. However, the computational challenge of estimating\nMIRT models prohibits its wide use because many of the extant methods can\nhardly provide results in a realistic time frame when the number of dimensions,\nsample size, and test length are large. Instead, variational estimation\nmethods, such as Gaussian Variational Expectation Maximization (GVEM)\nalgorithm, have been recently proposed to solve the estimation challenge by\nproviding a fast and accurate solution. However, results have shown that\nvariational estimation methods may produce some bias on discrimination\nparameters during confirmatory model estimation, and this note proposes an\nimportance weighted version of GVEM (i.e., IW-GVEM) to correct for such bias\nunder MIRT models. We also use the adaptive moment estimation method to update\nthe learning rate for gradient descent automatically. Our simulations show that\nIW-GVEM can effectively correct bias with modest increase of computation time,\ncompared with GVEM. The proposed method may also shed light on improving the\nvariational estimation for other psychometrics models.",
            "author": [
                "Chenchen Ma",
                "Jing Ouyang",
                "Chun Wang",
                "Gongjun Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12010v1",
                "http://arxiv.org/pdf/2310.12010v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12008v1",
            "title": "Multi-view Contrastive Learning for Entity Typing over Knowledge Graphs",
            "updated": "2023-10-18T14:41:09Z",
            "published": "2023-10-18T14:41:09Z",
            "summary": "Knowledge graph entity typing (KGET) aims at inferring plausible types of\nentities in knowledge graphs. Existing approaches to KGET focus on how to\nbetter encode the knowledge provided by the neighbors and types of an entity\ninto its representation. However, they ignore the semantic knowledge provided\nby the way in which types can be clustered together. In this paper, we propose\na novel method called Multi-view Contrastive Learning for knowledge graph\nEntity Typing (MCLET), which effectively encodes the coarse-grained knowledge\nprovided by clusters into entity and type embeddings. MCLET is composed of\nthree modules: i) Multi-view Generation and Encoder module, which encodes\nstructured information from entity-type, entity-cluster and cluster-type views;\nii) Cross-view Contrastive Learning module, which encourages different views to\ncollaboratively improve view-specific representations of entities and types;\niii) Entity Typing Prediction module, which integrates multi-head attention and\na Mixture-of-Experts strategy to infer missing entity types. Extensive\nexperiments show the strong performance of MCLET compared to the\nstate-of-the-art",
            "author": [
                "Zhiwei Hu",
                "V\u00edctor Guti\u00e9rrez-Basulto",
                "Zhiliang Xiang",
                "Ru Li",
                "Jeff Z. Pan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12008v1",
                "http://arxiv.org/pdf/2310.12008v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12001v1",
            "title": "Bayesian Flow Networks in Continual Learning",
            "updated": "2023-10-18T14:32:20Z",
            "published": "2023-10-18T14:32:20Z",
            "summary": "Bayesian Flow Networks (BFNs) has been recently proposed as one of the most\npromising direction to universal generative modelling, having ability to learn\nany of the data type. Their power comes from the expressiveness of neural\nnetworks and Bayesian inference which make them suitable in the context of\ncontinual learning. We delve into the mechanics behind BFNs and conduct the\nexperiments to empirically verify the generative capabilities on non-stationary\ndata.",
            "author": [
                "Mateusz Pyla",
                "Kamil Deja",
                "Bart\u0142omiej Twardowski",
                "Tomasz Trzci\u0144ski"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12001v1",
                "http://arxiv.org/pdf/2310.12001v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12000v1",
            "title": "Iterative Methods for Vecchia-Laplace Approximations for Latent Gaussian\n  Process Models",
            "updated": "2023-10-18T14:31:16Z",
            "published": "2023-10-18T14:31:16Z",
            "summary": "Latent Gaussian process (GP) models are flexible probabilistic non-parametric\nfunction models. Vecchia approximations are accurate approximations for GPs to\novercome computational bottlenecks for large data, and the Laplace\napproximation is a fast method with asymptotic convergence guarantees to\napproximate marginal likelihoods and posterior predictive distributions for\nnon-Gaussian likelihoods. Unfortunately, the computational complexity of\ncombined Vecchia-Laplace approximations grows faster than linearly in the\nsample size when used in combination with direct solver methods such as the\nCholesky decomposition. Computations with Vecchia-Laplace approximations thus\nbecome prohibitively slow precisely when the approximations are usually the\nmost accurate, i.e., on large data sets. In this article, we present several\niterative methods for inference with Vecchia-Laplace approximations which make\ncomputations considerably faster compared to Cholesky-based calculations. We\nanalyze our proposed methods theoretically and in experiments with simulated\nand real-world data. In particular, we obtain a speed-up of an order of\nmagnitude compared to Cholesky-based inference and a threefold increase in\nprediction accuracy in terms of the continuous ranked probability score\ncompared to a state-of-the-art method on a large satellite data set. All\nmethods are implemented in a free C++ software library with high-level Python\nand R packages.",
            "author": [
                "Pascal K\u00fcndig",
                "Fabio Sigrist"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12000v1",
                "http://arxiv.org/pdf/2310.12000v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11998v2",
            "title": "One-Bit Byzantine-Tolerant Distributed Learning via Over-the-Air\n  Computation",
            "updated": "2023-10-19T01:54:59Z",
            "published": "2023-10-18T14:29:44Z",
            "summary": "Distributed learning has become a promising computational parallelism\nparadigm that enables a wide scope of intelligent applications from the\nInternet of Things (IoT) to autonomous driving and the healthcare industry.\nThis paper studies distributed learning in wireless data center networks, which\ncontain a central edge server and multiple edge workers to collaboratively\ntrain a shared global model and benefit from parallel computing. However, the\ndistributed nature causes the vulnerability of the learning process to faults\nand adversarial attacks from Byzantine edge workers, as well as the severe\ncommunication and computation overhead induced by the periodical information\nexchange process. To achieve fast and reliable model aggregation in the\npresence of Byzantine attacks, we develop a signed stochastic gradient descent\n(SignSGD)-based Hierarchical Vote framework via over-the-air computation\n(AirComp), where one voting process is performed locally at the wireless edge\nby taking advantage of Bernoulli coding while the other is operated\nover-the-air at the central edge server by utilizing the waveform superposition\nproperty of the multiple-access channels. We comprehensively analyze the\nproposed framework on the impacts including Byzantine attacks and the wireless\nenvironment (channel fading and receiver noise), followed by characterizing the\nconvergence behavior under non-convex settings. Simulation results validate our\ntheoretical achievements and demonstrate the robustness of our proposed\nframework in the presence of Byzantine attacks and receiver noise.",
            "author": [
                "Yuhan Yang",
                "Youlong Wu",
                "Yuning Jiang",
                "Yuanming Shi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11998v2",
                "http://arxiv.org/pdf/2310.11998v2"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11991v1",
            "title": "Removing Spurious Concepts from Neural Network Representations via Joint\n  Subspace Estimation",
            "updated": "2023-10-18T14:22:36Z",
            "published": "2023-10-18T14:22:36Z",
            "summary": "Out-of-distribution generalization in neural networks is often hampered by\nspurious correlations. A common strategy is to mitigate this by removing\nspurious concepts from the neural network representation of the data. Existing\nconcept-removal methods tend to be overzealous by inadvertently eliminating\nfeatures associated with the main task of the model, thereby harming model\nperformance. We propose an iterative algorithm that separates spurious from\nmain-task concepts by jointly identifying two low-dimensional orthogonal\nsubspaces in the neural network representation. We evaluate the algorithm on\nbenchmark datasets for computer vision (Waterbirds, CelebA) and natural\nlanguage processing (MultiNLI), and show that it outperforms existing concept\nremoval methods",
            "author": [
                "Floris Holstege",
                "Bram Wouters",
                "Noud van Giersbergen",
                "Cees Diks"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11991v1",
                "http://arxiv.org/pdf/2310.11991v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11989v1",
            "title": "Image Clustering with External Guidance",
            "updated": "2023-10-18T14:20:55Z",
            "published": "2023-10-18T14:20:55Z",
            "summary": "The core of clustering is incorporating prior knowledge to construct\nsupervision signals. From classic k-means based on data compactness to recent\ncontrastive clustering guided by self-supervision, the evolution of clustering\nmethods intrinsically corresponds to the progression of supervision signals. At\npresent, substantial efforts have been devoted to mining internal supervision\nsignals from data. Nevertheless, the abundant external knowledge such as\nsemantic descriptions, which naturally conduces to clustering, is regrettably\noverlooked. In this work, we propose leveraging external knowledge as a new\nsupervision signal to guide clustering, even though it seems irrelevant to the\ngiven data. To implement and validate our idea, we design an externally guided\nclustering method (Text-Aided Clustering, TAC), which leverages the textual\nsemantics of WordNet to facilitate image clustering. Specifically, TAC first\nselects and retrieves WordNet nouns that best distinguish images to enhance the\nfeature discriminability. Then, to improve image clustering performance, TAC\ncollaborates text and image modalities by mutually distilling cross-modal\nneighborhood information. Experiments demonstrate that TAC achieves\nstate-of-the-art performance on five widely used and three more challenging\nimage clustering benchmarks, including the full ImageNet-1K dataset.",
            "author": [
                "Yunfan Li",
                "Peng Hu",
                "Dezhong Peng",
                "Jiancheng Lv",
                "Jianping Fan",
                "Xi Peng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11989v1",
                "http://arxiv.org/pdf/2310.11989v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11985v1",
            "title": "A Finite-Horizon Approach to Active Level Set Estimation",
            "updated": "2023-10-18T14:11:41Z",
            "published": "2023-10-18T14:11:41Z",
            "summary": "We consider the problem of active learning in the context of spatial sampling\nfor level set estimation (LSE), where the goal is to localize all regions where\na function of interest lies above/below a given threshold as quickly as\npossible. We present a finite-horizon search procedure to perform LSE in one\ndimension while optimally balancing both the final estimation error and the\ndistance traveled for a fixed number of samples. A tuning parameter is used to\ntrade off between the estimation accuracy and distance traveled. We show that\nthe resulting optimization problem can be solved in closed form and that the\nresulting policy generalizes existing approaches to this problem. We then show\nhow this approach can be used to perform level set estimation in higher\ndimensions under the popular Gaussian process model. Empirical results on\nsynthetic data indicate that as the cost of travel increases, our method's\nability to treat distance nonmyopically allows it to significantly improve on\nthe state of the art. On real air quality data, our approach achieves roughly\none fifth the estimation error at less than half the cost of competing\nalgorithms.",
            "author": [
                "Phillip Kearns",
                "Bruno Jedynak",
                "John Lipor"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11985v1",
                "http://arxiv.org/pdf/2310.11985v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.RO",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11984v1",
            "title": "From Interpolation to Extrapolation: Complete Length Generalization for\n  Arithmetic Transformers",
            "updated": "2023-10-18T14:10:47Z",
            "published": "2023-10-18T14:10:47Z",
            "summary": "Since its introduction, the transformer model has demonstrated outstanding\nperformance across various tasks. However, there are still unresolved issues\nregarding length generalization, particularly in algorithmic tasks. In this\npaper, we investigate the inherent capabilities of transformer models in\nlearning arithmetic algorithms, such as addition and multiplication. Through\nexperiments and attention analysis, we identify a number of crucial factors for\nachieving optimal length generalization. We show that transformer models are\nable to generalize to long lengths with the help of targeted attention biasing.\nWe then introduce Attention Bias Calibration (ABC), a calibration stage that\nenables the model to automatically learn the proper attention biases, which we\nlink to mechanisms in relative position encoding. We demonstrate that using\nABC, the transformer model can achieve unprecedented perfect length\ngeneralization on certain arithmetic tasks.",
            "author": [
                "Shaoxiong Duan",
                "Yining Shi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11984v1",
                "http://arxiv.org/pdf/2310.11984v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11978v2",
            "title": "Can bin-wise scaling improve consistency and adaptivity of prediction\n  uncertainty for machine learning regression ?",
            "updated": "2023-10-24T13:23:58Z",
            "published": "2023-10-18T14:05:04Z",
            "summary": "Binwise Variance Scaling (BVS) has recently been proposed as a post hoc\nrecalibration method for prediction uncertainties of machine learning\nregression problems that is able of more efficient corrections than uniform\nvariance (or temperature) scaling. The original version of BVS uses\nuncertainty-based binning, which is aimed to improve calibration conditionally\non uncertainty, i.e. consistency. I explore here several adaptations of BVS, in\nparticular with alternative loss functions and a binning scheme based on an\ninput-feature (X) in order to improve adaptivity, i.e. calibration conditional\non X. The performances of BVS and its proposed variants are tested on a\nbenchmark dataset for the prediction of atomization energies and compared to\nthe results of isotonic regression.",
            "author": [
                "Pascal Pernot"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11978v2",
                "http://arxiv.org/pdf/2310.11978v2"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "physics.chem-ph",
                "physics.data-an"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11971v2",
            "title": "Improving Generalization of Alignment with Human Preferences through\n  Group Invariant Learning",
            "updated": "2023-10-19T03:14:23Z",
            "published": "2023-10-18T13:54:15Z",
            "summary": "The success of AI assistants based on language models (LLMs) hinges crucially\non Reinforcement Learning from Human Feedback (RLHF), which enables the\ngeneration of responses more aligned with human preferences. As universal AI\nassistants, there's a growing expectation for them to perform consistently\nacross various domains. However, previous work shows that Reinforcement\nLearning (RL) often exploits shortcuts to attain high rewards and overlooks\nchallenging samples. This focus on quick reward gains undermines both the\nstability in training and the model's ability to generalize to new, unseen\ndata. In this work, we propose a novel approach that can learn a consistent\npolicy via RL across various data groups or domains. Given the challenges\nassociated with acquiring group annotations, our method automatically\nclassifies data into different groups, deliberately maximizing performance\nvariance. Then, we optimize the policy to perform well on challenging groups.\nLastly, leveraging the established groups, our approach adaptively adjusts the\nexploration space, allocating more learning capacity to more challenging data\nand preventing the model from over-optimizing on simpler data. Experimental\nresults indicate that our approach significantly enhances training stability\nand model generalization.",
            "author": [
                "Rui Zheng",
                "Wei Shen",
                "Yuan Hua",
                "Wenbin Lai",
                "Shihan Dou",
                "Yuhao Zhou",
                "Zhiheng Xi",
                "Xiao Wang",
                "Haoran Huang",
                "Tao Gui",
                "Qi Zhang",
                "Xuanjing Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11971v2",
                "http://arxiv.org/pdf/2310.11971v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11970v1",
            "title": "Quantifying Privacy Risks of Prompts in Visual Prompt Learning",
            "updated": "2023-10-18T13:51:27Z",
            "published": "2023-10-18T13:51:27Z",
            "summary": "Large-scale pre-trained models are increasingly adapted to downstream tasks\nthrough a new paradigm called prompt learning. In contrast to fine-tuning,\nprompt learning does not update the pre-trained model's parameters. Instead, it\nonly learns an input perturbation, namely prompt, to be added to the downstream\ntask data for predictions. Given the fast development of prompt learning, a\nwell-generalized prompt inevitably becomes a valuable asset as significant\neffort and proprietary data are used to create it. This naturally raises the\nquestion of whether a prompt may leak the proprietary information of its\ntraining data. In this paper, we perform the first comprehensive privacy\nassessment of prompts learned by visual prompt learning through the lens of\nproperty inference and membership inference attacks. Our empirical evaluation\nshows that the prompts are vulnerable to both attacks. We also demonstrate that\nthe adversary can mount a successful property inference attack with limited\ncost. Moreover, we show that membership inference attacks against prompts can\nbe successful with relaxed adversarial assumptions. We further make some\ninitial investigations on the defenses and observe that our method can mitigate\nthe membership inference attacks with a decent utility-defense trade-off but\nfails to defend against property inference attacks. We hope our results can\nshed light on the privacy risks of the popular prompt learning paradigm. To\nfacilitate the research in this direction, we will share our code and models\nwith the community.",
            "author": [
                "Yixin Wu",
                "Rui Wen",
                "Michael Backes",
                "Pascal Berrang",
                "Mathias Humbert",
                "Yun Shen",
                "Yang Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11970v1",
                "http://arxiv.org/pdf/2310.11970v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11967v1",
            "title": "Take the aTrain. Introducing an Interface for the Accessible\n  Transcription of Interviews",
            "updated": "2023-10-18T13:45:47Z",
            "published": "2023-10-18T13:45:47Z",
            "summary": "aTrain is an open-source and offline tool for transcribing audio data in\nmultiple languages with CPU and NVIDIA GPU support. It is specifically designed\nfor researchers using qualitative data generated from various forms of speech\ninteractions with research participants. aTrain requires no programming skills,\nruns on most computers, does not require an internet connection, and was\nverified not to upload data to any server. aTrain combines OpenAI's Whisper\nmodel with speaker recognition to provide output that integrates with the\npopular qualitative data analysis software tools MAXQDA and ATLAS.ti. It has an\neasy-to-use graphical interface and is provided as a Windows-App through the\nMicrosoft Store allowing for simple installation by researchers. The source\ncode is freely available on GitHub. Having developed aTrain with a focus on\nspeed on local computers, we show that the transcription time on current mobile\nCPUs is around 2 to 3 times the duration of the audio file using the\nhighest-accuracy transcription models. If an entry-level graphics card is\navailable, the transcription speed increases to 20% of the audio duration.",
            "author": [
                "Armin Haberl",
                "J\u00fcrgen Flei\u00df",
                "Dominik Kowald",
                "Stefan Thalmann"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11967v1",
                "http://arxiv.org/pdf/2310.11967v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11966v1",
            "title": "Flexible Payload Configuration for Satellites using Machine Learning",
            "updated": "2023-10-18T13:45:17Z",
            "published": "2023-10-18T13:45:17Z",
            "summary": "Satellite communications, essential for modern connectivity, extend access to\nmaritime, aeronautical, and remote areas where terrestrial networks are\nunfeasible. Current GEO systems distribute power and bandwidth uniformly across\nbeams using multi-beam footprints with fractional frequency reuse. However,\nrecent research reveals the limitations of this approach in heterogeneous\ntraffic scenarios, leading to inefficiencies. To address this, this paper\npresents a machine learning (ML)-based approach to Radio Resource Management\n(RRM).\n  We treat the RRM task as a regression ML problem, integrating RRM objectives\nand constraints into the loss function that the ML algorithm aims at\nminimizing. Moreover, we introduce a context-aware ML metric that evaluates the\nML model's performance but also considers the impact of its resource allocation\ndecisions on the overall performance of the communication system.",
            "author": [
                "Marcele O. K. Mendonca",
                "Flor G. Ortiz-Gomez",
                "Jorge Querol",
                "Eva Lagunas",
                "Juan A. V\u00e1squez Peralvo",
                "Victor Monzon Baeza",
                "Symeon Chatzinotas",
                "Bjorn Ottersten"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11966v1",
                "http://arxiv.org/pdf/2310.11966v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11962v1",
            "title": "Machine Learning for Staggered Difference-in-Differences and Dynamic\n  Treatment Effect Heterogeneity",
            "updated": "2023-10-18T13:41:41Z",
            "published": "2023-10-18T13:41:41Z",
            "summary": "We combine two recently proposed nonparametric difference-in-differences\nmethods, extending them to enable the examination of treatment effect\nheterogeneity in the staggered adoption setting using machine learning. The\nproposed method, machine learning difference-in-differences (MLDID), allows for\nestimation of time-varying conditional average treatment effects on the\ntreated, which can be used to conduct detailed inference on drivers of\ntreatment effect heterogeneity. We perform simulations to evaluate the\nperformance of MLDID and find that it accurately identifies the true predictors\nof treatment effect heterogeneity. We then use MLDID to evaluate the\nheterogeneous impacts of Brazil's Family Health Program on infant mortality,\nand find those in poverty and urban locations experienced the impact of the\npolicy more quickly than other subgroups.",
            "author": [
                "Julia Hatamyar",
                "Noemi Kreif",
                "Rudi Rocha",
                "Martin Huber"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11962v1",
                "http://arxiv.org/pdf/2310.11962v1"
            ],
            "primary_category": "econ.EM",
            "category": [
                "econ.EM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11960v2",
            "title": "Fast Multipole Attention: A Divide-and-Conquer Attention Mechanism for\n  Long Sequences",
            "updated": "2023-10-21T01:56:32Z",
            "published": "2023-10-18T13:40:41Z",
            "summary": "Transformer-based models have achieved state-of-the-art performance in many\nareas. However, the quadratic complexity of self-attention with respect to the\ninput length hinders the applicability of Transformer-based models to long\nsequences. To address this, we present Fast Multipole Attention, a new\nattention mechanism that uses a divide-and-conquer strategy to reduce the time\nand memory complexity of attention for sequences of length $n$ from\n$\\mathcal{O}(n^2)$ to $\\mathcal{O}(n \\log n)$ or $O(n)$, while retaining a\nglobal receptive field. The hierarchical approach groups queries, keys, and\nvalues into $\\mathcal{O}( \\log n)$ levels of resolution, where groups at\ngreater distances are increasingly larger in size and the weights to compute\ngroup quantities are learned. As such, the interaction between tokens far from\neach other is considered in lower resolution in an efficient hierarchical\nmanner. The overall complexity of Fast Multipole Attention is $\\mathcal{O}(n)$\nor $\\mathcal{O}(n \\log n)$, depending on whether the queries are down-sampled\nor not. This multi-level divide-and-conquer strategy is inspired by fast\nsummation methods from $n$-body physics and the Fast Multipole Method. We\nperform evaluation on autoregressive and bidirectional language modeling tasks\nand compare our Fast Multipole Attention model with other efficient attention\nvariants on medium-size datasets. We find empirically that the Fast Multipole\nTransformer performs much better than other efficient transformers in terms of\nmemory size and accuracy. The Fast Multipole Attention mechanism has the\npotential to empower large language models with much greater sequence lengths,\ntaking the full context into account in an efficient, naturally hierarchical\nmanner during training and when generating long sequences.",
            "author": [
                "Yanming Kang",
                "Giang Tran",
                "Hans De Sterck"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11960v2",
                "http://arxiv.org/pdf/2310.11960v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11959v1",
            "title": "A Multi-Scale Decomposition MLP-Mixer for Time Series Analysis",
            "updated": "2023-10-18T13:39:07Z",
            "published": "2023-10-18T13:39:07Z",
            "summary": "Time series data, often characterized by unique composition and complex\nmulti-scale temporal variations, requires special consideration of\ndecomposition and multi-scale modeling in its analysis. Existing deep learning\nmethods on this best fit to only univariate time series, and have not\nsufficiently accounted for sub-series level modeling and decomposition\ncompleteness. To address this, we propose MSD-Mixer, a Multi-Scale\nDecomposition MLP-Mixer which learns to explicitly decompose the input time\nseries into different components, and represents the components in different\nlayers. To handle multi-scale temporal patterns and inter-channel dependencies,\nwe propose a novel temporal patching approach to model the time series as\nmulti-scale sub-series, i.e., patches, and employ MLPs to mix intra- and\ninter-patch variations and channel-wise correlations. In addition, we propose a\nloss function to constrain both the magnitude and autocorrelation of the\ndecomposition residual for decomposition completeness. Through extensive\nexperiments on various real-world datasets for five common time series analysis\ntasks (long- and short-term forecasting, imputation, anomaly detection, and\nclassification), we demonstrate that MSD-Mixer consistently achieves\nsignificantly better performance in comparison with other state-of-the-art\ntask-general and task-specific approaches.",
            "author": [
                "Shuhan Zhong",
                "Sizhe Song",
                "Guanyao Li",
                "Weipeng Zhuo",
                "Yang Liu",
                "S. -H. Gary Chan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11959v1",
                "http://arxiv.org/pdf/2310.11959v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11958v1",
            "title": "Emptying the Ocean with a Spoon: Should We Edit Models?",
            "updated": "2023-10-18T13:38:03Z",
            "published": "2023-10-18T13:38:03Z",
            "summary": "We call into question the recently popularized method of direct model editing\nas a means of correcting factual errors in LLM generations. We contrast model\nediting with three similar but distinct approaches that pursue better defined\nobjectives: (1) retrieval-based architectures, which decouple factual memory\nfrom inference and linguistic capabilities embodied in LLMs; (2) concept\nerasure methods, which aim at preventing systemic bias in generated text; and\n(3) attribution methods, which aim at grounding generations into identified\ntextual sources. We argue that direct model editing cannot be trusted as a\nsystematic remedy for the disadvantages inherent to LLMs, and while it has\nproven potential in improving model explainability, it opens risks by\nreinforcing the notion that models can be trusted for factuality. We call for\ncautious promotion and application of model editing as part of the LLM\ndeployment process, and for responsibly limiting the use cases of LLMs to those\nnot relying on editing as a critical component.",
            "author": [
                "Yuval Pinter",
                "Michael Elhadad"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11958v1",
                "http://arxiv.org/pdf/2310.11958v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11952v1",
            "title": "Recasting Continual Learning as Sequence Modeling",
            "updated": "2023-10-18T13:26:52Z",
            "published": "2023-10-18T13:26:52Z",
            "summary": "In this work, we aim to establish a strong connection between two significant\nbodies of machine learning research: continual learning and sequence modeling.\nThat is, we propose to formulate continual learning as a sequence modeling\nproblem, allowing advanced sequence models to be utilized for continual\nlearning. Under this formulation, the continual learning process becomes the\nforward pass of a sequence model. By adopting the meta-continual learning (MCL)\nframework, we can train the sequence model at the meta-level, on multiple\ncontinual learning episodes. As a specific example of our new formulation, we\ndemonstrate the application of Transformers and their efficient variants as MCL\nmethods. Our experiments on seven benchmarks, covering both classification and\nregression, show that sequence models can be an attractive solution for general\nMCL.",
            "author": [
                "Soochan Lee",
                "Jaehyeon Son",
                "Gunhee Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11952v1",
                "http://arxiv.org/pdf/2310.11952v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11950v1",
            "title": "Too Good To Be True: performance overestimation in (re)current practices\n  for Human Activity Recognition",
            "updated": "2023-10-18T13:24:05Z",
            "published": "2023-10-18T13:24:05Z",
            "summary": "Today, there are standard and well established procedures within the Human\nActivity Recognition (HAR) pipeline. However, some of these conventional\napproaches lead to accuracy overestimation. In particular, sliding windows for\ndata segmentation followed by standard random k-fold cross validation, produce\nbiased results. An analysis of previous literature and present-day studies,\nsurprisingly, shows that these are common approaches in state-of-the-art\nstudies on HAR. It is important to raise awareness in the scientific community\nabout this problem, whose negative effects are being overlooked. Otherwise,\npublications of biased results lead to papers that report lower accuracies,\nwith correct unbiased methods, harder to publish. Several experiments with\ndifferent types of datasets and different types of classification models allow\nus to exhibit the problem and show it persists independently of the method or\ndataset.",
            "author": [
                "Andr\u00e9s Tello",
                "Victoria Degeler",
                "Alexander Lazovik"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11950v1",
                "http://arxiv.org/pdf/2310.11950v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11940v1",
            "title": "Interpretable Spectral Variational AutoEncoder (ISVAE) for time series\n  clustering",
            "updated": "2023-10-18T13:06:05Z",
            "published": "2023-10-18T13:06:05Z",
            "summary": "The best encoding is the one that is interpretable in nature. In this work,\nwe introduce a novel model that incorporates an interpretable bottleneck-termed\nthe Filter Bank (FB)-at the outset of a Variational Autoencoder (VAE). This\narrangement compels the VAE to attend on the most informative segments of the\ninput signal, fostering the learning of a novel encoding ${f_0}$ which boasts\nenhanced interpretability and clusterability over traditional latent spaces. By\ndeliberately constraining the VAE with this FB, we intentionally constrict its\ncapacity to access broad input domain information, promoting the development of\nan encoding that is discernible, separable, and of reduced dimensionality. The\nevolutionary learning trajectory of ${f_0}$ further manifests as a dynamic\nhierarchical tree, offering profound insights into cluster similarities.\nAdditionally, for handling intricate data configurations, we propose a tailored\ndecoder structure that is symmetrically aligned with FB's architecture.\nEmpirical evaluations highlight the superior efficacy of ISVAE, which compares\nfavorably to state-of-the-art results in clustering metrics across real-world\ndatasets.",
            "author": [
                "\u00d3scar Jim\u00e9nez Rama",
                "Fernando Moreno-Pino",
                "David Ram\u00edrez",
                "Pablo M. Olmos"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11940v1",
                "http://arxiv.org/pdf/2310.11940v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11924v1",
            "title": "Deep Learning Based Detection on RIS Assisted RSM and RSSK Techniques",
            "updated": "2023-10-18T12:39:44Z",
            "published": "2023-10-18T12:39:44Z",
            "summary": "The reconfigurable intelligent surface (RIS) is considered a crucial\ntechnology for the future of wireless communication. Recently, there has been\nsignificant interest in combining RIS with spatial modulation (SM) or space\nshift keying (SSK) to achieve a balance between spectral and energy efficiency.\nIn this paper, we have investigated the use of deep learning techniques for\ndetection in RIS-aided received SM (RSM)/received-SSK (RSSK) systems over\nWeibull fading channels, specifically by extending the RIS-aided SM/SSK system\nto a specific case of the conventional SM system. By employing the concept of\nneural networks, the study focuses on model-driven deep learning detection\nnamely block deep neural networks (B-DNN) for RIS-aided SM systems and compares\nits performance against maximum likelihood (ML) and greedy detectors. Finally,\nit has been demonstrated by Monte Carlo simulation that while B-DNN achieved a\nbit error rate (BER) performance close to that of ML, it gave better results\nthan the Greedy detector.",
            "author": [
                "Onur Salan",
                "Ferhat Bayar",
                "Hac\u0131 Ilhan",
                "Erdogan Aydin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11924v1",
                "http://arxiv.org/pdf/2310.11924v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11921v1",
            "title": "BUT CHiME-7 system description",
            "updated": "2023-10-18T12:26:43Z",
            "published": "2023-10-18T12:26:43Z",
            "summary": "This paper describes the joint effort of Brno University of Technology (BUT),\nAGH University of Krakow and University of Buenos Aires on the development of\nAutomatic Speech Recognition systems for the CHiME-7 Challenge. We train and\nevaluate various end-to-end models with several toolkits. We heavily relied on\nGuided Source Separation (GSS) to convert multi-channel audio to single\nchannel. The ASR is leveraging speech representations from models pre-trained\nby self-supervised learning, and we do a fusion of several ASR systems. In\naddition, we modified external data from the LibriSpeech corpus to become a\nclose domain and added it to the training. Our efforts were focused on the\nfar-field acoustic robustness sub-track of Task 1 - Distant Automatic Speech\nRecognition (DASR), our systems use oracle segmentation.",
            "author": [
                "Martin Karafi\u00e1t",
                "Karel Vesel\u00fd",
                "Igor Sz\u00f6ke",
                "Ladislav Mo\u0161ner",
                "Karel Bene\u0161",
                "Marcin Witkowski",
                "Germ\u00e1n Barchi",
                "Leonardo Pepino"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11921v1",
                "http://arxiv.org/pdf/2310.11921v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11917v1",
            "title": "A Benchmark for Semi-Inductive Link Prediction in Knowledge Graphs",
            "updated": "2023-10-18T12:13:13Z",
            "published": "2023-10-18T12:13:13Z",
            "summary": "Semi-inductive link prediction (LP) in knowledge graphs (KG) is the task of\npredicting facts for new, previously unseen entities based on context\ninformation. Although new entities can be integrated by retraining the model\nfrom scratch in principle, such an approach is infeasible for large-scale KGs,\nwhere retraining is expensive and new entities may arise frequently. In this\npaper, we propose and describe a large-scale benchmark to evaluate\nsemi-inductive LP models. The benchmark is based on and extends Wikidata5M: It\nprovides transductive, k-shot, and 0-shot LP tasks, each varying the available\ninformation from (i) only KG structure, to (ii) including textual mentions, and\n(iii) detailed descriptions of the entities. We report on a small study of\nrecent approaches and found that semi-inductive LP performance is far from\ntransductive performance on long-tail entities throughout all experiments. The\nbenchmark provides a test bed for further research into integrating context and\ntextual information in semi-inductive LP models.",
            "author": [
                "Adrian Kochsiek",
                "Rainer Gemulla"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11917v1",
                "http://arxiv.org/pdf/2310.11917v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11914v1",
            "title": "A connection between Tempering and Entropic Mirror Descent",
            "updated": "2023-10-18T12:06:47Z",
            "published": "2023-10-18T12:06:47Z",
            "summary": "This paper explores the connections between tempering (for Sequential Monte\nCarlo; SMC) and entropic mirror descent to sample from a target probability\ndistribution whose unnormalized density is known.\n  We establish that tempering SMC is a numerical approximation of entropic\nmirror descent applied to the Kullback-Leibler (KL) divergence and obtain\nconvergence rates for the tempering iterates.\n  Our result motivates the tempering iterates from an optimization point of\nview, showing that tempering can be used as an alternative to Langevin-based\nalgorithms to minimize the KL divergence.\n  We exploit the connection between tempering and mirror descent iterates to\njustify common practices in SMC and propose improvements to algorithms in\nliterature.",
            "author": [
                "Nicolas Chopin",
                "Francesca R. Crucinio",
                "Anna Korba"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11914v1",
                "http://arxiv.org/pdf/2310.11914v1"
            ],
            "primary_category": "stat.CO",
            "category": [
                "stat.CO",
                "math.OC",
                "math.ST",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11910v1",
            "title": "Multi-modal Medical Neurological Image Fusion using Wavelet Pooled Edge\n  Preserving Autoencoder",
            "updated": "2023-10-18T11:59:35Z",
            "published": "2023-10-18T11:59:35Z",
            "summary": "Medical image fusion integrates the complementary diagnostic information of\nthe source image modalities for improved visualization and analysis of\nunderlying anomalies. Recently, deep learning-based models have excelled the\nconventional fusion methods by executing feature extraction, feature selection,\nand feature fusion tasks, simultaneously. However, most of the existing\nconvolutional neural network (CNN) architectures use conventional pooling or\nstrided convolutional strategies to downsample the feature maps. It causes the\nblurring or loss of important diagnostic information and edge details available\nin the source images and dilutes the efficacy of the feature extraction\nprocess. Therefore, this paper presents an end-to-end unsupervised fusion model\nfor multimodal medical images based on an edge-preserving dense autoencoder\nnetwork. In the proposed model, feature extraction is improved by using wavelet\ndecomposition-based attention pooling of feature maps. This helps in preserving\nthe fine edge detail information present in both the source images and enhances\nthe visual perception of fused images. Further, the proposed model is trained\non a variety of medical image pairs which helps in capturing the intensity\ndistributions of the source images and preserves the diagnostic information\neffectively. Substantial experiments are conducted which demonstrate that the\nproposed method provides improved visual and quantitative results as compared\nto the other state-of-the-art fusion methods.",
            "author": [
                "Manisha Das",
                "Deep Gupta",
                "Petia Radeva",
                "Ashwini M Bakde"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11910v1",
                "http://arxiv.org/pdf/2310.11910v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11897v1",
            "title": "Accelerated Policy Gradient: On the Nesterov Momentum for Reinforcement\n  Learning",
            "updated": "2023-10-18T11:33:22Z",
            "published": "2023-10-18T11:33:22Z",
            "summary": "Policy gradient methods have recently been shown to enjoy global convergence\nat a $\\Theta(1/t)$ rate in the non-regularized tabular softmax setting.\nAccordingly, one important research question is whether this convergence rate\ncan be further improved, with only first-order updates. In this paper, we\nanswer the above question from the perspective of momentum by adapting the\ncelebrated Nesterov's accelerated gradient (NAG) method to reinforcement\nlearning (RL), termed \\textit{Accelerated Policy Gradient} (APG). To\ndemonstrate the potential of APG in achieving faster global convergence, we\nformally show that with the true gradient, APG with softmax policy\nparametrization converges to an optimal policy at a $\\tilde{O}(1/t^2)$ rate. To\nthe best of our knowledge, this is the first characterization of the global\nconvergence rate of NAG in the context of RL. Notably, our analysis relies on\none interesting finding: Regardless of the initialization, APG could end up\nreaching a locally nearly-concave regime, where APG could benefit significantly\nfrom the momentum, within finite iterations. By means of numerical validation,\nwe confirm that APG exhibits $\\tilde{O}(1/t^2)$ rate as well as show that APG\ncould significantly improve the convergence behavior over the standard policy\ngradient.",
            "author": [
                "Yen-Ju Chen",
                "Nai-Chieh Huang",
                "Ping-Chun Hsieh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11897v1",
                "http://arxiv.org/pdf/2310.11897v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11896v1",
            "title": "A New Multimodal Medical Image Fusion based on Laplacian Autoencoder\n  with Channel Attention",
            "updated": "2023-10-18T11:29:53Z",
            "published": "2023-10-18T11:29:53Z",
            "summary": "Medical image fusion combines the complementary information of multimodal\nmedical images to assist medical professionals in the clinical diagnosis of\npatients' disorders and provide guidance during preoperative and\nintra-operative procedures. Deep learning (DL) models have achieved end-to-end\nimage fusion with highly robust and accurate fusion performance. However, most\nDL-based fusion models perform down-sampling on the input images to minimize\nthe number of learnable parameters and computations. During this process,\nsalient features of the source images become irretrievable leading to the loss\nof crucial diagnostic edge details and contrast of various brain tissues. In\nthis paper, we propose a new multimodal medical image fusion model is proposed\nthat is based on integrated Laplacian-Gaussian concatenation with attention\npooling (LGCA). We prove that our model preserves effectively complementary\ninformation and important tissue structures.",
            "author": [
                "Payal Wankhede",
                "Manisha Das",
                "Deep Gupta",
                "Petia Radeva",
                "Ashwini M Bakde"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11896v1",
                "http://arxiv.org/pdf/2310.11896v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11892v1",
            "title": "Differentially Private Distributed Stochastic Optimization with\n  Time-Varying Sample Sizes",
            "updated": "2023-10-18T11:21:58Z",
            "published": "2023-10-18T11:21:58Z",
            "summary": "Differentially private distributed stochastic optimization has become a hot\ntopic due to the urgent need of privacy protection in distributed stochastic\noptimization. In this paper, two-time scale stochastic approximation-type\nalgorithms for differentially private distributed stochastic optimization with\ntime-varying sample sizes are proposed using gradient- and output-perturbation\nmethods. For both gradient- and output-perturbation cases, the convergence of\nthe algorithm and differential privacy with a finite cumulative privacy budget\n$\\varepsilon$ for an infinite number of iterations are simultaneously\nestablished, which is substantially different from the existing works. By a\ntime-varying sample sizes method, the privacy level is enhanced, and\ndifferential privacy with a finite cumulative privacy budget $\\varepsilon$ for\nan infinite number of iterations is established. By properly choosing a\nLyapunov function, the algorithm achieves almost-sure and mean-square\nconvergence even when the added privacy noises have an increasing variance.\nFurthermore, we rigorously provide the mean-square convergence rates of the\nalgorithm and show how the added privacy noise affects the convergence rate of\nthe algorithm. Finally, numerical examples including distributed training on a\nbenchmark machine learning dataset are presented to demonstrate the efficiency\nand advantages of the algorithms.",
            "author": [
                "Jimin Wang",
                "Ji-Feng Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11892v1",
                "http://arxiv.org/pdf/2310.11892v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11891v2",
            "title": "A Hyperparameter Study for Quantum Kernel Methods",
            "updated": "2023-12-06T16:51:09Z",
            "published": "2023-10-18T11:20:59Z",
            "summary": "Quantum kernel methods are a promising method in quantum machine learning\nthanks to the guarantees connected to them. Their accessibility for analytic\nconsiderations also opens up the possibility of prescreening datasets based on\ntheir potential for a quantum advantage. To do so, earlier works developed the\ngeometric difference, which can be understood as a closeness measure between\ntwo kernel-based machine learning approaches, most importantly between a\nquantum kernel and classical kernel. This metric links the quantum and\nclassical model complexities. Therefore, it raises the question of whether the\ngeometric difference, based on its relation to model complexity, can be a\nuseful tool in evaluations other than for the potential for quantum advantage.\nIn this work, we investigate the effects of hyperparameter choice on the model\nperformance and the generalization gap between classical and quantum kernels.\nThe importance of hyperparameter optimization is well known also for classical\nmachine learning. Especially for the quantum Hamiltonian evolution feature map,\nthe scaling of the input data has been shown to be crucial. However, there are\nadditional parameters left to be optimized, like the best number of qubits to\ntrace out before computing a projected quantum kernel. We investigate the\ninfluence of these hyperparameters and compare the classically reliable method\nof cross validation with the method of choosing based on the geometric\ndifference. Based on the thorough investigation of the hyperparameters across\n11 datasets we identified commodities that can be exploited when examining a\nnew dataset. In addition, our findings contribute to better understanding of\nthe applicability of the geometric difference.",
            "author": [
                "Sebastian Egginger",
                "Alona Sakhnenko",
                "Jeanette Miriam Lorenz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11891v2",
                "http://arxiv.org/pdf/2310.11891v2"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11889v1",
            "title": "Building a Graph-based Deep Learning network model from captured traffic\n  traces",
            "updated": "2023-10-18T11:16:32Z",
            "published": "2023-10-18T11:16:32Z",
            "summary": "Currently the state of the art network models are based or depend on Discrete\nEvent Simulation (DES). While DES is highly accurate, it is also\ncomputationally costly and cumbersome to parallelize, making it unpractical to\nsimulate high performance networks. Additionally, simulated scenarios fail to\ncapture all of the complexities present in real network scenarios. While there\nexists network models based on Machine Learning (ML) techniques to minimize\nthese issues, these models are also trained with simulated data and hence\nvulnerable to the same pitfalls. Consequently, the Graph Neural Networking\nChallenge 2023 introduces a dataset of captured traffic traces that can be used\nto build a ML-based network model without these limitations. In this paper we\npropose a Graph Neural Network (GNN)-based solution specifically designed to\nbetter capture the complexities of real network scenarios. This is done through\na novel encoding method to capture information from the sequence of captured\npackets, and an improved message passing algorithm to better represent the\ndependencies present in physical networks. We show that the proposed solution\nit is able to learn and generalize to unseen captured network scenarios.",
            "author": [
                "Carlos G\u00fcemes-Palau",
                "Miquel Ferriol Galm\u00e9s",
                "Albert Cabellos-Aparicio",
                "Pere Barlet-Ros"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11889v1",
                "http://arxiv.org/pdf/2310.11889v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11888v1",
            "title": "Analyze Mass Spectrometry data with Artificial Intelligence to assist\n  the understanding of past habitability of Mars and provide insights for\n  future missions",
            "updated": "2023-10-18T11:14:46Z",
            "published": "2023-10-18T11:14:46Z",
            "summary": "This paper presents an application of artificial intelligence on mass\nspectrometry data for detecting habitability potential of ancient Mars.\nAlthough data was collected for planet Mars the same approach can be replicated\nfor any terrestrial object of our solar system. Furthermore, proposed\nmethodology can be adapted to any domain that uses mass spectrometry. This\nresearch is focused in data analysis of two mass spectrometry techniques,\nevolved gas analysis (EGA-MS) and gas chromatography (GC-MS), which are used to\nidentify specific chemical compounds in geological material samples. The study\ndemonstrates the applicability of EGA-MS and GC-MS data to extra-terrestrial\nmaterial analysis. Most important features of proposed methodology includes\nsquare root transformation of mass spectrometry values, conversion of raw data\nto 2D sprectrograms and utilization of specific machine learning models and\ntechniques to avoid overfitting on relative small datasets. Both EGA-MS and\nGC-MS datasets come from NASA and two machine learning competitions that the\nauthor participated and exploited. Complete running code for the GC-MS\ndataset/competition is available at GitHub.1 Raw training mass spectrometry\ndata include [0, 1] labels of specific chemical compounds, selected to provide\nvaluable insights and contribute to our understanding of the potential past\nhabitability of Mars.",
            "author": [
                "Ioannis Nasios"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.icarus.2023.115824",
                "http://arxiv.org/abs/2310.11888v1",
                "http://arxiv.org/pdf/2310.11888v1"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP",
                "cs.AI",
                "cs.CV",
                "cs.LG",
                "physics.data-an"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11884v1",
            "title": "From Neural Activations to Concepts: A Survey on Explaining Concepts in\n  Neural Networks",
            "updated": "2023-10-18T11:08:02Z",
            "published": "2023-10-18T11:08:02Z",
            "summary": "In this paper, we review recent approaches for explaining concepts in neural\nnetworks. Concepts can act as a natural link between learning and reasoning:\nonce the concepts are identified that a neural learning system uses, one can\nintegrate those concepts with a reasoning system for inference or use a\nreasoning system to act upon them to improve or enhance the learning system. On\nthe other hand, knowledge can not only be extracted from neural networks but\nconcept knowledge can also be inserted into neural network architectures. Since\nintegrating learning and reasoning is at the core of neuro-symbolic AI, the\ninsights gained from this survey can serve as an important step towards\nrealizing neuro-symbolic AI based on explainable concepts.",
            "author": [
                "Jae Hee Lee",
                "Sergio Lanza",
                "Stefan Wermter"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11884v1",
                "http://arxiv.org/pdf/2310.11884v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.CV",
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11880v1",
            "title": "Online Convex Optimization with Switching Cost and Delayed Gradients",
            "updated": "2023-10-18T11:06:06Z",
            "published": "2023-10-18T11:06:06Z",
            "summary": "We consider the online convex optimization (OCO) problem with quadratic and\nlinear switching cost in the limited information setting, where an online\nalgorithm can choose its action using only gradient information about the\nprevious objective function. For $L$-smooth and $\\mu$-strongly convex objective\nfunctions, we propose an online multiple gradient descent (OMGD) algorithm and\nshow that its competitive ratio for the OCO problem with quadratic switching\ncost is at most $4(L + 5) + \\frac{16(L + 5)}{\\mu}$. The competitive ratio upper\nbound for OMGD is also shown to be order-wise tight in terms of $L,\\mu$. In\naddition, we show that the competitive ratio of any online algorithm is\n$\\max\\{\\Omega(L), \\Omega(\\frac{L}{\\sqrt{\\mu}})\\}$ in the limited information\nsetting when the switching cost is quadratic. We also show that the OMGD\nalgorithm achieves the optimal (order-wise) dynamic regret in the limited\ninformation setting. For the linear switching cost, the competitive ratio upper\nbound of the OMGD algorithm is shown to depend on both the path length and the\nsquared path length of the problem instance, in addition to $L, \\mu$, and is\nshown to be order-wise, the best competitive ratio any online algorithm can\nachieve. Consequently, we conclude that the optimal competitive ratio for the\nquadratic and linear switching costs are fundamentally different in the limited\ninformation setting.",
            "author": [
                "Spandan Senapati",
                "Rahul Vaze"
            ],
            "link": [
                "http://dx.doi.org/doi.org/10.1016/j.peva.2023.102371",
                "http://arxiv.org/abs/2310.11880v1",
                "http://arxiv.org/pdf/2310.11880v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11876v1",
            "title": "SQ Lower Bounds for Learning Mixtures of Linear Classifiers",
            "updated": "2023-10-18T10:56:57Z",
            "published": "2023-10-18T10:56:57Z",
            "summary": "We study the problem of learning mixtures of linear classifiers under\nGaussian covariates. Given sample access to a mixture of $r$ distributions on\n$\\mathbb{R}^n$ of the form $(\\mathbf{x},y_{\\ell})$, $\\ell\\in [r]$, where\n$\\mathbf{x}\\sim\\mathcal{N}(0,\\mathbf{I}_n)$ and\n$y_\\ell=\\mathrm{sign}(\\langle\\mathbf{v}_\\ell,\\mathbf{x}\\rangle)$ for an unknown\nunit vector $\\mathbf{v}_\\ell$, the goal is to learn the underlying distribution\nin total variation distance. Our main result is a Statistical Query (SQ) lower\nbound suggesting that known algorithms for this problem are essentially best\npossible, even for the special case of uniform mixtures. In particular, we show\nthat the complexity of any SQ algorithm for the problem is\n$n^{\\mathrm{poly}(1/\\Delta) \\log(r)}$, where $\\Delta$ is a lower bound on the\npairwise $\\ell_2$-separation between the $\\mathbf{v}_\\ell$'s. The key technical\ningredient underlying our result is a new construction of spherical designs\nthat may be of independent interest.",
            "author": [
                "Ilias Diakonikolas",
                "Daniel M. Kane",
                "Yuxin Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11876v1",
                "http://arxiv.org/pdf/2310.11876v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DS",
                "math.ST",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11875v1",
            "title": "Fractional Concepts in Neural Networks: Enhancing Activation and Loss\n  Functions",
            "updated": "2023-10-18T10:49:29Z",
            "published": "2023-10-18T10:49:29Z",
            "summary": "The paper presents a method for using fractional concepts in a neural network\nto modify the activation and loss functions. The methodology allows the neural\nnetwork to define and optimize its activation functions by determining the\nfractional derivative order of the training process as an additional\nhyperparameter. This will enable neurons in the network to adjust their\nactivation functions to match input data better and reduce output errors,\npotentially improving the network's overall performance.",
            "author": [
                "Zahra Alijani",
                "Vojtech Molek"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11875v1",
                "http://arxiv.org/pdf/2310.11875v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11868v1",
            "title": "To Generate or Not? Safety-Driven Unlearned Diffusion Models Are Still\n  Easy To Generate Unsafe Images ... For Now",
            "updated": "2023-10-18T10:36:34Z",
            "published": "2023-10-18T10:36:34Z",
            "summary": "The recent advances in diffusion models (DMs) have revolutionized the\ngeneration of complex and diverse images. However, these models also introduce\npotential safety hazards, such as the production of harmful content and\ninfringement of data copyrights. Although there have been efforts to create\nsafety-driven unlearning methods to counteract these challenges, doubts remain\nabout their capabilities. To bridge this uncertainty, we propose an evaluation\nframework built upon adversarial attacks (also referred to as adversarial\nprompts), in order to discern the trustworthiness of these safety-driven\nunlearned DMs. Specifically, our research explores the (worst-case) robustness\nof unlearned DMs in eradicating unwanted concepts, styles, and objects,\nassessed by the generation of adversarial prompts. We develop a novel\nadversarial learning approach called UnlearnDiff that leverages the inherent\nclassification capabilities of DMs to streamline the generation of adversarial\nprompts, making it as simple for DMs as it is for image classification attacks.\nThis technique streamlines the creation of adversarial prompts, making the\nprocess as intuitive for generative modeling as it is for image classification\nassaults. Through comprehensive benchmarking, we assess the unlearning\nrobustness of five prevalent unlearned DMs across multiple tasks. Our results\nunderscore the effectiveness and efficiency of UnlearnDiff when compared to\nstate-of-the-art adversarial prompting methods. Codes are available at\nhttps://github.com/OPTML-Group/Diffusion-MU-Attack. WARNING: This paper\ncontains model outputs that may be offensive in nature.",
            "author": [
                "Yimeng Zhang",
                "Jinghan Jia",
                "Xin Chen",
                "Aochuan Chen",
                "Yihua Zhang",
                "Jiancheng Liu",
                "Ke Ding",
                "Sijia Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11868v1",
                "http://arxiv.org/pdf/2310.11868v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11867v1",
            "title": "Evaluating the Fairness of Discriminative Foundation Models in Computer\n  Vision",
            "updated": "2023-10-18T10:32:39Z",
            "published": "2023-10-18T10:32:39Z",
            "summary": "We propose a novel taxonomy for bias evaluation of discriminative foundation\nmodels, such as Contrastive Language-Pretraining (CLIP), that are used for\nlabeling tasks. We then systematically evaluate existing methods for mitigating\nbias in these models with respect to our taxonomy. Specifically, we evaluate\nOpenAI's CLIP and OpenCLIP models for key applications, such as zero-shot\nclassification, image retrieval and image captioning. We categorize desired\nbehaviors based around three axes: (i) if the task concerns humans; (ii) how\nsubjective the task is (i.e., how likely it is that people from a diverse range\nof backgrounds would agree on a labeling); and (iii) the intended purpose of\nthe task and if fairness is better served by impartiality (i.e., making\ndecisions independent of the protected attributes) or representation (i.e.,\nmaking decisions to maximize diversity). Finally, we provide quantitative\nfairness evaluations for both binary-valued and multi-valued protected\nattributes over ten diverse datasets. We find that fair PCA, a post-processing\nmethod for fair representations, works very well for debiasing in most of the\naforementioned tasks while incurring only minor loss of performance. However,\ndifferent debiasing approaches vary in their effectiveness depending on the\ntask. Hence, one should choose the debiasing approach depending on the specific\nuse case.",
            "author": [
                "Junaid Ali",
                "Matthaeus Kleindessner",
                "Florian Wenzel",
                "Kailash Budhathoki",
                "Volkan Cevher",
                "Chris Russell"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3600211.3604720",
                "http://arxiv.org/abs/2310.11867v1",
                "http://arxiv.org/pdf/2310.11867v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CY",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11866v1",
            "title": "Stochastic Optimization for Non-convex Problem with Inexact Hessian\n  Matrix, Gradient, and Function",
            "updated": "2023-10-18T10:29:58Z",
            "published": "2023-10-18T10:29:58Z",
            "summary": "Trust-region (TR) and adaptive regularization using cubics (ARC) have proven\nto have some very appealing theoretical properties for non-convex optimization\nby concurrently computing function value, gradient, and Hessian matrix to\nobtain the next search direction and the adjusted parameters. Although\nstochastic approximations help largely reduce the computational cost, it is\nchallenging to theoretically guarantee the convergence rate. In this paper, we\nexplore a family of stochastic TR and ARC methods that can simultaneously\nprovide inexact computations of the Hessian matrix, gradient, and function\nvalues. Our algorithms require much fewer propagations overhead per iteration\nthan TR and ARC. We prove that the iteration complexity to achieve\n$\\epsilon$-approximate second-order optimality is of the same order as the\nexact computations demonstrated in previous studies. Additionally, the mild\nconditions on inexactness can be met by leveraging a random sampling technology\nin the finite-sum minimization problem. Numerical experiments with a non-convex\nproblem support these findings and demonstrate that, with the same or a similar\nnumber of iterations, our algorithms require less computational overhead per\niteration than current second-order methods.",
            "author": [
                "Liu Liu",
                "Xuanqing Liu",
                "Cho-Jui Hsieh",
                "Dacheng Tao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11866v1",
                "http://arxiv.org/pdf/2310.11866v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11865v1",
            "title": "Effective and Efficient Federated Tree Learning on Hybrid Data",
            "updated": "2023-10-18T10:28:29Z",
            "published": "2023-10-18T10:28:29Z",
            "summary": "Federated learning has emerged as a promising distributed learning paradigm\nthat facilitates collaborative learning among multiple parties without\ntransferring raw data. However, most existing federated learning studies focus\non either horizontal or vertical data settings, where the data of different\nparties are assumed to be from the same feature or sample space. In practice, a\ncommon scenario is the hybrid data setting, where data from different parties\nmay differ both in the features and samples. To address this, we propose\nHybridTree, a novel federated learning approach that enables federated tree\nlearning on hybrid data. We observe the existence of consistent split rules in\ntrees. With the help of these split rules, we theoretically show that the\nknowledge of parties can be incorporated into the lower layers of a tree. Based\non our theoretical analysis, we propose a layer-level solution that does not\nneed frequent communication traffic to train a tree. Our experiments\ndemonstrate that HybridTree can achieve comparable accuracy to the centralized\nsetting with low computational and communication overhead. HybridTree can\nachieve up to 8 times speedup compared with the other baselines.",
            "author": [
                "Qinbin Li",
                "Chulin Xie",
                "Xiaojun Xu",
                "Xiaoyuan Liu",
                "Ce Zhang",
                "Bo Li",
                "Bingsheng He",
                "Dawn Song"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11865v1",
                "http://arxiv.org/pdf/2310.11865v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11864v3",
            "title": "VQ-NeRF: Neural Reflectance Decomposition and Editing with Vector\n  Quantization",
            "updated": "2023-11-11T04:08:47Z",
            "published": "2023-10-18T10:26:56Z",
            "summary": "We propose VQ-NeRF, a two-branch neural network model that incorporates\nVector Quantization (VQ) to decompose and edit reflectance fields in 3D scenes.\nConventional neural reflectance fields use only continuous representations to\nmodel 3D scenes, despite the fact that objects are typically composed of\ndiscrete materials in reality. This lack of discretization can result in noisy\nmaterial decomposition and complicated material editing. To address these\nlimitations, our model consists of a continuous branch and a discrete branch.\nThe continuous branch follows the conventional pipeline to predict decomposed\nmaterials, while the discrete branch uses the VQ mechanism to quantize\ncontinuous materials into individual ones. By discretizing the materials, our\nmodel can reduce noise in the decomposition process and generate a segmentation\nmap of discrete materials. Specific materials can be easily selected for\nfurther editing by clicking on the corresponding area of the segmentation\noutcomes. Additionally, we propose a dropout-based VQ codeword ranking strategy\nto predict the number of materials in a scene, which reduces redundancy in the\nmaterial segmentation process. To improve usability, we also develop an\ninteractive interface to further assist material editing. We evaluate our model\non both computer-generated and real-world scenes, demonstrating its superior\nperformance. To the best of our knowledge, our model is the first to enable\ndiscrete material editing in 3D scenes.",
            "author": [
                "Hongliang Zhong",
                "Jingbo Zhang",
                "Jing Liao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11864v3",
                "http://arxiv.org/pdf/2310.11864v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11863v2",
            "title": "Structural transformations driven by local disorder at interfaces",
            "updated": "2023-10-30T16:16:34Z",
            "published": "2023-10-18T10:26:39Z",
            "summary": "Despite the fundamental importance of solid-solid transformations in many\ntechnologies, the microscopic mechanisms remain poorly understood. Here, we\nexplore the atomistic mechanisms at the migrating interface during solid-solid\nphase transformations between the topologically closed-packed A15 and\nbody-centred cubic phase in tungsten. The high energy barriers and slow\ndynamics associated with this transformation require the application of\nenhanced molecular sampling approaches. To this end, we performed metadynamics\nsimulations in combination with a path collective variable derived from a\nmachine learning classification of local structural environments, which allows\nthe system to freely sample the complex interface structure. A disordered\nregion of varying width forming at the migrating interface is identified as a\nkey physical descriptor of the transformation mechanisms, facilitating the\natomic shuffling and rearrangement necessary for structural transformations.\nFurthermore, this can directly be linked to the differences in interface\nmobility for distinct orientation relationships as well as the formation of\ninterfacial ledges during the migration along low-mobility directions.",
            "author": [
                "Yanyan Liang",
                "Grisell D\u00edaz Leines",
                "Ralf Drautz",
                "Jutta Rogal"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11863v2",
                "http://arxiv.org/pdf/2310.11863v2"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11862v2",
            "title": "Learning to Generate Parameters of ConvNets for Unseen Image Data",
            "updated": "2023-10-24T15:56:14Z",
            "published": "2023-10-18T10:26:18Z",
            "summary": "Typical Convolutional Neural Networks (ConvNets) depend heavily on large\namounts of image data and resort to an iterative optimization algorithm (e.g.,\nSGD or Adam) to learn network parameters, which makes training very time- and\nresource-intensive. In this paper, we propose a new training paradigm and\nformulate the parameter learning of ConvNets into a prediction task: given a\nConvNet architecture, we observe there exists correlations between image\ndatasets and their corresponding optimal network parameters, and explore if we\ncan learn a hyper-mapping between them to capture the relations, such that we\ncan directly predict the parameters of the network for an image dataset never\nseen during the training phase. To do this, we put forward a new hypernetwork\nbased model, called PudNet, which intends to learn a mapping between datasets\nand their corresponding network parameters, and then predicts parameters for\nunseen data with only a single forward propagation. Moreover, our model\nbenefits from a series of adaptive hyper recurrent units sharing weights to\ncapture the dependencies of parameters among different network layers.\nExtensive experiments demonstrate that our proposed method achieves good\nefficacy for unseen image datasets on two kinds of settings: Intra-dataset\nprediction and Inter-dataset prediction. Our PudNet can also well scale up to\nlarge-scale datasets, e.g., ImageNet-1K. It takes 8967 GPU seconds to train\nResNet-18 on the ImageNet-1K using GC from scratch and obtain a top-5 accuracy\nof 44.65 %. However, our PudNet costs only 3.89 GPU seconds to predict the\nnetwork parameters of ResNet-18 achieving comparable performance (44.92 %),\nmore than 2,300 times faster than the traditional training paradigm.",
            "author": [
                "Shiye Wang",
                "Kaituo Feng",
                "Changsheng Li",
                "Ye Yuan",
                "Guoren Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11862v2",
                "http://arxiv.org/pdf/2310.11862v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19813v1",
            "title": "Enhancing Genetic Improvement Mutations Using Large Language Models",
            "updated": "2023-10-18T10:24:14Z",
            "published": "2023-10-18T10:24:14Z",
            "summary": "Large language models (LLMs) have been successfully applied to software\nengineering tasks, including program repair. However, their application in\nsearch-based techniques such as Genetic Improvement (GI) is still largely\nunexplored. In this paper, we evaluate the use of LLMs as mutation operators\nfor GI to improve the search process. We expand the Gin Java GI toolkit to call\nOpenAI's API to generate edits for the JCodec tool. We randomly sample the\nspace of edits using 5 different edit types. We find that the number of patches\npassing unit tests is up to 75% higher with LLM-based edits than with standard\nInsert edits. Further, we observe that the patches found with LLMs are\ngenerally less diverse compared to standard edits. We ran GI with local search\nto find runtime improvements. Although many improving patches are found by\nLLM-enhanced GI, the best improving patch was found by standard GI.",
            "author": [
                "Alexander E. I. Brownlee",
                "James Callan",
                "Karine Even-Mendoza",
                "Alina Geiger",
                "Carol Hanna",
                "Justyna Petke",
                "Federica Sarro",
                "Dominik Sobania"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19813v1",
                "http://arxiv.org/pdf/2310.19813v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.AI",
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11859v1",
            "title": "Stress, Strain, or Energy: Which One Is the Superior Parameter to\n  Estimate Fatigue Life of Notched Components? An Answer by a Novel Machine\n  Learning-Based Framework",
            "updated": "2023-10-18T10:19:55Z",
            "published": "2023-10-18T10:19:55Z",
            "summary": "This paper introduces a simple framework for accurately predicting the\nfatigue lifetime of notched components by employing various machine learning\nalgorithms applied to a wide range of materials, loading conditions, notch\ngeometries, and fatigue lives. Traditional approaches for this task have relied\non empirical relationships involving one of the mechanical properties, such as\nstress, strain, or energy. This study goes further by exploring which\nmechanical property serves as a better measure. The key idea of the framework\nis to use the gradient of the mechanical properties (stress, strain, and\nenergy) to distinguish between different notch geometries. To demonstrate the\naccuracy and broad applicability of the framework, it is initially validated\nusing isotropic materials, subsequently applied to samples produced through\nadditive manufacturing techniques, and ultimately tested on carbon fiber\nlaminated composites. The research demonstrates that the gradient of all three\nmeasures can be effectively employed to estimate fatigue lifetime, with\nstress-based predictions exhibiting the highest accuracy. Among the machine\nlearning algorithms investigated, Gradient Boosting and Random Forest yield the\nmost successful results. A noteworthy finding is the significant improvement in\nprediction accuracy achieved by incorporating new data generated based on the\nBasquin equation.",
            "author": [
                "Amir Mohammad Mirzaei"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11859v1",
                "http://arxiv.org/pdf/2310.11859v1"
            ],
            "primary_category": "physics.app-ph",
            "category": [
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11852v1",
            "title": "CIR at the NTCIR-17 ULTRE-2 Task",
            "updated": "2023-10-18T10:08:20Z",
            "published": "2023-10-18T10:08:20Z",
            "summary": "The Chinese academy of sciences Information Retrieval team (CIR) has\nparticipated in the NTCIR-17 ULTRE-2 task. This paper describes our approaches\nand reports our results on the ULTRE-2 task. We recognize the issue of false\nnegatives in the Baidu search data in this competition is very severe, much\nmore severe than position bias. Hence, we adopt the Dual Learning Algorithm\n(DLA) to address the position bias and use it as an auxiliary model to study\nhow to alleviate the false negative issue. We approach the problem from two\nperspectives: 1) correcting the labels for non-clicked items by a relevance\njudgment model trained from DLA, and learn a new ranker that is initialized\nfrom DLA; 2) including random documents as true negatives and documents that\nhave partial matching as hard negatives. Both methods can enhance the model\nperformance and our best method has achieved nDCG@10 of 0.5355, which is 2.66%\nbetter than the best score from the organizer.",
            "author": [
                "Lulu Yu",
                "Keping Bi",
                "Jiafeng Guo",
                "Xueqi Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11852v1",
                "http://arxiv.org/pdf/2310.11852v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11850v1",
            "title": "Revisiting Transferable Adversarial Image Examples: Attack\n  Categorization, Evaluation Guidelines, and New Insights",
            "updated": "2023-10-18T10:06:42Z",
            "published": "2023-10-18T10:06:42Z",
            "summary": "Transferable adversarial examples raise critical security concerns in\nreal-world, black-box attack scenarios. However, in this work, we identify two\nmain problems in common evaluation practices: (1) For attack transferability,\nlack of systematic, one-to-one attack comparison and fair hyperparameter\nsettings. (2) For attack stealthiness, simply no comparisons. To address these\nproblems, we establish new evaluation guidelines by (1) proposing a novel\nattack categorization strategy and conducting systematic and fair\nintra-category analyses on transferability, and (2) considering diverse\nimperceptibility metrics and finer-grained stealthiness characteristics from\nthe perspective of attack traceback. To this end, we provide the first\nlarge-scale evaluation of transferable adversarial examples on ImageNet,\ninvolving 23 representative attacks against 9 representative defenses. Our\nevaluation leads to a number of new insights, including consensus-challenging\nones: (1) Under a fair attack hyperparameter setting, one early attack method,\nDI, actually outperforms all the follow-up methods. (2) A state-of-the-art\ndefense, DiffPure, actually gives a false sense of (white-box) security since\nit is indeed largely bypassed by our (black-box) transferable attacks. (3) Even\nwhen all attacks are bounded by the same $L_p$ norm, they lead to dramatically\ndifferent stealthiness performance, which negatively correlates with their\ntransferability performance. Overall, our work demonstrates that existing\nproblematic evaluations have indeed caused misleading conclusions and missing\npoints, and as a result, hindered the assessment of the actual progress in this\nfield.",
            "author": [
                "Zhengyu Zhao",
                "Hanwei Zhang",
                "Renjue Li",
                "Ronan Sicre",
                "Laurent Amsaleg",
                "Michael Backes",
                "Qi Li",
                "Chao Shen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11850v1",
                "http://arxiv.org/pdf/2310.11850v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11846v1",
            "title": "Masked Pretraining for Multi-Agent Decision Making",
            "updated": "2023-10-18T09:53:27Z",
            "published": "2023-10-18T09:53:27Z",
            "summary": "Building a single generalist agent with zero-shot capability has recently\nsparked significant advancements in decision-making. However, extending this\ncapability to multi-agent scenarios presents challenges. Most current works\nstruggle with zero-shot capabilities, due to two challenges particular to the\nmulti-agent settings: a mismatch between centralized pretraining and\ndecentralized execution, and varying agent numbers and action spaces, making it\ndifficult to create generalizable representations across diverse downstream\ntasks. To overcome these challenges, we propose a \\textbf{Mask}ed pretraining\nframework for \\textbf{M}ulti-\\textbf{a}gent decision making (MaskMA). This\nmodel, based on transformer architecture, employs a mask-based collaborative\nlearning strategy suited for decentralized execution with partial observation.\nMoreover, MaskMA integrates a generalizable action representation by dividing\nthe action space into actions toward self-information and actions related to\nother entities. This flexibility allows MaskMA to tackle tasks with varying\nagent numbers and thus different action spaces. Extensive experiments in SMAC\nreveal MaskMA, with a single model pretrained on 11 training maps, can achieve\nan impressive 77.8% zero-shot win rate on 60 unseen test maps by decentralized\nexecution, while also performing effectively on other types of downstream tasks\n(\\textit{e.g.,} varied policies collaboration and ad hoc team play).",
            "author": [
                "Jie Liu",
                "Yinmin Zhang",
                "Chuming Li",
                "Chao Yang",
                "Yaodong Yang",
                "Yu Liu",
                "Wanli Ouyang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11846v1",
                "http://arxiv.org/pdf/2310.11846v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11845v1",
            "title": "Accelerate Presolve in Large-Scale Linear Programming via Reinforcement\n  Learning",
            "updated": "2023-10-18T09:51:59Z",
            "published": "2023-10-18T09:51:59Z",
            "summary": "Large-scale LP problems from industry usually contain much redundancy that\nseverely hurts the efficiency and reliability of solving LPs, making presolve\n(i.e., the problem simplification module) one of the most critical components\nin modern LP solvers. However, how to design high-quality presolve routines --\nthat is, the program determining (P1) which presolvers to select, (P2) in what\norder to execute, and (P3) when to stop -- remains a highly challenging task\ndue to the extensive requirements on expert knowledge and the large search\nspace. Due to the sequential decision property of the task and the lack of\nexpert demonstrations, we propose a simple and efficient reinforcement learning\n(RL) framework -- namely, reinforcement learning for presolve (RL4Presolve) --\nto tackle (P1)-(P3) simultaneously. Specifically, we formulate the routine\ndesign task as a Markov decision process and propose an RL framework with\nadaptive action sequences to generate high-quality presolve routines\nefficiently. Note that adaptive action sequences help learn complex behaviors\nefficiently and adapt to various benchmarks. Experiments on two solvers\n(open-source and commercial) and eight benchmarks (real-world and synthetic)\ndemonstrate that RL4Presolve significantly and consistently improves the\nefficiency of solving large-scale LPs, especially on benchmarks from industry.\nFurthermore, we optimize the hard-coded presolve routines in LP solvers by\nextracting rules from learned policies for simple and efficient deployment to\nHuawei's supply chain. The results show encouraging economic and academic\npotential for incorporating machine learning to modern solvers.",
            "author": [
                "Yufei Kuang",
                "Xijun Li",
                "Jie Wang",
                "Fangzhou Zhu",
                "Meng Lu",
                "Zhihai Wang",
                "Jia Zeng",
                "Houqiang Li",
                "Yongdong Zhang",
                "Feng Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11845v1",
                "http://arxiv.org/pdf/2310.11845v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19812v1",
            "title": "Brain decoding: toward real-time reconstruction of visual perception",
            "updated": "2023-10-18T09:51:38Z",
            "published": "2023-10-18T09:51:38Z",
            "summary": "In the past five years, the use of generative and foundational AI systems has\ngreatly improved the decoding of brain activity. Visual perception, in\nparticular, can now be decoded from functional Magnetic Resonance Imaging\n(fMRI) with remarkable fidelity. This neuroimaging technique, however, suffers\nfrom a limited temporal resolution ($\\approx$0.5 Hz) and thus fundamentally\nconstrains its real-time usage. Here, we propose an alternative approach based\non magnetoencephalography (MEG), a neuroimaging device capable of measuring\nbrain activity with high temporal resolution ($\\approx$5,000 Hz). For this, we\ndevelop an MEG decoding model trained with both contrastive and regression\nobjectives and consisting of three modules: i) pretrained embeddings obtained\nfrom the image, ii) an MEG module trained end-to-end and iii) a pretrained\nimage generator. Our results are threefold: Firstly, our MEG decoder shows a 7X\nimprovement of image-retrieval over classic linear decoders. Second, late brain\nresponses to images are best decoded with DINOv2, a recent foundational image\nmodel. Third, image retrievals and generations both suggest that MEG signals\nprimarily contain high-level visual features, whereas the same approach applied\nto 7T fMRI also recovers low-level features. Overall, these results provide an\nimportant step towards the decoding - in real time - of the visual processes\ncontinuously unfolding within the human brain.",
            "author": [
                "Yohann Benchetrit",
                "Hubert Banville",
                "Jean-R\u00e9mi King"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19812v1",
                "http://arxiv.org/pdf/2310.19812v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.AI",
                "cs.LG",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12189v1",
            "title": "Mesh Represented Recycle Learning for 3D Hand Pose and Mesh Estimation",
            "updated": "2023-10-18T09:50:09Z",
            "published": "2023-10-18T09:50:09Z",
            "summary": "In general, hand pose estimation aims to improve the robustness of model\nperformance in the real-world scenes. However, it is difficult to enhance the\nrobustness since existing datasets are obtained in restricted environments to\nannotate 3D information. Although neural networks quantitatively achieve a high\nestimation accuracy, unsatisfied results can be observed in visual quality.\nThis discrepancy between quantitative results and their visual qualities\nremains an open issue in the hand pose representation. To this end, we propose\na mesh represented recycle learning strategy for 3D hand pose and mesh\nestimation which reinforces synthesized hand mesh representation in a training\nphase. To be specific, a hand pose and mesh estimation model first predicts\nparametric 3D hand annotations (i.e., 3D keypoint positions and vertices for\nhand mesh) with real-world hand images in the training phase. Second, synthetic\nhand images are generated with self-estimated hand mesh representations. After\nthat, the synthetic hand images are fed into the same model again. Thus, the\nproposed learning strategy simultaneously improves quantitative results and\nvisual qualities by reinforcing synthetic mesh representation. To encourage\nconsistency between original model output and its recycled one, we propose\nself-correlation loss which maximizes the accuracy and reliability of our\nlearning strategy. Consequently, the model effectively conducts self-refinement\non hand pose estimation by learning mesh representation from its own output. To\ndemonstrate the effectiveness of our learning strategy, we provide extensive\nexperiments on FreiHAND dataset. Notably, our learning strategy improves the\nperformance on hand pose and mesh estimation without any extra computational\nburden during the inference.",
            "author": [
                "Bosang Kim",
                "Jonghyun Kim",
                "Hyotae Lee",
                "Lanying Jin",
                "Jeongwon Ha",
                "Dowoo Kwon",
                "Jungpyo Kim",
                "Wonhyeok Im",
                "KyungMin Jin",
                "Jungho Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12189v1",
                "http://arxiv.org/pdf/2310.12189v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11840v1",
            "title": "On The Expressivity of Objective-Specification Formalisms in\n  Reinforcement Learning",
            "updated": "2023-10-18T09:46:01Z",
            "published": "2023-10-18T09:46:01Z",
            "summary": "To solve a task with reinforcement learning (RL), it is necessary to formally\nspecify the goal of that task. Although most RL algorithms require that the\ngoal is formalised as a Markovian reward function, alternatives have been\ndeveloped (such as Linear Temporal Logic and Multi-Objective Reinforcement\nLearning). Moreover, it is well known that some of these formalisms are able to\nexpress certain tasks that other formalisms cannot express. However, there has\nnot yet been any thorough analysis of how these formalisms relate to each other\nin terms of expressivity. In this work, we fill this gap in the existing\nliterature by providing a comprehensive comparison of the expressivities of 17\nobjective-specification formalisms in RL. We place these formalisms in a\npreorder based on their expressive power, and present this preorder as a Hasse\ndiagram. We find a variety of limitations for the different formalisms, and\nthat no formalism is both dominantly expressive and straightforward to optimise\nwith current techniques. For example, we prove that each of Regularised RL,\nOuter Nonlinear Markov Rewards, Reward Machines, Linear Temporal Logic, and\nLimit Average Rewards can express an objective that the others cannot. Our\nfindings have implications for both policy optimisation and reward learning.\nFirstly, we identify expressivity limitations which are important to consider\nwhen specifying objectives in practice. Secondly, our results highlight the\nneed for future research which adapts reward learning to work with a variety of\nformalisms, since many existing reward learning methods implicitly assume that\ndesired objectives can be expressed with Markovian rewards. Our work\ncontributes towards a more cohesive understanding of the costs and benefits of\ndifferent RL objective-specification formalisms.",
            "author": [
                "Rohan Subramani",
                "Marcus Williams",
                "Max Heitmann",
                "Halfdan Holm",
                "Charlie Griffin",
                "Joar Skalse"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11840v1",
                "http://arxiv.org/pdf/2310.11840v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11838v2",
            "title": "Equivariant Bootstrapping for Uncertainty Quantification in Imaging\n  Inverse Problems",
            "updated": "2023-10-20T11:48:25Z",
            "published": "2023-10-18T09:43:15Z",
            "summary": "Scientific imaging problems are often severely ill-posed, and hence have\nsignificant intrinsic uncertainty. Accurately quantifying the uncertainty in\nthe solutions to such problems is therefore critical for the rigorous\ninterpretation of experimental results as well as for reliably using the\nreconstructed images as scientific evidence. Unfortunately, existing imaging\nmethods are unable to quantify the uncertainty in the reconstructed images in a\nmanner that is robust to experiment replications. This paper presents a new\nuncertainty quantification methodology based on an equivariant formulation of\nthe parametric bootstrap algorithm that leverages symmetries and invariance\nproperties commonly encountered in imaging problems. Additionally, the proposed\nmethodology is general and can be easily applied with any image reconstruction\ntechnique, including unsupervised training strategies that can be trained from\nobserved data alone, thus enabling uncertainty quantification in situations\nwhere there is no ground truth data available. We demonstrate the proposed\napproach with a series of numerical experiments and through comparisons with\nalternative uncertainty quantification strategies from the state-of-the-art,\nsuch as Bayesian strategies involving score-based diffusion models and Langevin\nsamplers. In all our experiments, the proposed method delivers remarkably\naccurate high-dimensional confidence regions and outperforms the competing\napproaches in terms of estimation accuracy, uncertainty quantification\naccuracy, and computing time.",
            "author": [
                "Julian Tachella",
                "Marcelo Pereyra"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11838v2",
                "http://arxiv.org/pdf/2310.11838v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.LG",
                "eess.SP",
                "stat.ML",
                "68T07",
                "G.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11837v1",
            "title": "Optimising Distributions with Natural Gradient Surrogates",
            "updated": "2023-10-18T09:42:39Z",
            "published": "2023-10-18T09:42:39Z",
            "summary": "Natural gradient methods have been used to optimise the parameters of\nprobability distributions in a variety of settings, often resulting in\nfast-converging procedures. Unfortunately, for many distributions of interest,\ncomputing the natural gradient has a number of challenges. In this work we\npropose a novel technique for tackling such issues, which involves reframing\nthe optimisation as one with respect to the parameters of a surrogate\ndistribution, for which computing the natural gradient is easy. We give several\nexamples of existing methods that can be interpreted as applying this\ntechnique, and propose a new method for applying it to a wide variety of\nproblems. Our method expands the set of distributions that can be efficiently\ntargeted with natural gradients. Furthermore, it is fast, easy to understand,\nsimple to implement using standard autodiff software, and does not require\nlengthy model-specific derivations. We demonstrate our method on maximum\nlikelihood estimation and variational inference tasks.",
            "author": [
                "Jonathan So",
                "Richard E. Turner"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11837v1",
                "http://arxiv.org/pdf/2310.11837v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11830v2",
            "title": "CLARA: Multilingual Contrastive Learning for Audio Representation\n  Acquisition",
            "updated": "2023-11-01T11:38:40Z",
            "published": "2023-10-18T09:31:56Z",
            "summary": "Multilingual speech processing requires understanding emotions, a task made\ndifficult by limited labelled data. CLARA, minimizes reliance on labelled data,\nenhancing generalization across languages. It excels at fostering shared\nrepresentations, aiding cross-lingual transfer of speech and emotions, even\nwith little data. Our approach adeptly captures emotional nuances in speech,\novercoming subjective assessment issues. Using a large multilingual audio\ncorpus and self-supervised learning, CLARA develops speech representations\nenriched with emotions, advancing emotion-aware multilingual speech processing.\n  Our method expands the data range using data augmentation, textual embedding\nfor visual understanding, and transfers knowledge from high- to low-resource\nlanguages. CLARA demonstrates excellent performance in emotion recognition,\nlanguage comprehension, and audio benchmarks, excelling in zero-shot and\nfew-shot learning. It adapts to low-resource languages, marking progress in\nmultilingual speech representation learning.",
            "author": [
                "Kari A Noriy",
                "Xiaosong Yang",
                "Marcin Budka",
                "Jian Jun Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11830v2",
                "http://arxiv.org/pdf/2310.11830v2"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "cs.MM",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11829v2",
            "title": "Towards Graph Foundation Models: A Survey and Beyond",
            "updated": "2023-12-02T08:36:17Z",
            "published": "2023-10-18T09:31:21Z",
            "summary": "Foundation models have emerged as critical components in a variety of\nartificial intelligence applications, and showcase significant success in\nnatural language processing and several other domains. Meanwhile, the field of\ngraph machine learning is witnessing a paradigm transition from shallow methods\nto more sophisticated deep learning approaches. The capabilities of foundation\nmodels to generalize and adapt motivate graph machine learning researchers to\ndiscuss the potential of developing a new graph learning paradigm. This\nparadigm envisions models that are pre-trained on extensive graph data and can\nbe adapted for various graph tasks. Despite this burgeoning interest, there is\na noticeable lack of clear definitions and systematic analyses pertaining to\nthis new domain. To this end, this article introduces the concept of Graph\nFoundation Models (GFMs), and offers an exhaustive explanation of their key\ncharacteristics and underlying technologies. We proceed to classify the\nexisting work related to GFMs into three distinct categories, based on their\ndependence on graph neural networks and large language models. In addition to\nproviding a thorough review of the current state of GFMs, this article also\noutlooks potential avenues for future research in this rapidly evolving domain.",
            "author": [
                "Jiawei Liu",
                "Cheng Yang",
                "Zhiyuan Lu",
                "Junze Chen",
                "Yibo Li",
                "Mengmei Zhang",
                "Ting Bai",
                "Yuan Fang",
                "Lichao Sun",
                "Philip S. Yu",
                "Chuan Shi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11829v2",
                "http://arxiv.org/pdf/2310.11829v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11818v1",
            "title": "IntentDial: An Intent Graph based Multi-Turn Dialogue System with\n  Reasoning Path Visualization",
            "updated": "2023-10-18T09:21:37Z",
            "published": "2023-10-18T09:21:37Z",
            "summary": "Intent detection and identification from multi-turn dialogue has become a\nwidely explored technique in conversational agents, for example, voice\nassistants and intelligent customer services. The conventional approaches\ntypically cast the intent mining process as a classification task. Although\nneural classifiers have proven adept at such classification tasks, the issue of\nneural network models often impedes their practical deployment in real-world\nsettings. We present a novel graph-based multi-turn dialogue system called ,\nwhich identifies a user's intent by identifying intent elements and a standard\nquery from a dynamically constructed and extensible intent graph using\nreinforcement learning. In addition, we provide visualization components to\nmonitor the immediate reasoning path for each turn of a dialogue, which greatly\nfacilitates further improvement of the system.",
            "author": [
                "Zengguang Hao",
                "Jie Zhang",
                "Binxia Xu",
                "Yafang Wang",
                "Gerard de Melo",
                "Xiaolong Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11818v1",
                "http://arxiv.org/pdf/2310.11818v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11815v1",
            "title": "Conservative Predictions on Noisy Financial Data",
            "updated": "2023-10-18T09:14:19Z",
            "published": "2023-10-18T09:14:19Z",
            "summary": "Price movements in financial markets are well known to be very noisy. As a\nresult, even if there are, on occasion, exploitable patterns that could be\npicked up by machine-learning algorithms, these are obscured by feature and\nlabel noise rendering the predictions less useful, and risky in practice.\nTraditional rule-learning techniques developed for noisy data, such as CN2,\nwould seek only high precision rules and refrain from making predictions where\ntheir antecedents did not apply. We apply a similar approach, where a model\nabstains from making a prediction on data points that it is uncertain on.\nDuring training, a cascade of such models are learned in sequence, similar to\nrule lists, with each model being trained only on data on which the previous\nmodel(s) were uncertain. Similar pruning of data takes place at test-time, with\n(higher accuracy) predictions being made albeit only on a fraction (support) of\ntest-time data. In a financial prediction setting, such an approach allows\ndecisions to be taken only when the ensemble model is confident, thereby\nreducing risk. We present results using traditional MLPs as well as\ndifferentiable decision trees, on synthetic data as well as real financial\nmarket data, to predict fixed-term returns using commonly used features. We\nsubmit that our approach is likely to result in better overall returns at a\nlower level of risk. In this context we introduce an utility metric to measure\nthe average gain per trade, as well as the return adjusted for downside risk,\nboth of which are improved significantly by our approach.",
            "author": [
                "Omkar Nabar",
                "Gautam Shroff"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3604237.3626859",
                "http://arxiv.org/abs/2310.11815v1",
                "http://arxiv.org/pdf/2310.11815v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11814v1",
            "title": "Dynamic Resource Management in Integrated NOMA Terrestrial-Satellite\n  Networks using Multi-Agent Reinforcement Learning",
            "updated": "2023-10-18T09:11:52Z",
            "published": "2023-10-18T09:11:52Z",
            "summary": "This study introduces a resource allocation framework for integrated\nsatellite-terrestrial networks to address these challenges. The framework\nleverages local cache pool deployments and non-orthogonal multiple access\n(NOMA) to reduce time delays and improve energy efficiency. Our proposed\napproach utilizes a multi-agent enabled deep deterministic policy gradient\nalgorithm (MADDPG) to optimize user association, cache design, and transmission\npower control, resulting in enhanced energy efficiency. The approach comprises\ntwo phases: User Association and Power Control, where users are treated as\nagents, and Cache Optimization, where the satellite (Bs) is considered the\nagent. Through extensive simulations, we demonstrate that our approach\nsurpasses conventional single-agent deep reinforcement learning algorithms in\naddressing cache design and resource allocation challenges in integrated\nterrestrial-satellite networks. Specifically, our proposed approach achieves\nsignificantly higher energy efficiency and reduced time delays compared to\nexisting methods.",
            "author": [
                "Ali Nauman",
                "Haya Mesfer Alshahrani",
                "Nadhem Nemri",
                "Kamal M. Othman",
                "Nojood O Aljehane",
                "Mashael Maashi",
                "Ashit Kumar Dutta",
                "Mohammed Assiri",
                "Wali Ullah Khan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11814v1",
                "http://arxiv.org/pdf/2310.11814v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11807v2",
            "title": "Learning Global Quantum Properties from Local Measurements with Neural\n  Networks",
            "updated": "2023-11-07T10:14:50Z",
            "published": "2023-10-18T08:53:23Z",
            "summary": "Characterizing the properties of multiparticle quantum systems is a crucial\ntask for quantum computing and many-body quantum physics. The task, however,\nbecomes extremely challenging when the system size becomes large and when the\nproperties of interest involve global measurements on a large number of sites.\nHere we develop a multi-task neural network model that can accurately predict\nglobal properties of many-body quantum systems, like string order parameters\nand many-body topological invariants, using only limited measurement data\ngathered from few neighbouring sites. The model can simultaneously predict\nmultiple quantum properties, including not only expectation values of quantum\nobservables, but also general nonlinear functions of the quantum state, such as\nentanglement entropies. Remarkably, we find that multi-task training over a\ngiven set of quantum properties enables our model to discover new properties\noutside the original set. Without any labeled data, the model can perform\nunsupervised classification of quantum phases of matter and uncover unknown\nboundaries between different phases.",
            "author": [
                "Ya-Dong Wu",
                "Yan Zhu",
                "Yuexuan Wang",
                "Giulio Chiribella"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11807v2",
                "http://arxiv.org/pdf/2310.11807v2"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19811v1",
            "title": "A Historical Context for Data Streams",
            "updated": "2023-10-18T08:52:16Z",
            "published": "2023-10-18T08:52:16Z",
            "summary": "Machine learning from data streams is an active and growing research area.\nResearch on learning from streaming data typically makes strict assumptions\nlinked to computational resource constraints, including requirements for stream\nmining algorithms to inspect each instance not more than once and be ready to\ngive a prediction at any time. Here we review the historical context of data\nstreams research placing the common assumptions used in machine learning over\ndata streams in their historical context.",
            "author": [
                "Indre Zliobaite",
                "Jesse Read"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19811v1",
                "http://arxiv.org/pdf/2310.19811v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DB",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11802v1",
            "title": "De novo protein design using geometric vector field networks",
            "updated": "2023-10-18T08:45:57Z",
            "published": "2023-10-18T08:45:57Z",
            "summary": "Innovations like protein diffusion have enabled significant progress in de\nnovo protein design, which is a vital topic in life science. These methods\ntypically depend on protein structure encoders to model residue backbone\nframes, where atoms do not exist. Most prior encoders rely on atom-wise\nfeatures, such as angles and distances between atoms, which are not available\nin this context. Thus far, only several simple encoders, such as IPA, have been\nproposed for this scenario, exposing the frame modeling as a bottleneck. In\nthis work, we proffer the Vector Field Network (VFN), which enables network\nlayers to perform learnable vector computations between coordinates of\nframe-anchored virtual atoms, thus achieving a higher capability for modeling\nframes. The vector computation operates in a manner similar to a linear layer,\nwith each input channel receiving 3D virtual atom coordinates instead of scalar\nvalues. The multiple feature vectors output by the vector computation are then\nused to update the residue representations and virtual atom coordinates via\nattention aggregation. Remarkably, VFN also excels in modeling both frames and\natoms, as the real atoms can be treated as the virtual atoms for modeling,\npositioning VFN as a potential universal encoder. In protein diffusion (frame\nmodeling), VFN exhibits an impressive performance advantage over IPA, excelling\nin terms of both designability (67.04% vs. 53.58%) and diversity (66.54% vs.\n51.98%). In inverse folding (frame and atom modeling), VFN outperforms the\nprevious SoTA model, PiFold (54.7% vs. 51.66%), on sequence recovery rate. We\nalso propose a method of equipping VFN with the ESM model, which significantly\nsurpasses the previous ESM-based SoTA (62.67% vs. 55.65%), LM-Design, by a\nsubstantial margin.",
            "author": [
                "Weian Mao",
                "Muzhi Zhu",
                "Zheng Sun",
                "Shuaike Shen",
                "Lin Yuanbo Wu",
                "Hao Chen",
                "Chunhua Shen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11802v1",
                "http://arxiv.org/pdf/2310.11802v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE",
                "cs.LG",
                "q-bio.BM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11801v1",
            "title": "Towards Quantum Dynamics Simulation of Physical Systems: A Survey",
            "updated": "2023-10-18T08:45:35Z",
            "published": "2023-10-18T08:45:35Z",
            "summary": "After the emergence of quantum mechanics and realising its need for an\naccurate understanding of physical systems, numerical methods were being used\nto undergo quantum mechanical treatment. With increasing system correlations\nand size, numerical methods fell rather inefficient, and there was a need to\nsimulate quantum mechanical phenomena on actual quantum computing hardware.\nNow, with noisy quantum computing machines that have been built and made\navailable to use, realising quantum simulations are edging towards a practical\nreality. In this paper, we talk about the progress that has been made in the\nfield of quantum simulations by actual quantum computing hardware and talk\nabout some very fascinating fields where it has expanded its branches, too. Not\nonly that, but we also review different software tool-sets available to date,\nwhich are to lay the foundation for realising quantum simulations in a much\nmore comprehensive manner.",
            "author": [
                "Rikteem Bhowmick",
                "Navaneeth Krishnan Mohan",
                "Devesh Kumar",
                "Rohit Chaurasiya",
                "Nixon Patel"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11801v1",
                "http://arxiv.org/pdf/2310.11801v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11797v1",
            "title": "Panoptic Out-of-Distribution Segmentation",
            "updated": "2023-10-18T08:38:31Z",
            "published": "2023-10-18T08:38:31Z",
            "summary": "Deep learning has led to remarkable strides in scene understanding with\npanoptic segmentation emerging as a key holistic scene interpretation task.\nHowever, the performance of panoptic segmentation is severely impacted in the\npresence of out-of-distribution (OOD) objects i.e. categories of objects that\ndeviate from the training distribution. To overcome this limitation, we propose\nPanoptic Out-of Distribution Segmentation for joint pixel-level semantic\nin-distribution and out-of-distribution classification with instance\nprediction. We extend two established panoptic segmentation benchmarks,\nCityscapes and BDD100K, with out-of-distribution instance segmentation\nannotations, propose suitable evaluation metrics, and present multiple strong\nbaselines. Importantly, we propose the novel PoDS architecture with a shared\nbackbone, an OOD contextual module for learning global and local OOD object\ncues, and dual symmetrical decoders with task-specific heads that employ our\nalignment-mismatch strategy for better OOD generalization. Combined with our\ndata augmentation strategy, this approach facilitates progressive learning of\nout-of-distribution objects while maintaining in-distribution performance. We\nperform extensive evaluations that demonstrate that our proposed PoDS network\neffectively addresses the main challenges and substantially outperforms the\nbaselines. We make the dataset, code, and trained models publicly available at\nhttp://pods.cs.uni-freiburg.de.",
            "author": [
                "Rohit Mohan",
                "Kiran Kumaraswamy",
                "Juana Valeria Hurtado",
                "K\u00fcrsat Petek",
                "Abhinav Valada"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11797v1",
                "http://arxiv.org/pdf/2310.11797v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11792v1",
            "title": "Real-time Perceptive Motion Control using Control Barrier Functions with\n  Analytical Smoothing for Six-Wheeled-Telescopic-Legged Robot Tachyon 3",
            "updated": "2023-10-18T08:33:08Z",
            "published": "2023-10-18T08:33:08Z",
            "summary": "To achieve safe legged locomotion, it is important to generate motion in\nreal-time considering various constraints in robots and environments. In this\nstudy, we propose a lightweight real-time perspective motion control system for\nthe newly developed six-wheeled-telescopic-legged robot, Tachyon 3. In the\nproposed method, analytically smoothed constraints including Smooth Separating\nAxis Theorem (Smooth SAT) as a novel higher order differentiable collision\ndetection for 3D shapes is applied to the Control Barrier Function (CBF). The\nproposed system integrating the CBF achieves online motion generation in a\nshort control cycle of 1 ms that satisfies joint limitations, environmental\ncollision avoidance and safe convex foothold constraints. The efficiency of\nSmooth SAT is shown from the collision detection time of 1 us or less and the\nCBF constraint computation time for Tachyon3 of several us. Furthermore, the\neffectiveness of the proposed system is verified through the stair-climbing\nmotion, integrating online recognition in a simulation and a real machine.",
            "author": [
                "Noriaki Takasugi",
                "Masaya Kinoshita",
                "Yasuhisa Kamikawa",
                "Ryoichi Tsuzaki",
                "Atsushi Sakamoto",
                "Toshimitsu Kai",
                "Yasunori Kawanami"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11792v1",
                "http://arxiv.org/pdf/2310.11792v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11789v1",
            "title": "Adversarial Training for Physics-Informed Neural Networks",
            "updated": "2023-10-18T08:28:43Z",
            "published": "2023-10-18T08:28:43Z",
            "summary": "Physics-informed neural networks have shown great promise in solving partial\ndifferential equations. However, due to insufficient robustness, vanilla PINNs\noften face challenges when solving complex PDEs, especially those involving\nmulti-scale behaviors or solutions with sharp or oscillatory characteristics.\nTo address these issues, based on the projected gradient descent adversarial\nattack, we proposed an adversarial training strategy for PINNs termed by\nAT-PINNs. AT-PINNs enhance the robustness of PINNs by fine-tuning the model\nwith adversarial samples, which can accurately identify model failure locations\nand drive the model to focus on those regions during training. AT-PINNs can\nalso perform inference with temporal causality by selecting the initial\ncollocation points around temporal initial values. We implement AT-PINNs to the\nelliptic equation with multi-scale coefficients, Poisson equation with\nmulti-peak solutions, Burgers equation with sharp solutions and the Allen-Cahn\nequation. The results demonstrate that AT-PINNs can effectively locate and\nreduce failure regions. Moreover, AT-PINNs are suitable for solving complex\nPDEs, since locating failure regions through adversarial attacks is independent\nof the size of failure regions or the complexity of the distribution.",
            "author": [
                "Yao Li",
                "Shengzhu Shi",
                "Zhichang Guo",
                "Boying Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11789v1",
                "http://arxiv.org/pdf/2310.11789v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11787v1",
            "title": "NeuroCUT: A Neural Approach for Robust Graph Partitioning",
            "updated": "2023-10-18T08:27:09Z",
            "published": "2023-10-18T08:27:09Z",
            "summary": "Graph partitioning aims to divide a graph into $k$ disjoint subsets while\noptimizing a specific partitioning objective. The majority of formulations\nrelated to graph partitioning exhibit NP-hardness due to their combinatorial\nnature. As a result, conventional approximation algorithms rely on heuristic\nmethods, sometimes with approximation guarantees and sometimes without.\nUnfortunately, traditional approaches are tailored for specific partitioning\nobjectives and do not generalize well across other known partitioning\nobjectives from the literature. To overcome this limitation, and learn\nheuristics from the data directly, neural approaches have emerged,\ndemonstrating promising outcomes. In this study, we extend this line of work\nthrough a novel framework, NeuroCut. NeuroCut introduces two key innovations\nover prevailing methodologies. First, it is inductive to both graph topology\nand the partition count, which is provided at query time. Second, by leveraging\na reinforcement learning based framework over node representations derived from\na graph neural network, NeuroCut can accommodate any optimization objective,\neven those encompassing non-differentiable functions. Through empirical\nevaluation, we demonstrate that NeuroCut excels in identifying high-quality\npartitions, showcases strong generalization across a wide spectrum of\npartitioning objectives, and exhibits resilience to topological modifications.",
            "author": [
                "Rishi Shah",
                "Krishnanshu Jain",
                "Sahil Manchanda",
                "Sourav Medya",
                "Sayan Ranu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11787v1",
                "http://arxiv.org/pdf/2310.11787v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11780v1",
            "title": "Text Annotation Handbook: A Practical Guide for Machine Learning\n  Projects",
            "updated": "2023-10-18T08:19:53Z",
            "published": "2023-10-18T08:19:53Z",
            "summary": "This handbook is a hands-on guide on how to approach text annotation tasks.\nIt provides a gentle introduction to the topic, an overview of theoretical\nconcepts as well as practical advice. The topics covered are mostly technical,\nbut business, ethical and regulatory issues are also touched upon. The focus\nlies on readability and conciseness rather than completeness and scientific\nrigor. Experience with annotation and knowledge of machine learning are useful\nbut not required. The document may serve as a primer or reference book for a\nwide range of professions such as team leaders, project managers, IT\narchitects, software developers and machine learning engineers.",
            "author": [
                "Felix Stollenwerk",
                "Joey \u00d6hman",
                "Danila Petrelli",
                "Emma Waller\u00f6",
                "Fredrik Olsson",
                "Camilla Bengtsson",
                "Andreas Horndahl",
                "Gabriela Zarzar Gandler"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11780v1",
                "http://arxiv.org/pdf/2310.11780v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11777v1",
            "title": "DCRNN: A Deep Cross approach based on RNN for Partial Parameter Sharing\n  in Multi-task Learning",
            "updated": "2023-10-18T08:16:27Z",
            "published": "2023-10-18T08:16:27Z",
            "summary": "In recent years, DL has developed rapidly, and personalized services are\nexploring using DL algorithms to improve the performance of the recommendation\nsystem. For personalized services, a successful recommendation consists of two\nparts: attracting users to click the item and users being willing to consume\nthe item. If both tasks need to be predicted at the same time, traditional\nrecommendation systems generally train two independent models. This approach is\ncumbersome and does not effectively model the relationship between the two\nsubtasks of \"click-consumption\". Therefore, in order to improve the success\nrate of recommendation and reduce computational costs, researchers are trying\nto model multi-task learning.\n  At present, existing multi-task learning models generally adopt hard\nparameter sharing or soft parameter sharing architecture, but these two\narchitectures each have certain problems. Therefore, in this work, we propose a\nnovel recommendation model based on real recommendation scenarios, Deep Cross\nnetwork based on RNN for partial parameter sharing (DCRNN). The model has three\ninnovations: 1) It adopts the idea of cross network and uses RNN network to\ncross-process the features, thereby effectively improves the expressive ability\nof the model; 2) It innovatively proposes the structure of partial parameter\nsharing; 3) It can effectively capture the potential correlation between\ndifferent tasks to optimize the efficiency and methods for learning different\ntasks.",
            "author": [
                "Jie Zhou",
                "Qian Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11777v1",
                "http://arxiv.org/pdf/2310.11777v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11772v3",
            "title": "Improving Long Document Topic Segmentation Models With Enhanced\n  Coherence Modeling",
            "updated": "2023-10-23T06:05:59Z",
            "published": "2023-10-18T07:58:47Z",
            "summary": "Topic segmentation is critical for obtaining structured documents and\nimproving downstream tasks such as information retrieval. Due to its ability of\nautomatically exploring clues of topic shift from abundant labeled data, recent\nsupervised neural models have greatly promoted the development of long document\ntopic segmentation, but leaving the deeper relationship between coherence and\ntopic segmentation underexplored. Therefore, this paper enhances the ability of\nsupervised models to capture coherence from both logical structure and semantic\nsimilarity perspectives to further improve the topic segmentation performance,\nproposing Topic-aware Sentence Structure Prediction (TSSP) and Contrastive\nSemantic Similarity Learning (CSSL). Specifically, the TSSP task is proposed to\nforce the model to comprehend structural information by learning the original\nrelations between adjacent sentences in a disarrayed document, which is\nconstructed by jointly disrupting the original document at topic and sentence\nlevels. Moreover, we utilize inter- and intra-topic information to construct\ncontrastive samples and design the CSSL objective to ensure that the sentences\nrepresentations in the same topic have higher similarity, while those in\ndifferent topics are less similar. Extensive experiments show that the\nLongformer with our approach significantly outperforms old state-of-the-art\n(SOTA) methods. Our approach improve $F_1$ of old SOTA by 3.42 (73.74 -> 77.16)\nand reduces $P_k$ by 1.11 points (15.0 -> 13.89) on WIKI-727K and achieves an\naverage relative reduction of 4.3% on $P_k$ on WikiSection. The average\nrelative $P_k$ drop of 8.38% on two out-of-domain datasets also demonstrates\nthe robustness of our approach.",
            "author": [
                "Hai Yu",
                "Chong Deng",
                "Qinglin Zhang",
                "Jiaqing Liu",
                "Qian Chen",
                "Wen Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11772v3",
                "http://arxiv.org/pdf/2310.11772v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11762v2",
            "title": "A Quasi-Wasserstein Loss for Learning Graph Neural Networks",
            "updated": "2023-10-19T14:11:51Z",
            "published": "2023-10-18T07:39:05Z",
            "summary": "When learning graph neural networks (GNNs) in node-level prediction tasks,\nmost existing loss functions are applied for each node independently, even if\nnode embeddings and their labels are non-i.i.d. because of their graph\nstructures. To eliminate such inconsistency, in this study we propose a novel\nQuasi-Wasserstein (QW) loss with the help of the optimal transport defined on\ngraphs, leading to new learning and prediction paradigms of GNNs. In\nparticular, we design a \"Quasi-Wasserstein\" distance between the observed\nmulti-dimensional node labels and their estimations, optimizing the label\ntransport defined on graph edges. The estimations are parameterized by a GNN in\nwhich the optimal label transport may determine the graph edge weights\noptionally. By reformulating the strict constraint of the label transport to a\nBregman divergence-based regularizer, we obtain the proposed Quasi-Wasserstein\nloss associated with two efficient solvers learning the GNN together with\noptimal label transport. When predicting node labels, our model combines the\noutput of the GNN with the residual component provided by the optimal label\ntransport, leading to a new transductive prediction paradigm. Experiments show\nthat the proposed QW loss applies to various GNNs and helps to improve their\nperformance in node-level classification and regression tasks.",
            "author": [
                "Minjie Cheng",
                "Hongteng Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11762v2",
                "http://arxiv.org/pdf/2310.11762v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11761v1",
            "title": "A Comprehensive Evaluation of Large Language Models on Legal Judgment\n  Prediction",
            "updated": "2023-10-18T07:38:04Z",
            "published": "2023-10-18T07:38:04Z",
            "summary": "Large language models (LLMs) have demonstrated great potential for\ndomain-specific applications, such as the law domain. However, recent disputes\nover GPT-4's law evaluation raise questions concerning their performance in\nreal-world legal tasks. To systematically investigate their competency in the\nlaw, we design practical baseline solutions based on LLMs and test on the task\nof legal judgment prediction. In our solutions, LLMs can work alone to answer\nopen questions or coordinate with an information retrieval (IR) system to learn\nfrom similar cases or solve simplified multi-choice questions. We show that\nsimilar cases and multi-choice options, namely label candidates, included in\nprompts can help LLMs recall domain knowledge that is critical for expertise\nlegal reasoning. We additionally present an intriguing paradox wherein an IR\nsystem surpasses the performance of LLM+IR due to limited gains acquired by\nweaker LLMs from powerful IR systems. In such cases, the role of LLMs becomes\nredundant. Our evaluation pipeline can be easily extended into other tasks to\nfacilitate evaluations in other domains. Code is available at\nhttps://github.com/srhthu/LM-CompEval-Legal",
            "author": [
                "Ruihao Shui",
                "Yixin Cao",
                "Xiang Wang",
                "Tat-Seng Chua"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11761v1",
                "http://arxiv.org/pdf/2310.11761v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11758v1",
            "title": "Domain-Generalized Face Anti-Spoofing with Unknown Attacks",
            "updated": "2023-10-18T07:31:35Z",
            "published": "2023-10-18T07:31:35Z",
            "summary": "Although face anti-spoofing (FAS) methods have achieved remarkable\nperformance on specific domains or attack types, few studies have focused on\nthe simultaneous presence of domain changes and unknown attacks, which is\ncloser to real application scenarios. To handle domain-generalized unknown\nattacks, we introduce a new method, DGUA-FAS, which consists of a\nTransformer-based feature extractor and a synthetic unknown attack sample\ngenerator (SUASG). The SUASG network simulates unknown attack samples to assist\nthe training of the feature extractor. Experimental results show that our\nmethod achieves superior performance on domain generalization FAS with known or\nunknown attacks.",
            "author": [
                "Zong-Wei Hong",
                "Yu-Chen Lin",
                "Hsuan-Tung Liu",
                "Yi-Ren Yeh",
                "Chu-Song Chen"
            ],
            "link": [
                "http://dx.doi.org/10.1109/ICIP49359.2023.10223078",
                "http://arxiv.org/abs/2310.11758v1",
                "http://arxiv.org/pdf/2310.11758v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11755v3",
            "title": "RGM: A Robust Generalist Matching Model",
            "updated": "2023-11-14T03:07:45Z",
            "published": "2023-10-18T07:30:08Z",
            "summary": "Finding corresponding pixels within a pair of images is a fundamental\ncomputer vision task with various applications. Due to the specific\nrequirements of different tasks like optical flow estimation and local feature\nmatching, previous works are primarily categorized into dense matching and\nsparse feature matching focusing on specialized architectures along with\ntask-specific datasets, which may somewhat hinder the generalization\nperformance of specialized models. In this paper, we propose a deep model for\nsparse and dense matching, termed RGM (Robust Generalist Matching). In\nparticular, we elaborately design a cascaded GRU module for refinement by\nexploring the geometric similarity iteratively at multiple scales following an\nadditional uncertainty estimation module for sparsification. To narrow the gap\nbetween synthetic training samples and real-world scenarios, we build a new,\nlarge-scale dataset with sparse correspondence ground truth by generating\noptical flow supervision with greater intervals. As such, we are able to mix up\nvarious dense and sparse matching datasets, significantly improving the\ntraining diversity. The generalization capacity of our proposed RGM is greatly\nimproved by learning the matching and uncertainty estimation in a two-stage\nmanner on the large, mixed data. Superior performance is achieved for zero-shot\nmatching and downstream geometry estimation across multiple datasets,\noutperforming the previous methods by a large margin.",
            "author": [
                "Songyan Zhang",
                "Xinyu Sun",
                "Hao Chen",
                "Bo Li",
                "Chunhua Shen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11755v3",
                "http://arxiv.org/pdf/2310.11755v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11749v1",
            "title": "Estimating Material Properties of Interacting Objects Using Sum-GP-UCB",
            "updated": "2023-10-18T07:16:06Z",
            "published": "2023-10-18T07:16:06Z",
            "summary": "Robots need to estimate the material and dynamic properties of objects from\nobservations in order to simulate them accurately. We present a Bayesian\noptimization approach to identifying the material property parameters of\nobjects based on a set of observations. Our focus is on estimating these\nproperties based on observations of scenes with different sets of interacting\nobjects. We propose an approach that exploits the structure of the reward\nfunction by modeling the reward for each observation separately and using only\nthe parameters of the objects in that scene as inputs. The resulting\nlower-dimensional models generalize better over the parameter space, which in\nturn results in a faster optimization. To speed up the optimization process\nfurther, and reduce the number of simulation runs needed to find good parameter\nvalues, we also propose partial evaluations of the reward function, wherein the\nselected parameters are only evaluated on a subset of real world evaluations.\nThe approach was successfully evaluated on a set of scenes with a wide range of\nobject interactions, and we showed that our method can effectively perform\nincremental learning without resetting the rewards of the gathered\nobservations.",
            "author": [
                "M. Yunus Seker",
                "Oliver Kroemer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11749v1",
                "http://arxiv.org/pdf/2310.11749v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11742v1",
            "title": "AdaVis: Adaptive and Explainable Visualization Recommendation for\n  Tabular Data",
            "updated": "2023-10-18T06:54:55Z",
            "published": "2023-10-18T06:54:55Z",
            "summary": "Automated visualization recommendation facilitates the rapid creation of\neffective visualizations, which is especially beneficial for users with limited\ntime and limited knowledge of data visualization. There is an increasing trend\nin leveraging machine learning (ML) techniques to achieve an end-to-end\nvisualization recommendation. However, existing ML-based approaches implicitly\nassume that there is only one appropriate visualization for a specific dataset,\nwhich is often not true for real applications. Also, they often work like a\nblack box, and are difficult for users to understand the reasons for\nrecommending specific visualizations. To fill the research gap, we propose\nAdaVis, an adaptive and explainable approach to recommend one or multiple\nappropriate visualizations for a tabular dataset. It leverages a box\nembedding-based knowledge graph to well model the possible one-to-many mapping\nrelations among different entities (i.e., data features, dataset columns,\ndatasets, and visualization choices). The embeddings of the entities and\nrelations can be learned from dataset-visualization pairs. Also, AdaVis\nincorporates the attention mechanism into the inference framework. Attention\ncan indicate the relative importance of data features for a dataset and provide\nfine-grained explainability. Our extensive evaluations through quantitative\nmetric evaluations, case studies, and user interviews demonstrate the\neffectiveness of AdaVis.",
            "author": [
                "Songheng Zhang",
                "Haotian Li",
                "Huamin Qu",
                "Yong Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11742v1",
                "http://arxiv.org/pdf/2310.11742v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11741v1",
            "title": "Graph Sphere: From Nodes to Supernodes in Graphical Models",
            "updated": "2023-10-18T06:54:20Z",
            "published": "2023-10-18T06:54:20Z",
            "summary": "High-dimensional data analysis typically focuses on low-dimensional\nstructure, often to aid interpretation and computational efficiency. Graphical\nmodels provide a powerful methodology for learning the conditional independence\nstructure in multivariate data by representing variables as nodes and\ndependencies as edges. Inference is often focused on individual edges in the\nlatent graph. Nonetheless, there is increasing interest in determining more\ncomplex structures, such as communities of nodes, for multiple reasons,\nincluding more effective information retrieval and better interpretability. In\nthis work, we propose a multilayer graphical model where we first cluster nodes\nand then, at the second layer, investigate the relationships among groups of\nnodes. Specifically, nodes are partitioned into \"supernodes\" with a\ndata-coherent size-biased tessellation prior which combines ideas from Bayesian\nnonparametrics and Voronoi tessellations. This construct allows accounting also\nfor dependence of nodes within supernodes. At the second layer, dependence\nstructure among supernodes is modelled through a Gaussian graphical model,\nwhere the focus of inference is on \"superedges\". We provide theoretical\njustification for our modelling choices. We design tailored Markov chain Monte\nCarlo schemes, which also enable parallel computations. We demonstrate the\neffectiveness of our approach for large-scale structure learning in simulations\nand a transcriptomics application.",
            "author": [
                "Willem van den Boom",
                "Maria De Iorio",
                "Alexandros Beskos",
                "Ajay Jasra"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11741v1",
                "http://arxiv.org/pdf/2310.11741v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11739v1",
            "title": "Unintended Memorization in Large ASR Models, and How to Mitigate It",
            "updated": "2023-10-18T06:45:49Z",
            "published": "2023-10-18T06:45:49Z",
            "summary": "It is well-known that neural networks can unintentionally memorize their\ntraining examples, causing privacy concerns. However, auditing memorization in\nlarge non-auto-regressive automatic speech recognition (ASR) models has been\nchallenging due to the high compute cost of existing methods such as hardness\ncalibration. In this work, we design a simple auditing method to measure\nmemorization in large ASR models without the extra compute overhead.\nConcretely, we speed up randomly-generated utterances to create a mapping\nbetween vocal and text information that is difficult to learn from typical\ntraining examples. Hence, accurate predictions only for sped-up training\nexamples can serve as clear evidence for memorization, and the corresponding\naccuracy can be used to measure memorization. Using the proposed method, we\nshowcase memorization in the state-of-the-art ASR models. To mitigate\nmemorization, we tried gradient clipping during training to bound the influence\nof any individual example on the final model. We empirically show that clipping\neach example's gradient can mitigate memorization for sped-up training examples\nwith up to 16 repetitions in the training set. Furthermore, we show that in\nlarge-scale distributed training, clipping the average gradient on each compute\ncore maintains neutral model quality and compute cost while providing strong\nprivacy protection.",
            "author": [
                "Lun Wang",
                "Om Thakkar",
                "Rajiv Mathews"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11739v1",
                "http://arxiv.org/pdf/2310.11739v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11736v2",
            "title": "Kernel Learning in Ridge Regression \"Automatically\" Yields Exact Low\n  Rank Solution",
            "updated": "2023-11-27T20:30:54Z",
            "published": "2023-10-18T06:15:35Z",
            "summary": "We consider kernels of the form $(x,x') \\mapsto \\phi(\\|x-x'\\|^2_\\Sigma)$\nparametrized by $\\Sigma$. For such kernels, we study a variant of the kernel\nridge regression problem which simultaneously optimizes the prediction function\nand the parameter $\\Sigma$ of the reproducing kernel Hilbert space. The\neigenspace of the $\\Sigma$ learned from this kernel ridge regression problem\ncan inform us which directions in covariate space are important for prediction.\n  Assuming that the covariates have nonzero explanatory power for the response\nonly through a low dimensional subspace (central mean subspace), we find that\nthe global minimizer of the finite sample kernel learning objective is also low\nrank with high probability. More precisely, the rank of the minimizing $\\Sigma$\nis with high probability bounded by the dimension of the central mean subspace.\nThis phenomenon is interesting because the low rankness property is achieved\nwithout using any explicit regularization of $\\Sigma$, e.g., nuclear norm\npenalization.\n  Our theory makes correspondence between the observed phenomenon and the\nnotion of low rank set identifiability from the optimization literature. The\nlow rankness property of the finite sample solutions exists because the\npopulation kernel learning objective grows \"sharply\" when moving away from its\nminimizers in any direction perpendicular to the central mean subspace.",
            "author": [
                "Yunlu Chen",
                "Yang Li",
                "Keli Liu",
                "Feng Ruan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11736v2",
                "http://arxiv.org/pdf/2310.11736v2"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "math.OC",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11732v2",
            "title": "Investigating Uncertainty Calibration of Aligned Language Models under\n  the Multiple-Choice Setting",
            "updated": "2023-11-19T12:40:41Z",
            "published": "2023-10-18T06:07:28Z",
            "summary": "Despite the significant progress made in practical applications of aligned\nlanguage models (LMs), they tend to be overconfident in output answers compared\nto the corresponding pre-trained LMs. In this work, we systematically evaluate\nthe impact of the alignment process on logit-based uncertainty calibration of\nLMs under the multiple-choice setting. We first conduct a thoughtful empirical\nstudy on how aligned LMs differ in calibration from their pre-trained\ncounterparts. Experimental results reveal that there are two distinct\nuncertainties in LMs under the multiple-choice setting, which are responsible\nfor the answer decision and the format preference of the LMs, respectively.\nThen, we investigate the role of these two uncertainties on aligned LM's\ncalibration through fine-tuning in simple synthetic alignment schemes and\nconclude that one reason for aligned LMs' overconfidence is the conflation of\nthese two types of uncertainty. Furthermore, we examine the utility of common\npost-hoc calibration methods for aligned LMs and propose an easy-to-implement\nand sample-efficient method to calibrate aligned LMs. We hope our findings\ncould provide insights into the design of more reliable alignment processes for\nLMs.",
            "author": [
                "Guande He",
                "Peng Cui",
                "Jianfei Chen",
                "Wenbo Hu",
                "Jun Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11732v2",
                "http://arxiv.org/pdf/2310.11732v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11731v1",
            "title": "Action-Quantized Offline Reinforcement Learning for Robotic Skill\n  Learning",
            "updated": "2023-10-18T06:07:10Z",
            "published": "2023-10-18T06:07:10Z",
            "summary": "The offline reinforcement learning (RL) paradigm provides a general recipe to\nconvert static behavior datasets into policies that can perform better than the\npolicy that collected the data. While policy constraints, conservatism, and\nother methods for mitigating distributional shifts have made offline\nreinforcement learning more effective, the continuous action setting often\nnecessitates various approximations for applying these techniques. Many of\nthese challenges are greatly alleviated in discrete action settings, where\noffline RL constraints and regularizers can often be computed more precisely or\neven exactly. In this paper, we propose an adaptive scheme for action\nquantization. We use a VQ-VAE to learn state-conditioned action quantization,\navoiding the exponential blowup that comes with na\\\"ive discretization of the\naction space. We show that several state-of-the-art offline RL methods such as\nIQL, CQL, and BRAC improve in performance on benchmarks when combined with our\nproposed discretization scheme. We further validate our approach on a set of\nchallenging long-horizon complex robotic manipulation tasks in the Robomimic\nenvironment, where our discretized offline RL algorithms are able to improve\nupon their continuous counterparts by 2-3x. Our project page is at\nhttps://saqrl.github.io/",
            "author": [
                "Jianlan Luo",
                "Perry Dong",
                "Jeffrey Wu",
                "Aviral Kumar",
                "Xinyang Geng",
                "Sergey Levine"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11731v1",
                "http://arxiv.org/pdf/2310.11731v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11730v2",
            "title": "Federated Heterogeneous Graph Neural Network for Privacy-preserving\n  Recommendation",
            "updated": "2023-12-02T06:55:40Z",
            "published": "2023-10-18T05:59:41Z",
            "summary": "Heterogeneous information network (HIN), which contains rich semantics\ndepicted by meta-paths, has become a powerful tool to alleviate data sparsity\nin recommender systems. Existing HIN-based recommendations hold the data\ncentralized storage assumption and conduct centralized model training. However,\nthe real-world data is often stored in a distributed manner for privacy\nconcerns, resulting in the failure of centralized HIN-based recommendations. In\nthis paper, we suggest the HIN is partitioned into private HINs stored in the\nclient side and shared HINs in the server. Following this setting, we propose a\nfederated heterogeneous graph neural network (FedHGNN) based framework, which\ncan collaboratively train a recommendation model on distributed HINs without\nleaking user privacy. Specifically, we first formalize the privacy definition\nin the light of differential privacy for HIN-based federated recommendation,\nwhich aims to protect user-item interactions of private HIN as well as user's\nhigh-order patterns from shared HINs. To recover the broken meta-path based\nsemantics caused by distributed data storage and satisfy the proposed privacy,\nwe elaborately design a semantic-preserving user interactions publishing\nmethod, which locally perturbs user's high-order patterns as well as related\nuser-item interactions for publishing. After that, we propose a HGNN model for\nrecommendation, which conducts node- and semantic-level aggregations to capture\nrecovered semantics. Extensive experiments on three datasets demonstrate our\nmodel outperforms existing methods by a large margin (up to 34% in HR@10 and\n42% in NDCG@10) under an acceptable privacy budget.",
            "author": [
                "Bo Yan",
                "Yang Cao",
                "Haoyu Wang",
                "Wenchuan Yang",
                "Junping Du",
                "Chuan Shi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11730v2",
                "http://arxiv.org/pdf/2310.11730v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CR",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11723v1",
            "title": "Uncertainty in Automated Ontology Matching: Lessons Learned from an\n  Empirical Experimentation",
            "updated": "2023-10-18T05:42:51Z",
            "published": "2023-10-18T05:42:51Z",
            "summary": "Data integration is considered a classic research field and a pressing need\nwithin the information science community. Ontologies play a critical role in\nsuch a process by providing well-consolidated support to link and semantically\nintegrate datasets via interoperability. This paper approaches data integration\nfrom an application perspective, looking at techniques based on ontology\nmatching. An ontology-based process may only be considered adequate by assuming\nmanual matching of different sources of information. However, since the\napproach becomes unrealistic once the system scales up, automation of the\nmatching process becomes a compelling need. Therefore, we have conducted\nexperiments on actual data with the support of existing tools for automatic\nontology matching from the scientific community. Even considering a relatively\nsimple case study (i.e., the spatio-temporal alignment of global indicators),\noutcomes clearly show significant uncertainty resulting from errors and\ninaccuracies along the automated matching process. More concretely, this paper\naims to test on real-world data a bottom-up knowledge-building approach,\ndiscuss the lessons learned from the experimental results of the case study,\nand draw conclusions about uncertainty and uncertainty management in an\nautomated ontology matching process. While the most common evaluation metrics\nclearly demonstrate the unreliability of fully automated matching solutions,\nproperly designed semi-supervised approaches seem to be mature for a more\ngeneralized application.",
            "author": [
                "In\u00e8s Osman",
                "Salvatore F. Pileggi",
                "Sadok Ben Yahia"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11723v1",
                "http://arxiv.org/pdf/2310.11723v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11721v1",
            "title": "Chain-of-Thought Tuning: Masked Language Models can also Think Step By\n  Step in Natural Language Understanding",
            "updated": "2023-10-18T05:39:20Z",
            "published": "2023-10-18T05:39:20Z",
            "summary": "Chain-of-Thought (CoT) is a technique that guides Large Language Models\n(LLMs) to decompose complex tasks into multi-step reasoning through\nintermediate steps in natural language form. Briefly, CoT enables LLMs to think\nstep by step. However, although many Natural Language Understanding (NLU) tasks\nalso require thinking step by step, LLMs perform less well than small-scale\nMasked Language Models (MLMs). To migrate CoT from LLMs to MLMs, we propose\nChain-of-Thought Tuning (CoTT), a two-step reasoning framework based on prompt\ntuning, to implement step-by-step thinking for MLMs on NLU tasks. From the\nperspective of CoT, CoTT's two-step framework enables MLMs to implement task\ndecomposition; CoTT's prompt tuning allows intermediate steps to be used in\nnatural language form. Thereby, the success of CoT can be extended to NLU tasks\nthrough MLMs. To verify the effectiveness of CoTT, we conduct experiments on\ntwo NLU tasks: hierarchical classification and relation extraction, and the\nresults show that CoTT outperforms baselines and achieves state-of-the-art\nperformance.",
            "author": [
                "Caoyun Fan",
                "Jidong Tian",
                "Yitian Li",
                "Wenqing Chen",
                "Hao He",
                "Yaohui Jin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11721v1",
                "http://arxiv.org/pdf/2310.11721v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11715v2",
            "title": "Enhancing Low-resource Fine-grained Named Entity Recognition by\n  Leveraging Coarse-grained Datasets",
            "updated": "2023-11-13T13:18:58Z",
            "published": "2023-10-18T05:13:34Z",
            "summary": "Named Entity Recognition (NER) frequently suffers from the problem of\ninsufficient labeled data, particularly in fine-grained NER scenarios. Although\n$K$-shot learning techniques can be applied, their performance tends to\nsaturate when the number of annotations exceeds several tens of labels. To\novercome this problem, we utilize existing coarse-grained datasets that offer a\nlarge number of annotations. A straightforward approach to address this problem\nis pre-finetuning, which employs coarse-grained data for representation\nlearning. However, it cannot directly utilize the relationships between\nfine-grained and coarse-grained entities, although a fine-grained entity type\nis likely to be a subcategory of a coarse-grained entity type. We propose a\nfine-grained NER model with a Fine-to-Coarse(F2C) mapping matrix to leverage\nthe hierarchical structure explicitly. In addition, we present an inconsistency\nfiltering method to eliminate coarse-grained entities that are inconsistent\nwith fine-grained entity types to avoid performance degradation. Our\nexperimental results show that our method outperforms both $K$-shot learning\nand supervised learning methods when dealing with a small number of\nfine-grained annotations.",
            "author": [
                "Su Ah Lee",
                "Seokjin Oh",
                "Woohwan Jung"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11715v2",
                "http://arxiv.org/pdf/2310.11715v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11714v1",
            "title": "On the Evaluation of Generative Models in Distributed Learning Tasks",
            "updated": "2023-10-18T05:06:04Z",
            "published": "2023-10-18T05:06:04Z",
            "summary": "The evaluation of deep generative models including generative adversarial\nnetworks (GANs) and diffusion models has been extensively studied in the\nliterature. While the existing evaluation methods mainly target a centralized\nlearning problem with training data stored by a single client, many\napplications of generative models concern distributed learning settings, e.g.\nthe federated learning scenario, where training data are collected by and\ndistributed among several clients. In this paper, we study the evaluation of\ngenerative models in distributed learning tasks with heterogeneous data\ndistributions. First, we focus on the Fr\\'echet inception distance (FID) and\nconsider the following FID-based aggregate scores over the clients: 1) FID-avg\nas the mean of clients' individual FID scores, 2) FID-all as the FID distance\nof the trained model to the collective dataset containing all clients' data. We\nprove that the model rankings according to the FID-all and FID-avg scores could\nbe inconsistent, which can lead to different optimal generative models\naccording to the two aggregate scores. Next, we consider the kernel inception\ndistance (KID) and similarly define the KID-avg and KID-all aggregations.\nUnlike the FID case, we prove that KID-all and KID-avg result in the same\nrankings of generative models. We perform several numerical experiments on\nstandard image datasets and training schemes to support our theoretical\nfindings on the evaluation of generative models in distributed learning\nproblems.",
            "author": [
                "Zixiao Wang",
                "Farzan Farnia",
                "Zhenghao Lin",
                "Yunheng Shen",
                "Bei Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11714v1",
                "http://arxiv.org/pdf/2310.11714v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11710v2",
            "title": "Learning Co-Speech Gesture for Multimodal Aphasia Type Detection",
            "updated": "2023-10-20T05:43:28Z",
            "published": "2023-10-18T04:54:32Z",
            "summary": "Aphasia, a language disorder resulting from brain damage, requires accurate\nidentification of specific aphasia types, such as Broca's and Wernicke's\naphasia, for effective treatment. However, little attention has been paid to\ndeveloping methods to detect different types of aphasia. Recognizing the\nimportance of analyzing co-speech gestures for distinguish aphasia types, we\npropose a multimodal graph neural network for aphasia type detection using\nspeech and corresponding gesture patterns. By learning the correlation between\nthe speech and gesture modalities for each aphasia type, our model can generate\ntextual representations sensitive to gesture information, leading to accurate\naphasia type detection. Extensive experiments demonstrate the superiority of\nour approach over existing methods, achieving state-of-the-art results (F1\n84.2\\%). We also show that gesture features outperform acoustic features,\nhighlighting the significance of gesture expression in detecting aphasia types.\nWe provide the codes for reproducibility purposes.",
            "author": [
                "Daeun Lee",
                "Sejung Son",
                "Hyolim Jeon",
                "Seungbae Kim",
                "Jinyoung Han"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11710v2",
                "http://arxiv.org/pdf/2310.11710v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11709v2",
            "title": "Live Graph Lab: Towards Open, Dynamic and Real Transaction Graphs with\n  NFT",
            "updated": "2023-10-19T00:57:17Z",
            "published": "2023-10-18T04:54:22Z",
            "summary": "Numerous studies have been conducted to investigate the properties of\nlarge-scale temporal graphs. Despite the ubiquity of these graphs in real-world\nscenarios, it's usually impractical for us to obtain the whole real-time graphs\ndue to privacy concerns and technical limitations. In this paper, we introduce\nthe concept of {\\it Live Graph Lab} for temporal graphs, which enables open,\ndynamic and real transaction graphs from blockchains. Among them, Non-fungible\ntokens (NFTs) have become one of the most prominent parts of blockchain over\nthe past several years. With more than \\$40 billion market capitalization, this\ndecentralized ecosystem produces massive, anonymous and real transaction\nactivities, which naturally forms a complicated transaction network. However,\nthere is limited understanding about the characteristics of this emerging NFT\necosystem from a temporal graph analysis perspective. To mitigate this gap, we\ninstantiate a live graph with NFT transaction network and investigate its\ndynamics to provide new observations and insights. Specifically, through\ndownloading and parsing the NFT transaction activities, we obtain a temporal\ngraph with more than 4.5 million nodes and 124 million edges. Then, a series of\nmeasurements are presented to understand the properties of the NFT ecosystem.\nThrough comparisons with social, citation, and web networks, our analyses give\nintriguing findings and point out potential directions for future exploration.\nFinally, we also study machine learning models in this live graph to enrich the\ncurrent datasets and provide new opportunities for the graph community. The\nsource codes and dataset are available at https://livegraphlab.github.io.",
            "author": [
                "Zhen Zhang",
                "Bingqiao Luo",
                "Shengliang Lu",
                "Bingsheng He"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11709v2",
                "http://arxiv.org/pdf/2310.11709v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11708v1",
            "title": "Experimental Results of Underwater Sound Speed Profile Inversion by\n  Few-shot Multi-task Learning",
            "updated": "2023-10-18T04:53:01Z",
            "published": "2023-10-18T04:53:01Z",
            "summary": "Underwater Sound Speed Profile (SSP) distribution has great influence on the\npropagation mode of acoustic signal, thus the fast and accurate estimation of\nSSP is of great importance in building underwater observation systems. The\nstate-of-the-art SSP inversion methods include frameworks of matched field\nprocessing (MFP), compressive sensing (CS), and feedforeward neural networks\n(FNN), among which the FNN shows better real-time performance while maintain\nthe same level of accuracy. However, the training of FNN needs quite a lot\nhistorical SSP samples, which is diffcult to be satisfied in many ocean areas.\nThis situation is called few-shot learning. To tackle this issue, we propose a\nmulti-task learning (MTL) model with partial parameter sharing among different\ntraning tasks. By MTL, common features could be extracted, thus accelerating\nthe learning process on given tasks, and reducing the demand for reference\nsamples, so as to enhance the generalization ability in few-shot learning. To\nverify the feasibility and effectiveness of MTL, a deep-ocean experiment was\nheld in April 2023 at the South China Sea. Results shows that MTL outperforms\nthe state-of-the-art methods in terms of accuracy for SSP inversion, while\ninherits the real-time advantage of FNN during the inversion stage.",
            "author": [
                "Wei Huang",
                "Fan Gao",
                "Junting Wang",
                "Hao Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11708v1",
                "http://arxiv.org/pdf/2310.11708v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11707v1",
            "title": "Learning under Label Proportions for Text Classification",
            "updated": "2023-10-18T04:39:25Z",
            "published": "2023-10-18T04:39:25Z",
            "summary": "We present one of the preliminary NLP works under the challenging setup of\nLearning from Label Proportions (LLP), where the data is provided in an\naggregate form called bags and only the proportion of samples in each class as\nthe ground truth. This setup is inline with the desired characteristics of\ntraining models under Privacy settings and Weakly supervision. By\ncharacterizing some irregularities of the most widely used baseline technique\nDLLP, we propose a novel formulation that is also robust. This is accompanied\nwith a learnability result that provides a generalization bound under LLP.\nCombining this formulation with a self-supervised objective, our method\nachieves better results as compared to the baselines in almost 87% of the\nexperimental configurations which include large scale models for both long and\nshort range texts across multiple metrics.",
            "author": [
                "Jatin Chauhan",
                "Xiaoxuan Wang",
                "Wei Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11707v1",
                "http://arxiv.org/pdf/2310.11707v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11706v1",
            "title": "MalDICT: Benchmark Datasets on Malware Behaviors, Platforms,\n  Exploitation, and Packers",
            "updated": "2023-10-18T04:36:26Z",
            "published": "2023-10-18T04:36:26Z",
            "summary": "Existing research on malware classification focuses almost exclusively on two\ntasks: distinguishing between malicious and benign files and classifying\nmalware by family. However, malware can be categorized according to many other\ntypes of attributes, and the ability to identify these attributes in\nnewly-emerging malware using machine learning could provide significant value\nto analysts. In particular, we have identified four tasks which are\nunder-represented in prior work: classification by behaviors that malware\nexhibit, platforms that malware run on, vulnerabilities that malware exploit,\nand packers that malware are packed with. To obtain labels for training and\nevaluating ML classifiers on these tasks, we created an antivirus (AV) tagging\ntool called ClarAVy. ClarAVy's sophisticated AV label parser distinguishes\nitself from prior AV-based taggers, with the ability to accurately parse 882\ndifferent AV label formats used by 90 different AV products. We are releasing\nbenchmark datasets for each of these four classification tasks, tagged using\nClarAVy and comprising nearly 5.5 million malicious files in total. Our malware\nbehavior dataset includes 75 distinct tags - nearly 7x more than the only prior\nbenchmark dataset with behavioral tags. To our knowledge, we are the first to\nrelease datasets with malware platform and packer tags.",
            "author": [
                "Robert J. Joyce",
                "Edward Raff",
                "Charles Nicholas",
                "James Holt"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11706v1",
                "http://arxiv.org/pdf/2310.11706v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11702v1",
            "title": "DPF-Nutrition: Food Nutrition Estimation via Depth Prediction and Fusion",
            "updated": "2023-10-18T04:23:05Z",
            "published": "2023-10-18T04:23:05Z",
            "summary": "A reasonable and balanced diet is essential for maintaining good health. With\nthe advancements in deep learning, automated nutrition estimation method based\non food images offers a promising solution for monitoring daily nutritional\nintake and promoting dietary health. While monocular image-based nutrition\nestimation is convenient, efficient, and economical, the challenge of limited\naccuracy remains a significant concern. To tackle this issue, we proposed\nDPF-Nutrition, an end-to-end nutrition estimation method using monocular\nimages. In DPF-Nutrition, we introduced a depth prediction module to generate\ndepth maps, thereby improving the accuracy of food portion estimation.\nAdditionally, we designed an RGB-D fusion module that combined monocular images\nwith the predicted depth information, resulting in better performance for\nnutrition estimation. To the best of our knowledge, this was the pioneering\neffort that integrated depth prediction and RGB-D fusion techniques in food\nnutrition estimation. Comprehensive experiments performed on Nutrition5k\nevaluated the effectiveness and efficiency of DPF-Nutrition.",
            "author": [
                "Yuzhe Han",
                "Qimin Cheng",
                "Wenjin Wu",
                "Ziyang Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11702v1",
                "http://arxiv.org/pdf/2310.11702v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11700v1",
            "title": "Runner re-identification from single-view video in the open-world\n  setting",
            "updated": "2023-10-18T04:15:39Z",
            "published": "2023-10-18T04:15:39Z",
            "summary": "In many sports, player re-identification is crucial for automatic video\nprocessing and analysis. However, most of the current studies on player\nre-identification in multi- or single-view sports videos focus on\nre-identification in the closed-world setting using labeled image dataset, and\nplayer re-identification in the open-world setting for automatic video analysis\nis not well developed. In this paper, we propose a runner re-identification\nsystem that directly processes single-view video to address the open-world\nsetting. In the open-world setting, we cannot use labeled dataset and have to\nprocess video directly. The proposed system automatically processes raw video\nas input to identify runners, and it can identify runners even when they are\nframed out multiple times. For the automatic processing, we first detect the\nrunners in the video using the pre-trained YOLOv8 and the fine-tuned\nEfficientNet. We then track the runners using ByteTrack and detect their shoes\nwith the fine-tuned YOLOv8. Finally, we extract the image features of the\nrunners using an unsupervised method using the gated recurrent unit autoencoder\nmodel. To improve the accuracy of runner re-identification, we use dynamic\nfeatures of running sequence images. We evaluated the system on a running\npractice video dataset and showed that the proposed method identified runners\nwith higher accuracy than one of the state-of-the-art models in unsupervised\nre-identification. We also showed that our unsupervised running dynamic feature\nextractor was effective for runner re-identification. Our runner\nre-identification system can be useful for the automatic analysis of running\nvideos.",
            "author": [
                "Tomohiro Suzuki",
                "Kazushi Tsutsui",
                "Kazuya Takeda",
                "Keisuke Fujii"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11700v1",
                "http://arxiv.org/pdf/2310.11700v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12184v2",
            "title": "Architectural Implications of GNN Aggregation Programming Abstractions",
            "updated": "2023-10-21T00:30:32Z",
            "published": "2023-10-18T04:13:48Z",
            "summary": "Graph neural networks (GNNs) have gained significant popularity due to the\npowerful capability to extract useful representations from graph data. As the\nneed for efficient GNN computation intensifies, a variety of programming\nabstractions designed for optimizing GNN Aggregation have emerged to facilitate\nacceleration. However, there is no comprehensive evaluation and analysis upon\nexisting abstractions, thus no clear consensus on which approach is better. In\nthis letter, we classify existing programming abstractions for GNN Aggregation\nby the dimension of data organization and propagation method. By constructing\nthese abstractions on a state-of-the-art GNN library, we perform a thorough and\ndetailed characterization study to compare their performance and efficiency,\nand provide several insights on future GNN acceleration based on our analysis.",
            "author": [
                "Yingjie Qi",
                "Jianlei Yang",
                "Ao Zhou",
                "Tong Qiao",
                "Chunming Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12184v2",
                "http://arxiv.org/pdf/2310.12184v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.PF"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11696v1",
            "title": "MOHO: Learning Single-view Hand-held Object Reconstruction with\n  Multi-view Occlusion-Aware Supervision",
            "updated": "2023-10-18T03:57:06Z",
            "published": "2023-10-18T03:57:06Z",
            "summary": "Previous works concerning single-view hand-held object reconstruction\ntypically utilize supervision from 3D ground truth models, which are hard to\ncollect in real world. In contrast, abundant videos depicting hand-object\ninteractions can be accessed easily with low cost, although they only give\npartial object observations with complex occlusion. In this paper, we present\nMOHO to reconstruct hand-held object from a single image with multi-view\nsupervision from hand-object videos, tackling two predominant challenges\nincluding object's self-occlusion and hand-induced occlusion. MOHO inputs\nsemantic features indicating visible object parts and geometric embeddings\nprovided by hand articulations as partial-to-full cues to resist object's\nself-occlusion, so as to recover full shape of the object. Meanwhile, a novel\n2D-3D hand-occlusion-aware training scheme following the synthetic-to-real\nparadigm is proposed to release hand-induced occlusion. In the synthetic\npre-training stage, 2D-3D hand-object correlations are constructed by\nsupervising MOHO with rendered images to complete the hand-concealed regions of\nthe object in both 2D and 3D space. Subsequently, MOHO is finetuned in real\nworld by the mask-weighted volume rendering supervision adopting hand-object\ncorrelations obtained during pre-training. Extensive experiments on HO3D and\nDexYCB datasets demonstrate that 2D-supervised MOHO gains superior results\nagainst 3D-supervised methods by a large margin. Codes and key assets will be\nreleased soon.",
            "author": [
                "Chenyangguang Zhang",
                "Guanlong Jiao",
                "Yan Di",
                "Ziqin Huang",
                "Gu Wang",
                "Ruida Zhang",
                "Bowen Fu",
                "Federico Tombari",
                "Xiangyang Ji"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11696v1",
                "http://arxiv.org/pdf/2310.11696v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11693v1",
            "title": "AUC-mixup: Deep AUC Maximization with Mixup",
            "updated": "2023-10-18T03:43:11Z",
            "published": "2023-10-18T03:43:11Z",
            "summary": "While deep AUC maximization (DAM) has shown remarkable success on imbalanced\nmedical tasks, e.g., chest X-rays classification and skin lesions\nclassification, it could suffer from severe overfitting when applied to small\ndatasets due to its aggressive nature of pushing prediction scores of positive\ndata away from that of negative data. This paper studies how to improve\ngeneralization of DAM by mixup data augmentation -- an approach that is widely\nused for improving generalization of the cross-entropy loss based deep learning\nmethods. %For overfitting issues arising from limited data, the common approach\nis to employ mixup data augmentation to boost the models' generalization\nperformance by enriching the training data. However, AUC is defined over\npositive and negative pairs, which makes it challenging to incorporate mixup\ndata augmentation into DAM algorithms. To tackle this challenge, we employ the\nAUC margin loss and incorporate soft labels into the formulation to effectively\nlearn from data generated by mixup augmentation, which is referred to as the\nAUC-mixup loss. Our experimental results demonstrate the effectiveness of the\nproposed AUC-mixup methods on imbalanced benchmark and medical image datasets\ncompared to standard DAM training methods.",
            "author": [
                "Jianzhi Xv",
                "Gang Li",
                "Tianbao Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11693v1",
                "http://arxiv.org/pdf/2310.11693v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11690v1",
            "title": "Deep learning based on Transformer architecture for power system\n  short-term voltage stability assessment with class imbalance",
            "updated": "2023-10-18T03:36:10Z",
            "published": "2023-10-18T03:36:10Z",
            "summary": "Most existing data-driven power system short-term voltage stability\nassessment (STVSA) approaches presume class-balanced input data. However, in\npractical applications, the occurrence of short-term voltage instability\nfollowing a disturbance is minimal, leading to a significant class imbalance\nproblem and a consequent decline in classifier performance. This work proposes\na Transformer-based STVSA method to address this challenge. By utilizing the\nbasic Transformer architecture, a stability assessment Transformer (StaaT) is\ndeveloped {as a classification model to reflect the correlation between the\noperational states of the system and the resulting stability outcomes}. To\ncombat the negative impact of imbalanced datasets, this work employs a\nconditional Wasserstein generative adversarial network with gradient penalty\n(CWGAN-GP) for synthetic data generation, aiding in the creation of a balanced,\nrepresentative training set for the classifier. Semi-supervised clustering\nlearning is implemented to enhance clustering quality, addressing the lack of a\nunified quantitative criterion for short-term voltage stability. {Numerical\ntests on the IEEE 39-bus test system extensively demonstrate that the proposed\nmethod exhibits robust performance under class imbalances up to 100:1 and noisy\nenvironments, and maintains consistent effectiveness even with an increased\npenetration of renewable energy}. Comparative results reveal that the CWGAN-GP\ngenerates more balanced datasets than traditional oversampling methods and that\nthe StaaT outperforms other deep learning algorithms. This study presents a\ncompelling solution for real-world STVSA applications that often face class\nimbalance and data noise challenges.",
            "author": [
                "Yang Li",
                "Jiting Cao",
                "Yan Xu",
                "Lipeng Zhu",
                "Zhao Yang Dong"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.rser.2023.113913",
                "http://arxiv.org/abs/2310.11690v1",
                "http://arxiv.org/pdf/2310.11690v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11689v2",
            "title": "Adaptation with Self-Evaluation to Improve Selective Prediction in LLMs",
            "updated": "2023-11-11T19:29:42Z",
            "published": "2023-10-18T03:34:59Z",
            "summary": "Large language models (LLMs) have recently shown great advances in a variety\nof tasks, including natural language understanding and generation. However,\ntheir use in high-stakes decision-making scenarios is still limited due to the\npotential for errors. Selective prediction is a technique that can be used to\nimprove the reliability of the LLMs by allowing them to abstain from making\npredictions when they are unsure of the answer. In this work, we propose a\nnovel framework for adaptation with self-evaluation to improve the selective\nprediction performance of LLMs. Our framework is based on the idea of using\nparameter-efficient tuning to adapt the LLM to the specific task at hand while\nimproving its ability to perform self-evaluation. We evaluate our method on a\nvariety of question-answering (QA) datasets and show that it outperforms\nstate-of-the-art selective prediction methods. For example, on the CoQA\nbenchmark, our method improves the AUACC from 91.23% to 92.63% and improves the\nAUROC from 74.61% to 80.25%.",
            "author": [
                "Jiefeng Chen",
                "Jinsung Yoon",
                "Sayna Ebrahimi",
                "Sercan O Arik",
                "Tomas Pfister",
                "Somesh Jha"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11689v2",
                "http://arxiv.org/pdf/2310.11689v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11685v1",
            "title": "Superiority of Softmax: Unveiling the Performance Edge Over Linear\n  Attention",
            "updated": "2023-10-18T03:17:57Z",
            "published": "2023-10-18T03:17:57Z",
            "summary": "Large transformer models have achieved state-of-the-art results in numerous\nnatural language processing tasks. Among the pivotal components of the\ntransformer architecture, the attention mechanism plays a crucial role in\ncapturing token interactions within sequences through the utilization of\nsoftmax function.\n  Conversely, linear attention presents a more computationally efficient\nalternative by approximating the softmax operation with linear complexity.\nHowever, it exhibits substantial performance degradation when compared to the\ntraditional softmax attention mechanism.\n  In this paper, we bridge the gap in our theoretical understanding of the\nreasons behind the practical performance gap between softmax and linear\nattention. By conducting a comprehensive comparative analysis of these two\nattention mechanisms, we shed light on the underlying reasons for why softmax\nattention outperforms linear attention in most scenarios.",
            "author": [
                "Yichuan Deng",
                "Zhao Song",
                "Tianyi Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11685v1",
                "http://arxiv.org/pdf/2310.11685v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11684v1",
            "title": "Quantum Acceleration of Infinite Horizon Average-Reward Reinforcement\n  Learning",
            "updated": "2023-10-18T03:17:51Z",
            "published": "2023-10-18T03:17:51Z",
            "summary": "This paper investigates the potential of quantum acceleration in addressing\ninfinite horizon Markov Decision Processes (MDPs) to enhance average reward\noutcomes. We introduce an innovative quantum framework for the agent's\nengagement with an unknown MDP, extending the conventional interaction\nparadigm. Our approach involves the design of an optimism-driven tabular\nReinforcement Learning algorithm that harnesses quantum signals acquired by the\nagent through efficient quantum mean estimation techniques. Through thorough\ntheoretical analysis, we demonstrate that the quantum advantage in mean\nestimation leads to exponential advancements in regret guarantees for infinite\nhorizon Reinforcement Learning. Specifically, the proposed Quantum algorithm\nachieves a regret bound of $\\tilde{\\mathcal{O}}(1)$, a significant improvement\nover the $\\tilde{\\mathcal{O}}(\\sqrt{T})$ bound exhibited by classical\ncounterparts.",
            "author": [
                "Bhargav Ganguly",
                "Vaneet Aggarwal"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11684v1",
                "http://arxiv.org/pdf/2310.11684v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11678v1",
            "title": "Using Experience Classification for Training Non-Markovian Tasks",
            "updated": "2023-10-18T03:00:59Z",
            "published": "2023-10-18T03:00:59Z",
            "summary": "Unlike the standard Reinforcement Learning (RL) model, many real-world tasks\nare non-Markovian, whose rewards are predicated on state history rather than\nsolely on the current state. Solving a non-Markovian task, frequently applied\nin practical applications such as autonomous driving, financial trading, and\nmedical diagnosis, can be quite challenging. We propose a novel RL approach to\nachieve non-Markovian rewards expressed in temporal logic LTL$_f$ (Linear\nTemporal Logic over Finite Traces). To this end, an encoding of linear\ncomplexity from LTL$_f$ into MDPs (Markov Decision Processes) is introduced to\ntake advantage of advanced RL algorithms. Then, a prioritized experience replay\ntechnique based on the automata structure (semantics equivalent to LTL$_f$\nspecification) is utilized to improve the training process. We empirically\nevaluate several benchmark problems augmented with non-Markovian tasks to\ndemonstrate the feasibility and effectiveness of our approach.",
            "author": [
                "Ruixuan Miao",
                "Xu Lu",
                "Cong Tian",
                "Bin Yu",
                "Zhenhua Duan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11678v1",
                "http://arxiv.org/pdf/2310.11678v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.FL",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11677v1",
            "title": "Improved Sample Complexity Analysis of Natural Policy Gradient Algorithm\n  with General Parameterization for Infinite Horizon Discounted Reward Markov\n  Decision Processes",
            "updated": "2023-10-18T03:00:15Z",
            "published": "2023-10-18T03:00:15Z",
            "summary": "We consider the problem of designing sample efficient learning algorithms for\ninfinite horizon discounted reward Markov Decision Process. Specifically, we\npropose the Accelerated Natural Policy Gradient (ANPG) algorithm that utilizes\nan accelerated stochastic gradient descent process to obtain the natural policy\ngradient. ANPG achieves $\\mathcal{O}({\\epsilon^{-2}})$ sample complexity and\n$\\mathcal{O}(\\epsilon^{-1})$ iteration complexity with general parameterization\nwhere $\\epsilon$ defines the optimality error. This improves the\nstate-of-the-art sample complexity by a $\\log(\\frac{1}{\\epsilon})$ factor. ANPG\nis a first-order algorithm and unlike some existing literature, does not\nrequire the unverifiable assumption that the variance of importance sampling\n(IS) weights is upper bounded. In the class of Hessian-free and IS-free\nalgorithms, ANPG beats the best-known sample complexity by a factor of\n$\\mathcal{O}(\\epsilon^{-\\frac{1}{2}})$ and simultaneously matches their\nstate-of-the-art iteration complexity.",
            "author": [
                "Washim Uddin Mondal",
                "Vaneet Aggarwal"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11677v1",
                "http://arxiv.org/pdf/2310.11677v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11676v3",
            "title": "PREM: A Simple Yet Effective Approach for Node-Level Graph Anomaly\n  Detection",
            "updated": "2023-11-28T03:42:30Z",
            "published": "2023-10-18T02:59:57Z",
            "summary": "Node-level graph anomaly detection (GAD) plays a critical role in identifying\nanomalous nodes from graph-structured data in various domains such as medicine,\nsocial networks, and e-commerce. However, challenges have arisen due to the\ndiversity of anomalies and the dearth of labeled data. Existing methodologies -\nreconstruction-based and contrastive learning - while effective, often suffer\nfrom efficiency issues, stemming from their complex objectives and elaborate\nmodules. To improve the efficiency of GAD, we introduce a simple method termed\nPREprocessing and Matching (PREM for short). Our approach streamlines GAD,\nreducing time and memory consumption while maintaining powerful anomaly\ndetection capabilities. Comprising two modules - a pre-processing module and an\nego-neighbor matching module - PREM eliminates the necessity for\nmessage-passing propagation during training, and employs a simple contrastive\nloss, leading to considerable reductions in training time and memory usage.\nMoreover, through rigorous evaluations of five real-world datasets, our method\ndemonstrated robustness and effectiveness. Notably, when validated on the ACM\ndataset, PREM achieved a 5% improvement in AUC, a 9-fold increase in training\nspeed, and sharply reduce memory usage compared to the most efficient baseline.",
            "author": [
                "Junjun Pan",
                "Yixin Liu",
                "Yizhen Zheng",
                "Shirui Pan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11676v3",
                "http://arxiv.org/pdf/2310.11676v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11672v2",
            "title": "Open-ended Commonsense Reasoning with Unrestricted Answer Scope",
            "updated": "2023-10-27T13:50:09Z",
            "published": "2023-10-18T02:45:54Z",
            "summary": "Open-ended Commonsense Reasoning is defined as solving a commonsense question\nwithout providing 1) a short list of answer candidates and 2) a pre-defined\nanswer scope. Conventional ways of formulating the commonsense question into a\nquestion-answering form or utilizing external knowledge to learn\nretrieval-based methods are less applicable in the open-ended setting due to an\ninherent challenge. Without pre-defining an answer scope or a few candidates,\nopen-ended commonsense reasoning entails predicting answers by searching over\nan extremely large searching space. Moreover, most questions require implicit\nmulti-hop reasoning, which presents even more challenges to our problem. In\nthis work, we leverage pre-trained language models to iteratively retrieve\nreasoning paths on the external knowledge base, which does not require\ntask-specific supervision. The reasoning paths can help to identify the most\nprecise answer to the commonsense question. We conduct experiments on two\ncommonsense benchmark datasets. Compared to other approaches, our proposed\nmethod achieves better performance both quantitatively and qualitatively.",
            "author": [
                "Chen Ling",
                "Xuchao Zhang",
                "Xujiang Zhao",
                "Yanchi Liu",
                "Wei Cheng",
                "Mika Oishi",
                "Takao Osaki",
                "Katsushi Matsuda",
                "Haifeng Chen",
                "Liang Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11672v2",
                "http://arxiv.org/pdf/2310.11672v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11670v3",
            "title": "Prototype-based HyperAdapter for Sample-Efficient Multi-task Tuning",
            "updated": "2023-11-11T15:30:30Z",
            "published": "2023-10-18T02:42:17Z",
            "summary": "Parameter-efficient fine-tuning (PEFT) has shown its effectiveness in\nadapting the pre-trained language models to downstream tasks while only\nupdating a small number of parameters. Despite the success, most existing\nmethods independently adapt to each task without considering knowledge transfer\nbetween tasks and are limited to low-data regimes. To overcome this issue, we\npropose Prototype-based HyperAdapter (PHA), a novel framework built on the\nadapter-tuning and hypernetwork. It introduces an instance-dense retriever and\na prototypical hypernetwork to generate the conditional modules in a\nsample-efficient manner. This leads to comparable performance improvements\nagainst existing PEFT methods on multi-task learning and few-shot transfer\nlearning. More importantly, when the available data size gets smaller, our\nmethod outperforms other strong baselines by a large margin. Based on our\nextensive empirical experiments across various datasets, we demonstrate that\nPHA strikes a better trade-off between trainable parameters, accuracy on stream\ntasks, and sample efficiency.",
            "author": [
                "Hao Zhao",
                "Jie Fu",
                "Zhaofeng He"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11670v3",
                "http://arxiv.org/pdf/2310.11670v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11667v1",
            "title": "SOTOPIA: Interactive Evaluation for Social Intelligence in Language\n  Agents",
            "updated": "2023-10-18T02:27:01Z",
            "published": "2023-10-18T02:27:01Z",
            "summary": "Humans are social beings; we pursue social goals in our daily interactions,\nwhich is a crucial aspect of social intelligence. Yet, AI systems' abilities in\nthis realm remain elusive. We present SOTOPIA, an open-ended environment to\nsimulate complex social interactions between artificial agents and evaluate\ntheir social intelligence. In our environment, agents role-play and interact\nunder a wide variety of scenarios; they coordinate, collaborate, exchange, and\ncompete with each other to achieve complex social goals. We simulate the\nrole-play interaction between LLM-based agents and humans within this task\nspace and evaluate their performance with a holistic evaluation framework\ncalled SOTOPIA-Eval. With SOTOPIA, we find significant differences between\nthese models in terms of their social intelligence, and we identify a subset of\nSOTOPIA scenarios, SOTOPIA-hard, that is generally challenging for all models.\nWe find that on this subset, GPT-4 achieves a significantly lower goal\ncompletion rate than humans and struggles to exhibit social commonsense\nreasoning and strategic communication skills. These findings demonstrate\nSOTOPIA's promise as a general platform for research on evaluating and\nimproving social intelligence in artificial agents.",
            "author": [
                "Xuhui Zhou",
                "Hao Zhu",
                "Leena Mathur",
                "Ruohong Zhang",
                "Haofei Yu",
                "Zhengyang Qi",
                "Louis-Philippe Morency",
                "Yonatan Bisk",
                "Daniel Fried",
                "Graham Neubig",
                "Maarten Sap"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11667v1",
                "http://arxiv.org/pdf/2310.11667v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11666v1",
            "title": "Non-empirical shape dynamics of heavy nuclei with multi-task deep\n  learning",
            "updated": "2023-10-18T02:22:59Z",
            "published": "2023-10-18T02:22:59Z",
            "summary": "A microscopic description of nuclear fission represents one of the most\nchallenging problems in nuclear theory. While phenomenological coordinates,\nsuch as multipole moments, have often been employed to describe fission, it is\nnot obvious whether these parameters fully reflect the shape dynamics of\ninterest. We here propose a novel method to extract collective coordinates,\nwhich are free from phenomenology, based on multi-task deep learning in\nconjunction with a density functional theory (DFT). To this end, we first\nintroduce randomly generated external fields to a Skyrme-EDF and construct a\nset of nuclear number densities and binding energies for deformed states of\n${}^{236}$U around the ground state. By training a neural network on such\ndataset with a combination of an autoencoder and supervised learning, we\nsuccessfully identify a two-dimensional latent variables that accurately\nreproduce both the energies and the densities of the original Skyrme-EDF\ncalculations, within a mean absolute error of 113 keV for the energies. In\ncontrast, when multipole moments are used as latent variables for training in\nconstructing the decoders, we find that the training data for the binding\nenergies are reproduced only within 2 MeV. This implies that conventional\nmultipole moments do not provide fully adequate variables for a shape dynamics\nof heavy nuclei.",
            "author": [
                "N. Hizawa",
                "K. Hagino"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11666v1",
                "http://arxiv.org/pdf/2310.11666v1"
            ],
            "primary_category": "nucl-th",
            "category": [
                "nucl-th",
                "physics.data-an"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11664v1",
            "title": "Hetero$^2$Net: Heterophily-aware Representation Learning on\n  Heterogenerous Graphs",
            "updated": "2023-10-18T02:19:12Z",
            "published": "2023-10-18T02:19:12Z",
            "summary": "Real-world graphs are typically complex, exhibiting heterogeneity in the\nglobal structure, as well as strong heterophily within local neighborhoods.\nWhile a growing body of literature has revealed the limitations of common graph\nneural networks (GNNs) in handling homogeneous graphs with heterophily, little\nwork has been conducted on investigating the heterophily properties in the\ncontext of heterogeneous graphs. To bridge this research gap, we identify the\nheterophily in heterogeneous graphs using metapaths and propose two practical\nmetrics to quantitatively describe the levels of heterophily. Through in-depth\ninvestigations on several real-world heterogeneous graphs exhibiting varying\nlevels of heterophily, we have observed that heterogeneous graph neural\nnetworks (HGNNs), which inherit many mechanisms from GNNs designed for\nhomogeneous graphs, fail to generalize to heterogeneous graphs with heterophily\nor low level of homophily. To address the challenge, we present Hetero$^2$Net,\na heterophily-aware HGNN that incorporates both masked metapath prediction and\nmasked label prediction tasks to effectively and flexibly handle both\nhomophilic and heterophilic heterogeneous graphs. We evaluate the performance\nof Hetero$^2$Net on five real-world heterogeneous graph benchmarks with varying\nlevels of heterophily. The results demonstrate that Hetero$^2$Net outperforms\nstrong baselines in the semi-supervised node classification task, providing\nvaluable insights into effectively handling more complex heterogeneous graphs.",
            "author": [
                "Jintang Li",
                "Zheng Wei",
                "Jiawang Dan",
                "Jing Zhou",
                "Yuchang Zhu",
                "Ruofan Wu",
                "Baokun Wang",
                "Zhang Zhen",
                "Changhua Meng",
                "Hong Jin",
                "Zibin Zheng",
                "Liang Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11664v1",
                "http://arxiv.org/pdf/2310.11664v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11657v1",
            "title": "ChatGPT-guided Semantics for Zero-shot Learning",
            "updated": "2023-10-18T02:07:22Z",
            "published": "2023-10-18T02:07:22Z",
            "summary": "Zero-shot learning (ZSL) aims to classify objects that are not observed or\nseen during training. It relies on class semantic description to transfer\nknowledge from the seen classes to the unseen classes. Existing methods of\nobtaining class semantics include manual attributes or automatic word vectors\nfrom language models (like word2vec). We know attribute annotation is costly,\nwhereas automatic word-vectors are relatively noisy. To address this problem,\nwe explore how ChatGPT, a large language model, can enhance class semantics for\nZSL tasks. ChatGPT can be a helpful source to obtain text descriptions for each\nclass containing related attributes and semantics. We use the word2vec model to\nget a word vector using the texts from ChatGPT. Then, we enrich word vectors by\ncombining the word embeddings from class names and descriptions generated by\nChatGPT. More specifically, we leverage ChatGPT to provide extra supervision\nfor the class description, eventually benefiting ZSL models. We evaluate our\napproach on various 2D image (CUB and AwA) and 3D point cloud (ModelNet10,\nModelNet40, and ScanObjectNN) datasets and show that it improves ZSL\nperformance. Our work contributes to the ZSL literature by applying ChatGPT for\nclass semantics enhancement and proposing a novel word vector fusion method.",
            "author": [
                "Fahimul Hoque Shubho",
                "Townim Faisal Chowdhury",
                "Ali Cheraghian",
                "Morteza Saberi",
                "Nabeel Mohammed",
                "Shafin Rahman"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11657v1",
                "http://arxiv.org/pdf/2310.11657v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11654v1",
            "title": "Subject-specific Deep Neural Networks for Count Data with\n  High-cardinality Categorical Features",
            "updated": "2023-10-18T01:54:48Z",
            "published": "2023-10-18T01:54:48Z",
            "summary": "There is a growing interest in subject-specific predictions using deep neural\nnetworks (DNNs) because real-world data often exhibit correlations, which has\nbeen typically overlooked in traditional DNN frameworks. In this paper, we\npropose a novel hierarchical likelihood learning framework for introducing\ngamma random effects into the Poisson DNN, so as to improve the prediction\nperformance by capturing both nonlinear effects of input variables and\nsubject-specific cluster effects. The proposed method simultaneously yields\nmaximum likelihood estimators for fixed parameters and best unbiased predictors\nfor random effects by optimizing a single objective function. This approach\nenables a fast end-to-end algorithm for handling clustered count data, which\noften involve high-cardinality categorical features. Furthermore,\nstate-of-the-art network architectures can be easily implemented into the\nproposed h-likelihood framework. As an example, we introduce multi-head\nattention layer and a sparsemax function, which allows feature selection in\nhigh-dimensional settings. To enhance practical performance and learning\nefficiency, we present an adjustment procedure for prediction of random\nparameters and a method-of-moments estimator for pretraining of variance\ncomponent. Various experiential studies and real data analyses confirm the\nadvantages of our proposed methods.",
            "author": [
                "Hangbin Lee",
                "Il Do Ha",
                "Changha Hwang",
                "Youngjo Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11654v1",
                "http://arxiv.org/pdf/2310.11654v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11641v1",
            "title": "Cloud-Magnetic Resonance Imaging System: In the Era of 6G and Artificial\n  Intelligence",
            "updated": "2023-10-18T00:35:05Z",
            "published": "2023-10-18T00:35:05Z",
            "summary": "Magnetic Resonance Imaging (MRI) plays an important role in medical\ndiagnosis, generating petabytes of image data annually in large hospitals. This\nvoluminous data stream requires a significant amount of network bandwidth and\nextensive storage infrastructure. Additionally, local data processing demands\nsubstantial manpower and hardware investments. Data isolation across different\nhealthcare institutions hinders cross-institutional collaboration in clinics\nand research. In this work, we anticipate an innovative MRI system and its four\ngenerations that integrate emerging distributed cloud computing, 6G bandwidth,\nedge computing, federated learning, and blockchain technology. This system is\ncalled Cloud-MRI, aiming at solving the problems of MRI data storage security,\ntransmission speed, AI algorithm maintenance, hardware upgrading, and\ncollaborative work. The workflow commences with the transformation of k-space\nraw data into the standardized Imaging Society for Magnetic Resonance in\nMedicine Raw Data (ISMRMRD) format. Then, the data are uploaded to the cloud or\nedge nodes for fast image reconstruction, neural network training, and\nautomatic analysis. Then, the outcomes are seamlessly transmitted to clinics or\nresearch institutes for diagnosis and other services. The Cloud-MRI system will\nsave the raw imaging data, reduce the risk of data loss, facilitate\ninter-institutional medical collaboration, and finally improve diagnostic\naccuracy and work efficiency.",
            "author": [
                "Yirong Zhou",
                "Yanhuang Wu",
                "Yuhan Su",
                "Jing Li",
                "Jianyun Cai",
                "Yongfu You",
                "Di Guo",
                "Xiaobo Qu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11641v1",
                "http://arxiv.org/pdf/2310.11641v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.AI",
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11640v1",
            "title": "Free-text Keystroke Authentication using Transformers: A Comparative\n  Study of Architectures and Loss Functions",
            "updated": "2023-10-18T00:34:26Z",
            "published": "2023-10-18T00:34:26Z",
            "summary": "Keystroke biometrics is a promising approach for user identification and\nverification, leveraging the unique patterns in individuals' typing behavior.\nIn this paper, we propose a Transformer-based network that employs\nself-attention to extract informative features from keystroke sequences,\nsurpassing the performance of traditional Recurrent Neural Networks. We explore\ntwo distinct architectures, namely bi-encoder and cross-encoder, and compare\ntheir effectiveness in keystroke authentication. Furthermore, we investigate\ndifferent loss functions, including triplet, batch-all triplet, and WDCL loss,\nalong with various distance metrics such as Euclidean, Manhattan, and cosine\ndistances. These experiments allow us to optimize the training process and\nenhance the performance of our model. To evaluate our proposed model, we employ\nthe Aalto desktop keystroke dataset. The results demonstrate that the\nbi-encoder architecture with batch-all triplet loss and cosine distance\nachieves the best performance, yielding an exceptional Equal Error Rate of\n0.0186%. Furthermore, alternative algorithms for calculating similarity scores\nare explored to enhance accuracy. Notably, the utilization of a one-class\nSupport Vector Machine reduces the Equal Error Rate to an impressive 0.0163%.\nThe outcomes of this study indicate that our model surpasses the previous\nstate-of-the-art in free-text keystroke authentication. These findings\ncontribute to advancing the field of keystroke authentication and offer\npractical implications for secure user verification systems.",
            "author": [
                "Saleh Momeni",
                "Bagher BabaAli"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11640v1",
                "http://arxiv.org/pdf/2310.11640v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11637v1",
            "title": "FixPix: Fixing Bad Pixels using Deep Learning",
            "updated": "2023-10-18T00:14:47Z",
            "published": "2023-10-18T00:14:47Z",
            "summary": "Efficient and effective on-line detection and correction of bad pixels can\nimprove yield and increase the expected lifetime of image sensors. This paper\npresents a comprehensive Deep Learning (DL) based on-line detection-correction\napproach, suitable for a wide range of pixel corruption rates. A confidence\ncalibrated segmentation approach is introduced, which achieves nearly perfect\nbad pixel detection, even with few training samples. A computationally\nlight-weight correction algorithm is proposed for low rates of pixel\ncorruption, that surpasses the accuracy of traditional interpolation-based\ntechniques. We also propose an autoencoder based image reconstruction approach\nwhich alleviates the need for prior bad pixel detection and yields promising\nresults for high rates of pixel corruption. Unlike previous methods, which use\nproprietary images, we demonstrate the efficacy of the proposed methods on the\nopen-source Samsung S7 ISP and MIT-Adobe FiveK datasets. Our approaches yield\nup to 99.6% detection accuracy with <0.6% false positives and corrected images\nwithin 1.5% average pixel error from 70% corrupted images.",
            "author": [
                "Sreetama Sarkar",
                "Xinan Ye",
                "Gourav Datta",
                "Peter A. Beerel"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11637v1",
                "http://arxiv.org/pdf/2310.11637v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11634v1",
            "title": "MAGNIFICo: Evaluating the In-Context Learning Ability of Large Language\n  Models to Generalize to Novel Interpretations",
            "updated": "2023-10-18T00:02:38Z",
            "published": "2023-10-18T00:02:38Z",
            "summary": "Humans possess a remarkable ability to assign novel interpretations to\nlinguistic expressions, enabling them to learn new words and understand\ncommunity-specific connotations. However, Large Language Models (LLMs) have a\nknowledge cutoff and are costly to finetune repeatedly. Therefore, it is\ncrucial for LLMs to learn novel interpretations in-context. In this paper, we\nsystematically analyse the ability of LLMs to acquire novel interpretations\nusing in-context learning. To facilitate our study, we introduce MAGNIFICo, an\nevaluation suite implemented within a text-to-SQL semantic parsing framework\nthat incorporates diverse tokens and prompt settings to simulate real-world\ncomplexity. Experimental results on MAGNIFICo demonstrate that LLMs exhibit a\nsurprisingly robust capacity for comprehending novel interpretations from\nnatural language descriptions as well as from discussions within long\nconversations. Nevertheless, our findings also highlight the need for further\nimprovements, particularly when interpreting unfamiliar words or when composing\nmultiple novel interpretations simultaneously in the same example.\nAdditionally, our analysis uncovers the semantic predispositions in LLMs and\nreveals the impact of recency bias for information presented in long contexts.",
            "author": [
                "Arkil Patel",
                "Satwik Bhattamishra",
                "Siva Reddy",
                "Dzmitry Bahdanau"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11634v1",
                "http://arxiv.org/pdf/2310.11634v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11628v1",
            "title": "Learn Your Tokens: Word-Pooled Tokenization for Language Modeling",
            "updated": "2023-10-17T23:34:39Z",
            "published": "2023-10-17T23:34:39Z",
            "summary": "Language models typically tokenize text into subwords, using a deterministic,\nhand-engineered heuristic of combining characters into longer surface-level\nstrings such as 'ing' or whole words. Recent literature has repeatedly shown\nthe limitations of such a tokenization strategy, particularly for documents not\nwritten in English and for representing numbers. On the other extreme,\nbyte/character-level language models are much less restricted but suffer from\nincreased sequence description lengths and a subsequent quadratic expansion in\nself-attention computation. Recent attempts to compress and limit these context\nlengths with fixed size convolutions is helpful but completely ignores the word\nboundary. This paper considers an alternative 'learn your tokens' scheme which\nutilizes the word boundary to pool bytes/characters into word representations,\nwhich are fed to the primary language model, before again decoding individual\ncharacters/bytes per word in parallel. We find that our moderately expressive\nand moderately fast end-to-end tokenizer outperform by over 300% both subwords\nand byte/character models over the intrinsic language modeling metric of\nnext-word prediction across datasets. It particularly outshines on rare words,\noutperforming by a factor of 30! We extensively study the language modeling\nsetup for all three categories of tokenizers and theoretically analyze how our\nend-to-end models can also be a strong trade-off in efficiency and robustness.",
            "author": [
                "Avijit Thawani",
                "Saurabh Ghanekar",
                "Xiaoyuan Zhu",
                "Jay Pujara"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11628v1",
                "http://arxiv.org/pdf/2310.11628v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11614v1",
            "title": "Learning a Hierarchical Planner from Humans in Multiple Generations",
            "updated": "2023-10-17T22:28:13Z",
            "published": "2023-10-17T22:28:13Z",
            "summary": "A typical way in which a machine acquires knowledge from humans is by\nprogramming. Compared to learning from demonstrations or experiences,\nprogrammatic learning allows the machine to acquire a novel skill as soon as\nthe program is written, and, by building a library of programs, a machine can\nquickly learn how to perform complex tasks. However, as programs often take\ntheir execution contexts for granted, they are brittle when the contexts\nchange, making it difficult to adapt complex programs to new contexts. We\npresent natural programming, a library learning system that combines\nprogrammatic learning with a hierarchical planner. Natural programming\nmaintains a library of decompositions, consisting of a goal, a linguistic\ndescription of how this goal decompose into sub-goals, and a concrete instance\nof its decomposition into sub-goals. A user teaches the system via curriculum\nbuilding, by identifying a challenging yet not impossible goal along with\nlinguistic hints on how this goal may be decomposed into sub-goals. The system\nsolves for the goal via hierarchical planning, using the linguistic hints to\nguide its probability distribution in proposing the right plans. The system\nlearns from this interaction by adding newly found decompositions in the\nsuccessful search into its library. Simulated studies and a human experiment\n(n=360) on a controlled environment demonstrate that natural programming can\nrobustly compose programs learned from different users and contexts, adapting\nfaster and solving more complex tasks when compared to programmatic baselines.",
            "author": [
                "Leonardo Hernandez Cano",
                "Yewen Pu",
                "Robert D. Hawkins",
                "Josh Tenenbaum",
                "Armando Solar-Lezama"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11614v1",
                "http://arxiv.org/pdf/2310.11614v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11612v1",
            "title": "Balance Act: Mitigating Hubness in Cross-Modal Retrieval with Query and\n  Gallery Banks",
            "updated": "2023-10-17T22:10:17Z",
            "published": "2023-10-17T22:10:17Z",
            "summary": "In this work, we present a post-processing solution to address the hubness\nproblem in cross-modal retrieval, a phenomenon where a small number of gallery\ndata points are frequently retrieved, resulting in a decline in retrieval\nperformance. We first theoretically demonstrate the necessity of incorporating\nboth the gallery and query data for addressing hubness as hubs always exhibit\nhigh similarity with gallery and query data. Second, building on our\ntheoretical results, we propose a novel framework, Dual Bank Normalization\n(DBNorm). While previous work has attempted to alleviate hubness by only\nutilizing the query samples, DBNorm leverages two banks constructed from the\nquery and gallery samples to reduce the occurrence of hubs during inference.\nNext, to complement DBNorm, we introduce two novel methods, dual inverted\nsoftmax and dual dynamic inverted softmax, for normalizing similarity based on\nthe two banks. Specifically, our proposed methods reduce the similarity between\nhubs and queries while improving the similarity between non-hubs and queries.\nFinally, we present extensive experimental results on diverse language-grounded\nbenchmarks, including text-image, text-video, and text-audio, demonstrating the\nsuperior performance of our approaches compared to previous methods in\naddressing hubness and boosting retrieval performance. Our code is available at\nhttps://github.com/yimuwangcs/Better_Cross_Modal_Retrieval.",
            "author": [
                "Yimu Wang",
                "Xiangru Jian",
                "Bo Xue"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11612v1",
                "http://arxiv.org/pdf/2310.11612v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11611v1",
            "title": "In defense of parameter sharing for model-compression",
            "updated": "2023-10-17T22:08:01Z",
            "published": "2023-10-17T22:08:01Z",
            "summary": "When considering a model architecture, there are several ways to reduce its\nmemory footprint. Historically, popular approaches included selecting smaller\narchitectures and creating sparse networks through pruning. More recently,\nrandomized parameter-sharing (RPS) methods have gained traction for model\ncompression at start of training. In this paper, we comprehensively assess the\ntrade-off between memory and accuracy across RPS, pruning techniques, and\nbuilding smaller models. Our findings demonstrate that RPS, which is both data\nand model-agnostic, consistently outperforms/matches smaller models and all\nmoderately informed pruning strategies, such as MAG, SNIP, SYNFLOW, and GRASP,\nacross the entire compression range. This advantage becomes particularly\npronounced in higher compression scenarios. Notably, even when compared to\nhighly informed pruning techniques like Lottery Ticket Rewinding (LTR), RPS\nexhibits superior performance in high compression settings. This points out\ninherent capacity advantage that RPS enjoys over sparse models. Theoretically,\nwe establish RPS as a superior technique in terms of memory-efficient\nrepresentation when compared to pruning for linear models. This paper argues in\nfavor of paradigm shift towards RPS based models. During our rigorous\nevaluation of RPS, we identified issues in the state-of-the-art RPS technique\nROAST, specifically regarding stability (ROAST's sensitivity to initialization\nhyperparameters, often leading to divergence) and Pareto-continuity (ROAST's\ninability to recover the accuracy of the original model at zero compression).\nWe provably address both of these issues. We refer to the modified RPS, which\nincorporates our improvements, as STABLE-RPS.",
            "author": [
                "Aditya Desai",
                "Anshumali Shrivastava"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11611v1",
                "http://arxiv.org/pdf/2310.11611v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11609v2",
            "title": "Reflection-Equivariant Diffusion for 3D Structure Determination from\n  Isotopologue Rotational Spectra in Natural Abundance",
            "updated": "2023-11-19T22:53:59Z",
            "published": "2023-10-17T22:05:11Z",
            "summary": "Structure determination is necessary to identify unknown organic molecules,\nsuch as those in natural products, forensic samples, the interstellar medium,\nand laboratory syntheses. Rotational spectroscopy enables structure\ndetermination by providing accurate 3D information about small organic\nmolecules via their moments of inertia. Using these moments, Kraitchman\nanalysis determines isotopic substitution coordinates, which are the unsigned\n$|x|,|y|,|z|$ coordinates of all atoms with natural isotopic abundance,\nincluding carbon, nitrogen, and oxygen. While unsigned substitution coordinates\ncan verify guesses of structures, the missing $+/-$ signs make it challenging\nto determine the actual structure from the substitution coordinates alone. To\ntackle this inverse problem, we develop KREED (Kraitchman\nREflection-Equivariant Diffusion), a generative diffusion model that infers a\nmolecule's complete 3D structure from its molecular formula, moments of\ninertia, and unsigned substitution coordinates of heavy atoms. KREED's top-1\npredictions identify the correct 3D structure with >98% accuracy on the QM9 and\nGEOM datasets when provided with substitution coordinates of all heavy atoms\nwith natural isotopic abundance. When substitution coordinates are restricted\nto only a subset of carbons, accuracy is retained at 91% on QM9 and 32% on\nGEOM. On a test set of experimentally measured substitution coordinates\ngathered from the literature, KREED predicts the correct all-atom 3D structure\nin 25 of 33 cases, demonstrating experimental applicability for context-free 3D\nstructure determination with rotational spectroscopy.",
            "author": [
                "Austin Cheng",
                "Alston Lo",
                "Santiago Miret",
                "Brooks Pate",
                "Al\u00e1n Aspuru-Guzik"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11609v2",
                "http://arxiv.org/pdf/2310.11609v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "astro-ph.GA",
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11607v1",
            "title": "TK-KNN: A Balanced Distance-Based Pseudo Labeling Approach for\n  Semi-Supervised Intent Classification",
            "updated": "2023-10-17T22:00:42Z",
            "published": "2023-10-17T22:00:42Z",
            "summary": "The ability to detect intent in dialogue systems has become increasingly\nimportant in modern technology. These systems often generate a large amount of\nunlabeled data, and manually labeling this data requires substantial human\neffort. Semi-supervised methods attempt to remedy this cost by using a model\ntrained on a few labeled examples and then by assigning pseudo-labels to\nfurther a subset of unlabeled examples that has a model prediction confidence\nhigher than a certain threshold. However, one particularly perilous consequence\nof these methods is the risk of picking an imbalanced set of examples across\nclasses, which could lead to poor labels. In the present work, we describe\nTop-K K-Nearest Neighbor (TK-KNN), which uses a more robust pseudo-labeling\napproach based on distance in the embedding space while maintaining a balanced\nset of pseudo-labeled examples across classes through a ranking-based approach.\nExperiments on several datasets show that TK-KNN outperforms existing models,\nparticularly when labeled data is scarce on popular datasets such as CLINC150\nand Banking77. Code is available at https://github.com/ServiceNow/tk-knn",
            "author": [
                "Nicholas Botzer",
                "David Vasquez",
                "Tim Weninger",
                "Issam Laradji"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11607v1",
                "http://arxiv.org/pdf/2310.11607v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11605v1",
            "title": "DIAR: Deep Image Alignment and Reconstruction using Swin Transformers",
            "updated": "2023-10-17T21:59:45Z",
            "published": "2023-10-17T21:59:45Z",
            "summary": "When taking images of some occluded content, one is often faced with the\nproblem that every individual image frame contains unwanted artifacts, but a\ncollection of images contains all relevant information if properly aligned and\naggregated. In this paper, we attempt to build a deep learning pipeline that\nsimultaneously aligns a sequence of distorted images and reconstructs them. We\ncreate a dataset that contains images with image distortions, such as lighting,\nspecularities, shadows, and occlusion. We create perspective distortions with\ncorresponding ground-truth homographies as labels. We use our dataset to train\nSwin transformer models to analyze sequential image data. The attention maps\nenable the model to detect relevant image content and differentiate it from\noutliers and artifacts. We further explore using neural feature maps as\nalternatives to classical key point detectors. The feature maps of trained\nconvolutional layers provide dense image descriptors that can be used to find\npoint correspondences between images. We utilize this to compute coarse image\nalignments and explore its limitations.",
            "author": [
                "Monika Kwiatkowski",
                "Simon Matern",
                "Olaf Hellwich"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-031-45725-8_12",
                "http://arxiv.org/abs/2310.11605v1",
                "http://arxiv.org/pdf/2310.11605v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11604v1",
            "title": "Language Models as Zero-Shot Trajectory Generators",
            "updated": "2023-10-17T21:57:36Z",
            "published": "2023-10-17T21:57:36Z",
            "summary": "Large Language Models (LLMs) have recently shown promise as high-level\nplanners for robots when given access to a selection of low-level skills.\nHowever, it is often assumed that LLMs do not possess sufficient knowledge to\nbe used for the low-level trajectories themselves. In this work, we address\nthis assumption thoroughly, and investigate if an LLM (GPT-4) can directly\npredict a dense sequence of end-effector poses for manipulation skills, when\ngiven access to only object detection and segmentation vision models. We study\nhow well a single task-agnostic prompt, without any in-context examples, motion\nprimitives, or external trajectory optimisers, can perform across 26 real-world\nlanguage-based tasks, such as \"open the bottle cap\" and \"wipe the plate with\nthe sponge\", and we investigate which design choices in this prompt are the\nmost effective. Our conclusions raise the assumed limit of LLMs for robotics,\nand we reveal for the first time that LLMs do indeed possess an understanding\nof low-level robot control sufficient for a range of common tasks, and that\nthey can additionally detect failures and then re-plan trajectories\naccordingly. Videos, code, and prompts are available at:\nhttps://www.robot-learning.uk/language-models-trajectory-generators.",
            "author": [
                "Teyun Kwon",
                "Norman Di Palo",
                "Edward Johns"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11604v1",
                "http://arxiv.org/pdf/2310.11604v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CL",
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11598v1",
            "title": "Learning Neural Implicit through Volume Rendering with Attentive Depth\n  Fusion Priors",
            "updated": "2023-10-17T21:45:51Z",
            "published": "2023-10-17T21:45:51Z",
            "summary": "Learning neural implicit representations has achieved remarkable performance\nin 3D reconstruction from multi-view images. Current methods use volume\nrendering to render implicit representations into either RGB or depth images\nthat are supervised by multi-view ground truth. However, rendering a view each\ntime suffers from incomplete depth at holes and unawareness of occluded\nstructures from the depth supervision, which severely affects the accuracy of\ngeometry inference via volume rendering. To resolve this issue, we propose to\nlearn neural implicit representations from multi-view RGBD images through\nvolume rendering with an attentive depth fusion prior. Our prior allows neural\nnetworks to perceive coarse 3D structures from the Truncated Signed Distance\nFunction (TSDF) fused from all depth images available for rendering. The TSDF\nenables accessing the missing depth at holes on one depth image and the\noccluded parts that are invisible from the current view. By introducing a novel\nattention mechanism, we allow neural networks to directly use the depth fusion\nprior with the inferred occupancy as the learned implicit function. Our\nattention mechanism works with either a one-time fused TSDF that represents a\nwhole scene or an incrementally fused TSDF that represents a partial scene in\nthe context of Simultaneous Localization and Mapping (SLAM). Our evaluations on\nwidely used benchmarks including synthetic and real-world scans show our\nsuperiority over the latest neural implicit methods. Project page:\nhttps://machineperceptionlab.github.io/Attentive_DF_Prior/",
            "author": [
                "Pengchong Hu",
                "Zhizhong Han"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11598v1",
                "http://arxiv.org/pdf/2310.11598v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11597v1",
            "title": "The Efficacy of Transformer-based Adversarial Attacks in Security\n  Domains",
            "updated": "2023-10-17T21:45:23Z",
            "published": "2023-10-17T21:45:23Z",
            "summary": "Today, the security of many domains rely on the use of Machine Learning to\ndetect threats, identify vulnerabilities, and safeguard systems from attacks.\nRecently, transformer architectures have improved the state-of-the-art\nperformance on a wide range of tasks such as malware detection and network\nintrusion detection. But, before abandoning current approaches to transformers,\nit is crucial to understand their properties and implications on cybersecurity\napplications. In this paper, we evaluate the robustness of transformers to\nadversarial samples for system defenders (i.e., resiliency to adversarial\nperturbations generated on different types of architectures) and their\nadversarial strength for system attackers (i.e., transferability of adversarial\nsamples generated by transformers to other target models). To that effect, we\nfirst fine-tune a set of pre-trained transformer, Convolutional Neural Network\n(CNN), and hybrid (an ensemble of transformer and CNN) models to solve\ndifferent downstream image-based tasks. Then, we use an attack algorithm to\ncraft 19,367 adversarial examples on each model for each task. The\ntransferability of these adversarial examples is measured by evaluating each\nset on other models to determine which models offer more adversarial strength,\nand consequently, more robustness against these attacks. We find that the\nadversarial examples crafted on transformers offer the highest transferability\nrate (i.e., 25.7% higher than the average) onto other models. Similarly,\nadversarial examples crafted on other models have the lowest rate of\ntransferability (i.e., 56.7% lower than the average) onto transformers. Our\nwork emphasizes the importance of studying transformer architectures for\nattacking and defending models in security domains, and suggests using them as\nthe primary architecture in transfer attack settings.",
            "author": [
                "Kunyang Li",
                "Kyle Domico",
                "Jean-Charles Noirot Ferrand",
                "Patrick McDaniel"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11597v1",
                "http://arxiv.org/pdf/2310.11597v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11594v2",
            "title": "Adversarial Robustness Unhardening via Backdoor Attacks in Federated\n  Learning",
            "updated": "2023-10-21T03:18:35Z",
            "published": "2023-10-17T21:38:41Z",
            "summary": "In today's data-driven landscape, the delicate equilibrium between\nsafeguarding user privacy and unleashing data potential stands as a paramount\nconcern. Federated learning, which enables collaborative model training without\nnecessitating data sharing, has emerged as a privacy-centric solution. This\ndecentralized approach brings forth security challenges, notably poisoning and\nbackdoor attacks where malicious entities inject corrupted data. Our research,\ninitially spurred by test-time evasion attacks, investigates the intersection\nof adversarial training and backdoor attacks within federated learning,\nintroducing Adversarial Robustness Unhardening (ARU). ARU is employed by a\nsubset of adversaries to intentionally undermine model robustness during\ndecentralized training, rendering models susceptible to a broader range of\nevasion attacks. We present extensive empirical experiments evaluating ARU's\nimpact on adversarial training and existing robust aggregation defenses against\npoisoning and backdoor attacks. Our findings inform strategies for enhancing\nARU to counter current defensive measures and highlight the limitations of\nexisting defenses, offering insights into bolstering defenses against ARU.",
            "author": [
                "Taejin Kim",
                "Jiarui Li",
                "Shubhranshu Singh",
                "Nikhil Madaan",
                "Carlee Joe-Wong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11594v2",
                "http://arxiv.org/pdf/2310.11594v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11593v1",
            "title": "Automated Evaluation of Personalized Text Generation using Large\n  Language Models",
            "updated": "2023-10-17T21:35:06Z",
            "published": "2023-10-17T21:35:06Z",
            "summary": "Personalized text generation presents a specialized mechanism for delivering\ncontent that is specific to a user's personal context. While the research\nprogress in this area has been rapid, evaluation still presents a challenge.\nTraditional automated metrics such as BLEU and ROUGE primarily measure lexical\nsimilarity to human-written references, and are not able to distinguish\npersonalization from other subtle semantic aspects, thus falling short of\ncapturing the nuances of personalized generated content quality. On the other\nhand, human judgments are costly to obtain, especially in the realm of\npersonalized evaluation. Inspired by these challenges, we explore the use of\nlarge language models (LLMs) for evaluating personalized text generation, and\nexamine their ability to understand nuanced user context. We present AuPEL, a\nnovel evaluation method that distills three major semantic aspects of the\ngenerated text: personalization, quality and relevance, and automatically\nmeasures these aspects. To validate the effectiveness of AuPEL, we design\ncarefully controlled experiments and compare the accuracy of the evaluation\njudgments made by LLMs versus that of judgements made by human annotators, and\nconduct rigorous analyses of the consistency and sensitivity of the proposed\nmetric. We find that, compared to existing evaluation metrics, AuPEL not only\ndistinguishes and ranks models based on their personalization abilities more\naccurately, but also presents commendable consistency and efficiency for this\ntask. Our work suggests that using LLMs as the evaluators of personalized text\ngeneration is superior to traditional text similarity metrics, even though\ninteresting new challenges still remain.",
            "author": [
                "Yaqing Wang",
                "Jiepu Jiang",
                "Mingyang Zhang",
                "Cheng Li",
                "Yi Liang",
                "Qiaozhu Mei",
                "Michael Bendersky"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11593v1",
                "http://arxiv.org/pdf/2310.11593v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13015v1",
            "title": "Audio-AdapterFusion: A Task-ID-free Approach for Efficient and\n  Non-Destructive Multi-task Speech Recognition",
            "updated": "2023-10-17T21:21:40Z",
            "published": "2023-10-17T21:21:40Z",
            "summary": "Adapters are an efficient, composable alternative to full fine-tuning of\npre-trained models and help scale the deployment of large ASR models to many\ntasks. In practice, a task ID is commonly prepended to the input during\ninference to route to single-task adapters for the specified task. However, one\nmajor limitation of this approach is that the task ID may not be known during\ninference, rendering it unsuitable for most multi-task settings. To address\nthis, we propose three novel task-ID-free methods to combine single-task\nadapters in multi-task ASR and investigate two learning algorithms for\ntraining. We evaluate our methods on 10 test sets from 4 diverse ASR tasks and\nshow that our methods are non-destructive and parameter-efficient. While only\nupdating 17% of the model parameters, our methods can achieve an 8% mean WER\nimprovement relative to full fine-tuning and are on-par with task-ID adapter\nrouting.",
            "author": [
                "Hillary Ngai",
                "Rohan Agrawal",
                "Neeraj Gaur",
                "Ronny Huang",
                "Parisa Haghani",
                "Pedro Moreno Mengibar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13015v1",
                "http://arxiv.org/pdf/2310.13015v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11590v1",
            "title": "Towards Inferring Users' Impressions of Robot Performance in Navigation\n  Scenarios",
            "updated": "2023-10-17T21:12:32Z",
            "published": "2023-10-17T21:12:32Z",
            "summary": "Human impressions of robot performance are often measured through surveys. As\na more scalable and cost-effective alternative, we study the possibility of\npredicting people's impressions of robot behavior using non-verbal behavioral\ncues and machine learning techniques. To this end, we first contribute the SEAN\nTOGETHER Dataset consisting of observations of an interaction between a person\nand a mobile robot in a Virtual Reality simulation, together with impressions\nof robot performance provided by users on a 5-point scale. Second, we\ncontribute analyses of how well humans and supervised learning techniques can\npredict perceived robot performance based on different combinations of\nobservation types (e.g., facial, spatial, and map features). Our results show\nthat facial expressions alone provide useful information about human\nimpressions of robot performance; but in the navigation scenarios we tested,\nspatial features are the most critical piece of information for this inference\ntask. Also, when evaluating results as binary classification (rather than\nmulticlass classification), the F1-Score of human predictions and machine\nlearning models more than doubles, showing that both are better at telling the\ndirectionality of robot performance than predicting exact performance ratings.\nBased on our findings, we provide guidelines for implementing these predictions\nmodels in real-world navigation scenarios.",
            "author": [
                "Qiping Zhang",
                "Nathan Tsoi",
                "Booyeon Choi",
                "Jie Tan",
                "Hao-Tien Lewis Chiang",
                "Marynel V\u00e1zquez"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11590v1",
                "http://arxiv.org/pdf/2310.11590v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11589v1",
            "title": "Eliciting Human Preferences with Language Models",
            "updated": "2023-10-17T21:11:21Z",
            "published": "2023-10-17T21:11:21Z",
            "summary": "Language models (LMs) can be directed to perform target tasks by using\nlabeled examples or natural language prompts. But selecting examples or writing\nprompts for can be challenging--especially in tasks that involve unusual edge\ncases, demand precise articulation of nebulous preferences, or require an\naccurate mental model of LM behavior. We propose to use *LMs themselves* to\nguide the task specification process. In this paper, we introduce **Generative\nActive Task Elicitation (GATE)**: a learning framework in which models elicit\nand infer intended behavior through free-form, language-based interaction with\nusers. We study GATE in three domains: email validation, content\nrecommendation, and moral reasoning. In preregistered experiments, we show that\nLMs prompted to perform GATE (e.g., by generating open-ended questions or\nsynthesizing informative edge cases) elicit responses that are often more\ninformative than user-written prompts or labels. Users report that interactive\ntask elicitation requires less effort than prompting or example labeling and\nsurfaces novel considerations not initially anticipated by users. Our findings\nsuggest that LM-driven elicitation can be a powerful tool for aligning models\nto complex human preferences and values.",
            "author": [
                "Belinda Z. Li",
                "Alex Tamkin",
                "Noah Goodman",
                "Jacob Andreas"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11589v1",
                "http://arxiv.org/pdf/2310.11589v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11577v1",
            "title": "Studying the Effects of Sex-related Differences on Brain Age Prediction\n  using brain MR Imaging",
            "updated": "2023-10-17T20:55:53Z",
            "published": "2023-10-17T20:55:53Z",
            "summary": "While utilizing machine learning models, one of the most crucial aspects is\nhow bias and fairness affect model outcomes for diverse demographics. This\nbecomes especially relevant in the context of machine learning for medical\nimaging applications as these models are increasingly being used for diagnosis\nand treatment planning. In this paper, we study biases related to sex when\ndeveloping a machine learning model based on brain magnetic resonance images\n(MRI). We investigate the effects of sex by performing brain age prediction\nconsidering different experimental designs: model trained using only female\nsubjects, only male subjects and a balanced dataset. We also perform evaluation\non multiple MRI datasets (Calgary-Campinas(CC359) and CamCAN) to assess the\ngeneralization capability of the proposed models. We found disparities in the\nperformance of brain age prediction models when trained on distinct sex\nsubgroups and datasets, in both final predictions and decision making (assessed\nusing interpretability models). Our results demonstrated variations in model\ngeneralizability across sex-specific subgroups, suggesting potential biases in\nmodels trained on unbalanced datasets. This underlines the critical role of\ncareful experimental design in generating fair and reliable outcomes.",
            "author": [
                "Mahsa Dibaji",
                "Neha Gianchandani",
                "Akhil Nair",
                "Mansi Singhal",
                "Roberto Souza",
                "Mariana Bento"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11577v1",
                "http://arxiv.org/pdf/2310.11577v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11571v1",
            "title": "What is a good question? Task-oriented asking with fact-level masking",
            "updated": "2023-10-17T20:40:59Z",
            "published": "2023-10-17T20:40:59Z",
            "summary": "Asking questions is an important element of real-life collaboration on\nreasoning tasks like question answering. For example, a legal assistant chatbot\nmay be unable to make accurate recommendations without specific information on\nthe user's circumstances. However, large language models are usually deployed\nto solve reasoning tasks directly without asking follow-up questions to the\nuser or third parties. We term this problem task-oriented asking (TOA).\nZero-shot chat models can perform TOA, but their training is primarily based on\nnext-token prediction rather than whether questions contribute to successful\ncollaboration. To enable the training and evaluation of TOA models, we present\na definition and framework for natural language task-oriented asking, the\nproblem of generating questions that result in answers useful for a reasoning\ntask. We also present fact-level masking (FLM), a procedure for converting\nnatural language datasets into self-supervised TOA datasets by omitting\nparticular critical facts. Finally, we generate a TOA dataset from the HotpotQA\ndataset using FLM and evaluate several zero-shot language models on it. Our\nexperiments show that current zero-shot models struggle to ask questions that\nretrieve useful information, as compared to human annotators. These results\ndemonstrate an opportunity to use FLM datasets and the TOA framework to train\nand evaluate better TOA models.",
            "author": [
                "Matthew Toles",
                "Yukun Huang",
                "Zhou Yu",
                "Luis Gravano"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11571v1",
                "http://arxiv.org/pdf/2310.11571v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11569v2",
            "title": "When Rigidity Hurts: Soft Consistency Regularization for Probabilistic\n  Hierarchical Time Series Forecasting",
            "updated": "2023-10-19T04:03:11Z",
            "published": "2023-10-17T20:30:16Z",
            "summary": "Probabilistic hierarchical time-series forecasting is an important variant of\ntime-series forecasting, where the goal is to model and forecast multivariate\ntime-series that have underlying hierarchical relations. Most methods focus on\npoint predictions and do not provide well-calibrated probabilistic forecasts\ndistributions. Recent state-of-art probabilistic forecasting methods also\nimpose hierarchical relations on point predictions and samples of distribution\nwhich does not account for coherency of forecast distributions. Previous works\nalso silently assume that datasets are always consistent with given\nhierarchical relations and do not adapt to real-world datasets that show\ndeviation from this assumption. We close both these gap and propose PROFHiT,\nwhich is a fully probabilistic hierarchical forecasting model that jointly\nmodels forecast distribution of entire hierarchy. PROFHiT uses a flexible\nprobabilistic Bayesian approach and introduces a novel Distributional Coherency\nregularization to learn from hierarchical relations for entire forecast\ndistribution that enables robust and calibrated forecasts as well as adapt to\ndatasets of varying hierarchical consistency. On evaluating PROFHiT over wide\nrange of datasets, we observed 41-88% better performance in accuracy and\nsignificantly better calibration. Due to modeling the coherency over full\ndistribution, we observed that PROFHiT can robustly provide reliable forecasts\neven if up to 10% of input time-series data is missing where other methods'\nperformance severely degrade by over 70%.",
            "author": [
                "Harshavardhan Kamarthi",
                "Lingkai Kong",
                "Alexander Rodr\u00edguez",
                "Chao Zhang",
                "B. Aditya Prakash"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11569v2",
                "http://arxiv.org/pdf/2310.11569v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11566v1",
            "title": "Partially Observable Stochastic Games with Neural Perception Mechanisms",
            "updated": "2023-10-17T20:25:40Z",
            "published": "2023-10-17T20:25:40Z",
            "summary": "Stochastic games are a well established model for multi-agent sequential\ndecision making under uncertainty. In reality, though, agents have only partial\nobservability of their environment, which makes the problem computationally\nchallenging, even in the single-agent setting of partially observable Markov\ndecision processes. Furthermore, in practice, agents increasingly perceive\ntheir environment using data-driven approaches such as neural networks trained\non continuous data. To tackle this problem, we propose the model of\nneuro-symbolic partially-observable stochastic games (NS-POSGs), a variant of\ncontinuous-space concurrent stochastic games that explicitly incorporates\nperception mechanisms. We focus on a one-sided setting, comprising a\npartially-informed agent with discrete, data-driven observations and a\nfully-informed agent with continuous observations. We present a new point-based\nmethod, called one-sided NS-HSVI, for approximating values of one-sided\nNS-POSGs and implement it based on the popular particle-based beliefs, showing\nthat it has closed forms for computing values of interest. We provide\nexperimental results to demonstrate the practical applicability of our method\nfor neural networks whose preimage is in polyhedral form.",
            "author": [
                "Rui Yan",
                "Gabriel Santos",
                "Gethin Norman",
                "David Parker",
                "Marta Kwiatkowska"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11566v1",
                "http://arxiv.org/pdf/2310.11566v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11564v1",
            "title": "Personalized Soups: Personalized Large Language Model Alignment via\n  Post-hoc Parameter Merging",
            "updated": "2023-10-17T20:22:13Z",
            "published": "2023-10-17T20:22:13Z",
            "summary": "While Reinforcement Learning from Human Feedback (RLHF) aligns Large Language\nModels (LLMs) with general, aggregate human preferences, it is suboptimal for\nlearning diverse, individual perspectives. In this work, we study Reinforcement\nLearning from Personalized Human Feedback (RLPHF) problem, wherein LLMs are\naligned to multiple (sometimes conflicting) preferences by modeling alignment\nas a Multi-Objective Reinforcement Learning (MORL) problem. Compared to strong\nsingle-objective baselines, we show that we can achieve personalized alignment\nby decomposing preferences into multiple dimensions. These dimensions are\ndefined based on personalizations that are declared as desirable by the user.\nIn this work, we show that they can be efficiently trained independently in a\ndistributed manner and combined effectively post-hoc through parameter merging.\nThe code is available at https://github.com/joeljang/RLPHF.",
            "author": [
                "Joel Jang",
                "Seungone Kim",
                "Bill Yuchen Lin",
                "Yizhong Wang",
                "Jack Hessel",
                "Luke Zettlemoyer",
                "Hannaneh Hajishirzi",
                "Yejin Choi",
                "Prithviraj Ammanabrolu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11564v1",
                "http://arxiv.org/pdf/2310.11564v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11562v1",
            "title": "RekomGNN: Visualizing, Contextualizing and Evaluating Graph Neural\n  Networks Recommendations",
            "updated": "2023-10-17T20:20:38Z",
            "published": "2023-10-17T20:20:38Z",
            "summary": "Content recommendation tasks increasingly use Graph Neural Networks, but it\nremains challenging for machine learning experts to assess the quality of their\noutputs. Visualization systems for GNNs that could support this interrogation\nare few. Moreover, those that do exist focus primarily on exposing GNN\narchitectures for tuning and prediction tasks and do not address the challenges\nof recommendation tasks. We developed RekomGNN, a visual analytics system that\nsupports ML experts in exploring GNN recommendations across several dimensions\nand making annotations about their quality. RekomGNN straddles the design space\nbetween Neural Network and recommender system visualization to arrive at a set\nof encoding and interaction choices for recommendation tasks. We found that\nRekomGNN helps experts make qualitative assessments of the GNN's results, which\nthey can use for model refinement. Overall, our contributions and findings add\nto the growing understanding of visualizing GNNs for increasingly complex\ntasks.",
            "author": [
                "Camelia D. Brumar",
                "Gabriel Appleby",
                "Jen Rogers",
                "Teddy Matinde",
                "Lara Thompson",
                "Remco Chang",
                "Anamaria Crisan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11562v1",
                "http://arxiv.org/pdf/2310.11562v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11559v1",
            "title": "Confidential Consortium Framework: Secure Multiparty Applications with\n  Confidentiality, Integrity, and High Availability",
            "updated": "2023-10-17T20:12:07Z",
            "published": "2023-10-17T20:12:07Z",
            "summary": "Confidentiality, integrity protection, and high availability, abbreviated to\nCIA, are essential properties for trustworthy data systems. The rise of cloud\ncomputing and the growing demand for multiparty applications however means that\nbuilding modern CIA systems is more challenging than ever. In response, we\npresent the Confidential Consortium Framework (CCF), a general-purpose\nfoundation for developing secure stateful CIA applications. CCF combines\ncentralized compute with decentralized trust, supporting deployment on\nuntrusted cloud infrastructure and transparent governance by mutually untrusted\nparties. CCF leverages hardware-based trusted execution environments for\nremotely verifiable confidentiality and code integrity. This is coupled with\nstate machine replication backed by an auditable immutable ledger for data\nintegrity and high availability. CCF enables each service to bring its own\napplication logic, custom multiparty governance model, and deployment scenario,\ndecoupling the operators of nodes from the consortium that governs them. CCF is\nopen-source and available now at https://github.com/microsoft/CCF.",
            "author": [
                "Heidi Howard",
                "Fritz Alder",
                "Edward Ashton",
                "Amaury Chamayou",
                "Sylvan Clebsch",
                "Manuel Costa",
                "Antoine Delignat-Lavaud",
                "Cedric Fournet",
                "Andrew Jeffery",
                "Matthew Kerner",
                "Fotios Kounelis",
                "Markus A. Kuppe",
                "Julien Maffre",
                "Mark Russinovich",
                "Christoph M. Wintersteiger"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11559v1",
                "http://arxiv.org/pdf/2310.11559v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11558v1",
            "title": "Online Algorithms with Uncertainty-Quantified Predictions",
            "updated": "2023-10-17T20:09:41Z",
            "published": "2023-10-17T20:09:41Z",
            "summary": "Online algorithms with predictions have become a trending topic in the field\nof beyond worst-case analysis of algorithms. These algorithms incorporate\npredictions about the future to obtain performance guarantees that are of high\nquality when the predictions are good, while still maintaining bounded\nworst-case guarantees when predictions are arbitrarily poor. In general, the\nalgorithm is assumed to be unaware of the prediction's quality. However, recent\ndevelopments in the machine learning literature have studied techniques for\nproviding uncertainty quantification on machine-learned predictions, which\ndescribes how certain a model is about its quality. This paper examines the\nquestion of how to optimally utilize uncertainty-quantified predictions in the\ndesign of online algorithms. In particular, we consider predictions augmented\nwith uncertainty quantification describing the likelihood of the ground truth\nfalling in a certain range, designing online algorithms with these\nprobabilistic predictions for two classic online problems: ski rental and\nonline search. In each case, we demonstrate that non-trivial modifications to\nalgorithm design are needed to fully leverage the probabilistic predictions.\nMoreover, we consider how to utilize more general forms of uncertainty\nquantification, proposing a framework based on online learning that learns to\nexploit uncertainty quantification to make optimal decisions in multi-instance\nsettings.",
            "author": [
                "Bo Sun",
                "Jerry Huang",
                "Nicolas Christianson",
                "Mohammad Hajiesmaili",
                "Adam Wierman"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11558v1",
                "http://arxiv.org/pdf/2310.11558v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11550v1",
            "title": "Towards Optimal Regret in Adversarial Linear MDPs with Bandit Feedback",
            "updated": "2023-10-17T19:43:37Z",
            "published": "2023-10-17T19:43:37Z",
            "summary": "We study online reinforcement learning in linear Markov decision processes\nwith adversarial losses and bandit feedback, without prior knowledge on\ntransitions or access to simulators. We introduce two algorithms that achieve\nimproved regret performance compared to existing approaches. The first\nalgorithm, although computationally inefficient, ensures a regret of\n$\\widetilde{\\mathcal{O}}\\left(\\sqrt{K}\\right)$, where $K$ is the number of\nepisodes. This is the first result with the optimal $K$ dependence in the\nconsidered setting. The second algorithm, which is based on the policy\noptimization framework, guarantees a regret of\n$\\widetilde{\\mathcal{O}}\\left(K^{\\frac{3}{4}} \\right)$ and is computationally\nefficient. Both our results significantly improve over the state-of-the-art: a\ncomputationally inefficient algorithm by Kong et al. [2023] with\n$\\widetilde{\\mathcal{O}}\\left(K^{\\frac{4}{5}}+poly\\left(\\frac{1}{\\lambda_{\\min}}\\right)\n\\right)$ regret, for some problem-dependent constant $\\lambda_{\\min}$ that can\nbe arbitrarily close to zero, and a computationally efficient algorithm by\nSherman et al. [2023b] with $\\widetilde{\\mathcal{O}}\\left(K^{\\frac{6}{7}}\n\\right)$ regret.",
            "author": [
                "Haolin Liu",
                "Chen-Yu Wei",
                "Julian Zimmert"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11550v1",
                "http://arxiv.org/pdf/2310.11550v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11546v1",
            "title": "Bias and Error Mitigation in Software-Generated Data: An Advanced Search\n  and Optimization Framework Leveraging Generative Code Models",
            "updated": "2023-10-17T19:31:05Z",
            "published": "2023-10-17T19:31:05Z",
            "summary": "Data generation and analysis is a fundamental aspect of many industries and\ndisciplines, from strategic decision making in business to research in the\nphysical and social sciences. However, data generated using software and\nalgorithms can be subject to biases and errors. These can be due to problems\nwith the original software, default settings that do not align with the\nspecific needs of the situation, or even deeper problems with the underlying\ntheories and models. This paper proposes an advanced search and optimization\nframework aimed at generating and choosing optimal source code capable of\ncorrecting errors and biases from previous versions to address typical problems\nin software systems specializing in data analysis and generation, especially\nthose in the corporate and data science world. Applying this framework multiple\ntimes on the same software system would incrementally improve the quality of\nthe output results. It uses Solomonoff Induction as a sound theoretical basis,\nextending it with Kolmogorov Conditional Complexity, a novel adaptation, to\nevaluate a set of candidate programs. We propose the use of generative models\nfor the creation of this set of programs, with special emphasis on the\ncapabilities of Large Language Models (LLMs) to generate high quality code.",
            "author": [
                "Ernesto Giralt Hern\u00e1ndez"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11546v1",
                "http://arxiv.org/pdf/2310.11546v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.IT",
                "cs.LG",
                "math.IT",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11543v1",
            "title": "Robust variational data assimilation of sparse velocity reference data\n  in RANS simulations through a divergence-free forcing term",
            "updated": "2023-10-17T19:27:41Z",
            "published": "2023-10-17T19:27:41Z",
            "summary": "The Reynolds-averaged Navier-Stokes (RANS) equations offer a computationally\nefficient way of solving fluid flow problems in engineering applications.\nHowever, the use of closure models to represent turbulence effects can\ncompromise their accuracy. In order to address this issue, recent research has\nexplored data-driven techniques like data assimilation and machine learning. We\npresent an efficient variational data assimilation (DA) approach to enhance\nsteady-state RANS simulations based on eddy viscosity closure models. Our\nmethod introduces a corrective forcing term based on a potential field that is\ndivergence-free and enhances simulation accuracy. The DA implementation relies\non the discrete adjoint method and approximations for efficient gradient\nevaluation. The implementation is built on a two-dimensional coupled RANS\nsolver in \\emph{OpenFOAM}, which is extended to allow the computation of the\nadjoint velocity and pressure as well as the adjoint gradient. A gradient-based\noptimizer is employed to minimize the difference between the simulation results\nand the reference data. To assess this approach, it is compared with\nalternative data assimilation methods for canonical stationary two-dimensional\nturbulent flow problems. For the DA, sparsely distributed data from averaged\nhigh-fidelity simulation results are used. The findings indicate that the\nproposed method achieves the optimization goal more efficiently compared to\napplying data assimilation for obtaining the eddy viscosity, or a field\nmodifying the eddy viscosity, directly. It is sturdy with respect to varying\nthe regularization parameters and the number of reference data points, and runs\nefficiently by leveraging coarse meshes.",
            "author": [
                "Oliver Brenner",
                "Justin Plogmann",
                "Pasha Piroozmand",
                "Patrick Jenny"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11543v1",
                "http://arxiv.org/pdf/2310.11543v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11541v1",
            "title": "MUST&P-SRL: Multi-lingual and Unified Syllabification in Text and\n  Phonetic Domains for Speech Representation Learning",
            "updated": "2023-10-17T19:27:23Z",
            "published": "2023-10-17T19:27:23Z",
            "summary": "In this paper, we present a methodology for linguistic feature extraction,\nfocusing particularly on automatically syllabifying words in multiple\nlanguages, with a design to be compatible with a forced-alignment tool, the\nMontreal Forced Aligner (MFA). In both the textual and phonetic domains, our\nmethod focuses on the extraction of phonetic transcriptions from text, stress\nmarks, and a unified automatic syllabification (in text and phonetic domains).\nThe system was built with open-source components and resources. Through an\nablation study, we demonstrate the efficacy of our approach in automatically\nsyllabifying words from several languages (English, French and Spanish).\nAdditionally, we apply the technique to the transcriptions of the CMU ARCTIC\ndataset, generating valuable annotations available\nonline\\footnote{\\url{https://github.com/noetits/MUST_P-SRL}} that are ideal for\nspeech representation learning, speech unit discovery, and disentanglement of\nspeech factors in several speech-related fields.",
            "author": [
                "No\u00e9 Tits"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11541v1",
                "http://arxiv.org/pdf/2310.11541v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11535v1",
            "title": "Learning Lens Blur Fields",
            "updated": "2023-10-17T19:10:45Z",
            "published": "2023-10-17T19:10:45Z",
            "summary": "Optical blur is an inherent property of any lens system and is challenging to\nmodel in modern cameras because of their complex optical elements. To tackle\nthis challenge, we introduce a high-dimensional neural representation of\nblur$-$$\\textit{the lens blur field}$$-$and a practical method for acquiring\nit. The lens blur field is a multilayer perceptron (MLP) designed to (1)\naccurately capture variations of the lens 2D point spread function over image\nplane location, focus setting and, optionally, depth and (2) represent these\nvariations parametrically as a single, sensor-specific function. The\nrepresentation models the combined effects of defocus, diffraction, aberration,\nand accounts for sensor features such as pixel color filters and pixel-specific\nmicro-lenses. To learn the real-world blur field of a given device, we\nformulate a generalized non-blind deconvolution problem that directly optimizes\nthe MLP weights using a small set of focal stacks as the only input. We also\nprovide a first-of-its-kind dataset of 5D blur fields$-$for smartphone cameras,\ncamera bodies equipped with a variety of lenses, etc. Lastly, we show that\nacquired 5D blur fields are expressive and accurate enough to reveal, for the\nfirst time, differences in optical behavior of smartphone devices of the same\nmake and model.",
            "author": [
                "Esther Y. H. Lin",
                "Zhecheng Wang",
                "Rebecca Lin",
                "Daniel Miau",
                "Florian Kainz",
                "Jiawen Chen",
                "Xuaner Cecilia Zhang",
                "David B. Lindell",
                "Kiriakos N. Kutulakos"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11535v1",
                "http://arxiv.org/pdf/2310.11535v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11531v1",
            "title": "Efficient Online Learning with Offline Datasets for Infinite Horizon\n  MDPs: A Bayesian Approach",
            "updated": "2023-10-17T19:01:08Z",
            "published": "2023-10-17T19:01:08Z",
            "summary": "In this paper, we study the problem of efficient online reinforcement\nlearning in the infinite horizon setting when there is an offline dataset to\nstart with. We assume that the offline dataset is generated by an expert but\nwith unknown level of competence, i.e., it is not perfect and not necessarily\nusing the optimal policy. We show that if the learning agent models the\nbehavioral policy (parameterized by a competence parameter) used by the expert,\nit can do substantially better in terms of minimizing cumulative regret, than\nif it doesn't do that. We establish an upper bound on regret of the exact\ninformed PSRL algorithm that scales as $\\tilde{O}(\\sqrt{T})$. This requires a\nnovel prior-dependent regret analysis of Bayesian online learning algorithms\nfor the infinite horizon setting. We then propose an approximate Informed RLSVI\nalgorithm that we can interpret as performing imitation learning with the\noffline dataset, and then performing online learning.",
            "author": [
                "Dengwang Tang",
                "Rahul Jain",
                "Botao Hao",
                "Zheng Wen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11531v1",
                "http://arxiv.org/pdf/2310.11531v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.SY",
                "eess.SY",
                "stat.ML",
                "93E35"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11527v1",
            "title": "Thin and Deep Gaussian Processes",
            "updated": "2023-10-17T18:50:24Z",
            "published": "2023-10-17T18:50:24Z",
            "summary": "Gaussian processes (GPs) can provide a principled approach to uncertainty\nquantification with easy-to-interpret kernel hyperparameters, such as the\nlengthscale, which controls the correlation distance of function values.\nHowever, selecting an appropriate kernel can be challenging. Deep GPs avoid\nmanual kernel engineering by successively parameterizing kernels with GP\nlayers, allowing them to learn low-dimensional embeddings of the inputs that\nexplain the output data. Following the architecture of deep neural networks,\nthe most common deep GPs warp the input space layer-by-layer but lose all the\ninterpretability of shallow GPs. An alternative construction is to successively\nparameterize the lengthscale of a kernel, improving the interpretability but\nultimately giving away the notion of learning lower-dimensional embeddings.\nUnfortunately, both methods are susceptible to particular pathologies which may\nhinder fitting and limit their interpretability. This work proposes a novel\nsynthesis of both previous approaches: Thin and Deep GP (TDGP). Each TDGP layer\ndefines locally linear transformations of the original input data maintaining\nthe concept of latent embeddings while also retaining the interpretation of\nlengthscales of a kernel. Moreover, unlike the prior solutions, TDGP induces\nnon-pathological manifolds that admit learning lower-dimensional\nrepresentations. We show with theoretical and experimental results that i) TDGP\nis, unlike previous models, tailored to specifically discover lower-dimensional\nmanifolds in the input data, ii) TDGP behaves well when increasing the number\nof layers, and iii) TDGP performs well in standard benchmark datasets.",
            "author": [
                "Daniel Augusto de Souza",
                "Alexander Nikitin",
                "ST John",
                "Magnus Ross",
                "Mauricio A. \u00c1lvarez",
                "Marc Peter Deisenroth",
                "Jo\u00e3o P. P. Gomes",
                "Diego Mesquita",
                "C\u00e9sar Lincoln C. Mattos"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11527v1",
                "http://arxiv.org/pdf/2310.11527v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11523v1",
            "title": "Group Preference Optimization: Few-Shot Alignment of Large Language\n  Models",
            "updated": "2023-10-17T18:41:57Z",
            "published": "2023-10-17T18:41:57Z",
            "summary": "Many applications of large language models (LLMs), ranging from chatbots to\ncreative writing, require nuanced subjective judgments that can differ\nsignificantly across different groups. Existing alignment algorithms can be\nexpensive to align for each group, requiring prohibitive amounts of\ngroup-specific preference data and computation for real-world use cases. We\nintroduce Group Preference Optimization (GPO), an alignment framework that\nsteers language models to preferences of individual groups in a few-shot\nmanner. In GPO, we augment the base LLM with an independent transformer module\ntrained to predict the preferences of a group for the LLM generations. For\nfew-shot learning, we parameterize this module as an in-context autoregressive\ntransformer and train it via meta-learning on several groups. We empirically\nvalidate the efficacy of GPO through rigorous evaluations using LLMs with\nvaried sizes on three human opinion adaptation tasks. These tasks involve\nadapting to the preferences of US demographic groups, global countries, and\nindividual users. Our results demonstrate that GPO not only aligns models more\naccurately but also requires fewer group-specific preferences, and less\ntraining and inference computing resources, outperforming existing strategies\nsuch as in-context steering and fine-tuning methods.",
            "author": [
                "Siyan Zhao",
                "John Dang",
                "Aditya Grover"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11523v1",
                "http://arxiv.org/pdf/2310.11523v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11520v1",
            "title": "Automatic News Summerization",
            "updated": "2023-10-17T18:38:03Z",
            "published": "2023-10-17T18:38:03Z",
            "summary": "Natural Language Processing is booming with its applications in the real\nworld, one of which is Text Summarization for large texts including news\narticles. This research paper provides an extensive comparative evaluation of\nextractive and abstractive approaches for news text summarization, with an\nemphasis on the ROUGE score analysis. The study employs the CNN-Daily Mail\ndataset, which consists of news articles and human-generated reference\nsummaries. The evaluation employs ROUGE scores to assess the efficacy and\nquality of generated summaries. After Evaluation, we integrate the\nbest-performing models on a web application to assess their real-world\ncapabilities and user experience.",
            "author": [
                "Kavach Dheer",
                "Arpit Dhankhar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11520v1",
                "http://arxiv.org/pdf/2310.11520v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11518v3",
            "title": "Guarantees for Self-Play in Multiplayer Games via Polymatrix\n  Decomposability",
            "updated": "2023-11-29T17:39:17Z",
            "published": "2023-10-17T18:33:21Z",
            "summary": "Self-play is a technique for machine learning in multi-agent systems where a\nlearning algorithm learns by interacting with copies of itself. Self-play is\nuseful for generating large quantities of data for learning, but has the\ndrawback that the agents the learner will face post-training may have\ndramatically different behavior than the learner came to expect by interacting\nwith itself. For the special case of two-player constant-sum games, self-play\nthat reaches Nash equilibrium is guaranteed to produce strategies that perform\nwell against any post-training opponent; however, no such guarantee exists for\nmultiplayer games. We show that in games that approximately decompose into a\nset of two-player constant-sum games (called constant-sum polymatrix games)\nwhere global $\\epsilon$-Nash equilibria are boundedly far from Nash equilibria\nin each subgame (called subgame stability), any no-external-regret algorithm\nthat learns by self-play will produce a strategy with bounded vulnerability.\nFor the first time, our results identify a structural property of multiplayer\ngames that enable performance guarantees for the strategies produced by a broad\nclass of self-play algorithms. We demonstrate our findings through experiments\non Leduc poker.",
            "author": [
                "Revan MacQueen",
                "James R. Wright"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11518v3",
                "http://arxiv.org/pdf/2310.11518v3"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11515v1",
            "title": "Value-Biased Maximum Likelihood Estimation for Model-based Reinforcement\n  Learning in Discounted Linear MDPs",
            "updated": "2023-10-17T18:27:27Z",
            "published": "2023-10-17T18:27:27Z",
            "summary": "We consider the infinite-horizon linear Markov Decision Processes (MDPs),\nwhere the transition probabilities of the dynamic model can be linearly\nparameterized with the help of a predefined low-dimensional feature mapping.\nWhile the existing regression-based approaches have been theoretically shown to\nachieve nearly-optimal regret, they are computationally rather inefficient due\nto the need for a large number of optimization runs in each time step,\nespecially when the state and action spaces are large. To address this issue,\nwe propose to solve linear MDPs through the lens of Value-Biased Maximum\nLikelihood Estimation (VBMLE), which is a classic model-based exploration\nprinciple in the adaptive control literature for resolving the well-known\nclosed-loop identification problem of Maximum Likelihood Estimation. We\nformally show that (i) VBMLE enjoys $\\widetilde{O}(d\\sqrt{T})$ regret, where\n$T$ is the time horizon and $d$ is the dimension of the model parameter, and\n(ii) VBMLE is computationally more efficient as it only requires solving one\noptimization problem in each time step. In our regret analysis, we offer a\ngeneric convergence result of MLE in linear MDPs through a novel\nsupermartingale construct and uncover an interesting connection between linear\nMDPs and online learning, which could be of independent interest. Finally, the\nsimulation results show that VBMLE significantly outperforms the benchmark\nmethod in terms of both empirical regret and computation time.",
            "author": [
                "Yu-Heng Hung",
                "Ping-Chun Hsieh",
                "Akshay Mete",
                "P. R. Kumar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11515v1",
                "http://arxiv.org/pdf/2310.11515v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11513v1",
            "title": "GenEval: An Object-Focused Framework for Evaluating Text-to-Image\n  Alignment",
            "updated": "2023-10-17T18:20:03Z",
            "published": "2023-10-17T18:20:03Z",
            "summary": "Recent breakthroughs in diffusion models, multimodal pretraining, and\nefficient finetuning have led to an explosion of text-to-image generative\nmodels. Given human evaluation is expensive and difficult to scale, automated\nmethods are critical for evaluating the increasingly large number of new\nmodels. However, most current automated evaluation metrics like FID or\nCLIPScore only offer a holistic measure of image quality or image-text\nalignment, and are unsuited for fine-grained or instance-level analysis. In\nthis paper, we introduce GenEval, an object-focused framework to evaluate\ncompositional image properties such as object co-occurrence, position, count,\nand color. We show that current object detection models can be leveraged to\nevaluate text-to-image models on a variety of generation tasks with strong\nhuman agreement, and that other discriminative vision models can be linked to\nthis pipeline to further verify properties like object color. We then evaluate\nseveral open-source text-to-image models and analyze their relative generative\ncapabilities on our benchmark. We find that recent models demonstrate\nsignificant improvement on these tasks, though they are still lacking in\ncomplex capabilities such as spatial relations and attribute binding. Finally,\nwe demonstrate how GenEval might be used to help discover existing failure\nmodes, in order to inform development of the next generation of text-to-image\nmodels. Our code to run the GenEval framework is publicly available at\nhttps://github.com/djghosh13/geneval.",
            "author": [
                "Dhruba Ghosh",
                "Hanna Hajishirzi",
                "Ludwig Schmidt"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11513v1",
                "http://arxiv.org/pdf/2310.11513v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11511v1",
            "title": "Self-RAG: Learning to Retrieve, Generate, and Critique through\n  Self-Reflection",
            "updated": "2023-10-17T18:18:32Z",
            "published": "2023-10-17T18:18:32Z",
            "summary": "Despite their remarkable capabilities, large language models (LLMs) often\nproduce responses containing factual inaccuracies due to their sole reliance on\nthe parametric knowledge they encapsulate. Retrieval-Augmented Generation\n(RAG), an ad hoc approach that augments LMs with retrieval of relevant\nknowledge, decreases such issues. However, indiscriminately retrieving and\nincorporating a fixed number of retrieved passages, regardless of whether\nretrieval is necessary, or passages are relevant, diminishes LM versatility or\ncan lead to unhelpful response generation. We introduce a new framework called\nSelf-Reflective Retrieval-Augmented Generation (Self-RAG) that enhances an LM's\nquality and factuality through retrieval and self-reflection. Our framework\ntrains a single arbitrary LM that adaptively retrieves passages on-demand, and\ngenerates and reflects on retrieved passages and its own generations using\nspecial tokens, called reflection tokens. Generating reflection tokens makes\nthe LM controllable during the inference phase, enabling it to tailor its\nbehavior to diverse task requirements. Experiments show that Self-RAG (7B and\n13B parameters) significantly outperforms state-of-the-art LLMs and\nretrieval-augmented models on a diverse set of tasks. Specifically, Self-RAG\noutperforms ChatGPT and retrieval-augmented Llama2-chat on Open-domain QA,\nreasoning and fact verification tasks, and it shows significant gains in\nimproving factuality and citation accuracy for long-form generations relative\nto these models.",
            "author": [
                "Akari Asai",
                "Zeqiu Wu",
                "Yizhong Wang",
                "Avirup Sil",
                "Hannaneh Hajishirzi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11511v1",
                "http://arxiv.org/pdf/2310.11511v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11499v1",
            "title": "The JWST Early Release Science Program for Direct Observations of\n  Exoplanetary Systems IV: NIRISS Aperture Masking Interferometry Performance\n  and Lessons Learned",
            "updated": "2023-10-17T18:00:07Z",
            "published": "2023-10-17T18:00:07Z",
            "summary": "We present a performance analysis for the aperture masking interferometry\n(AMI) mode on board the James Webb Space Telescope Near Infrared Imager and\nSlitless Spectrograph (JWST/NIRISS). Thanks to self-calibrating observables,\nAMI accesses inner working angles down to and even within the classical\ndiffraction limit. The scientific potential of this mode has recently been\ndemonstrated by the Early Release Science (ERS) 1386 program with a deep search\nfor close-in companions in the HIP 65426 exoplanetary system. As part of ERS\n1386, we use the same dataset to explore the random, static, and calibration\nerrors of NIRISS AMI observables. We compare the observed noise properties and\nachievable contrast to theoretical predictions. We explore possible sources of\ncalibration errors, and show that differences in charge migration between the\nobservations of HIP 65426 and point-spread function calibration stars can\naccount for the achieved contrast curves. Lastly, we use self-calibration tests\nto demonstrate that with adequate calibration, NIRISS AMI can reach contrast\nlevels of $\\sim9-10$ mag. These tests lead us to observation planning\nrecommendations and strongly motivate future studies aimed at producing\nsophisticated calibration strategies taking these systematic effects into\naccount. This will unlock the unprecedented capabilities of JWST/NIRISS AMI,\nwith sensitivity to significantly colder, lower mass exoplanets than\nground-based setups at orbital separations inaccessible to JWST coronagraphy.",
            "author": [
                "Steph Sallum",
                "Shrishmoy Ray",
                "Jens Kammerer",
                "Anand Sivaramakrishnan",
                "Rachel Cooper",
                "Alexandra Z. Greebaum",
                "Deepashri Thatte",
                "Matthew de Furio",
                "Samuel Factor",
                "Michael Meyer",
                "Jordan M. Stone",
                "Aarynn Carter",
                "Beth Biller",
                "Sasha Hinkley",
                "Andrew Skemer",
                "Genaro Suarez",
                "Jarron M. Leisenring",
                "Marshall D. Perrin",
                "Adam L. Kraus",
                "Olivier Absil",
                "William O. Balmer",
                "Mickael Bonnefoy",
                "Marta L. Bryan",
                "Sarah K. Betti",
                "Anthony Boccaletti",
                "Mariangela Bonavita",
                "Mark Booth",
                "Brendan P. Bowler",
                "Zackery W. Briesemeister",
                "Faustine Cantalloube",
                "Gael Chauvin",
                "Valentin Christiaens",
                "Gabriele Cugno",
                "Thayne Currie",
                "Camilla Danielski",
                "Trent J. Dupuy",
                "Jacqueline K. Faherty",
                "Christine H. Chen",
                "Per Calissendorff",
                "Elodie Choquet",
                "Michael P. Fitzgerald",
                "Jonathan J. Fortney",
                "Kyle Franson",
                "Julien H. Girard",
                "Carol A. Grady",
                "Eileen C. Gonzales",
                "Thomas Henning",
                "Dean C. Hines",
                "Kielan K. W. Hoch",
                "Callie E. Hood",
                "Alex R. Howe",
                "Markus Janson",
                "Paul Kalas",
                "Grant M. Kennedy",
                "Matthew A. Kenworthy",
                "Pierre Kervella",
                "Daniel Kitzmann",
                "Masayuki Kuzuhara",
                "Anne-Marie Lagrange",
                "Pierre-Olivier Lagage",
                "Kellen Lawson",
                "Cecilia Lazzoni",
                "Ben W. P. Lew",
                "Michael C. Liu",
                "Pengyu Liu",
                "Jorge Llop-Sayson",
                "James P. Lloyd",
                "Anna Lueber",
                "Bruce Macintosh",
                "Elena Manjavacas",
                "Sebastian Marino",
                "Mark S. Marley",
                "Christian Marois",
                "Raquel A. Martinez",
                "Brenda C. Matthews",
                "Elisabeth C. Matthews",
                "Dimitri Mawet",
                "Johan Mazoyer",
                "Michael W. McElwain",
                "Stanimir Metchev",
                "Brittany E. Miles",
                "Maxwell A. Millar-Blanchaer",
                "Paul Molliere",
                "Sarah E. Moran",
                "Caroline V. Morley",
                "Sagnick Mukherjee",
                "Paulina Palma-Bifani",
                "Eric Pantin",
                "Polychronis Patapis",
                "Simon Petrus",
                "Laurent Pueyo",
                "Sascha P. Quanz",
                "Andreas Quirrenbach",
                "Isabel Rebollido",
                "Jea Adams Redai",
                "Bin B. Ren",
                "Emily Rickman",
                "Matthias Samland",
                "B. A. Sargent",
                "Joshua E. Schlieder",
                "Glenn Schneider",
                "Karl R. Stapelfeldt",
                "Ben J. Sutlieff",
                "Motohide Tamura",
                "Xianyu Tan",
                "Christopher A. Theissen",
                "Taichi Uyama",
                "Arthur Vigan",
                "Malavika Vasist",
                "Johanna M. Vos",
                "Kevin Wagner",
                "Jason J. Wang",
                "Kimberly Ward-Duong",
                "Niall Whiteford",
                "Schuyler G. Wolff",
                "Kadin Worthen",
                "Mark C. Wyatt",
                "Marie Ygouf",
                "Xi Zhang",
                "Keming Zhang",
                "Zhoujian Zhang",
                "Yifan Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11499v1",
                "http://arxiv.org/pdf/2310.11499v1"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11454v1",
            "title": "VeRA: Vector-based Random Matrix Adaptation",
            "updated": "2023-10-17T17:59:46Z",
            "published": "2023-10-17T17:59:46Z",
            "summary": "Low-rank adapation (LoRA) is a popular method that reduces the number of\ntrainable parameters when finetuning large language models, but still faces\nacute storage challenges when scaling to even larger models or deploying\nnumerous per-user or per-task adapted models. In this work, we present\nVector-based Random Matrix Adaptation (VeRA), which reduces the number of\ntrainable parameters by 10x compared to LoRA, yet maintains the same\nperformance. It achieves this by using a single pair of low-rank matrices\nshared across all layers and learning small scaling vectors instead. We\ndemonstrate its effectiveness on the GLUE and E2E benchmarks, and show its\napplication in instruction-following with just 1.4M parameters using the Llama2\n7B model.",
            "author": [
                "Dawid Jan Kopiczko",
                "Tijmen Blankevoort",
                "Yuki Markus Asano"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11454v1",
                "http://arxiv.org/pdf/2310.11454v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11451v1",
            "title": "Seeking Neural Nuggets: Knowledge Transfer in Large Language Models from\n  a Parametric Perspective",
            "updated": "2023-10-17T17:58:34Z",
            "published": "2023-10-17T17:58:34Z",
            "summary": "Large Language Models (LLMs) inherently encode a wealth of knowledge within\ntheir parameters through pre-training on extensive corpora. While prior\nresearch has delved into operations on these parameters to manipulate the\nunderlying implicit knowledge (encompassing detection, editing, and merging),\nthere remains an ambiguous understanding regarding their transferability across\nmodels with varying scales. In this paper, we seek to empirically investigate\nknowledge transfer from larger to smaller models through a parametric\nperspective. To achieve this, we employ sensitivity-based techniques to extract\nand align knowledge-specific parameters between different LLMs. Moreover, the\nLoRA module is used as the intermediary mechanism for injecting the extracted\nknowledge into smaller models. Evaluations across four benchmarks validate the\nefficacy of our proposed method. Our findings highlight the critical factors\ncontributing to the process of parametric knowledge transfer, underscoring the\ntransferability of model parameters across LLMs of different scales. We release\ncode and data at \\url{https://github.com/maszhongming/ParaKnowTransfer}.",
            "author": [
                "Ming Zhong",
                "Chenxin An",
                "Weizhu Chen",
                "Jiawei Han",
                "Pengcheng He"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11451v1",
                "http://arxiv.org/pdf/2310.11451v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11450v1",
            "title": "Explaining Deep Neural Networks for Bearing Fault Detection with\n  Vibration Concepts",
            "updated": "2023-10-17T17:58:19Z",
            "published": "2023-10-17T17:58:19Z",
            "summary": "Concept-based explanation methods, such as Concept Activation Vectors, are\npotent means to quantify how abstract or high-level characteristics of input\ndata influence the predictions of complex deep neural networks. However,\napplying them to industrial prediction problems is challenging as it is not\nimmediately clear how to define and access appropriate concepts for individual\nuse cases and specific data types. In this work, we investigate how to leverage\nestablished concept-based explanation techniques in the context of bearing\nfault detection with deep neural networks trained on vibration signals. Since\nbearings are prevalent in almost every rotating equipment, ensuring the\nreliability of intransparent fault detection models is crucial to prevent\ncostly repairs and downtimes of industrial machinery. Our evaluations\ndemonstrate that explaining opaque models in terms of vibration concepts\nenables human-comprehensible and intuitive insights about their inner workings,\nbut the underlying assumptions need to be carefully validated first.",
            "author": [
                "Thomas Decker",
                "Michael Lebacher",
                "Volker Tresp"
            ],
            "link": [
                "http://dx.doi.org/10.1109/INDIN51400.2023.10218170",
                "http://arxiv.org/abs/2310.11450v1",
                "http://arxiv.org/pdf/2310.11450v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13014v1",
            "title": "Large Language Model Prediction Capabilities: Evidence from a Real-World\n  Forecasting Tournament",
            "updated": "2023-10-17T17:58:17Z",
            "published": "2023-10-17T17:58:17Z",
            "summary": "Accurately predicting the future would be an important milestone in the\ncapabilities of artificial intelligence. However, research on the ability of\nlarge language models to provide probabilistic predictions about future events\nremains nascent. To empirically test this ability, we enrolled OpenAI's\nstate-of-the-art large language model, GPT-4, in a three-month forecasting\ntournament hosted on the Metaculus platform. The tournament, running from July\nto October 2023, attracted 843 participants and covered diverse topics\nincluding Big Tech, U.S. politics, viral outbreaks, and the Ukraine conflict.\nFocusing on binary forecasts, we show that GPT-4's probabilistic forecasts are\nsignificantly less accurate than the median human-crowd forecasts. We find that\nGPT-4's forecasts did not significantly differ from the no-information\nforecasting strategy of assigning a 50% probability to every question. We\nexplore a potential explanation, that GPT-4 might be predisposed to predict\nprobabilities close to the midpoint of the scale, but our data do not support\nthis hypothesis. Overall, we find that GPT-4 significantly underperforms in\nreal-world predictive tasks compared to median human-crowd forecasts. A\npotential explanation for this underperformance is that in real-world\nforecasting tournaments, the true answers are genuinely unknown at the time of\nprediction; unlike in other benchmark tasks like professional exams or time\nseries forecasting, where strong performance may at least partly be due to the\nanswers being memorized from the training data. This makes real-world\nforecasting tournaments an ideal environment for testing the generalized\nreasoning and prediction capabilities of artificial intelligence going forward.",
            "author": [
                "Philipp Schoenegger",
                "Peter S. Park"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13014v1",
                "http://arxiv.org/pdf/2310.13014v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11449v1",
            "title": "DELIFFAS: Deformable Light Fields for Fast Avatar Synthesis",
            "updated": "2023-10-17T17:58:00Z",
            "published": "2023-10-17T17:58:00Z",
            "summary": "Generating controllable and photorealistic digital human avatars is a\nlong-standing and important problem in Vision and Graphics. Recent methods have\nshown great progress in terms of either photorealism or inference speed while\nthe combination of the two desired properties still remains unsolved. To this\nend, we propose a novel method, called DELIFFAS, which parameterizes the\nappearance of the human as a surface light field that is attached to a\ncontrollable and deforming human mesh model. At the core, we represent the\nlight field around the human with a deformable two-surface parameterization,\nwhich enables fast and accurate inference of the human appearance. This allows\nperceptual supervision on the full image compared to previous approaches that\ncould only supervise individual pixels or small patches due to their slow\nruntime. Our carefully designed human representation and supervision strategy\nleads to state-of-the-art synthesis results and inference time. The video\nresults and code are available at\nhttps://vcai.mpi-inf.mpg.de/projects/DELIFFAS.",
            "author": [
                "Youngjoong Kwon",
                "Lingjie Liu",
                "Henry Fuchs",
                "Marc Habermann",
                "Christian Theobalt"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11449v1",
                "http://arxiv.org/pdf/2310.11449v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11448v3",
            "title": "4K4D: Real-Time 4D View Synthesis at 4K Resolution",
            "updated": "2023-10-28T06:41:48Z",
            "published": "2023-10-17T17:57:38Z",
            "summary": "This paper targets high-fidelity and real-time view synthesis of dynamic 3D\nscenes at 4K resolution. Recently, some methods on dynamic view synthesis have\nshown impressive rendering quality. However, their speed is still limited when\nrendering high-resolution images. To overcome this problem, we propose 4K4D, a\n4D point cloud representation that supports hardware rasterization and enables\nunprecedented rendering speed. Our representation is built on a 4D feature grid\nso that the points are naturally regularized and can be robustly optimized. In\naddition, we design a novel hybrid appearance model that significantly boosts\nthe rendering quality while preserving efficiency. Moreover, we develop a\ndifferentiable depth peeling algorithm to effectively learn the proposed model\nfrom RGB videos. Experiments show that our representation can be rendered at\nover 400 FPS on the DNA-Rendering dataset at 1080p resolution and 80 FPS on the\nENeRF-Outdoor dataset at 4K resolution using an RTX 4090 GPU, which is 30x\nfaster than previous methods and achieves the state-of-the-art rendering\nquality. Our project page is available at https://zju3dv.github.io/4k4d/.",
            "author": [
                "Zhen Xu",
                "Sida Peng",
                "Haotong Lin",
                "Guangzhao He",
                "Jiaming Sun",
                "Yujun Shen",
                "Hujun Bao",
                "Xiaowei Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11448v3",
                "http://arxiv.org/pdf/2310.11448v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11445v1",
            "title": "Stochastic Quantum Sampling for Non-Logconcave Distributions and\n  Estimating Partition Functions",
            "updated": "2023-10-17T17:55:32Z",
            "published": "2023-10-17T17:55:32Z",
            "summary": "We present quantum algorithms for sampling from non-logconcave probability\ndistributions in the form of $\\pi(x) \\propto \\exp(-\\beta f(x))$. Here, $f$ can\nbe written as a finite sum $f(x):= \\frac{1}{N}\\sum_{k=1}^N f_k(x)$. Our\napproach is based on quantum simulated annealing on slowly varying Markov\nchains derived from unadjusted Langevin algorithms, removing the necessity for\nfunction evaluations which can be computationally expensive for large data sets\nin mixture modeling and multi-stable systems. We also incorporate a stochastic\ngradient oracle that implements the quantum walk operators inexactly by only\nusing mini-batch gradients. As a result, our stochastic gradient based\nalgorithm only accesses small subsets of data points in implementing the\nquantum walk. One challenge of quantizing the resulting Markov chains is that\nthey do not satisfy the detailed balance condition in general. Consequently,\nthe mixing time of the algorithm cannot be expressed in terms of the spectral\ngap of the transition density, making the quantum algorithms nontrivial to\nanalyze. To overcome these challenges, we first build a hypothetical Markov\nchain that is reversible, and also converges to the target distribution. Then,\nwe quantified the distance between our algorithm's output and the target\ndistribution by using this hypothetical chain as a bridge to establish the\ntotal complexity. Our quantum algorithms exhibit polynomial speedups in terms\nof both dimension and precision dependencies when compared to the best-known\nclassical algorithms.",
            "author": [
                "Guneykan Ozgul",
                "Xiantao Li",
                "Mehrdad Mahdavi",
                "Chunhao Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11445v1",
                "http://arxiv.org/pdf/2310.11445v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06275v1",
            "title": "Algorithmic Robustness",
            "updated": "2023-10-17T17:51:12Z",
            "published": "2023-10-17T17:51:12Z",
            "summary": "Algorithmic robustness refers to the sustained performance of a computational\nsystem in the face of change in the nature of the environment in which that\nsystem operates or in the task that the system is meant to perform. Below, we\nmotivate the importance of algorithmic robustness, present a conceptual\nframework, and highlight the relevant areas of research for which algorithmic\nrobustness is relevant. Why robustness? Robustness is an important enabler of\nother goals that are frequently cited in the context of public policy decisions\nabout computational systems, including trustworthiness, accountability,\nfairness, and safety. Despite this dependence, it tends to be under-recognized\ncompared to these other concepts. This is unfortunate, because robustness is\noften more immediately achievable than these other ultimate goals, which can be\nmore subjective and exacting. Thus, we highlight robustness as an important\ngoal for researchers, engineers, regulators, and policymakers when considering\nthe design, implementation, and deployment of computational systems. We urge\nresearchers and practitioners to elevate the attention paid to robustness when\ndesigning and evaluating computational systems. For many key systems, the\nimmediate question after any demonstration of high performance should be: \"How\nrobust is that performance to realistic changes in the task or environment?\"\nGreater robustness will set the stage for systems that are more trustworthy,\naccountable, fair, and safe. Toward that end, this document provides a brief\nroadmap to some of the concepts and existing research around the idea of\nalgorithmic robustness.",
            "author": [
                "David Jensen",
                "Brian LaMacchia",
                "Ufuk Topcu",
                "Pamela Wisniewski"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06275v1",
                "http://arxiv.org/pdf/2311.06275v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11439v1",
            "title": "Understanding deep neural networks through the lens of their\n  non-linearity",
            "updated": "2023-10-17T17:50:22Z",
            "published": "2023-10-17T17:50:22Z",
            "summary": "The remarkable success of deep neural networks (DNN) is often attributed to\ntheir high expressive power and their ability to approximate functions of\narbitrary complexity. Indeed, DNNs are highly non-linear models, and activation\nfunctions introduced into them are largely responsible for this. While many\nworks studied the expressive power of DNNs through the lens of their\napproximation capabilities, quantifying the non-linearity of DNNs or of\nindividual activation functions remains an open problem. In this paper, we\npropose the first theoretically sound solution to track non-linearity\npropagation in deep neural networks with a specific focus on computer vision\napplications. Our proposed affinity score allows us to gain insights into the\ninner workings of a wide range of different architectures and learning\nparadigms. We provide extensive experimental results that highlight the\npractical utility of the proposed affinity score and its potential for\nlong-reaching applications.",
            "author": [
                "Quentin Bouniot",
                "Ievgen Redko",
                "Anton Mallasto",
                "Charlotte Laclau",
                "Karol Arndt",
                "Oliver Struckmeier",
                "Markus Heinonen",
                "Ville Kyrki",
                "Samuel Kaski"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11439v1",
                "http://arxiv.org/pdf/2310.11439v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11435v1",
            "title": "Uncertainty Quantification For Turbulent Flows with Machine Learning",
            "updated": "2023-10-17T17:45:56Z",
            "published": "2023-10-17T17:45:56Z",
            "summary": "Turbulent flows are of central importance across applications in science and\nengineering problems. For design and analysis, scientists and engineers use\nComputational Fluid Dynamics (CFD) simulations using turbulence models.\nTurbulent models are limited approximations, introducing epistemic uncertainty\nin CFD results. For reliable design and analysis, we require quantification of\nthese uncertainties. The Eigenspace Perturbation Method (EPM) is the preeminent\nphysics based approach for turbulence model UQ, but often leads to overly\nconservative uncertainty bounds. In this study, we use Machine Learning (ML)\nmodels to moderate the EPM perturbations and introduce our physics constrained\nmachine learning framework for turbulence model UQ. We test this framework in\nmultiple problems to show that it leads to improved calibration of the\nuncertainty estimates.",
            "author": [
                "Minghan Chu",
                "Weicheng Qian"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11435v1",
                "http://arxiv.org/pdf/2310.11435v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11431v2",
            "title": "Identifying Interpretable Visual Features in Artificial and Biological\n  Neural Systems",
            "updated": "2023-10-18T02:02:33Z",
            "published": "2023-10-17T17:41:28Z",
            "summary": "Single neurons in neural networks are often interpretable in that they\nrepresent individual, intuitively meaningful features. However, many neurons\nexhibit $\\textit{mixed selectivity}$, i.e., they represent multiple unrelated\nfeatures. A recent hypothesis proposes that features in deep networks may be\nrepresented in $\\textit{superposition}$, i.e., on non-orthogonal axes by\nmultiple neurons, since the number of possible interpretable features in\nnatural data is generally larger than the number of neurons in a given network.\nAccordingly, we should be able to find meaningful directions in activation\nspace that are not aligned with individual neurons. Here, we propose (1) an\nautomated method for quantifying visual interpretability that is validated\nagainst a large database of human psychophysics judgments of neuron\ninterpretability, and (2) an approach for finding meaningful directions in\nnetwork activation space. We leverage these methods to discover directions in\nconvolutional neural networks that are more intuitively meaningful than\nindividual neurons, as we confirm and investigate in a series of analyses.\nMoreover, we apply the same method to three recent datasets of visual neural\nresponses in the brain and find that our conclusions largely transfer to real\nneural data, suggesting that superposition might be deployed by the brain. This\nalso provides a link with disentanglement and raises fundamental questions\nabout robust, efficient and factorized representations in both artificial and\nbiological neural systems.",
            "author": [
                "David Klindt",
                "Sophia Sanborn",
                "Francisco Acosta",
                "Fr\u00e9d\u00e9ric Poitevin",
                "Nina Miolane"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11431v2",
                "http://arxiv.org/pdf/2310.11431v2"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11430v1",
            "title": "An Empirical Study of Translation Hypothesis Ensembling with Large\n  Language Models",
            "updated": "2023-10-17T17:40:21Z",
            "published": "2023-10-17T17:40:21Z",
            "summary": "Large language models (LLMs) are becoming a one-fits-many solution, but they\nsometimes hallucinate or produce unreliable output. In this paper, we\ninvestigate how hypothesis ensembling can improve the quality of the generated\ntext for the specific problem of LLM-based machine translation. We experiment\nwith several techniques for ensembling hypotheses produced by LLMs such as\nChatGPT, LLaMA, and Alpaca. We provide a comprehensive study along multiple\ndimensions, including the method to generate hypotheses (multiple prompts,\ntemperature-based sampling, and beam search) and the strategy to produce the\nfinal translation (instruction-based, quality-based reranking, and minimum\nBayes risk (MBR) decoding). Our results show that MBR decoding is a very\neffective method, that translation quality can be improved using a small number\nof samples, and that instruction tuning has a strong impact on the relation\nbetween the diversity of the hypotheses and the sampling temperature.",
            "author": [
                "Ant\u00f3nio Farinhas",
                "Jos\u00e9 G. C. de Souza",
                "Andr\u00e9 F. T. Martins"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11430v1",
                "http://arxiv.org/pdf/2310.11430v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11428v1",
            "title": "Butterfly Effects of SGD Noise: Error Amplification in Behavior Cloning\n  and Autoregression",
            "updated": "2023-10-17T17:39:40Z",
            "published": "2023-10-17T17:39:40Z",
            "summary": "This work studies training instabilities of behavior cloning with deep neural\nnetworks. We observe that minibatch SGD updates to the policy network during\ntraining result in sharp oscillations in long-horizon rewards, despite\nnegligibly affecting the behavior cloning loss. We empirically disentangle the\nstatistical and computational causes of these oscillations, and find them to\nstem from the chaotic propagation of minibatch SGD noise through unstable\nclosed-loop dynamics. While SGD noise is benign in the single-step action\nprediction objective, it results in catastrophic error accumulation over long\nhorizons, an effect we term gradient variance amplification (GVA). We show that\nmany standard mitigation techniques do not alleviate GVA, but find an\nexponential moving average (EMA) of iterates to be surprisingly effective at\ndoing so. We illustrate the generality of this phenomenon by showing the\nexistence of GVA and its amelioration by EMA in both continuous control and\nautoregressive language generation. Finally, we provide theoretical vignettes\nthat highlight the benefits of EMA in alleviating GVA and shed light on the\nextent to which classical convex models can help in understanding the benefits\nof iterate averaging in deep learning.",
            "author": [
                "Adam Block",
                "Dylan J. Foster",
                "Akshay Krishnamurthy",
                "Max Simchowitz",
                "Cyril Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11428v1",
                "http://arxiv.org/pdf/2310.11428v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11423v1",
            "title": "Predicting polymerization reactions via transfer learning using chemical\n  language models",
            "updated": "2023-10-17T17:31:52Z",
            "published": "2023-10-17T17:31:52Z",
            "summary": "Polymers are candidate materials for a wide range of sustainability\napplications such as carbon capture and energy storage. However, computational\npolymer discovery lacks automated analysis of reaction pathways and stability\nassessment through retro-synthesis. Here, we report the first extension of\ntransformer-based language models to polymerization reactions for both forward\nand retrosynthesis tasks. To that end, we have curated a polymerization dataset\nfor vinyl polymers covering reactions and retrosynthesis for representative\nhomo-polymers and co-polymers. Overall, we obtain a forward model Top-4\naccuracy of 80% and a backward model Top-4 accuracy of 60%. We further analyze\nthe model performance with representative polymerization and retro-synthesis\nexamples and evaluate its prediction quality from a materials science\nperspective.",
            "author": [
                "Brenda S. Ferrari",
                "Matteo Manica",
                "Ronaldo Giro",
                "Teodoro Laino",
                "Mathias B. Steiner"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11423v1",
                "http://arxiv.org/pdf/2310.11423v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11420v1",
            "title": "Revisiting Map Relations for Unsupervised Non-Rigid Shape Matching",
            "updated": "2023-10-17T17:28:03Z",
            "published": "2023-10-17T17:28:03Z",
            "summary": "We propose a novel unsupervised learning approach for non-rigid 3D shape\nmatching. Our approach improves upon recent state-of-the art deep functional\nmap methods and can be applied to a broad range of different challenging\nscenarios. Previous deep functional map methods mainly focus on feature\nextraction and aim exclusively at obtaining more expressive features for\nfunctional map computation. However, the importance of the functional map\ncomputation itself is often neglected and the relationship between the\nfunctional map and point-wise map is underexplored. In this paper, we\nsystematically investigate the coupling relationship between the functional map\nfrom the functional map solver and the point-wise map based on feature\nsimilarity. To this end, we propose a self-adaptive functional map solver to\nadjust the functional map regularisation for different shape matching\nscenarios, together with a vertex-wise contrastive loss to obtain more\ndiscriminative features. Using different challenging datasets (including\nnon-isometry, topological noise and partiality), we demonstrate that our method\nsubstantially outperforms previous state-of-the-art methods.",
            "author": [
                "Dongliang Cao",
                "Paul Roetzer",
                "Florian Bernard"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11420v1",
                "http://arxiv.org/pdf/2310.11420v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11417v1",
            "title": "VcT: Visual change Transformer for Remote Sensing Image Change Detection",
            "updated": "2023-10-17T17:25:31Z",
            "published": "2023-10-17T17:25:31Z",
            "summary": "Existing visual change detectors usually adopt CNNs or Transformers for\nfeature representation learning and focus on learning effective representation\nfor the changed regions between images. Although good performance can be\nobtained by enhancing the features of the change regions, however, these works\nare still limited mainly due to the ignorance of mining the unchanged\nbackground context information. It is known that one main challenge for change\ndetection is how to obtain the consistent representations for two images\ninvolving different variations, such as spatial variation, sunlight intensity,\netc. In this work, we demonstrate that carefully mining the common background\ninformation provides an important cue to learn the consistent representations\nfor the two images which thus obviously facilitates the visual change detection\nproblem. Based on this observation, we propose a novel Visual change\nTransformer (VcT) model for visual change detection problem. To be specific, a\nshared backbone network is first used to extract the feature maps for the given\nimage pair. Then, each pixel of feature map is regarded as a graph node and the\ngraph neural network is proposed to model the structured information for coarse\nchange map prediction. Top-K reliable tokens can be mined from the map and\nrefined by using the clustering algorithm. Then, these reliable tokens are\nenhanced by first utilizing self/cross-attention schemes and then interacting\nwith original features via an anchor-primary attention learning module.\nFinally, the prediction head is proposed to get a more accurate change map.\nExtensive experiments on multiple benchmark datasets validated the\neffectiveness of our proposed VcT model.",
            "author": [
                "Bo Jiang",
                "Zitian Wang",
                "Xixi Wang",
                "Ziyan Zhang",
                "Lan Chen",
                "Xiao Wang",
                "Bin Luo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11417v1",
                "http://arxiv.org/pdf/2310.11417v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11409v2",
            "title": "Evaluating LLMs for Privilege-Escalation Scenarios",
            "updated": "2023-10-23T16:48:02Z",
            "published": "2023-10-17T17:15:41Z",
            "summary": "Penetration testing, an essential component of cybersecurity, allows\norganizations to proactively identify and remediate vulnerabilities in their\nsystems, thus bolstering their defense mechanisms against potential\ncyberattacks. One recent advancement in the realm of penetration testing is the\nutilization of Language Models (LLMs). We explore the intersection of LLMs and\npenetration testing to gain insight into their capabilities and challenges in\nthe context of privilige escalation. We create an automated Linux\nprivilege-escalation benchmark utilizing local virtual machines. We introduce\nan LLM-guided privilege-escalation tool designed for evaluating different LLMs\nand prompt strategies against our benchmark. We analyze the impact of different\nprompt designs, the benefits of in-context learning, and the advantages of\noffering high-level guidance to LLMs. We discuss challenging areas for LLMs,\nincluding maintaining focus during testing, coping with errors, and finally\ncomparing them with both stochastic parrots as well as with human hackers.",
            "author": [
                "Andreas Happe",
                "Aaron Kaplan",
                "J\u00fcrgen Cito"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11409v2",
                "http://arxiv.org/pdf/2310.11409v2"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11407v1",
            "title": "Group-blind optimal transport to group parity and its constrained\n  variants",
            "updated": "2023-10-17T17:14:07Z",
            "published": "2023-10-17T17:14:07Z",
            "summary": "Fairness holds a pivotal role in the realm of machine learning, particularly\nwhen it comes to addressing groups categorised by sensitive attributes, e.g.,\ngender, race. Prevailing algorithms in fair learning predominantly hinge on\naccessibility or estimations of these sensitive attributes, at least in the\ntraining process. We design a single group-blind projection map that aligns the\nfeature distributions of both groups in the source data, achieving\n(demographic) group parity, without requiring values of the protected attribute\nfor individual samples in the computation of the map, as well as its use.\nInstead, our approach utilises the feature distributions of the privileged and\nunprivileged groups in a boarder population and the essential assumption that\nthe source data are unbiased representation of the population. We present\nnumerical results on synthetic data and real data.",
            "author": [
                "Quan Zhou",
                "Jakub Marecek"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11407v1",
                "http://arxiv.org/pdf/2310.11407v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11406v1",
            "title": "GreenNFV: Energy-Efficient Network Function Virtualization with Service\n  Level Agreement Constraints",
            "updated": "2023-10-17T17:14:01Z",
            "published": "2023-10-17T17:14:01Z",
            "summary": "Network Function Virtualization (NFV) platforms consume significant energy,\nintroducing high operational costs in edge and data centers. This paper\npresents a novel framework called GreenNFV that optimizes resource usage for\nnetwork function chains using deep reinforcement learning. GreenNFV optimizes\nresource parameters such as CPU sharing ratio, CPU frequency scaling,\nlast-level cache (LLC) allocation, DMA buffer size, and packet batch size.\nGreenNFV learns the resource scheduling model from the benchmark experiments\nand takes Service Level Agreements (SLAs) into account to optimize resource\nusage models based on the different throughput and energy consumption\nrequirements. Our evaluation shows that GreenNFV models achieve high transfer\nthroughput and low energy consumption while satisfying various SLA constraints.\nSpecifically, GreenNFV with Throughput SLA can achieve $4.4\\times$ higher\nthroughput and $1.5\\times$ better energy efficiency over the baseline settings,\nwhereas GreenNFV with Energy SLA can achieve $3\\times$ higher throughput while\nreducing energy consumption by 50%.",
            "author": [
                "MD S Q Zulkar Nine",
                "Tevfik Kosar",
                "Fatih Bulut",
                "Jinho Hwang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11406v1",
                "http://arxiv.org/pdf/2310.11406v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11405v1",
            "title": "On Coherence-based Predictors for Dense Query Performance Prediction",
            "updated": "2023-10-17T17:13:13Z",
            "published": "2023-10-17T17:13:13Z",
            "summary": "Query Performance Prediction (QPP) estimates the effectiveness of a search\nengine's results in response to a query without relevance judgments.\nTraditionally, post-retrieval predictors have focused upon either the\ndistribution of the retrieval scores, or the coherence of the top-ranked\ndocuments using traditional bag-of-words index representations. More recently,\nBERT-based models using dense embedded document representations have been used\nto create new predictors, but mostly applied to predict the performance of\nrankings created by BM25. Instead, we aim to predict the effectiveness of\nrankings created by single-representation dense retrieval models (ANCE &\nTCT-ColBERT). Therefore, we propose a number of variants of existing\nunsupervised coherence-based predictors that employ neural embedding\nrepresentations. In our experiments on the TREC Deep Learning Track datasets,\nwe demonstrate improved accuracy upon dense retrieval (up to 92% compared to\nsparse variants for TCT-ColBERT and 188% for ANCE). Going deeper, we select the\nmost representative and best performing predictors to study the importance of\ndifferences among predictors and query types on query performance. Using\nexisting distribution-based evaluation QPP measures and a particular type of\nlinear mixed models, we find that query types further significantly influence\nquery performance (and are up to 35% responsible for the unstable performance\nof QPP predictors), and that this sensitivity is unique to dense retrieval\nmodels. Our approach introduces a new setting for obtaining richer information\non query differences in dense QPP that can explain potential unstable\nperformance of existing predictors and outlines the unique characteristics of\ndifferent query types on dense retrieval models.",
            "author": [
                "Maria Vlachou",
                "Craig Macdonald"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11405v1",
                "http://arxiv.org/pdf/2310.11405v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11401v1",
            "title": "Enhancing Group Fairness in Online Settings Using Oblique Decision\n  Forests",
            "updated": "2023-10-17T17:10:56Z",
            "published": "2023-10-17T17:10:56Z",
            "summary": "Fairness, especially group fairness, is an important consideration in the\ncontext of machine learning systems. The most commonly adopted group\nfairness-enhancing techniques are in-processing methods that rely on a mixture\nof a fairness objective (e.g., demographic parity) and a task-specific\nobjective (e.g., cross-entropy) during the training process. However, when data\narrives in an online fashion -- one instance at a time -- optimizing such\nfairness objectives poses several challenges. In particular, group fairness\nobjectives are defined using expectations of predictions across different\ndemographic groups. In the online setting, where the algorithm has access to a\nsingle instance at a time, estimating the group fairness objective requires\nadditional storage and significantly more computation (e.g., forward/backward\npasses) than the task-specific objective at every time step. In this paper, we\npropose Aranyani, an ensemble of oblique decision trees, to make fair decisions\nin online settings. The hierarchical tree structure of Aranyani enables\nparameter isolation and allows us to efficiently compute the fairness gradients\nusing aggregate statistics of previous decisions, eliminating the need for\nadditional storage and forward/backward passes. We also present an efficient\nframework to train Aranyani and theoretically analyze several of its\nproperties. We conduct empirical evaluations on 5 publicly available benchmarks\n(including vision and language datasets) to show that Aranyani achieves a\nbetter accuracy-fairness trade-off compared to baseline approaches.",
            "author": [
                "Somnath Basu Roy Chowdhury",
                "Nicholas Monath",
                "Ahmad Beirami",
                "Rahul Kidambi",
                "Avinava Dubey",
                "Amr Ahmed",
                "Snigdha Chaturvedi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11401v1",
                "http://arxiv.org/pdf/2310.11401v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12181v1",
            "title": "Precise influence evaluation in complex networks",
            "updated": "2023-10-17T17:09:50Z",
            "published": "2023-10-17T17:09:50Z",
            "summary": "Evaluating node influence is fundamental for identifying key nodes in complex\nnetworks. Existing methods typically rely on generic indicators to rank node\ninfluence across diverse networks, thereby ignoring the individualized features\nof each network itself. Actually, node influence stems not only from general\nfeatures but the multi-scale individualized information encompassing specific\nnetwork structure and task. Here we design an active learning architecture to\npredict node influence quantitively and precisely, which samples representative\nnodes based on graph entropy correlation matrix integrating multi-scale\nindividualized information. This brings two intuitive advantages: (1)\ndiscovering potential high-influence but weak-connected nodes that are usually\nignored in existing methods, (2) improving the influence maximization strategy\nby deducing influence interference. Significantly, our architecture\ndemonstrates exceptional transfer learning capabilities across multiple types\nof networks, which can identify those key nodes with large disputation across\ndifferent existing methods. Additionally, our approach, combined with a simple\ngreedy algorithm, exhibits dominant performance in solving the influence\nmaximization problem. This architecture holds great potential for applications\nin graph mining and prediction tasks.",
            "author": [
                "Bingyu Zhu",
                "Qingyun Sun",
                "Jianxin Li",
                "Daqing Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12181v1",
                "http://arxiv.org/pdf/2310.12181v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "physics.data-an"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11399v2",
            "title": "Real-time data assimilation for the thermodynamic modeling of cryogenic\n  storage tanks",
            "updated": "2023-10-20T07:42:41Z",
            "published": "2023-10-17T17:07:20Z",
            "summary": "The thermal management of cryogenic storage tanks requires advanced control\nstrategies to minimize the boil-off losses produced by heat leakages and\nsloshing-enhanced heat and mass transfer. This work presents a\ndata-assimilation approach to calibrate a 0D thermodynamic model for cryogenic\nfuel tanks from data collected in real time from multiple tanks. The model\ncombines energy and mass balance between three control volumes (the ullage\nvapor, the liquid, and the solid tank) with an Artificial Neural Network (ANN)\nfor predicting the heat transfer coefficients from the current tank state. The\nproposed approach combines ideas from traditional data assimilation and\nmulti-environment reinforcement learning, where an agent's training (model\nassimilation) is carried out simultaneously on multiple environments (systems).\nThe real-time assimilation uses a mini-batch version of the Limited-memory\nBroyden-Fletcher-Goldfarb-Shanno with bounds (L-BFGS-B) and adjoint-based\ngradient computation for solving the underlying optimization problem. The\napproach is tested on synthetic datasets simulating multiple tanks undergoing\ndifferent operation phases (pressurization, hold, long-term storage, and\nsloshing). The results show that the assimilation is robust against measurement\nnoise and uses it to explore the parameter space further. Moreover, we show\nthat sampling from multiple environments simultaneously accelerates the\nassimilation.",
            "author": [
                "Pedro Afonso Marques",
                "Samuel Ahizi",
                "Miguel Alfonso Mendez"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11399v2",
                "http://arxiv.org/pdf/2310.11399v2"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11398v2",
            "title": "Neural Attention: Enhancing QKV Calculation in Self-Attention Mechanism\n  with Neural Networks",
            "updated": "2023-10-24T17:12:49Z",
            "published": "2023-10-17T17:06:26Z",
            "summary": "In the realm of deep learning, the self-attention mechanism has substantiated\nits pivotal role across a myriad of tasks, encompassing natural language\nprocessing and computer vision. Despite achieving success across diverse\napplications, the traditional self-attention mechanism primarily leverages\nlinear transformations for the computation of query, key, and value (QKV),\nwhich may not invariably be the optimal choice under specific circumstances.\nThis paper probes into a novel methodology for QKV computation-implementing a\nspecially-designed neural network structure for the calculation. Utilizing a\nmodified Marian model, we conducted experiments on the IWSLT 2017\nGerman-English translation task dataset and juxtaposed our method with the\nconventional approach. The experimental results unveil a significant\nenhancement in BLEU scores with our method. Furthermore, our approach also\nmanifested superiority when training the Roberta model with the Wikitext-103\ndataset, reflecting a notable reduction in model perplexity compared to its\noriginal counterpart. These experimental outcomes not only validate the\nefficacy of our method but also reveal the immense potential in optimizing the\nself-attention mechanism through neural network-based QKV computation, paving\nthe way for future research and practical applications. The source code and\nimplementation details for our proposed method can be accessed at\nhttps://github.com/ocislyjrti/NeuralAttention.",
            "author": [
                "Muhan Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11398v2",
                "http://arxiv.org/pdf/2310.11398v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11397v1",
            "title": "Last One Standing: A Comparative Analysis of Security and Privacy of\n  Soft Prompt Tuning, LoRA, and In-Context Learning",
            "updated": "2023-10-17T17:03:00Z",
            "published": "2023-10-17T17:03:00Z",
            "summary": "Large Language Models (LLMs) are powerful tools for natural language\nprocessing, enabling novel applications and user experiences. However, to\nachieve optimal performance, LLMs often require adaptation with private data,\nwhich poses privacy and security challenges. Several techniques have been\nproposed to adapt LLMs with private data, such as Low-Rank Adaptation (LoRA),\nSoft Prompt Tuning (SPT), and In-Context Learning (ICL), but their comparative\nprivacy and security properties have not been systematically investigated. In\nthis work, we fill this gap by evaluating the robustness of LoRA, SPT, and ICL\nagainst three types of well-established attacks: membership inference, which\nexposes data leakage (privacy); backdoor, which injects malicious behavior\n(security); and model stealing, which can violate intellectual property\n(privacy and security). Our results show that there is no silver bullet for\nprivacy and security in LLM adaptation and each technique has different\nstrengths and weaknesses.",
            "author": [
                "Rui Wen",
                "Tianhao Wang",
                "Michael Backes",
                "Yang Zhang",
                "Ahmed Salem"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11397v1",
                "http://arxiv.org/pdf/2310.11397v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11389v1",
            "title": "VaR\\ and CVaR Estimation in a Markov Cost Process: Lower and Upper\n  Bounds",
            "updated": "2023-10-17T16:35:39Z",
            "published": "2023-10-17T16:35:39Z",
            "summary": "We tackle the problem of estimating the Value-at-Risk (VaR) and the\nConditional Value-at-Risk (CVaR) of the infinite-horizon discounted cost within\na Markov cost process. First, we derive a minimax lower bound of\n$\\Omega(1/\\sqrt{n})$ that holds both in an expected and in a probabilistic\nsense. Then, using a finite-horizon truncation scheme, we derive an upper bound\nfor the error in CVaR estimation, which matches our lower bound up to constant\nfactors. Finally, we discuss an extension of our estimation scheme that covers\nmore general risk measures satisfying a certain continuity criterion, e.g.,\nspectral risk measures, utility-based shortfall risk. To the best of our\nknowledge, our work is the first to provide lower and upper bounds on the\nestimation error for any risk measure within Markovian settings. We remark that\nour lower bounds also extend to the infinite-horizon discounted costs' mean.\nEven in that case, our result $\\Omega(1/\\sqrt{n}) $ improves upon the existing\nresult $\\Omega(1/n)$[13].",
            "author": [
                "Sanjay Bhat",
                "Prashanth L. A.",
                "Gugan Thoppe"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11389v1",
                "http://arxiv.org/pdf/2310.11389v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11385v1",
            "title": "A voxel-level approach to brain age prediction: A method to assess\n  regional brain aging",
            "updated": "2023-10-17T16:32:38Z",
            "published": "2023-10-17T16:32:38Z",
            "summary": "Brain aging is a regional phenomenon, a facet that remains relatively\nunder-explored within the realm of brain age prediction research using machine\nlearning methods. Voxel-level predictions can provide localized brain age\nestimates that can provide granular insights into the regional aging processes.\nThis is essential to understand the differences in aging trajectories in\nhealthy versus diseased subjects. In this work, a deep learning-based multitask\nmodel is proposed for voxel-level brain age prediction from T1-weighted\nmagnetic resonance images. The proposed model outperforms the models existing\nin the literature and yields valuable clinical insights when applied to both\nhealthy and diseased populations. Regional analysis is performed on the\nvoxel-level brain age predictions to understand aging trajectories of known\nanatomical regions in the brain and show that there exist disparities in\nregional aging trajectories of healthy subjects compared to ones with\nunderlying neurological disorders such as Dementia and more specifically,\nAlzheimer's disease. Our code is available at\nhttps://github.com/nehagianchandani/Voxel-level-brain-age-prediction.",
            "author": [
                "Neha Gianchandani",
                "Mahsa Dibaji",
                "Johanna Ospel",
                "Fernando Vega",
                "Mariana Bento",
                "M. Ethan MacDonald",
                "Roberto Souza"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11385v1",
                "http://arxiv.org/pdf/2310.11385v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11377v1",
            "title": "Faster Algorithms for Generalized Mean Densest Subgraph Problem",
            "updated": "2023-10-17T16:21:28Z",
            "published": "2023-10-17T16:21:28Z",
            "summary": "The densest subgraph of a large graph usually refers to some subgraph with\nthe highest average degree, which has been extended to the family of $p$-means\ndense subgraph objectives by~\\citet{veldt2021generalized}. The $p$-mean densest\nsubgraph problem seeks a subgraph with the highest average $p$-th-power degree,\nwhereas the standard densest subgraph problem seeks a subgraph with a simple\nhighest average degree. It was shown that the standard peeling algorithm can\nperform arbitrarily poorly on generalized objective when $p>1$ but uncertain\nwhen $0<p<1$. In this paper, we are the first to show that a standard peeling\nalgorithm can still yield $2^{1/p}$-approximation for the case $0<p < 1$.\n(Veldt 2021) proposed a new generalized peeling algorithm (GENPEEL), which for\n$p \\geq 1$ has an approximation guarantee ratio $(p+1)^{1/p}$, and time\ncomplexity $O(mn)$, where $m$ and $n$ denote the number of edges and nodes in\ngraph respectively. In terms of algorithmic contributions, we propose a new and\nfaster generalized peeling algorithm (called GENPEEL++ in this paper), which\nfor $p \\in [1, +\\infty)$ has an approximation guarantee ratio $(2(p+1))^{1/p}$,\nand time complexity $O(m(\\log n))$, where $m$ and $n$ denote the number of\nedges and nodes in graph, respectively. This approximation ratio converges to 1\nas $p \\rightarrow \\infty$.",
            "author": [
                "Chenglin Fan",
                "Ping Li",
                "Hanyu Peng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11377v1",
                "http://arxiv.org/pdf/2310.11377v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11486v1",
            "title": "End-to-End real time tracking of children's reading with pointer network",
            "updated": "2023-10-17T16:12:18Z",
            "published": "2023-10-17T16:12:18Z",
            "summary": "In this work, we explore how a real time reading tracker can be built\nefficiently for children's voices. While previously proposed reading trackers\nfocused on ASR-based cascaded approaches, we propose a fully end-to-end model\nmaking it less prone to lags in voice tracking. We employ a pointer network\nthat directly learns to predict positions in the ground truth text conditioned\non the streaming speech. To train this pointer network, we generate ground\ntruth training signals by using forced alignment between the read speech and\nthe text being read on the training set. Exploring different forced alignment\nmodels, we find a neural attention based model is at least as close in\nalignment accuracy to the Montreal Forced Aligner, but surprisingly is a better\ntraining signal for the pointer network. Our results are reported on one adult\nspeech data (TIMIT) and two children's speech datasets (CMU Kids and Reading\nRaces). Our best model can accurately track adult speech with 87.8% accuracy\nand the much harder and disfluent children's speech with 77.1% accuracy on CMU\nKids data and a 65.3% accuracy on the Reading Races dataset.",
            "author": [
                "Vishal Sunder",
                "Beulah Karrolla",
                "Eric Fosler-Lussier"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11486v1",
                "http://arxiv.org/pdf/2310.11486v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11366v1",
            "title": "Lie Group Decompositions for Equivariant Neural Networks",
            "updated": "2023-10-17T16:04:33Z",
            "published": "2023-10-17T16:04:33Z",
            "summary": "Invariance and equivariance to geometrical transformations have proven to be\nvery useful inductive biases when training (convolutional) neural network\nmodels, especially in the low-data regime. Much work has focused on the case\nwhere the symmetry group employed is compact or abelian, or both. Recent work\nhas explored enlarging the class of transformations used to the case of Lie\ngroups, principally through the use of their Lie algebra, as well as the group\nexponential and logarithm maps. The applicability of such methods to larger\ntransformation groups is limited by the fact that depending on the group of\ninterest $G$, the exponential map may not be surjective. Further limitations\nare encountered when $G$ is neither compact nor abelian. Using the structure\nand geometry of Lie groups and their homogeneous spaces, we present a framework\nby which it is possible to work with such groups primarily focusing on the Lie\ngroups $G = \\text{GL}^{+}(n, \\mathbb{R})$ and $G = \\text{SL}(n, \\mathbb{R})$,\nas well as their representation as affine transformations $\\mathbb{R}^{n}\n\\rtimes G$. Invariant integration as well as a global parametrization is\nrealized by decomposing the `larger` groups into subgroups and submanifolds\nwhich can be handled individually. Under this framework, we show how\nconvolution kernels can be parametrized to build models equivariant with\nrespect to affine transformations. We evaluate the robustness and\nout-of-distribution generalisation capability of our model on the standard\naffine-invariant benchmark classification task, where we outperform all\nprevious equivariant models as well as all Capsule Network proposals.",
            "author": [
                "Mircea Mironenco",
                "Patrick Forr\u00e9"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11366v1",
                "http://arxiv.org/pdf/2310.11366v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11364v1",
            "title": "High-Fidelity Noise Reduction with Differentiable Signal Processing",
            "updated": "2023-10-17T16:02:07Z",
            "published": "2023-10-17T16:02:07Z",
            "summary": "Noise reduction techniques based on deep learning have demonstrated\nimpressive performance in enhancing the overall quality of recorded speech.\nWhile these approaches are highly performant, their application in audio\nengineering can be limited due to a number of factors. These include operation\nonly on speech without support for music, lack of real-time capability, lack of\ninterpretable control parameters, operation at lower sample rates, and a\ntendency to introduce artifacts. On the other hand, signal processing-based\nnoise reduction algorithms offer fine-grained control and operation on a broad\nrange of content, however, they often require manual operation to achieve the\nbest results. To address the limitations of both approaches, in this work we\nintroduce a method that leverages a signal processing-based denoiser that when\ncombined with a neural network controller, enables fully automatic and\nhigh-fidelity noise reduction on both speech and music signals. We evaluate our\nproposed method with objective metrics and a perceptual listening test. Our\nevaluation reveals that speech enhancement models can be extended to music,\nhowever training the model to remove only stationary noise is critical.\nFurthermore, our proposed approach achieves performance on par with the deep\nlearning models, while being significantly more efficient and introducing fewer\nartifacts in some cases. Listening examples are available online at\nhttps://tape.it/research/denoiser .",
            "author": [
                "Christian J. Steinmetz",
                "Thomas Walther",
                "Joshua D. Reiss"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11364v1",
                "http://arxiv.org/pdf/2310.11364v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11360v1",
            "title": "Enhancing Neural Machine Translation with Semantic Units",
            "updated": "2023-10-17T15:55:31Z",
            "published": "2023-10-17T15:55:31Z",
            "summary": "Conventional neural machine translation (NMT) models typically use subwords\nand words as the basic units for model input and comprehension. However,\ncomplete words and phrases composed of several tokens are often the fundamental\nunits for expressing semantics, referred to as semantic units. To address this\nissue, we propose a method Semantic Units for Machine Translation (SU4MT) which\nmodels the integral meanings of semantic units within a sentence, and then\nleverages them to provide a new perspective for understanding the sentence.\nSpecifically, we first propose Word Pair Encoding (WPE), a phrase extraction\nmethod to help identify the boundaries of semantic units. Next, we design an\nAttentive Semantic Fusion (ASF) layer to integrate the semantics of multiple\nsubwords into a single vector: the semantic unit representation. Lastly, the\nsemantic-unit-level sentence representation is concatenated to the token-level\none, and they are combined as the input of encoder. Experimental results\ndemonstrate that our method effectively models and leverages\nsemantic-unit-level information and outperforms the strong baselines. The code\nis available at https://github.com/ictnlp/SU4MT.",
            "author": [
                "Langlin Huang",
                "Shuhao Gu",
                "Zhuocheng Zhang",
                "Yang Feng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11360v1",
                "http://arxiv.org/pdf/2310.11360v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11358v1",
            "title": "Deep learning segmentation of low-resolution images for prostate\n  magnetic resonance-guided radiotherapy",
            "updated": "2023-10-17T15:48:09Z",
            "published": "2023-10-17T15:48:09Z",
            "summary": "The MR-Linac can enable real-time radiotherapy adaptation. However, real-time\nimage acquisition is restricted to 2D to obtain sufficient spatial resolution,\nhindering accurate 3D segmentation. By reducing spatial resolution fast 3D\nimaging is feasible. Our study evaluates how much the spatial resolution of\nMR-images can be reduced without compromising a deep-learning segmentation\nperformance. We also assess the effect of an auxiliary task of simultaneous\nrestoration of high-resolution images. Artificially downsampled images were\ncreated from 163 3D MR-scans using a k-space truncation to spatial resolution\nlevels of approximately 1.5x1.5x2/1.5x3x3/1.5x6x6/2.5x9x9 mm3. Data was split\ninto train/validation/test of 116/12/35 images. A U-Net was trained to obtain\nhigh-resolution segmentation of prostate, bladder, and rectum on each\nresolution level. Images acquired with low resolution were obtained by scanning\n10 male healthy volunteers, 4 series per subject with a gradually decreasing\nspatial resolution. The networks trained from the artificially downsampled data\nwere fine-tuned to segment these images. For the artificially downsampled\nimages results in terms of DICE when including the auxiliary task, going from\ntraining on the highest resolution images to the lowest, where\n0.87/0.86/0.86/0.85, 0.95/0.94/0.93/0.93 and 0.82/0.84/0.83/0.80 for CTV,\nbladder, and rectum, respectively while for the acquired low-resolution images\n0.78/0.76/0.71/0.59, 0.82/0.85/0.81/0.74 and 0.81/0.82/0.69/0.58. The\nsegmentation results when training including the auxiliary task were comparable\nfor the artificial images and with a trend towards better for the acquired LR\nimages. These results indicate that some speed-up in image acquisition can be\nobtained without significantly reducing the accuracy of a segmentation\ndeep-learning network.",
            "author": [
                "Samuel Fransson",
                "David Tilly",
                "Robin Strand"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11358v1",
                "http://arxiv.org/pdf/2310.11358v1"
            ],
            "primary_category": "physics.med-ph",
            "category": [
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11354v1",
            "title": "Learning by Teaching: Key Challenges and Design Implications",
            "updated": "2023-10-17T15:40:43Z",
            "published": "2023-10-17T15:40:43Z",
            "summary": "Benefits of learning by teaching (LbT) have been highlighted by previous\nstudies from a pedagogical lens, as well as through computer-supported systems.\nHowever, the challenges that university students face in technology-mediated\nLbT$\\unicode{x2013}$whether it be teaching oneself, teaching a peer, or\nteaching an agent$\\unicode{x2013}$are not well understood. Furthermore, there\nis a gap in knowledge on the challenges that students encounter throughout the\nprocess of teaching (content selection, preparation, teaching, receiving and\ngiving feedback, and reflection) despite its importance to the design of LbT\nplatforms. Thus, we conducted a study with 24 university students where they\ntaught content they had not fully grasped, without guidance, and participated\nin a semi-structured interview. Results demonstrate that participants\nencountered the following challenges: psychological barriers relating to self\nand others, and lack of know-how. Furthermore, we illuminate design\nimplications required to overcome these challenges and benefit from LbT without\nrequiring prior training in pedagogy.",
            "author": [
                "Amy Debban\u00e9",
                "Ken Jen Lee",
                "Jarvis Tse",
                "Edith Law"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3579501",
                "http://arxiv.org/abs/2310.11354v1",
                "http://arxiv.org/pdf/2310.11354v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "K.3.1; H.5.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11353v1",
            "title": "Hybrid quantum-classical graph neural networks for tumor classification\n  in digital pathology",
            "updated": "2023-10-17T15:40:26Z",
            "published": "2023-10-17T15:40:26Z",
            "summary": "Advances in classical machine learning and single-cell technologies have\npaved the way to understand interactions between disease cells and tumor\nmicroenvironments to accelerate therapeutic discovery. However, challenges in\nthese machine learning methods and NP-hard problems in spatial Biology create\nan opportunity for quantum computing algorithms. We create a hybrid\nquantum-classical graph neural network (GNN) that combines GNN with a\nVariational Quantum Classifier (VQC) for classifying binary sub-tasks in breast\ncancer subtyping. We explore two variants of the same, the first with fixed\npretrained GNN parameters and the second with end-to-end training of GNN+VQC.\nThe results demonstrate that the hybrid quantum neural network (QNN) is at par\nwith the state-of-the-art classical graph neural networks (GNN) in terms of\nweighted precision, recall and F1-score. We also show that by means of\namplitude encoding, we can compress information in logarithmic number of qubits\nand attain better performance than using classical compression (which leads to\ninformation loss while keeping the number of qubits required constant in both\nregimes). Finally, we show that end-to-end training enables to improve over\nfixed GNN parameters and also slightly improves over vanilla GNN with same\nnumber of dimensions.",
            "author": [
                "Anupama Ray",
                "Dhiraj Madan",
                "Srushti Patil",
                "Maria Anna Rapsomaniki",
                "Pushpak Pati"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11353v1",
                "http://arxiv.org/pdf/2310.11353v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11349v2",
            "title": "A robust and high precision algorithm for elastic scattering problems\n  from cornered domains",
            "updated": "2023-10-18T05:14:15Z",
            "published": "2023-10-17T15:39:06Z",
            "summary": "The Navier equation is the governing equation of elastic waves, and computing\nits solution accurately and rapidly has a wide range of applications in\ngeophysical exploration, materials science, etc. In this paper, we focus on the\nefficient and high-precision numerical algorithm for the time harmonic elastic\nwave scattering problems from cornered domains via the boundary integral\nequations in two dimensions. The approach is based on the combination of\nNystr\\\"om discretization, analytical singular integrals and kernel-splitting\nmethod, which results in a high-order solver for smooth boundaries. It is then\ncombined with the recursively compressed inverse preconditioning (RCIP) method\nto solve elastic scattering problems from cornered domains. Numerical\nexperiments demonstrate that the proposed approach achieves high accuracy, with\nstabilized errors close to machine precision in various geometric\nconfigurations. The algorithm is further applied to investigate the asymptotic\nbehavior of density functions associated with boundary integral operators near\ncorners, and the numerical results are highly consistent with the theoretical\nformulas.",
            "author": [
                "Jianan Yao",
                "Baoling Xie",
                "Jun Lai"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11349v2",
                "http://arxiv.org/pdf/2310.11349v2"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "35J05, 45L05, 45E05, 65R20, 75B05"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11346v2",
            "title": "Towards Generalizable Multi-Camera 3D Object Detection via Perspective\n  Debiasing",
            "updated": "2023-11-30T07:06:20Z",
            "published": "2023-10-17T15:31:28Z",
            "summary": "Detecting objects in 3D space using multiple cameras, known as Multi-Camera\n3D Object Detection (MC3D-Det), has gained prominence with the advent of\nbird's-eye view (BEV) approaches. However, these methods often struggle when\nfaced with unfamiliar testing environments due to the lack of diverse training\ndata encompassing various viewpoints and environments. To address this, we\npropose a novel method that aligns 3D detection with 2D camera plane results,\nensuring consistent and accurate detections. Our framework, anchored in\nperspective debiasing, helps the learning of features resilient to domain\nshifts. In our approach, we render diverse view maps from BEV features and\nrectify the perspective bias of these maps, leveraging implicit foreground\nvolumes to bridge the camera and BEV planes. This two-step process promotes the\nlearning of perspective- and context-independent features, crucial for accurate\nobject detection across varying viewpoints, camera parameters and environment\nconditions. Notably, our model-agnostic approach preserves the original network\nstructure without incurring additional inference costs, facilitating seamless\nintegration across various models and simplifying deployment. Furthermore, we\nalso show our approach achieves satisfactory results in real data when trained\nonly with virtual datasets, eliminating the need for real scene annotations.\nExperimental results on both Domain Generalization (DG) and Unsupervised Domain\nAdaptation (UDA) clearly demonstrate its effectiveness. Our code will be\nreleased.",
            "author": [
                "Hao Lu",
                "Yunpeng Zhang",
                "Qing Lian",
                "Dalong Du",
                "Yingcong Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11346v2",
                "http://arxiv.org/pdf/2310.11346v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11341v1",
            "title": "Dual Cognitive Architecture: Incorporating Biases and Multi-Memory\n  Systems for Lifelong Learning",
            "updated": "2023-10-17T15:24:02Z",
            "published": "2023-10-17T15:24:02Z",
            "summary": "Artificial neural networks (ANNs) exhibit a narrow scope of expertise on\nstationary independent data. However, the data in the real world is continuous\nand dynamic, and ANNs must adapt to novel scenarios while also retaining the\nlearned knowledge to become lifelong learners. The ability of humans to excel\nat these tasks can be attributed to multiple factors ranging from cognitive\ncomputational structures, cognitive biases, and the multi-memory systems in the\nbrain. We incorporate key concepts from each of these to design a novel\nframework, Dual Cognitive Architecture (DUCA), which includes multiple\nsub-systems, implicit and explicit knowledge representation dichotomy,\ninductive bias, and a multi-memory system. The inductive bias learner within\nDUCA is instrumental in encoding shape information, effectively countering the\ntendency of ANNs to learn local textures. Simultaneously, the inclusion of a\nsemantic memory submodule facilitates the gradual consolidation of knowledge,\nreplicating the dynamics observed in fast and slow learning systems,\nreminiscent of the principles underpinning the complementary learning system in\nhuman cognition. DUCA shows improvement across different settings and datasets,\nand it also exhibits reduced task recency bias, without the need for extra\ninformation. To further test the versatility of lifelong learning methods on a\nchallenging distribution shift, we introduce a novel domain-incremental dataset\nDN4IL. In addition to improving performance on existing benchmarks, DUCA also\ndemonstrates superior performance on this complex dataset.",
            "author": [
                "Shruthi Gowda",
                "Bahram Zonooz",
                "Elahe Arani"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11341v1",
                "http://arxiv.org/pdf/2310.11341v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11340v1",
            "title": "Contextualized Machine Learning",
            "updated": "2023-10-17T15:23:00Z",
            "published": "2023-10-17T15:23:00Z",
            "summary": "We examine Contextualized Machine Learning (ML), a paradigm for learning\nheterogeneous and context-dependent effects. Contextualized ML estimates\nheterogeneous functions by applying deep learning to the meta-relationship\nbetween contextual information and context-specific parametric models. This is\na form of varying-coefficient modeling that unifies existing frameworks\nincluding cluster analysis and cohort modeling by introducing two reusable\nconcepts: a context encoder which translates sample context into model\nparameters, and sample-specific model which operates on sample predictors. We\nreview the process of developing contextualized models, nonparametric inference\nfrom contextualized models, and identifiability conditions of contextualized\nmodels. Finally, we present the open-source PyTorch package ContextualizedML.",
            "author": [
                "Benjamin Lengerich",
                "Caleb N. Ellington",
                "Andrea Rubbi",
                "Manolis Kellis",
                "Eric P. Xing"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11340v1",
                "http://arxiv.org/pdf/2310.11340v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11335v1",
            "title": "Non-ergodicity in reinforcement learning: robustness via ergodicity\n  transformations",
            "updated": "2023-10-17T15:13:33Z",
            "published": "2023-10-17T15:13:33Z",
            "summary": "Envisioned application areas for reinforcement learning (RL) include\nautonomous driving, precision agriculture, and finance, which all require RL\nagents to make decisions in the real world. A significant challenge hindering\nthe adoption of RL methods in these domains is the non-robustness of\nconventional algorithms. In this paper, we argue that a fundamental issue\ncontributing to this lack of robustness lies in the focus on the expected value\nof the return as the sole \"correct\" optimization objective. The expected value\nis the average over the statistical ensemble of infinitely many trajectories.\nFor non-ergodic returns, this average differs from the average over a single\nbut infinitely long trajectory. Consequently, optimizing the expected value can\nlead to policies that yield exceptionally high returns with probability zero\nbut almost surely result in catastrophic outcomes. This problem can be\ncircumvented by transforming the time series of collected returns into one with\nergodic increments. This transformation enables learning robust policies by\noptimizing the long-term return for individual agents rather than the average\nacross infinitely many trajectories. We propose an algorithm for learning\nergodicity transformations from data and demonstrate its effectiveness in an\ninstructive, non-ergodic environment and on standard RL benchmarks.",
            "author": [
                "Dominik Baumann",
                "Erfaun Noorani",
                "James Price",
                "Ole Peters",
                "Colm Connaughton",
                "Thomas B. Sch\u00f6n"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11335v1",
                "http://arxiv.org/pdf/2310.11335v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11333v1",
            "title": "Key Point-based Orientation Estimation of Strawberries for Robotic Fruit\n  Picking",
            "updated": "2023-10-17T15:12:11Z",
            "published": "2023-10-17T15:12:11Z",
            "summary": "Selective robotic harvesting is a promising technological solution to address\nlabour shortages which are affecting modern agriculture in many parts of the\nworld. For an accurate and efficient picking process, a robotic harvester\nrequires the precise location and orientation of the fruit to effectively plan\nthe trajectory of the end effector. The current methods for estimating fruit\norientation employ either complete 3D information which typically requires\nregistration from multiple views or rely on fully-supervised learning\ntechniques, which require difficult-to-obtain manual annotation of the\nreference orientation. In this paper, we introduce a novel key-point-based\nfruit orientation estimation method allowing for the prediction of 3D\norientation from 2D images directly. The proposed technique can work without\nfull 3D orientation annotations but can also exploit such information for\nimproved accuracy. We evaluate our work on two separate datasets of strawberry\nimages obtained from real-world data collection scenarios. Our proposed method\nachieves state-of-the-art performance with an average error as low as\n$8^{\\circ}$, improving predictions by $\\sim30\\%$ compared to previous work\npresented in~\\cite{wagner2021efficient}. Furthermore, our method is suited for\nreal-time robotic applications with fast inference times of $\\sim30$ms.",
            "author": [
                "Justin Le Lou\u00ebdec",
                "Grzegorz Cielniak"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-031-44137-0_13",
                "http://arxiv.org/abs/2310.11333v1",
                "http://arxiv.org/pdf/2310.11333v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11332v1",
            "title": "Discovering High-Quality Process Models Despite Data Scarcity",
            "updated": "2023-10-17T15:12:05Z",
            "published": "2023-10-17T15:12:05Z",
            "summary": "Process discovery algorithms learn process models from executed activity\nsequences, describing concurrency, causality, and conflict. Concurrent\nactivities require observing multiple permutations, increasing data\nrequirements, especially for processes with concurrent subprocesses such as\nhierarchical, composite, or distributed processes. While process discovery\nalgorithms traditionally use sequences of activities as input, recently\nintroduced object-centric process discovery algorithms can use graphs of\nactivities as input, encoding partial orders between activities. As such, they\ncontain the concurrency information of many sequences in a single graph. In\nthis paper, we address the research question of reducing process discovery data\nrequirements when using object-centric event logs for process discovery. We\nclassify different real-life processes according to the control-flow complexity\nwithin and between subprocesses and introduce an evaluation framework to assess\nprocess discovery algorithm quality of traditional and object-centric process\ndiscovery based on the sample size. We complement this with a large-scale\nproduction process case study. Our results show reduced data requirements,\nenabling the discovery of large, concurrent processes such as manufacturing\nwith little data, previously infeasible with traditional process discovery. Our\nfindings suggest that object-centric process mining could revolutionize process\ndiscovery in various sectors, including manufacturing and supply chains.",
            "author": [
                "Jan Niklas Adams",
                "Jari Peeperkorn",
                "Tobias Brockhoff",
                "Isabelle Terrier",
                "Heiko G\u00f6hner",
                "Merih Seran Uysal",
                "Seppe vanden Broucke",
                "Jochen De Weerdt",
                "Wil M. P. van der Aalst"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11332v1",
                "http://arxiv.org/pdf/2310.11332v1"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11325v1",
            "title": "Detection of Malicious DNS-over-HTTPS Traffic: An Anomaly Detection\n  Approach using Autoencoders",
            "updated": "2023-10-17T15:03:37Z",
            "published": "2023-10-17T15:03:37Z",
            "summary": "To maintain the privacy of users' web browsing history, popular browsers\nencrypt their DNS traffic using the DNS-over-HTTPS (DoH) protocol.\nUnfortunately, encrypting DNS packets prevents many existing intrusion\ndetection systems from using plaintext domain names to detect malicious\ntraffic. In this paper, we design an autoencoder that is capable of detecting\nmalicious DNS traffic by only observing the encrypted DoH traffic. Compared to\nprevious works, the proposed autoencoder looks for anomalies in DoH traffic,\nand thus can detect malicious traffic that has not been previously observed,\ni.e., zero-day attacks. We run extensive experiments to evaluate the\nperformance of our proposed autoencoder and compare it to that of other anomaly\ndetection algorithms, namely, local outlier factor, one-class support vector\nmachine, isolation forest, and variational autoencoders. We find that our\nproposed autoencoder achieves the highest detection performance, with a median\nF-1 score of 99\\% over several types of malicious traffic.",
            "author": [
                "Sergio Salinas Monroy",
                "Aman Kumar Gupta",
                "Garrett Wahlstedt"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11325v1",
                "http://arxiv.org/pdf/2310.11325v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11324v1",
            "title": "Quantifying Language Models' Sensitivity to Spurious Features in Prompt\n  Design or: How I learned to start worrying about prompt formatting",
            "updated": "2023-10-17T15:03:30Z",
            "published": "2023-10-17T15:03:30Z",
            "summary": "As large language models (LLMs) are adopted as a fundamental component of\nlanguage technologies, it is crucial to accurately characterize their\nperformance. Because choices in prompt design can strongly influence model\nbehavior, this design process is critical in effectively using any modern\npre-trained generative language model. In this work, we focus on LLM\nsensitivity to a quintessential class of meaning-preserving design choices:\nprompt formatting. We find that several widely used open-source LLMs are\nextremely sensitive to subtle changes in prompt formatting in few-shot\nsettings, with performance differences of up to 76 accuracy points when\nevaluated using LLaMA-2-13B. Sensitivity remains even when increasing model\nsize, the number of few-shot examples, or performing instruction tuning. Our\nanalysis suggests that work evaluating LLMs with prompting-based methods would\nbenefit from reporting a range of performance across plausible prompt formats,\ninstead of the currently-standard practice of reporting performance on a single\nformat. We also show that format performance only weakly correlates between\nmodels, which puts into question the methodological validity of comparing\nmodels with an arbitrarily chosen, fixed prompt format. To facilitate\nsystematic analysis we propose FormatSpread, an algorithm that rapidly\nevaluates a sampled set of plausible prompt formats for a given task, and\nreports the interval of expected performance without accessing model weights.\nFurthermore, we present a suite of analyses that characterize the nature of\nthis sensitivity, including exploring the influence of particular atomic\nperturbations and the internal representation of particular formats.",
            "author": [
                "Melanie Sclar",
                "Yejin Choi",
                "Yulia Tsvetkov",
                "Alane Suhr"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11324v1",
                "http://arxiv.org/pdf/2310.11324v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11320v1",
            "title": "Towards Generic Semi-Supervised Framework for Volumetric Medical Image\n  Segmentation",
            "updated": "2023-10-17T14:58:18Z",
            "published": "2023-10-17T14:58:18Z",
            "summary": "Volume-wise labeling in 3D medical images is a time-consuming task that\nrequires expertise. As a result, there is growing interest in using\nsemi-supervised learning (SSL) techniques to train models with limited labeled\ndata. However, the challenges and practical applications extend beyond SSL to\nsettings such as unsupervised domain adaptation (UDA) and semi-supervised\ndomain generalization (SemiDG). This work aims to develop a generic SSL\nframework that can handle all three settings. We identify two main obstacles to\nachieving this goal in the existing SSL framework: 1) the weakness of capturing\ndistribution-invariant features; and 2) the tendency for unlabeled data to be\noverwhelmed by labeled data, leading to over-fitting to the labeled data during\ntraining. To address these issues, we propose an Aggregating & Decoupling\nframework. The aggregating part consists of a Diffusion encoder that constructs\na common knowledge set by extracting distribution-invariant features from\naggregated information from multiple distributions/domains. The decoupling part\nconsists of three decoders that decouple the training process with labeled and\nunlabeled data, thus avoiding over-fitting to labeled data, specific domains\nand classes. We evaluate our proposed framework on four benchmark datasets for\nSSL, Class-imbalanced SSL, UDA and SemiDG. The results showcase notable\nimprovements compared to state-of-the-art methods across all four settings,\nindicating the potential of our framework to tackle more challenging SSL\nscenarios. Code and models are available at:\nhttps://github.com/xmed-lab/GenericSSL.",
            "author": [
                "Haonan Wang",
                "Xiaomeng Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11320v1",
                "http://arxiv.org/pdf/2310.11320v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11318v1",
            "title": "Utilising a Large Language Model to Annotate Subject Metadata: A Case\n  Study in an Australian National Research Data Catalogue",
            "updated": "2023-10-17T14:52:33Z",
            "published": "2023-10-17T14:52:33Z",
            "summary": "In support of open and reproducible research, there has been a rapidly\nincreasing number of datasets made available for research. As the availability\nof datasets increases, it becomes more important to have quality metadata for\ndiscovering and reusing them. Yet, it is a common issue that datasets often\nlack quality metadata due to limited resources for data curation. Meanwhile,\ntechnologies such as artificial intelligence and large language models (LLMs)\nare progressing rapidly. Recently, systems based on these technologies, such as\nChatGPT, have demonstrated promising capabilities for certain data curation\ntasks. This paper proposes to leverage LLMs for cost-effective annotation of\nsubject metadata through the LLM-based in-context learning. Our method employs\nGPT-3.5 with prompts designed for annotating subject metadata, demonstrating\npromising performance in automatic metadata annotation. However, models based\non in-context learning cannot acquire discipline-specific rules, resulting in\nlower performance in several categories. This limitation arises from the\nlimited contextual information available for subject inference. To the best of\nour knowledge, we are introducing, for the first time, an in-context learning\nmethod that harnesses large language models for automated subject metadata\nannotation.",
            "author": [
                "Shiwei Zhang",
                "Mingfang Wu",
                "Xiuzhen Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11318v1",
                "http://arxiv.org/pdf/2310.11318v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13013v1",
            "title": "Generative error correction for code-switching speech recognition using\n  large language models",
            "updated": "2023-10-17T14:49:48Z",
            "published": "2023-10-17T14:49:48Z",
            "summary": "Code-switching (CS) speech refers to the phenomenon of mixing two or more\nlanguages within the same sentence. Despite the recent advances in automatic\nspeech recognition (ASR), CS-ASR is still a challenging task ought to the\ngrammatical structure complexity of the phenomenon and the data scarcity of\nspecific training corpus. In this work, we propose to leverage large language\nmodels (LLMs) and lists of hypotheses generated by an ASR to address the CS\nproblem. Specifically, we first employ multiple well-trained ASR models for\nN-best hypotheses generation, with the aim of increasing the diverse and\ninformative elements in the set of hypotheses. Next, we utilize the LLMs to\nlearn the hypotheses-to-transcription (H2T) mapping by adding a trainable\nlow-rank adapter. Such a generative error correction (GER) method directly\npredicts the accurate transcription according to its expert linguistic\nknowledge and N-best hypotheses, resulting in a paradigm shift from the\ntraditional language model rescoring or error correction techniques.\nExperimental evidence demonstrates that GER significantly enhances CS-ASR\naccuracy, in terms of reduced mixed error rate (MER). Furthermore, LLMs show\nremarkable data efficiency for H2T learning, providing a potential solution to\nthe data scarcity problem of CS-ASR in low-resource languages.",
            "author": [
                "Chen Chen",
                "Yuchen Hu",
                "Chao-Han Huck Yang",
                "Hexin Liu",
                "Sabato Marco Siniscalchi",
                "Eng Siong Chng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13013v1",
                "http://arxiv.org/pdf/2310.13013v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11316v1",
            "title": "MonoSKD: General Distillation Framework for Monocular 3D Object\n  Detection via Spearman Correlation Coefficient",
            "updated": "2023-10-17T14:48:02Z",
            "published": "2023-10-17T14:48:02Z",
            "summary": "Monocular 3D object detection is an inherently ill-posed problem, as it is\nchallenging to predict accurate 3D localization from a single image. Existing\nmonocular 3D detection knowledge distillation methods usually project the LiDAR\nonto the image plane and train the teacher network accordingly. Transferring\nLiDAR-based model knowledge to RGB-based models is more complex, so a general\ndistillation strategy is needed. To alleviate cross-modal prob-lem, we propose\nMonoSKD, a novel Knowledge Distillation framework for Monocular 3D detection\nbased on Spearman correlation coefficient, to learn the relative correlation\nbetween cross-modal features. Considering the large gap between these features,\nstrict alignment of features may mislead the training, so we propose a looser\nSpearman loss. Furthermore, by selecting appropriate distillation locations and\nremoving redundant modules, our scheme saves more GPU resources and trains\nfaster than existing methods. Extensive experiments are performed to verify the\neffectiveness of our framework on the challenging KITTI 3D object detection\nbenchmark. Our method achieves state-of-the-art performance until submission\nwith no additional inference computational cost. Our codes are available at\nhttps://github.com/Senwang98/MonoSKD",
            "author": [
                "Sen Wang",
                "Jin Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11316v1",
                "http://arxiv.org/pdf/2310.11316v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11311v1",
            "title": "Elucidating The Design Space of Classifier-Guided Diffusion Generation",
            "updated": "2023-10-17T14:34:58Z",
            "published": "2023-10-17T14:34:58Z",
            "summary": "Guidance in conditional diffusion generation is of great importance for\nsample quality and controllability. However, existing guidance schemes are to\nbe desired. On one hand, mainstream methods such as classifier guidance and\nclassifier-free guidance both require extra training with labeled data, which\nis time-consuming and unable to adapt to new conditions. On the other hand,\ntraining-free methods such as universal guidance, though more flexible, have\nyet to demonstrate comparable performance. In this work, through a\ncomprehensive investigation into the design space, we show that it is possible\nto achieve significant performance improvements over existing guidance schemes\nby leveraging off-the-shelf classifiers in a training-free fashion, enjoying\nthe best of both worlds. Employing calibration as a general guideline, we\npropose several pre-conditioning techniques to better exploit pretrained\noff-the-shelf classifiers for guiding diffusion generation. Extensive\nexperiments on ImageNet validate our proposed method, showing that\nstate-of-the-art diffusion models (DDPM, EDM, DiT) can be further improved (up\nto 20%) using off-the-shelf classifiers with barely any extra computational\ncost. With the proliferation of publicly available pretrained classifiers, our\nproposed approach has great potential and can be readily scaled up to\ntext-to-image generation tasks. The code is available at\nhttps://github.com/AlexMaOLS/EluCD/tree/main.",
            "author": [
                "Jiajun Ma",
                "Tianyang Hu",
                "Wenjia Wang",
                "Jiacheng Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11311v1",
                "http://arxiv.org/pdf/2310.11311v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11307v1",
            "title": "Multi Self-supervised Pre-fine-tuned Transformer Fusion for Better\n  Intelligent Transportation Detection",
            "updated": "2023-10-17T14:32:49Z",
            "published": "2023-10-17T14:32:49Z",
            "summary": "Intelligent transportation system combines advanced information technology to\nprovide intelligent services such as monitoring, detection, and early warning\nfor modern transportation. Intelligent transportation detection is the\ncornerstone of many intelligent traffic services by identifying task targets\nthrough object detection methods. However existing detection methods in\nintelligent transportation are limited by two aspects. First, there is a\ndifference between the model knowledge pre-trained on large-scale datasets and\nthe knowledge required for target task. Second, most detection models follow\nthe pattern of single-source learning, which limits the learning ability. To\naddress these problems, we propose a Multi Self-supervised Pre-fine-tuned\nTransformer Fusion (MSPTF) network, consisting of two steps: unsupervised\npre-fine-tune domain knowledge learning and multi-model fusion target task\nlearning. In the first step, we introduced self-supervised learning methods\ninto transformer model pre-fine-tune which could reduce data costs and\nalleviate the knowledge gap between pre-trained model and target task. In the\nsecond step, we take feature information differences between different model\narchitectures and different pre-fine-tune tasks into account and propose\nMulti-model Semantic Consistency Cross-attention Fusion (MSCCF) network to\ncombine different transformer model features by considering channel semantic\nconsistency and feature vector semantic consistency, which obtain more complete\nand proper fusion features for detection task. We experimented the proposed\nmethod on vehicle recognition dataset and road disease detection dataset and\nachieved 1.1%, 5.5%, 4.2% improvement compared with baseline and 0.7%, 1.8%,\n1.7% compared with sota, which proved the effectiveness of our method.",
            "author": [
                "Juwu Zheng",
                "Jiangtao Ren"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11307v1",
                "http://arxiv.org/pdf/2310.11307v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11305v2",
            "title": "MiniZero: Comparative Analysis of AlphaZero and MuZero on Go, Othello,\n  and Atari Games",
            "updated": "2023-11-15T05:49:17Z",
            "published": "2023-10-17T14:29:25Z",
            "summary": "This paper presents MiniZero, a zero-knowledge learning framework that\nsupports four state-of-the-art algorithms, including AlphaZero, MuZero, Gumbel\nAlphaZero, and Gumbel MuZero. While these algorithms have demonstrated\nsuper-human performance in many games, it remains unclear which among them is\nmost suitable or efficient for specific tasks. Through MiniZero, we\nsystematically evaluate the performance of each algorithm in two board games,\n9x9 Go and 8x8 Othello, as well as 57 Atari games. For two board games, using\nmore simulations generally results in higher performance. However, the choice\nof AlphaZero and MuZero may differ based on game properties. For Atari games,\nboth MuZero and Gumbel MuZero are worth considering. Since each game has unique\ncharacteristics, different algorithms and simulations yield varying results. In\naddition, we introduce an approach, called progressive simulation, which\nprogressively increases the simulation budget during training to allocate\ncomputation more efficiently. Our empirical results demonstrate that\nprogressive simulation achieves significantly superior performance in two board\ngames. By making our framework and trained models publicly available, this\npaper contributes a benchmark for future research on zero-knowledge learning\nalgorithms, assisting researchers in algorithm selection and comparison against\nthese zero-knowledge learning baselines. Our code and data are available at\nhttps://rlg.iis.sinica.edu.tw/papers/minizero.",
            "author": [
                "Ti-Rong Wu",
                "Hung Guei",
                "Po-Wei Huang",
                "Pei-Chiun Peng",
                "Ting Han Wei",
                "Chung-Chin Shih",
                "Yun-Jui Tsai"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11305v2",
                "http://arxiv.org/pdf/2310.11305v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11303v1",
            "title": "QADYNAMICS: Training Dynamics-Driven Synthetic QA Diagnostic for\n  Zero-Shot Commonsense Question Answering",
            "updated": "2023-10-17T14:27:34Z",
            "published": "2023-10-17T14:27:34Z",
            "summary": "Zero-shot commonsense Question-Answering (QA) requires models to reason about\ngeneral situations beyond specific benchmarks. State-of-the-art approaches\nfine-tune language models on QA pairs constructed from CommonSense Knowledge\nBases (CSKBs) to equip the models with more commonsense knowledge in a QA\ncontext. However, current QA synthesis protocols may introduce noise from the\nCSKBs and generate ungrammatical questions and false negative options, which\nimpede the model's ability to generalize. To address these issues, we propose\nQADYNAMICS, a training dynamics-driven framework for QA diagnostics and\nrefinement. Our approach analyzes the training dynamics of each QA pair at both\nthe question level and option level, discarding machine-detectable artifacts by\nremoving uninformative QA pairs and mislabeled or false-negative options.\nExtensive experiments demonstrate the effectiveness of our approach, which\noutperforms all baselines while using only 33% of the synthetic data, even\nincluding LLMs such as ChatGPT. Moreover, expert evaluations confirm that our\nframework significantly improves the quality of QA synthesis. Our codes and\nmodel checkpoints are available at\nhttps://github.com/HKUST-KnowComp/QaDynamics.",
            "author": [
                "Haochen Shi",
                "Weiqi Wang",
                "Tianqing Fang",
                "Baixuan Xu",
                "Wenxuan Ding",
                "Xin Liu",
                "Yangqiu Song"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11303v1",
                "http://arxiv.org/pdf/2310.11303v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11293v2",
            "title": "On the use of artificial intelligence in financial regulations and the\n  impact on financial stability",
            "updated": "2023-10-25T07:06:28Z",
            "published": "2023-10-17T14:16:23Z",
            "summary": "As the financial authorities increase their use of artificial intelligence\n(AI), micro regulations, such as consumer protection and routine banking\nregulations, will benefit because of ample data, short time horizons, clear\nobjectives, and repeated decisions, leaving plenty of data for AI to train on.\nIt is different from macro, focused on the stability of the entire financial\nsystem, where AI can potentially undermine financial stability. Infrequent and\nmostly unique events frustrate AI learning and hence its use for macro\nregulations. Using distributed decision making, humans retain the advantage\nover AI for advising on and making decisions in times of extreme stress. Even\nif the authorities prefer a conservative approach to AI adoption, it will\nlikely become widely used by stealth, taking over increasingly high level\nfunctions, driven by significant cost efficiencies, robustness and accuracy. We\npropose six criteria against which to judge the suitability of AI use by the\nprivate sector and financial regulation and crisis resolution.",
            "author": [
                "Jon Danielsson",
                "Andreas Uthemann"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11293v2",
                "http://arxiv.org/pdf/2310.11293v2"
            ],
            "primary_category": "econ.GN",
            "category": [
                "econ.GN",
                "q-fin.EC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11291v1",
            "title": "An Automatic Learning Rate Schedule Algorithm for Achieving Faster\n  Convergence and Steeper Descent",
            "updated": "2023-10-17T14:15:57Z",
            "published": "2023-10-17T14:15:57Z",
            "summary": "The delta-bar-delta algorithm is recognized as a learning rate adaptation\ntechnique that enhances the convergence speed of the training process in\noptimization by dynamically scheduling the learning rate based on the\ndifference between the current and previous weight updates. While this\nalgorithm has demonstrated strong competitiveness in full data optimization\nwhen compared to other state-of-the-art algorithms like Adam and SGD, it may\nencounter convergence issues in mini-batch optimization scenarios due to the\npresence of noisy gradients.\n  In this study, we thoroughly investigate the convergence behavior of the\ndelta-bar-delta algorithm in real-world neural network optimization. To address\nany potential convergence challenges, we propose a novel approach called RDBD\n(Regrettable Delta-Bar-Delta). Our approach allows for prompt correction of\nbiased learning rate adjustments and ensures the convergence of the\noptimization process. Furthermore, we demonstrate that RDBD can be seamlessly\nintegrated with any optimization algorithm and significantly improve the\nconvergence speed.\n  By conducting extensive experiments and evaluations, we validate the\neffectiveness and efficiency of our proposed RDBD approach. The results\nshowcase its capability to overcome convergence issues in mini-batch\noptimization and its potential to enhance the convergence speed of various\noptimization algorithms. This research contributes to the advancement of\noptimization techniques in neural network training, providing practitioners\nwith a reliable automatic learning rate scheduler for achieving faster\nconvergence and improved optimization outcomes.",
            "author": [
                "Zhao Song",
                "Chiwun Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11291v1",
                "http://arxiv.org/pdf/2310.11291v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11287v1",
            "title": "Evaluating the Impact of Humanitarian Aid on Food Security",
            "updated": "2023-10-17T14:09:45Z",
            "published": "2023-10-17T14:09:45Z",
            "summary": "In the face of climate change-induced droughts, vulnerable regions encounter\nsevere threats to food security, demanding urgent humanitarian assistance. This\npaper introduces a causal inference framework for the Horn of Africa, aiming to\nassess the impact of cash-based interventions on food crises. Our contributions\nencompass identifying causal relationships within the food security system,\nharmonizing a comprehensive database, and estimating the causal effect of\nhumanitarian interventions on malnutrition. Our results revealed no significant\neffects, likely due to limited sample size, suboptimal data quality, and an\nimperfect causal graph resulting from our limited understanding of\nmultidisciplinary systems like food security. This underscores the need to\nenhance data collection and refine causal models with domain experts for more\neffective future interventions and policies, improving transparency and\naccountability in humanitarian aid.",
            "author": [
                "Jordi Cerd\u00e0-Bautista",
                "Jos\u00e9 Mar\u00eda T\u00e1rraga",
                "Vasileios Sitokonstantinou",
                "Gustau Camps-Valls"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11287v1",
                "http://arxiv.org/pdf/2310.11287v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11284v1",
            "title": "Self-Supervised 3D Scene Flow Estimation and Motion Prediction using\n  Local Rigidity Prior",
            "updated": "2023-10-17T14:06:55Z",
            "published": "2023-10-17T14:06:55Z",
            "summary": "In this article, we investigate self-supervised 3D scene flow estimation and\nclass-agnostic motion prediction on point clouds. A realistic scene can be well\nmodeled as a collection of rigidly moving parts, therefore its scene flow can\nbe represented as a combination of the rigid motion of these individual parts.\nBuilding upon this observation, we propose to generate pseudo scene flow labels\nfor self-supervised learning through piecewise rigid motion estimation, in\nwhich the source point cloud is decomposed into local regions and each region\nis treated as rigid. By rigidly aligning each region with its potential\ncounterpart in the target point cloud, we obtain a region-specific rigid\ntransformation to generate its pseudo flow labels. To mitigate the impact of\npotential outliers on label generation, when solving the rigid registration for\neach region, we alternately perform three steps: establishing point\ncorrespondences, measuring the confidence for the correspondences, and updating\nthe rigid transformation based on the correspondences and their confidence. As\na result, confident correspondences will dominate label generation and a\nvalidity mask will be derived for the generated pseudo labels. By using the\npseudo labels together with their validity mask for supervision, models can be\ntrained in a self-supervised manner. Extensive experiments on FlyingThings3D\nand KITTI datasets demonstrate that our method achieves new state-of-the-art\nperformance in self-supervised scene flow learning, without any ground truth\nscene flow for supervision, even performing better than some supervised\ncounterparts. Additionally, our method is further extended to class-agnostic\nmotion prediction and significantly outperforms previous state-of-the-art\nself-supervised methods on nuScenes dataset.",
            "author": [
                "Ruibo Li",
                "Chi Zhang",
                "Zhe Wang",
                "Chunhua Shen",
                "Guosheng Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11284v1",
                "http://arxiv.org/pdf/2310.11284v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11281v1",
            "title": "Self-supervision meets kernel graph neural models: From architecture to\n  augmentations",
            "updated": "2023-10-17T14:04:22Z",
            "published": "2023-10-17T14:04:22Z",
            "summary": "Graph representation learning has now become the de facto standard when\nhandling graph-structured data, with the framework of message-passing graph\nneural networks (MPNN) being the most prevailing algorithmic tool. Despite its\npopularity, the family of MPNNs suffers from several drawbacks such as\ntransparency and expressivity. Recently, the idea of designing neural models on\ngraphs using the theory of graph kernels has emerged as a more transparent as\nwell as sometimes more expressive alternative to MPNNs known as kernel graph\nneural networks (KGNNs). Developments on KGNNs are currently a nascent field of\nresearch, leaving several challenges from algorithmic design and adaptation to\nother learning paradigms such as self-supervised learning. In this paper, we\nimprove the design and learning of KGNNs. Firstly, we extend the algorithmic\nformulation of KGNNs by allowing a more flexible graph-level similarity\ndefinition that encompasses former proposals like random walk graph kernel, as\nwell as providing a smoother optimization objective that alleviates the need of\nintroducing combinatorial learning procedures. Secondly, we enhance KGNNs\nthrough the lens of self-supervision via developing a novel\nstructure-preserving graph data augmentation method called latent graph\naugmentation (LGA). Finally, we perform extensive empirical evaluations to\ndemonstrate the efficacy of our proposed mechanisms. Experimental results over\nbenchmark datasets suggest that our proposed model achieves competitive\nperformance that is comparable to or sometimes outperforming state-of-the-art\ngraph representation learning frameworks with or without self-supervision on\ngraph classification tasks. Comparisons against other previously established\ngraph data augmentation methods verify that the proposed LGA augmentation\nscheme captures better semantics of graph-level invariance.",
            "author": [
                "Jiawang Dan",
                "Ruofan Wu",
                "Yunpeng Liu",
                "Baokun Wang",
                "Changhua Meng",
                "Tengfei Liu",
                "Tianyi Zhang",
                "Ningtao Wang",
                "Xing Fu",
                "Qi Li",
                "Weiqiang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11281v1",
                "http://arxiv.org/pdf/2310.11281v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11275v1",
            "title": "xMEN: A Modular Toolkit for Cross-Lingual Medical Entity Normalization",
            "updated": "2023-10-17T13:53:57Z",
            "published": "2023-10-17T13:53:57Z",
            "summary": "Objective: To improve performance of medical entity normalization across many\nlanguages, especially when fewer language resources are available compared to\nEnglish.\n  Materials and Methods: We introduce xMEN, a modular system for cross-lingual\nmedical entity normalization, which performs well in both low- and\nhigh-resource scenarios. When synonyms in the target language are scarce for a\ngiven terminology, we leverage English aliases via cross-lingual candidate\ngeneration. For candidate ranking, we incorporate a trainable cross-encoder\nmodel if annotations for the target task are available. We also evaluate\ncross-encoders trained in a weakly supervised manner based on\nmachine-translated datasets from a high resource domain. Our system is publicly\navailable as an extensible Python toolkit.\n  Results: xMEN improves the state-of-the-art performance across a wide range\nof multilingual benchmark datasets. Weakly supervised cross-encoders are\neffective when no training data is available for the target task. Through the\ncompatibility of xMEN with the BigBIO framework, it can be easily used with\nexisting and prospective datasets.\n  Discussion: Our experiments show the importance of balancing the output of\ngeneral-purpose candidate generators with subsequent trainable re-rankers,\nwhich we achieve through a rank regularization term in the loss function of the\ncross-encoder. However, error analysis reveals that multi-word expressions and\nother complex entities are still challenging.\n  Conclusion: xMEN exhibits strong performance for medical entity normalization\nin multiple languages, even when no labeled data and few terminology aliases\nfor the target language are available. Its configuration system and evaluation\nmodules enable reproducible benchmarks. Models and code are available online at\nthe following URL: https://github.com/hpi-dhc/xmen",
            "author": [
                "Florian Borchert",
                "Ignacio Llorca",
                "Roland Roller",
                "Bert Arnrich",
                "Matthieu-P. Schapranow"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11275v1",
                "http://arxiv.org/pdf/2310.11275v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11270v3",
            "title": "Graph Neural Networks for Recommendation: Reproducibility, Graph\n  Topology, and Node Representation",
            "updated": "2023-11-28T13:57:46Z",
            "published": "2023-10-17T13:42:32Z",
            "summary": "Graph neural networks (GNNs) have gained prominence in recommendation systems\nin recent years. By representing the user-item matrix as a bipartite and\nundirected graph, GNNs have demonstrated their potential to capture short- and\nlong-distance user-item interactions, thereby learning more accurate preference\npatterns than traditional recommendation approaches. In contrast to previous\ntutorials on the same topic, this tutorial aims to present and examine three\nkey aspects that characterize GNNs for recommendation: (i) the reproducibility\nof state-of-the-art approaches, (ii) the potential impact of graph topological\ncharacteristics on the performance of these models, and (iii) strategies for\nlearning node representations when training features from scratch or utilizing\npre-trained embeddings as additional item information (e.g., multimodal\nfeatures). The goal is to provide three novel theoretical and practical\nperspectives on the field, currently subject to debate in graph learning but\nlong been overlooked in the context of recommendation systems.",
            "author": [
                "Daniele Malitesta",
                "Claudio Pomo",
                "Tommaso Di Noia"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11270v3",
                "http://arxiv.org/pdf/2310.11270v3"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11265v1",
            "title": "Image Compression using only Attention based Neural Networks",
            "updated": "2023-10-17T13:38:38Z",
            "published": "2023-10-17T13:38:38Z",
            "summary": "In recent research, Learned Image Compression has gained prominence for its\ncapacity to outperform traditional handcrafted pipelines, especially at low\nbit-rates. While existing methods incorporate convolutional priors with\noccasional attention blocks to address long-range dependencies, recent advances\nin computer vision advocate for a transformative shift towards fully\ntransformer-based architectures grounded in the attention mechanism. This paper\ninvestigates the feasibility of image compression exclusively using attention\nlayers within our novel model, QPressFormer. We introduce the concept of\nlearned image queries to aggregate patch information via cross-attention,\nfollowed by quantization and coding techniques. Through extensive evaluations,\nour work demonstrates competitive performance achieved by convolution-free\narchitectures across the popular Kodak, DIV2K, and CLIC datasets.",
            "author": [
                "Natacha Luka",
                "Romain Negrel",
                "David Picard"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11265v1",
                "http://arxiv.org/pdf/2310.11265v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11258v2",
            "title": "Utilizing Weak Supervision To Generate Indonesian Conservation Dataset",
            "updated": "2023-10-24T12:01:14Z",
            "published": "2023-10-17T13:23:18Z",
            "summary": "Weak supervision has emerged as a promising approach for rapid and\nlarge-scale dataset creation in response to the increasing demand for\naccelerated NLP development. By leveraging labeling functions, weak supervision\nallows practitioners to generate datasets quickly by creating learned label\nmodels that produce soft-labeled datasets. This paper aims to show how such an\napproach can be utilized to build an Indonesian NLP dataset from conservation\nnews text. We construct two types of datasets: multi-class classification and\nsentiment classification. We then provide baseline experiments using various\npretrained language models. These baseline results demonstrate test\nperformances of 59.79% accuracy and 55.72% F1-score for sentiment\nclassification, 66.87% F1-score-macro, 71.5% F1-score-micro, and 83.67% ROC-AUC\nfor multi-class classification. Additionally, we release the datasets and\nlabeling functions used in this work for further research and exploration.",
            "author": [
                "Mega Fransiska",
                "Diah Pitaloka",
                "Saripudin",
                "Satrio Putra",
                "Lintang Sutawika"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11258v2",
                "http://arxiv.org/pdf/2310.11258v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11256v1",
            "title": "Gromov-Wassertein-like Distances in the Gaussian Mixture Models Space",
            "updated": "2023-10-17T13:22:36Z",
            "published": "2023-10-17T13:22:36Z",
            "summary": "In this paper, we introduce two Gromov-Wasserstein-type distances on the set\nof Gaussian mixture models. The first one takes the form of a\nGromov-Wasserstein distance between two discrete distributionson the space of\nGaussian measures. This distance can be used as an alternative to\nGromov-Wasserstein for applications which only require to evaluate how far the\ndistributions are from each other but does not allow to derive directly an\noptimal transportation plan between clouds of points. To design a way to define\nsuch a transportation plan, we introduce another distance between measures\nliving in incomparable spaces that turns out to be closely related to\nGromov-Wasserstein. When restricting the set of admissible transportation\ncouplings to be themselves Gaussian mixture models in this latter, this defines\nanother distance between Gaussian mixture models that can be used as another\nalternative to Gromov-Wasserstein and which allows to derive an optimal\nassignment between points. Finally, we design a transportation plan associated\nwith the first distance by analogy with the second, and we illustrate their\npractical uses on medium-to-large scale problems such as shape matching and\nhyperspectral image color transfer.",
            "author": [
                "Antoine Salmona",
                "Julie Delon",
                "Agn\u00e8s Desolneux"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11256v1",
                "http://arxiv.org/pdf/2310.11256v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11248v2",
            "title": "CrossCodeEval: A Diverse and Multilingual Benchmark for Cross-File Code\n  Completion",
            "updated": "2023-11-17T02:51:39Z",
            "published": "2023-10-17T13:18:01Z",
            "summary": "Code completion models have made significant progress in recent years, yet\ncurrent popular evaluation datasets, such as HumanEval and MBPP, predominantly\nfocus on code completion tasks within a single file. This over-simplified\nsetting falls short of representing the real-world software development\nscenario where repositories span multiple files with numerous cross-file\ndependencies, and accessing and understanding cross-file context is often\nrequired to complete the code correctly.\n  To fill in this gap, we propose CrossCodeEval, a diverse and multilingual\ncode completion benchmark that necessitates an in-depth cross-file contextual\nunderstanding to complete the code accurately. CrossCodeEval is built on a\ndiverse set of real-world, open-sourced, permissively-licensed repositories in\nfour popular programming languages: Python, Java, TypeScript, and C#. To create\nexamples that strictly require cross-file context for accurate completion, we\npropose a straightforward yet efficient static-analysis-based approach to\npinpoint the use of cross-file context within the current file.\n  Extensive experiments on state-of-the-art code language models like CodeGen\nand StarCoder demonstrate that CrossCodeEval is extremely challenging when the\nrelevant cross-file context is absent, and we see clear improvements when\nadding these context into the prompt. However, despite such improvements, the\npinnacle of performance remains notably unattained even with the\nhighest-performing model, indicating that CrossCodeEval is also capable of\nassessing model's capability in leveraging extensive context to make better\ncode completion. Finally, we benchmarked various methods in retrieving\ncross-file context, and show that CrossCodeEval can also be used to measure the\ncapability of code retrievers.",
            "author": [
                "Yangruibo Ding",
                "Zijian Wang",
                "Wasi Uddin Ahmad",
                "Hantian Ding",
                "Ming Tan",
                "Nihal Jain",
                "Murali Krishna Ramanathan",
                "Ramesh Nallapati",
                "Parminder Bhatia",
                "Dan Roth",
                "Bing Xiang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11248v2",
                "http://arxiv.org/pdf/2310.11248v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11247v1",
            "title": "Mismatch Negativity: is it time for deconstruction?",
            "updated": "2023-10-17T13:15:42Z",
            "published": "2023-10-17T13:15:42Z",
            "summary": "Addressed in over 7000 papers, the mismatch negativity (MMN) is an automatic\nbrain response to unexpectation that has profoundly shaped perception research.\nAn important turn has been its computational interpretation as a prediction\nerror. This learning-based account is grounded in Bayesian theory and offers\ntestable hypotheses for addressing efficiently the context-sensitivity of\nsensory processing. We emphasize that this theoretical turn requires a\nmethodological one. Specifically, we advocate dynamical modeling over\naveraged-based approaches providing the MMN. We show that dynamic analysis\naddresses the interpretation of subtle fluctuations in brain activity, a\nnecessary step to understand how perception adapts to change.",
            "author": [
                "Francoise Lecaignard",
                "Jeremie Mattout"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11247v1",
                "http://arxiv.org/pdf/2310.11247v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11245v1",
            "title": "Neural network approach for a rapid prediction of metal-supported\n  borophene properties",
            "updated": "2023-10-17T13:13:23Z",
            "published": "2023-10-17T13:13:23Z",
            "summary": "We develop a high-dimensional neural network potential (NNP) to describe the\nstructural and energetic properties of borophene deposited on silver. This NNP\nhas the accuracy of DFT calculations while achieving computational speedups of\nseveral orders of magnitude, allowing the study of extensive structures that\nmay reveal intriguing moir\\'e patterns or surface corrugations. We describe an\nefficient approach to constructing the training data set using an iterative\ntechnique known as the \"adaptive learning approach\". The developed NNP\npotential is able to produce, with an excellent agreement, the structure,\nenergy and forces of DFT. Finally, the calculated stability of various\nborophene polymorphs, including those not initially included in the training\ndataset, shows better stabilization for $\\nu\\sim0.1$ hole density, and in\nparticular for the allotrope $\\alpha$ ($\\nu=\\frac{1}{9}$). The stability of\nborophene on the metal surface is shown to depend on its orientation, implying\nstructural corrugation patterns that can only be observed from long time\nsimulations on extended systems. The NNP also demonstrates its ability to\nsimulate vibrational densities of states and produce realistic structures, with\nsimulated STM images closely matching the experimental ones.",
            "author": [
                "Pierre Mignon",
                "Abdul-Rahman Allouche",
                "Neil Richard Innis",
                "Colin Bousige"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11245v1",
                "http://arxiv.org/pdf/2310.11245v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "physics.chem-ph",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11244v1",
            "title": "Entity Matching using Large Language Models",
            "updated": "2023-10-17T13:12:32Z",
            "published": "2023-10-17T13:12:32Z",
            "summary": "Entity Matching is the task of deciding whether two entity descriptions refer\nto the same real-world entity. Entity Matching is a central step in most data\nintegration pipelines and an enabler for many e-commerce applications which\nrequire to match products offers from different vendors. State-of-the-art\nentity matching methods often rely on pre-trained language models (PLMs) such\nas BERT or RoBERTa. Two major drawbacks of these models for entity matching are\nthat (i) the models require significant amounts of task-specific training data\nand (ii) the fine-tuned models are not robust concerning out-of-distribution\nentities. In this paper, we investigate using large language models (LLMs) for\nentity matching as a less domain-specific training data reliant and more robust\nalternative to PLM-based matchers. Our study covers hosted LLMs, such as GPT3.5\nand GPT4, as well as open source LLMs based on Llama2 which can be run locally.\nWe evaluate these models in a zero-shot scenario as well as a scenario where\ntask-specific training data is available. We compare different prompt designs\nas well as the prompt sensitivity of the models in the zero-shot scenario. We\ninvestigate (i) the selection of in-context demonstrations, (ii) the generation\nof matching rules, as well as (iii) fine-tuning GPT3.5 in the second scenario\nusing the same pool of training data across the different approaches. Our\nexperiments show that GPT4 without any task-specific training data outperforms\nfine-tuned PLMs (RoBERTa and Ditto) on three out of five benchmark datasets\nreaching F1 scores around 90%. The experiments with in-context learning and\nrule generation show that all models beside of GPT4 benefit from these\ntechniques (on average 5.9% and 2.2% F1), while GPT4 does not need such\nadditional guidance in most cases...",
            "author": [
                "Ralph Peeters",
                "Christian Bizer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11244v1",
                "http://arxiv.org/pdf/2310.11244v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11241v1",
            "title": "Humanising robot-assisted navigation",
            "updated": "2023-10-17T13:10:23Z",
            "published": "2023-10-17T13:10:23Z",
            "summary": "Robot-assisted navigation is a perfect example of a class of applications\nrequiring flexible control approaches. When the human is reliable, the robot\nshould concede space to their initiative. When the human makes inappropriate\nchoices the robot controller should kick-in guiding them towards safer paths.\nShared authority control is a way to achieve this behaviour by deciding online\nhow much of the authority should be given to the human and how much should be\nretained by the robot. An open problem is how to evaluate the appropriateness\nof the human's choices. One possible way is to consider the deviation from an\nideal path computed by the robot. This choice is certainly safe and efficient,\nbut it emphasises the importance of the robot's decision and relegates the\nhuman to a secondary role. In this paper, we propose a different paradigm: a\nhuman's behaviour is correct if, at every time, it bears a close resemblance to\nwhat other humans do in similar situations. This idea is implemented through\nthe combination of machine learning and adaptive control. The map of the\nenvironment is decomposed into a grid. In each cell, we classify the possible\nmotions that the human executes. We use a neural network classifier to classify\nthe current motion, and the probability score is used as a hyperparameter in\nthe control to vary the amount of intervention. The experiments collected for\nthe paper show the feasibility of the idea. A qualitative evaluation, done by\nsurveying the users after they have tested the robot, shows that the\nparticipants preferred our control method over a state-of-the-art visco-elastic\ncontrol.",
            "author": [
                "Placido Falqueto",
                "Alessandro Antonucci",
                "Luigi Palopoli",
                "Daniele Fontanelli"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11241v1",
                "http://arxiv.org/pdf/2310.11241v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11482v1",
            "title": "Rethinking Class-incremental Learning in the Era of Large Pre-trained\n  Models via Test-Time Adaptation",
            "updated": "2023-10-17T13:06:39Z",
            "published": "2023-10-17T13:06:39Z",
            "summary": "Class-incremental learning (CIL) is a challenging task that involves\ncontinually learning to categorize classes into new tasks without forgetting\npreviously learned information. The advent of the large pre-trained models\n(PTMs) has fast-tracked the progress in CIL due to the highly transferable PTM\nrepresentations, where tuning a small set of parameters results in\nstate-of-the-art performance when compared with the traditional CIL methods\nthat are trained from scratch. However, repeated fine-tuning on each task\ndestroys the rich representations of the PTMs and further leads to forgetting\nprevious tasks. To strike a balance between the stability and plasticity of\nPTMs for CIL, we propose a novel perspective of eliminating training on every\nnew task and instead performing test-time adaptation (TTA) directly on the test\ninstances. Concretely, we propose \"Test-Time Adaptation for Class-Incremental\nLearning\" (TTACIL) that first fine-tunes Layer Norm parameters of the PTM on\neach test instance for learning task-specific features, and then resets them\nback to the base model to preserve stability. As a consequence, TTACIL does not\nundergo any forgetting, while benefiting each task with the rich PTM features.\nAdditionally, by design, our method is robust to common data corruptions. Our\nTTACIL outperforms several state-of-the-art CIL methods when evaluated on\nmultiple CIL benchmarks under both clean and corrupted data.",
            "author": [
                "Imad Eddine Marouf",
                "Subhankar Roy",
                "Enzo Tartaglione",
                "St\u00e9phane Lathuili\u00e8re"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11482v1",
                "http://arxiv.org/pdf/2310.11482v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11232v1",
            "title": "Learning to Sample Better",
            "updated": "2023-10-17T13:03:49Z",
            "published": "2023-10-17T13:03:49Z",
            "summary": "These lecture notes provide an introduction to recent advances in generative\nmodeling methods based on the dynamical transportation of measures, by means of\nwhich samples from a simple base measure are mapped to samples from a target\nmeasure of interest. Special emphasis is put on the applications of these\nmethods to Monte-Carlo (MC) sampling techniques, such as importance sampling\nand Markov Chain Monte-Carlo (MCMC) schemes. In this context, it is shown how\nthe maps can be learned variationally using data generated by MC sampling, and\nhow they can in turn be used to improve such sampling in a positive feedback\nloop.",
            "author": [
                "Michael S. Albergo",
                "Eric Vanden-Eijnden"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11232v1",
                "http://arxiv.org/pdf/2310.11232v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11230v2",
            "title": "Zipformer: A faster and better encoder for automatic speech recognition",
            "updated": "2023-12-06T11:58:34Z",
            "published": "2023-10-17T13:01:10Z",
            "summary": "The Conformer has become the most popular encoder model for automatic speech\nrecognition (ASR). It adds convolution modules to a transformer to learn both\nlocal and global dependencies. In this work we describe a faster, more\nmemory-efficient, and better-performing transformer, called Zipformer. Modeling\nchanges include: 1) a U-Net-like encoder structure where middle stacks operate\nat lower frame rates; 2) reorganized block structure with more modules, within\nwhich we re-use attention weights for efficiency; 3) a modified form of\nLayerNorm called BiasNorm allows us to retain some length information; 4) new\nactivation functions SwooshR and SwooshL work better than Swish. We also\npropose a new optimizer, called ScaledAdam, which scales the update by each\ntensor's current scale to keep the relative change about the same, and also\nexplictly learns the parameter scale. It achieves faster convergence and better\nperformance than Adam. Extensive experiments on LibriSpeech, Aishell-1, and\nWenetSpeech datasets demonstrate the effectiveness of our proposed Zipformer\nover other state-of-the-art ASR models. Our code is publicly available at\nhttps://github.com/k2-fsa/icefall.",
            "author": [
                "Zengwei Yao",
                "Liyong Guo",
                "Xiaoyu Yang",
                "Wei Kang",
                "Fangjun Kuang",
                "Yifan Yang",
                "Zengrui Jin",
                "Long Lin",
                "Daniel Povey"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11230v2",
                "http://arxiv.org/pdf/2310.11230v2"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.LG",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11481v1",
            "title": "Contracting Tsetlin Machine with Absorbing Automata",
            "updated": "2023-10-17T12:56:39Z",
            "published": "2023-10-17T12:56:39Z",
            "summary": "In this paper, we introduce a sparse Tsetlin Machine (TM) with absorbing\nTsetlin Automata (TA) states. In brief, the TA of each clause literal has both\nan absorbing Exclude- and an absorbing Include state, making the learning\nscheme absorbing instead of ergodic. When a TA reaches an absorbing state, it\nwill never leave that state again. If the absorbing state is an Exclude state,\nboth the automaton and the literal can be removed from further consideration.\nThe literal will as a result never participates in that clause. If the\nabsorbing state is an Include state, on the other hand, the literal is stored\nas a permanent part of the clause while the TA is discarded. A novel sparse\ndata structure supports these updates by means of three action lists: Absorbed\nInclude, Include, and Exclude. By updating these lists, the TM gets smaller and\nsmaller as the literals and their TA withdraw. In this manner, the computation\naccelerates during learning, leading to faster learning and less energy\nconsumption.",
            "author": [
                "Bimal Bhattarai",
                "Ole-Christoffer Granmo",
                "Lei Jiao",
                "Per-Arne Andersen",
                "Svein Anders Tunheim",
                "Rishad Shafik",
                "Alex Yakovlev"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11481v1",
                "http://arxiv.org/pdf/2310.11481v1"
            ],
            "primary_category": "cs.FL",
            "category": [
                "cs.FL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11223v1",
            "title": "Model-based Estimation of AV-nodal Refractory Period and Conduction\n  Delay Trends from ECG",
            "updated": "2023-10-17T12:55:59Z",
            "published": "2023-10-17T12:55:59Z",
            "summary": "Atrial fibrillation (AF) is the most common arrhythmia, associated with\nsignificant burdens to patients and the healthcare system. The atrioventricular\n(AV) node plays a vital role in regulating heart rate during AF, but is often\ninsufficient in regards to maintaining a healthy heart rate. Thus, the AV node\nproperties are modified using rate-control drugs. Hence, quantifying individual\ndifferences in diurnal and short-term variability of AV-nodal function could\naid in personalized treatment selection.\n  This study presents a novel methodology for estimating the refractory period\n(RP) and conduction delay (CD) trends and their uncertainty in the two pathways\nof the AV node during 24 hours using non-invasive data. This was achieved using\na network model together with a problem-specific genetic algorithm and an\napproximate Bayesian computation algorithm. Diurnal and short-term variability\nin the estimated RP and CD was quantified by the difference between the daytime\nand nighttime estimates and by the Kolmogorov-Smirnov distance between adjacent\n10-minute segments in the 24-hour trends.\n  Holter ECGs from 51 patients with permanent AF during baseline were analyzed,\nand the predictive power of variations in RP and CD on the resulting heart rate\nreduction after treatment with four rate control drugs was investigated.\nDiurnal variability yielded no correlation to treatment outcome, and no\nprediction of drug outcome was possible using the machine learning tools.\nHowever, a correlation between the short-term variability for the RP and CD in\nthe fast pathway and resulting heart rate reduction during treatment with\nmetoprolol ($\\rho=0.48, p<0.005$ in RP, $\\rho=0.35, p<0.05$ in CD) were found.\n  The proposed methodology enables non-invasive estimation of the AV node\nproperties during 24 hours, which may have the potential to assist in treatment\nselection.",
            "author": [
                "Mattias Karlsson",
                "Pyotr G Platonov",
                "Sara R. Ulimoen",
                "Frida Sandberg",
                "Mikael Wallman"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11223v1",
                "http://arxiv.org/pdf/2310.11223v1"
            ],
            "primary_category": "stat.AP",
            "category": [
                "stat.AP",
                "q-bio.TO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11217v1",
            "title": "Innovative Methods for Non-Destructive Inspection of Handwritten\n  Documents",
            "updated": "2023-10-17T12:45:04Z",
            "published": "2023-10-17T12:45:04Z",
            "summary": "Handwritten document analysis is an area of forensic science, with the goal\nof establishing authorship of documents through examination of inherent\ncharacteristics. Law enforcement agencies use standard protocols based on\nmanual processing of handwritten documents. This method is time-consuming, is\noften subjective in its evaluation, and is not replicable. To overcome these\nlimitations, in this paper we present a framework capable of extracting and\nanalyzing intrinsic measures of manuscript documents related to text line\nheights, space between words, and character sizes using image processing and\ndeep learning techniques. The final feature vector for each document involved\nconsists of the mean and standard deviation for every type of measure\ncollected. By quantifying the Euclidean distance between the feature vectors of\nthe documents to be compared, authorship can be discerned. We also proposed a\nnew and challenging dataset consisting of 362 handwritten manuscripts written\non paper and digital devices by 124 different people. Our study pioneered the\ncomparison between traditionally handwritten documents and those produced with\ndigital tools (e.g., tablets). Experimental results demonstrate the ability of\nour method to objectively determine authorship in different writing media,\noutperforming the state of the art.",
            "author": [
                "Eleonora Breci",
                "Luca Guarnera",
                "Sebastiano Battiato"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11217v1",
                "http://arxiv.org/pdf/2310.11217v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11211v3",
            "title": "Understanding Fairness Surrogate Functions in Algorithmic Fairness",
            "updated": "2023-12-02T15:08:20Z",
            "published": "2023-10-17T12:40:53Z",
            "summary": "It has been observed that machine learning algorithms exhibit biased\npredictions against certain population groups. To mitigate such bias while\nachieving comparable accuracy, a promising approach is to introduce surrogate\nfunctions of the concerned fairness definition and solve a constrained\noptimization problem. However, it is intriguing in previous work that such\nfairness surrogate functions may yield unfair results and high instability. In\nthis work, in order to deeply understand them, taking a widely used fairness\ndefinition--demographic parity as an example, we show that there is a\nsurrogate-fairness gap between the fairness definition and the fairness\nsurrogate function. Also, the theoretical analysis and experimental results\nabout the gap motivate us that the fairness and stability will be affected by\nthe points far from the decision boundary, which is the large margin points\nissue investigated in this paper. To address it, we propose the general sigmoid\nsurrogate to simultaneously reduce both the surrogate-fairness gap and the\nvariance, and offer a rigorous fairness and stability upper bound.\nInterestingly, the theory also provides insights into two important issues that\ndeal with the large margin points as well as obtaining a more balanced dataset\nare beneficial to fairness and stability. Furthermore, we elaborate a novel and\ngeneral algorithm called Balanced Surrogate, which iteratively reduces the gap\nto mitigate unfairness. Finally, we provide empirical evidence showing that our\nmethods consistently improve fairness and stability while maintaining accuracy\ncomparable to the baselines in three real-world datasets.",
            "author": [
                "Wei Yao",
                "Zhanke Zhou",
                "Zhicong Li",
                "Bo Han",
                "Yong Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11211v3",
                "http://arxiv.org/pdf/2310.11211v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11210v1",
            "title": "Learning Comprehensive Representations with Richer Self for\n  Text-to-Image Person Re-Identification",
            "updated": "2023-10-17T12:39:16Z",
            "published": "2023-10-17T12:39:16Z",
            "summary": "Text-to-image person re-identification (TIReID) retrieves pedestrian images\nof the same identity based on a query text. However, existing methods for\nTIReID typically treat it as a one-to-one image-text matching problem, only\nfocusing on the relationship between image-text pairs within a view. The\nmany-to-many matching between image-text pairs across views under the same\nidentity is not taken into account, which is one of the main reasons for the\npoor performance of existing methods. To this end, we propose a simple yet\neffective framework, called LCR$^2$S, for modeling many-to-many correspondences\nof the same identity by learning comprehensive representations for both\nmodalities from a novel perspective. We construct a support set for each image\n(text) by using other images (texts) under the same identity and design a\nmulti-head attentional fusion module to fuse the image (text) and its support\nset. The resulting enriched image and text features fuse information from\nmultiple views, which are aligned to train a \"richer\" TIReID model with\nmany-to-many correspondences. Since the support set is unavailable during\ninference, we propose to distill the knowledge learned by the \"richer\" model\ninto a lightweight model for inference with a single image/text as input. The\nlightweight model focuses on semantic association and reasoning of multi-view\ninformation, which can generate a comprehensive representation containing\nmulti-view information with only a single-view input to perform accurate\ntext-to-image retrieval during inference. In particular, we use the intra-modal\nfeatures and inter-modal semantic relations of the \"richer\" model to supervise\nthe lightweight model to inherit its powerful capability. Extensive experiments\ndemonstrate the effectiveness of LCR$^2$S, and it also achieves new\nstate-of-the-art performance on three popular TIReID datasets.",
            "author": [
                "Shuanglin Yan",
                "Neng Dong",
                "Jun Liu",
                "Liyan Zhang",
                "Jinhui Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11210v1",
                "http://arxiv.org/pdf/2310.11210v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11207v1",
            "title": "Can Large Language Models Explain Themselves? A Study of LLM-Generated\n  Self-Explanations",
            "updated": "2023-10-17T12:34:32Z",
            "published": "2023-10-17T12:34:32Z",
            "summary": "Large language models (LLMs) such as ChatGPT have demonstrated superior\nperformance on a variety of natural language processing (NLP) tasks including\nsentiment analysis, mathematical reasoning and summarization. Furthermore,\nsince these models are instruction-tuned on human conversations to produce\n\"helpful\" responses, they can and often will produce explanations along with\nthe response, which we call self-explanations. For example, when analyzing the\nsentiment of a movie review, the model may output not only the positivity of\nthe sentiment, but also an explanation (e.g., by listing the sentiment-laden\nwords such as \"fantastic\" and \"memorable\" in the review). How good are these\nautomatically generated self-explanations? In this paper, we investigate this\nquestion on the task of sentiment analysis and for feature attribution\nexplanation, one of the most commonly studied settings in the interpretability\nliterature (for pre-ChatGPT models). Specifically, we study different ways to\nelicit the self-explanations, evaluate their faithfulness on a set of\nevaluation metrics, and compare them to traditional explanation methods such as\nocclusion or LIME saliency maps. Through an extensive set of experiments, we\nfind that ChatGPT's self-explanations perform on par with traditional ones, but\nare quite different from them according to various agreement metrics, meanwhile\nbeing much cheaper to produce (as they are generated along with the\nprediction). In addition, we identified several interesting characteristics of\nthem, which prompt us to rethink many current model interpretability practices\nin the era of ChatGPT(-like) LLMs.",
            "author": [
                "Shiyuan Huang",
                "Siddarth Mamidanna",
                "Shreedhar Jangam",
                "Yilun Zhou",
                "Leilani H. Gilpin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11207v1",
                "http://arxiv.org/pdf/2310.11207v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11480v1",
            "title": "Whole-brain radiomics for clustered federated personalization in brain\n  tumor segmentation",
            "updated": "2023-10-17T12:33:43Z",
            "published": "2023-10-17T12:33:43Z",
            "summary": "Federated learning and its application to medical image segmentation have\nrecently become a popular research topic. This training paradigm suffers from\nstatistical heterogeneity between participating institutions' local datasets,\nincurring convergence slowdown as well as potential accuracy loss compared to\nclassical training. To mitigate this effect, federated personalization emerged\nas the federated optimization of one model per institution. We propose a novel\npersonalization algorithm tailored to the feature shift induced by the usage of\ndifferent scanners and acquisition parameters by different institutions. This\nmethod is the first to account for both inter and intra-institution feature\nshift (multiple scanners used in a single institution). It is based on the\ncomputation, within each centre, of a series of radiomic features capturing the\nglobal texture of each 3D image volume, followed by a clustering analysis\npooling all feature vectors transferred from the local institutions to the\ncentral server. Each computed clustered decentralized dataset (potentially\nincluding data from different institutions) then serves to finetune a global\nmodel obtained through classical federated learning. We validate our approach\non the Federated Brain Tumor Segmentation 2022 Challenge dataset (FeTS2022).\nOur code is available at (https://github.com/MatthisManthe/radiomics_CFFL).",
            "author": [
                "Matthis Manthe",
                "Stefan Duffner",
                "Carole Lartizien"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11480v1",
                "http://arxiv.org/pdf/2310.11480v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11203v1",
            "title": "Federated Learning with Nonvacuous Generalisation Bounds",
            "updated": "2023-10-17T12:29:29Z",
            "published": "2023-10-17T12:29:29Z",
            "summary": "We introduce a novel strategy to train randomised predictors in federated\nlearning, where each node of the network aims at preserving its privacy by\nreleasing a local predictor but keeping secret its training dataset with\nrespect to the other nodes. We then build a global randomised predictor which\ninherits the properties of the local private predictors in the sense of a\nPAC-Bayesian generalisation bound. We consider the synchronous case where all\nnodes share the same training objective (derived from a generalisation bound),\nand the asynchronous case where each node may have its own personalised\ntraining objective. We show through a series of numerical experiments that our\napproach achieves a comparable predictive performance to that of the batch\napproach where all datasets are shared across nodes. Moreover the predictors\nare supported by numerically nonvacuous generalisation bounds while preserving\nprivacy for each node. We explicitly compute the increment on predictive\nperformance and generalisation bounds between batch and federated settings,\nhighlighting the price to pay to preserve privacy.",
            "author": [
                "Pierre Jobic",
                "Maxime Haddouche",
                "Benjamin Guedj"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11203v1",
                "http://arxiv.org/pdf/2310.11203v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11199v1",
            "title": "Superradiant Broadband Magneto-electric Arrays Empowered by\n  Meta-learning",
            "updated": "2023-10-17T12:25:52Z",
            "published": "2023-10-17T12:25:52Z",
            "summary": "Laws of electrodynamics constrain scattering cross-sections of resonant\nobjects. Nevertheless, a fundamental bound that expresses how larger that\nscattering cross-section can be is yet to be found. Approaches based on\ncascading multiple resonances permitted to push the scattering responses of\nsubwavelength structures and to exceed existing estimators, for which the\nChu-Harrington criterion is, potentially, the most commonly considered one. The\nsuperradiant empirical limit, addressing scattering performances of near-field\ncoupled resonator arrays, was subsequently developed to tighten existing\nestimates, setting a new bound that prompted efforts to find structures that\nexceed it. Here, we demonstrate that genetically designed superscattering\nstructures, encompassing arrays of constructively interfering electric and\nmagnetic dipoles, can build enormously high scatting cross-sections exceeding\nthose imposed by existing criteria in electromagnetic theory including the\nsuperradiant empirical limit. After undergoing thousands of evolutionary\ngenerations, iterating sizes, mutual orientations, and locations of resonators,\nthe structures approach their heuristically maximized performance, which is\nunlikely to be obtained by a random distribution given more than a billion\ntrials. As an additional practically valuable parameter, the scattering\nbandwidth also underwent optimization. We demonstrate that flat\nwavelength-comparable structures can have significant backscattering alongside\nmore than 40% fractional bandwidth. The result demonstrates the fundamental\ncapability to untighten scattering cross-section from bandwidth limitations.\nNew capabilities of genetic optimization algorithms, equipped with fast\ncomputational tools and constrained by experimentally obtainable\nelectromagnetic parameters, allow chasing well-accepted traditional bounds,\ndemonstrating ever-seen electromagnetic performances.",
            "author": [
                "Konstantin Grotov",
                "Anna Mikhailovskaya",
                "Dmytro Vovchuk",
                "Dmitry Dobrykh",
                "Carsten Rockstuhl",
                "Pavel Ginzburg"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11199v1",
                "http://arxiv.org/pdf/2310.11199v1"
            ],
            "primary_category": "physics.app-ph",
            "category": [
                "physics.app-ph",
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11198v1",
            "title": "EEG motor imagery decoding: A framework for comparative analysis with\n  channel attention mechanisms",
            "updated": "2023-10-17T12:25:31Z",
            "published": "2023-10-17T12:25:31Z",
            "summary": "The objective of this study is to investigate the application of various\nchannel attention mechanisms within the domain of brain-computer interface\n(BCI) for motor imagery decoding. Channel attention mechanisms can be seen as a\npowerful evolution of spatial filters traditionally used for motor imagery\ndecoding. This study systematically compares such mechanisms by integrating\nthem into a lightweight architecture framework to evaluate their impact. We\ncarefully construct a straightforward and lightweight baseline architecture\ndesigned to seamlessly integrate different channel attention mechanisms. This\napproach is contrary to previous works which only investigate one attention\nmechanism and usually build a very complex, sometimes nested architecture. Our\nframework allows us to evaluate and compare the impact of different attention\nmechanisms under the same circumstances. The easy integration of different\nchannel attention mechanisms as well as the low computational complexity\nenables us to conduct a wide range of experiments on three datasets to\nthoroughly assess the effectiveness of the baseline model and the attention\nmechanisms. Our experiments demonstrate the strength and generalizability of\nour architecture framework as well as how channel attention mechanisms can\nimprove the performance while maintaining the small memory footprint and low\ncomputational complexity of our baseline architecture. Our architecture\nemphasizes simplicity, offering easy integration of channel attention\nmechanisms, while maintaining a high degree of generalizability across\ndatasets, making it a versatile and efficient solution for EEG motor imagery\ndecoding within brain-computer interfaces.",
            "author": [
                "Martin Wimpff",
                "Leonardo Gizzi",
                "Jan Zerfowski",
                "Bin Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11198v1",
                "http://arxiv.org/pdf/2310.11198v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11188v2",
            "title": "Adversarial Bandits with Multi-User Delayed Feedback: Theory and\n  Application",
            "updated": "2023-11-26T17:18:23Z",
            "published": "2023-10-17T12:08:15Z",
            "summary": "The multi-armed bandit (MAB) models have attracted significant research\nattention due to their applicability and effectiveness in various real-world\nscenarios such as resource allocation, online advertising, and dynamic pricing.\nAs an important branch, the adversarial MAB problems with delayed feedback have\nbeen proposed and studied by many researchers recently where a conceptual\nadversary strategically selects the reward distributions associated with each\narm to challenge the learning algorithm and the agent experiences a delay\nbetween taking an action and receiving the corresponding reward feedback.\nHowever, the existing models restrict the feedback to be generated from only\none user, which makes models inapplicable to the prevailing scenarios of\nmultiple users (e.g. ad recommendation for a group of users). In this paper, we\nconsider that the delayed feedback results are from multiple users and are\nunrestricted on internal distribution. In contrast, the feedback delay is\narbitrary and unknown to the player in advance. Also, for different users in a\nround, the delays in feedback have no assumption of latent correlation. Thus,\nwe formulate an adversarial MAB problem with multi-user delayed feedback and\ndesign a modified EXP3 algorithm MUD-EXP3, which makes a decision at each round\nby considering the importance-weighted estimator of the received feedback from\ndifferent users. On the premise of known terminal round index $T$, the number\nof users $M$, the number of arms $N$, and upper bound of delay $d_{max}$, we\nprove a regret of $\\mathcal{O}(\\sqrt{TM^2\\ln{N}(N\\mathrm{e}+4d_{max})})$.\nFurthermore, for the more common case of unknown $T$, an adaptive algorithm\nAMUD-EXP3 is proposed with a sublinear regret with respect to $T$. Finally,\nextensive experiments are conducted to indicate the correctness and\neffectiveness of our algorithms.",
            "author": [
                "Yandi Li",
                "Jianxiong Guo",
                "Yupeng Li",
                "Tian Wang",
                "Weijia Jia"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11188v2",
                "http://arxiv.org/pdf/2310.11188v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11186v1",
            "title": "Efficiently Visualizing Large Graphs",
            "updated": "2023-10-17T12:07:14Z",
            "published": "2023-10-17T12:07:14Z",
            "summary": "Most existing graph visualization methods based on dimension reduction are\nlimited to relatively small graphs due to performance issues. In this work, we\npropose a novel dimension reduction method for graph visualization, called\nt-Distributed Stochastic Graph Neighbor Embedding (t-SGNE). t-SGNE is\nspecifically designed to visualize cluster structures in the graph. As a\nvariant of the standard t-SNE method, t-SGNE avoids the time-consuming\ncomputations of pairwise similarity. Instead, it uses the neighbor structures\nof the graph to reduce the time complexity from quadratic to linear, thus\nsupporting larger graphs. In addition, to suit t-SGNE, we combined Laplacian\nEigenmaps with the shortest path algorithm in graphs to form the graph\nembedding algorithm ShortestPath Laplacian Eigenmaps Embedding (SPLEE).\nPerforming SPLEE to obtain a high-dimensional embedding of the large-scale\ngraph and then using t-SGNE to reduce its dimension for visualization, we are\nable to visualize graphs with up to 300K nodes and 1M edges within 5 minutes\nand achieve approximately 10% improvement in visualization quality. Codes and\ndata are available at\nhttps://github.com/Charlie-XIAO/embedding-visualization-test.",
            "author": [
                "Xinyu Li",
                "Yao Xiao",
                "Yuchen Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11186v1",
                "http://arxiv.org/pdf/2310.11186v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11184v1",
            "title": "Sparse Multi-Object Render-and-Compare",
            "updated": "2023-10-17T12:01:32Z",
            "published": "2023-10-17T12:01:32Z",
            "summary": "Reconstructing 3D shape and pose of static objects from a single image is an\nessential task for various industries, including robotics, augmented reality,\nand digital content creation. This can be done by directly predicting 3D shape\nin various representations or by retrieving CAD models from a database and\npredicting their alignments. Directly predicting 3D shapes often produces\nunrealistic, overly smoothed or tessellated shapes. Retrieving CAD models\nensures realistic shapes but requires robust and accurate alignment. Learning\nto directly predict CAD model poses from image features is challenging and\ninaccurate. Works, such as ROCA, compute poses from predicted normalised object\ncoordinates which can be more accurate but are susceptible to systematic\nfailure. SPARC demonstrates that following a ''render-and-compare'' approach\nwhere a network iteratively improves upon its own predictions achieves accurate\nalignments. Nevertheless, it performs individual CAD alignment for every object\ndetected in an image. This approach is slow when applied to many objects as the\ntime complexity increases linearly with the number of objects and can not learn\ninter-object relations. Introducing a new network architecture Multi-SPARC we\nlearn to perform CAD model alignments for multiple detected objects jointly.\nCompared to other single-view methods we achieve state-of-the-art performance\non the challenging real-world dataset ScanNet. By improving the instance\nalignment accuracy from 31.8% to 40.3% we perform similar to state-of-the-art\nmulti-view methods.",
            "author": [
                "Florian Langer",
                "Ignas Budvytis",
                "Roberto Cipolla"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11184v1",
                "http://arxiv.org/pdf/2310.11184v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11178v1",
            "title": "FocDepthFormer: Transformer with LSTM for Depth Estimation from Focus",
            "updated": "2023-10-17T11:53:32Z",
            "published": "2023-10-17T11:53:32Z",
            "summary": "Depth estimation from focal stacks is a fundamental computer vision problem\nthat aims to infer depth from focus/defocus cues in the image stacks. Most\nexisting methods tackle this problem by applying convolutional neural networks\n(CNNs) with 2D or 3D convolutions over a set of fixed stack images to learn\nfeatures across images and stacks. Their performance is restricted due to the\nlocal properties of the CNNs, and they are constrained to process a fixed\nnumber of stacks consistent in train and inference, limiting the generalization\nto the arbitrary length of stacks. To handle the above limitations, we develop\na novel Transformer-based network, FocDepthFormer, composed mainly of a\nTransformer with an LSTM module and a CNN decoder. The self-attention in\nTransformer enables learning more informative features via an implicit\nnon-local cross reference. The LSTM module is learned to integrate the\nrepresentations across the stack with arbitrary images. To directly capture the\nlow-level features of various degrees of focus/defocus, we propose to use\nmulti-scale convolutional kernels in an early-stage encoder. Benefiting from\nthe design with LSTM, our FocDepthFormer can be pre-trained with abundant\nmonocular RGB depth estimation data for visual pattern capturing, alleviating\nthe demand for the hard-to-collect focal stack data. Extensive experiments on\nvarious focal stack benchmark datasets show that our model outperforms the\nstate-of-the-art models on multiple metrics.",
            "author": [
                "Xueyang Kang",
                "Fengze Han",
                "Abdur Fayjie",
                "Dong Gong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11178v1",
                "http://arxiv.org/pdf/2310.11178v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "eess.IV",
                "I.4.9; I.2.10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11173v1",
            "title": "Knowledge Extraction and Distillation from Large-Scale Image-Text\n  Colonoscopy Records Leveraging Large Language and Vision Models",
            "updated": "2023-10-17T11:41:38Z",
            "published": "2023-10-17T11:41:38Z",
            "summary": "The development of artificial intelligence systems for colonoscopy analysis\noften necessitates expert-annotated image datasets. However, limitations in\ndataset size and diversity impede model performance and generalisation.\nImage-text colonoscopy records from routine clinical practice, comprising\nmillions of images and text reports, serve as a valuable data source, though\nannotating them is labour-intensive. Here we leverage recent advancements in\nlarge language and vision models and propose EndoKED, a data mining paradigm\nfor deep knowledge extraction and distillation. EndoKED automates the\ntransformation of raw colonoscopy records into image datasets with pixel-level\nannotation. We validate EndoKED using multi-centre datasets of raw colonoscopy\nrecords (~1 million images), demonstrating its superior performance in training\npolyp detection and segmentation models. Furthermore, the EndoKED pre-trained\nvision backbone enables data-efficient and generalisable learning for optical\nbiopsy, achieving expert-level performance in both retrospective and\nprospective validation.",
            "author": [
                "Shuo Wang",
                "Yan Zhu",
                "Xiaoyuan Luo",
                "Zhiwei Yang",
                "Yizhe Zhang",
                "Peiyao Fu",
                "Manning Wang",
                "Zhijian Song",
                "Quanlin Li",
                "Pinghong Zhou",
                "Yike Guo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11173v1",
                "http://arxiv.org/pdf/2310.11173v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11169v1",
            "title": "MST-GAT: A Multimodal Spatial-Temporal Graph Attention Network for Time\n  Series Anomaly Detection",
            "updated": "2023-10-17T11:37:40Z",
            "published": "2023-10-17T11:37:40Z",
            "summary": "Multimodal time series (MTS) anomaly detection is crucial for maintaining the\nsafety and stability of working devices (e.g., water treatment system and\nspacecraft), whose data are characterized by multivariate time series with\ndiverse modalities. Although recent deep learning methods show great potential\nin anomaly detection, they do not explicitly capture spatial-temporal\nrelationships between univariate time series of different modalities, resulting\nin more false negatives and false positives. In this paper, we propose a\nmultimodal spatial-temporal graph attention network (MST-GAT) to tackle this\nproblem. MST-GAT first employs a multimodal graph attention network (M-GAT) and\na temporal convolution network to capture the spatial-temporal correlation in\nmultimodal time series. Specifically, M-GAT uses a multi-head attention module\nand two relational attention modules (i.e., intra- and inter-modal attention)\nto model modal correlations explicitly. Furthermore, MST-GAT optimizes the\nreconstruction and prediction modules simultaneously. Experimental results on\nfour multimodal benchmarks demonstrate that MST-GAT outperforms the\nstate-of-the-art baselines. Further analysis indicates that MST-GAT strengthens\nthe interpretability of detected anomalies by locating the most anomalous\nunivariate time series.",
            "author": [
                "Chaoyue Ding",
                "Shiliang Sun",
                "Jing Zhao"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.inffus.2022.08.011",
                "http://arxiv.org/abs/2310.11169v1",
                "http://arxiv.org/pdf/2310.11169v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "I.5.4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11165v1",
            "title": "Serenade: A Model for Human-in-the-loop Automatic Chord Estimation",
            "updated": "2023-10-17T11:31:29Z",
            "published": "2023-10-17T11:31:29Z",
            "summary": "Computational harmony analysis is important for MIR tasks such as automatic\nsegmentation, corpus analysis and automatic chord label estimation. However,\nrecent research into the ambiguous nature of musical harmony, causing limited\ninter-rater agreement, has made apparent that there is a glass ceiling for\ncommon metrics such as accuracy. Commonly, these issues are addressed either in\nthe training data itself by creating majority-rule annotations or during the\ntraining phase by learning soft targets. We propose a novel alternative\napproach in which a human and an autoregressive model together co-create a\nharmonic annotation for an audio track. After automatically generating harmony\npredictions, a human sparsely annotates parts with low model confidence and the\nmodel then adjusts its predictions following human guidance. We evaluate our\nmodel on a dataset of popular music and we show that, with this\nhuman-in-the-loop approach, harmonic analysis performance improves over a\nmodel-only approach. The human contribution is amplified by the second,\nconstrained prediction of the model.",
            "author": [
                "Hendrik Vincent Koops",
                "Gianluca Micchi",
                "Ilaria Manco",
                "Elio Quinton"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11165v1",
                "http://arxiv.org/pdf/2310.11165v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11163v1",
            "title": "IMTLab: An Open-Source Platform for Building, Evaluating, and Diagnosing\n  Interactive Machine Translation Systems",
            "updated": "2023-10-17T11:29:04Z",
            "published": "2023-10-17T11:29:04Z",
            "summary": "We present IMTLab, an open-source end-to-end interactive machine translation\n(IMT) system platform that enables researchers to quickly build IMT systems\nwith state-of-the-art models, perform an end-to-end evaluation, and diagnose\nthe weakness of systems. IMTLab treats the whole interactive translation\nprocess as a task-oriented dialogue with a human-in-the-loop setting, in which\nhuman interventions can be explicitly incorporated to produce high-quality,\nerror-free translations. To this end, a general communication interface is\ndesigned to support the flexible IMT architectures and user policies. Based on\nthe proposed design, we construct a simulated and real interactive environment\nto achieve end-to-end evaluation and leverage the framework to systematically\nevaluate previous IMT systems. Our simulated and manual experiments show that\nthe prefix-constrained decoding approach still gains the lowest editing cost in\nthe end-to-end evaluation, while BiTIIMT achieves comparable editing cost with\na better interactive experience.",
            "author": [
                "Xu Huang",
                "Zhirui Zhang",
                "Ruize Gao",
                "Yichao Du",
                "Lemao Liu",
                "Gouping Huang",
                "Shuming Shi",
                "Jiajun Chen",
                "Shujian Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11163v1",
                "http://arxiv.org/pdf/2310.11163v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11161v1",
            "title": "Accurate prediction of international trade flows: Leveraging knowledge\n  graphs and their embeddings",
            "updated": "2023-10-17T11:28:30Z",
            "published": "2023-10-17T11:28:30Z",
            "summary": "Knowledge representation (KR) is vital in designing symbolic notations to\nrepresent real-world facts and facilitate automated decision-making tasks.\nKnowledge graphs (KGs) have emerged so far as a popular form of KR, offering a\ncontextual and human-like representation of knowledge. In international\neconomics, KGs have proven valuable in capturing complex interactions between\ncommodities, companies, and countries. By putting the gravity model, which is a\ncommon economic framework, into the process of building KGs, important factors\nthat affect trade relationships can be taken into account, making it possible\nto predict international trade patterns. This paper proposes an approach that\nleverages Knowledge Graph embeddings for modeling international trade, focusing\non link prediction using embeddings. Thus, valuable insights are offered to\npolicymakers, businesses, and economists, enabling them to anticipate the\neffects of changes in the international trade system. Moreover, the integration\nof traditional machine learning methods with KG embeddings, such as decision\ntrees and graph neural networks are also explored. The research findings\ndemonstrate the potential for improving prediction accuracy and provide\ninsights into embedding explainability in knowledge representation. The paper\nalso presents a comprehensive analysis of the influence of embedding methods on\nother intelligent algorithms.",
            "author": [
                "Diego Rincon-Yanez",
                "Chahinez Ounoughi",
                "Bassem Sellami",
                "Tarmo Kalvet",
                "Marek Tiits",
                "Sabrina Senatore",
                "Sadok Ben Yahia"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11161v1",
                "http://arxiv.org/pdf/2310.11161v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.SC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11158v1",
            "title": "Probing the Creativity of Large Language Models: Can models produce\n  divergent semantic association?",
            "updated": "2023-10-17T11:23:32Z",
            "published": "2023-10-17T11:23:32Z",
            "summary": "Large language models possess remarkable capacity for processing language,\nbut it remains unclear whether these models can further generate creative\ncontent. The present study aims to investigate the creative thinking of large\nlanguage models through a cognitive perspective. We utilize the divergent\nassociation task (DAT), an objective measurement of creativity that asks models\nto generate unrelated words and calculates the semantic distance between them.\nWe compare the results across different models and decoding strategies. Our\nfindings indicate that: (1) When using the greedy search strategy, GPT-4\noutperforms 96% of humans, while GPT-3.5-turbo exceeds the average human level.\n(2) Stochastic sampling and temperature scaling are effective to obtain higher\nDAT scores for models except GPT-4, but face a trade-off between creativity and\nstability. These results imply that advanced large language models have\ndivergent semantic associations, which is a fundamental process underlying\ncreativity.",
            "author": [
                "Honghua Chen",
                "Nai Ding"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11158v1",
                "http://arxiv.org/pdf/2310.11158v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11157v1",
            "title": "PyOcto: A high-throughput seismic phase associator",
            "updated": "2023-10-17T11:23:24Z",
            "published": "2023-10-17T11:23:24Z",
            "summary": "Seismic phase association is an essential task for characterising seismicity:\ngiven a collection of phase picks, identify all seismic events in the data. In\nrecent years, machine learning pickers have lead to a rapid growth in the\nnumber of seismic phase picks. Even though new associators have been suggested,\nthese suffer from long runtimes and sensitivity issues when faced with dense\nseismic sequences. Here we introduce PyOcto, a novel phase associator tackling\nthese issues. PyOcto uses 4D space-time partitioning and can employ homogeneous\nand 1D velocity models. We benchmark PyOcto against popular state of the art\nassociators on two synthetic scenarios and a real, dense aftershock sequence.\nPyOcto consistently achieves detection sensitivities on par or above current\nalgorithms. Furthermore, its runtime is consistently at least 10 times lower,\nwith many scenarios reaching speedup factors above 50. On the challenging 2014\nIquique earthquake sequence, PyOcto achieves excellent detection capability\nwhile maintaining a speedup factor of at least 70 against the other models.\nPyOcto is available as an open source tool for Python on Github and through\nPyPI.",
            "author": [
                "Jannes M\u00fcnchmeyer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11157v1",
                "http://arxiv.org/pdf/2310.11157v1"
            ],
            "primary_category": "physics.geo-ph",
            "category": [
                "physics.geo-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11154v1",
            "title": "Causal discovery using dynamically requested knowledge",
            "updated": "2023-10-17T11:21:23Z",
            "published": "2023-10-17T11:21:23Z",
            "summary": "Causal Bayesian Networks (CBNs) are an important tool for reasoning under\nuncertainty in complex real-world systems. Determining the graphical structure\nof a CBN remains a key challenge and is undertaken either by eliciting it from\nhumans, using machine learning to learn it from data, or using a combination of\nthese two approaches. In the latter case, human knowledge is generally provided\nto the algorithm before it starts, but here we investigate a novel approach\nwhere the structure learning algorithm itself dynamically identifies and\nrequests knowledge for relationships that the algorithm identifies as uncertain\nduring structure learning. We integrate this approach into the Tabu structure\nlearning algorithm and show that it offers considerable gains in structural\naccuracy, which are generally larger than those offered by existing approaches\nfor integrating knowledge. We suggest that a variant which requests only arc\norientation information may be particularly useful where the practitioner has\nlittle preexisting knowledge of the causal relationships. As well as offering\nimproved accuracy, the approach can use human expertise more effectively and\ncontributes to making the structure learning process more transparent.",
            "author": [
                "Neville K Kitson",
                "Anthony C Constantinou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11154v1",
                "http://arxiv.org/pdf/2310.11154v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11153v1",
            "title": "Unsupervised Pre-Training Using Masked Autoencoders for ECG Analysis",
            "updated": "2023-10-17T11:19:51Z",
            "published": "2023-10-17T11:19:51Z",
            "summary": "Unsupervised learning methods have become increasingly important in deep\nlearning due to their demonstrated large utilization of datasets and higher\naccuracy in computer vision and natural language processing tasks. There is a\ngrowing trend to extend unsupervised learning methods to other domains, which\nhelps to utilize a large amount of unlabelled data. This paper proposes an\nunsupervised pre-training technique based on masked autoencoder (MAE) for\nelectrocardiogram (ECG) signals. In addition, we propose a task-specific\nfine-tuning to form a complete framework for ECG analysis. The framework is\nhigh-level, universal, and not individually adapted to specific model\narchitectures or tasks. Experiments are conducted using various model\narchitectures and large-scale datasets, resulting in an accuracy of 94.39% on\nthe MITDB dataset for ECG arrhythmia classification task. The result shows a\nbetter performance for the classification of previously unseen data for the\nproposed approach compared to fully supervised methods.",
            "author": [
                "Guoxin Wang",
                "Qingyuan Wang",
                "Ganesh Neelakanta Iyer",
                "Avishek Nag",
                "Deepu John"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11153v1",
                "http://arxiv.org/pdf/2310.11153v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11143v1",
            "title": "A new high-resolution indoor radon map for Germany using a machine\n  learning based probabilistic exposure model",
            "updated": "2023-10-17T10:51:05Z",
            "published": "2023-10-17T10:51:05Z",
            "summary": "Radon is a carcinogenic, radioactive gas that can accumulate indoors. Indoor\nradon exposure at the national scale is usually estimated on the basis of\nextensive measurement campaigns. However, characteristics of the sample often\ndiffer from the characteristics of the population due to the large number of\nrelevant factors such as the availability of geogenic radon or floor level.\nFurthermore, the sample size usually does not allow exposure estimation with\nhigh spatial resolution. We propose a model-based approach that allows a more\nrealistic estimation of indoor radon distribution with a higher spatial\nresolution than a purely data-based approach. We applied a two-stage modelling\napproach: 1) a quantile regression forest using environmental and building data\nas predictors was applied to estimate the probability distribution function of\nindoor radon for each floor level of each residential building in Germany; (2)\na probabilistic Monte Carlo sampling technique enabled the combination and\npopulation weighting of floor-level predictions. In this way, the uncertainty\nof the individual predictions is effectively propagated into the estimate of\nvariability at the aggregated level. The results give an arithmetic mean of 63\nBq/m3, a geometric mean of 41 Bq/m3 and a 95 %ile of 180 Bq/m3. The exceedance\nprobability for 100 Bq/m3 and 300 Bq/m3 are 12.5 % (10.5 million people) and\n2.2 % (1.9 million people), respectively. In large cities, individual indoor\nradon exposure is generally lower than in rural areas, which is a due to the\ndifferent distribution of the population on floor levels. The advantages of our\napproach are 1) an accurate exposure estimation even if the survey was not\nfully representative with respect to the main controlling factors, and 2) an\nestimate of the exposure distribution with a much higher spatial resolution\nthan basic descriptive statistics.",
            "author": [
                "Eric Petermann",
                "Peter Bossew",
                "Joachim Kemski",
                "Valeria Gruber",
                "Nils Suhr",
                "Bernd Hoffmann"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11143v1",
                "http://arxiv.org/pdf/2310.11143v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "physics.data-an"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11142v1",
            "title": "BayesDiff: Estimating Pixel-wise Uncertainty in Diffusion via Bayesian\n  Inference",
            "updated": "2023-10-17T10:45:28Z",
            "published": "2023-10-17T10:45:28Z",
            "summary": "Diffusion models have impressive image generation capability, but low-quality\ngenerations still exist, and their identification remains challenging due to\nthe lack of a proper sample-wise metric. To address this, we propose BayesDiff,\na pixel-wise uncertainty estimator for generations from diffusion models based\non Bayesian inference. In particular, we derive a novel uncertainty iteration\nprinciple to characterize the uncertainty dynamics in diffusion, and leverage\nthe last-layer Laplace approximation for efficient Bayesian inference. The\nestimated pixel-wise uncertainty can not only be aggregated into a sample-wise\nmetric to filter out low-fidelity images but also aids in augmenting successful\ngenerations and rectifying artifacts in failed generations in text-to-image\ntasks. Extensive experiments demonstrate the efficacy of BayesDiff and its\npromise for practical applications.",
            "author": [
                "Siqi Kou",
                "Lei Gan",
                "Dequan Wang",
                "Chongxuan Li",
                "Zhijie Deng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11142v1",
                "http://arxiv.org/pdf/2310.11142v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11141v1",
            "title": "Long-form Simultaneous Speech Translation: Thesis Proposal",
            "updated": "2023-10-17T10:44:05Z",
            "published": "2023-10-17T10:44:05Z",
            "summary": "Simultaneous speech translation (SST) aims to provide real-time translation\nof spoken language, even before the speaker finishes their sentence.\nTraditionally, SST has been addressed primarily by cascaded systems that\ndecompose the task into subtasks, including speech recognition, segmentation,\nand machine translation. However, the advent of deep learning has sparked\nsignificant interest in end-to-end (E2E) systems. Nevertheless, a major\nlimitation of most approaches to E2E SST reported in the current literature is\nthat they assume that the source speech is pre-segmented into sentences, which\nis a significant obstacle for practical, real-world applications. This thesis\nproposal addresses end-to-end simultaneous speech translation, particularly in\nthe long-form setting, i.e., without pre-segmentation. We present a survey of\nthe latest advancements in E2E SST, assess the primary obstacles in SST and its\nrelevance to long-form scenarios, and suggest approaches to tackle these\nchallenges.",
            "author": [
                "Peter Pol\u00e1k"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11141v1",
                "http://arxiv.org/pdf/2310.11141v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11140v1",
            "title": "Moving from ISAD(G) to a CIDOC CRM-based Linked Data Model in the\n  Portuguese Archives",
            "updated": "2023-10-17T10:43:08Z",
            "published": "2023-10-17T10:43:08Z",
            "summary": "Archives are facing numerous challenges. On the one hand, archival assets are\nevolving to encompass digitized documents and increasing quantities of\nborn-digital information in diverse formats. On the other hand, the audience is\nchanging along with how it wishes to access archival material. Moreover, the\ninteroperability requirements of cultural heritage repositories are growing. In\nthis context, the Portuguese Archives started an ambitious program aiming to\nevolve its data model, migrate existing records, and build a new archival\nmanagement system appropriate to both archival tasks and public access. The\noverall goal is to have a fine-grained and flexible description, more\nmachine-actionable than the current one. This work describes ArchOnto, a linked\nopen data model for archives, and rules for its automatic population from\nexisting records. ArchOnto adopts a semantic web approach and encompasses the\nCIDOC Conceptual Reference Model and additional ontologies, envisioning\ninteroperability with datasets curated by multiple communities of practice.\nExisting ISAD(G)-conforming descriptions are being migrated to the new model\nusing the direct mappings provided here. We used a sample of 25 records\nassociated with different description levels to validate the completeness and\nconformity of ArchOnto to existing data. This work is in progress and is\noriginal in several respects: (1) it is one of the first approaches to use\nCIDOC CRM in the context of archives, identifying problems and questions that\nemerged during the process and pinpointing possible solutions; (2) it addresses\nthe balance in the model between the migration of existing records and the\nconstruction of new ones by archive professionals; and (3) it adopts an open\nworld view on linking archival data to global information sources.",
            "author": [
                "In\u00eas Koch",
                "Carla Teixeira Lopes",
                "Cristina Ribeiro"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3605910",
                "http://arxiv.org/abs/2310.11140v1",
                "http://arxiv.org/pdf/2310.11140v1"
            ],
            "primary_category": "cs.DL",
            "category": [
                "cs.DL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11138v1",
            "title": "Keep Various Trajectories: Promoting Exploration of Ensemble Policies in\n  Continuous Control",
            "updated": "2023-10-17T10:40:05Z",
            "published": "2023-10-17T10:40:05Z",
            "summary": "The combination of deep reinforcement learning (DRL) with ensemble methods\nhas been proved to be highly effective in addressing complex sequential\ndecision-making problems. This success can be primarily attributed to the\nutilization of multiple models, which enhances both the robustness of the\npolicy and the accuracy of value function estimation. However, there has been\nlimited analysis of the empirical success of current ensemble RL methods thus\nfar. Our new analysis reveals that the sample efficiency of previous ensemble\nDRL algorithms may be limited by sub-policies that are not as diverse as they\ncould be. Motivated by these findings, our study introduces a new ensemble RL\nalgorithm, termed \\textbf{T}rajectories-awar\\textbf{E} \\textbf{E}nsemble\nexploratio\\textbf{N} (TEEN). The primary goal of TEEN is to maximize the\nexpected return while promoting more diverse trajectories. Through extensive\nexperiments, we demonstrate that TEEN not only enhances the sample diversity of\nthe ensemble policy compared to using sub-policies alone but also improves the\nperformance over ensemble RL algorithms. On average, TEEN outperforms the\nbaseline ensemble DRL algorithms by 41\\% in performance on the tested\nrepresentative environments.",
            "author": [
                "Chao Li",
                "Chen Gong",
                "Qiang He",
                "Xinwen Hou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11138v1",
                "http://arxiv.org/pdf/2310.11138v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11132v2",
            "title": "Non-parametric Conditional Independence Testing for Mixed\n  Continuous-Categorical Variables: A Novel Method and Numerical Evaluation",
            "updated": "2023-11-05T10:11:28Z",
            "published": "2023-10-17T10:29:23Z",
            "summary": "Conditional independence testing (CIT) is a common task in machine learning,\ne.g., for variable selection, and a main component of constraint-based causal\ndiscovery. While most current CIT approaches assume that all variables are\nnumerical or all variables are categorical, many real-world applications\ninvolve mixed-type datasets that include numerical and categorical variables.\nNon-parametric CIT can be conducted using conditional mutual information (CMI)\nestimators combined with a local permutation scheme. Recently, two novel CMI\nestimators for mixed-type datasets based on k-nearest-neighbors (k-NN) have\nbeen proposed. As with any k-NN method, these estimators rely on the definition\nof a distance metric. One approach computes distances by a one-hot encoding of\nthe categorical variables, essentially treating categorical variables as\ndiscrete-numerical, while the other expresses CMI by entropy terms where the\ncategorical variables appear as conditions only. In this work, we study these\nestimators and propose a variation of the former approach that does not treat\ncategorical variables as numeric. Our numerical experiments show that our\nvariant detects dependencies more robustly across different data distributions\nand preprocessing types.",
            "author": [
                "Oana-Iuliana Popescu",
                "Andreas Gerhardus",
                "Jakob Runge"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11132v2",
                "http://arxiv.org/pdf/2310.11132v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11131v1",
            "title": "FROST: Towards Energy-efficient AI-on-5G Platforms -- A GPU Power\n  Capping Evaluation",
            "updated": "2023-10-17T10:28:28Z",
            "published": "2023-10-17T10:28:28Z",
            "summary": "The Open Radio Access Network (O-RAN) is a burgeoning market with projected\ngrowth in the upcoming years. RAN has the highest CAPEX impact on the network\nand, most importantly, consumes 73% of its total energy. That makes it an ideal\ntarget for optimisation through the integration of Machine Learning (ML).\nHowever, the energy consumption of ML is frequently overlooked in such\necosystems. Our work addresses this critical aspect by presenting FROST -\nFlexible Reconfiguration method with Online System Tuning - a solution for\nenergy-aware ML pipelines that adhere to O-RAN's specifications and principles.\nFROST is capable of profiling the energy consumption of an ML pipeline and\noptimising the hardware accordingly, thereby limiting the power draw. Our\nfindings indicate that FROST can achieve energy savings of up to 26.4% without\ncompromising the model's accuracy or introducing significant time delays.",
            "author": [
                "Ioannis Mavromatis",
                "Stefano De Feo",
                "Pietro Carnelli",
                "Robert J. Piechocki",
                "Aftab Khan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11131v1",
                "http://arxiv.org/pdf/2310.11131v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11130v1",
            "title": "Topological Expressivity of ReLU Neural Networks",
            "updated": "2023-10-17T10:28:00Z",
            "published": "2023-10-17T10:28:00Z",
            "summary": "We study the expressivity of ReLU neural networks in the setting of a binary\nclassification problem from a topological perspective. Recently, empirical\nstudies showed that neural networks operate by changing topology, transforming\na topologically complicated data set into a topologically simpler one as it\npasses through the layers. This topological simplification has been measured by\nBetti numbers, which are algebraic invariants of a topological space. We use\nthe same measure to establish lower and upper bounds on the topological\nsimplification a ReLU neural network can achieve with a given architecture. We\ntherefore contribute to a better understanding of the expressivity of ReLU\nneural networks in the context of binary classification problems by shedding\nlight on their ability to capture the underlying topological structure of the\ndata. In particular the results show that deep ReLU neural networks are\nexponentially more powerful than shallow ones in terms of topological\nsimplification. This provides a mathematically rigorous explanation why deeper\nnetworks are better equipped to handle complex and topologically rich datasets.",
            "author": [
                "Ekin Ergen",
                "Moritz Grillo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11130v1",
                "http://arxiv.org/pdf/2310.11130v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11479v3",
            "title": "On the Temperature of Bayesian Graph Neural Networks for Conformal\n  Prediction",
            "updated": "2023-12-03T06:31:09Z",
            "published": "2023-10-17T10:24:25Z",
            "summary": "Accurate uncertainty quantification in graph neural networks (GNNs) is\nessential, especially in high-stakes domains where GNNs are frequently\nemployed. Conformal prediction (CP) offers a promising framework for\nquantifying uncertainty by providing $\\textit{valid}$ prediction sets for any\nblack-box model. CP ensures formal probabilistic guarantees that a prediction\nset contains a true label with a desired probability. However, the size of\nprediction sets, known as $\\textit{inefficiency}$, is influenced by the\nunderlying model and data generating process. On the other hand, Bayesian\nlearning also provides a credible region based on the estimated posterior\ndistribution, but this region is $\\textit{well-calibrated}$ only when the model\nis correctly specified. Building on a recent work that introduced a scaling\nparameter for constructing valid credible regions from posterior estimate, our\nstudy explores the advantages of incorporating a temperature parameter into\nBayesian GNNs within CP framework. We empirically demonstrate the existence of\ntemperatures that result in more efficient prediction sets. Furthermore, we\nconduct an analysis to identify the factors contributing to inefficiency and\noffer valuable insights into the relationship between CP performance and model\ncalibration.",
            "author": [
                "Seohyeon Cha",
                "Honggu Kang",
                "Joonhyuk Kang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11479v3",
                "http://arxiv.org/pdf/2310.11479v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11122v3",
            "title": "Sensitivity-Aware Amortized Bayesian Inference",
            "updated": "2023-11-23T14:45:13Z",
            "published": "2023-10-17T10:14:10Z",
            "summary": "Bayesian inference is a powerful framework for making probabilistic\ninferences and decisions under uncertainty. Fundamental choices in modern\nBayesian workflows concern the specification of the likelihood function and\nprior distributions, the posterior approximator, and the data. Each choice can\nsignificantly influence model-based inference and subsequent decisions, thereby\nnecessitating sensitivity analysis. In this work, we propose a multifaceted\napproach to integrate sensitivity analyses into amortized Bayesian inference\n(ABI, i.e., simulation-based inference with neural networks). First, we utilize\nweight sharing to encode the structural similarities between alternative\nlikelihood and prior specifications in the training process with minimal\ncomputational overhead. Second, we leverage the rapid inference of neural\nnetworks to assess sensitivity to various data perturbations or pre-processing\nprocedures. In contrast to most other Bayesian approaches, both steps\ncircumvent the costly bottleneck of refitting the model(s) for each choice of\nlikelihood, prior, or dataset. Finally, we propose to use neural network\nensembles to evaluate variation in results induced by unreliable approximation\non unseen data. We demonstrate the effectiveness of our method in applied\nmodeling problems, ranging from the estimation of disease outbreak dynamics and\nglobal warming thresholds to the comparison of human decision-making models.\nOur experiments showcase how our approach enables practitioners to effectively\nunveil hidden relationships between modeling choices and inferential\nconclusions.",
            "author": [
                "Lasse Elsem\u00fcller",
                "Hans Olischl\u00e4ger",
                "Marvin Schmitt",
                "Paul-Christian B\u00fcrkner",
                "Ullrich K\u00f6the",
                "Stefan T. Radev"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11122v3",
                "http://arxiv.org/pdf/2310.11122v3"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11112v1",
            "title": "Super resolution of histopathological frozen sections via deep learning\n  preserving tissue structure",
            "updated": "2023-10-17T09:52:54Z",
            "published": "2023-10-17T09:52:54Z",
            "summary": "Histopathology plays a pivotal role in medical diagnostics. In contrast to\npreparing permanent sections for histopathology, a time-consuming process,\npreparing frozen sections is significantly faster and can be performed during\nsurgery, where the sample scanning time should be optimized. Super-resolution\ntechniques allow imaging the sample in lower magnification and sparing scanning\ntime. In this paper, we present a new approach to super resolution for\nhistopathological frozen sections, with focus on achieving better distortion\nmeasures, rather than pursuing photorealistic images that may compromise\ncritical diagnostic information. Our deep-learning architecture focuses on\nlearning the error between interpolated images and real images, thereby it\ngenerates high-resolution images while preserving critical image details,\nreducing the risk of diagnostic misinterpretation. This is done by leveraging\nthe loss functions in the frequency domain, assigning higher weights to the\nreconstruction of complex, high-frequency components. In comparison to existing\nmethods, we obtained significant improvements in terms of Structural Similarity\nIndex (SSIM) and Peak Signal-to-Noise Ratio (PSNR), as well as indicated\ndetails that lost in the low-resolution frozen-section images, affecting the\npathologist's clinical decisions. Our approach has a great potential in\nproviding more-rapid frozen-section imaging, with less scanning, while\npreserving the high resolution in the imaged sample.",
            "author": [
                "Elad Yoshai",
                "Gil Goldinger",
                "Miki Haifler",
                "Natan T. Shaked"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11112v1",
                "http://arxiv.org/pdf/2310.11112v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11110v1",
            "title": "Minimally Informed Linear Discriminant Analysis: training an LDA model\n  with unlabelled data",
            "updated": "2023-10-17T09:50:31Z",
            "published": "2023-10-17T09:50:31Z",
            "summary": "Linear Discriminant Analysis (LDA) is one of the oldest and most popular\nlinear methods for supervised classification problems. In this paper, we\ndemonstrate that it is possible to compute the exact projection vector from LDA\nmodels based on unlabelled data, if some minimal prior information is\navailable. More precisely, we show that only one of the following three pieces\nof information is actually sufficient to compute the LDA projection vector if\nonly unlabelled data are available: (1) the class average of one of the two\nclasses, (2) the difference between both class averages (up to a scaling), or\n(3) the class covariance matrices (up to a scaling). These theoretical results\nare validated in numerical experiments, demonstrating that this minimally\ninformed Linear Discriminant Analysis (MILDA) model closely matches the\nperformance of a supervised LDA model. Furthermore, we show that the MILDA\nprojection vector can be computed in a closed form with a computational cost\ncomparable to LDA and is able to quickly adapt to non-stationary data, making\nit well-suited to use as an adaptive classifier.",
            "author": [
                "Nicolas Heintz",
                "Tom Francart",
                "Alexander Bertrand"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11110v1",
                "http://arxiv.org/pdf/2310.11110v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11106v1",
            "title": "3D Structure-guided Network for Tooth Alignment in 2D Photograph",
            "updated": "2023-10-17T09:44:30Z",
            "published": "2023-10-17T09:44:30Z",
            "summary": "Orthodontics focuses on rectifying misaligned teeth (i.e., malocclusions),\naffecting both masticatory function and aesthetics. However, orthodontic\ntreatment often involves complex, lengthy procedures. As such, generating a 2D\nphotograph depicting aligned teeth prior to orthodontic treatment is crucial\nfor effective dentist-patient communication and, more importantly, for\nencouraging patients to accept orthodontic intervention. In this paper, we\npropose a 3D structure-guided tooth alignment network that takes 2D photographs\nas input (e.g., photos captured by smartphones) and aligns the teeth within the\n2D image space to generate an orthodontic comparison photograph featuring\naesthetically pleasing, aligned teeth. Notably, while the process operates\nwithin a 2D image space, our method employs 3D intra-oral scanning models\ncollected in clinics to learn about orthodontic treatment, i.e., projecting the\npre- and post-orthodontic 3D tooth structures onto 2D tooth contours, followed\nby a diffusion model to learn the mapping relationship. Ultimately, the aligned\ntooth contours are leveraged to guide the generation of a 2D photograph with\naesthetically pleasing, aligned teeth and realistic textures. We evaluate our\nnetwork on various facial photographs, demonstrating its exceptional\nperformance and strong applicability within the orthodontic industry.",
            "author": [
                "Yulong Dou",
                "Lanzhuju Mei",
                "Dinggang Shen",
                "Zhiming Cui"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11106v1",
                "http://arxiv.org/pdf/2310.11106v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11105v1",
            "title": "Generalizability of CNN Architectures for Face Morph Presentation Attack",
            "updated": "2023-10-17T09:39:53Z",
            "published": "2023-10-17T09:39:53Z",
            "summary": "Automatic border control systems are wide spread in modern airports\nworldwide. Morphing attacks on face biometrics is a serious threat that\nundermines the security and reliability of face recognition systems deployed in\nairports and border controls. Therefore, developing a robust Machine Learning\n(ML) system is necessary to prevent criminals crossing borders with fake\nidentifications especially since it has been shown that security officers\ncannot detect morphs better than machines. In this study, we investigate the\ngeneralization power of Convolutional Neural Network (CNN) architectures\nagainst morphing attacks. The investigation utilizes 5 distinct CNNs namely\nShuffleNet, DenseNet201, VGG16, EffecientNet-B0 and InceptionResNet-v2. Each\nCNN architecture represents a well-known family of CNN models in terms of\nnumber of parameters, architectural design and performance across various\ncomputer vision applications. To ensure robust evaluation, we employ 4\ndifferent datasets (Utrecht, London, Defacto and KurdFace) that contain a\ndiverse range of digital face images which cover variations in ethnicity,\ngender, age, lighting condition and camera setting. One of the fundamental\nconcepts of ML system design is the ability to generalize effectively to\npreviously unseen data, hence not only we evaluate the performance of CNN\nmodels within individual datasets but also explore their performance across\ncombined datasets and investigating each dataset in testing phase only.\nExperimental results on more than 8 thousand images (genuine and morph) from\nthe 4 datasets show that InceptionResNet-v2 generalizes better to unseen data\nand outperforms the other 4 CNN models.",
            "author": [
                "Sherko R. HmaSalah",
                "Aras Asaad"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11105v1",
                "http://arxiv.org/pdf/2310.11105v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11104v1",
            "title": "Local Lipschitz Constant Computation of ReLU-FNNs: Upper Bound\n  Computation with Exactness Verification",
            "updated": "2023-10-17T09:37:16Z",
            "published": "2023-10-17T09:37:16Z",
            "summary": "This paper is concerned with the computation of the local Lipschitz constant\nof feedforward neural networks (FNNs) with activation functions being rectified\nlinear units (ReLUs). The local Lipschitz constant of an FNN for a target input\nis a reasonable measure for its quantitative evaluation of the reliability. By\nfollowing a standard procedure using multipliers that capture the behavior of\nReLUs,we first reduce the upper bound computation problem of the local\nLipschitz constant into a semidefinite programming problem (SDP). Here we newly\nintroduce copositive multipliers to capture the ReLU behavior accurately. Then,\nby considering the dual of the SDP for the upper bound computation, we second\nderive a viable test to conclude the exactness of the computed upper bound.\nHowever, these SDPs are intractable for practical FNNs with hundreds of ReLUs.\nTo address this issue, we further propose a method to construct a reduced order\nmodel whose input-output property is identical to the original FNN over a\nneighborhood of the target input. We finally illustrate the effectiveness of\nthe model reduction and exactness verification methods with numerical examples\nof practical FNNs.",
            "author": [
                "Yoshio Ebihara",
                "Xin Dai",
                "Victor Magron",
                "Dimitri Peaucelle",
                "Sophie Tarbouriech"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11104v1",
                "http://arxiv.org/pdf/2310.11104v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11478v1",
            "title": "ASP: Automatic Selection of Proxy dataset for efficient AutoML",
            "updated": "2023-10-17T09:36:22Z",
            "published": "2023-10-17T09:36:22Z",
            "summary": "Deep neural networks have gained great success due to the increasing amounts\nof data, and diverse effective neural network designs. However, it also brings\na heavy computing burden as the amount of training data is proportional to the\ntraining time. In addition, a well-behaved model requires repeated trials of\ndifferent structure designs and hyper-parameters, which may take a large amount\nof time even with state-of-the-art (SOTA) hyper-parameter optimization (HPO)\nalgorithms and neural architecture search (NAS) algorithms. In this paper, we\npropose an Automatic Selection of Proxy dataset framework (ASP) aimed to\ndynamically find the informative proxy subsets of training data at each epoch,\nreducing the training data size as well as saving the AutoML processing time.\nWe verify the effectiveness and generalization of ASP on CIFAR10, CIFAR100,\nImageNet16-120, and ImageNet-1k, across various public model benchmarks. The\nexperiment results show that ASP can obtain better results than other data\nselection methods at all selection ratios. ASP can also enable much more\nefficient AutoML processing with a speedup of 2x-20x while obtaining better\narchitectures and better hyper-parameters compared to utilizing the entire\ndataset.",
            "author": [
                "Peng Yao",
                "Chao Liao",
                "Jiyuan Jia",
                "Jianchao Tan",
                "Bin Chen",
                "Chengru Song",
                "Di Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11478v1",
                "http://arxiv.org/pdf/2310.11478v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11102v3",
            "title": "HGCVAE: Integrating Generative and Contrastive Learning for\n  Heterogeneous Graph Learning",
            "updated": "2023-10-19T12:21:01Z",
            "published": "2023-10-17T09:34:34Z",
            "summary": "Generative self-supervised learning (SSL) has exhibited significant potential\nand garnered increasing interest in graph learning. In this study, we aim to\nexplore the problem of generative SSL in the context of heterogeneous graph\nlearning (HGL). The previous SSL approaches for heterogeneous graphs have\nprimarily relied on contrastive learning, necessitating the design of complex\nviews to capture heterogeneity. However, existing generative SSL methods have\nnot fully leveraged the capabilities of generative models to address the\nchallenges of HGL. In this paper, we present HGCVAE, a novel contrastive\nvariational graph auto-encoder that liberates HGL from the burden of intricate\nheterogeneity capturing. Instead of focusing on complicated heterogeneity,\nHGCVAE harnesses the full potential of generative SSL. HGCVAE innovatively\nconsolidates contrastive learning with generative SSL, introducing several key\ninnovations. Firstly, we employ a progressive mechanism to generate\nhigh-quality hard negative samples for contrastive learning, utilizing the\npower of variational inference. Additionally, we present a dynamic mask\nstrategy to ensure effective and stable learning. Moreover, we propose an\nenhanced scaled cosine error as the criterion for better attribute\nreconstruction. As an initial step in combining generative and contrastive SSL,\nHGCVAE achieves remarkable results compared to various state-of-the-art\nbaselines, confirming its superiority.",
            "author": [
                "Yulan Hu",
                "Zhirui Yang",
                "Sheng Ouyang",
                "Junchen Wan",
                "Fuzheng Zhang",
                "Zhongyuan Wang",
                "Yong Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11102v3",
                "http://arxiv.org/pdf/2310.11102v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11096v1",
            "title": "Sparse-DySta: Sparsity-Aware Dynamic and Static Scheduling for Sparse\n  Multi-DNN Workloads",
            "updated": "2023-10-17T09:25:17Z",
            "published": "2023-10-17T09:25:17Z",
            "summary": "Running multiple deep neural networks (DNNs) in parallel has become an\nemerging workload in both edge devices, such as mobile phones where multiple\ntasks serve a single user for daily activities, and data centers, where various\nrequests are raised from millions of users, as seen with large language models.\nTo reduce the costly computational and memory requirements of these workloads,\nvarious efficient sparsification approaches have been introduced, resulting in\nwidespread sparsity across different types of DNN models. In this context,\nthere is an emerging need for scheduling sparse multi-DNN workloads, a problem\nthat is largely unexplored in previous literature. This paper systematically\nanalyses the use-cases of multiple sparse DNNs and investigates the\nopportunities for optimizations. Based on these findings, we propose Dysta, a\nnovel bi-level dynamic and static scheduler that utilizes both static sparsity\npatterns and dynamic sparsity information for the sparse multi-DNN scheduling.\nBoth static and dynamic components of Dysta are jointly designed at the\nsoftware and hardware levels, respectively, to improve and refine the\nscheduling approach. To facilitate future progress in the study of this class\nof workloads, we construct a public benchmark that contains sparse multi-DNN\nworkloads across different deployment scenarios, spanning from mobile phones\nand AR/VR wearables to data centers. A comprehensive evaluation on the sparse\nmulti-DNN benchmark demonstrates that our proposed approach outperforms the\nstate-of-the-art methods with up to 10% decrease in latency constraint\nviolation rate and nearly 4X reduction in average normalized turnaround time.\nOur artifacts and code are publicly available at:\nhttps://github.com/SamsungLabs/Sparse-Multi-DNN-Scheduling.",
            "author": [
                "Hongxiang Fan",
                "Stylianos I. Venieris",
                "Alexandros Kouris",
                "Nicholas D. Lane"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3613424.3614263",
                "http://arxiv.org/abs/2310.11096v1",
                "http://arxiv.org/pdf/2310.11096v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.AR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11094v1",
            "title": "Relearning Forgotten Knowledge: on Forgetting, Overfit and Training-Free\n  Ensembles of DNNs",
            "updated": "2023-10-17T09:22:22Z",
            "published": "2023-10-17T09:22:22Z",
            "summary": "The infrequent occurrence of overfit in deep neural networks is perplexing.\nOn the one hand, theory predicts that as models get larger they should\neventually become too specialized for a specific training set, with ensuing\ndecrease in generalization. In contrast, empirical results in image\nclassification indicate that increasing the training time of deep models or\nusing bigger models almost never hurts generalization. Is it because the way we\nmeasure overfit is too limited? Here, we introduce a novel score for\nquantifying overfit, which monitors the forgetting rate of deep models on\nvalidation data. Presumably, this score indicates that even while\ngeneralization improves overall, there are certain regions of the data space\nwhere it deteriorates. When thus measured, we show that overfit can occur with\nand without a decrease in validation accuracy, and may be more common than\npreviously appreciated. This observation may help to clarify the aforementioned\nconfusing picture. We use our observations to construct a new ensemble method,\nbased solely on the training history of a single network, which provides\nsignificant improvement in performance without any additional cost in training\ntime. An extensive empirical evaluation with modern deep models shows our\nmethod's utility on multiple datasets, neural networks architectures and\ntraining schemes, both when training from scratch and when using pre-trained\nnetworks in transfer learning. Notably, our method outperforms comparable\nmethods while being easier to implement and use, and further improves the\nperformance of competitive networks on Imagenet by 1\\%.",
            "author": [
                "Uri Stern",
                "Daphna Weinshall"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11094v1",
                "http://arxiv.org/pdf/2310.11094v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11093v1",
            "title": "SODA: Robust Training of Test-Time Data Adaptors",
            "updated": "2023-10-17T09:22:20Z",
            "published": "2023-10-17T09:22:20Z",
            "summary": "Adapting models deployed to test distributions can mitigate the performance\ndegradation caused by distribution shifts. However, privacy concerns may render\nmodel parameters inaccessible. One promising approach involves utilizing\nzeroth-order optimization (ZOO) to train a data adaptor to adapt the test data\nto fit the deployed models. Nevertheless, the data adaptor trained with ZOO\ntypically brings restricted improvements due to the potential corruption of\ndata features caused by the data adaptor. To address this issue, we revisit ZOO\nin the context of test-time data adaptation. We find that the issue directly\nstems from the unreliable estimation of the gradients used to optimize the data\nadaptor, which is inherently due to the unreliable nature of the pseudo-labels\nassigned to the test data. Based on this observation, we propose\npseudo-label-robust data adaptation (SODA) to improve the performance of data\nadaptation. Specifically, SODA leverages high-confidence predicted labels as\nreliable labels to optimize the data adaptor with ZOO for label prediction. For\ndata with low-confidence predictions, SODA encourages the adaptor to preserve\ndata information to mitigate data corruption. Empirical results indicate that\nSODA can significantly enhance the performance of deployed models in the\npresence of distribution shifts without requiring access to model parameters.",
            "author": [
                "Zige Wang",
                "Yonggang Zhang",
                "Zhen Fang",
                "Long Lan",
                "Wenjing Yang",
                "Bo Han"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11093v1",
                "http://arxiv.org/pdf/2310.11093v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11092v2",
            "title": "DORec: Decomposed Object Reconstruction Utilizing 2D Self-Supervised\n  Features",
            "updated": "2023-10-19T14:16:49Z",
            "published": "2023-10-17T09:21:29Z",
            "summary": "Decomposing a target object from a complex background while reconstructing is\nchallenging. Most approaches acquire the perception for object instances\nthrough the use of manual labels, but the annotation procedure is costly. The\nrecent advancements in 2D self-supervised learning have brought new prospects\nto object-aware representation, yet it remains unclear how to leverage such\nnoisy 2D features for clean decomposition. In this paper, we propose a\nDecomposed Object Reconstruction (DORec) network based on neural implicit\nrepresentations. Our key idea is to transfer 2D self-supervised features into\nmasks of two levels of granularity to supervise the decomposition, including a\nbinary mask to indicate the foreground regions and a K-cluster mask to indicate\nthe semantically similar regions. These two masks are complementary to each\nother and lead to robust decomposition. Experimental results show the\nsuperiority of DORec in segmenting and reconstructing the foreground object on\nvarious datasets.",
            "author": [
                "Jun Wu",
                "Sicheng Li",
                "Sihui Ji",
                "Yue Wang",
                "Rong Xiong",
                "Yiyi Liao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11092v2",
                "http://arxiv.org/pdf/2310.11092v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11088v1",
            "title": "MeKB-Rec: Personal Knowledge Graph Learning for Cross-Domain\n  Recommendation",
            "updated": "2023-10-17T09:13:24Z",
            "published": "2023-10-17T09:13:24Z",
            "summary": "It is a long-standing challenge in modern recommender systems to effectively\nmake recommendations for new users, namely the cold-start problem. Cross-Domain\nRecommendation (CDR) has been proposed to address this challenge, but current\nways to represent users' interests across systems are still severely limited.\nWe introduce Personal Knowledge Graph (PKG) as a domain-invariant interest\nrepresentation, and propose a novel CDR paradigm named MeKB-Rec. We first link\nusers and entities in a knowledge base to construct a PKG of users' interests,\nnamed MeKB. Then we learn a semantic representation of MeKB for the\ncross-domain recommendation. To efficiently utilize limited training data in\nCDR, MeKB-Rec employs Pretrained Language Models to inject world knowledge into\nunderstanding users' interests. Beyond most existing systems, our approach\nbuilds a semantic mapping across domains which breaks the requirement for\nin-domain user behaviors, enabling zero-shot recommendations for new users in a\nlow-resource domain. We experiment MeKB-Rec on well-established public CDR\ndatasets, and demonstrate that the new formulation % is more powerful than\nprevious approaches, achieves a new state-of-the-art that significantly\nimproves HR@10 and NDCG@10 metrics over best previous approaches by 24\\%--91\\%,\nwith a 105\\% improvement for HR@10 of zero-shot users with no behavior in the\ntarget domain. We deploy MeKB-Rec in WeiXin recommendation scenarios and\nachieve significant gains in core online metrics. MeKB-Rec is now serving\nhundreds of millions of users in real-world products.",
            "author": [
                "Xin Su",
                "Yao Zhou",
                "Zifei Shan",
                "Qian Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11088v1",
                "http://arxiv.org/pdf/2310.11088v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11087v1",
            "title": "Feature Pyramid biLSTM: Using Smartphone Sensors for Transportation Mode\n  Detection",
            "updated": "2023-10-17T09:13:10Z",
            "published": "2023-10-17T09:13:10Z",
            "summary": "The widespread utilization of smartphones has provided extensive availability\nto Inertial Measurement Units, providing a wide range of sensory data that can\nbe advantageous for the detection of transportation modes. The objective of\nthis study is to propose a novel end-to-end approach to effectively explore a\nreduced amount of sensory data collected from a smartphone to achieve accurate\nmode detection in common daily traveling activities. Our approach, called\nFeature Pyramid biLSTM (FPbiLSTM), is characterized by its ability to reduce\nthe number of sensors required and processing demands, resulting in a more\nefficient modeling process without sacrificing the quality of the outcomes than\nthe other current models. FPbiLSTM extends an existing CNN biLSTM model with\nthe Feature Pyramid Network, leveraging the advantages of both shallow layer\nrichness and deeper layer feature resilience for capturing temporal moving\npatterns in various transportation modes. It exhibits an excellent performance\nby employing the data collected from only three out of seven sensors, i.e.\naccelerometers, gyroscopes, and magnetometers, in the 2018 Sussex-Huawei\nLocomotion (SHL) challenge dataset, attaining a noteworthy accuracy of 95.1%\nand an F1-score of 94.7% in detecting eight different transportation modes.",
            "author": [
                "Qinrui Tang",
                "Hao Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11087v1",
                "http://arxiv.org/pdf/2310.11087v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14893v1",
            "title": "Data Drift Monitoring for Log Anomaly Detection Pipelines",
            "updated": "2023-10-17T09:10:40Z",
            "published": "2023-10-17T09:10:40Z",
            "summary": "Logs enable the monitoring of infrastructure status and the performance of\nassociated applications. Logs are also invaluable for diagnosing the root\ncauses of any problems that may arise. Log Anomaly Detection (LAD) pipelines\nautomate the detection of anomalies in logs, providing assistance to site\nreliability engineers (SREs) in system diagnosis. Log patterns change over\ntime, necessitating updates to the LAD model defining the `normal' log activity\nprofile. In this paper, we introduce a Bayes Factor-based drift detection\nmethod that identifies when intervention, retraining, and updating of the LAD\nmodel are required with human involvement. We illustrate our method using\nsequences of log activity, both from unaltered data, and simulated activity\nwith controlled levels of anomaly contamination, based on real collected log\ndata.",
            "author": [
                "Dipak Wani",
                "Samuel Ackerman",
                "Eitan Farchi",
                "Xiaotong Liu",
                "Hau-wen Chang",
                "Sarasi Lalithsena"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14893v1",
                "http://arxiv.org/pdf/2310.14893v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SY",
                "eess.SY",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11085v1",
            "title": "In-Context Few-Shot Relation Extraction via Pre-Trained Language Models",
            "updated": "2023-10-17T09:10:27Z",
            "published": "2023-10-17T09:10:27Z",
            "summary": "Relation extraction aims at inferring structured human knowledge from textual\ndocuments. State-of-the-art methods based on language models commonly have two\nlimitations: (1) they require named entities to be either given as input or\ninfer them, which introduces additional noise, and (2) they require human\nannotations of documents. As a remedy, we present a novel framework for\nin-context few-shot relation extraction via pre-trained language models. To the\nbest of our knowledge, we are the first to reformulate the relation extraction\ntask as a tailored in-context few-shot learning paradigm. Thereby, we achieve\ncrucial benefits in that we eliminate the need for both named entity\nrecognition and human annotation of documents. Unlike existing methods based on\nfine-tuning, our framework is flexible in that it can be easily updated for a\nnew set of relations without re-training. We evaluate our framework using\nDocRED, the largest publicly available dataset for document-level relation\nextraction, and demonstrate that our framework achieves state-of-the-art\nperformance. Finally, our framework allows us to identify missing annotations,\nand we thus show that our framework actually performs much better than the\noriginal labels from the development set of DocRED.",
            "author": [
                "Yilmazcan Ozyurt",
                "Stefan Feuerriegel",
                "Ce Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11085v1",
                "http://arxiv.org/pdf/2310.11085v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11083v1",
            "title": "CSG: Curriculum Representation Learning for Signed Graph",
            "updated": "2023-10-17T09:08:33Z",
            "published": "2023-10-17T09:08:33Z",
            "summary": "Signed graphs are valuable for modeling complex relationships with positive\nand negative connections, and Signed Graph Neural Networks (SGNNs) have become\ncrucial tools for their analysis. However, prior to our work, no specific\ntraining plan existed for SGNNs, and the conventional random sampling approach\ndid not address varying learning difficulties within the graph's structure. We\nproposed a curriculum-based training approach, where samples progress from easy\nto complex, inspired by human learning. To measure learning difficulty, we\nintroduced a lightweight mechanism and created the Curriculum representation\nlearning framework for Signed Graphs (CSG). This framework optimizes the order\nin which samples are presented to the SGNN model. Empirical validation across\nsix real-world datasets showed impressive results, enhancing SGNN model\naccuracy by up to 23.7% in link sign prediction (AUC) and significantly\nimproving stability with an up to 8.4 reduction in the standard deviation of\nAUC scores.",
            "author": [
                "Zeyu Zhang",
                "Jiamou Liu",
                "Kaiqi Zhao",
                "Yifei Wang",
                "Pengqian Han",
                "Xianda Zheng",
                "Qiqi Wang",
                "Zijian Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11083v1",
                "http://arxiv.org/pdf/2310.11083v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11082v1",
            "title": "Multi-omics Sampling-based Graph Transformer for Synthetic Lethality\n  Prediction",
            "updated": "2023-10-17T09:06:41Z",
            "published": "2023-10-17T09:06:41Z",
            "summary": "Synthetic lethality (SL) prediction is used to identify if the co-mutation of\ntwo genes results in cell death. The prevalent strategy is to abstract SL\nprediction as an edge classification task on gene nodes within SL data and\nachieve it through graph neural networks (GNNs). However, GNNs suffer from\nlimitations in their message passing mechanisms, including over-smoothing and\nover-squashing issues. Moreover, harnessing the information of non-SL gene\nrelationships within large-scale multi-omics data to facilitate SL prediction\nposes a non-trivial challenge. To tackle these issues, we propose a new\nmulti-omics sampling-based graph transformer for SL prediction (MSGT-SL).\nConcretely, we introduce a shallow multi-view GNN to acquire local structural\npatterns from both SL and multi-omics data. Further, we input gene features\nthat encode multi-view information into the standard self-attention to capture\nlong-range dependencies. Notably, starting with batch genes from SL data, we\nadopt parallel random walk sampling across multiple omics gene graphs\nencompassing them. Such sampling effectively and modestly incorporates genes\nfrom omics in a structure-aware manner before using self-attention. We showcase\nthe effectiveness of MSGT-SL on real-world SL tasks, demonstrating the\nempirical benefits gained from the graph transformer and multi-omics data.",
            "author": [
                "Xusheng Zhao",
                "Hao Liu",
                "Qiong Dai",
                "Hao Peng",
                "Xu Bai",
                "Huailiang Peng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11082v1",
                "http://arxiv.org/pdf/2310.11082v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11081v1",
            "title": "Understanding writing style in social media with a supervised\n  contrastively pre-trained transformer",
            "updated": "2023-10-17T09:01:17Z",
            "published": "2023-10-17T09:01:17Z",
            "summary": "Online Social Networks serve as fertile ground for harmful behavior, ranging\nfrom hate speech to the dissemination of disinformation. Malicious actors now\nhave unprecedented freedom to misbehave, leading to severe societal unrest and\ndire consequences, as exemplified by events such as the Capitol assault during\nthe US presidential election and the Antivaxx movement during the COVID-19\npandemic. Understanding online language has become more pressing than ever.\nWhile existing works predominantly focus on content analysis, we aim to shift\nthe focus towards understanding harmful behaviors by relating content to their\nrespective authors. Numerous novel approaches attempt to learn the stylistic\nfeatures of authors in texts, but many of these approaches are constrained by\nsmall datasets or sub-optimal training losses. To overcome these limitations,\nwe introduce the Style Transformer for Authorship Representations (STAR),\ntrained on a large corpus derived from public sources of 4.5 x 10^6 authored\ntexts involving 70k heterogeneous authors. Our model leverages Supervised\nContrastive Loss to teach the model to minimize the distance between texts\nauthored by the same individual. This author pretext pre-training task yields\ncompetitive performance at zero-shot with PAN challenges on attribution and\nclustering. Additionally, we attain promising results on PAN verification\nchallenges using a single dense layer, with our model serving as an embedding\nencoder. Finally, we present results from our test partition on Reddit. Using a\nsupport base of 8 documents of 512 tokens, we can discern authors from sets of\nup to 1616 authors with at least 80\\% accuracy. We share our pre-trained model\nat huggingface (https://huggingface.co/AIDA-UPM/star) and our code is available\nat (https://github.com/jahuerta92/star)",
            "author": [
                "Javier Huertas-Tato",
                "Alejandro Martin",
                "David Camacho"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11081v1",
                "http://arxiv.org/pdf/2310.11081v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11079v1",
            "title": "Learning from Red Teaming: Gender Bias Provocation and Mitigation in\n  Large Language Models",
            "updated": "2023-10-17T08:56:04Z",
            "published": "2023-10-17T08:56:04Z",
            "summary": "Recently, researchers have made considerable improvements in dialogue systems\nwith the progress of large language models (LLMs) such as ChatGPT and GPT-4.\nThese LLM-based chatbots encode the potential biases while retaining\ndisparities that can harm humans during interactions. The traditional biases\ninvestigation methods often rely on human-written test cases. However, these\ntest cases are usually expensive and limited. In this work, we propose a\nfirst-of-its-kind method that automatically generates test cases to detect\nLLMs' potential gender bias. We apply our method to three well-known LLMs and\nfind that the generated test cases effectively identify the presence of biases.\nTo address the biases identified, we propose a mitigation strategy that uses\nthe generated test cases as demonstrations for in-context learning to\ncircumvent the need for parameter fine-tuning. The experimental results show\nthat LLMs generate fairer responses with the proposed approach.",
            "author": [
                "Hsuan Su",
                "Cheng-Chu Cheng",
                "Hua Farn",
                "Shachi H Kumar",
                "Saurav Sahay",
                "Shang-Tse Chen",
                "Hung-yi Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11079v1",
                "http://arxiv.org/pdf/2310.11079v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11077v1",
            "title": "United We Stand: Using Epoch-wise Agreement of Ensembles to Combat\n  Overfit",
            "updated": "2023-10-17T08:51:44Z",
            "published": "2023-10-17T08:51:44Z",
            "summary": "Deep neural networks have become the method of choice for solving many image\nclassification tasks, largely because they can fit very complex functions\ndefined over raw images. The downside of such powerful learners is the danger\nof overfitting the training set, leading to poor generalization, which is\nusually avoided by regularization and \"early stopping\" of the training. In this\npaper, we propose a new deep network ensemble classifier that is very effective\nagainst overfit. We begin with the theoretical analysis of a regression model,\nwhose predictions - that the variance among classifiers increases when overfit\noccurs - is demonstrated empirically in deep networks in common use. Guided by\nthese results, we construct a new ensemble-based prediction method designed to\ncombat overfit, where the prediction is determined by the most consensual\nprediction throughout the training. On multiple image and text classification\ndatasets, we show that when regular ensembles suffer from overfit, our method\neliminates the harmful reduction in generalization due to overfit, and often\neven surpasses the performance obtained by early stopping. Our method is easy\nto implement, and can be integrated with any training scheme and architecture,\nwithout additional prior knowledge beyond the training set. Accordingly, it is\na practical and useful tool to overcome overfit.",
            "author": [
                "Uri Stern",
                "Daniel Shwartz",
                "Daphna Weinshall"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11077v1",
                "http://arxiv.org/pdf/2310.11077v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11075v1",
            "title": "Sim-to-Real Transfer of Adaptive Control Parameters for AUV\n  Stabilization under Current Disturbance",
            "updated": "2023-10-17T08:46:56Z",
            "published": "2023-10-17T08:46:56Z",
            "summary": "Learning-based adaptive control methods hold the premise of enabling\nautonomous agents to reduce the effect of process variations with minimal human\nintervention. However, its application to autonomous underwater vehicles (AUVs)\nhas so far been restricted due to 1) unknown dynamics under the form of sea\ncurrent disturbance that we can not model properly nor measure due to limited\nsensor capability and 2) the nonlinearity of AUVs tasks where the controller\nresponse at some operating points must be overly conservative in order to\nsatisfy the specification at other operating points. Deep Reinforcement\nLearning (DRL) can alleviates these limitations by training general-purpose\nneural network policies, but applications of DRL algorithms to AUVs have been\nrestricted to simulated environments, due to their inherent high sample\ncomplexity and distribution shift problem. This paper presents a novel\napproach, merging the Maximum Entropy Deep Reinforcement Learning framework\nwith a classic model-based control architecture, to formulate an adaptive\ncontroller. Within this framework, we introduce a Sim-to-Real transfer strategy\ncomprising the following components: a bio-inspired experience replay\nmechanism, an enhanced domain randomisation technique, and an evaluation\nprotocol executed on a physical platform. Our experimental assessments\ndemonstrate that this method effectively learns proficient policies from\nsuboptimal simulated models of the AUV, resulting in control performance 3\ntimes higher when transferred to a real-world vehicle, compared to its\nmodel-based nonadaptive but optimal counterpart.",
            "author": [
                "Thomas Chaffre",
                "Jonathan Wheare",
                "Andrew Lammas",
                "Paulo Santos",
                "Gilles Le Chenadec",
                "Karl Sammut",
                "Benoit Clement"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11075v1",
                "http://arxiv.org/pdf/2310.11075v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11070v1",
            "title": "Intelligent Resource Allocation for UAV-Based Cognitive NOMA Networks:\n  An Active Inference Approach",
            "updated": "2023-10-17T08:33:44Z",
            "published": "2023-10-17T08:33:44Z",
            "summary": "Future wireless networks will need to improve adaptive resource allocation\nand decision-making to handle the increasing number of intelligent devices.\nUnmanned aerial vehicles (UAVs) are being explored for their potential in\nreal-time decision-making. Moreover, cognitive non-orthogonal multiple access\n(Cognitive-NOMA) is envisioned as a remedy to address spectrum scarcity and\nenable massive connectivity. This paper investigates the design of joint\nsubchannel and power allocation in an uplink UAV-based cognitive NOMA network.\nWe aim to maximize the cumulative sum rate by jointly optimizing the subchannel\nand power allocation based on the UAV's mobility at each time step. This is\noften formulated as an optimization problem with random variables. However,\nconventional optimization algorithms normally introduce significant complexity,\nand machine learning methods often rely on large but partially representative\ndatasets to build solution models, assuming stationary testing data.\nConsequently, inference strategies for non stationary events are often\noverlooked. In this study, we introduce a novel active inference-based learning\napproach, rooted in cognitive neuroscience, to solve this complex problem. The\nframework involves creating a training dataset using random or iterative\nmethods to find suboptimal resource allocations. This dataset trains a mobile\nUAV offline, enabling it to learn a generative model of discrete subchannels\nand continuous power allocation. The UAV then uses this model for online\ninference. The method incrementally derives new generative models from training\ndata by identifying dynamic equilibrium conditions between required actions and\nvariables, represented within a unique dynamic Bayesian network. The proposed\napproach is validated through numerical simulations, showing efficient\nperformance compared to suboptimal baseline schemes.",
            "author": [
                "Felix Obite",
                "Ali Krayani",
                "Atm S. Alam",
                "Lucio Marcenaro",
                "Arumugam Nallanathan",
                "Carlo Regazzoni"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11070v1",
                "http://arxiv.org/pdf/2310.11070v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11065v1",
            "title": "Resampling Stochastic Gradient Descent Cheaply for Efficient Uncertainty\n  Quantification",
            "updated": "2023-10-17T08:18:10Z",
            "published": "2023-10-17T08:18:10Z",
            "summary": "Stochastic gradient descent (SGD) or stochastic approximation has been widely\nused in model training and stochastic optimization. While there is a huge\nliterature on analyzing its convergence, inference on the obtained solutions\nfrom SGD has only been recently studied, yet is important due to the growing\nneed for uncertainty quantification. We investigate two computationally cheap\nresampling-based methods to construct confidence intervals for SGD solutions.\nOne uses multiple, but few, SGDs in parallel via resampling with replacement\nfrom the data, and another operates this in an online fashion. Our methods can\nbe regarded as enhancements of established bootstrap schemes to substantially\nreduce the computation effort in terms of resampling requirements, while at the\nsame time bypassing the intricate mixing conditions in existing batching\nmethods. We achieve these via a recent so-called cheap bootstrap idea and\nBerry-Esseen-type bound for SGD.",
            "author": [
                "Henry Lam",
                "Zitong Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11065v1",
                "http://arxiv.org/pdf/2310.11065v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12178v1",
            "title": "Prediction and control of spatiotemporal chaos by learning conjugate\n  tubular neighborhoods",
            "updated": "2023-10-17T08:14:15Z",
            "published": "2023-10-17T08:14:15Z",
            "summary": "I present a data-driven predictive modeling tool that is applicable to\nhigh-dimensional chaotic systems with unstable periodic orbits. The basic idea\nis using deep neural networks to learn coordinate transformations between the\ntrajectories in the periodic orbits' neighborhoods and those of low-dimensional\nlinear systems in a latent space. I argue that the resulting models are\npartially interpretable since their latent-space dynamics is fully understood.\nTo illustrate the method, I apply it to the numerical solutions of the\nKuramoto--Sivashinsky partial differential equation in one dimension. Besides\nthe forward-time predictions, I also show that these models can be leveraged\nfor control.",
            "author": [
                "Nazmi Burak Budanur"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12178v1",
                "http://arxiv.org/pdf/2310.12178v1"
            ],
            "primary_category": "nlin.AO",
            "category": [
                "nlin.AO",
                "math.DS",
                "nlin.CD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11060v1",
            "title": "Locally Differentially Private Graph Embedding",
            "updated": "2023-10-17T08:06:08Z",
            "published": "2023-10-17T08:06:08Z",
            "summary": "Graph embedding has been demonstrated to be a powerful tool for learning\nlatent representations for nodes in a graph. However, despite its superior\nperformance in various graph-based machine learning tasks, learning over graphs\ncan raise significant privacy concerns when graph data involves sensitive\ninformation. To address this, in this paper, we investigate the problem of\ndeveloping graph embedding algorithms that satisfy local differential privacy\n(LDP). We propose LDP-GE, a novel privacy-preserving graph embedding framework,\nto protect the privacy of node data. Specifically, we propose an LDP mechanism\nto obfuscate node data and adopt personalized PageRank as the proximity measure\nto learn node representations. Then, we theoretically analyze the privacy\nguarantees and utility of the LDP-GE framework. Extensive experiments conducted\nover several real-world graph datasets demonstrate that LDP-GE achieves\nfavorable privacy-utility trade-offs and significantly outperforms existing\napproaches in both node classification and link prediction tasks.",
            "author": [
                "Zening Li",
                "Rong-Hua Li",
                "Meihao Liao",
                "Fusheng Jin",
                "Guoren Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11060v1",
                "http://arxiv.org/pdf/2310.11060v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11059v1",
            "title": "Causal Feature Selection via Transfer Entropy",
            "updated": "2023-10-17T08:04:45Z",
            "published": "2023-10-17T08:04:45Z",
            "summary": "Machine learning algorithms are designed to capture complex relationships\nbetween features. In this context, the high dimensionality of data often\nresults in poor model performance, with the risk of overfitting. Feature\nselection, the process of selecting a subset of relevant and non-redundant\nfeatures, is, therefore, an essential step to mitigate these issues. However,\nclassical feature selection approaches do not inspect the causal relationship\nbetween selected features and target, which can lead to misleading results in\nreal-world applications. Causal discovery, instead, aims to identify causal\nrelationships between features with observational data. In this paper, we\npropose a novel methodology at the intersection between feature selection and\ncausal discovery, focusing on time series. We introduce a new causal feature\nselection approach that relies on the forward and backward feature selection\nprocedures and leverages transfer entropy to estimate the causal flow of\ninformation from the features to the target in time series. Our approach\nenables the selection of features not only in terms of mere model performance\nbut also captures the causal information flow. In this context, we provide\ntheoretical guarantees on the regression and classification errors for both the\nexact and the finite-sample cases. Finally, we present numerical validations on\nsynthetic and real-world regression problems, showing results competitive\nw.r.t. the considered baselines.",
            "author": [
                "Paolo Bonetti",
                "Alberto Maria Metelli",
                "Marcello Restelli"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11059v1",
                "http://arxiv.org/pdf/2310.11059v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11477v1",
            "title": "Robust-MBFD: A Robust Deep Learning System for Motor Bearing Faults\n  Detection Using Multiple Deep Learning Training Strategies and A Novel Double\n  Loss Function",
            "updated": "2023-10-17T07:50:52Z",
            "published": "2023-10-17T07:50:52Z",
            "summary": "This paper presents a comprehensive analysis of motor bearing fault detection\n(MBFD), which involves the task of identifying faults in a motor bearing based\non its vibration. To this end, we first propose and evaluate various machine\nlearning based systems for the MBFD task. Furthermore, we propose three deep\nlearning based systems for the MBFD task, each of which explores one of the\nfollowing training strategies: supervised learning, semi-supervised learning,\nand unsupervised learning. The proposed machine learning based systems and deep\nlearning based systems are evaluated, compared, and then they are used to\nidentify the best model for the MBFD task. We conducted extensive experiments\non various benchmark datasets of motor bearing faults, including those from the\nAmerican Society for Mechanical Failure Prevention Technology (MFPT), Case\nWestern Reserve University Bearing Center (CWRU), and the Condition Monitoring\nof Bearing Damage in Electromechanical Drive Systems from Paderborn University\n(PU). The experimental results on different datasets highlight two main\ncontributions of this study. First, we prove that deep learning based systems\nare more effective than machine learning based systems for the MBFD task.\nSecond, we achieve a robust and general deep learning based system with a novel\nloss function for the MBFD task on several benchmark datasets, demonstrating\nits potential for real-life MBFD applications.",
            "author": [
                "Khoa Tran",
                "Lam Pham",
                "Hai-Canh Vu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11477v1",
                "http://arxiv.org/pdf/2310.11477v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11053v2",
            "title": "Denevil: Towards Deciphering and Navigating the Ethical Values of Large\n  Language Models via Instruction Learning",
            "updated": "2023-10-30T02:30:35Z",
            "published": "2023-10-17T07:42:40Z",
            "summary": "Large Language Models (LLMs) have made unprecedented breakthroughs, yet their\nincreasing integration into everyday life might raise societal risks due to\ngenerated unethical content. Despite extensive study on specific issues like\nbias, the intrinsic values of LLMs remain largely unexplored from a moral\nphilosophy perspective. This work delves into ethical values utilizing Moral\nFoundation Theory. Moving beyond conventional discriminative evaluations with\npoor reliability, we propose DeNEVIL, a novel prompt generation algorithm\ntailored to dynamically exploit LLMs' value vulnerabilities and elicit the\nviolation of ethics in a generative manner, revealing their underlying value\ninclinations. On such a basis, we construct MoralPrompt, a high-quality dataset\ncomprising 2,397 prompts covering 500+ value principles, and then benchmark the\nintrinsic values across a spectrum of LLMs. We discovered that most models are\nessentially misaligned, necessitating further ethical value alignment. In\nresponse, we develop VILMO, an in-context alignment method that substantially\nenhances the value compliance of LLM outputs by learning to generate\nappropriate value instructions, outperforming existing competitors. Our methods\nare suitable for black-box and open-source models, offering a promising initial\nstep in studying the ethical values of LLMs.",
            "author": [
                "Shitong Duan",
                "Xiaoyuan Yi",
                "Peng Zhang",
                "Tun Lu",
                "Xing Xie",
                "Ning Gu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11053v2",
                "http://arxiv.org/pdf/2310.11053v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11052v1",
            "title": "Investigating Threats Posed by SMS Origin Spoofing to IoT Devices",
            "updated": "2023-10-17T07:41:04Z",
            "published": "2023-10-17T07:41:04Z",
            "summary": "The short message service (SMS) is a service for exchanging texts via mobile\nnetworks that has been developed not only as a means of text communication\nbetween subscribers but also as a means to remotely manage Internet of Things\n(IoT) devices. However, the originating number of an SMS can be spoofed. If IoT\ndevices authenticate administrators based on the originating number of an SMS,\nthe authentication is bypassed via SMS origin spoofing. Consequently, IoT\ndevices are at risk of accepting commands from attackers and performing\nunauthorized actions. Accordingly, in this study, the specifications of major\ncellular IoT gateways were evaluated by focusing on remote management via SMS,\nand the authentication bypass hypothesis was verified. The results showed that\n25 of the 32 targeted products supported SMS-based remote management, and 20\nimplemented authentication based on the originating number of the SMS.\nFurthermore, by spoofing the originating number of the SMS, one product was\ndemonstrated to be remotely exploitable through authentication bypassing. Thus,\nthis study revealed the threats posed by SMS origin spoofing to IoT devices and\nproved that SMS origin spoofing not only threatens text communication between\npeople but also puts machine communication at risk.",
            "author": [
                "Akaki Tsunoda"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11052v1",
                "http://arxiv.org/pdf/2310.11052v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11050v1",
            "title": "$k$-$t$ CLAIR: Self-Consistency Guided Multi-Prior Learning for Dynamic\n  Parallel MR Image Reconstruction",
            "updated": "2023-10-17T07:37:32Z",
            "published": "2023-10-17T07:37:32Z",
            "summary": "Cardiac magnetic resonance imaging (CMR) has been widely used in clinical\npractice for the medical diagnosis of cardiac diseases. However, the long\nacquisition time hinders its development in real-time applications. Here, we\npropose a novel self-consistency guided multi-prior learning framework named\n$k$-$t$ CLAIR to exploit spatiotemporal correlations from highly undersampled\ndata for accelerated dynamic parallel MRI reconstruction. The $k$-$t$ CLAIR\nprogressively reconstructs faithful images by leveraging multiple complementary\npriors learned in the $x$-$t$, $x$-$f$, and $k$-$t$ domains in an iterative\nfashion, as dynamic MRI exhibits high spatiotemporal redundancy. Additionally,\n$k$-$t$ CLAIR incorporates calibration information for prior learning,\nresulting in a more consistent reconstruction. Experimental results on cardiac\ncine and T1W/T2W images demonstrate that $k$-$t$ CLAIR achieves high-quality\ndynamic MR reconstruction in terms of both quantitative and qualitative\nperformance.",
            "author": [
                "Liping Zhang",
                "Weitian Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11050v1",
                "http://arxiv.org/pdf/2310.11050v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11049v1",
            "title": "Nonet at SemEval-2023 Task 6: Methodologies for Legal Evaluation",
            "updated": "2023-10-17T07:35:11Z",
            "published": "2023-10-17T07:35:11Z",
            "summary": "This paper describes our submission to the SemEval-2023 for Task 6 on\nLegalEval: Understanding Legal Texts. Our submission concentrated on three\nsubtasks: Legal Named Entity Recognition (L-NER) for Task-B, Legal Judgment\nPrediction (LJP) for Task-C1, and Court Judgment Prediction with Explanation\n(CJPE) for Task-C2. We conducted various experiments on these subtasks and\npresented the results in detail, including data statistics and methodology. It\nis worth noting that legal tasks, such as those tackled in this research, have\nbeen gaining importance due to the increasing need to automate legal analysis\nand support. Our team obtained competitive rankings of 15$^{th}$, 11$^{th}$,\nand 1$^{st}$ in Task-B, Task-C1, and Task-C2, respectively, as reported on the\nleaderboard.",
            "author": [
                "Shubham Kumar Nigam",
                "Aniket Deroy",
                "Noel Shallum",
                "Ayush Kumar Mishra",
                "Anup Roy",
                "Shubham Kumar Mishra",
                "Arnab Bhattacharya",
                "Saptarshi Ghosh",
                "Kripabandhu Ghosh"
            ],
            "link": [
                "http://dx.doi.org/10.18653/v1/2023.semeval-1.180",
                "http://arxiv.org/abs/2310.11049v1",
                "http://arxiv.org/pdf/2310.11049v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11048v1",
            "title": "Understanding Contrastive Learning via Distributionally Robust\n  Optimization",
            "updated": "2023-10-17T07:32:59Z",
            "published": "2023-10-17T07:32:59Z",
            "summary": "This study reveals the inherent tolerance of contrastive learning (CL)\ntowards sampling bias, wherein negative samples may encompass similar semantics\n(\\eg labels). However, existing theories fall short in providing explanations\nfor this phenomenon. We bridge this research gap by analyzing CL through the\nlens of distributionally robust optimization (DRO), yielding several key\ninsights: (1) CL essentially conducts DRO over the negative sampling\ndistribution, thus enabling robust performance across a variety of potential\ndistributions and demonstrating robustness to sampling bias; (2) The design of\nthe temperature $\\tau$ is not merely heuristic but acts as a Lagrange\nCoefficient, regulating the size of the potential distribution set; (3) A\ntheoretical connection is established between DRO and mutual information, thus\npresenting fresh evidence for ``InfoNCE as an estimate of MI'' and a new\nestimation approach for $\\phi$-divergence-based generalized mutual information.\nWe also identify CL's potential shortcomings, including over-conservatism and\nsensitivity to outliers, and introduce a novel Adjusted InfoNCE loss (ADNCE) to\nmitigate these issues. It refines potential distribution, improving performance\nand accelerating convergence. Extensive experiments on various domains (image,\nsentence, and graphs) validate the effectiveness of the proposal. The code is\navailable at \\url{https://github.com/junkangwu/ADNCE}.",
            "author": [
                "Junkang Wu",
                "Jiawei Chen",
                "Jiancan Wu",
                "Wentao Shi",
                "Xiang Wang",
                "Xiangnan He"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11048v1",
                "http://arxiv.org/pdf/2310.11048v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11047v1",
            "title": "The Impact of Gamified Auditory-Verbal Training for Hearing-Challenged\n  Children at Intermediate and Advanced Rehabilitation Stages",
            "updated": "2023-10-17T07:29:21Z",
            "published": "2023-10-17T07:29:21Z",
            "summary": "Auditory-verbal training is essential for children with hearing challenges,\nand the gamification approach has become a promising direction for improving\nthe rehabilitation experience and effect. However, the specific influence of\nthe gamified training approach on participants at different rehabilitation\nstages has not been empirically studied. This paper is thusly intended to\ninvestigate the research questions: Do the training performances of children at\nadvanced rehabilitation stage differ before and after using the gamified\ntraining system? Do the training performances of children at intermediate\nrehabilitation stage differ before and after using the gamified training\nsystem? Do children enjoy the gamified training approach? For the purpose, a\ndigital gamified auditory-verbal training system was originally developed, and\na series of user experiments were organized. Particularly, 31\nhearing-challenged children aging between three-six years old at an\nauditory-verbal rehabilitation center were recruited to take the training, and\nsix professional therapists were also invited to assist with the experiments\nand attend the interviews. Based on the training performance observation and\ninterviews with participants, their parents and the therapists, it can be found\nthat generally the gamified training approach can effectively facilitate the\ntraining experience, and help with the basic auditory memory and expression\ncapabilities. Regarding the specific influence, the gamified way can better\nimprove the basic auditory-verbal performance of children at the intermediate\nstage, since they focus more on the ease of learning and adaption to the\ntraining system. These findings and conclusions can provide insights for the\nfurther exploration and application of the gamification approach in children's\nauditory-verbal rehabilitation.",
            "author": [
                "Yan Xiang",
                "Zhen Zhang",
                "Danni Chang",
                "Lei Tu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11047v1",
                "http://arxiv.org/pdf/2310.11047v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11046v1",
            "title": "Fast Graph Condensation with Structure-based Neural Tangent Kernel",
            "updated": "2023-10-17T07:25:59Z",
            "published": "2023-10-17T07:25:59Z",
            "summary": "The rapid development of Internet technology has given rise to a vast amount\nof graph-structured data. Graph Neural Networks (GNNs), as an effective method\nfor various graph mining tasks, incurs substantial computational resource costs\nwhen dealing with large-scale graph data. A data-centric manner solution is\nproposed to condense the large graph dataset into a smaller one without\nsacrificing the predictive performance of GNNs. However, existing efforts\ncondense graph-structured data through a computational intensive bi-level\noptimization architecture also suffer from massive computation costs. In this\npaper, we propose reforming the graph condensation problem as a Kernel Ridge\nRegression (KRR) task instead of iteratively training GNNs in the inner loop of\nbi-level optimization. More specifically, We propose a novel dataset\ncondensation framework (GC-SNTK) for graph-structured data, where a\nStructure-based Neural Tangent Kernel (SNTK) is developed to capture the\ntopology of graph and serves as the kernel function in KRR paradigm.\nComprehensive experiments demonstrate the effectiveness of our proposed model\nin accelerating graph condensation while maintaining high prediction\nperformance.",
            "author": [
                "Lin Wang",
                "Wenqi Fan",
                "Jiatong Li",
                "Yao Ma",
                "Qing Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11046v1",
                "http://arxiv.org/pdf/2310.11046v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "68T01",
                "I.2.0"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11042v1",
            "title": "Diagrammatic Modelling of Causality and Causal Relations",
            "updated": "2023-10-17T07:17:51Z",
            "published": "2023-10-17T07:17:51Z",
            "summary": "It has been stated that the notion of cause and effect is one object of study\nthat sciences and engineering revolve around. Lately, in software engineering,\ndiagrammatic causal inference methods (e.g., Pearl s model) have gained\npopularity (e.g., analyzing causes and effects of change in software\nrequirement development). This paper concerns diagrammatical (graphic) models\nof causal relationships. Specifically, we experiment with using the conceptual\nlanguage of thinging machines (TMs) as a tool in this context. This would\nbenefit works on causal relationships in requirements engineering, enhance our\nunderstanding of the TM modeling, and contribute to the study of the\nphilosophical notion of causality. To specify the causality in a system s\ndescription is to constrain the system s behavior and thus exclude some\npossible chronologies of events. The notion of causality has been studied based\non tools to express causal questions in diagrammatic and algebraic forms.\nCausal models deploy diagrammatic models, structural equations, and\ncounterfactual and interventional logic. Diagrammatic models serve as a\nlanguage for representing what we know about the world. The research\nmethodology in the paper focuses on converting causal graphs into TM models and\ncontrasts the two types of representation. The results show that the TM\ndepiction of causality is more complete and therefore can provide a foundation\nfor causal graphs.",
            "author": [
                "Sabah Al-Fedaghi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11042v1",
                "http://arxiv.org/pdf/2310.11042v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11040v2",
            "title": "Co-Learning Semantic-aware Unsupervised Segmentation for Pathological\n  Image Registration",
            "updated": "2023-10-19T06:54:58Z",
            "published": "2023-10-17T07:13:28Z",
            "summary": "The registration of pathological images plays an important role in medical\napplications. Despite its significance, most researchers in this field\nprimarily focus on the registration of normal tissue into normal tissue. The\nnegative impact of focal tissue, such as the loss of spatial correspondence\ninformation and the abnormal distortion of tissue, are rarely considered. In\nthis paper, we propose GIRNet, a novel unsupervised approach for pathological\nimage registration by incorporating segmentation and inpainting through the\nprinciples of Generation, Inpainting, and Registration (GIR). The registration,\nsegmentation, and inpainting modules are trained simultaneously in a\nco-learning manner so that the segmentation of the focal area and the\nregistration of inpainted pairs can improve collaboratively. Overall, the\nregistration of pathological images is achieved in a completely unsupervised\nlearning framework. Experimental results on multiple datasets, including\nMagnetic Resonance Imaging (MRI) of T1 sequences, demonstrate the efficacy of\nour proposed method. Our results show that our method can accurately achieve\nthe registration of pathological images and identify lesions even in\nchallenging imaging modalities. Our unsupervised approach offers a promising\nsolution for the efficient and cost-effective registration of pathological\nimages. Our code is available at\nhttps://github.com/brain-intelligence-lab/GIRNet.",
            "author": [
                "Yang Liu",
                "Shi Gu"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-031-43999-5_51",
                "http://arxiv.org/abs/2310.11040v2",
                "http://arxiv.org/pdf/2310.11040v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11031v1",
            "title": "Domain Generalization Using Large Pretrained Models with\n  Mixture-of-Adapters",
            "updated": "2023-10-17T07:01:24Z",
            "published": "2023-10-17T07:01:24Z",
            "summary": "Learning a robust vision model despite large distribution shift is essential\nfor model deployment in real-world settings. Especially, domain generalization\n(DG) algorithm aims to maintain the performance of a trained model on different\ndistributions which were not seen during training. One of the most effective\nmethods has been leveraging the already learned rich knowledge of large\npretrained models. However, naively fine-tuning large models to DG tasks is\noften practically infeasible due to memory limitations, extensive time\nrequirements for training, and the risk of learned knowledge deterioration.\nRecently, parameter-efficient fine-tuning (PEFT) methods have been proposed to\nreduce the high computational cost during training and efficiently adapt large\nmodels to downstream tasks. In this work, for the first time, we find that the\nuse of adapters in PEFT methods not only reduce high computational cost during\ntraining but also serve as an effective regularizer for DG tasks. Surprisingly,\na naive adapter implementation for large models achieve superior performance on\ncommon datasets. However, in situations of large distribution shifts,\nadditional factors such as optimal amount of regularization due to the strength\nof distribution shifts should be considered for a sophisticated adapter\nimplementation. To address this, we propose a mixture-of-expert based adapter\nfine-tuning method, dubbed as mixture-of-adapters (MoA). Specifically, we\nemploy multiple adapters that have varying capacities, and by using learnable\nrouters, we allocate each token to a proper adapter. By using both PEFT and MoA\nmethods, we effectively alleviate the performance deterioration caused by\ndistribution shifts and achieve state-of-the-art performance on diverse DG\nbenchmarks.",
            "author": [
                "Gyuseong Lee",
                "Wooseok Jang",
                "Jin Hyeon Kim",
                "Jaewoo Jung",
                "Seungryong Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11031v1",
                "http://arxiv.org/pdf/2310.11031v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11028v1",
            "title": "Matrix Compression via Randomized Low Rank and Low Precision\n  Factorization",
            "updated": "2023-10-17T06:56:57Z",
            "published": "2023-10-17T06:56:57Z",
            "summary": "Matrices are exceptionally useful in various fields of study as they provide\na convenient framework to organize and manipulate data in a structured manner.\nHowever, modern matrices can involve billions of elements, making their storage\nand processing quite demanding in terms of computational resources and memory\nusage. Although prohibitively large, such matrices are often approximately low\nrank. We propose an algorithm that exploits this structure to obtain a low rank\ndecomposition of any matrix $\\mathbf{A}$ as $\\mathbf{A} \\approx\n\\mathbf{L}\\mathbf{R}$, where $\\mathbf{L}$ and $\\mathbf{R}$ are the low rank\nfactors. The total number of elements in $\\mathbf{L}$ and $\\mathbf{R}$ can be\nsignificantly less than that in $\\mathbf{A}$. Furthermore, the entries of\n$\\mathbf{L}$ and $\\mathbf{R}$ are quantized to low precision formats $--$\ncompressing $\\mathbf{A}$ by giving us a low rank and low precision\nfactorization. Our algorithm first computes an approximate basis of the range\nspace of $\\mathbf{A}$ by randomly sketching its columns, followed by a\nquantization of the vectors constituting this basis. It then computes\napproximate projections of the columns of $\\mathbf{A}$ onto this quantized\nbasis. We derive upper bounds on the approximation error of our algorithm, and\nanalyze the impact of target rank and quantization bit-budget. The tradeoff\nbetween compression ratio and approximation accuracy allows for flexibility in\nchoosing these parameters based on specific application requirements. We\nempirically demonstrate the efficacy of our algorithm in image compression,\nnearest neighbor classification of image and text embeddings, and compressing\nthe layers of LlaMa-$7$b. Our results illustrate that we can achieve\ncompression ratios as aggressive as one bit per matrix coordinate, all while\nsurpassing or maintaining the performance of traditional compression\ntechniques.",
            "author": [
                "Rajarshi Saha",
                "Varun Srivastava",
                "Mert Pilanci"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11028v1",
                "http://arxiv.org/pdf/2310.11028v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IT",
                "math.IT",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11026v1",
            "title": "Exploring Automatic Evaluation Methods based on a Decoder-based LLM for\n  Text Generation",
            "updated": "2023-10-17T06:53:00Z",
            "published": "2023-10-17T06:53:00Z",
            "summary": "Automatic evaluation of text generation is essential for improving the\naccuracy of generation tasks. In light of the current trend towards\nincreasingly larger decoder-based language models, we investigate automatic\nevaluation methods based on such models for text generation. This paper\ncompares various methods, including tuning with encoder-based models and large\nlanguage models under equal conditions, on two different tasks, machine\ntranslation evaluation and semantic textual similarity, in two languages,\nJapanese and English. Experimental results show that compared to the tuned\nencoder-based models, the tuned decoder-based models perform poorly. The\nanalysis of the causes for this suggests that the decoder-based models focus on\nsurface word sequences and do not capture meaning. It is also revealed that\nin-context learning of very large decoder-based models such as ChatGPT makes it\ndifficult to identify fine-grained semantic differences.",
            "author": [
                "Tomohito Kasahara",
                "Daisuke Kawahara"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11026v1",
                "http://arxiv.org/pdf/2310.11026v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11025v1",
            "title": "SignGT: Signed Attention-based Graph Transformer for Graph\n  Representation Learning",
            "updated": "2023-10-17T06:42:11Z",
            "published": "2023-10-17T06:42:11Z",
            "summary": "The emerging graph Transformers have achieved impressive performance for\ngraph representation learning over graph neural networks (GNNs). In this work,\nwe regard the self-attention mechanism, the core module of graph Transformers,\nas a two-step aggregation operation on a fully connected graph. Due to the\nproperty of generating positive attention values, the self-attention mechanism\nis equal to conducting a smooth operation on all nodes, preserving the\nlow-frequency information. However, only capturing the low-frequency\ninformation is inefficient in learning complex relations of nodes on diverse\ngraphs, such as heterophily graphs where the high-frequency information is\ncrucial. To this end, we propose a Signed Attention-based Graph Transformer\n(SignGT) to adaptively capture various frequency information from the graphs.\nSpecifically, SignGT develops a new signed self-attention mechanism (SignSA)\nthat produces signed attention values according to the semantic relevance of\nnode pairs. Hence, the diverse frequency information between different node\npairs could be carefully preserved. Besides, SignGT proposes a structure-aware\nfeed-forward network (SFFN) that introduces the neighborhood bias to preserve\nthe local topology information. In this way, SignGT could learn informative\nnode representations from both long-range dependencies and local topology\ninformation. Extensive empirical results on both node-level and graph-level\ntasks indicate the superiority of SignGT against state-of-the-art graph\nTransformers as well as advanced GNNs.",
            "author": [
                "Jinsong Chen",
                "Gaichao Li",
                "John E. Hopcroft",
                "Kun He"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11025v1",
                "http://arxiv.org/pdf/2310.11025v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11022v1",
            "title": "Compatible Transformer for Irregularly Sampled Multivariate Time Series",
            "updated": "2023-10-17T06:29:09Z",
            "published": "2023-10-17T06:29:09Z",
            "summary": "To analyze multivariate time series, most previous methods assume regular\nsubsampling of time series, where the interval between adjacent measurements\nand the number of samples remain unchanged. Practically, data collection\nsystems could produce irregularly sampled time series due to sensor failures\nand interventions. However, existing methods designed for regularly sampled\nmultivariate time series cannot directly handle irregularity owing to\nmisalignment along both temporal and variate dimensions. To fill this gap, we\npropose Compatible Transformer (CoFormer), a transformer-based encoder to\nachieve comprehensive temporal-interaction feature learning for each individual\nsample in irregular multivariate time series. In CoFormer, we view each sample\nas a unique variate-time point and leverage intra-variate/inter-variate\nattentions to learn sample-wise temporal/interaction features based on\nintra-variate/inter-variate neighbors. With CoFormer as the core, we can\nanalyze irregularly sampled multivariate time series for many downstream tasks,\nincluding classification and prediction. We conduct extensive experiments on 3\nreal-world datasets and validate that the proposed CoFormer significantly and\nconsistently outperforms existing methods.",
            "author": [
                "Yuxi Wei",
                "Juntong Peng",
                "Tong He",
                "Chenxin Xu",
                "Jian Zhang",
                "Shirui Pan",
                "Siheng Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11022v1",
                "http://arxiv.org/pdf/2310.11022v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11021v2",
            "title": "Dynamic quantum circuit compilation",
            "updated": "2023-11-21T11:02:43Z",
            "published": "2023-10-17T06:26:30Z",
            "summary": "Quantum computing has shown tremendous promise in addressing complex\ncomputational problems, yet its practical realization is hindered by the\nlimited availability of qubits for computation. Recent advancements in quantum\nhardware have introduced mid-circuit measurements and resets, enabling the\nreuse of measured qubits and significantly reducing the qubit requirements for\nexecuting quantum algorithms. In this work, we present a systematic study of\ndynamic quantum circuit compilation, a process that transforms static quantum\ncircuits into their dynamic equivalents with a reduced qubit count through\nqubit-reuse. We establish the first general framework for optimizing the\ndynamic circuit compilation via graph manipulation. In particular, we\ncompletely characterize the optimal quantum circuit compilation using binary\ninteger programming, provide efficient algorithms for determining whether a\ngiven quantum circuit can be reduced to a smaller circuit and present heuristic\nalgorithms for devising dynamic compilation schemes in general. Furthermore, we\nconduct a thorough analysis of quantum circuits with practical relevance,\noffering optimal compilations for well-known quantum algorithms in quantum\ncomputation, ansatz circuits utilized in quantum machine learning, and\nmeasurement-based quantum computation crucial for quantum networking. We also\nperform a comparative analysis against state-of-the-art approaches,\ndemonstrating the superior performance of our methods in both structured and\nrandom quantum circuits. Our framework lays a rigorous foundation for\ncomprehending dynamic quantum circuit compilation via qubit-reuse, bridging the\ngap between theoretical quantum algorithms and their physical implementation on\nquantum computers with limited resources.",
            "author": [
                "Kun Fang",
                "Munan Zhang",
                "Ruqi Shi",
                "Yinan Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11021v2",
                "http://arxiv.org/pdf/2310.11021v2"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11015v1",
            "title": "Pure Exploration in Asynchronous Federated Bandits",
            "updated": "2023-10-17T06:04:00Z",
            "published": "2023-10-17T06:04:00Z",
            "summary": "We study the federated pure exploration problem of multi-armed bandits and\nlinear bandits, where $M$ agents cooperatively identify the best arm via\ncommunicating with the central server. To enhance the robustness against\nlatency and unavailability of agents that are common in practice, we propose\nthe first federated asynchronous multi-armed bandit and linear bandit\nalgorithms for pure exploration with fixed confidence. Our theoretical analysis\nshows the proposed algorithms achieve near-optimal sample complexities and\nefficient communication costs in a fully asynchronous environment. Moreover,\nexperimental results based on synthetic and real-world data empirically\nelucidate the effectiveness and communication cost-efficiency of the proposed\nalgorithms.",
            "author": [
                "Zichen Wang",
                "Chuanhao Li",
                "Chenyu Song",
                "Lianghui Wang",
                "Quanquan Gu",
                "Huazheng Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11015v1",
                "http://arxiv.org/pdf/2310.11015v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11014v1",
            "title": "Hyperspectral In-Memory Computing with Optical Frequency Combs and\n  Programmable Optical Memories",
            "updated": "2023-10-17T06:03:45Z",
            "published": "2023-10-17T06:03:45Z",
            "summary": "The rapid advancements in machine learning across numerous industries have\namplified the demand for extensive matrix-vector multiplication operations,\nthereby challenging the capacities of traditional von Neumann computing\narchitectures. To address this, researchers are currently exploring\nalternatives such as in-memory computing systems to develop faster and more\nenergy-efficient hardware. In particular, there is renewed interest in\ncomputing systems based on optics, which could potentially handle matrix-vector\nmultiplication in a more energy-efficient way. Despite promising initial\nresults, developing a highly parallel, programmable, and scalable optical\ncomputing system capable of rivaling electronic computing hardware still\nremains elusive. In this context, we propose a hyperspectral in-memory\ncomputing architecture that integrates space multiplexing with frequency\nmultiplexing of optical frequency combs and uses spatial light modulators as a\nprogrammable optical memory, thereby boosting the computational throughput and\nthe energy efficiency. We have experimentally demonstrated multiply-accumulate\noperations with higher than 4-bit precision in both matrix-vector and\nmatrix-matrix multiplications, which suggests the system's potential for a wide\nvariety of deep learning and optimization tasks. This system exhibits\nextraordinary modularity, scalability, and programmability, effectively\ntranscending the traditional limitations of optics-based computing\narchitectures. Our approach demonstrates the potential to scale beyond peta\noperations per second, marking a significant step towards achieving\nhigh-throughput energy-efficient optical computing.",
            "author": [
                "Mostafa Honari Latifpour",
                "Byoung Jun Park",
                "Yoshihisa Yamamoto",
                "Myoung-Gyun Suh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11014v1",
                "http://arxiv.org/pdf/2310.11014v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics",
                "cs.ET",
                "cs.LG",
                "cs.NE",
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11012v1",
            "title": "A Data-Driven Density Functional Model for Nuclear Systems",
            "updated": "2023-10-17T05:49:08Z",
            "published": "2023-10-17T05:49:08Z",
            "summary": "Through ensemble learning with multitasking and complex connection neural\nnetworks, we aggregated nuclear properties, including ground state charge\nradii, binding energies, and single-particle state information obtained from\nthe Kohn-Sham auxiliary single-particle systems. Compared to traditional\ndensity functional theory, our model can more accurately characterize nuclear\nground state information. Aiming at binding energy, the root mean square error\nis reduced to 450 keV. Although the complexity involving the nuclear\ninteraction is skipped, the model has not completely devolved into a black box.\nLeveraging the correlation between densities and binding energies, we calculate\nthe neutron skin thickness of $^{208}$Pb to be 0.223 fm. This model will\nadvance our understanding of nuclear properties and accelerate the integration\nof machine learning into modern nuclear physics.",
            "author": [
                "Zu-Xing Yang",
                "Xiao-Hua Fan",
                "Zhi-Pan Li",
                "Haozhao Liang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11012v1",
                "http://arxiv.org/pdf/2310.11012v1"
            ],
            "primary_category": "nucl-th",
            "category": [
                "nucl-th",
                "nucl-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11011v1",
            "title": "From Identifiable Causal Representations to Controllable Counterfactual\n  Generation: A Survey on Causal Generative Modeling",
            "updated": "2023-10-17T05:45:32Z",
            "published": "2023-10-17T05:45:32Z",
            "summary": "Deep generative models have shown tremendous success in data density\nestimation and data generation from finite samples. While these models have\nshown impressive performance by learning correlations among features in the\ndata, some fundamental shortcomings are their lack of explainability, the\ntendency to induce spurious correlations, and poor out-of-distribution\nextrapolation. In an effort to remedy such challenges, one can incorporate the\ntheory of causality in deep generative modeling. Structural causal models\n(SCMs) describe data-generating processes and model complex causal\nrelationships and mechanisms among variables in a system. Thus, SCMs can\nnaturally be combined with deep generative models. Causal models offer several\nbeneficial properties to deep generative models, such as distribution shift\nrobustness, fairness, and interoperability. We provide a technical survey on\ncausal generative modeling categorized into causal representation learning and\ncontrollable counterfactual generation methods. We focus on fundamental theory,\nformulations, drawbacks, datasets, metrics, and applications of causal\ngenerative models in fairness, privacy, out-of-distribution generalization, and\nprecision medicine. We also discuss open problems and fruitful research\ndirections for future work in the field.",
            "author": [
                "Aneesh Komanduri",
                "Xintao Wu",
                "Yongkai Wu",
                "Feng Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11011v1",
                "http://arxiv.org/pdf/2310.11011v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11009v2",
            "title": "Adaptive Pairwise Encodings for Link Prediction",
            "updated": "2023-10-18T20:21:34Z",
            "published": "2023-10-17T05:36:46Z",
            "summary": "Link prediction is a common task on graph-structured data that has seen\napplications in a variety of domains. Classically, hand-crafted heuristics were\nused for this task. Heuristic measures are chosen such that they correlate well\nwith the underlying factors related to link formation. In recent years, a new\nclass of methods has emerged that combines the advantages of message-passing\nneural networks (MPNN) and heuristics methods. These methods perform\npredictions by using the output of an MPNN in conjunction with a \"pairwise\nencoding\" that captures the relationship between nodes in the candidate link.\nThey have been shown to achieve strong performance on numerous datasets.\nHowever, current pairwise encodings often contain a strong inductive bias,\nusing the same underlying factors to classify all links. This limits the\nability of existing methods to learn how to properly classify a variety of\ndifferent links that may form from different factors. To address this\nlimitation, we propose a new method, LPFormer, which attempts to adaptively\nlearn the pairwise encodings for each link. LPFormer models the link factors\nvia an attention module that learns the pairwise encoding that exists between\nnodes by modeling multiple factors integral to link prediction. Extensive\nexperiments demonstrate that LPFormer can achieve SOTA performance on numerous\ndatasets while maintaining efficiency.",
            "author": [
                "Harry Shomer",
                "Yao Ma",
                "Haitao Mao",
                "Juanhui Li",
                "Bo Wu",
                "Jiliang Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11009v2",
                "http://arxiv.org/pdf/2310.11009v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11003v1",
            "title": "Correction Focused Language Model Training for Speech Recognition",
            "updated": "2023-10-17T05:10:39Z",
            "published": "2023-10-17T05:10:39Z",
            "summary": "Language models (LMs) have been commonly adopted to boost the performance of\nautomatic speech recognition (ASR) particularly in domain adaptation tasks.\nConventional way of LM training treats all the words in corpora equally,\nresulting in suboptimal improvements in ASR performance. In this work, we\nintroduce a novel correction focused LM training approach which aims to\nprioritize ASR fallible words. The word-level ASR fallibility score,\nrepresenting the likelihood of ASR mis-recognition, is defined and shaped as a\nprior word distribution to guide the LM training. To enable correction focused\ntraining with text-only corpora, large language models (LLMs) are employed as\nfallibility score predictors and text generators through multi-task\nfine-tuning. Experimental results for domain adaptation tasks demonstrate the\neffectiveness of our proposed method. Compared with conventional LMs,\ncorrection focused training achieves up to relatively 5.5% word error rate\n(WER) reduction in sufficient text scenarios. In insufficient text scenarios,\nLM training with LLM-generated text achieves up to relatively 13% WER\nreduction, while correction focused training further obtains up to relatively\n6% WER reduction.",
            "author": [
                "Yingyi Ma",
                "Zhe Liu",
                "Ozlem Kalinli"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11003v1",
                "http://arxiv.org/pdf/2310.11003v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11001v1",
            "title": "Spatially-resolved hyperlocal weather prediction and anomaly detection\n  using IoT sensor networks and machine learning techniques",
            "updated": "2023-10-17T05:04:53Z",
            "published": "2023-10-17T05:04:53Z",
            "summary": "Accurate and timely hyperlocal weather predictions are essential for various\napplications, ranging from agriculture to disaster management. In this paper,\nwe propose a novel approach that combines hyperlocal weather prediction and\nanomaly detection using IoT sensor networks and advanced machine learning\ntechniques. Our approach leverages data from multiple spatially-distributed yet\nrelatively close locations and IoT sensors to create high-resolution weather\nmodels capable of predicting short-term, localized weather conditions such as\ntemperature, pressure, and humidity. By monitoring changes in weather\nparameters across these locations, our system is able to enhance the spatial\nresolution of predictions and effectively detect anomalies in real-time.\nAdditionally, our system employs unsupervised learning algorithms to identify\nunusual weather patterns, providing timely alerts. Our findings indicate that\nthis system has the potential to enhance decision-making.",
            "author": [
                "Anita B. Agarwal",
                "Rohit Rajesh",
                "Nitin Arul"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11001v1",
                "http://arxiv.org/pdf/2310.11001v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10998v1",
            "title": "Accelerating Scalable Graph Neural Network Inference with Node-Adaptive\n  Propagation",
            "updated": "2023-10-17T05:03:00Z",
            "published": "2023-10-17T05:03:00Z",
            "summary": "Graph neural networks (GNNs) have exhibited exceptional efficacy in a diverse\narray of applications. However, the sheer size of large-scale graphs presents a\nsignificant challenge to real-time inference with GNNs. Although existing\nScalable GNNs leverage linear propagation to preprocess the features and\naccelerate the training and inference procedure, these methods still suffer\nfrom scalability issues when making inferences on unseen nodes, as the feature\npreprocessing requires the graph to be known and fixed. To further accelerate\nScalable GNNs inference in this inductive setting, we propose an online\npropagation framework and two novel node-adaptive propagation methods that can\ncustomize the optimal propagation depth for each node based on its topological\ninformation and thereby avoid redundant feature propagation. The trade-off\nbetween accuracy and latency can be flexibly managed through simple\nhyper-parameters to accommodate various latency constraints. Moreover, to\ncompensate for the inference accuracy loss caused by the potential early\ntermination of propagation, we further propose Inception Distillation to\nexploit the multi-scale receptive field information within graphs. The rigorous\nand comprehensive experimental study on public datasets with varying scales and\ncharacteristics demonstrates that the proposed inference acceleration framework\noutperforms existing state-of-the-art graph inference acceleration methods in\nterms of accuracy and efficiency. Particularly, the superiority of our approach\nis notable on datasets with larger scales, yielding a 75x inference speedup on\nthe largest Ogbn-products dataset.",
            "author": [
                "Xinyi Gao",
                "Wentao Zhang",
                "Junliang Yu",
                "Yingxia Shao",
                "Quoc Viet Hung Nguyen",
                "Bin Cui",
                "Hongzhi Yin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10998v1",
                "http://arxiv.org/pdf/2310.10998v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10997v1",
            "title": "Cooperative Dispatch of Microgrids Community Using Risk-Sensitive\n  Reinforcement Learning with Monotonously Improved Performance",
            "updated": "2023-10-17T05:01:58Z",
            "published": "2023-10-17T05:01:58Z",
            "summary": "The integration of individual microgrids (MGs) into Microgrid Clusters (MGCs)\nsignificantly improves the reliability and flexibility of energy supply,\nthrough resource sharing and ensuring backup during outages. The dispatch of\nMGCs is the key challenge to be tackled to ensure their secure and economic\noperation. Currently, there is a lack of optimization method that can achieve a\ntrade-off among top-priority requirements of MGCs' dispatch, including fast\ncomputation speed, optimality, multiple objectives, and risk mitigation against\nuncertainty. In this paper, a novel Multi-Objective, Risk-Sensitive, and Online\nTrust Region Policy Optimization (RS-TRPO) Algorithm is proposed to tackle this\nproblem. First, a dispatch paradigm for autonomous MGs in the MGC is proposed,\nenabling them sequentially implement their self-dispatch to mitigate potential\nconflicts. This dispatch paradigm is then formulated as a Markov Game model,\nwhich is finally solved by the RS-TRPO algorithm. This online algorithm enables\nMGs to spontaneously search for the Pareto Frontier considering multiple\nobjectives and risk mitigation. The outstanding computational performance of\nthis algorithm is demonstrated in comparison with mathematical programming\nmethods and heuristic algorithms in a modified IEEE 30-Bus Test System\nintegrated with four autonomous MGs.",
            "author": [
                "Ziqing Zhu",
                "Xiang Gao",
                "Siqi Bu",
                "Ka Wing Chan",
                "Bin Zhou",
                "Shiwei Xia"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10997v1",
                "http://arxiv.org/pdf/2310.10997v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11476v1",
            "title": "Program Translation via Code Distillation",
            "updated": "2023-10-17T04:59:15Z",
            "published": "2023-10-17T04:59:15Z",
            "summary": "Software version migration and program translation are an important and\ncostly part of the lifecycle of large codebases. Traditional machine\ntranslation relies on parallel corpora for supervised translation, which is not\nfeasible for program translation due to a dearth of aligned data. Recent\nunsupervised neural machine translation techniques have overcome data\nlimitations by included techniques such as back translation and low level\ncompiler intermediate representations (IR). These methods face significant\nchallenges due to the noise in code snippet alignment and the diversity of IRs\nrespectively. In this paper we propose a novel model called Code Distillation\n(CoDist) whereby we capture the semantic and structural equivalence of code in\na language agnostic intermediate representation. Distilled code serves as a\ntranslation pivot for any programming language, leading by construction to\nparallel corpora which scale to all available source code by simply applying\nthe distillation compiler. We demonstrate that our approach achieves\nstate-of-the-art performance on CodeXGLUE and TransCoder GeeksForGeeks\ntranslation benchmarks, with an average absolute increase of 12.7% on the\nTransCoder GeeksforGeeks translation benchmark compare to TransCoder-ST.",
            "author": [
                "Yufan Huang",
                "Mengnan Qi",
                "Yongqiang Yao",
                "Maoquan Wang",
                "Bin Gu",
                "Colin Clement",
                "Neel Sundaresan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11476v1",
                "http://arxiv.org/pdf/2310.11476v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10989v1",
            "title": "WGoM: A novel model for categorical data with weighted responses",
            "updated": "2023-10-17T04:23:31Z",
            "published": "2023-10-17T04:23:31Z",
            "summary": "The Graded of Membership (GoM) model is a powerful tool for inferring latent\nclasses in categorical data, which enables subjects to belong to multiple\nlatent classes. However, its application is limited to categorical data with\nnonnegative integer responses, making it inappropriate for datasets with\ncontinuous or negative responses. To address this limitation, this paper\nproposes a novel model named the Weighted Grade of Membership (WGoM) model.\nCompared with GoM, our WGoM relaxes GoM's distribution constraint on the\ngeneration of a response matrix and it is more general than GoM. We then\npropose an algorithm to estimate the latent mixed memberships and the other\nWGoM parameters. We derive the error bounds of the estimated parameters and\nshow that the algorithm is statistically consistent. The algorithmic\nperformance is validated in both synthetic and real-world datasets. The results\ndemonstrate that our algorithm is accurate and efficient, indicating its high\npotential for practical applications. This paper makes a valuable contribution\nto the literature by introducing a novel model that extends the applicability\nof the GoM model and provides a more flexible framework for analyzing\ncategorical data with weighted responses.",
            "author": [
                "Huan Qing"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10989v1",
                "http://arxiv.org/pdf/2310.10989v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10987v1",
            "title": "Why Do Students Drop Out? University Dropout Prediction and Associated\n  Factor Analysis Using Machine Learning Techniques",
            "updated": "2023-10-17T04:20:00Z",
            "published": "2023-10-17T04:20:00Z",
            "summary": "Graduation and dropout rates have always been a serious consideration for\neducational institutions and students. High dropout rates negatively impact\nboth the lives of individual students and institutions. To address this\nproblem, this study examined university dropout prediction using academic,\ndemographic, socioeconomic, and macroeconomic data types. Additionally, we\nperformed associated factor analysis to analyze which type of data would be\nmost influential on the performance of machine learning models in predicting\ngraduation and dropout status. These features were used to train four binary\nclassifiers to determine if students would graduate or drop out. The overall\nperformance of the classifiers in predicting dropout status had an average\nROC-AUC score of 0.935. The data type most influential to the model performance\nwas found to be academic data, with the average ROC-AUC score dropping from\n0.935 to 0.811 when excluding all academic-related features from the data set.\nPreliminary results indicate that a correlation does exist between data types\nand dropout status.",
            "author": [
                "Sean Kim",
                "Eliot Yoo",
                "Samuel Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10987v1",
                "http://arxiv.org/pdf/2310.10987v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10984v1",
            "title": "Latent class analysis with weighted responses",
            "updated": "2023-10-17T04:16:20Z",
            "published": "2023-10-17T04:16:20Z",
            "summary": "The latent class model has been proposed as a powerful tool for cluster\nanalysis of categorical data in various fields such as social, psychological,\nbehavioral, and biological sciences. However, one important limitation of the\nlatent class model is that it is only suitable for data with binary responses,\nmaking it fail to model real-world data with continuous or negative responses.\nIn many applications, ignoring the weights throws out a lot of potentially\nvaluable information contained in the weights. To address this limitation, we\npropose a novel generative model, the weighted latent class model (WLCM). Our\nmodel allows data's response matrix to be generated from an arbitrary\ndistribution with a latent class structure. In comparison to the latent class\nmodel, our WLCM is more realistic and more general. To our knowledge, our WLCM\nis the first model for latent class analysis with weighted responses. We\ninvestigate the identifiability of the model and propose an efficient algorithm\nfor estimating the latent classes and other model parameters. We show that the\nproposed algorithm enjoys consistent estimation. The performance of the\nproposed algorithm is investigated using both computer-generated and real-world\nweighted response data.",
            "author": [
                "Huan Qing"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10984v1",
                "http://arxiv.org/pdf/2310.10984v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10976v1",
            "title": "Exact nonlinear state estimation",
            "updated": "2023-10-17T03:44:29Z",
            "published": "2023-10-17T03:44:29Z",
            "summary": "The majority of data assimilation (DA) methods in the geosciences are based\non Gaussian assumptions. While these assumptions facilitate efficient\nalgorithms, they cause analysis biases and subsequent forecast degradations.\nNon-parametric, particle-based DA algorithms have superior accuracy, but their\napplication to high-dimensional models still poses operational challenges.\nDrawing inspiration from recent advances in the field of generative artificial\nintelligence (AI), this article introduces a new nonlinear estimation theory\nwhich attempts to bridge the existing gap in DA methodology. Specifically, a\nConjugate Transform Filter (CTF) is derived and shown to generalize the\ncelebrated Kalman filter to arbitrarily non-Gaussian distributions. The new\nfilter has several desirable properties, such as its ability to preserve\nstatistical relationships in the prior state and convergence to highly accurate\nobservations. An ensemble approximation of the new theory (ECTF) is also\npresented and validated using idealized statistical experiments that feature\nbounded quantities with non-Gaussian distributions, a prevalent challenge in\nEarth system models. Results from these experiments indicate that the greatest\nbenefits from ECTF occur when observation errors are small relative to the\nforecast uncertainty and when state variables exhibit strong nonlinear\ndependencies. Ultimately, the new filtering theory offers exciting avenues for\nimproving conventional DA algorithms through their principled integration with\nAI techniques.",
            "author": [
                "Hristo G. Chipilski"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10976v1",
                "http://arxiv.org/pdf/2310.10976v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "cs.CE",
                "cs.LG",
                "math.DS",
                "physics.ao-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10975v2",
            "title": "NICE: Improving Panoptic Narrative Detection and Segmentation with\n  Cascading Collaborative Learning",
            "updated": "2023-10-23T10:34:34Z",
            "published": "2023-10-17T03:42:12Z",
            "summary": "Panoptic Narrative Detection (PND) and Segmentation (PNS) are two challenging\ntasks that involve identifying and locating multiple targets in an image\naccording to a long narrative description. In this paper, we propose a unified\nand effective framework called NICE that can jointly learn these two panoptic\nnarrative recognition tasks. Existing visual grounding tasks use a two-branch\nparadigm, but applying this directly to PND and PNS can result in prediction\nconflict due to their intrinsic many-to-many alignment property. To address\nthis, we introduce two cascading modules based on the barycenter of the mask,\nwhich are Coordinate Guided Aggregation (CGA) and Barycenter Driven\nLocalization (BDL), responsible for segmentation and detection, respectively.\nBy linking PNS and PND in series with the barycenter of segmentation as the\nanchor, our approach naturally aligns the two tasks and allows them to\ncomplement each other for improved performance. Specifically, CGA provides the\nbarycenter as a reference for detection, reducing BDL's reliance on a large\nnumber of candidate boxes. BDL leverages its excellent properties to\ndistinguish different instances, which improves the performance of CGA for\nsegmentation. Extensive experiments demonstrate that NICE surpasses all\nexisting methods by a large margin, achieving 4.1% for PND and 2.9% for PNS\nover the state-of-the-art. These results validate the effectiveness of our\nproposed collaborative learning strategy. The project of this work is made\npublicly available at https://github.com/Mr-Neko/NICE.",
            "author": [
                "Haowei Wang",
                "Jiayi Ji",
                "Tianyu Guo",
                "Yilong Yang",
                "Yiyi Zhou",
                "Xiaoshuai Sun",
                "Rongrong Ji"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10975v2",
                "http://arxiv.org/pdf/2310.10975v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10971v1",
            "title": "Context-Aware Meta-Learning",
            "updated": "2023-10-17T03:35:27Z",
            "published": "2023-10-17T03:35:27Z",
            "summary": "Large Language Models like ChatGPT demonstrate a remarkable capacity to learn\nnew concepts during inference without any fine-tuning. However, visual models\ntrained to detect new objects during inference have been unable to replicate\nthis ability, and instead either perform poorly or require meta-training and/or\nfine-tuning on similar objects. In this work, we propose a meta-learning\nalgorithm that emulates Large Language Models by learning new visual concepts\nduring inference without fine-tuning. Our approach leverages a frozen\npre-trained feature extractor, and analogous to in-context learning, recasts\nmeta-learning as sequence modeling over datapoints with known labels and a test\ndatapoint with an unknown label. On 8 out of 11 meta-learning benchmarks, our\napproach -- without meta-training or fine-tuning -- exceeds or matches the\nstate-of-the-art algorithm, P>M>F, which is meta-trained on these benchmarks.",
            "author": [
                "Christopher Fifty",
                "Dennis Duan",
                "Ronald G. Junkins",
                "Ehsan Amid",
                "Jure Leskovec",
                "Christopher R\u00e9",
                "Sebastian Thrun"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10971v1",
                "http://arxiv.org/pdf/2310.10971v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10970v2",
            "title": "Deep Learning based Spatially Dependent Acoustical Properties Recovery",
            "updated": "2023-11-23T00:02:55Z",
            "published": "2023-10-17T03:31:47Z",
            "summary": "The physics-informed neural network (PINN) is capable of recovering partial\ndifferential equation (PDE) coefficients that remain constant throughout the\nspatial domain directly from physical measurements. In this work, we propose a\nspatially dependent physics-informed neural network (SD-PINN), which enables\nthe recovery of coefficients in spatially-dependent PDEs using a single neural\nnetwork, eliminating the requirement for domain-specific physical expertise. We\napply the SD-PINN to spatially-dependent wave equation coefficients recovery to\nreveal the spatial distribution of acoustical properties in the inhomogeneous\nmedium. The proposed method exhibits robustness to noise owing to the\nincorporation of a loss function for the physical constraint that the assumed\nPDE must be satisfied. For the coefficients recovery of spatially\ntwo-dimensional PDEs, we store the PDE coefficients at all locations in the 2D\nregion of interest into a matrix and incorporate the low-rank assumption for\nsuch a matrix to recover the coefficients at locations without available\nmeasurements.",
            "author": [
                "Ruixian Liu",
                "Peter Gerstoft"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10970v2",
                "http://arxiv.org/pdf/2310.10970v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10969v1",
            "title": "On the spectrum of the Hodge Laplacian on sequences",
            "updated": "2023-10-17T03:30:51Z",
            "published": "2023-10-17T03:30:51Z",
            "summary": "Hodge Laplacians have been previously proposed as a natural tool for\nunderstanding higher-order interactions in networks and directed graphs. Here\nwe introduce a Hodge-theoretic approach to spectral theory and dimensionality\nreduction for probability distributions on sequences and simplicial complexes.\nWe demonstrate that this Hodge theory has desirable properties with respect to\nnatural null-models, where the underlying vertices are independent.\n  We prove that for the case of independent vertices in simplicial complexes,\nthe appropriate Laplacians are multiples of the identity and thus have no\nmeaningful Fourier modes. For the null model of independent vertices in\nsequences, we prove that the appropriate Hodge Laplacian has an integer\nspectrum, and describe its eigenspaces. We also prove that the underlying cell\ncomplex of sequences has trivial reduced homology. Our results establish a\nfoundation for developing Fourier analyses of probabilistic models, which are\ncommon in theoretical neuroscience and machine-learning.",
            "author": [
                "Hannah Santa Cruz Baur",
                "Vladimir Itskov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10969v1",
                "http://arxiv.org/pdf/2310.10969v1"
            ],
            "primary_category": "math.AT",
            "category": [
                "math.AT",
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10965v1",
            "title": "The neural network models with delays for solving absolute value\n  equations",
            "updated": "2023-10-17T03:26:35Z",
            "published": "2023-10-17T03:26:35Z",
            "summary": "An inverse-free neural network model with mixed delays is proposed for\nsolving the absolute value equation (AVE) $Ax -|x| - b =0$, which includes an\ninverse-free neural network model with discrete delay as a special case. By\nusing the Lyapunov-Krasovskii theory and the linear matrix inequality (LMI)\nmethod, the developed neural network models are proved to be exponentially\nconvergent to the solution of the AVE. Compared with the existing neural\nnetwork models for solving the AVE, the proposed models feature the ability of\nsolving a class of AVE with $\\|A^{-1}\\|>1$. Numerical simulations are given to\nshow the effectiveness of the two delayed neural network models.",
            "author": [
                "Dongmei Yu",
                "Gehao Zhang",
                "Cairong Chen",
                "Deren Han"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10965v1",
                "http://arxiv.org/pdf/2310.10965v1"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS",
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10963v1",
            "title": "MRI brain tumor segmentation using informative feature vectors and\n  kernel dictionary learning",
            "updated": "2023-10-17T03:25:22Z",
            "published": "2023-10-17T03:25:22Z",
            "summary": "This paper presents a method based on a kernel dictionary learning algorithm\nfor segmenting brain tumor regions in magnetic resonance images (MRI). A set of\nfirst-order and second-order statistical feature vectors are extracted from\npatches of size 3 * 3 around pixels in the brain MRI scans. These feature\nvectors are utilized to train two kernel dictionaries separately for healthy\nand tumorous tissues. To enhance the efficiency of the dictionaries and reduce\ntraining time, a correlation-based sample selection technique is developed to\nidentify the most informative and discriminative subset of feature vectors.\nThis technique aims to improve the performance of the dictionaries by selecting\na subset of feature vectors that provide valuable information for the\nsegmentation task. Subsequently, a linear classifier is utilized to distinguish\nbetween healthy and unhealthy pixels based on the learned dictionaries. The\nresults demonstrate that the proposed method outperforms other existing methods\nin terms of segmentation accuracy and significantly reduces both the time and\nmemory required, resulting in a remarkably fast training process.",
            "author": [
                "Seyedeh Mahya Mousavi",
                "Mohammad Mostafavi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10963v1",
                "http://arxiv.org/pdf/2310.10963v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10962v1",
            "title": "Semantic-Aware Contrastive Sentence Representation Learning with Large\n  Language Models",
            "updated": "2023-10-17T03:21:43Z",
            "published": "2023-10-17T03:21:43Z",
            "summary": "Contrastive learning has been proven to be effective in learning better\nsentence representations. However, to train a contrastive learning model, large\nnumbers of labeled sentences are required to construct positive and negative\npairs explicitly, such as those in natural language inference (NLI) datasets.\nUnfortunately, acquiring sufficient high-quality labeled data can be both\ntime-consuming and resource-intensive, leading researchers to focus on\ndeveloping methods for learning unsupervised sentence representations. As there\nis no clear relationship between these unstructured randomly-sampled sentences,\nbuilding positive and negative pairs over them is tricky and problematic. To\ntackle these challenges, in this paper, we propose SemCSR, a semantic-aware\ncontrastive sentence representation framework. By leveraging the generation and\nevaluation capabilities of large language models (LLMs), we can automatically\nconstruct a high-quality NLI-style corpus without any human annotation, and\nfurther incorporate the generated sentence pairs into learning a contrastive\nsentence representation model. Extensive experiments and comprehensive analyses\ndemonstrate the effectiveness of our proposed framework for learning a better\nsentence representation with LLMs.",
            "author": [
                "Huiming Wang",
                "Liying Cheng",
                "Zhaodonghui Li",
                "De Wen Soh",
                "Lidong Bing"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10962v1",
                "http://arxiv.org/pdf/2310.10962v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10961v1",
            "title": "Stealthy Terrain-Aware Multi-Agent Active Search",
            "updated": "2023-10-17T03:20:53Z",
            "published": "2023-10-17T03:20:53Z",
            "summary": "Stealthy multi-agent active search is the problem of making efficient\nsequential data-collection decisions to identify an unknown number of sparsely\nlocated targets while adapting to new sensing information and concealing the\nsearch agents' location from the targets. This problem is applicable to\nreconnaissance tasks wherein the safety of the search agents can be compromised\nas the targets may be adversarial. Prior work usually focuses either on\nadversarial search, where the risk of revealing the agents' location to the\ntargets is ignored or evasion strategies where efficient search is ignored. We\npresent the Stealthy Terrain-Aware Reconnaissance (STAR) algorithm, a\nmulti-objective parallelized Thompson sampling-based algorithm that relies on a\nstrong topographical prior to reason over changing visibility risk over the\ncourse of the search. The STAR algorithm outperforms existing state-of-the-art\nmulti-agent active search methods on both rate of recovery of targets as well\nas minimising risk even when subject to noisy observations, communication\nfailures and an unknown number of targets.",
            "author": [
                "Nikhil Angad Bakshi",
                "Jeff Schneider"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10961v1",
                "http://arxiv.org/pdf/2310.10961v1"
            ],
            "primary_category": "cs.MA",
            "category": [
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10959v1",
            "title": "Origami-inspired Bi-directional Actuator with Orthogonal Actuation",
            "updated": "2023-10-17T03:16:27Z",
            "published": "2023-10-17T03:16:27Z",
            "summary": "Origami offers a promising alternative for designing innovative soft robotic\nactuators. While features of origami, such as bi-directional motion and\nstructural anisotropy, haven't been extensively explored in the past, this\nletter presents a novel design inspired by origami tubes for a bi-directional\nactuator. This actuator is capable of moving in two orthogonal directions and\nhas separate channels throughout its body to control each movement. We\nintroduce a bottom-up design methodology that can also be adapted for other\ncomplex movements. The actuator was manufactured using popular 3D printing\ntechniques. To enhance its durability, we experimented with different 3D\nprinting technologies and materials. The actuator's strength was further\nimproved using silicon spin coating, and we compared the performance of coated,\nuncoated, and silicon-only specimens. The material model was empirically\nderived by testing specimens on a universal testing machine (UTM). Lastly, we\nsuggest potential applications for these actuators, such as in quadruped\nrobots.",
            "author": [
                "Shuai Liu",
                "Sheeraz Athar",
                "Michael Yu Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10959v1",
                "http://arxiv.org/pdf/2310.10959v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10958v1",
            "title": "Enhancing Deep Neural Network Training Efficiency and Performance\n  through Linear Prediction",
            "updated": "2023-10-17T03:11:30Z",
            "published": "2023-10-17T03:11:30Z",
            "summary": "Deep neural networks (DNN) have achieved remarkable success in various\nfields, including computer vision and natural language processing. However,\ntraining an effective DNN model still poses challenges. This paper aims to\npropose a method to optimize the training effectiveness of DNN, with the goal\nof improving model performance. Firstly, based on the observation that the DNN\nparameters change in certain laws during training process, the potential of\nparameter prediction for improving model training efficiency and performance is\ndiscovered. Secondly, considering the magnitude of DNN model parameters,\nhardware limitations and characteristics of Stochastic Gradient Descent (SGD)\nfor noise tolerance, a Parameter Linear Prediction (PLP) method is exploit to\nperform DNN parameter prediction. Finally, validations are carried out on some\nrepresentative backbones. Experiment results show that compare to the normal\ntraining ways, under the same training conditions and epochs, by employing\nproposed PLP method, the optimal model is able to obtain average about 1%\naccuracy improvement and 0.01 top-1/top-5 error reduction for Vgg16, Resnet18\nand GoogLeNet based on CIFAR-100 dataset, which shown the effectiveness of the\nproposed method on different DNN structures, and validated its capacity in\nenhancing DNN training efficiency and performance.",
            "author": [
                "Hejie Ying",
                "Mengmeng Song",
                "Yaohong Tang",
                "Shungen Xiao",
                "Zimin Xiao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10958v1",
                "http://arxiv.org/pdf/2310.10958v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10957v1",
            "title": "Medical Image Segmentation via Sparse Coding Decoder",
            "updated": "2023-10-17T03:08:35Z",
            "published": "2023-10-17T03:08:35Z",
            "summary": "Transformers have achieved significant success in medical image segmentation,\nowing to its capability to capture long-range dependencies. Previous works\nincorporate convolutional layers into the encoder module of transformers,\nthereby enhancing their ability to learn local relationships among pixels.\nHowever, transformers may suffer from limited generalization capabilities and\nreduced robustness, attributed to the insufficient spatial recovery ability of\ntheir decoders. To address this issue, A convolution sparse vector coding based\ndecoder is proposed , namely CAScaded multi-layer Convolutional Sparse vector\nCoding DEcoder (CASCSCDE), which represents features extracted by the encoder\nusing sparse vectors. To prove the effectiveness of our CASCSCDE, The\nwidely-used TransUNet model is chosen for the demonstration purpose, and the\nCASCSCDE is incorporated with TransUNet to establish the TransCASCSCDE\narchitecture. Our experiments demonstrate that TransUNet with CASCSCDE\nsignificantly enhances performance on the Synapse benchmark, obtaining up to\n3.15\\% and 1.16\\% improvements in DICE and mIoU scores, respectively. CASCSCDE\nopens new ways for constructing decoders based on convolutional sparse vector\ncoding.",
            "author": [
                "Long Zeng",
                "Kaigui Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10957v1",
                "http://arxiv.org/pdf/2310.10957v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "68T07, 68U10",
                "I.4.6; I.4.7; I.5.1"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10955v1",
            "title": "A State-Vector Framework for Dataset Effects",
            "updated": "2023-10-17T03:05:06Z",
            "published": "2023-10-17T03:05:06Z",
            "summary": "The impressive success of recent deep neural network (DNN)-based systems is\nsignificantly influenced by the high-quality datasets used in training.\nHowever, the effects of the datasets, especially how they interact with each\nother, remain underexplored. We propose a state-vector framework to enable\nrigorous studies in this direction. This framework uses idealized probing test\nresults as the bases of a vector space. This framework allows us to quantify\nthe effects of both standalone and interacting datasets. We show that the\nsignificant effects of some commonly-used language understanding datasets are\ncharacteristic and are concentrated on a few linguistic dimensions.\nAdditionally, we observe some ``spill-over'' effects: the datasets could impact\nthe models along dimensions that may seem unrelated to the intended tasks. Our\nstate-vector framework paves the way for a systematic understanding of the\ndataset effects, a crucial component in responsible and robust model\ndevelopment.",
            "author": [
                "Esmat Sahak",
                "Zining Zhu",
                "Frank Rudzicz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10955v1",
                "http://arxiv.org/pdf/2310.10955v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10953v1",
            "title": "A Local Graph Limits Perspective on Sampling-Based GNNs",
            "updated": "2023-10-17T02:58:49Z",
            "published": "2023-10-17T02:58:49Z",
            "summary": "We propose a theoretical framework for training Graph Neural Networks (GNNs)\non large input graphs via training on small, fixed-size sampled subgraphs. This\nframework is applicable to a wide range of models, including popular\nsampling-based GNNs, such as GraphSAGE and FastGCN. Leveraging the theory of\ngraph local limits, we prove that, under mild assumptions, parameters learned\nfrom training sampling-based GNNs on small samples of a large input graph are\nwithin an $\\epsilon$-neighborhood of the outcome of training the same\narchitecture on the whole graph. We derive bounds on the number of samples, the\nsize of the graph, and the training steps required as a function of $\\epsilon$.\nOur results give a novel theoretical understanding for using sampling in\ntraining GNNs. They also suggest that by training GNNs on small samples of the\ninput graph, practitioners can identify and select the best models,\nhyperparameters, and sampling algorithms more efficiently. We empirically\nillustrate our results on a node classification task on large citation graphs,\nobserving that sampling-based GNNs trained on local subgraphs 12$\\times$\nsmaller than the original graph achieve comparable performance to those trained\non the input graph.",
            "author": [
                "Yeganeh Alimohammadi",
                "Luana Ruiz",
                "Amin Saberi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10953v1",
                "http://arxiv.org/pdf/2310.10953v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10952v1",
            "title": "Restricted Tweedie Stochastic Block Models",
            "updated": "2023-10-17T02:58:03Z",
            "published": "2023-10-17T02:58:03Z",
            "summary": "The stochastic block model (SBM) is a widely used framework for community\ndetection in networks, where the network structure is typically represented by\nan adjacency matrix. However, conventional SBMs are not directly applicable to\nan adjacency matrix that consists of non-negative zero-inflated continuous edge\nweights. To model the international trading network, where edge weights\nrepresent trading values between countries, we propose an innovative SBM based\non a restricted Tweedie distribution. Additionally, we incorporate nodal\ninformation, such as the geographical distance between countries, and account\nfor its dynamic effect on edge weights. Notably, we show that given a\nsufficiently large number of nodes, estimating this covariate effect becomes\nindependent of community labels of each node when computing the maximum\nlikelihood estimator of parameters in our model. This result enables the\ndevelopment of an efficient two-step algorithm that separates the estimation of\ncovariate effects from other parameters. We demonstrate the effectiveness of\nour proposed method through extensive simulation studies and an application to\nreal-world international trading data.",
            "author": [
                "Jie Jian",
                "Mu Zhu",
                "Peijun Sang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10952v1",
                "http://arxiv.org/pdf/2310.10952v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "stat.AP",
                "stat.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10948v1",
            "title": "Combat Urban Congestion via Collaboration: Heterogeneous GNN-based MARL\n  for Coordinated Platooning and Traffic Signal Control",
            "updated": "2023-10-17T02:46:04Z",
            "published": "2023-10-17T02:46:04Z",
            "summary": "Over the years, reinforcement learning has emerged as a popular approach to\ndevelop signal control and vehicle platooning strategies either independently\nor in a hierarchical way. However, jointly controlling both in real-time to\nalleviate traffic congestion presents new challenges, such as the inherent\nphysical and behavioral heterogeneity between signal control and platooning, as\nwell as coordination between them. This paper proposes an innovative solution\nto tackle these challenges based on heterogeneous graph multi-agent\nreinforcement learning and traffic theories. Our approach involves: 1)\ndesigning platoon and signal control as distinct reinforcement learning agents\nwith their own set of observations, actions, and reward functions to optimize\ntraffic flow; 2) designing coordination by incorporating graph neural networks\nwithin multi-agent reinforcement learning to facilitate seamless information\nexchange among agents on a regional scale. We evaluate our approach through\nSUMO simulation, which shows a convergent result in terms of various\ntransportation metrics and better performance over sole signal or platooning\ncontrol.",
            "author": [
                "Xianyue Peng",
                "Hang Gao",
                "Hao Wang",
                "H. Michael Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10948v1",
                "http://arxiv.org/pdf/2310.10948v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10946v1",
            "title": "Multi-point Feedback of Bandit Convex Optimization with Hard Constraints",
            "updated": "2023-10-17T02:43:22Z",
            "published": "2023-10-17T02:43:22Z",
            "summary": "This paper studies bandit convex optimization with constraints, where the\nlearner aims to generate a sequence of decisions under partial information of\nloss functions such that the cumulative loss is reduced as well as the\ncumulative constraint violation is simultaneously reduced. We adopt the\ncumulative \\textit{hard} constraint violation as the metric of constraint\nviolation, which is defined by $\\sum_{t=1}^{T} \\max\\{g_t(\\boldsymbol{x}_t),\n0\\}$. Owing to the maximum operator, a strictly feasible solution cannot cancel\nout the effects of violated constraints compared to the conventional metric\nknown as \\textit{long-term} constraints violation. We present a penalty-based\nproximal gradient descent method that attains a sub-linear growth of both\nregret and cumulative hard constraint violation, in which the gradient is\nestimated with a two-point function evaluation. Precisely, our algorithm\nattains $O(d^2T^{\\max\\{c,1-c\\}})$ regret bounds and $O(d^2T^{1-\\frac{c}{2}})$\ncumulative hard constraint violation bounds for convex loss functions and\ntime-varying constraints, where $d$ is the dimensionality of the feasible\nregion and $c\\in[\\frac{1}{2}, 1)$ is a user-determined parameter. We also\nextend the result for the case where the loss functions are strongly convex and\nshow that both regret and constraint violation bounds can be further reduced.",
            "author": [
                "Yasunari Hikima"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10946v1",
                "http://arxiv.org/pdf/2310.10946v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09233v1",
            "title": "Neural Packing: from Visual Sensing to Reinforcement Learning",
            "updated": "2023-10-17T02:42:54Z",
            "published": "2023-10-17T02:42:54Z",
            "summary": "We present a novel learning framework to solve the transport-and-packing\n(TAP) problem in 3D. It constitutes a full solution pipeline from partial\nobservations of input objects via RGBD sensing and recognition to final box\nplacement, via robotic motion planning, to arrive at a compact packing in a\ntarget container. The technical core of our method is a neural network for TAP,\ntrained via reinforcement learning (RL), to solve the NP-hard combinatorial\noptimization problem. Our network simultaneously selects an object to pack and\ndetermines the final packing location, based on a judicious encoding of the\ncontinuously evolving states of partially observed source objects and available\nspaces in the target container, using separate encoders both enabled with\nattention mechanisms. The encoded feature vectors are employed to compute the\nmatching scores and feasibility masks of different pairings of box selection\nand available space configuration for packing strategy optimization. Extensive\nexperiments, including ablation studies and physical packing execution by a\nreal robot (Universal Robot UR5e), are conducted to evaluate our method in\nterms of its design choices, scalability, generalizability, and comparisons to\nbaselines, including the most recent RL-based TAP solution. We also contribute\nthe first benchmark for TAP which covers a variety of input settings and\ndifficulty levels.",
            "author": [
                "Juzhan Xu",
                "Minglun Gong",
                "Hao Zhang",
                "Hui Huang",
                "Ruizhen Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09233v1",
                "http://arxiv.org/pdf/2311.09233v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.GR",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10943v2",
            "title": "Reaching the Limit in Autonomous Racing: Optimal Control versus\n  Reinforcement Learning",
            "updated": "2023-10-18T14:32:37Z",
            "published": "2023-10-17T02:40:27Z",
            "summary": "A central question in robotics is how to design a control system for an agile\nmobile robot. This paper studies this question systematically, focusing on a\nchallenging setting: autonomous drone racing. We show that a neural network\ncontroller trained with reinforcement learning (RL) outperformed optimal\ncontrol (OC) methods in this setting. We then investigated which fundamental\nfactors have contributed to the success of RL or have limited OC. Our study\nindicates that the fundamental advantage of RL over OC is not that it optimizes\nits objective better but that it optimizes a better objective. OC decomposes\nthe problem into planning and control with an explicit intermediate\nrepresentation, such as a trajectory, that serves as an interface. This\ndecomposition limits the range of behaviors that can be expressed by the\ncontroller, leading to inferior control performance when facing unmodeled\neffects. In contrast, RL can directly optimize a task-level objective and can\nleverage domain randomization to cope with model uncertainty, allowing the\ndiscovery of more robust control responses. Our findings allowed us to push an\nagile drone to its maximum performance, achieving a peak acceleration greater\nthan 12 times the gravitational acceleration and a peak velocity of 108\nkilometers per hour. Our policy achieved superhuman control within minutes of\ntraining on a standard workstation. This work presents a milestone in agile\nrobotics and sheds light on the role of RL and OC in robot control.",
            "author": [
                "Yunlong Song",
                "Angel Romero",
                "Matthias Mueller",
                "Vladlen Koltun",
                "Davide Scaramuzza"
            ],
            "link": [
                "http://dx.doi.org/10.1126/scirobotics.adg1462",
                "http://arxiv.org/abs/2310.10943v2",
                "http://arxiv.org/pdf/2310.10943v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10941v1",
            "title": "MASON-NLP at eRisk 2023: Deep Learning-Based Detection of Depression\n  Symptoms from Social Media Texts",
            "updated": "2023-10-17T02:34:34Z",
            "published": "2023-10-17T02:34:34Z",
            "summary": "Depression is a mental health disorder that has a profound impact on people's\nlives. Recent research suggests that signs of depression can be detected in the\nway individuals communicate, both through spoken words and written texts. In\nparticular, social media posts are a rich and convenient text source that we\nmay examine for depressive symptoms. The Beck Depression Inventory (BDI)\nQuestionnaire, which is frequently used to gauge the severity of depression, is\none instrument that can aid in this study. We can narrow our study to only\nthose symptoms since each BDI question is linked to a particular depressive\nsymptom. It's important to remember that not everyone with depression exhibits\nall symptoms at once, but rather a combination of them. Therefore, it is\nextremely useful to be able to determine if a sentence or a piece of\nuser-generated content is pertinent to a certain condition. With this in mind,\nthe eRisk 2023 Task 1 was designed to do exactly that: assess the relevance of\ndifferent sentences to the symptoms of depression as outlined in the BDI\nquestionnaire. This report is all about how our team, Mason-NLP, participated\nin this subtask, which involved identifying sentences related to different\ndepression symptoms. We used a deep learning approach that incorporated\nMentalBERT, RoBERTa, and LSTM. Despite our efforts, the evaluation results were\nlower than expected, underscoring the challenges inherent in ranking sentences\nfrom an extensive dataset about depression, which necessitates both appropriate\nmethodological choices and significant computational resources. We anticipate\nthat future iterations of this shared task will yield improved results as our\nunderstanding and techniques evolve.",
            "author": [
                "Fardin Ahsan Sakib",
                "Ahnaf Atef Choudhury",
                "Ozlem Uzuner"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10941v1",
                "http://arxiv.org/pdf/2310.10941v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10939v1",
            "title": "Fast and Simple Spectral Clustering in Theory and Practice",
            "updated": "2023-10-17T02:31:57Z",
            "published": "2023-10-17T02:31:57Z",
            "summary": "Spectral clustering is a popular and effective algorithm designed to find $k$\nclusters in a graph $G$. In the classical spectral clustering algorithm, the\nvertices of $G$ are embedded into $\\mathbb{R}^k$ using $k$ eigenvectors of the\ngraph Laplacian matrix. However, computing this embedding is computationally\nexpensive and dominates the running time of the algorithm. In this paper, we\npresent a simple spectral clustering algorithm based on a vertex embedding with\n$O(\\log(k))$ vectors computed by the power method. The vertex embedding is\ncomputed in nearly-linear time with respect to the size of the graph, and the\nalgorithm provably recovers the ground truth clusters under natural assumptions\non the input graph. We evaluate the new algorithm on several synthetic and\nreal-world datasets, finding that it is significantly faster than alternative\nclustering algorithms, while producing results with approximately the same\nclustering accuracy.",
            "author": [
                "Peter Macgregor"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10939v1",
                "http://arxiv.org/pdf/2310.10939v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10935v1",
            "title": "Intent Detection and Slot Filling for Home Assistants: Dataset and\n  Analysis for Bangla and Sylheti",
            "updated": "2023-10-17T02:12:12Z",
            "published": "2023-10-17T02:12:12Z",
            "summary": "As voice assistants cement their place in our technologically advanced\nsociety, there remains a need to cater to the diverse linguistic landscape,\nincluding colloquial forms of low-resource languages. Our study introduces the\nfirst-ever comprehensive dataset for intent detection and slot filling in\nformal Bangla, colloquial Bangla, and Sylheti languages, totaling 984 samples\nacross 10 unique intents. Our analysis reveals the robustness of large language\nmodels for tackling downstream tasks with inadequate data. The GPT-3.5 model\nachieves an impressive F1 score of 0.94 in intent detection and 0.51 in slot\nfilling for colloquial Bangla.",
            "author": [
                "Fardin Ahsan Sakib",
                "A H M Rezaul Karim",
                "Saadat Hasan Khan",
                "Md Mushfiqur Rahman"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10935v1",
                "http://arxiv.org/pdf/2310.10935v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10930v1",
            "title": "Enhanced Transformer Architecture for Natural Language Processing",
            "updated": "2023-10-17T01:59:07Z",
            "published": "2023-10-17T01:59:07Z",
            "summary": "Transformer is a state-of-the-art model in the field of natural language\nprocessing (NLP). Current NLP models primarily increase the number of\ntransformers to improve processing performance. However, this technique\nrequires a lot of training resources such as computing capacity. In this paper,\na novel structure of Transformer is proposed. It is featured by full layer\nnormalization, weighted residual connection, positional encoding exploiting\nreinforcement learning, and zero masked self-attention. The proposed\nTransformer model, which is called Enhanced Transformer, is validated by the\nbilingual evaluation understudy (BLEU) score obtained with the Multi30k\ntranslation dataset. As a result, the Enhanced Transformer achieves 202.96%\nhigher BLEU score as compared to the original transformer with the translation\ndataset.",
            "author": [
                "Woohyeon Moon",
                "Taeyoung Kim",
                "Bumgeun Park",
                "Dongsoo Har"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10930v1",
                "http://arxiv.org/pdf/2310.10930v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10928v1",
            "title": "Using Audio Data to Facilitate Depression Risk Assessment in Primary\n  Health Care",
            "updated": "2023-10-17T01:55:49Z",
            "published": "2023-10-17T01:55:49Z",
            "summary": "Telehealth is a valuable tool for primary health care (PHC), where depression\nis a common condition. PHC is the first point of contact for most people with\ndepression, but about 25% of diagnoses made by PHC physicians are inaccurate.\nMany other barriers also hinder depression detection and treatment in PHC.\nArtificial intelligence (AI) may help reduce depression misdiagnosis in PHC and\nimprove overall diagnosis and treatment outcomes. Telehealth consultations\noften have video issues, such as poor connectivity or dropped calls. Audio-only\ntelehealth is often more practical for lower-income patients who may lack\nstable internet connections. Thus, our study focused on using audio data to\npredict depression risk. The objectives were to: 1) Collect audio data from 24\npeople (12 with depression and 12 without mental health or major health\ncondition diagnoses); 2) Build a machine learning model to predict depression\nrisk. TPOT, an autoML tool, was used to select the best machine learning\nalgorithm, which was the K-nearest neighbors classifier. The selected model had\nhigh performance in classifying depression risk (Precision: 0.98, Recall: 0.93,\nF1-Score: 0.96). These findings may lead to a range of tools to help screen for\nand treat depression. By developing tools to detect depression risk, patients\ncan be routed to AI-driven chatbots for initial screenings. Partnerships with a\nrange of stakeholders are crucial to implementing these solutions. Moreover,\nethical considerations, especially around data privacy and potential biases in\nAI models, need to be at the forefront of any AI-driven intervention in mental\nhealth care.",
            "author": [
                "Adam Valen Levinson",
                "Abhay Goyal",
                "Roger Ho Chun Man",
                "Roy Ka-Wei Lee",
                "Koustuv Saha",
                "Nimay Parekh",
                "Frederick L. Altice",
                "Lam Yin Cheung",
                "Munmun De Choudhury",
                "Navin Kumar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10928v1",
                "http://arxiv.org/pdf/2310.10928v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10922v1",
            "title": "Spatial HuBERT: Self-supervised Spatial Speech Representation Learning\n  for a Single Talker from Multi-channel Audio",
            "updated": "2023-10-17T01:31:59Z",
            "published": "2023-10-17T01:31:59Z",
            "summary": "Self-supervised learning has been used to leverage unlabelled data, improving\naccuracy and generalisation of speech systems through the training of\nrepresentation models. While many recent works have sought to produce effective\nrepresentations across a variety of acoustic domains, languages, modalities and\neven simultaneous speakers, these studies have all been limited to\nsingle-channel audio recordings. This paper presents Spatial HuBERT, a\nself-supervised speech representation model that learns both acoustic and\nspatial information pertaining to a single speaker in a potentially noisy\nenvironment by using multi-channel audio inputs. Spatial HuBERT learns\nrepresentations that outperform state-of-the-art single-channel speech\nrepresentations on a variety of spatial downstream tasks, particularly in\nreverberant and noisy environments. We also demonstrate the utility of the\nrepresentations learned by Spatial HuBERT on a speech localisation downstream\ntask. Along with this paper, we publicly release a new dataset of 100 000\nsimulated first-order ambisonics room impulse responses.",
            "author": [
                "Antoni Dimitriadis",
                "Siqi Pan",
                "Vidhyasaharan Sethu",
                "Beena Ahmed"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10922v1",
                "http://arxiv.org/pdf/2310.10922v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13011v1",
            "title": "Compositional preference models for aligning LMs",
            "updated": "2023-10-17T01:31:59Z",
            "published": "2023-10-17T01:31:59Z",
            "summary": "As language models (LMs) become more capable, it is increasingly important to\nalign them with human preferences. However, the dominant paradigm for training\nPreference Models (PMs) for that purpose suffers from fundamental limitations,\nsuch as lack of transparency and scalability, along with susceptibility to\noverfitting the preference dataset. We propose Compositional Preference Models\n(CPMs), a novel PM framework that decomposes one global preference assessment\ninto several interpretable features, obtains scalar scores for these features\nfrom a prompted LM, and aggregates these scores using a logistic regression\nclassifier. CPMs allow to control which properties of the preference data are\nused to train the preference model and to build it based on features that are\nbelieved to underlie the human preference judgment. Our experiments show that\nCPMs not only improve generalization and are more robust to overoptimization\nthan standard PMs, but also that best-of-n samples obtained using CPMs tend to\nbe preferred over samples obtained using conventional PMs. Overall, our\napproach demonstrates the benefits of endowing PMs with priors about which\nfeatures determine human preferences while relying on LM capabilities to\nextract those features in a scalable and robust way.",
            "author": [
                "Dongyoung Go",
                "Tomasz Korbak",
                "Germ\u00e1n Kruszewski",
                "Jos Rozen",
                "Marc Dymetman"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13011v1",
                "http://arxiv.org/pdf/2310.13011v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10921v1",
            "title": "Intelligent Software Tooling for Improving Software Development",
            "updated": "2023-10-17T01:29:07Z",
            "published": "2023-10-17T01:29:07Z",
            "summary": "Software has eaten the world with many of the necessities and quality of life\nservices people use requiring software. Therefore, tools that improve the\nsoftware development experience can have a significant impact on the world such\nas generating code and test cases, detecting bugs, question and answering,\netc., The success of Deep Learning (DL) over the past decade has shown huge\nadvancements in automation across many domains, including Software Development\nprocesses. One of the main reasons behind this success is the availability of\nlarge datasets such as open-source code available through GitHub or image\ndatasets of mobile Graphical User Interfaces (GUIs) with RICO and ReDRAW to be\ntrained on. Therefore, the central research question my dissertation explores\nis: In what ways can the software development process be improved through\nleveraging DL techniques on the vast amounts of unstructured software\nengineering artifacts?",
            "author": [
                "Nathan Cooper"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10921v1",
                "http://arxiv.org/pdf/2310.10921v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10910v1",
            "title": "Machine Learning in the Quantum Age: Quantum vs. Classical Support\n  Vector Machines",
            "updated": "2023-10-17T01:06:59Z",
            "published": "2023-10-17T01:06:59Z",
            "summary": "This work endeavors to juxtapose the efficacy of machine learning algorithms\nwithin classical and quantum computational paradigms. Particularly, by\nemphasizing on Support Vector Machines (SVM), we scrutinize the classification\nprowess of classical SVM and Quantum Support Vector Machines (QSVM) operational\non quantum hardware over the Iris dataset. The methodology embraced\nencapsulates an extensive array of experiments orchestrated through the Qiskit\nlibrary, alongside hyperparameter optimization. The findings unveil that in\nparticular scenarios, QSVMs extend a level of accuracy that can vie with\nclassical SVMs, albeit the execution times are presently protracted. Moreover,\nwe underscore that augmenting quantum computational capacity and the magnitude\nof parallelism can markedly ameliorate the performance of quantum machine\nlearning algorithms. This inquiry furnishes invaluable insights regarding the\nextant scenario and future potentiality of machine learning applications in the\nquantum epoch. Colab: https://t.ly/QKuz0",
            "author": [
                "Davut Emre Tasar",
                "Kutan Koruyan",
                "Ceren Ocal Tasar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10910v1",
                "http://arxiv.org/pdf/2310.10910v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10909v1",
            "title": "Heterogenous Memory Augmented Neural Networks",
            "updated": "2023-10-17T01:05:28Z",
            "published": "2023-10-17T01:05:28Z",
            "summary": "It has been shown that semi-parametric methods, which combine standard neural\nnetworks with non-parametric components such as external memory modules and\ndata retrieval, are particularly helpful in data scarcity and\nout-of-distribution (OOD) scenarios. However, existing semi-parametric methods\nmostly depend on independent raw data points - this strategy is difficult to\nscale up due to both high computational costs and the incapacity of current\nattention mechanisms with a large number of tokens. In this paper, we introduce\na novel heterogeneous memory augmentation approach for neural networks which,\nby introducing learnable memory tokens with attention mechanism, can\neffectively boost performance without huge computational overhead. Our\ngeneral-purpose method can be seamlessly combined with various backbones (MLP,\nCNN, GNN, and Transformer) in a plug-and-play manner. We extensively evaluate\nour approach on various image and graph-based tasks under both in-distribution\n(ID) and OOD conditions and show its competitive performance against\ntask-specific state-of-the-art methods. Code is available at\n\\url{https://github.com/qiuzh20/HMA}.",
            "author": [
                "Zihan Qiu",
                "Zhen Liu",
                "Shuicheng Yan",
                "Shanghang Zhang",
                "Jie Fu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10909v1",
                "http://arxiv.org/pdf/2310.10909v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10908v1",
            "title": "Emergent Mixture-of-Experts: Can Dense Pre-trained Transformers Benefit\n  from Emergent Modular Structures?",
            "updated": "2023-10-17T01:02:32Z",
            "published": "2023-10-17T01:02:32Z",
            "summary": "Incorporating modular designs into neural networks demonstrates superior\nout-of-generalization, learning efficiency, etc. Existing modular neural\nnetworks are generally $\\textit{explicit}$ because their modular architectures\nare pre-defined, and individual modules are expected to implement distinct\nfunctions. Conversely, recent works reveal that there exist $\\textit{implicit}$\nmodular structures in standard pre-trained transformers, namely\n$\\textit{Emergent Modularity}$. They indicate that such modular structures\nexhibit during the early pre-training phase and are totally spontaneous.\nHowever, most transformers are still treated as monolithic models with their\nmodular natures underutilized. Therefore, given the excellent properties of\nexplicit modular architecture, we explore $\\textit{whether and how dense\npre-trained transformers can benefit from emergent modular structures.}$ To\nstudy this question, we construct \\textbf{E}mergent\n$\\textbf{M}$ixture-$\\textbf{o}$f-$\\textbf{E}$xperts (EMoE). Without introducing\nadditional parameters, EMoE can be seen as the modular counterpart of the\noriginal model and can be effortlessly incorporated into downstream tuning.\nExtensive experiments (we tune 1785 models) on various downstream tasks (vision\nand language) and models (22M to1.5B) demonstrate that EMoE effectively boosts\nin-domain and out-of-domain generalization abilities. Further analysis and\nablation study suggest that EMoE mitigates negative knowledge transfer and is\nrobust to various configurations. Code is available at\n\\url{https://github.com/qiuzh20/EMoE}",
            "author": [
                "Zihan Qiu",
                "Zeyu Huang",
                "Jie Fu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10908v1",
                "http://arxiv.org/pdf/2310.10908v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10907v2",
            "title": "Surrogate Active Subspaces for Jump-Discontinuous Functions",
            "updated": "2023-10-18T14:33:27Z",
            "published": "2023-10-17T00:44:51Z",
            "summary": "Surrogate modeling and active subspaces have emerged as powerful paradigms in\ncomputational science and engineering. Porting such techniques to computational\nmodels in the social sciences brings into sharp relief their limitations in\ndealing with discontinuous simulators, such as Agent-Based Models, which have\ndiscrete outputs. Nevertheless, prior applied work has shown that surrogate\nestimates of active subspaces for such estimators can yield interesting\nresults. But given that active subspaces are defined by way of gradients, it is\nnot clear what quantity is being estimated when this methodology is applied to\na discontinuous simulator. We begin this article by showing some pathologies\nthat can arise when conducting such an analysis. This motivates an extension of\nactive subspaces to discontinuous functions, clarifying what is actually being\nestimated in such analyses. We also conduct numerical experiments on synthetic\ntest functions to compare Gaussian process estimates of active subspaces on\ncontinuous and discontinuous functions. Finally, we deploy our methodology on\nFlee, an agent-based model of refugee movement, yielding novel insights into\nwhich parameters of the simulation are most important across 8 displacement\ncrises in Africa and the Middle East.",
            "author": [
                "Nathan Wycoff"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10907v2",
                "http://arxiv.org/pdf/2310.10907v2"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10899v1",
            "title": "Instilling Inductive Biases with Subnetworks",
            "updated": "2023-10-17T00:12:19Z",
            "published": "2023-10-17T00:12:19Z",
            "summary": "Despite the recent success of artificial neural networks on a variety of\ntasks, we have little knowledge or control over the exact solutions these\nmodels implement. Instilling inductive biases -- preferences for some solutions\nover others -- into these models is one promising path toward understanding and\ncontrolling their behavior. Much work has been done to study the inherent\ninductive biases of models and instill different inductive biases through\nhand-designed architectures or carefully curated training regimens. In this\nwork, we explore a more mechanistic approach: Subtask Induction. Our method\ndiscovers a functional subnetwork that implements a particular subtask within a\ntrained model and uses it to instill inductive biases towards solutions\nutilizing that subtask. Subtask Induction is flexible and efficient, and we\ndemonstrate its effectiveness with two experiments. First, we show that Subtask\nInduction significantly reduces the amount of training data required for a\nmodel to adopt a specific, generalizable solution to a modular arithmetic task.\nSecond, we demonstrate that Subtask Induction successfully induces a human-like\nshape bias while increasing data efficiency for convolutional and\ntransformer-based image classification models.",
            "author": [
                "Enyan Zhang",
                "Michael A. Lepori",
                "Ellie Pavlick"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10899v1",
                "http://arxiv.org/pdf/2310.10899v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10898v1",
            "title": "Analyzing Modularity Maximization in Approximation, Heuristic, and Graph\n  Neural Network Algorithms for Community Detection",
            "updated": "2023-10-17T00:12:18Z",
            "published": "2023-10-17T00:12:18Z",
            "summary": "Community detection, a fundamental problem in computational sciences, finds\napplications in various domains. Heuristics are often employed to detect\ncommunities through maximizing an objective function, modularity, over\npartitions of network nodes. Our research delves into the performance of\ndifferent modularity maximization algorithms in achieving optimal partitions.\nWe use 104 networks, comprising real-world instances from diverse contexts and\nsynthetic graphs with modular structures. We analyze ten inexact\nmodularity-based algorithms against an exact baseline which is an exact integer\nprogramming method that globally optimizes modularity. The ten algorithms\nanalyzed include eight heuristics, two variations of a graph neural network\nalgorithm, and several variations of the Bayan approximation algorithm. Our\nanalysis uncovers substantial dissimilarities between the partitions obtained\nby most commonly used modularity-based methods and any optimal partition of the\nnetworks, as indicated by both adjusted and reduced mutual information metrics.\nImportantly, our results show that near-optimal partitions are often\ndisproportionately dissimilar to any optimal partition. Taken together, our\nanalysis points to a crucial limitation of the commonly used unguaranteed\nmodularity-based methods for discovering communities: they rarely produce an\noptimal partition or a partition resembling an optimal partition even on\nnetworks with modular structures. If modularity is to be used for detecting\ncommunities, approximate optimization algorithms are recommendable for a more\nmethodologically sound usage of modularity within its applicability limits.",
            "author": [
                "Samin Aref",
                "Mahdi Mostajabdaveh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10898v1",
                "http://arxiv.org/pdf/2310.10898v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cond-mat.stat-mech",
                "cs.LG",
                "math.OC",
                "90C90, 90C10, 90C57, 90C59, 90C35, 05C15, 65K05"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10895v1",
            "title": "Fibration symmetry uncovers minimal regulatory networks for logical\n  computation in bacteria",
            "updated": "2023-10-17T00:05:01Z",
            "published": "2023-10-17T00:05:01Z",
            "summary": "Symmetry principles have proven important in physics, deep learning and\ngeometry, allowing for the reduction of complicated systems to simpler, more\ncomprehensible models that preserve the system's features of interest.\nBiological systems often show a high level of complexity and consist of a high\nnumber of interacting parts. Using symmetry fibrations, the relevant symmetries\nfor biological 'message-passing' networks, we reduced the gene regulatory\nnetworks of E. coli and B. subtilis bacteria in a way that preserves\ninformation flow and highlights the computational capabilities of the network.\nNodes that share isomorphic input trees are grouped into equivalence classes\ncalled fibers, whereby genes that receive signals with the same 'history'\nbelong to one fiber and synchronize. We further reduce the networks to its\ncomputational core by removing 'dangling ends' via k-core decomposition. The\ncomputational core of the network consists of a few strongly connected\ncomponents in which signals can cycle while signals are transmitted between\nthese 'information vortices' in a linear feed-forward manner. These components\nare in charge of decision making in the bacterial cell by employing a series of\ngenetic toggle-switch circuits that store memory, and oscillator circuits.\nThese circuits act as the central computation machine of the network, whose\noutput signals then spread to the rest of the network.",
            "author": [
                "Luis A. \u00c1lvarez-Garc\u00eda",
                "Wolfram Liebermeister",
                "Ian Leifer",
                "Hern\u00e1n A. Makse"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10895v1",
                "http://arxiv.org/pdf/2310.10895v1"
            ],
            "primary_category": "q-bio.CB",
            "category": [
                "q-bio.CB",
                "q-bio.MN"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10893v2",
            "title": "Active Learning Framework for Cost-Effective TCR-Epitope Binding\n  Affinity Prediction",
            "updated": "2023-10-30T17:06:32Z",
            "published": "2023-10-16T23:53:07Z",
            "summary": "T cell receptors (TCRs) are critical components of adaptive immune systems,\nresponsible for responding to threats by recognizing epitope sequences\npresented on host cell surface. Computational prediction of binding affinity\nbetween TCRs and epitope sequences using machine/deep learning has attracted\nintense attention recently. However, its success is hindered by the lack of\nlarge collections of annotated TCR-epitope pairs. Annotating their binding\naffinity requires expensive and time-consuming wet-lab evaluation. To reduce\nannotation cost, we present ActiveTCR, a framework that incorporates active\nlearning and TCR-epitope binding affinity prediction models. Starting with a\nsmall set of labeled training pairs, ActiveTCR iteratively searches for\nunlabeled TCR-epitope pairs that are ''worth'' for annotation. It aims to\nmaximize performance gains while minimizing the cost of annotation. We compared\nfour query strategies with a random sampling baseline and demonstrated that\nActiveTCR reduces annotation costs by approximately 40%. Furthermore, we showed\nthat providing ground truth labels of TCR-epitope pairs to query strategies can\nhelp identify and reduce more than 40% redundancy among already annotated pairs\nwithout compromising model performance, enabling users to train equally\npowerful prediction models with less training data. Our work is the first\nsystematic investigation of data optimization for TCR-epitope binding affinity\nprediction.",
            "author": [
                "Pengfei Zhang",
                "Seojin Bang",
                "Heewook Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10893v2",
                "http://arxiv.org/pdf/2310.10893v2"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10886v1",
            "title": "The Calysto Scheme Project",
            "updated": "2023-10-16T23:41:21Z",
            "published": "2023-10-16T23:41:21Z",
            "summary": "Calysto Scheme is written in Scheme in Continuation-Passing Style, and\nconverted through a series of correctness-preserving program transformations\ninto Python. It has support for standard Scheme functionality, including\ncall/cc, as well as syntactic extensions, a nondeterministic operator for\nautomatic backtracking, and many extensions to allow Python interoperation.\nBecause of its Python foundation, it can take advantage of modern Python\nlibraries, including those for machine learning and other pedagogical contexts.\nAlthough Calysto Scheme was developed with educational purposes in mind, it has\nproven to be generally useful due to its simplicity and ease of installation.\nIt has been integrated into the Jupyter Notebook ecosystem and used in the\nclassroom to teach introductory Programming Languages with some interesting and\nunique twists.",
            "author": [
                "Douglas S. Blank",
                "James B. Marshall"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10886v1",
                "http://arxiv.org/pdf/2310.10886v1"
            ],
            "primary_category": "cs.PL",
            "category": [
                "cs.PL",
                "cs.LG",
                "D.3.0"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10732v2",
            "title": "White Paper: The Generative Education (GenEd) Framework",
            "updated": "2023-11-22T16:07:26Z",
            "published": "2023-10-16T23:30:42Z",
            "summary": "The Generative Education (GenEd) Framework explores the transition from Large\nLanguage Models (LLMs) to Large Multimodal Models (LMMs) in education,\nenvisioning a harmonious relationship between AI and educators to enhance\nlearning experiences. This paper delves into the potential of LMMs to create\npersonalized, interactive, and emotionally-aware learning environments. Through\naddressing the Two-Sigma problem and the introduction of a conceptual product\nnamed Harmony, the narrative emphasizes educator development, adapting policy\nframeworks, and fostering cross-sector collaboration to realize the envisioned\nAI-enhanced education landscape. The discussion underscores the urgency for\nproactive adaptation amidst AI's evolution, offering a pragmatic roadmap to\nnavigate the technical, ethical, and policy intricacies of integrating AI in\neducation.",
            "author": [
                "Daniel Leiker"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10732v2",
                "http://arxiv.org/pdf/2311.10732v2"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10879v1",
            "title": "BLoad: Enhancing Neural Network Training with Efficient Sequential Data\n  Handling",
            "updated": "2023-10-16T23:14:56Z",
            "published": "2023-10-16T23:14:56Z",
            "summary": "The increasing complexity of modern deep neural network models and the\nexpanding sizes of datasets necessitate the development of optimized and\nscalable training methods. In this white paper, we addressed the challenge of\nefficiently training neural network models using sequences of varying sizes. To\naddress this challenge, we propose a novel training scheme that enables\nefficient distributed data-parallel training on sequences of different sizes\nwith minimal overhead. By using this scheme we were able to reduce the padding\namount by more than 100$x$ while not deleting a single frame, resulting in an\noverall increased performance on both training time and Recall in our\nexperiments.",
            "author": [
                "Raphael Ruschel",
                "A. S. M. Iftekhar",
                "B. S. Manjunath",
                "Suya You"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10879v1",
                "http://arxiv.org/pdf/2310.10879v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10878v1",
            "title": "Eco-Driving Control of Connected and Automated Vehicles using Neural\n  Network based Rollout",
            "updated": "2023-10-16T23:13:51Z",
            "published": "2023-10-16T23:13:51Z",
            "summary": "Connected and autonomous vehicles have the potential to minimize energy\nconsumption by optimizing the vehicle velocity and powertrain dynamics with\nVehicle-to-Everything info en route. Existing deterministic and stochastic\nmethods created to solve the eco-driving problem generally suffer from high\ncomputational and memory requirements, which makes online implementation\nchallenging.\n  This work proposes a hierarchical multi-horizon optimization framework\nimplemented via a neural network. The neural network learns a full-route value\nfunction to account for the variability in route information and is then used\nto approximate the terminal cost in a receding horizon optimization.\nSimulations over real-world routes demonstrate that the proposed approach\nachieves comparable performance to a stochastic optimization solution obtained\nvia reinforcement learning, while requiring no sophisticated training paradigm\nand negligible on-board memory.",
            "author": [
                "Jacob Paugh",
                "Zhaoxuan Zhu",
                "Shobhit Gupta",
                "Marcello Canova",
                "Stephanie Stockar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10878v1",
                "http://arxiv.org/pdf/2310.10878v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10875v1",
            "title": "Filling the Holes on 3D Heritage Object Surface based on Automatic\n  Segmentation Algorithm",
            "updated": "2023-10-16T23:01:39Z",
            "published": "2023-10-16T23:01:39Z",
            "summary": "Reconstructing and processing the 3D objects are popular activities in the\nresearch field of computer graphics, image processing and computer vision. The\n3D objects are processed based on the methods like geometric modeling, a branch\nof applied mathematics and computational geometry, or the machine learning\nalgorithms based on image processing. The computation of geometrical objects\nincludes processing the curves and surfaces, subdivision, simplification,\nmeshing, holes filling, reconstructing, and refining the 3D surface objects on\nboth point cloud data and triangular mesh. While the machine learning methods\nare developed using deep learning models. With the support of 3D laser scan\ndevices and Lidar techniques, the obtained dataset is close to original shape\nof the real objects. Besides, the photography and its application based on the\nmodern techniques in recent years help us collect data and process the 3D\nmodels more precise. This article proposes an improved method for filling holes\non the 3D object surface based on an automatic segmentation. Instead of filling\nthe hole directly as the existing methods, we now subdivide the hole before\nfilling it. The hole is first determined and segmented automatically based on\ncomputation of its local curvature. It is then filled on each part of the hole\nto match its local curvature shape. The method can work on both 3D point cloud\nsurfaces and triangular mesh surface. Comparing to the state of the art\nmethods, our proposed method obtained higher accuracy of the reconstructed 3D\nobjects.",
            "author": [
                "Sinh Van Nguyen",
                "Son Thanh Le",
                "Minh Khai Tran",
                "Le Thanh Sach"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10875v1",
                "http://arxiv.org/pdf/2310.10875v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10874v1",
            "title": "Religious Affiliation in the Twenty-First Century: A Machine Learning\n  Perspective on the World Value Survey",
            "updated": "2023-10-16T23:01:16Z",
            "published": "2023-10-16T23:01:16Z",
            "summary": "This paper is a quantitative analysis of the data collected globally by the\nWorld Value Survey. The data is used to study the trajectories of change in\nindividuals' religious beliefs, values, and behaviors in societies. Utilizing\nrandom forest, we aim to identify the key factors of religiosity and classify\nrespondents of the survey as religious and non religious using country level\ndata. We use resampling techniques to balance the data and improve imbalanced\nlearning performance metrics. The results of the variable importance analysis\nsuggest that Age and Income are the most important variables in the majority of\ncountries. The results are discussed with fundamental sociological theories\nregarding religion and human behavior. This study is an application of machine\nlearning in identifying the underlying patterns in the data of 30 countries\nparticipating in the World Value Survey. The results from variable importance\nanalysis and classification of imbalanced data provide valuable insights\nbeneficial to theoreticians and researchers of social sciences.",
            "author": [
                "Elaheh Jafarigol",
                "William Keely",
                "Tess Hartog",
                "Tom Welborn",
                "Peyman Hekmatpour",
                "Theodore B. Trafalis"
            ],
            "link": [
                "http://dx.doi.org/10.1007/s12115-023-00887-0",
                "http://arxiv.org/abs/2310.10874v1",
                "http://arxiv.org/pdf/2310.10874v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10873v1",
            "title": "IDEAL: Influence-Driven Selective Annotations Empower In-Context\n  Learners in Large Language Models",
            "updated": "2023-10-16T22:53:54Z",
            "published": "2023-10-16T22:53:54Z",
            "summary": "In-context learning is a promising paradigm that utilizes in-context examples\nas prompts for the predictions of large language models. These prompts are\ncrucial for achieving strong performance. However, since the prompts need to be\nsampled from a large volume of annotated examples, finding the right prompt may\nresult in high annotation costs. To address this challenge, this paper\nintroduces an influence-driven selective annotation method that aims to\nminimize annotation costs while improving the quality of in-context examples.\nThe essence of our method is to select a pivotal subset from a large-scale\nunlabeled data pool to annotate for the subsequent sampling of prompts.\nSpecifically, a directed graph is first constructed to represent unlabeled\ndata. Afterward, the influence of candidate unlabeled subsets is quantified\nwith a diffusion process. A simple yet effective greedy algorithm for unlabeled\ndata selection is lastly introduced. It iteratively selects the data if it\nprovides a maximum marginal gain with respect to quantified influence. Compared\nwith previous efforts on selective annotations, our influence-driven method\nworks in an end-to-end manner, avoids an intractable explicit balance between\ndata diversity and representativeness, and enjoys theoretical support.\nExperiments confirm the superiority of the proposed method on various\nbenchmarks, achieving better performance under lower time consumption during\nsubset selection. The project page is available at\nhttps://skzhang1.github.io/IDEAL/.",
            "author": [
                "Shaokun Zhang",
                "Xiaobo Xia",
                "Zhaoqing Wang",
                "Ling-Hao Chen",
                "Jiale Liu",
                "Qingyun Wu",
                "Tongliang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10873v1",
                "http://arxiv.org/pdf/2310.10873v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10869v1",
            "title": "Approximation properties of slice-matching operators",
            "updated": "2023-10-16T22:32:43Z",
            "published": "2023-10-16T22:32:43Z",
            "summary": "Iterative slice-matching procedures are efficient schemes for transferring a\nsource measure to a target measure, especially in high dimensions. These\nschemes have been successfully used in applications such as color transfer and\nshape retrieval, and are guaranteed to converge under regularity assumptions.\nIn this paper, we explore approximation properties related to a single step of\nsuch iterative schemes by examining an associated slice-matching operator,\ndepending on a source measure, a target measure, and slicing directions. In\nparticular, we demonstrate an invariance property with respect to the source\nmeasure, an equivariance property with respect to the target measure, and\nLipschitz continuity concerning the slicing directions. We furthermore\nestablish error bounds corresponding to approximating the target measure by one\nstep of the slice-matching scheme and characterize situations in which the\nslice-matching operator recovers the optimal transport map between two\nmeasures. We also investigate connections to affine registration problems with\nrespect to (sliced) Wasserstein distances. These connections can be also be\nviewed as extensions to the invariance and equivariance properties of the\nslice-matching operator and illustrate the extent to which slice-matching\nschemes incorporate affine effects.",
            "author": [
                "Shiying Li",
                "Caroline Moosmueller"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10869v1",
                "http://arxiv.org/pdf/2310.10869v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.CV",
                "cs.NA",
                "math.OC",
                "stat.ML",
                "49Q22, 68T10, 41A65, 65D18"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10867v1",
            "title": "Evolving Horizons in Radiotherapy Auto-Contouring: Distilling Insights,\n  Embracing Data-Centric Frameworks, and Moving Beyond Geometric Quantification",
            "updated": "2023-10-16T22:30:29Z",
            "published": "2023-10-16T22:30:29Z",
            "summary": "Deep learning has significantly advanced the potential for automated\ncontouring in radiotherapy planning. In this manuscript, guided by contemporary\nliterature, we underscore three key insights: (1) High-quality training data is\nessential for auto-contouring algorithms; (2) Auto-contouring models\ndemonstrate commendable performance even with limited medical image data; (3)\nThe quantitative performance of auto-contouring is reaching a plateau. Given\nthese insights, we emphasize the need for the radiotherapy research community\nto embrace data-centric approaches to further foster clinical adoption of\nauto-contouring technologies.",
            "author": [
                "Kareem A. Wahid",
                "Carlos E. Cardenas",
                "Barbara Marquez",
                "Tucker J. Netherton",
                "Benjamin H. Kann",
                "Laurence E. Court",
                "Renjie He",
                "Mohamed A. Naser",
                "Amy C. Moreno",
                "Clifton D. Fuller",
                "David Fuentes"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10867v1",
                "http://arxiv.org/pdf/2310.10867v1"
            ],
            "primary_category": "physics.med-ph",
            "category": [
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10865v2",
            "title": "Will the Prince Get True Love's Kiss? On the Model Sensitivity to Gender\n  Perturbation over Fairytale Texts",
            "updated": "2023-11-15T21:32:28Z",
            "published": "2023-10-16T22:25:09Z",
            "summary": "Recent studies show that traditional fairytales are rife with harmful gender\nbiases. To help mitigate these gender biases in fairytales, this work aims to\nassess learned biases of language models by evaluating their robustness against\ngender perturbations. Specifically, we focus on Question Answering (QA) tasks\nin fairytales. Using counterfactual data augmentation to the FairytaleQA\ndataset, we evaluate model robustness against swapped gender character\ninformation, and then mitigate learned biases by introducing counterfactual\ngender stereotypes during training time. We additionally introduce a novel\napproach that utilizes the massive vocabulary of language models to support\ntext genres beyond fairytales. Our experimental results suggest that models are\nsensitive to gender perturbations, with significant performance drops compared\nto the original testing set. However, when first fine-tuned on a counterfactual\ntraining dataset, models are less sensitive to the later introduced anti-gender\nstereotyped text.",
            "author": [
                "Christina Chance",
                "Da Yin",
                "Dakuo Wang",
                "Kai-Wei Chang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10865v2",
                "http://arxiv.org/pdf/2310.10865v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03366v1",
            "title": "Neural Rankers for Code Generation via Inter-Cluster Modeling",
            "updated": "2023-10-16T22:20:31Z",
            "published": "2023-10-16T22:20:31Z",
            "summary": "Code Large Language Models (CodeLLMs) have ushered in a new era of code\ngeneration advancements. However, selecting the best solutions from among all\npossible CodeLLM solutions remains a challenge. Previous methods frequently\noverlooked the intricate functional similarities and interactions between\nclusters, resulting in suboptimal results. In this work, we introduce\n\\textit{SRank}, a novel reranking strategy for selecting the best solution from\ncode generation that focuses on modeling inter-cluster relationship. By\nquantifying the functional overlap between clusters, our approach provides a\nbetter ranking strategy of code solutions. Empirical results show that our\nmethod achieves a remarkable results on pass@1 score. For instance, on the\nHuman-Eval benchmark, we achieve 69.66\\% in pass@1 with Codex002, 75.31\\% for\nWizardCoder, 53.99\\% for StarCoder and 60.55\\% for CodeGen, which surpass the\nstate-of-the-arts solution ranking methods, such as CodeT and Coder-Reviewer on\nthe same CodeLLM with significant margin ($\\approx 6.1\\%$ improvement on\naverage). Comparing to the random sampling method, we can achieve an average\nimprovement of $\\approx 23.07\\%$ on Human-Eval and 17.64\\% on MBPP. Even in\nscenarios with limited test inputs, our approach demonstrates robustness and\nsuperiority, marking a new state-of-the-arts in code generation reranking.",
            "author": [
                "Hung Quoc To",
                "Minh Huynh Nguyen",
                "Nghi D. Q. Bui"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03366v1",
                "http://arxiv.org/pdf/2311.03366v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10856v1",
            "title": "Joint Optimization of Traffic Signal Control and Vehicle Routing in\n  Signalized Road Networks using Multi-Agent Deep Reinforcement Learning",
            "updated": "2023-10-16T22:10:47Z",
            "published": "2023-10-16T22:10:47Z",
            "summary": "Urban traffic congestion is a critical predicament that plagues modern road\nnetworks. To alleviate this issue and enhance traffic efficiency, traffic\nsignal control and vehicle routing have proven to be effective measures. In\nthis paper, we propose a joint optimization approach for traffic signal control\nand vehicle routing in signalized road networks. The objective is to enhance\nnetwork performance by simultaneously controlling signal timings and route\nchoices using Multi-Agent Deep Reinforcement Learning (MADRL). Signal control\nagents (SAs) are employed to establish signal timings at intersections, whereas\nvehicle routing agents (RAs) are responsible for selecting vehicle routes. By\nestablishing relevance between agents and enabling them to share observations\nand rewards, interaction and cooperation among agents are fostered, which\nenhances individual training. The Multi-Agent Advantage Actor-Critic algorithm\nis used to handle multi-agent environments, and Deep Neural Network (DNN)\nstructures are designed to facilitate the algorithm's convergence. Notably, our\nwork is the first to utilize MADRL in determining the optimal joint policy for\nsignal control and vehicle routing. Numerical experiments conducted on the\nmodified Sioux network demonstrate that our integration of signal control and\nvehicle routing outperforms controlling signal timings or vehicles' routes\nalone in enhancing traffic efficiency.",
            "author": [
                "Xianyue Peng",
                "Hang Gao",
                "Gengyue Han",
                "Hao Wang",
                "Michael Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10856v1",
                "http://arxiv.org/pdf/2310.10856v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.MA",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10850v1",
            "title": "Digital interventions and habit formation in educational technology",
            "updated": "2023-10-16T21:50:56Z",
            "published": "2023-10-16T21:50:56Z",
            "summary": "As online educational technology products have become increasingly prevalent,\nrich evidence indicates that learners often find it challenging to establish\nregular learning habits and complete their programs. Concurrently, online\nproducts geared towards entertainment and social interactions are sometimes so\neffective in increasing user engagement and creating frequent usage habits that\nthey inadvertently lead to digital addiction, especially among youth. In this\nproject, we carry out a contest-based intervention, common in the entertainment\ncontext, on an educational app for Indian children learning English.\nApproximately ten thousand randomly selected learners entered a 100-day reading\ncontest. They would win a set of physical books if they ranked sufficiently\nhigh on a leaderboard based on the amount of educational content consumed.\nTwelve weeks after the end of the contest, when the treatment group had no\nadditional incentives to use the app, they continued their engagement with it\nat a rate 75\\% higher than the control group, indicating a successful formation\nof a reading habit. In addition, we observed a 6\\% increase in retention within\nthe treatment group. These results underscore the potential of digital\ninterventions in fostering positive engagement habits with educational\ntechnology products, ultimately enhancing users' long-term learning outcomes.",
            "author": [
                "Keshav Agrawal",
                "Susan Athey",
                "Ayush Kanodia",
                "Emil Palikot"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10850v1",
                "http://arxiv.org/pdf/2310.10850v1"
            ],
            "primary_category": "econ.GN",
            "category": [
                "econ.GN",
                "q-fin.EC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10845v1",
            "title": "CoTFormer: More Tokens With Attention Make Up For Less Depth",
            "updated": "2023-10-16T21:37:34Z",
            "published": "2023-10-16T21:37:34Z",
            "summary": "The race to continually develop ever larger and deeper foundational models is\nunderway. However, techniques like the Chain-of-Thought (CoT) method continue\nto play a pivotal role in achieving optimal downstream performance. In this\nwork, we establish an approximate parallel between using chain-of-thought and\nemploying a deeper transformer. Building on this insight, we introduce\nCoTFormer, a transformer variant that employs an implicit CoT-like mechanism to\nachieve capacity comparable to a deeper model. Our empirical findings\ndemonstrate the effectiveness of CoTFormers, as they significantly outperform\nlarger standard transformers.",
            "author": [
                "Amirkeivan Mohtashami",
                "Matteo Pagliardini",
                "Martin Jaggi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10845v1",
                "http://arxiv.org/pdf/2310.10845v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10844v1",
            "title": "Survey of Vulnerabilities in Large Language Models Revealed by\n  Adversarial Attacks",
            "updated": "2023-10-16T21:37:24Z",
            "published": "2023-10-16T21:37:24Z",
            "summary": "Large Language Models (LLMs) are swiftly advancing in architecture and\ncapability, and as they integrate more deeply into complex systems, the urgency\nto scrutinize their security properties grows. This paper surveys research in\nthe emerging interdisciplinary field of adversarial attacks on LLMs, a subfield\nof trustworthy ML, combining the perspectives of Natural Language Processing\nand Security. Prior work has shown that even safety-aligned LLMs (via\ninstruction tuning and reinforcement learning through human feedback) can be\nsusceptible to adversarial attacks, which exploit weaknesses and mislead AI\nsystems, as evidenced by the prevalence of `jailbreak' attacks on models like\nChatGPT and Bard. In this survey, we first provide an overview of large\nlanguage models, describe their safety alignment, and categorize existing\nresearch based on various learning structures: textual-only attacks,\nmulti-modal attacks, and additional attack methods specifically targeting\ncomplex systems, such as federated learning or multi-agent systems. We also\noffer comprehensive remarks on works that focus on the fundamental sources of\nvulnerabilities and potential defenses. To make this field more accessible to\nnewcomers, we present a systematic review of existing works, a structured\ntypology of adversarial attack concepts, and additional resources, including\nslides for presentations on related topics at the 62nd Annual Meeting of the\nAssociation for Computational Linguistics (ACL'24).",
            "author": [
                "Erfan Shayegani",
                "Md Abdullah Al Mamun",
                "Yu Fu",
                "Pedram Zaree",
                "Yue Dong",
                "Nael Abu-Ghazaleh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10844v1",
                "http://arxiv.org/pdf/2310.10844v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10843v1",
            "title": "Probabilistic Classification by Density Estimation Using Gaussian\n  Mixture Model and Masked Autoregressive Flow",
            "updated": "2023-10-16T21:37:22Z",
            "published": "2023-10-16T21:37:22Z",
            "summary": "Density estimation, which estimates the distribution of data, is an important\ncategory of probabilistic machine learning. A family of density estimators is\nmixture models, such as Gaussian Mixture Model (GMM) by expectation\nmaximization. Another family of density estimators is the generative models\nwhich generate data from input latent variables. One of the generative models\nis the Masked Autoregressive Flow (MAF) which makes use of normalizing flows\nand autoregressive networks. In this paper, we use the density estimators for\nclassification, although they are often used for estimating the distribution of\ndata. We model the likelihood of classes of data by density estimation,\nspecifically using GMM and MAF. The proposed classifiers outperform simpler\nclassifiers such as linear discriminant analysis which model the likelihood\nusing only a single Gaussian distribution. This work opens the research door\nfor proposing other probabilistic classifiers based on joint density\nestimation.",
            "author": [
                "Benyamin Ghojogh",
                "Milad Amir Toutounchian"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10843v1",
                "http://arxiv.org/pdf/2310.10843v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10841v1",
            "title": "A Machine Learning-based Algorithm for Automated Detection of\n  Frequency-based Events in Recorded Time Series of Sensor Data",
            "updated": "2023-10-16T21:35:23Z",
            "published": "2023-10-16T21:35:23Z",
            "summary": "Automated event detection has emerged as one of the fundamental practices to\nmonitor the behavior of technical systems by means of sensor data. In the\nautomotive industry, these methods are in high demand for tracing events in\ntime series data. For assessing the active vehicle safety systems, a diverse\nrange of driving scenarios is conducted. These scenarios involve the recording\nof the vehicle's behavior using external sensors, enabling the evaluation of\noperational performance. In such setting, automated detection methods not only\naccelerate but also standardize and objectify the evaluation by avoiding\nsubjective, human-based appraisals in the data inspection. This work proposes a\nnovel event detection method that allows to identify frequency-based events in\ntime series data. To this aim, the time series data is mapped to\nrepresentations in the time-frequency domain, known as scalograms. After\nfiltering scalograms to enhance relevant parts of the signal, an object\ndetection model is trained to detect the desired event objects in the\nscalograms. For the analysis of unseen time series data, events can be detected\nin their scalograms with the trained object detection model and are thereafter\nmapped back to the time series data to mark the corresponding time interval.\nThe algorithm, evaluated on unseen datasets, achieves a precision rate of 0.97\nin event detection, providing sharp time interval boundaries whose accurate\nindication by human visual inspection is challenging. Incorporating this method\ninto the vehicle development process enhances the accuracy and reliability of\nevent detection, which holds major importance for rapid testing analysis.",
            "author": [
                "Bahareh Medghalchi",
                "Andreas Vogel"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10841v1",
                "http://arxiv.org/pdf/2310.10841v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10837v3",
            "title": "Approximating Two-Layer Feedforward Networks for Efficient Transformers",
            "updated": "2023-11-21T13:58:00Z",
            "published": "2023-10-16T21:23:16Z",
            "summary": "How to reduce compute and memory requirements of neural networks (NNs)\nwithout sacrificing performance? Many recent works use sparse Mixtures of\nExperts (MoEs) to build resource-efficient large language models (LMs). Here we\nintroduce several novel perspectives on MoEs, presenting a general framework\nthat unifies various methods to approximate two-layer NNs (e.g., feedforward\nblocks of Transformers), including product-key memories (PKMs). Leveraging\ninsights from this framework, we propose methods to improve both MoEs and PKMs.\nUnlike prior work that compares MoEs with dense baselines under the\ncompute-equal condition, our evaluation condition is parameter-equal, which is\ncrucial to properly evaluate LMs. We show that our MoEs are competitive with\nthe dense Transformer-XL on both the WikiText-103 and enwiki8 datasets at two\ndifferent scales, while being much more resource efficient. This demonstrates\nthat MoEs are relevant not only to extremely large LMs but also to any-scale\nresource-efficient LMs. Our code is public.",
            "author": [
                "R\u00f3bert Csord\u00e1s",
                "Kazuki Irie",
                "J\u00fcrgen Schmidhuber"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10837v3",
                "http://arxiv.org/pdf/2310.10837v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10836v1",
            "title": "Gaussian processes based data augmentation and expected signature for\n  time series classification",
            "updated": "2023-10-16T21:18:51Z",
            "published": "2023-10-16T21:18:51Z",
            "summary": "The signature is a fundamental object that describes paths (that is,\ncontinuous functions from an interval to a Euclidean space). Likewise, the\nexpected signature provides a statistical description of the law of stochastic\nprocesses. We propose a feature extraction model for time series built upon the\nexpected signature. This is computed through a Gaussian processes based data\naugmentation. One of the main features is that an optimal feature extraction is\nlearnt through the supervised task that uses the model.",
            "author": [
                "Marco Romito",
                "Francesco Triggiano"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10836v1",
                "http://arxiv.org/pdf/2310.10836v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10835v1",
            "title": "Provable Probabilistic Imaging using Score-Based Generative Priors",
            "updated": "2023-10-16T21:17:29Z",
            "published": "2023-10-16T21:17:29Z",
            "summary": "Estimating high-quality images while also quantifying their uncertainty are\ntwo desired features in an image reconstruction algorithm for solving ill-posed\ninverse problems. In this paper, we propose plug-and-play Monte Carlo (PMC) as\na principled framework for characterizing the space of possible solutions to a\ngeneral inverse problem. PMC is able to incorporate expressive score-based\ngenerative priors for high-quality image reconstruction while also performing\nuncertainty quantification via posterior sampling. In particular, we introduce\ntwo PMC algorithms which can be viewed as the sampling analogues of the\ntraditional plug-and-play priors (PnP) and regularization by denoising (RED)\nalgorithms. We also establish a theoretical analysis for characterizing the\nconvergence of the PMC algorithms. Our analysis provides non-asymptotic\nstationarity guarantees for both algorithms, even in the presence of\nnon-log-concave likelihoods and imperfect score networks. We demonstrate the\nperformance of the PMC algorithms on multiple representative inverse problems\nwith both linear and nonlinear forward models. Experimental results show that\nPMC significantly improves reconstruction quality and enables high-fidelity\nuncertainty quantification.",
            "author": [
                "Yu Sun",
                "Zihui Wu",
                "Yifan Chen",
                "Berthy T. Feng",
                "Katherine L. Bouman"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10835v1",
                "http://arxiv.org/pdf/2310.10835v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10833v1",
            "title": "Proper Laplacian Representation Learning",
            "updated": "2023-10-16T21:14:50Z",
            "published": "2023-10-16T21:14:50Z",
            "summary": "The ability to learn good representations of states is essential for solving\nlarge reinforcement learning problems, where exploration, generalization, and\ntransfer are particularly challenging. The Laplacian representation is a\npromising approach to address these problems by inducing intrinsic rewards for\ntemporally-extended action discovery and reward shaping, and informative state\nencoding. To obtain the Laplacian representation one needs to compute the\neigensystem of the graph Laplacian, which is often approximated through\noptimization objectives compatible with deep learning approaches. These\napproximations, however, depend on hyperparameters that are impossible to tune\nefficiently, converge to arbitrary rotations of the desired eigenvectors, and\nare unable to accurately recover the corresponding eigenvalues. In this paper\nwe introduce a theoretically sound objective and corresponding optimization\nalgorithm for approximating the Laplacian representation. Our approach\nnaturally recovers both the true eigenvectors and eigenvalues while eliminating\nthe hyperparameter dependence of previous approximations. We provide\ntheoretical guarantees for our method and we show that those results translate\nempirically into robust learning across multiple environments.",
            "author": [
                "Diego Gomez",
                "Michael Bowling",
                "Marlos C. Machado"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10833v1",
                "http://arxiv.org/pdf/2310.10833v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10831v1",
            "title": "Accurate Data-Driven Surrogates of Dynamical Systems for Forward\n  Propagation of Uncertainty",
            "updated": "2023-10-16T21:07:54Z",
            "published": "2023-10-16T21:07:54Z",
            "summary": "Stochastic collocation (SC) is a well-known non-intrusive method of\nconstructing surrogate models for uncertainty quantification. In dynamical\nsystems, SC is especially suited for full-field uncertainty propagation that\ncharacterizes the distributions of the high-dimensional primary solution fields\nof a model with stochastic input parameters. However, due to the highly\nnonlinear nature of the parameter-to-solution map in even the simplest\ndynamical systems, the constructed SC surrogates are often inaccurate. This\nwork presents an alternative approach, where we apply the SC approximation over\nthe dynamics of the model, rather than the solution. By combining the\ndata-driven sparse identification of nonlinear dynamics (SINDy) framework with\nSC, we construct dynamics surrogates and integrate them through time to\nconstruct the surrogate solutions. We demonstrate that the SC-over-dynamics\nframework leads to smaller errors, both in terms of the approximated system\ntrajectories as well as the model state distributions, when compared against\nfull-field SC applied to the solutions directly. We present numerical evidence\nof this improvement using three test problems: a chaotic ordinary differential\nequation, and two partial differential equations from solid mechanics.",
            "author": [
                "Saibal De",
                "Reese E. Jones",
                "Hemanth Kolla"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10831v1",
                "http://arxiv.org/pdf/2310.10831v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.LG",
                "cs.NA",
                "math.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10819v1",
            "title": "Elucidating the Role of Filament Turnover in Cortical Flow using\n  Simulations and Representation Learning",
            "updated": "2023-10-16T20:39:37Z",
            "published": "2023-10-16T20:39:37Z",
            "summary": "Cell polarization relies on long-range cortical flows, which are driven by\nactive stresses and resisted by the cytoskeletal network. While the general\nmechanisms that contribute to cortical flows are known, a quantitative\nunderstanding of the factors that tune flow speeds has remained lacking. Here,\nwe combine physical simulation, representation learning, and theory to\nelucidate the role of actin turnover in cortical flows. We show how turnover\ntunes the actin density and filament curvature and use representation learning\nto demonstrate that these quantities are sufficient to predict cortical flow\nspeeds. We extend a recent theory for contractility to account for filament\ncurvature in addition to the nonuniform distribution of crosslinkers along\nactin filaments due to turnover. We obtain formulas that can be used to fit\ndata from simulations and microscopy experiments. Our work provides insights\ninto the mechanisms of contractility that contribute to cortical flows and how\nthey can be controlled quantitatively.",
            "author": [
                "Yuqing Qiu",
                "Elizabeth D. White",
                "Edwin M. Munro",
                "Suriyanarayanan Vaikuntanathan",
                "Aaron R. Dinner"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10819v1",
                "http://arxiv.org/pdf/2310.10819v1"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10818v1",
            "title": "Uncertainty-aware transfer across tasks using hybrid model-based\n  successor feature reinforcement learning",
            "updated": "2023-10-16T20:37:36Z",
            "published": "2023-10-16T20:37:36Z",
            "summary": "Sample efficiency is central to developing practical reinforcement learning\n(RL) for complex and large-scale decision-making problems. The ability to\ntransfer and generalize knowledge gained from previous experiences to\ndownstream tasks can significantly improve sample efficiency. Recent research\nindicates that successor feature (SF) RL algorithms enable knowledge\ngeneralization between tasks with different rewards but identical transition\ndynamics. It has recently been hypothesized that combining model-based (MB)\nmethods with SF algorithms can alleviate the limitation of fixed transition\ndynamics. Furthermore, uncertainty-aware exploration is widely recognized as\nanother appealing approach for improving sample efficiency. Putting together\ntwo ideas of hybrid model-based successor feature (MB-SF) and uncertainty leads\nto an approach to the problem of sample efficient uncertainty-aware knowledge\ntransfer across tasks with different transition dynamics or/and reward\nfunctions. In this paper, the uncertainty of the value of each action is\napproximated by a Kalman filter (KF)-based multiple-model adaptive estimation.\nThis KF-based framework treats the parameters of a model as random variables.\nTo the best of our knowledge, this is the first attempt at formulating a hybrid\nMB-SF algorithm capable of generalizing knowledge across large or continuous\nstate space tasks with various transition dynamics while requiring less\ncomputation at decision time than MB methods. The number of samples required to\nlearn the tasks was compared to recent SF and MB baselines. The results show\nthat our algorithm generalizes its knowledge across different transition\ndynamics, learns downstream tasks with significantly fewer samples than\nstarting from scratch, and outperforms existing approaches.",
            "author": [
                "Parvin Malekzadeh",
                "Ming Hou",
                "Konstantinos N. Plataniotis"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.neucom.2023.01.076",
                "http://arxiv.org/abs/2310.10818v1",
                "http://arxiv.org/pdf/2310.10818v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10817v1",
            "title": "Exploring Documentation Usage via Page-view Log Analysis",
            "updated": "2023-10-16T20:37:29Z",
            "published": "2023-10-16T20:37:29Z",
            "summary": "Almost no modern software system is written from scratch, and developers are\nrequired to effectively learn to use third-party libraries or software\nservices. Thus, many practitioners and researchers have looked for ways to\ncreate effective documentation that supports developers' learning. However, few\nefforts have focused on how people actually use the documentation. In this\npaper, we report on an exploratory, multi-phase, mixed methods empirical study\nof documentation page-view logs from four cloud-based industrial services. By\nanalyzing page-view logs for over 100,000 users, we find diverse patterns of\ndocumentation page visits. Moreover, we show statistically that which\ndocumentation pages people visit often correlates with user characteristics\nsuch as past experience with the specific product, on the one hand, and with\nfuture adoption of the API on the other hand. We discuss the implications of\nthese results on documentation design and propose documentation page-view log\nanalysis as a feasible technique for design audits of documentation, from ones\nwritten for software developers to ones designed to support end users (e.g.,\nAdobe Photoshop).",
            "author": [
                "Daye Nam",
                "Andrew Macvean",
                "Brad Myers",
                "Bogdan Vasilescu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10817v1",
                "http://arxiv.org/pdf/2310.10817v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10810v1",
            "title": "Robust Multi-Agent Reinforcement Learning via Adversarial\n  Regularization: Theoretical Foundation and Stable Algorithms",
            "updated": "2023-10-16T20:14:06Z",
            "published": "2023-10-16T20:14:06Z",
            "summary": "Multi-Agent Reinforcement Learning (MARL) has shown promising results across\nseveral domains. Despite this promise, MARL policies often lack robustness and\nare therefore sensitive to small changes in their environment. This presents a\nserious concern for the real world deployment of MARL algorithms, where the\ntesting environment may slightly differ from the training environment. In this\nwork we show that we can gain robustness by controlling a policy's Lipschitz\nconstant, and under mild conditions, establish the existence of a Lipschitz and\nclose-to-optimal policy. Based on these insights, we propose a new robust MARL\nframework, ERNIE, that promotes the Lipschitz continuity of the policies with\nrespect to the state observations and actions by adversarial regularization.\nThe ERNIE framework provides robustness against noisy observations, changing\ntransition dynamics, and malicious actions of agents. However, ERNIE's\nadversarial regularization may introduce some training instability. To reduce\nthis instability, we reformulate adversarial regularization as a Stackelberg\ngame. We demonstrate the effectiveness of the proposed framework with extensive\nexperiments in traffic light control and particle environments. In addition, we\nextend ERNIE to mean-field MARL with a formulation based on distributionally\nrobust optimization that outperforms its non-robust counterpart and is of\nindependent interest. Our code is available at\nhttps://github.com/abukharin3/ERNIE.",
            "author": [
                "Alexander Bukharin",
                "Yan Li",
                "Yue Yu",
                "Qingru Zhang",
                "Zhehui Chen",
                "Simiao Zuo",
                "Chao Zhang",
                "Songan Zhang",
                "Tuo Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10810v1",
                "http://arxiv.org/pdf/2310.10810v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10807v1",
            "title": "Regularization properties of adversarially-trained linear regression",
            "updated": "2023-10-16T20:09:58Z",
            "published": "2023-10-16T20:09:58Z",
            "summary": "State-of-the-art machine learning models can be vulnerable to very small\ninput perturbations that are adversarially constructed. Adversarial training is\nan effective approach to defend against it. Formulated as a min-max problem, it\nsearches for the best solution when the training data were corrupted by the\nworst-case attacks. Linear models are among the simple models where\nvulnerabilities can be observed and are the focus of our study. In this case,\nadversarial training leads to a convex optimization problem which can be\nformulated as the minimization of a finite sum. We provide a comparative\nanalysis between the solution of adversarial training in linear regression and\nother regularization methods. Our main findings are that: (A) Adversarial\ntraining yields the minimum-norm interpolating solution in the\noverparameterized regime (more parameters than data), as long as the maximum\ndisturbance radius is smaller than a threshold. And, conversely, the\nminimum-norm interpolator is the solution to adversarial training with a given\nradius. (B) Adversarial training can be equivalent to parameter shrinking\nmethods (ridge regression and Lasso). This happens in the underparametrized\nregion, for an appropriate choice of adversarial radius and zero-mean\nsymmetrically distributed covariates. (C) For $\\ell_\\infty$-adversarial\ntraining -- as in square-root Lasso -- the choice of adversarial radius for\noptimal bounds does not depend on the additive noise variance. We confirm our\ntheoretical findings with numerical examples.",
            "author": [
                "Ant\u00f4nio H. Ribeiro",
                "Dave Zachariah",
                "Francis Bach",
                "Thomas B. Sch\u00f6n"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10807v1",
                "http://arxiv.org/pdf/2310.10807v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.CR",
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10806v1",
            "title": "Convolutional Neural Network Model for Diabetic Retinopathy Feature\n  Extraction and Classification",
            "updated": "2023-10-16T20:09:49Z",
            "published": "2023-10-16T20:09:49Z",
            "summary": "The application of Artificial Intelligence in the medical market brings up\nincreasing concerns but aids in more timely diagnosis of silent progressing\ndiseases like Diabetic Retinopathy. In order to diagnose Diabetic Retinopathy\n(DR), ophthalmologists use color fundus images, or pictures of the back of the\nretina, to identify small distinct features through a difficult and\ntime-consuming process. Our work creates a novel CNN model and identifies the\nseverity of DR through fundus image input. We classified 4 known DR features,\nincluding micro-aneurysms, cotton wools, exudates, and hemorrhages, through\nconvolutional layers and were able to provide an accurate diagnostic without\nadditional user input. The proposed model is more interpretable and robust to\noverfitting. We present initial results with a sensitivity of 97% and an\naccuracy of 71%. Our contribution is an interpretable model with similar\naccuracy to more complex models. With that, our model advances the field of DR\ndetection and proves to be a key step towards AI-focused medical diagnosis.",
            "author": [
                "Sharan Subramanian",
                "Leilani H. Gilpin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10806v1",
                "http://arxiv.org/pdf/2310.10806v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10803v1",
            "title": "SD-HuBERT: Self-Distillation Induces Syllabic Organization in HuBERT",
            "updated": "2023-10-16T20:05:36Z",
            "published": "2023-10-16T20:05:36Z",
            "summary": "Data-driven unit discovery in self-supervised learning (SSL) of speech has\nembarked on a new era of spoken language processing. Yet, the discovered units\noften remain in phonetic space, limiting the utility of SSL representations.\nHere, we demonstrate that a syllabic organization emerges in learning\nsentence-level representation of speech. In particular, we adopt\n\"self-distillation\" objective to fine-tune the pretrained HuBERT with an\naggregator token that summarizes the entire sentence. Without any supervision,\nthe resulting model draws definite boundaries in speech, and the\nrepresentations across frames show salient syllabic structures. We demonstrate\nthat this emergent structure largely corresponds to the ground truth syllables.\nFurthermore, we propose a new benchmark task, Spoken Speech ABX, for evaluating\nsentence-level representation of speech. When compared to previous models, our\nmodel outperforms in both unsupervised syllable discovery and learning\nsentence-level representation. Together, we demonstrate that the\nself-distillation of HuBERT gives rise to syllabic organization without relying\non external labels or modalities, and potentially provides novel data-driven\nunits for spoken language modeling.",
            "author": [
                "Cheol Jun Cho",
                "Abdelrahman Mohamed",
                "Shang-Wen Li",
                "Alan W Black",
                "Gopala K. Anumanchipalli"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10803v1",
                "http://arxiv.org/pdf/2310.10803v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10791v1",
            "title": "Neural Tangent Kernels Motivate Graph Neural Networks with\n  Cross-Covariance Graphs",
            "updated": "2023-10-16T19:54:21Z",
            "published": "2023-10-16T19:54:21Z",
            "summary": "Neural tangent kernels (NTKs) provide a theoretical regime to analyze the\nlearning and generalization behavior of over-parametrized neural networks. For\na supervised learning task, the association between the eigenvectors of the NTK\nkernel and given data (a concept referred to as alignment in this paper) can\ngovern the rate of convergence of gradient descent, as well as generalization\nto unseen data. Building upon this concept, we investigate NTKs and alignment\nin the context of graph neural networks (GNNs), where our analysis reveals that\noptimizing alignment translates to optimizing the graph representation or the\ngraph shift operator in a GNN. Our results further establish the theoretical\nguarantees on the optimality of the alignment for a two-layer GNN and these\nguarantees are characterized by the graph shift operator being a function of\nthe cross-covariance between the input and the output data. The theoretical\ninsights drawn from the analysis of NTKs are validated by our experiments\nfocused on a multi-variate time series prediction task for a publicly available\ndataset. Specifically, they demonstrate that GNNs with cross-covariance as the\ngraph shift operator indeed outperform those that operate on the covariance\nmatrix from only the input data.",
            "author": [
                "Shervin Khalafi",
                "Saurabh Sihag",
                "Alejandro Ribeiro"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10791v1",
                "http://arxiv.org/pdf/2310.10791v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10788v1",
            "title": "Self-Supervised Models of Speech Infer Universal Articulatory Kinematics",
            "updated": "2023-10-16T19:50:01Z",
            "published": "2023-10-16T19:50:01Z",
            "summary": "Self-Supervised Learning (SSL) based models of speech have shown remarkable\nperformance on a range of downstream tasks. These state-of-the-art models have\nremained blackboxes, but many recent studies have begun \"probing\" models like\nHuBERT, to correlate their internal representations to different aspects of\nspeech. In this paper, we show \"inference of articulatory kinematics\" as\nfundamental property of SSL models, i.e., the ability of these models to\ntransform acoustics into the causal articulatory dynamics underlying the speech\nsignal. We also show that this abstraction is largely overlapping across the\nlanguage of the data used to train the model, with preference to the language\nwith similar phonological system. Furthermore, we show that with simple affine\ntransformations, Acoustic-to-Articulatory inversion (AAI) is transferrable\nacross speakers, even across genders, languages, and dialects, showing the\ngeneralizability of this property. Together, these results shed new light on\nthe internals of SSL models that are critical to their superior performance,\nand open up new avenues into language-agnostic universal models for speech\nengineering, that are interpretable and grounded in speech science.",
            "author": [
                "Cheol Jun Cho",
                "Abdelrahman Mohamed",
                "Alan W Black",
                "Gopala K. Anumanchipalli"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10788v1",
                "http://arxiv.org/pdf/2310.10788v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10786v1",
            "title": "An analysis on improvement of x-ray diffractometer results by\n  controlling and calibration of parameters",
            "updated": "2023-10-16T19:46:08Z",
            "published": "2023-10-16T19:46:08Z",
            "summary": "The X-ray diffractometer in the laboratory is a crucial instrument for\nanalyzing materials in science. It can be used on almost any crystal material,\nand if the machine parameters are appropriately controlled, it can offer a lot\nof information about the samples characteristics. Nevertheless, the data\nobtained from these machines are complicated by an aberration function that can\nbe resolved through calibration. In this study, a powder comprising of Barium\nSulfate (BaSO4), Zinc Oxide (ZnO) and Aluminum (Al) was used as the first\nsample and a single crystal sample comprised of Gallium Nitride (GaN) and\nAluminum Oxide (Al2O3). The required calibration parameters of the X-ray\ndiffractometer namely: Straight Beam Alignment, Beam Cut Alignment and Sample\nTilt Alignment for two samples were analyzed and carried out. Using the results\nof the X-ray spectrum, important parameters such as corresponding planes for\npeak positions, d-spacing of planes, intensities, smallest crystallite sizes\nand lattice parameters, and a comparison with the reference data were all\ncarried out. As another result, the out-of-plane alignment and Full-Width at\nHalf-Maximum (FWHM) value for GaN could be determined using the rocking curve.",
            "author": [
                "Hamidreza Moradi",
                "Fatemeh Mehradnia"
            ],
            "link": [
                "http://dx.doi.org/10.46793/adeletters.2023.2.3.4",
                "http://arxiv.org/abs/2310.10786v1",
                "http://arxiv.org/pdf/2310.10786v1"
            ],
            "primary_category": "physics.app-ph",
            "category": [
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10781v1",
            "title": "BanglaNLP at BLP-2023 Task 1: Benchmarking different Transformer Models\n  for Violence Inciting Text Detection in Bengali",
            "updated": "2023-10-16T19:35:04Z",
            "published": "2023-10-16T19:35:04Z",
            "summary": "This paper presents the system that we have developed while solving this\nshared task on violence inciting text detection in Bangla. We explain both the\ntraditional and the recent approaches that we have used to make our models\nlearn. Our proposed system helps to classify if the given text contains any\nthreat. We studied the impact of data augmentation when there is a limited\ndataset available. Our quantitative results show that finetuning a\nmultilingual-e5-base model performed the best in our task compared to other\ntransformer-based architectures. We obtained a macro F1 of 68.11\\% in the test\nset and our performance in this shared task is ranked at 23 in the leaderboard.",
            "author": [
                "Saumajit Saha",
                "Albert Nanda"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10781v1",
                "http://arxiv.org/pdf/2310.10781v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10780v2",
            "title": "Demystifying Poisoning Backdoor Attacks from a Statistical Perspective",
            "updated": "2023-10-18T01:49:57Z",
            "published": "2023-10-16T19:35:01Z",
            "summary": "The growing dependence on machine learning in real-world applications\nemphasizes the importance of understanding and ensuring its safety. Backdoor\nattacks pose a significant security risk due to their stealthy nature and\npotentially serious consequences. Such attacks involve embedding triggers\nwithin a learning model with the intention of causing malicious behavior when\nan active trigger is present while maintaining regular functionality without\nit. This paper evaluates the effectiveness of any backdoor attack incorporating\na constant trigger, by establishing tight lower and upper boundaries for the\nperformance of the compromised model on both clean and backdoor test data. The\ndeveloped theory answers a series of fundamental but previously underexplored\nproblems, including (1) what are the determining factors for a backdoor\nattack's success, (2) what is the direction of the most effective backdoor\nattack, and (3) when will a human-imperceptible trigger succeed. Our derived\nunderstanding applies to both discriminative and generative models. We also\ndemonstrate the theory by conducting experiments using benchmark datasets and\nstate-of-the-art backdoor attack scenarios.",
            "author": [
                "Ganghua Wang",
                "Xun Xian",
                "Jayanth Srinivasa",
                "Ashish Kundu",
                "Xuan Bi",
                "Mingyi Hong",
                "Jie Ding"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10780v2",
                "http://arxiv.org/pdf/2310.10780v2"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10776v1",
            "title": "Correcting model misspecification in physics-informed neural networks\n  (PINNs)",
            "updated": "2023-10-16T19:25:52Z",
            "published": "2023-10-16T19:25:52Z",
            "summary": "Data-driven discovery of governing equations in computational science has\nemerged as a new paradigm for obtaining accurate physical models and as a\npossible alternative to theoretical derivations. The recently developed\nphysics-informed neural networks (PINNs) have also been employed to learn\ngoverning equations given data across diverse scientific disciplines. Despite\nthe effectiveness of PINNs for discovering governing equations, the physical\nmodels encoded in PINNs may be misspecified in complex systems as some of the\nphysical processes may not be fully understood, leading to the poor accuracy of\nPINN predictions. In this work, we present a general approach to correct the\nmisspecified physical models in PINNs for discovering governing equations,\ngiven some sparse and/or noisy data. Specifically, we first encode the assumed\nphysical models, which may be misspecified, then employ other deep neural\nnetworks (DNNs) to model the discrepancy between the imperfect models and the\nobservational data. Due to the expressivity of DNNs, the proposed method is\ncapable of reducing the computational errors caused by the model\nmisspecification and thus enables the applications of PINNs in complex systems\nwhere the physical processes are not exactly known. Furthermore, we utilize the\nBayesian PINNs (B-PINNs) and/or ensemble PINNs to quantify uncertainties\narising from noisy and/or gappy data in the discovered governing equations. A\nseries of numerical examples including non-Newtonian channel and cavity flows\ndemonstrate that the added DNNs are capable of correcting the model\nmisspecification in PINNs and thus reduce the discrepancy between the physical\nmodels and the observational data. We envision that the proposed approach will\nextend the applications of PINNs for discovering governing equations in\nproblems where the physico-chemical or biological processes are not well\nunderstood.",
            "author": [
                "Zongren Zou",
                "Xuhui Meng",
                "George Em Karniadakis"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10776v1",
                "http://arxiv.org/pdf/2310.10776v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10773v1",
            "title": "Gotta be SAFE: A New Framework for Molecular Design",
            "updated": "2023-10-16T19:12:56Z",
            "published": "2023-10-16T19:12:56Z",
            "summary": "Traditional molecular string representations, such as SMILES, often pose\nchallenges for AI-driven molecular design due to their non-sequential depiction\nof molecular substructures. To address this issue, we introduce Sequential\nAttachment-based Fragment Embedding (SAFE), a novel line notation for chemical\nstructures. SAFE reimagines SMILES strings as an unordered sequence of\ninterconnected fragment blocks while maintaining full compatibility with\nexisting SMILES parsers. It streamlines complex generative tasks, including\nscaffold decoration, fragment linking, polymer generation, and scaffold\nhopping, while facilitating autoregressive generation for fragment-constrained\ndesign, thereby eliminating the need for intricate decoding or graph-based\nmodels. We demonstrate the effectiveness of SAFE by training an\n87-million-parameter GPT2-like model on a dataset containing 1.1 billion SAFE\nrepresentations. Through extensive experimentation, we show that our SAFE-GPT\nmodel exhibits versatile and robust optimization performance. SAFE opens up new\navenues for the rapid exploration of chemical space under various constraints,\npromising breakthroughs in AI-driven molecular design.",
            "author": [
                "Emmanuel Noutahi",
                "Cristian Gabellini",
                "Michael Craig",
                "Jonathan S. C Lim",
                "Prudencio Tossou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10773v1",
                "http://arxiv.org/pdf/2310.10773v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.BM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10772v1",
            "title": "Unsupervised Lead Sheet Generation via Semantic Compression",
            "updated": "2023-10-16T19:12:20Z",
            "published": "2023-10-16T19:12:20Z",
            "summary": "Lead sheets have become commonplace in generative music research, being used\nas an initial compressed representation for downstream tasks like multitrack\nmusic generation and automatic arrangement. Despite this, researchers have\noften fallen back on deterministic reduction methods (such as the skyline\nalgorithm) to generate lead sheets when seeking paired lead sheets and full\nscores, with little attention being paid toward the quality of the lead sheets\nthemselves and how they accurately reflect their orchestrated counterparts. To\naddress these issues, we propose the problem of conditional lead sheet\ngeneration (i.e. generating a lead sheet given its full score version), and\nshow that this task can be formulated as an unsupervised music compression\ntask, where the lead sheet represents a compressed latent version of the score.\nWe introduce a novel model, called Lead-AE, that models the lead sheets as a\ndiscrete subselection of the original sequence, using a differentiable top-k\noperator to allow for controllable local sparsity constraints. Across both\nautomatic proxy tasks and direct human evaluations, we find that our method\nimproves upon the established deterministic baseline and produces coherent\nreductions of large multitrack scores.",
            "author": [
                "Zachary Novack",
                "Nikita Srivatsan",
                "Taylor Berg-Kirkpatrick",
                "Julian McAuley"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10772v1",
                "http://arxiv.org/pdf/2310.10772v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "cs.MM",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10769v1",
            "title": "LAMP: Learn A Motion Pattern for Few-Shot-Based Video Generation",
            "updated": "2023-10-16T19:03:19Z",
            "published": "2023-10-16T19:03:19Z",
            "summary": "With the impressive progress in diffusion-based text-to-image generation,\nextending such powerful generative ability to text-to-video raises enormous\nattention. Existing methods either require large-scale text-video pairs and a\nlarge number of training resources or learn motions that are precisely aligned\nwith template videos. It is non-trivial to balance a trade-off between the\ndegree of generation freedom and the resource costs for video generation. In\nour study, we present a few-shot-based tuning framework, LAMP, which enables\ntext-to-image diffusion model Learn A specific Motion Pattern with 8~16 videos\non a single GPU. Specifically, we design a first-frame-conditioned pipeline\nthat uses an off-the-shelf text-to-image model for content generation so that\nour tuned video diffusion model mainly focuses on motion learning. The\nwell-developed text-to-image techniques can provide visually pleasing and\ndiverse content as generation conditions, which highly improves video quality\nand generation freedom. To capture the features of temporal dimension, we\nexpand the pretrained 2D convolution layers of the T2I model to our novel\ntemporal-spatial motion learning layers and modify the attention blocks to the\ntemporal level. Additionally, we develop an effective inference trick,\nshared-noise sampling, which can improve the stability of videos with\ncomputational costs. Our method can also be flexibly applied to other tasks,\ne.g. real-world image animation and video editing. Extensive experiments\ndemonstrate that LAMP can effectively learn the motion pattern on limited data\nand generate high-quality videos. The code and models are available at\nhttps://rq-wu.github.io/projects/LAMP.",
            "author": [
                "Ruiqi Wu",
                "Liangyu Chen",
                "Tong Yang",
                "Chunle Guo",
                "Chongyi Li",
                "Xiangyu Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10769v1",
                "http://arxiv.org/pdf/2310.10769v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10767v1",
            "title": "Wide Neural Networks as Gaussian Processes: Lessons from Deep\n  Equilibrium Models",
            "updated": "2023-10-16T19:00:43Z",
            "published": "2023-10-16T19:00:43Z",
            "summary": "Neural networks with wide layers have attracted significant attention due to\ntheir equivalence to Gaussian processes, enabling perfect fitting of training\ndata while maintaining generalization performance, known as benign overfitting.\nHowever, existing results mainly focus on shallow or finite-depth networks,\nnecessitating a comprehensive analysis of wide neural networks with\ninfinite-depth layers, such as neural ordinary differential equations (ODEs)\nand deep equilibrium models (DEQs). In this paper, we specifically investigate\nthe deep equilibrium model (DEQ), an infinite-depth neural network with shared\nweight matrices across layers. Our analysis reveals that as the width of DEQ\nlayers approaches infinity, it converges to a Gaussian process, establishing\nwhat is known as the Neural Network and Gaussian Process (NNGP) correspondence.\nRemarkably, this convergence holds even when the limits of depth and width are\ninterchanged, which is not observed in typical infinite-depth Multilayer\nPerceptron (MLP) networks. Furthermore, we demonstrate that the associated\nGaussian vector remains non-degenerate for any pairwise distinct input data,\nensuring a strictly positive smallest eigenvalue of the corresponding kernel\nmatrix using the NNGP kernel. These findings serve as fundamental elements for\nstudying the training and generalization of DEQs, laying the groundwork for\nfuture research in this area.",
            "author": [
                "Tianxiang Gao",
                "Xiaokai Huo",
                "Hailiang Liu",
                "Hongyang Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10767v1",
                "http://arxiv.org/pdf/2310.10767v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10765v3",
            "title": "BiomedJourney: Counterfactual Biomedical Image Generation by\n  Instruction-Learning from Multimodal Patient Journeys",
            "updated": "2023-10-21T02:59:47Z",
            "published": "2023-10-16T18:59:31Z",
            "summary": "Rapid progress has been made in instruction-learning for image editing with\nnatural-language instruction, as exemplified by InstructPix2Pix. In\nbiomedicine, such methods can be applied to counterfactual image generation,\nwhich helps differentiate causal structure from spurious correlation and\nfacilitate robust image interpretation for disease progression modeling.\nHowever, generic image-editing models are ill-suited for the biomedical domain,\nand counterfactual biomedical image generation is largely underexplored. In\nthis paper, we present BiomedJourney, a novel method for counterfactual\nbiomedical image generation by instruction-learning from multimodal patient\njourneys. Given a patient with two biomedical images taken at different time\npoints, we use GPT-4 to process the corresponding imaging reports and generate\na natural language description of disease progression. The resulting triples\n(prior image, progression description, new image) are then used to train a\nlatent diffusion model for counterfactual biomedical image generation. Given\nthe relative scarcity of image time series data, we introduce a two-stage\ncurriculum that first pretrains the denoising network using the much more\nabundant single image-report pairs (with dummy prior image), and then continues\ntraining using the counterfactual triples. Experiments using the standard\nMIMIC-CXR dataset demonstrate the promise of our method. In a comprehensive\nbattery of tests on counterfactual medical image generation, BiomedJourney\nsubstantially outperforms prior state-of-the-art methods in instruction image\nediting and medical image generation such as InstructPix2Pix and RoentGen. To\nfacilitate future study in counterfactual medical generation, we plan to\nrelease our instruction-learning code and pretrained models.",
            "author": [
                "Yu Gu",
                "Jianwei Yang",
                "Naoto Usuyama",
                "Chunyuan Li",
                "Sheng Zhang",
                "Matthew P. Lungren",
                "Jianfeng Gao",
                "Hoifung Poon"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10765v3",
                "http://arxiv.org/pdf/2310.10765v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10762v1",
            "title": "Exploring hyperelastic material model discovery for human brain cortex:\n  multivariate analysis vs. artificial neural network approaches",
            "updated": "2023-10-16T18:49:59Z",
            "published": "2023-10-16T18:49:59Z",
            "summary": "Traditional computational methods, such as the finite element analysis, have\nprovided valuable insights into uncovering the underlying mechanisms of brain\nphysical behaviors. However, precise predictions of brain physics require\neffective constitutive models to represent the intricate mechanical properties\nof brain tissue. In this study, we aimed to identify the most favorable\nconstitutive material model for human brain tissue. To achieve this, we applied\nartificial neural network and multiple regression methods to a generalization\nof widely accepted classic models, and compared the results obtained from these\ntwo approaches. To evaluate the applicability and efficacy of the model, all\nsetups were kept consistent across both methods, except for the approach to\nprevent potential overfitting. Our results demonstrate that artificial neural\nnetworks are capable of automatically identifying accurate constitutive models\nfrom given admissible estimators. Nonetheless, the five-term and two-term\nneural network models trained under single-mode and multi-mode loading\nscenarios, were found to be suboptimal and could be further simplified into\ntwo-term and single-term, respectively, with higher accuracy using multiple\nregression. Our findings highlight the importance of hyperparameters for the\nartificial neural network and emphasize the necessity for detailed\ncross-validations of regularization parameters to ensure optimal selection at a\nglobal level in the development of material constitutive models. This study\nvalidates the applicability and accuracy of artificial neural network to\nautomatically discover constitutive material models with proper regularization\nas well as the benefits in model simplification without compromising accuracy\nfor traditional multivariable regression.",
            "author": [
                "Jixin Hou",
                "Nicholas Filla",
                "Xianyan Chen",
                "Mir Jalil Razavi",
                "Tianming Liu",
                "Xianqiao Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10762v1",
                "http://arxiv.org/pdf/2310.10762v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10758v1",
            "title": "Statistical Barriers to Affine-equivariant Estimation",
            "updated": "2023-10-16T18:42:00Z",
            "published": "2023-10-16T18:42:00Z",
            "summary": "We investigate the quantitative performance of affine-equivariant estimators\nfor robust mean estimation. As a natural stability requirement, the\nconstruction of such affine-equivariant estimators has been extensively studied\nin the statistics literature. We quantitatively evaluate these estimators under\ntwo outlier models which have been the subject of much recent work: the\nheavy-tailed and adversarial corruption settings. We establish lower bounds\nwhich show that affine-equivariance induces a strict degradation in recovery\nerror with quantitative rates degrading by a factor of $\\sqrt{d}$ in both\nsettings. We find that classical estimators such as the Tukey median (Tukey\n'75) and Stahel-Donoho estimator (Stahel '81 and Donoho '82) are either\nquantitatively sub-optimal even within the class of affine-equivariant\nestimators or lack any quantitative guarantees. On the other hand, recent\nestimators with strong quantitative guarantees are not affine-equivariant or\nrequire additional distributional assumptions to achieve it. We remedy this by\nconstructing a new affine-equivariant estimator which nearly matches our lower\nbound. Our estimator is based on a novel notion of a high-dimensional median\nwhich may be of independent interest. Notably, our results are applicable more\nbroadly to any estimator whose performance is evaluated in the Mahalanobis norm\nwhich, for affine-equivariant estimators, corresponds to an evaluation in\nEuclidean norm on isotropic distributions.",
            "author": [
                "Zihao Chen",
                "Yeshwanth Cherapanamjeri"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10758v1",
                "http://arxiv.org/pdf/2310.10758v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "cs.DS",
                "cs.LG",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10756v1",
            "title": "Deep Conditional Shape Models for 3D cardiac image segmentation",
            "updated": "2023-10-16T18:38:26Z",
            "published": "2023-10-16T18:38:26Z",
            "summary": "Delineation of anatomical structures is often the first step of many medical\nimage analysis workflows. While convolutional neural networks achieve high\nperformance, these do not incorporate anatomical shape information. We\nintroduce a novel segmentation algorithm that uses Deep Conditional Shape\nmodels (DCSMs) as a core component. Using deep implicit shape representations,\nthe algorithm learns a modality-agnostic shape model that can generate the\nsigned distance functions for any anatomy of interest. To fit the generated\nshape to the image, the shape model is conditioned on anatomic landmarks that\ncan be automatically detected or provided by the user. Finally, we add a\nmodality-dependent, lightweight refinement network to capture any fine details\nnot represented by the implicit function. The proposed DCSM framework is\nevaluated on the problem of cardiac left ventricle (LV) segmentation from\nmultiple 3D modalities (contrast-enhanced CT, non-contrasted CT, 3D\nechocardiography-3DE). We demonstrate that the automatic DCSM outperforms the\nbaseline for non-contrasted CT without the local refinement, and with the\nrefinement for contrasted CT and 3DE, especially with significant improvement\nin the Hausdorff distance. The semi-automatic DCSM with user-input landmarks,\nwhile only trained on contrasted CT, achieves greater than 92% Dice for all\nmodalities. Both automatic DCSM with refinement and semi-automatic DCSM achieve\nequivalent or better performance compared to inter-user variability for these\nmodalities.",
            "author": [
                "Athira J Jacob",
                "Puneet Sharma",
                "Daniel Ruckert"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10756v1",
                "http://arxiv.org/pdf/2310.10756v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10745v1",
            "title": "Mori-Zwanzig latent space Koopman closure for nonlinear autoencoder",
            "updated": "2023-10-16T18:22:02Z",
            "published": "2023-10-16T18:22:02Z",
            "summary": "The Koopman operator presents an attractive approach to achieve global\nlinearization of nonlinear systems, making it a valuable method for simplifying\nthe understanding of complex dynamics. While data-driven methodologies have\nexhibited promise in approximating finite Koopman operators, they grapple with\nvarious challenges, such as the judicious selection of observables,\ndimensionality reduction, and the ability to predict complex system behaviours\naccurately. This study presents a novel approach termed Mori-Zwanzig\nautoencoder (MZ-AE) to robustly approximate the Koopman operator in\nlow-dimensional spaces. The proposed method leverages a nonlinear autoencoder\nto extract key observables for approximating a finite invariant Koopman\nsubspace and integrates a non-Markovian correction mechanism using the\nMori-Zwanzig formalism. Consequently, this approach yields a closed\nrepresentation of dynamics within the latent manifold of the nonlinear\nautoencoder, thereby enhancing the precision and stability of the Koopman\noperator approximation. Demonstrations showcase the technique's ability to\ncapture regime transitions in the flow around a circular cylinder. It also\nprovided a low dimensional approximation for chaotic Kuramoto-Sivashinsky with\npromising short-term predictability and robust long-term statistical\nperformance. By bridging the gap between data-driven techniques and the\nmathematical foundations of Koopman theory, MZ-AE offers a promising avenue for\nimproved understanding and prediction of complex nonlinear dynamics.",
            "author": [
                "Priyam Gupta",
                "Peter J. Schmid",
                "Denis Sipp",
                "Taraneh Sayadi",
                "Georgios Rigas"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10745v1",
                "http://arxiv.org/pdf/2310.10745v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.DS",
                "physics.flu-dyn",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10744v1",
            "title": "Fast Adversarial Label-Flipping Attack on Tabular Data",
            "updated": "2023-10-16T18:20:44Z",
            "published": "2023-10-16T18:20:44Z",
            "summary": "Machine learning models are increasingly used in fields that require high\nreliability such as cybersecurity. However, these models remain vulnerable to\nvarious attacks, among which the adversarial label-flipping attack poses\nsignificant threats. In label-flipping attacks, the adversary maliciously flips\na portion of training labels to compromise the machine learning model. This\npaper raises significant concerns as these attacks can camouflage a highly\nskewed dataset as an easily solvable classification problem, often misleading\nmachine learning practitioners into lower defenses and miscalculations of\npotential risks. This concern amplifies in tabular data settings, where\nidentifying true labels requires expertise, allowing malicious label-flipping\nattacks to easily slip under the radar. To demonstrate this risk is inherited\nin the adversary's objective, we propose FALFA (Fast Adversarial Label-Flipping\nAttack), a novel efficient attack for crafting adversarial labels. FALFA is\nbased on transforming the adversary's objective and employs linear programming\nto reduce computational complexity. Using ten real-world tabular datasets, we\ndemonstrate FALFA's superior attack potential, highlighting the need for robust\ndefenses against such threats.",
            "author": [
                "Xinglong Chang",
                "Gillian Dobbie",
                "J\u00f6rg Wicker"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10744v1",
                "http://arxiv.org/pdf/2310.10744v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10740v1",
            "title": "Unbiased Estimation of Structured Prediction Error",
            "updated": "2023-10-16T18:17:20Z",
            "published": "2023-10-16T18:17:20Z",
            "summary": "Many modern datasets, such as those in ecology and geology, are composed of\nsamples with spatial structure and dependence. With such data violating the\nusual independent and identically distributed (IID) assumption in machine\nlearning and classical statistics, it is unclear a priori how one should\nmeasure the performance and generalization of models. Several authors have\nempirically investigated cross-validation (CV) methods in this setting,\nreaching mixed conclusions. We provide a class of unbiased estimation methods\nfor general quadratic errors, correlated Gaussian response, and arbitrary\nprediction function $g$, for a noise-elevated version of the error. Our\napproach generalizes the coupled bootstrap (CB) from the normal means problem\nto general normal data, allowing correlation both within and between the\ntraining and test sets. CB relies on creating bootstrap samples that are\nintelligently decoupled, in the sense of being statistically independent.\nSpecifically, the key to CB lies in generating two independent \"views\" of our\ndata and using them as stand-ins for the usual independent training and test\nsamples. Beginning with Mallows' $C_p$, we generalize the estimator to develop\nour generalized $C_p$ estimators (GC). We show at under only a moment condition\non $g$, this noise-elevated error estimate converges smoothly to the noiseless\nerror estimate. We show that when Stein's unbiased risk estimator (SURE)\napplies, GC converges to SURE as in the normal means problem. Further, we use\nthese same tools to analyze CV and provide some theoretical analysis to help\nunderstand when CV will provide good estimates of error. Simulations align with\nour theoretical results, demonstrating the effectiveness of GC and illustrating\nthe behavior of CV methods. Lastly, we apply our estimator to a model selection\ntask on geothermal data in Nevada.",
            "author": [
                "Kevin Fry",
                "Jonathan E. Taylor"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10740v1",
                "http://arxiv.org/pdf/2310.10740v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10735v1",
            "title": "Building Persona Consistent Dialogue Agents with Offline Reinforcement\n  Learning",
            "updated": "2023-10-16T18:05:54Z",
            "published": "2023-10-16T18:05:54Z",
            "summary": "Maintaining a consistent persona is a key quality for any open domain\ndialogue system. Current state-of-the-art systems do this by training agents\nwith supervised learning or online reinforcement learning (RL). However,\nsystems trained with supervised learning often lack consistency as they are\nnever punished for uttering contradictions. Additional training with RL can\nalleviate some of these issues, however the training process is expensive.\nInstead, we propose an offline RL framework to improve the persona consistency\nof dialogue systems. Our framework allows us to combine the advantages of\nprevious methods as we can inexpensively train our model on existing data as in\nsupervised learning, while punishing and rewarding specific utterances as in\nRL. We also introduce a simple importance sampling method to reduce the\nvariance of importance weights in offline RL training which we call\nVariance-Reducing MLE-Initialized (VaRMI) importance sampling. Our automatic\nand human evaluations show that our framework improves both the persona\nconsistency and dialogue quality of a state-of-the-art social chatbot.",
            "author": [
                "Ryan Shea",
                "Zhou Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10735v1",
                "http://arxiv.org/pdf/2310.10735v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10732v1",
            "title": "MOFDiff: Coarse-grained Diffusion for Metal-Organic Framework Design",
            "updated": "2023-10-16T18:00:15Z",
            "published": "2023-10-16T18:00:15Z",
            "summary": "Metal-organic frameworks (MOFs) are of immense interest in applications such\nas gas storage and carbon capture due to their exceptional porosity and tunable\nchemistry. Their modular nature has enabled the use of template-based methods\nto generate hypothetical MOFs by combining molecular building blocks in\naccordance with known network topologies. However, the ability of these methods\nto identify top-performing MOFs is often hindered by the limited diversity of\nthe resulting chemical space. In this work, we propose MOFDiff: a\ncoarse-grained (CG) diffusion model that generates CG MOF structures through a\ndenoising diffusion process over the coordinates and identities of the building\nblocks. The all-atom MOF structure is then determined through a novel assembly\nalgorithm. Equivariant graph neural networks are used for the diffusion model\nto respect the permutational and roto-translational symmetries. We\ncomprehensively evaluate our model's capability to generate valid and novel MOF\nstructures and its effectiveness in designing outstanding MOF materials for\ncarbon capture applications with molecular simulations.",
            "author": [
                "Xiang Fu",
                "Tian Xie",
                "Andrew S. Rosen",
                "Tommi Jaakkola",
                "Jake Smith"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10732v1",
                "http://arxiv.org/pdf/2310.10732v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "cond-mat.mtrl-sci",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10717v1",
            "title": "A representation learning approach to probe for dynamical dark energy in\n  matter power spectra",
            "updated": "2023-10-16T18:00:01Z",
            "published": "2023-10-16T18:00:01Z",
            "summary": "We present DE-VAE, a variational autoencoder (VAE) architecture to search for\na compressed representation of dynamical dark energy (DE) models in\nobservational studies of the cosmic large-scale structure. DE-VAE is trained on\nmatter power spectra boosts generated at wavenumbers $k\\in(0.01-2.5) \\\nh/\\rm{Mpc}$ and at four redshift values $z\\in(0.1,0.48,0.78,1.5)$ for the most\ntypical dynamical DE parametrization with two extra parameters describing an\nevolving DE equation of state. The boosts are compressed to a lower-dimensional\nrepresentation, which is concatenated with standard cold dark matter (CDM)\nparameters and then mapped back to reconstructed boosts; both the compression\nand the reconstruction components are parametrized as neural networks.\nRemarkably, we find that a single latent parameter is sufficient to predict 95%\n(99%) of DE power spectra generated over a broad range of cosmological\nparameters within $1\\sigma$ ($2\\sigma$) of a Gaussian error which includes\ncosmic variance, shot noise and systematic effects for a Stage IV-like survey.\nThis single parameter shows a high mutual information with the two DE\nparameters, and these three variables can be linked together with an explicit\nequation through symbolic regression. Considering a model with two latent\nvariables only marginally improves the accuracy of the predictions, and adding\na third latent variable has no significant impact on the model's performance.\nWe discuss how the DE-VAE architecture can be extended from a proof of concept\nto a general framework to be employed in the search for a common\nlower-dimensional parametrization of a wide range of beyond-$\\Lambda$CDM models\nand for different cosmological datasets. Such a framework could then both\ninform the development of cosmological surveys by targeting optimal probes, and\nprovide theoretical insight into the common phenomenological aspects of\nbeyond-$\\Lambda$CDM models.",
            "author": [
                "Davide Piras",
                "Lucas Lombriser"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10717v1",
                "http://arxiv.org/pdf/2310.10717v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "astro-ph.IM",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10649v2",
            "title": "A Computational Framework for Solving Wasserstein Lagrangian Flows",
            "updated": "2023-10-17T17:55:33Z",
            "published": "2023-10-16T17:59:54Z",
            "summary": "The dynamical formulation of the optimal transport can be extended through\nvarious choices of the underlying geometry ($\\textit{kinetic energy}$), and the\nregularization of density paths ($\\textit{potential energy}$). These\ncombinations yield different variational problems ($\\textit{Lagrangians}$),\nencompassing many variations of the optimal transport problem such as the\nSchr\\\"odinger bridge, unbalanced optimal transport, and optimal transport with\nphysical constraints, among others. In general, the optimal density path is\nunknown, and solving these variational problems can be computationally\nchallenging. Leveraging the dual formulation of the Lagrangians, we propose a\nnovel deep learning based framework approaching all of these problems from a\nunified perspective. Our method does not require simulating or backpropagating\nthrough the trajectories of the learned dynamics, and does not need access to\noptimal couplings. We showcase the versatility of the proposed framework by\noutperforming previous approaches for the single-cell trajectory inference,\nwhere incorporating prior knowledge into the dynamics is crucial for correct\npredictions.",
            "author": [
                "Kirill Neklyudov",
                "Rob Brekelmans",
                "Alexander Tong",
                "Lazar Atanackovic",
                "Qiang Liu",
                "Alireza Makhzani"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10649v2",
                "http://arxiv.org/pdf/2310.10649v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10648v1",
            "title": "Step-by-Step Remediation of Students' Mathematical Mistakes",
            "updated": "2023-10-16T17:59:50Z",
            "published": "2023-10-16T17:59:50Z",
            "summary": "Scaling high-quality tutoring is a major challenge in education. Because of\nthe growing demand, many platforms employ novice tutors who, unlike\nprofessional educators, struggle to effectively address student mistakes and\nthus fail to seize prime learning opportunities for students. In this paper, we\nexplore the potential for large language models (LLMs) to assist math tutors in\nremediating student mistakes. We present ReMath, a benchmark co-developed with\nexperienced math teachers that deconstructs their thought process for\nremediation. The benchmark consists of three step-by-step tasks: (1) infer the\ntype of student error, (2) determine the strategy to address the error, and (3)\ngenerate a response that incorporates that information. We evaluate the\nperformance of state-of-the-art instruct-tuned and dialog models on ReMath. Our\nfindings suggest that although models consistently improve upon original tutor\nresponses, we cannot rely on models alone to remediate mistakes. Providing\nmodels with the error type (e.g., the student is guessing) and strategy (e.g.,\nsimplify the problem) leads to a 75% improvement in the response quality over\nmodels without that information. Nonetheless, despite the improvement, the\nquality of the best model's responses still falls short of experienced math\nteachers. Our work sheds light on the potential and limitations of using\ncurrent LLMs to provide high-quality learning experiences for both tutors and\nstudents at scale. Our work is open-sourced at this link:\n\\url{https://github.com/rosewang2008/remath}.",
            "author": [
                "Rose E. Wang",
                "Qingyang Zhang",
                "Carly Robinson",
                "Susanna Loeb",
                "Dorottya Demszky"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10648v1",
                "http://arxiv.org/pdf/2310.10648v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10647v1",
            "title": "A Survey on Video Diffusion Models",
            "updated": "2023-10-16T17:59:28Z",
            "published": "2023-10-16T17:59:28Z",
            "summary": "The recent wave of AI-generated content (AIGC) has witnessed substantial\nsuccess in computer vision, with the diffusion model playing a crucial role in\nthis achievement. Due to their impressive generative capabilities, diffusion\nmodels are gradually superseding methods based on GANs and auto-regressive\nTransformers, demonstrating exceptional performance not only in image\ngeneration and editing, but also in the realm of video-related research.\nHowever, existing surveys mainly focus on diffusion models in the context of\nimage generation, with few up-to-date reviews on their application in the video\ndomain. To address this gap, this paper presents a comprehensive review of\nvideo diffusion models in the AIGC era. Specifically, we begin with a concise\nintroduction to the fundamentals and evolution of diffusion models.\nSubsequently, we present an overview of research on diffusion models in the\nvideo domain, categorizing the work into three key areas: video generation,\nvideo editing, and other video understanding tasks. We conduct a thorough\nreview of the literature in these three key areas, including further\ncategorization and practical contributions in the field. Finally, we discuss\nthe challenges faced by research in this domain and outline potential future\ndevelopmental trends. A comprehensive list of video diffusion models studied in\nthis survey is available at\nhttps://github.com/ChenHsing/Awesome-Video-Diffusion-Models.",
            "author": [
                "Zhen Xing",
                "Qijun Feng",
                "Haoran Chen",
                "Qi Dai",
                "Han Hu",
                "Hang Xu",
                "Zuxuan Wu",
                "Yu-Gang Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10647v1",
                "http://arxiv.org/pdf/2310.10647v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10642v1",
            "title": "Real-time Photorealistic Dynamic Scene Representation and Rendering with\n  4D Gaussian Splatting",
            "updated": "2023-10-16T17:57:43Z",
            "published": "2023-10-16T17:57:43Z",
            "summary": "Reconstructing dynamic 3D scenes from 2D images and generating diverse views\nover time is challenging due to scene complexity and temporal dynamics. Despite\nadvancements in neural implicit models, limitations persist: (i) Inadequate\nScene Structure: Existing methods struggle to reveal the spatial and temporal\nstructure of dynamic scenes from directly learning the complex 6D plenoptic\nfunction. (ii) Scaling Deformation Modeling: Explicitly modeling scene element\ndeformation becomes impractical for complex dynamics. To address these issues,\nwe consider the spacetime as an entirety and propose to approximate the\nunderlying spatio-temporal 4D volume of a dynamic scene by optimizing a\ncollection of 4D primitives, with explicit geometry and appearance modeling.\nLearning to optimize the 4D primitives enables us to synthesize novel views at\nany desired time with our tailored rendering routine. Our model is conceptually\nsimple, consisting of a 4D Gaussian parameterized by anisotropic ellipses that\ncan rotate arbitrarily in space and time, as well as view-dependent and\ntime-evolved appearance represented by the coefficient of 4D spherindrical\nharmonics. This approach offers simplicity, flexibility for variable-length\nvideo and end-to-end training, and efficient real-time rendering, making it\nsuitable for capturing complex dynamic scene motions. Experiments across\nvarious benchmarks, including monocular and multi-view scenarios, demonstrate\nour 4DGS model's superior visual quality and efficiency.",
            "author": [
                "Zeyu Yang",
                "Hongye Yang",
                "Zijie Pan",
                "Xiatian Zhu",
                "Li Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10642v1",
                "http://arxiv.org/pdf/2310.10642v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10638v4",
            "title": "In-Context Pretraining: Language Modeling Beyond Document Boundaries",
            "updated": "2023-11-30T23:26:35Z",
            "published": "2023-10-16T17:57:12Z",
            "summary": "Large language models (LMs) are currently trained to predict tokens given\ndocument prefixes, enabling them to directly perform long-form generation and\nprompting-style tasks which can be reduced to document completion. Existing\npretraining pipelines train LMs by concatenating random sets of short documents\nto create input contexts but the prior documents provide no signal for\npredicting the next document. We instead present In-Context Pretraining, a new\napproach where language models are pretrained on a sequence of related\ndocuments, thereby explicitly encouraging them to read and reason across\ndocument boundaries. We can do In-Context Pretraining by simply changing the\ndocument ordering so that each context contains related documents, and directly\napplying existing pretraining pipelines. However, this document sorting problem\nis challenging. There are billions of documents and we would like the sort to\nmaximize contextual similarity for every document without repeating any data.\nTo do this, we introduce approximate algorithms for finding related documents\nwith efficient nearest neighbor search and constructing coherent input contexts\nwith a graph traversal algorithm. Our experiments show In-Context Pretraining\noffers a simple and scalable approach to significantly enhance LMs'performance:\nwe see notable improvements in tasks that require more complex contextual\nreasoning, including in-context learning (+8%), reading comprehension (+15%),\nfaithfulness to previous contexts (+16%), long-context reasoning (+5%), and\nretrieval augmentation (+9%).",
            "author": [
                "Weijia Shi",
                "Sewon Min",
                "Maria Lomeli",
                "Chunting Zhou",
                "Margaret Li",
                "Rich James",
                "Xi Victoria Lin",
                "Noah A. Smith",
                "Luke Zettlemoyer",
                "Scott Yih",
                "Mike Lewis"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10638v4",
                "http://arxiv.org/pdf/2310.10638v4"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10637v1",
            "title": "\"Mistakes Help Us Grow\": Facilitating and Evaluating Growth Mindset\n  Supportive Language in Classrooms",
            "updated": "2023-10-16T17:56:07Z",
            "published": "2023-10-16T17:56:07Z",
            "summary": "Teachers' growth mindset supportive language (GMSL)--rhetoric emphasizing\nthat one's skills can be improved over time--has been shown to significantly\nreduce disparities in academic achievement and enhance students' learning\noutcomes. Although teachers espouse growth mindset principles, most find it\ndifficult to adopt GMSL in their practice due the lack of effective coaching in\nthis area. We explore whether large language models (LLMs) can provide\nautomated, personalized coaching to support teachers' use of GMSL. We establish\nan effective coaching tool to reframe unsupportive utterances to GMSL by\ndeveloping (i) a parallel dataset containing GMSL-trained teacher reframings of\nunsupportive statements with an accompanying annotation guide, (ii) a GMSL\nprompt framework to revise teachers' unsupportive language, and (iii) an\nevaluation framework grounded in psychological theory for evaluating GMSL with\nthe help of students and teachers. We conduct a large-scale evaluation\ninvolving 174 teachers and 1,006 students, finding that both teachers and\nstudents perceive GMSL-trained teacher and model reframings as more effective\nin fostering a growth mindset and promoting challenge-seeking behavior, among\nother benefits. We also find that model-generated reframings outperform those\nfrom the GMSL-trained teachers. These results show promise for harnessing LLMs\nto provide automated GMSL feedback for teachers and, more broadly, LLMs'\npotentiality for supporting students' learning in the classroom. Our findings\nalso demonstrate the benefit of large-scale human evaluations when applying\nLLMs in educational domains.",
            "author": [
                "Kunal Handa",
                "Margaret Clapper",
                "Jessica Boyle",
                "Rose E Wang",
                "Diyi Yang",
                "David S Yeager",
                "Dorottya Demszky"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10637v1",
                "http://arxiv.org/pdf/2310.10637v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10636v1",
            "title": "Efficacy of Dual-Encoders for Extreme Multi-Label Classification",
            "updated": "2023-10-16T17:55:43Z",
            "published": "2023-10-16T17:55:43Z",
            "summary": "Dual-encoder models have demonstrated significant success in dense retrieval\ntasks for open-domain question answering that mostly involves zero-shot and\nfew-shot scenarios. However, their performance in many-shot retrieval problems\nwhere training data is abundant, such as extreme multi-label classification\n(XMC), remains under-explored. Existing empirical evidence suggests that, for\nsuch problems, the dual-encoder method's accuracies lag behind the performance\nof state-of-the-art (SOTA) extreme classification methods that grow the number\nof learnable parameters linearly with the number of classes. As a result, some\nrecent extreme classification techniques use a combination of dual-encoders and\na learnable classification head for each class to excel on these tasks. In this\npaper, we investigate the potential of \"pure\" DE models in XMC tasks. Our\nfindings reveal that when trained correctly standard dual-encoders can match or\noutperform SOTA extreme classification methods by up to 2% at Precision@1 even\non the largest XMC datasets while being 20x smaller in terms of the number of\ntrainable parameters. We further propose a differentiable topk error-based loss\nfunction, which can be used to specifically optimize for Recall@k metrics. We\ninclude our PyTorch implementation along with other resources for reproducing\nthe results in the supplementary material.",
            "author": [
                "Nilesh Gupta",
                "Devvrit Khatri",
                "Ankit S Rawat",
                "Srinadh Bhojanapalli",
                "Prateek Jain",
                "Inderjit S Dhillon"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10636v1",
                "http://arxiv.org/pdf/2310.10636v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10635v1",
            "title": "Towards Scenario-based Safety Validation for Autonomous Trains with Deep\n  Generative Models",
            "updated": "2023-10-16T17:55:14Z",
            "published": "2023-10-16T17:55:14Z",
            "summary": "Modern AI techniques open up ever-increasing possibilities for autonomous\nvehicles, but how to appropriately verify the reliability of such systems\nremains unclear. A common approach is to conduct safety validation based on a\npredefined Operational Design Domain (ODD) describing specific conditions under\nwhich a system under test is required to operate properly. However, collecting\nsufficient realistic test cases to ensure comprehensive ODD coverage is\nchallenging. In this paper, we report our practical experiences regarding the\nutility of data simulation with deep generative models for scenario-based ODD\nvalidation. We consider the specific use case of a camera-based rail-scene\nsegmentation system designed to support autonomous train operation. We\ndemonstrate the capabilities of semantically editing railway scenes with deep\ngenerative models to make a limited amount of test data more representative. We\nalso show how our approach helps to analyze the degree to which a system\ncomplies with typical ODD requirements. Specifically, we focus on evaluating\nproper operation under different lighting and weather conditions as well as\nwhile transitioning between them.",
            "author": [
                "Thomas Decker",
                "Ananta R. Bhattarai",
                "Michael Lebacher"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-031-40923-3_20",
                "http://arxiv.org/abs/2310.10635v1",
                "http://arxiv.org/pdf/2310.10635v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10629v1",
            "title": "Certainty In, Certainty Out: REVQCs for Quantum Machine Learning",
            "updated": "2023-10-16T17:53:30Z",
            "published": "2023-10-16T17:53:30Z",
            "summary": "The field of Quantum Machine Learning (QML) has emerged recently in the hopes\nof finding new machine learning protocols or exponential speedups for classical\nones. Apart from problems with vanishing gradients and efficient encoding\nmethods, these speedups are hard to find because the sampling nature of quantum\ncomputers promotes either simulating computations classically or running them\nmany times on quantum computers in order to use approximate expectation values\nin gradient calculations. In this paper, we make a case for setting high\nsingle-sample accuracy as a primary goal. We discuss the statistical theory\nwhich enables highly accurate and precise sample inference, and propose a\nmethod of reversed training towards this end. We show the effectiveness of this\ntraining method by assessing several effective variational quantum circuits\n(VQCs), trained in both the standard and reversed directions, on random binary\nsubsets of the MNIST and MNIST Fashion datasets, on which our method provides\nan increase of $10-15\\%$ in single-sample inference accuracy.",
            "author": [
                "Hannah Helgesen",
                "Michael Felsberg",
                "Jan-\u00c5ke Larsson"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10629v1",
                "http://arxiv.org/pdf/2310.10629v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "quant-ph",
                "I.2.6; I.6.5"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10625v1",
            "title": "Video Language Planning",
            "updated": "2023-10-16T17:48:45Z",
            "published": "2023-10-16T17:48:45Z",
            "summary": "We are interested in enabling visual planning for complex long-horizon tasks\nin the space of generated videos and language, leveraging recent advances in\nlarge generative models pretrained on Internet-scale data. To this end, we\npresent video language planning (VLP), an algorithm that consists of a tree\nsearch procedure, where we train (i) vision-language models to serve as both\npolicies and value functions, and (ii) text-to-video models as dynamics models.\nVLP takes as input a long-horizon task instruction and current image\nobservation, and outputs a long video plan that provides detailed multimodal\n(video and language) specifications that describe how to complete the final\ntask. VLP scales with increasing computation budget where more computation time\nresults in improved video plans, and is able to synthesize long-horizon video\nplans across different robotics domains: from multi-object rearrangement, to\nmulti-camera bi-arm dexterous manipulation. Generated video plans can be\ntranslated into real robot actions via goal-conditioned policies, conditioned\non each intermediate frame of the generated video. Experiments show that VLP\nsubstantially improves long-horizon task success rates compared to prior\nmethods on both simulated and real robots (across 3 hardware platforms).",
            "author": [
                "Yilun Du",
                "Mengjiao Yang",
                "Pete Florence",
                "Fei Xia",
                "Ayzaan Wahid",
                "Brian Ichter",
                "Pierre Sermanet",
                "Tianhe Yu",
                "Pieter Abbeel",
                "Joshua B. Tenenbaum",
                "Leslie Kaelbling",
                "Andy Zeng",
                "Jonathan Tompson"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10625v1",
                "http://arxiv.org/pdf/2310.10625v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10623v1",
            "title": "Generating Summaries with Controllable Readability Levels",
            "updated": "2023-10-16T17:46:26Z",
            "published": "2023-10-16T17:46:26Z",
            "summary": "Readability refers to how easily a reader can understand a written text.\nSeveral factors affect the readability level, such as the complexity of the\ntext, its subject matter, and the reader's background knowledge. Generating\nsummaries based on different readability levels is critical for enabling\nknowledge consumption by diverse audiences. However, current text generation\napproaches lack refined control, resulting in texts that are not customized to\nreaders' proficiency levels. In this work, we bridge this gap and study\ntechniques to generate summaries at specified readability levels. Unlike\nprevious methods that focus on a specific readability level (e.g., lay\nsummarization), we generate summaries with fine-grained control over their\nreadability. We develop three text generation techniques for controlling\nreadability: (1) instruction-based readability control, (2) reinforcement\nlearning to minimize the gap between requested and observed readability and (3)\na decoding approach that uses lookahead to estimate the readability of upcoming\ndecoding steps. We show that our generation methods significantly improve\nreadability control on news summarization (CNN/DM dataset), as measured by\nvarious readability metrics and human judgement, establishing strong baselines\nfor controllable readability in summarization.",
            "author": [
                "Leonardo F. R. Ribeiro",
                "Mohit Bansal",
                "Markus Dreyer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10623v1",
                "http://arxiv.org/pdf/2310.10623v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10616v1",
            "title": "How Do Transformers Learn In-Context Beyond Simple Functions? A Case\n  Study on Learning with Representations",
            "updated": "2023-10-16T17:40:49Z",
            "published": "2023-10-16T17:40:49Z",
            "summary": "While large language models based on the transformer architecture have\ndemonstrated remarkable in-context learning (ICL) capabilities, understandings\nof such capabilities are still in an early stage, where existing theory and\nmechanistic understanding focus mostly on simple scenarios such as learning\nsimple function classes. This paper takes initial steps on understanding ICL in\nmore complex scenarios, by studying learning with representations. Concretely,\nwe construct synthetic in-context learning problems with a compositional\nstructure, where the label depends on the input through a possibly complex but\nfixed representation function, composed with a linear function that differs in\neach instance. By construction, the optimal ICL algorithm first transforms the\ninputs by the representation function, and then performs linear ICL on top of\nthe transformed dataset. We show theoretically the existence of transformers\nthat approximately implement such algorithms with mild depth and size.\nEmpirically, we find trained transformers consistently achieve near-optimal ICL\nperformance in this setting, and exhibit the desired dissection where lower\nlayers transforms the dataset and upper layers perform linear ICL. Through\nextensive probing and a new pasting experiment, we further reveal several\nmechanisms within the trained transformers, such as concrete copying behaviors\non both the inputs and the representations, linear ICL capability of the upper\nlayers alone, and a post-ICL representation selection mechanism in a harder\nmixture setting. These observed mechanisms align well with our theory and may\nshed light on how transformers perform ICL in more realistic scenarios.",
            "author": [
                "Tianyu Guo",
                "Wei Hu",
                "Song Mei",
                "Huan Wang",
                "Caiming Xiong",
                "Silvio Savarese",
                "Yu Bai"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10616v1",
                "http://arxiv.org/pdf/2310.10616v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10611v1",
            "title": "IW-GAE: Importance weighted group accuracy estimation for improved\n  calibration and model selection in unsupervised domain adaptation",
            "updated": "2023-10-16T17:35:29Z",
            "published": "2023-10-16T17:35:29Z",
            "summary": "Reasoning about a model's accuracy on a test sample from its confidence is a\ncentral problem in machine learning, being connected to important applications\nsuch as uncertainty representation, model selection, and exploration. While\nthese connections have been well-studied in the i.i.d. settings, distribution\nshifts pose significant challenges to the traditional methods. Therefore, model\ncalibration and model selection remain challenging in the unsupervised domain\nadaptation problem--a scenario where the goal is to perform well in a\ndistribution shifted domain without labels. In this work, we tackle\ndifficulties coming from distribution shifts by developing a novel importance\nweighted group accuracy estimator. Specifically, we formulate an optimization\nproblem for finding an importance weight that leads to an accurate group\naccuracy estimation in the distribution shifted domain with theoretical\nanalyses. Extensive experiments show the effectiveness of group accuracy\nestimation on model calibration and model selection. Our results emphasize the\nsignificance of group accuracy estimation for addressing challenges in\nunsupervised domain adaptation, as an orthogonal improvement direction with\nimproving transferability of accuracy.",
            "author": [
                "Taejong Joo",
                "Diego Klabjan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10611v1",
                "http://arxiv.org/pdf/2310.10611v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10610v1",
            "title": "Quantifying Assistive Robustness Via the Natural-Adversarial Frontier",
            "updated": "2023-10-16T17:34:54Z",
            "published": "2023-10-16T17:34:54Z",
            "summary": "Our ultimate goal is to build robust policies for robots that assist people.\nWhat makes this hard is that people can behave unexpectedly at test time,\npotentially interacting with the robot outside its training distribution and\nleading to failures. Even just measuring robustness is a challenge. Adversarial\nperturbations are the default, but they can paint the wrong picture: they can\ncorrespond to human motions that are unlikely to occur during natural\ninteractions with people. A robot policy might fail under small adversarial\nperturbations but work under large natural perturbations. We propose that\ncapturing robustness in these interactive settings requires constructing and\nanalyzing the entire natural-adversarial frontier: the Pareto-frontier of human\npolicies that are the best trade-offs between naturalness and low robot\nperformance. We introduce RIGID, a method for constructing this frontier by\ntraining adversarial human policies that trade off between minimizing robot\nreward and acting human-like (as measured by a discriminator). On an Assistive\nGym task, we use RIGID to analyze the performance of standard collaborative\nReinforcement Learning, as well as the performance of existing methods meant to\nincrease robustness. We also compare the frontier RIGID identifies with the\nfailures identified in expert adversarial interaction, and with\nnaturally-occurring failures during user interaction. Overall, we find evidence\nthat RIGID can provide a meaningful measure of robustness predictive of\ndeployment performance, and uncover failure cases in human-robot interaction\nthat are difficult to find manually. https://ood-human.github.io.",
            "author": [
                "Jerry Zhi-Yang He",
                "Zackory Erickson",
                "Daniel S. Brown",
                "Anca D. Dragan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10610v1",
                "http://arxiv.org/pdf/2310.10610v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10606v1",
            "title": "BayRnTune: Adaptive Bayesian Domain Randomization via Strategic\n  Fine-tuning",
            "updated": "2023-10-16T17:32:23Z",
            "published": "2023-10-16T17:32:23Z",
            "summary": "Domain randomization (DR), which entails training a policy with randomized\ndynamics, has proven to be a simple yet effective algorithm for reducing the\ngap between simulation and the real world. However, DR often requires careful\ntuning of randomization parameters. Methods like Bayesian Domain Randomization\n(Bayesian DR) and Active Domain Randomization (Adaptive DR) address this issue\nby automating parameter range selection using real-world experience. While\neffective, these algorithms often require long computation time, as a new\npolicy is trained from scratch every iteration. In this work, we propose\nAdaptive Bayesian Domain Randomization via Strategic Fine-tuning (BayRnTune),\nwhich inherits the spirit of BayRn but aims to significantly accelerate the\nlearning processes by fine-tuning from previously learned policy. This idea\nleads to a critical question: which previous policy should we use as a prior\nduring fine-tuning? We investigated four different fine-tuning strategies and\ncompared them against baseline algorithms in five simulated environments,\nranging from simple benchmark tasks to more complex legged robot environments.\nOur analysis demonstrates that our method yields better rewards in the same\namount of timesteps compared to vanilla domain randomization or Bayesian DR.",
            "author": [
                "Tianle Huang",
                "Nitish Sontakke",
                "K. Niranjan Kumar",
                "Irfan Essa",
                "Stefanos Nikolaidis",
                "Dennis W. Hong",
                "Sehoon Ha"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10606v1",
                "http://arxiv.org/pdf/2310.10606v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10605v1",
            "title": "ForceGen: End-to-end de novo protein generation based on nonlinear\n  mechanical unfolding responses using a protein language diffusion model",
            "updated": "2023-10-16T17:31:34Z",
            "published": "2023-10-16T17:31:34Z",
            "summary": "Through evolution, nature has presented a set of remarkable protein\nmaterials, including elastins, silks, keratins and collagens with superior\nmechanical performances that play crucial roles in mechanobiology. However,\ngoing beyond natural designs to discover proteins that meet specified\nmechanical properties remains challenging. Here we report a generative model\nthat predicts protein designs to meet complex nonlinear mechanical\nproperty-design objectives. Our model leverages deep knowledge on protein\nsequences from a pre-trained protein language model and maps mechanical\nunfolding responses to create novel proteins. Via full-atom molecular\nsimulations for direct validation, we demonstrate that the designed proteins\nare novel, and fulfill the targeted mechanical properties, including unfolding\nenergy and mechanical strength, as well as the detailed unfolding\nforce-separation curves. Our model offers rapid pathways to explore the\nenormous mechanobiological protein sequence space unconstrained by biological\nsynthesis, using mechanical features as target to enable the discovery of\nprotein materials with superior mechanical properties.",
            "author": [
                "Bo Ni",
                "David L. Kaplan",
                "Markus J. Buehler"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10605v1",
                "http://arxiv.org/pdf/2310.10605v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cond-mat.mes-hall",
                "cs.CL",
                "cs.LG",
                "q-bio.BM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10604v1",
            "title": "Generation or Replication: Auscultating Audio Latent Diffusion Models",
            "updated": "2023-10-16T17:31:26Z",
            "published": "2023-10-16T17:31:26Z",
            "summary": "The introduction of audio latent diffusion models possessing the ability to\ngenerate realistic sound clips on demand from a text description has the\npotential to revolutionize how we work with audio. In this work, we make an\ninitial attempt at understanding the inner workings of audio latent diffusion\nmodels by investigating how their audio outputs compare with the training data,\nsimilar to how a doctor auscultates a patient by listening to the sounds of\ntheir organs. Using text-to-audio latent diffusion models trained on the\nAudioCaps dataset, we systematically analyze memorization behavior as a\nfunction of training set size. We also evaluate different retrieval metrics for\nevidence of training data memorization, finding the similarity between mel\nspectrograms to be more robust in detecting matches than learned embedding\nvectors. In the process of analyzing memorization in audio latent diffusion\nmodels, we also discover a large amount of duplicated audio clips within the\nAudioCaps database.",
            "author": [
                "Dimitrios Bralios",
                "Gordon Wichern",
                "Fran\u00e7ois G. Germain",
                "Zexu Pan",
                "Sameer Khurana",
                "Chiori Hori",
                "Jonathan Le Roux"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10604v1",
                "http://arxiv.org/pdf/2310.10604v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10603v1",
            "title": "Exploring the Power of Graph Neural Networks in Solving Linear\n  Optimization Problems",
            "updated": "2023-10-16T17:31:25Z",
            "published": "2023-10-16T17:31:25Z",
            "summary": "Recently, machine learning, particularly message-passing graph neural\nnetworks (MPNNs), has gained traction in enhancing exact optimization\nalgorithms. For example, MPNNs speed up solving mixed-integer optimization\nproblems by imitating computational intensive heuristics like strong branching,\nwhich entails solving multiple linear optimization problems (LPs). Despite the\nempirical success, the reasons behind MPNNs' effectiveness in emulating linear\noptimization remain largely unclear. Here, we show that MPNNs can simulate\nstandard interior-point methods for LPs, explaining their practical success.\nFurthermore, we highlight how MPNNs can serve as a lightweight proxy for\nsolving LPs, adapting to a given problem instance distribution. Empirically, we\nshow that MPNNs solve LP relaxations of standard combinatorial optimization\nproblems close to optimality, often surpassing conventional solvers and\ncompeting approaches in solving time.",
            "author": [
                "Chendi Qian",
                "Didier Ch\u00e9telat",
                "Christopher Morris"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10603v1",
                "http://arxiv.org/pdf/2310.10603v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.NE",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10602v1",
            "title": "Physics-informed neural wavefields with Gabor basis functions",
            "updated": "2023-10-16T17:30:33Z",
            "published": "2023-10-16T17:30:33Z",
            "summary": "Recently, Physics-Informed Neural Networks (PINNs) have gained significant\nattention for their versatile interpolation capabilities in solving partial\ndifferential equations (PDEs). Despite their potential, the training can be\ncomputationally demanding, especially for intricate functions like wavefields.\nThis is primarily due to the neural-based (learned) basis functions, biased\ntoward low frequencies, as they are dominated by polynomial calculations, which\nare not inherently wavefield-friendly. In response, we propose an approach to\nenhance the efficiency and accuracy of neural network wavefield solutions by\nmodeling them as linear combinations of Gabor basis functions that satisfy the\nwave equation. Specifically, for the Helmholtz equation, we augment the fully\nconnected neural network model with an adaptable Gabor layer constituting the\nfinal hidden layer, employing a weighted summation of these Gabor neurons to\ncompute the predictions (output). These weights/coefficients of the Gabor\nfunctions are learned from the previous hidden layers that include nonlinear\nactivation functions. To ensure the Gabor layer's utilization across the model\nspace, we incorporate a smaller auxiliary network to forecast the center of\neach Gabor function based on input coordinates. Realistic assessments showcase\nthe efficacy of this novel implementation compared to the vanilla PINN,\nparticularly in scenarios involving high-frequencies and realistic models that\nare often challenging for PINNs.",
            "author": [
                "Tariq Alkhalifah",
                "Xinquan Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10602v1",
                "http://arxiv.org/pdf/2310.10602v1"
            ],
            "primary_category": "physics.geo-ph",
            "category": [
                "physics.geo-ph",
                "cs.AI",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10598v1",
            "title": "Pareto Optimization to Accelerate Multi-Objective Virtual Screening",
            "updated": "2023-10-16T17:19:46Z",
            "published": "2023-10-16T17:19:46Z",
            "summary": "The discovery of therapeutic molecules is fundamentally a multi-objective\noptimization problem. One formulation of the problem is to identify molecules\nthat simultaneously exhibit strong binding affinity for a target protein,\nminimal off-target interactions, and suitable pharmacokinetic properties.\nInspired by prior work that uses active learning to accelerate the\nidentification of strong binders, we implement multi-objective Bayesian\noptimization to reduce the computational cost of multi-property virtual\nscreening and apply it to the identification of ligands predicted to be\nselective based on docking scores to on- and off-targets. We demonstrate the\nsuperiority of Pareto optimization over scalarization across three case\nstudies. Further, we use the developed optimization tool to search a virtual\nlibrary of over 4M molecules for those predicted to be selective dual\ninhibitors of EGFR and IGF1R, acquiring 100% of the molecules that form the\nlibrary's Pareto front after exploring only 8% of the library. This workflow\nand associated open source software can reduce the screening burden of\nmolecular design projects and is complementary to research aiming to improve\nthe accuracy of binding predictions and other molecular properties.",
            "author": [
                "Jenna C. Fromer",
                "David E. Graff",
                "Connor W. Coley"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10598v1",
                "http://arxiv.org/pdf/2310.10598v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10594v1",
            "title": "Motion2Language, Unsupervised learning of synchronized semantic motion\n  segmentation",
            "updated": "2023-10-16T17:16:32Z",
            "published": "2023-10-16T17:16:32Z",
            "summary": "In this paper, we investigate building a sequence to sequence architecture\nfor motion to language translation and synchronization. The aim is to translate\nmotion capture inputs into English natural-language descriptions, such that the\ndescriptions are generated synchronously with the actions performed, enabling\nsemantic segmentation as a byproduct, but without requiring synchronized\ntraining data. We propose a new recurrent formulation of local attention that\nis suited for synchronous/live text generation, as well as an improved motion\nencoder architecture better suited to smaller data and for synchronous\ngeneration. We evaluate both contributions in individual experiments, using the\nstandard BLEU4 metric, as well as a simple semantic equivalence measure, on the\nKIT motion language dataset. In a follow-up experiment, we assess the quality\nof the synchronization of generated text in our proposed approaches through\nmultiple evaluation metrics. We find that both contributions to the attention\nmechanism and the encoder architecture additively improve the quality of\ngenerated text (BLEU and semantic equivalence), but also of synchronization.\nOur code will be made available at\n\\url{https://github.com/rd20karim/M2T-Segmentation/tree/main}",
            "author": [
                "Karim Radouane",
                "Andon Tchechmedjiev",
                "Sylvie Ranwez",
                "Julien Lagarde"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10594v1",
                "http://arxiv.org/pdf/2310.10594v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10590v1",
            "title": "Mastering the Task of Open Information Extraction with Large Language\n  Models and Consistent Reasoning Environment",
            "updated": "2023-10-16T17:11:42Z",
            "published": "2023-10-16T17:11:42Z",
            "summary": "Open Information Extraction (OIE) aims to extract objective structured\nknowledge from natural texts, which has attracted growing attention to build\ndedicated models with human experience. As the large language models (LLMs)\nhave exhibited remarkable in-context learning capabilities, a question arises\nas to whether the task of OIE can be effectively tackled with this paradigm? In\nthis paper, we explore solving the OIE problem by constructing an appropriate\nreasoning environment for LLMs. Specifically, we first propose a method to\neffectively estimate the discrepancy of syntactic distribution between a LLM\nand test samples, which can serve as correlation evidence for preparing\npositive demonstrations. Upon the evidence, we introduce a simple yet effective\nmechanism to establish the reasoning environment for LLMs on specific tasks.\nWithout bells and whistles, experimental results on the standard CaRB benchmark\ndemonstrate that our $6$-shot approach outperforms state-of-the-art supervised\nmethod, achieving an $55.3$ $F_1$ score. Further experiments on TACRED and\nACE05 show that our method can naturally generalize to other information\nextraction tasks, resulting in improvements of $5.7$ and $6.8$ $F_1$ scores,\nrespectively.",
            "author": [
                "Ji Qi",
                "Kaixuan Ji",
                "Xiaozhi Wang",
                "Jifan Yu",
                "Kaisheng Zeng",
                "Lei Hou",
                "Juanzi Li",
                "Bin Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10590v1",
                "http://arxiv.org/pdf/2310.10590v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10583v1",
            "title": "Who Are All The Stochastic Parrots Imitating? They Should Tell Us!",
            "updated": "2023-10-16T16:57:55Z",
            "published": "2023-10-16T16:57:55Z",
            "summary": "Both standalone language models (LMs) as well as LMs within downstream-task\nsystems have been shown to generate statements which are factually untrue. This\nproblem is especially severe for low-resource languages, where training data is\nscarce and of worse quality than for high-resource languages. In this opinion\npiece, we argue that LMs in their current state will never be fully trustworthy\nin critical settings and suggest a possible novel strategy to handle this\nissue: by building LMs such that can cite their sources - i.e., point a user to\nthe parts of their training data that back up their outputs. We first discuss\nwhich current NLP tasks would or would not benefit from such models. We then\nhighlight the expected benefits such models would bring, e.g., quick\nverifiability of statements. We end by outlining the individual tasks that\nwould need to be solved on the way to developing LMs with the ability to cite.\nWe hope to start a discussion about the field's current approach to building\nLMs, especially for low-resource languages, and the role of the training data\nin explaining model generations.",
            "author": [
                "Sagi Shaier",
                "Lawrence E. Hunter",
                "Katharina von der Wense"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10583v1",
                "http://arxiv.org/pdf/2310.10583v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10575v1",
            "title": "Matching the Neuronal Representations of V1 is Necessary to Improve\n  Robustness in CNNs with V1-like Front-ends",
            "updated": "2023-10-16T16:52:15Z",
            "published": "2023-10-16T16:52:15Z",
            "summary": "While some convolutional neural networks (CNNs) have achieved great success\nin object recognition, they struggle to identify objects in images corrupted\nwith different types of common noise patterns. Recently, it was shown that\nsimulating computations in early visual areas at the front of CNNs leads to\nimprovements in robustness to image corruptions. Here, we further explore this\nresult and show that the neuronal representations that emerge from precisely\nmatching the distribution of RF properties found in primate V1 is key for this\nimprovement in robustness. We built two variants of a model with a front-end\nmodeling the primate primary visual cortex (V1): one sampling RF properties\nuniformly and the other sampling from empirical biological distributions. The\nmodel with the biological sampling has a considerably higher robustness to\nimage corruptions that the uniform variant (relative difference of 8.72%).\nWhile similar neuronal sub-populations across the two variants have similar\nresponse properties and learn similar downstream weights, the impact on\ndownstream processing is strikingly different. This result sheds light on the\norigin of the improvements in robustness observed in some biologically-inspired\nmodels, pointing to the need of precisely mimicking the neuronal\nrepresentations found in the primate brain.",
            "author": [
                "Ruxandra Barbulescu",
                "Tiago Marques",
                "Arlindo L. Oliveira"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10575v1",
                "http://arxiv.org/pdf/2310.10575v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10571v1",
            "title": "Emerging Challenges in Personalized Medicine: Assessing Demographic\n  Effects on Biomedical Question Answering Systems",
            "updated": "2023-10-16T16:45:52Z",
            "published": "2023-10-16T16:45:52Z",
            "summary": "State-of-the-art question answering (QA) models exhibit a variety of social\nbiases (e.g., with respect to sex or race), generally explained by similar\nissues in their training data. However, what has been overlooked so far is that\nin the critical domain of biomedicine, any unjustified change in model output\ndue to patient demographics is problematic: it results in the unfair treatment\nof patients. Selecting only questions on biomedical topics whose answers do not\ndepend on ethnicity, sex, or sexual orientation, we ask the following research\nquestions: (RQ1) Do the answers of QA models change when being provided with\nirrelevant demographic information? (RQ2) Does the answer of RQ1 differ between\nknowledge graph (KG)-grounded and text-based QA systems? We find that\nirrelevant demographic information change up to 15% of the answers of a\nKG-grounded system and up to 23% of the answers of a text-based system,\nincluding changes that affect accuracy. We conclude that unjustified answer\nchanges caused by patient demographics are a frequent phenomenon, which raises\nfairness concerns and should be paid more attention to.",
            "author": [
                "Sagi Shaier",
                "Kevin Bennett",
                "Lawrence Hunter",
                "Katharina von der Wense"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10571v1",
                "http://arxiv.org/pdf/2310.10571v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10565v1",
            "title": "HelmSim: Learning Helmholtz Dynamics for Interpretable Fluid Simulation",
            "updated": "2023-10-16T16:38:32Z",
            "published": "2023-10-16T16:38:32Z",
            "summary": "Fluid simulation is a long-standing challenge due to the intrinsic\nhigh-dimensional non-linear dynamics. Previous methods usually utilize the\nnon-linear modeling capability of deep models to directly estimate velocity\nfields for future prediction. However, skipping over inherent physical\nproperties but directly learning superficial velocity fields will overwhelm the\nmodel from generating precise or physics-reliable results. In this paper, we\npropose the HelmSim toward an accurate and interpretable simulator for fluid.\nInspired by the Helmholtz theorem, we design a HelmDynamic block to learn the\nHelmholtz dynamics, which decomposes fluid dynamics into more solvable\ncurl-free and divergence-free parts, physically corresponding to potential and\nstream functions of fluid. By embedding the HelmDynamic block into a Multiscale\nIntegration Network, HelmSim can integrate learned Helmholtz dynamics along\ntemporal dimension in multiple spatial scales to yield future fluid. Comparing\nwith previous velocity estimating methods, HelmSim is faithfully derived from\nHelmholtz theorem and ravels out complex fluid dynamics with physically\ninterpretable evidence. Experimentally, our proposed HelmSim achieves the\nconsistent state-of-the-art in both numerical simulated and real-world observed\nbenchmarks, even for scenarios with complex boundaries.",
            "author": [
                "Lanxiang Xing",
                "Haixu Wu",
                "Yuezhou Ma",
                "Jianmin Wang",
                "Mingsheng Long"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10565v1",
                "http://arxiv.org/pdf/2310.10565v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10563v1",
            "title": "RefConv: Re-parameterized Refocusing Convolution for Powerful ConvNets",
            "updated": "2023-10-16T16:36:54Z",
            "published": "2023-10-16T16:36:54Z",
            "summary": "We propose Re-parameterized Refocusing Convolution (RefConv) as a replacement\nfor regular convolutional layers, which is a plug-and-play module to improve\nthe performance without any inference costs. Specifically, given a pre-trained\nmodel, RefConv applies a trainable Refocusing Transformation to the basis\nkernels inherited from the pre-trained model to establish connections among the\nparameters. For example, a depth-wise RefConv can relate the parameters of a\nspecific channel of convolution kernel to the parameters of the other kernel,\ni.e., make them refocus on the other parts of the model they have never\nattended to, rather than focus on the input features only. From another\nperspective, RefConv augments the priors of existing model structures by\nutilizing the representations encoded in the pre-trained parameters as the\npriors and refocusing on them to learn novel representations, thus further\nenhancing the representational capacity of the pre-trained model. Experimental\nresults validated that RefConv can improve multiple CNN-based models by a clear\nmargin on image classification (up to 1.47% higher top-1 accuracy on ImageNet),\nobject detection and semantic segmentation without introducing any extra\ninference costs or altering the original model structure. Further studies\ndemonstrated that RefConv can reduce the redundancy of channels and smooth the\nloss landscape, which explains its effectiveness.",
            "author": [
                "Zhicheng Cai",
                "Xiaohan Ding",
                "Qiu Shen",
                "Xun Cao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10563v1",
                "http://arxiv.org/pdf/2310.10563v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10560v1",
            "title": "Towards the Imagenets of ML4EDA",
            "updated": "2023-10-16T16:35:03Z",
            "published": "2023-10-16T16:35:03Z",
            "summary": "Despite the growing interest in ML-guided EDA tools from RTL to GDSII, there\nare no standard datasets or prototypical learning tasks defined for the EDA\nproblem domain. Experience from the computer vision community suggests that\nsuch datasets are crucial to spur further progress in ML for EDA. Here we\ndescribe our experience curating two large-scale, high-quality datasets for\nVerilog code generation and logic synthesis. The first, VeriGen, is a dataset\nof Verilog code collected from GitHub and Verilog textbooks. The second,\nOpenABC-D, is a large-scale, labeled dataset designed to aid ML for logic\nsynthesis tasks. The dataset consists of 870,000 And-Inverter-Graphs (AIGs)\nproduced from 1500 synthesis runs on a large number of open-source hardware\nprojects. In this paper we will discuss challenges in curating, maintaining and\ngrowing the size and scale of these datasets. We will also touch upon questions\nof dataset quality and security, and the use of novel data augmentation tools\nthat are tailored for the hardware domain.",
            "author": [
                "Animesh Basak Chowdhury",
                "Shailja Thakur",
                "Hammond Pearce",
                "Ramesh Karri",
                "Siddharth Garg"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10560v1",
                "http://arxiv.org/pdf/2310.10560v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.AR",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10559v1",
            "title": "Causal Dynamic Variational Autoencoder for Counterfactual Regression in\n  Longitudinal Data",
            "updated": "2023-10-16T16:32:35Z",
            "published": "2023-10-16T16:32:35Z",
            "summary": "Estimating treatment effects over time is relevant in many real-world\napplications, such as precision medicine, epidemiology, economy, and marketing.\nMany state-of-the-art methods either assume the observations of all confounders\nor seek to infer the unobserved ones. We take a different perspective by\nassuming unobserved risk factors, i.e., adjustment variables that affect only\nthe sequence of outcomes. Under unconfoundedness, we target the Individual\nTreatment Effect (ITE) estimation with unobserved heterogeneity in the\ntreatment response due to missing risk factors. We address the challenges posed\nby time-varying effects and unobserved adjustment variables. Led by theoretical\nresults over the validity of the learned adjustment variables and\ngeneralization bounds over the treatment effect, we devise Causal DVAE (CDVAE).\nThis model combines a Dynamic Variational Autoencoder (DVAE) framework with a\nweighting strategy using propensity scores to estimate counterfactual\nresponses. The CDVAE model allows for accurate estimation of ITE and captures\nthe underlying heterogeneity in longitudinal data. Evaluations of our model\nshow superior performance over state-of-the-art models.",
            "author": [
                "Mouad El Bouchattaoui",
                "Myriam Tami",
                "Benoit Lepetit",
                "Paul-Henry Courn\u00e8de"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10559v1",
                "http://arxiv.org/pdf/2310.10559v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10556v1",
            "title": "Sample Complexity of Preference-Based Nonparametric Off-Policy\n  Evaluation with Deep Networks",
            "updated": "2023-10-16T16:27:06Z",
            "published": "2023-10-16T16:27:06Z",
            "summary": "A recently popular approach to solving reinforcement learning is with data\nfrom human preferences. In fact, human preference data are now used with\nclassic reinforcement learning algorithms such as actor-critic methods, which\ninvolve evaluating an intermediate policy over a reward learned from human\npreference data with distribution shift, known as off-policy evaluation (OPE).\nSuch algorithm includes (i) learning reward function from human preference\ndataset, and (ii) learning expected cumulative reward of a target policy.\nDespite the huge empirical success, existing OPE methods with preference data\noften lack theoretical understanding and rely heavily on heuristics. In this\npaper, we study the sample efficiency of OPE with human preference and\nestablish a statistical guarantee for it. Specifically, we approach OPE by\nlearning the value function by fitted-Q-evaluation with a deep neural network.\nBy appropriately selecting the size of a ReLU network, we show that one can\nleverage any low-dimensional manifold structure in the Markov decision process\nand obtain a sample-efficient estimator without suffering from the curse of\nhigh data ambient dimensionality. Under the assumption of high reward\nsmoothness, our results \\textit{almost align with the classical OPE results\nwith observable reward data}. To the best of our knowledge, this is the first\nresult that establishes a \\textit{provably efficient} guarantee for off-policy\nevaluation with RLHF.",
            "author": [
                "Zihao Li",
                "Xiang Ji",
                "Minshuo Chen",
                "Mengdi Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10556v1",
                "http://arxiv.org/pdf/2310.10556v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10555v1",
            "title": "Population-based wind farm monitoring based on a spatial autoregressive\n  approach",
            "updated": "2023-10-16T16:26:40Z",
            "published": "2023-10-16T16:26:40Z",
            "summary": "An important challenge faced by wind farm operators is to reduce operation\nand maintenance cost. Structural health monitoring provides a means of cost\nreduction through minimising unnecessary maintenance trips as well as\nprolonging turbine service life. Population-based structural health monitoring\ncan further reduce the cost of health monitoring systems by implementing one\nsystem for multiple structures (i.e.~turbines). At the same time, shared data\nwithin a population of structures may improve the predictions of structural\nbehaviour. To monitor turbine performance at a population/farm level, an\nimportant initial step is to construct a model that describes the behaviour of\nall turbines under normal conditions. This paper proposes a population-level\nmodel that explicitly captures the spatial and temporal correlations (between\nturbines) induced by the wake effect. The proposed model is a Gaussian\nprocess-based spatial autoregressive model, named here a GP-SPARX model. This\napproach is developed since (a) it reflects our physical understanding of the\nwake effect, and (b) it benefits from a stochastic data-based learner. A case\nstudy is provided to demonstrate the capability of the GP-SPARX model in\ncapturing spatial and temporal variations as well as its potential\napplicability in a health monitoring system.",
            "author": [
                "W. Lin",
                "K. Worden",
                "E. J. Cross"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10555v1",
                "http://arxiv.org/pdf/2310.10555v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10553v2",
            "title": "TacticAI: an AI assistant for football tactics",
            "updated": "2023-10-17T13:46:50Z",
            "published": "2023-10-16T16:25:15Z",
            "summary": "Identifying key patterns of tactics implemented by rival teams, and\ndeveloping effective responses, lies at the heart of modern football. However,\ndoing so algorithmically remains an open research challenge. To address this\nunmet need, we propose TacticAI, an AI football tactics assistant developed and\nevaluated in close collaboration with domain experts from Liverpool FC. We\nfocus on analysing corner kicks, as they offer coaches the most direct\nopportunities for interventions and improvements. TacticAI incorporates both a\npredictive and a generative component, allowing the coaches to effectively\nsample and explore alternative player setups for each corner kick routine and\nto select those with the highest predicted likelihood of success. We validate\nTacticAI on a number of relevant benchmark tasks: predicting receivers and shot\nattempts and recommending player position adjustments. The utility of TacticAI\nis validated by a qualitative study conducted with football domain experts at\nLiverpool FC. We show that TacticAI's model suggestions are not only\nindistinguishable from real tactics, but also favoured over existing tactics\n90% of the time, and that TacticAI offers an effective corner kick retrieval\nsystem. TacticAI achieves these results despite the limited availability of\ngold-standard data, achieving data efficiency through geometric deep learning.",
            "author": [
                "Zhe Wang",
                "Petar Veli\u010dkovi\u0107",
                "Daniel Hennes",
                "Nenad Toma\u0161ev",
                "Laurel Prince",
                "Michael Kaisers",
                "Yoram Bachrach",
                "Romuald Elie",
                "Li Kevin Wenliang",
                "Federico Piccinini",
                "William Spearman",
                "Ian Graham",
                "Jerome Connor",
                "Yi Yang",
                "Adri\u00e0 Recasens",
                "Mina Khan",
                "Nathalie Beauguerlange",
                "Pablo Sprechmann",
                "Pol Moreno",
                "Nicolas Heess",
                "Michael Bowling",
                "Demis Hassabis",
                "Karl Tuyls"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10553v2",
                "http://arxiv.org/pdf/2310.10553v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.MA",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10707v1",
            "title": "Demonstrations Are All You Need: Advancing Offensive Content\n  Paraphrasing using In-Context Learning",
            "updated": "2023-10-16T16:18:55Z",
            "published": "2023-10-16T16:18:55Z",
            "summary": "Paraphrasing of offensive content is a better alternative to content removal\nand helps improve civility in a communication environment. Supervised\nparaphrasers; however, rely heavily on large quantities of labelled data to\nhelp preserve meaning and intent. They also retain a large portion of the\noffensiveness of the original content, which raises questions on their overall\nusability. In this paper we aim to assist practitioners in developing usable\nparaphrasers by exploring In-Context Learning (ICL) with large language models\n(LLMs), i.e., using a limited number of input-label demonstration pairs to\nguide the model in generating desired outputs for specific queries. Our study\nfocuses on key factors such as -- number and order of demonstrations, exclusion\nof prompt instruction, and reduction in measured toxicity. We perform\nprincipled evaluation on three datasets, including our proposed Context-Aware\nPolite Paraphrase dataset, comprising of dialogue-style rude utterances, polite\nparaphrases, and additional dialogue context. We evaluate our approach using\ntwo closed source and one open source LLM. Our results reveal that ICL is\ncomparable to supervised methods in generation quality, while being\nqualitatively better by 25% on human evaluation and attaining lower toxicity by\n76%. Also, ICL-based paraphrasers only show a slight reduction in performance\neven with just 10% training data.",
            "author": [
                "Anirudh Som",
                "Karan Sikka",
                "Helen Gent",
                "Ajay Divakaran",
                "Andreas Kathol",
                "Dimitra Vergyri"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10707v1",
                "http://arxiv.org/pdf/2310.10707v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10550v1",
            "title": "Deep learning applied to EEG data with different montages using spatial\n  attention",
            "updated": "2023-10-16T16:17:33Z",
            "published": "2023-10-16T16:17:33Z",
            "summary": "The ability of Deep Learning to process and extract relevant information in\ncomplex brain dynamics from raw EEG data has been demonstrated in various\nrecent works. Deep learning models, however, have also been shown to perform\nbest on large corpora of data. When processing EEG, a natural approach is to\ncombine EEG datasets from different experiments to train large deep-learning\nmodels. However, most EEG experiments use custom channel montages, requiring\nthe data to be transformed into a common space. Previous methods have used the\nraw EEG signal to extract features of interest and focused on using a common\nfeature space across EEG datasets. While this is a sensible approach, it\nunderexploits the potential richness of EEG raw data. Here, we explore using\nspatial attention applied to EEG electrode coordinates to perform channel\nharmonization of raw EEG data, allowing us to train deep learning on EEG data\nusing different montages. We test this model on a gender classification task.\nWe first show that spatial attention increases model performance. Then, we show\nthat a deep learning model trained on data using different channel montages\nperforms significantly better than deep learning models trained on fixed 23-\nand 128-channel data montages.",
            "author": [
                "Dung Truong",
                "Muhammad Abdullah Khalid",
                "Arnaud Delorme"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10550v1",
                "http://arxiv.org/pdf/2310.10550v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10549v1",
            "title": "Applications of Distributed Machine Learning for the Internet-of-Things:\n  A Comprehensive Survey",
            "updated": "2023-10-16T16:16:34Z",
            "published": "2023-10-16T16:16:34Z",
            "summary": "The emergence of new services and applications in emerging wireless networks\n(e.g., beyond 5G and 6G) has shown a growing demand for the usage of artificial\nintelligence (AI) in the Internet of Things (IoT). However, the proliferation\nof massive IoT connections and the availability of computing resources\ndistributed across future IoT systems have strongly demanded the development of\ndistributed AI for better IoT services and applications. Therefore, existing\nAI-enabled IoT systems can be enhanced by implementing distributed machine\nlearning (aka distributed learning) approaches. This work aims to provide a\ncomprehensive survey on distributed learning for IoT services and applications\nin emerging networks. In particular, we first provide a background of machine\nlearning and present a preliminary to typical distributed learning approaches,\nsuch as federated learning, multi-agent reinforcement learning, and distributed\ninference. Then, we provide an extensive review of distributed learning for\ncritical IoT services (e.g., data sharing and computation offloading,\nlocalization, mobile crowdsensing, and security and privacy) and IoT\napplications (e.g., smart healthcare, smart grid, autonomous vehicle, aerial\nIoT networks, and smart industry). From the reviewed literature, we also\npresent critical challenges of distributed learning for IoT and propose several\npromising solutions and research directions in this emerging area.",
            "author": [
                "Mai Le",
                "Thien Huynh-The",
                "Tan Do-Duy",
                "Thai-Hoc Vu",
                "Won-Joo Hwang",
                "Quoc-Viet Pham"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10549v1",
                "http://arxiv.org/pdf/2310.10549v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10547v1",
            "title": "InfoGCN++: Learning Representation by Predicting the Future for Online\n  Human Skeleton-based Action Recognition",
            "updated": "2023-10-16T16:15:11Z",
            "published": "2023-10-16T16:15:11Z",
            "summary": "Skeleton-based action recognition has made significant advancements recently,\nwith models like InfoGCN showcasing remarkable accuracy. However, these models\nexhibit a key limitation: they necessitate complete action observation prior to\nclassification, which constrains their applicability in real-time situations\nsuch as surveillance and robotic systems. To overcome this barrier, we\nintroduce InfoGCN++, an innovative extension of InfoGCN, explicitly developed\nfor online skeleton-based action recognition. InfoGCN++ augments the abilities\nof the original InfoGCN model by allowing real-time categorization of action\ntypes, independent of the observation sequence's length. It transcends\nconventional approaches by learning from current and anticipated future\nmovements, thereby creating a more thorough representation of the entire\nsequence. Our approach to prediction is managed as an extrapolation issue,\ngrounded on observed actions. To enable this, InfoGCN++ incorporates Neural\nOrdinary Differential Equations, a concept that lets it effectively model the\ncontinuous evolution of hidden states. Following rigorous evaluations on three\nskeleton-based action recognition benchmarks, InfoGCN++ demonstrates\nexceptional performance in online action recognition. It consistently equals or\nexceeds existing techniques, highlighting its significant potential to reshape\nthe landscape of real-time action recognition applications. Consequently, this\nwork represents a major leap forward from InfoGCN, pushing the limits of what's\npossible in online, skeleton-based action recognition. The code for InfoGCN++\nis publicly available at https://github.com/stnoah1/infogcn2 for further\nexploration and validation.",
            "author": [
                "Seunggeun Chi",
                "Hyung-gun Chi",
                "Qixing Huang",
                "Karthik Ramani"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10547v1",
                "http://arxiv.org/pdf/2310.10547v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10545v1",
            "title": "Optimal vintage factor analysis with deflation varimax",
            "updated": "2023-10-16T16:14:43Z",
            "published": "2023-10-16T16:14:43Z",
            "summary": "Vintage factor analysis is one important type of factor analysis that aims to\nfirst find a low-dimensional representation of the original data, and then to\nseek a rotation such that the rotated low-dimensional representation is\nscientifically meaningful. Perhaps the most widely used vintage factor analysis\nis the Principal Component Analysis (PCA) followed by the varimax rotation.\nDespite its popularity, little theoretical guarantee can be provided mainly\nbecause varimax rotation requires to solve a non-convex optimization over the\nset of orthogonal matrices.\n  In this paper, we propose a deflation varimax procedure that solves each row\nof an orthogonal matrix sequentially. In addition to its net computational gain\nand flexibility, we are able to fully establish theoretical guarantees for the\nproposed procedure in a broad context.\n  Adopting this new varimax approach as the second step after PCA, we further\nanalyze this two step procedure under a general class of factor models. Our\nresults show that it estimates the factor loading matrix in the optimal rate\nwhen the signal-to-noise-ratio (SNR) is moderate or large. In the low SNR\nregime, we offer possible improvement over using PCA and the deflation\nprocedure when the additive noise under the factor model is structured. The\nmodified procedure is shown to be optimal in all SNR regimes. Our theory is\nvalid for finite sample and allows the number of the latent factors to grow\nwith the sample size as well as the ambient dimension to grow with, or even\nexceed, the sample size.\n  Extensive simulation and real data analysis further corroborate our\ntheoretical findings.",
            "author": [
                "Xin Bing",
                "Dian Jin",
                "Yuqian Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10545v1",
                "http://arxiv.org/pdf/2310.10545v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.IT",
                "cs.LG",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10541v2",
            "title": "AST: Effective Dataset Distillation through Alignment with Smooth and\n  High-Quality Expert Trajectories",
            "updated": "2023-11-27T16:45:18Z",
            "published": "2023-10-16T16:13:53Z",
            "summary": "Training large AI models typically requires large-scale datasets in the\nmachine learning process, making training and parameter-tuning process both\ntime-consuming and costly. Some researchers address this problem by carefully\nsynthesizing a very small number of highly representative and informative\nsamples from real-world datasets. This approach, known as Dataset Distillation\n(DD), proposes a perspective for data-efficient learning. Despite recent\nprogress in this field, the performance of existing methods still cannot meet\nexpectations, and distilled datasets cannot effectively replace original\ndatasets. In this paper, unlike previous methods that focus solely on improving\nthe effectiveness of student distillation, we recognize and leverage the\nimportant mutual influence between expert and student models. We observed that\nthe smoothness of expert trajectories has a significant impact on subsequent\nstudent parameter alignment. Based on this, we propose an effective DD\nframework named AST, standing for Alignment with Smooth and high-quality expert\nTrajectories. We devise the integration of clipping loss and gradient penalty\nto regulate the rate of parameter changes in expert trajectory generation. To\nfurther refine the student parameter alignment with expert trajectory, we put\nforward representative initialization for the synthetic dataset and balanced\ninner-loop loss in response to the sensitivity exhibited towards randomly\ninitialized variables during distillation. We also propose two enhancement\nstrategies, namely intermediate matching loss and weight perturbation, to\nmitigate the potential occurrence of cumulative errors. We conduct extensive\nexperiments on datasets of different scales, sizes, and resolutions. The\nresults demonstrate that the proposed method significantly outperforms prior\nmethods.",
            "author": [
                "Jiyuan Shen",
                "Wenzhuo Yang",
                "Kwok-Yan Lam"
            ],
            "link": [
                "http://dx.doi.org/10.48550/arXiv.2310.10541",
                "http://arxiv.org/abs/2310.10541v2",
                "http://arxiv.org/pdf/2310.10541v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10537v3",
            "title": "Microscaling Data Formats for Deep Learning",
            "updated": "2023-10-19T16:38:33Z",
            "published": "2023-10-16T16:07:41Z",
            "summary": "Narrow bit-width data formats are key to reducing the computational and\nstorage costs of modern deep learning applications. This paper evaluates\nMicroscaling (MX) data formats that combine a per-block scaling factor with\nnarrow floating-point and integer types for individual elements. MX formats\nbalance the competing needs of hardware efficiency, model accuracy, and user\nfriction. Empirical results on over two dozen benchmarks demonstrate\npracticality of MX data formats as a drop-in replacement for baseline FP32 for\nAI inference and training with low user friction. We also show the first\ninstance of training generative language models at sub-8-bit weights,\nactivations, and gradients with minimal accuracy loss and no modifications to\nthe training recipe.",
            "author": [
                "Bita Darvish Rouhani",
                "Ritchie Zhao",
                "Ankit More",
                "Mathew Hall",
                "Alireza Khodamoradi",
                "Summer Deng",
                "Dhruv Choudhary",
                "Marius Cornea",
                "Eric Dellinger",
                "Kristof Denolf",
                "Stosic Dusan",
                "Venmugil Elango",
                "Maximilian Golub",
                "Alexander Heinecke",
                "Phil James-Roxby",
                "Dharmesh Jani",
                "Gaurav Kolhe",
                "Martin Langhammer",
                "Ada Li",
                "Levi Melnick",
                "Maral Mesmakhosroshahi",
                "Andres Rodriguez",
                "Michael Schulte",
                "Rasoul Shafipour",
                "Lei Shao",
                "Michael Siu",
                "Pradeep Dubey",
                "Paulius Micikevicius",
                "Maxim Naumov",
                "Colin Verrilli",
                "Ralph Wittig",
                "Doug Burger",
                "Eric Chung"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10537v3",
                "http://arxiv.org/pdf/2310.10537v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10534v1",
            "title": "Comparing Comparators in Generalization Bounds",
            "updated": "2023-10-16T16:00:58Z",
            "published": "2023-10-16T16:00:58Z",
            "summary": "We derive generic information-theoretic and PAC-Bayesian generalization\nbounds involving an arbitrary convex comparator function, which measures the\ndiscrepancy between the training and population loss. The bounds hold under the\nassumption that the cumulant-generating function (CGF) of the comparator is\nupper-bounded by the corresponding CGF within a family of bounding\ndistributions. We show that the tightest possible bound is obtained with the\ncomparator being the convex conjugate of the CGF of the bounding distribution,\nalso known as the Cram\\'er function. This conclusion applies more broadly to\ngeneralization bounds with a similar structure. This confirms the\nnear-optimality of known bounds for bounded and sub-Gaussian losses and leads\nto novel bounds under other bounding distributions.",
            "author": [
                "Fredrik Hellstr\u00f6m",
                "Benjamin Guedj"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10534v1",
                "http://arxiv.org/pdf/2310.10534v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IT",
                "math.IT",
                "math.ST",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10531v1",
            "title": "Learning optimal integration of spatial and temporal information in\n  noisy chemotaxis",
            "updated": "2023-10-16T15:50:23Z",
            "published": "2023-10-16T15:50:23Z",
            "summary": "We investigate the boundary between chemotaxis driven by spatial estimation\nof gradients and chemotaxis driven by temporal estimation. While it is well\nknown that spatial chemotaxis becomes disadvantageous for small organisms at\nhigh noise levels, it is unclear whether there is a discontinuous switch of\noptimal strategies or a continuous transition exists. Here, we employ deep\nreinforcement learning to study the possible integration of spatial and\ntemporal information in an a priori unconstrained manner. We parameterize such\na combined chemotactic policy by a recurrent neural network and evaluate it\nusing a minimal theoretical model of a chemotactic cell. By comparing with\nconstrained variants of the policy, we show that it converges to purely\ntemporal and spatial strategies at small and large cell sizes, respectively. We\nfind that the transition between the regimes is continuous, with the combined\nstrategy outperforming in the transition region both the constrained variants\nas well as models that explicitly integrate spatial and temporal information.\nFinally, by utilizing the attribution method of integrated gradients, we show\nthat the policy relies on a non-trivial combination of spatially and temporally\nderived gradient information in a ratio that varies dynamically during the\nchemotactic trajectories.",
            "author": [
                "Albert Alonso",
                "Julius B. Kirkegaard"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10531v1",
                "http://arxiv.org/pdf/2310.10531v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.LG",
                "physics.bio-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10523v1",
            "title": "From Spectral Theorem to Statistical Independence with Application to\n  System Identification",
            "updated": "2023-10-16T15:40:43Z",
            "published": "2023-10-16T15:40:43Z",
            "summary": "High dimensional random dynamical systems are ubiquitous, including -- but\nnot limited to -- cyber-physical systems, daily return on different stocks of\nS&P 1500 and velocity profile of interacting particle systems around\nMcKeanVlasov limit. Mathematically, underlying phenomenon can be captured via a\nstable $n$-dimensional linear transformation `$A$' and additive randomness.\nSystem identification aims at extracting useful information about underlying\ndynamical system, given a length $N$ trajectory from it (corresponds to an $n\n\\times N$ dimensional data matrix). We use spectral theorem for non-Hermitian\noperators to show that spatio-temperal correlations are dictated by the\ndiscrepancy between algebraic and geometric multiplicity of distinct\neigenvalues corresponding to state transition matrix. Small discrepancies imply\nthat original trajectory essentially comprises of multiple lower dimensional\nrandom dynamical systems living on $A$ invariant subspaces and are\nstatistically independent of each other. In the process, we provide first\nquantitative handle on decay rate of finite powers of state transition matrix\n$\\|A^{k}\\|$ . It is shown that when a stable dynamical system has only one\ndistinct eigenvalue and discrepancy of $n-1$: $\\|A\\|$ has a dependence on $n$,\nresulting dynamics are spatially inseparable and consequently there exist at\nleast one row with covariates of typical size $\\Theta\\big(\\sqrt{N-n+1}$\n$e^{n}\\big)$ i.e., even under stability assumption, covariates can suffer from\ncurse of dimensionality. In the light of these findings we set the stage for\nnon-asymptotic error analysis in estimation of state transition matrix $A$ via\nleast squares regression on observed trajectory by showing that element-wise\nerror is essentially a variant of well-know Littlewood-Offord problem.",
            "author": [
                "Muhammad Abdullah Naeem",
                "Amir Khazraei",
                "Miroslav Pajic"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10523v1",
                "http://arxiv.org/pdf/2310.10523v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "cs.LG",
                "cs.SY",
                "eess.SY",
                "math.PR",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10521v1",
            "title": "Reproducing Bayesian Posterior Distributions for Exoplanet Atmospheric\n  Parameter Retrievals with a Machine Learning Surrogate Model",
            "updated": "2023-10-16T15:39:05Z",
            "published": "2023-10-16T15:39:05Z",
            "summary": "We describe a machine-learning-based surrogate model for reproducing the\nBayesian posterior distributions for exoplanet atmospheric parameters derived\nfrom transmission spectra of transiting planets with typical retrieval software\nsuch as TauRex. The model is trained on ground truth distributions for seven\nparameters: the planet radius, the atmospheric temperature, and the mixing\nratios for five common absorbers: $H_2O$, $CH_4$, $NH_3$, $CO$ and $CO_2$. The\nmodel performance is enhanced by domain-inspired preprocessing of the features\nand the use of semi-supervised learning in order to leverage the large amount\nof unlabelled training data available. The model was among the winning\nsolutions in the 2023 Ariel Machine Learning Data Challenge.",
            "author": [
                "Eyup B. Unlu",
                "Roy T. Forestano",
                "Konstantin T. Matchev",
                "Katia Matcheva"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10521v1",
                "http://arxiv.org/pdf/2310.10521v1"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP",
                "astro-ph.IM",
                "cs.LG",
                "physics.data-an"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10520v3",
            "title": "Semantic Parsing by Large Language Models for Intricate Updating\n  Strategies of Zero-Shot Dialogue State Tracking",
            "updated": "2023-11-25T02:09:35Z",
            "published": "2023-10-16T15:38:02Z",
            "summary": "Zero-shot Dialogue State Tracking (DST) addresses the challenge of acquiring\nand annotating task-oriented dialogues, which can be time-consuming and costly.\nHowever, DST extends beyond simple slot-filling and requires effective updating\nstrategies for tracking dialogue state as conversations progress. In this\npaper, we propose ParsingDST, a new In-Context Learning (ICL) method, to\nintroduce additional intricate updating strategies in zero-shot DST. Our\napproach reformulates the DST task by leveraging powerful Large Language Models\n(LLMs) and translating the original dialogue text to JSON through semantic\nparsing as an intermediate state. We also design a novel framework that\nincludes more modules to ensure the effectiveness of updating strategies in the\ntext-to-JSON process. Experimental results demonstrate that our approach\noutperforms existing zero-shot DST methods on MultiWOZ, exhibiting significant\nimprovements in Joint Goal Accuracy (JGA) and slot accuracy compared to\nexisting ICL methods. Our code has been released.",
            "author": [
                "Yuxiang Wu",
                "Guanting Dong",
                "Weiran Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10520v3",
                "http://arxiv.org/pdf/2310.10520v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10513v1",
            "title": "Unifying Image Processing as Visual Prompting Question Answering",
            "updated": "2023-10-16T15:32:57Z",
            "published": "2023-10-16T15:32:57Z",
            "summary": "Image processing is a fundamental task in computer vision, which aims at\nenhancing image quality and extracting essential features for subsequent vision\napplications. Traditionally, task-specific models are developed for individual\ntasks and designing such models requires distinct expertise. Building upon the\nsuccess of large language models (LLMs) in natural language processing (NLP),\nthere is a similar trend in computer vision, which focuses on developing\nlarge-scale models through pretraining and in-context learning. This paradigm\nshift reduces the reliance on task-specific models, yielding a powerful unified\nmodel to deal with various tasks. However, these advances have predominantly\nconcentrated on high-level vision tasks, with less attention paid to low-level\nvision tasks. To address this issue, we propose a universal model for general\nimage processing that covers image restoration, image enhancement, image\nfeature extraction tasks, \\textit{etc}. Our proposed framework, named\nPromptGIP, unifies these diverse image processing tasks within a universal\nframework. Inspired by NLP question answering (QA) techniques, we employ a\nvisual prompting question answering paradigm. Specifically, we treat the\ninput-output image pair as a structured question-answer sentence, thereby\nreprogramming the image processing task as a prompting QA problem. PromptGIP\ncan undertake diverse \\textbf{cross-domain} tasks using provided visual\nprompts, eliminating the need for task-specific finetuning. Our methodology\noffers a universal and adaptive solution to general image processing. While\nPromptGIP has demonstrated a certain degree of out-of-domain task\ngeneralization capability, further research is expected to fully explore its\nmore powerful emergent generalization.",
            "author": [
                "Yihao Liu",
                "Xiangyu Chen",
                "Xianzheng Ma",
                "Xintao Wang",
                "Jiantao Zhou",
                "Yu Qiao",
                "Chao Dong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10513v1",
                "http://arxiv.org/pdf/2310.10513v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10509v1",
            "title": "Efficient Sim-to-real Transfer of Contact-Rich Manipulation Skills with\n  Online Admittance Residual Learning",
            "updated": "2023-10-16T15:28:10Z",
            "published": "2023-10-16T15:28:10Z",
            "summary": "Learning contact-rich manipulation skills is essential. Such skills require\nthe robots to interact with the environment with feasible manipulation\ntrajectories and suitable compliance control parameters to enable safe and\nstable contact. However, learning these skills is challenging due to data\ninefficiency in the real world and the sim-to-real gap in simulation. In this\npaper, we introduce a hybrid offline-online framework to learn robust\nmanipulation skills. We employ model-free reinforcement learning for the\noffline phase to obtain the robot motion and compliance control parameters in\nsimulation \\RV{with domain randomization}. Subsequently, in the online phase,\nwe learn the residual of the compliance control parameters to maximize robot\nperformance-related criteria with force sensor measurements in real time. To\ndemonstrate the effectiveness and robustness of our approach, we provide\ncomparative results against existing methods for assembly, pivoting, and\nscrewing tasks.",
            "author": [
                "Xiang Zhang",
                "Changhao Wang",
                "Lingfeng Sun",
                "Zheng Wu",
                "Xinghao Zhu",
                "Masayoshi Tomizuka"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10509v1",
                "http://arxiv.org/pdf/2310.10509v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10505v2",
            "title": "ReMax: A Simple, Effective, and Efficient Reinforcement Learning Method\n  for Aligning Large Language Models",
            "updated": "2023-10-17T06:39:21Z",
            "published": "2023-10-16T15:25:14Z",
            "summary": "Alignment is of critical importance for training large language models\n(LLMs). The predominant strategy to address this is through Reinforcement\nLearning from Human Feedback (RLHF), where PPO serves as the de-facto\nalgorithm. Yet, PPO is known to suffer from computational inefficiency, which\nis a challenge that this paper aims to address. We identify three important\nproperties in RLHF tasks: fast simulation, deterministic transitions, and\ntrajectory-level rewards, which are not leveraged in PPO. Based on such\nobservations, we develop a new algorithm tailored for RLHF, called ReMax. The\nalgorithm design of ReMax is built on a celebrated algorithm REINFORCE but is\nequipped with a new variance-reduction technique.\n  Our method has three-fold advantages over PPO: first, ReMax is simple to\nimplement and removes many hyper-parameters in PPO, which are scale-sensitive\nand laborious to tune. Second, ReMax saves about 50% memory usage in principle.\nAs a result, PPO runs out-of-memory when fine-tuning a Llama2 (7B) model on\n8xA100-40GB GPUs, whereas ReMax can afford training. This memory improvement is\nachieved by removing the value model in PPO. Third, based on our calculations,\nwe find that even assuming PPO can afford the training of Llama2 (7B), it would\nstill run about 2x slower than ReMax. This is due to the computational overhead\nof the value model, which does not exist in ReMax. Importantly, the above\ncomputational improvements do not sacrifice the performance. We hypothesize\nthese advantages can be maintained in larger-scaled models. Our implementation\nof ReMax is available at https://github.com/liziniu/ReMax",
            "author": [
                "Ziniu Li",
                "Tian Xu",
                "Yushun Zhang",
                "Yang Yu",
                "Ruoyu Sun",
                "Zhi-Quan Luo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10505v2",
                "http://arxiv.org/pdf/2310.10505v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10500v1",
            "title": "Few-Shot Learning Patterns in Financial Time-Series for Trend-Following\n  Strategies",
            "updated": "2023-10-16T15:20:12Z",
            "published": "2023-10-16T15:20:12Z",
            "summary": "Forecasting models for systematic trading strategies do not adapt quickly\nwhen financial market conditions change, as was seen in the advent of the\nCOVID-19 pandemic in 2020, when market conditions changed dramatically causing\nmany forecasting models to take loss-making positions. To deal with such\nsituations, we propose a novel time-series trend-following forecaster that is\nable to quickly adapt to new market conditions, referred to as regimes. We\nleverage recent developments from the deep learning community and use few-shot\nlearning. We propose the Cross Attentive Time-Series Trend Network - X-Trend -\nwhich takes positions attending over a context set of financial time-series\nregimes. X-Trend transfers trends from similar patterns in the context set to\nmake predictions and take positions for a new distinct target regime. X-Trend\nis able to quickly adapt to new financial regimes with a Sharpe ratio increase\nof 18.9% over a neural forecaster and 10-fold over a conventional Time-series\nMomentum strategy during the turbulent market period from 2018 to 2023. Our\nstrategy recovers twice as quickly from the COVID-19 drawdown compared to the\nneural-forecaster. X-Trend can also take zero-shot positions on novel unseen\nfinancial assets obtaining a 5-fold Sharpe ratio increase versus a neural\ntime-series trend forecaster over the same period. X-Trend both forecasts\nnext-day prices and outputs a trading signal. Furthermore, the cross-attention\nmechanism allows us to interpret the relationship between forecasts and\npatterns in the context set.",
            "author": [
                "Kieran Wood",
                "Samuel Kessler",
                "Stephen J. Roberts",
                "Stefan Zohren"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10500v1",
                "http://arxiv.org/pdf/2310.10500v1"
            ],
            "primary_category": "q-fin.TR",
            "category": [
                "q-fin.TR",
                "cs.LG",
                "q-fin.PM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10494v1",
            "title": "Multivariate Scalar on Multidimensional Distribution Regression",
            "updated": "2023-10-16T15:17:11Z",
            "published": "2023-10-16T15:17:11Z",
            "summary": "We develop a new method for multivariate scalar on multidimensional\ndistribution regression. Traditional approaches typically analyze isolated\nunivariate scalar outcomes or consider unidimensional distributional\nrepresentations as predictors. However, these approaches are sub-optimal\nbecause: i) they fail to utilize the dependence between the distributional\npredictors: ii) neglect the correlation structure of the response. To overcome\nthese limitations, we propose a multivariate distributional analysis framework\nthat harnesses the power of multivariate density functions and multitask\nlearning. We develop a computationally efficient semiparametric estimation\nmethod for modelling the effect of the latent joint density on multivariate\nresponse of interest. Additionally, we introduce a new conformal algorithm for\nquantifying the uncertainty of regression models with multivariate responses\nand distributional predictors, providing valuable insights into the conditional\ndistribution of the response. We have validated the effectiveness of our\nproposed method through comprehensive numerical simulations, clearly\ndemonstrating its superior performance compared to traditional methods. The\napplication of the proposed method is demonstrated on tri-axial accelerometer\ndata from the National Health and Nutrition Examination Survey (NHANES)\n2011-2014 for modelling the association between cognitive scores across various\ndomains and distributional representation of physical activity among older\nadult population. Our results highlight the advantages of the proposed\napproach, emphasizing the significance of incorporating complete spatial\ninformation derived from the accelerometer device.",
            "author": [
                "Rahul Ghosal",
                "Marcos Matabuena"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10494v1",
                "http://arxiv.org/pdf/2310.10494v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10492v1",
            "title": "UNO-DST: Leveraging Unlabelled Data in Zero-Shot Dialogue State Tracking",
            "updated": "2023-10-16T15:16:16Z",
            "published": "2023-10-16T15:16:16Z",
            "summary": "Previous zero-shot dialogue state tracking (DST) methods only apply transfer\nlearning, but ignore unlabelled data in the target domain. We transform\nzero-shot DST into few-shot DST by utilising such unlabelled data via joint and\nself-training methods. Our method incorporates auxiliary tasks that generate\nslot types as inverse prompts for main tasks, creating slot values during joint\ntraining. Cycle consistency between these two tasks enables the generation and\nselection of quality samples in unknown target domains for subsequent\nfine-tuning. This approach also facilitates automatic label creation, thereby\noptimizing the training and fine-tuning of DST models. We demonstrate this\nmethod's effectiveness on large language models in zero-shot scenarios,\nimproving average joint goal accuracy by $8\\%$ across all domains in MultiWOZ.",
            "author": [
                "Chuang Li",
                "Yan Zhang",
                "Min-Yen Kan",
                "Haizhou Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10492v1",
                "http://arxiv.org/pdf/2310.10492v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10490v1",
            "title": "On the Transferability of Learning Models for Semantic Segmentation for\n  Remote Sensing Data",
            "updated": "2023-10-16T15:13:36Z",
            "published": "2023-10-16T15:13:36Z",
            "summary": "Recent deep learning-based methods outperform traditional learning methods on\nremote sensing (RS) semantic segmentation/classification tasks. However, they\nrequire large training datasets and are generally known for lack of\ntransferability due to the highly disparate RS image content across different\ngeographical regions. Yet, there is no comprehensive analysis of their\ntransferability, i.e., to which extent a model trained on a source domain can\nbe readily applicable to a target domain. Therefore, in this paper, we aim to\ninvestigate the raw transferability of traditional and deep learning (DL)\nmodels, as well as the effectiveness of domain adaptation (DA) approaches in\nenhancing the transferability of the DL models (adapted transferability). By\nutilizing four highly diverse RS datasets, we train six models with and without\nthree DA approaches to analyze their transferability between these datasets\nquantitatively. Furthermore, we developed a straightforward method to quantify\nthe transferability of a model using the spectral indices as a medium and have\ndemonstrated its effectiveness in evaluating the model transferability at the\ntarget domain when the labels are unavailable. Our experiments yield several\ngenerally important yet not well-reported observations regarding the raw and\nadapted transferability. Moreover, our proposed label-free transferability\nassessment method is validated to be better than posterior model confidence.\nThe findings can guide the future development of generalized RS learning\nmodels. The trained models are released under this link:\nhttps://github.com/GDAOSU/Transferability-Remote-Sensing",
            "author": [
                "Rongjun Qin",
                "Guixiang Zhang",
                "Yang Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10490v1",
                "http://arxiv.org/pdf/2310.10490v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10487v1",
            "title": "Type-aware Decoding via Explicitly Aggregating Event Information for\n  Document-level Event Extraction",
            "updated": "2023-10-16T15:10:42Z",
            "published": "2023-10-16T15:10:42Z",
            "summary": "Document-level event extraction (DEE) faces two main challenges:\narguments-scattering and multi-event. Although previous methods attempt to\naddress these challenges, they overlook the interference of event-unrelated\nsentences during event detection and neglect the mutual interference of\ndifferent event roles during argument extraction. Therefore, this paper\nproposes a novel Schema-based Explicitly Aggregating~(SEA) model to address\nthese limitations. SEA aggregates event information into event type and role\nrepresentations, enabling the decoding of event records based on specific\ntype-aware representations. By detecting each event based on its event type\nrepresentation, SEA mitigates the interference caused by event-unrelated\ninformation. Furthermore, SEA extracts arguments for each role based on its\nrole-aware representations, reducing mutual interference between different\nroles. Experimental results on the ChFinAnn and DuEE-fin datasets show that SEA\noutperforms the SOTA methods.",
            "author": [
                "Gang Zhao",
                "Yidong Shi",
                "Shudong Lu",
                "Xinjie Yang",
                "Guanting Dong",
                "Jian Xu",
                "Xiaocheng Gong",
                "Si Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10487v1",
                "http://arxiv.org/pdf/2310.10487v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10486v1",
            "title": "ManyQuadrupeds: Learning a Single Locomotion Policy for Diverse\n  Quadruped Robots",
            "updated": "2023-10-16T15:06:16Z",
            "published": "2023-10-16T15:06:16Z",
            "summary": "Learning a locomotion policy for quadruped robots has traditionally been\nconstrained to specific robot morphology, mass, and size. The learning process\nmust usually be repeated for every new robot, where hyperparameters and reward\nfunction weights must be re-tuned to maximize performance for each new system.\nAlternatively, attempting to train a single policy to accommodate different\nrobot sizes, while maintaining the same degrees of freedom (DoF) and\nmorphology, requires either complex learning frameworks, or mass, inertia, and\ndimension randomization, which leads to prolonged training periods. In our\nstudy, we show that drawing inspiration from animal motor control allows us to\neffectively train a single locomotion policy capable of controlling a diverse\nrange of quadruped robots. These differences encompass a variable number of\nDoFs, (i.e. 12 or 16 joints), three distinct morphologies, a broad mass range\nspanning from 2 kg to 200 kg, and nominal standing heights ranging from 16 cm\nto 100 cm. Our policy modulates a representation of the Central Pattern\nGenerator (CPG) in the spinal cord, effectively coordinating both frequencies\nand amplitudes of the CPG to produce rhythmic output (Rhythm Generation), which\nis then mapped to a Pattern Formation (PF) layer. Across different robots, the\nonly varying component is the PF layer, which adjusts the scaling parameters\nfor the stride height and length. Subsequently, we evaluate the sim-to-real\ntransfer by testing the single policy on both the Unitree Go1 and A1 robots.\nRemarkably, we observe robust performance, even when adding a 15 kg load,\nequivalent to 125% of the A1 robot's nominal mass.",
            "author": [
                "Milad Shafiee",
                "Guillaume Bellegarda",
                "Auke Ijspeert"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10486v1",
                "http://arxiv.org/pdf/2310.10486v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10483v1",
            "title": "Passive Inference Attacks on Split Learning via Adversarial\n  Regularization",
            "updated": "2023-10-16T15:03:55Z",
            "published": "2023-10-16T15:03:55Z",
            "summary": "Split Learning (SL) has emerged as a practical and efficient alternative to\ntraditional federated learning. While previous attempts to attack SL have often\nrelied on overly strong assumptions or targeted easily exploitable models, we\nseek to develop more practical attacks. We introduce SDAR, a novel attack\nframework against SL with an honest-but-curious server. SDAR leverages\nauxiliary data and adversarial regularization to learn a decodable simulator of\nthe client's private model, which can effectively infer the client's private\nfeatures under the vanilla SL, and both features and labels under the U-shaped\nSL. We perform extensive experiments in both configurations to validate the\neffectiveness of our proposed attacks. Notably, in challenging but practical\nscenarios where existing passive attacks struggle to reconstruct the client's\nprivate data effectively, SDAR consistently achieves attack performance\ncomparable to active attacks. On CIFAR-10, at the deep split level of 7, SDAR\nachieves private feature reconstruction with less than 0.025 mean squared error\nin both the vanilla and the U-shaped SL, and attains a label inference accuracy\nof over 98% in the U-shaped setting, while existing attacks fail to produce\nnon-trivial results.",
            "author": [
                "Xiaochen Zhu",
                "Xinjian Luo",
                "Yuncheng Wu",
                "Yangfan Jiang",
                "Xiaokui Xiao",
                "Beng Chin Ooi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10483v1",
                "http://arxiv.org/pdf/2310.10483v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10482v1",
            "title": "xCOMET: Transparent Machine Translation Evaluation through Fine-grained\n  Error Detection",
            "updated": "2023-10-16T15:03:14Z",
            "published": "2023-10-16T15:03:14Z",
            "summary": "Widely used learned metrics for machine translation evaluation, such as COMET\nand BLEURT, estimate the quality of a translation hypothesis by providing a\nsingle sentence-level score. As such, they offer little insight into\ntranslation errors (e.g., what are the errors and what is their severity). On\nthe other hand, generative large language models (LLMs) are amplifying the\nadoption of more granular strategies to evaluation, attempting to detail and\ncategorize translation errors. In this work, we introduce xCOMET, an\nopen-source learned metric designed to bridge the gap between these approaches.\nxCOMET integrates both sentence-level evaluation and error span detection\ncapabilities, exhibiting state-of-the-art performance across all types of\nevaluation (sentence-level, system-level, and error span detection). Moreover,\nit does so while highlighting and categorizing error spans, thus enriching the\nquality assessment. We also provide a robustness analysis with stress tests,\nand show that xCOMET is largely capable of identifying localized critical\nerrors and hallucinations.",
            "author": [
                "Nuno M. Guerreiro",
                "Ricardo Rei",
                "Daan van Stigt",
                "Luisa Coheur",
                "Pierre Colombo",
                "Andr\u00e9 F. T. Martins"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10482v1",
                "http://arxiv.org/pdf/2310.10482v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10481v1",
            "title": "DemoSG: Demonstration-enhanced Schema-guided Generation for Low-resource\n  Event Extraction",
            "updated": "2023-10-16T15:02:37Z",
            "published": "2023-10-16T15:02:37Z",
            "summary": "Most current Event Extraction (EE) methods focus on the high-resource\nscenario, which requires a large amount of annotated data and can hardly be\napplied to low-resource domains. To address EE more effectively with limited\nresources, we propose the Demonstration-enhanced Schema-guided Generation\n(DemoSG) model, which benefits low-resource EE from two aspects: Firstly, we\npropose the demonstration-based learning paradigm for EE to fully use the\nannotated data, which transforms them into demonstrations to illustrate the\nextraction process and help the model learn effectively. Secondly, we formulate\nEE as a natural language generation task guided by schema-based prompts,\nthereby leveraging label semantics and promoting knowledge transfer in\nlow-resource scenarios. We conduct extensive experiments under in-domain and\ndomain adaptation low-resource settings on three datasets, and study the\nrobustness of DemoSG. The results show that DemoSG significantly outperforms\ncurrent methods in low-resource scenarios.",
            "author": [
                "Gang Zhao",
                "Xiaocheng Gong",
                "Xinjie Yang",
                "Guanting Dong",
                "Shudong Lu",
                "Si Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10481v1",
                "http://arxiv.org/pdf/2310.10481v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10480v1",
            "title": "G-SPEED: General SParse Efficient Editing MoDel",
            "updated": "2023-10-16T15:01:18Z",
            "published": "2023-10-16T15:01:18Z",
            "summary": "Large Language Models~(LLMs) have demonstrated incredible capabilities in\nunderstanding, generating, and manipulating languages. Through human-model\ninteractions, LLMs can automatically understand human-issued instructions and\noutput the expected contents, which can significantly increase working\nefficiency. In various types of real-world demands, editing-oriented tasks\naccount for a considerable proportion, which involves an interactive process\nthat entails the continuous refinement of existing texts to meet specific\ncriteria. Due to the need for multi-round human-model interaction and the\ngeneration of complicated editing tasks, there is an emergent need for\nefficient general editing models. In this paper, we propose\n\\underline{\\textbf{G}}eneral \\underline{\\textbf{SP}}arse\n\\underline{\\textbf{E}}fficient \\underline{\\textbf{E}}diting\nMo\\underline{\\textbf{D}}el~(\\textbf{G-SPEED}), which can fulfill diverse\nediting requirements through a single model while maintaining low computational\ncosts. Specifically, we first propose a novel unsupervised text editing data\nclustering algorithm to deal with the data scarcity problem. Subsequently, we\nintroduce a sparse editing model architecture to mitigate the inherently\nlimited learning capabilities of small language models. The experimental\noutcomes indicate that G-SPEED, with its 508M parameters, can surpass LLMs\nequipped with 175B parameters. Our code and model checkpoints are available at\n\\url{https://github.com/Banner-Z/G-SPEED}.",
            "author": [
                "Haoke Zhang",
                "Yue Wang",
                "Juntao Li",
                "Xiabing Zhou",
                "Min Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10480v1",
                "http://arxiv.org/pdf/2310.10480v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10477v2",
            "title": "Gaining Wisdom from Setbacks: Aligning Large Language Models via Mistake\n  Analysis",
            "updated": "2023-10-20T13:50:24Z",
            "published": "2023-10-16T14:59:10Z",
            "summary": "The rapid advancement of large language models (LLMs) presents both\nopportunities and challenges, particularly concerning unintentional generation\nof harmful and toxic responses. While the traditional alignment methods strive\nto steer LLMs towards desired performance and shield them from malicious\ncontent, this study proposes a novel alignment strategy rooted in mistake\nanalysis by exposing LLMs to flawed outputs purposefully and then conducting a\nthorough assessment to fully comprehend internal reasons via natural language\nanalysis. Thus, toxic responses can be transformed into instruction tuning\ncorpus for model alignment, and LLMs can not only be deterred from generating\nflawed responses but also trained to self-criticize, leveraging its innate\nability to discriminate toxic content. Experimental results demonstrate that\nthe proposed method outperforms conventional alignment techniques for safety\ninstruction following, while maintaining superior efficiency.",
            "author": [
                "Kai Chen",
                "Chunwei Wang",
                "Kuo Yang",
                "Jianhua Han",
                "Lanqing Hong",
                "Fei Mi",
                "Hang Xu",
                "Zhengying Liu",
                "Wenyong Huang",
                "Zhenguo Li",
                "Dit-Yan Yeung",
                "Lifeng Shang",
                "Xin Jiang",
                "Qun Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10477v2",
                "http://arxiv.org/pdf/2310.10477v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10705v2",
            "title": "Machine Learning Classification Techniques for Identifying the Defective\n  Patterns in Semiconductor Wafer Maps: A Survey, Empirical, and Experimental\n  Evaluations",
            "updated": "2023-11-12T07:54:41Z",
            "published": "2023-10-16T14:46:45Z",
            "summary": "This survey paper offers a comprehensive review of methodologies utilizing\nmachine learning (ML) classification techniques for identifying wafer defects\nin semiconductor manufacturing. Despite the growing body of research\ndemonstrating the effectiveness of ML in wafer defect identification, there is\na noticeable absence of comprehensive reviews on this subject. This survey\nattempts to fill this void by amalgamating available literature and providing\nan in-depth analysis of the advantages, limitations, and potential applications\nof various ML classification algorithms in the realm of wafer defect detection.\nAn innovative taxonomy of methodologies that we present provides a detailed\nclassification of algorithms into more refined categories and techniques. This\ntaxonomy follows a four-tier structure, starting from broad methodology\ncategories and ending with specific sub-techniques. It aids researchers in\ncomprehending the complex relationships between different algorithms and their\ntechniques. We employ a rigorous empirical and experimental evaluation to rank\nthese varying techniques. For the empirical evaluation, we assess techniques\nbased on a set of four criteria. The experimental evaluation ranks the\nalgorithms employing the same sub-techniques, techniques, sub-categories, and\ncategories. This integration of a multi-layered taxonomy, empirical\nevaluations, and comparative experiments provides a detailed and holistic\nunderstanding of ML techniques and algorithms for identifying wafer defects.\nAdditionally, the paper illuminates the future prospects of ML classification\ntechniques for wafer defect identification, underscoring potential advancements\nand opportunities for further research in this field",
            "author": [
                "Kamal Taha"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10705v2",
                "http://arxiv.org/pdf/2310.10705v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10464v2",
            "title": "Making Every Photon Count: A Quantum Polyspectra Approach to the\n  Dynamics of Blinking Quantum Emitters at Low Photon Rates Without Binning",
            "updated": "2023-10-18T11:42:46Z",
            "published": "2023-10-16T14:43:42Z",
            "summary": "The blinking statistics of quantum emitters and their corresponding Markov\nmodels play an important role in high resolution microscopy of biological\nsamples as well as in nano-optoelectronics and many other fields of science and\nengineering. Current methods for analyzing the blinking statistics like the\nfull counting statistics or the Viterbi algorithm break down for low photon\nrates. We present an evaluation scheme that eliminates the need for both a\nminimum photon flux and the usual binning of photon events which limits the\nmeasurement bandwidth. Our approach is based on higher order spectra of the\nmeasurement record which we model within the recently introduced method of\nquantum polyspectra from the theory of continuous quantum measurements. By\nvirtue of this approach we can determine on- and off-switching rates of a\nsemiconductor quantum dot at light levels 1000 times lower than in a standard\nexperiment and 20 times lower than achieved with a scheme from full counting\nstatistics. Thus a very powerful high-bandwidth approach to the parameter\nlearning task of single photon hidden Markov models has been established with\napplications in many fields of science.",
            "author": [
                "M. Sifft",
                "A. Kurzmann",
                "J. Kerski",
                "R. Schott",
                "A. Ludwig",
                "A. D. Wieck",
                "A. Lorke",
                "M. Geller",
                "D. H\u00e4gele"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10464v2",
                "http://arxiv.org/pdf/2310.10464v2"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10463v1",
            "title": "Combating Label Noise With A General Surrogate Model For Sample\n  Selection",
            "updated": "2023-10-16T14:43:27Z",
            "published": "2023-10-16T14:43:27Z",
            "summary": "Modern deep learning systems are data-hungry. Learning with web data is one\nof the feasible solutions, but will introduce label noise inevitably, which can\nhinder the performance of deep neural networks. Sample selection is an\neffective way to deal with label noise. The key is to separate clean samples\nbased on some criterion. Previous methods pay more attention to the small loss\ncriterion where small-loss samples are regarded as clean ones. Nevertheless,\nsuch a strategy relies on the learning dynamics of each data instance. Some\nnoisy samples are still memorized due to frequently occurring corrupted\nlearning patterns. To tackle this problem, a training-free surrogate model is\npreferred, freeing from the effect of memorization. In this work, we propose to\nleverage the vision-language surrogate model CLIP to filter noisy samples\nautomatically. CLIP brings external knowledge to facilitate the selection of\nclean samples with its ability of text-image alignment. Furthermore, a margin\nadaptive loss is designed to regularize the selection bias introduced by CLIP,\nproviding robustness to label noise. We validate the effectiveness of our\nproposed method on both real-world and synthetic noisy datasets. Our method\nachieves significant improvement without CLIP involved during the inference\nstage.",
            "author": [
                "Chao Liang",
                "Linchao Zhu",
                "Humphrey Shi",
                "Yi Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10463v1",
                "http://arxiv.org/pdf/2310.10463v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10462v1",
            "title": "Adaptive Neural Ranking Framework: Toward Maximized Business Goal for\n  Cascade Ranking Systems",
            "updated": "2023-10-16T14:43:02Z",
            "published": "2023-10-16T14:43:02Z",
            "summary": "Cascade ranking is widely used for large-scale top-k selection problems in\nonline advertising and recommendation systems, and learning-to-rank is an\nimportant way to optimize the models in cascade ranking systems. Previous works\non learning-to-rank usually focus on letting the model learn the complete order\nor pay more attention to the order of top materials, and adopt the\ncorresponding rank metrics as optimization targets. However, these optimization\ntargets can not adapt to various cascade ranking scenarios with varying data\ncomplexities and model capabilities; and the existing metric-driven methods\nsuch as the Lambda framework can only optimize a rough upper bound of the\nmetric, potentially resulting in performance misalignment. To address these\nissues, we first propose a novel perspective on optimizing cascade ranking\nsystems by highlighting the adaptability of optimization targets to data\ncomplexities and model capabilities. Concretely, we employ multi-task learning\nframework to adaptively combine the optimization of relaxed and full targets,\nwhich refers to metrics Recall@m@k and OAP respectively. Then we introduce a\npermutation matrix to represent the rank metrics and employ differentiable\nsorting techniques to obtain a relaxed permutation matrix with controllable\napproximate error bound. This enables us to optimize both the relaxed and full\ntargets directly and more appropriately using the proposed surrogate losses\nwithin the deep learning framework. We named this method as Adaptive Neural\nRanking Framework. We use the NeuralSort method to obtain the relaxed\npermutation matrix and draw on the uncertainty weight method in multi-task\nlearning to optimize the proposed losses jointly. Experiments on a total of 4\npublic and industrial benchmarks show the effectiveness and generalization of\nour method, and online experiment shows that our method has significant\napplication value.",
            "author": [
                "Yunli Wang",
                "Zhiqiang Wang",
                "Jian Yang",
                "Shiyang Wen",
                "Dongying Kong",
                "Han Li",
                "Kun Gai"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10462v1",
                "http://arxiv.org/pdf/2310.10462v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10461v1",
            "title": "Model Selection of Anomaly Detectors in the Absence of Labeled\n  Validation Data",
            "updated": "2023-10-16T14:42:22Z",
            "published": "2023-10-16T14:42:22Z",
            "summary": "Anomaly detection requires detecting abnormal samples in large unlabeled\ndatasets. While progress in deep learning and the advent of foundation models\nhas produced powerful unsupervised anomaly detection methods, their deployment\nin practice is often hindered by the lack of labeled data -- without it, the\ndetection accuracy of an anomaly detector cannot be evaluated reliably. In this\nwork, we propose a general-purpose framework for evaluating image-based anomaly\ndetectors with synthetically generated validation data. Our method assumes\naccess to a small support set of normal images which are processed with a\npre-trained diffusion model (our proposed method requires no training or\nfine-tuning) to produce synthetic anomalies. When mixed with normal samples\nfrom the support set, the synthetic anomalies create detection tasks that\ncompose a validation framework for anomaly detection evaluation and model\nselection. In an extensive empirical study, ranging from natural images to\nindustrial applications, we find that our synthetic validation framework\nselects the same models and hyper-parameters as selection with a ground-truth\nvalidation set. In addition, we find that prompts selected by our method for\nCLIP-based anomaly detection outperforms all other prompt selection strategies,\nand leads to the overall best detection accuracy, even on the challenging\nMVTec-AD dataset.",
            "author": [
                "Clement Fung",
                "Chen Qiu",
                "Aodong Li",
                "Maja Rudolph"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10461v1",
                "http://arxiv.org/pdf/2310.10461v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10449v2",
            "title": "Text Summarization Using Large Language Models: A Comparative Study of\n  MPT-7b-instruct, Falcon-7b-instruct, and OpenAI Chat-GPT Models",
            "updated": "2023-10-17T19:54:16Z",
            "published": "2023-10-16T14:33:02Z",
            "summary": "Text summarization is a critical Natural Language Processing (NLP) task with\napplications ranging from information retrieval to content generation.\nLeveraging Large Language Models (LLMs) has shown remarkable promise in\nenhancing summarization techniques. This paper embarks on an exploration of\ntext summarization with a diverse set of LLMs, including MPT-7b-instruct,\nfalcon-7b-instruct, and OpenAI ChatGPT text-davinci-003 models. The experiment\nwas performed with different hyperparameters and evaluated the generated\nsummaries using widely accepted metrics such as the Bilingual Evaluation\nUnderstudy (BLEU) Score, Recall-Oriented Understudy for Gisting Evaluation\n(ROUGE) Score, and Bidirectional Encoder Representations from Transformers\n(BERT) Score. According to the experiment, text-davinci-003 outperformed the\nothers. This investigation involved two distinct datasets: CNN Daily Mail and\nXSum. Its primary objective was to provide a comprehensive understanding of the\nperformance of Large Language Models (LLMs) when applied to different datasets.\nThe assessment of these models' effectiveness contributes valuable insights to\nresearchers and practitioners within the NLP domain. This work serves as a\nresource for those interested in harnessing the potential of LLMs for text\nsummarization and lays the foundation for the development of advanced\nGenerative AI applications aimed at addressing a wide spectrum of business\nchallenges.",
            "author": [
                "Lochan Basyal",
                "Mihir Sanghvi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10449v2",
                "http://arxiv.org/pdf/2310.10449v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10448v1",
            "title": "A Geometric Insight into Equivariant Message Passing Neural Networks on\n  Riemannian Manifolds",
            "updated": "2023-10-16T14:31:13Z",
            "published": "2023-10-16T14:31:13Z",
            "summary": "This work proposes a geometric insight into equivariant message passing on\nRiemannian manifolds. As previously proposed, numerical features on Riemannian\nmanifolds are represented as coordinate-independent feature fields on the\nmanifold. To any coordinate-independent feature field on a manifold comes\nattached an equivariant embedding of the principal bundle to the space of\nnumerical features. We argue that the metric this embedding induces on the\nnumerical feature space should optimally preserve the principal bundle's\noriginal metric. This optimality criterion leads to the minimization of a\ntwisted form of the Polyakov action with respect to the graph of this\nembedding, yielding an equivariant diffusion process on the associated vector\nbundle. We obtain a message passing scheme on the manifold by discretizing the\ndiffusion equation flow for a fixed time step. We propose a higher-order\nequivariant diffusion process equivalent to diffusion on the cartesian product\nof the base manifold. The discretization of the higher-order diffusion process\non a graph yields a new general class of equivariant GNN, generalizing the ACE\nand MACE formalism to data on Riemannian manifolds.",
            "author": [
                "Ilyes Batatia"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10448v1",
                "http://arxiv.org/pdf/2310.10448v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10443v1",
            "title": "Taming the Sigmoid Bottleneck: Provably Argmaxable Sparse Multi-Label\n  Classification",
            "updated": "2023-10-16T14:25:50Z",
            "published": "2023-10-16T14:25:50Z",
            "summary": "Sigmoid output layers are widely used in multi-label classification (MLC)\ntasks, in which multiple labels can be assigned to any input. In many practical\nMLC tasks, the number of possible labels is in the thousands, often exceeding\nthe number of input features and resulting in a low-rank output layer. In\nmulti-class classification, it is known that such a low-rank output layer is a\nbottleneck that can result in unargmaxable classes: classes which cannot be\npredicted for any input. In this paper, we show that for MLC tasks, the\nanalogous sigmoid bottleneck results in exponentially many unargmaxable label\ncombinations. We explain how to detect these unargmaxable outputs and\ndemonstrate their presence in three widely used MLC datasets. We then show that\nthey can be prevented in practice by introducing a Discrete Fourier Transform\n(DFT) output layer, which guarantees that all sparse label combinations with up\nto $k$ active labels are argmaxable. Our DFT layer trains faster and is more\nparameter efficient, matching the F1@k score of a sigmoid layer while using up\nto 50% fewer trainable parameters. Our code is publicly available at\nhttps://github.com/andreasgrv/sigmoid-bottleneck.",
            "author": [
                "Andreas Grivas",
                "Antonio Vergari",
                "Adam Lopez"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10443v1",
                "http://arxiv.org/pdf/2310.10443v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10441v1",
            "title": "Efficiently matching random inhomogeneous graphs via degree profiles",
            "updated": "2023-10-16T14:25:43Z",
            "published": "2023-10-16T14:25:43Z",
            "summary": "In this paper, we study the problem of recovering the latent vertex\ncorrespondence between two correlated random graphs with vastly inhomogeneous\nand unknown edge probabilities between different pairs of vertices. Inspired by\nand extending the matching algorithm via degree profiles by Ding, Ma, Wu and Xu\n(2021), we obtain an efficient matching algorithm as long as the minimal\naverage degree is at least $\\Omega(\\log^{2} n)$ and the minimal correlation is\nat least $1 - O(\\log^{-2} n)$.",
            "author": [
                "Jian Ding",
                "Yumou Fei",
                "Yuanzheng Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10441v1",
                "http://arxiv.org/pdf/2310.10441v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "math.PR",
                "math.ST",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10437v1",
            "title": "Physical learning of power-efficient solutions",
            "updated": "2023-10-16T14:20:16Z",
            "published": "2023-10-16T14:20:16Z",
            "summary": "As the size and ubiquity of artificial intelligence and computational machine\nlearning (ML) models grow, their energy consumption for training and use is\nrapidly becoming economically and environmentally unsustainable. Neuromorphic\ncomputing, or the implementation of ML in hardware, has the potential to reduce\nthis cost. In particular, recent laboratory prototypes of self-learning\nelectronic circuits, examples of ``physical learning machines,\" open the door\nto analog hardware that directly employs physics to learn desired functions\nfrom examples. In this work, we show that this hardware platform allows for\neven further reduction of energy consumption by using good initial conditions\nas well as a new learning algorithm. Using analytical calculations, simulation\nand experiment, we show that a trade-off emerges when learning dynamics attempt\nto minimize both the error and the power consumption of the solution--greater\npower reductions can be achieved at the cost of decreasing solution accuracy.\nFinally, we demonstrate a practical procedure to weigh the relative importance\nof error and power minimization, improving power efficiency given a specific\ntolerance to error.",
            "author": [
                "Menachem Stern",
                "Sam Dillavou",
                "Dinesh Jayaraman",
                "Douglas J. Durian",
                "Andrea J. Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10437v1",
                "http://arxiv.org/pdf/2310.10437v1"
            ],
            "primary_category": "cond-mat.dis-nn",
            "category": [
                "cond-mat.dis-nn",
                "cond-mat.soft",
                "cond-mat.stat-mech"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10436v1",
            "title": "Large Language Model-Empowered Agents for Simulating Macroeconomic\n  Activities",
            "updated": "2023-10-16T14:19:40Z",
            "published": "2023-10-16T14:19:40Z",
            "summary": "The advent of the Web has brought about a paradigm shift in traditional\neconomics, particularly in the digital economy era, enabling the precise\nrecording and analysis of individual economic behavior. This has led to a\ngrowing emphasis on data-driven modeling in macroeconomics. In macroeconomic\nresearch, Agent-based modeling (ABM) emerged as an alternative, evolving\nthrough rule-based agents, machine learning-enhanced decision-making, and, more\nrecently, advanced AI agents. However, the existing works are suffering from\nthree main challenges when endowing agents with human-like decision-making,\nincluding agent heterogeneity, the influence of macroeconomic trends, and\nmultifaceted economic factors. Large language models (LLMs) have recently\ngained prominence in offering autonomous human-like characteristics. Therefore,\nleveraging LLMs in macroeconomic simulation presents an opportunity to overcome\ntraditional limitations. In this work, we take an early step in introducing a\nnovel approach that leverages LLMs in macroeconomic simulation. We design\nprompt-engineering-driven LLM agents to exhibit human-like decision-making and\nadaptability in the economic environment, with the abilities of perception,\nreflection, and decision-making to address the abovementioned challenges.\nSimulation experiments on macroeconomic activities show that LLM-empowered\nagents can make realistic work and consumption decisions and emerge more\nreasonable macroeconomic phenomena than existing rule-based or AI agents. Our\nwork demonstrates the promising potential to simulate macroeconomics based on\nLLM and its human-like characteristics.",
            "author": [
                "Nian Li",
                "Chen Gao",
                "Yong Li",
                "Qingmin Liao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10436v1",
                "http://arxiv.org/pdf/2310.10436v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10434v1",
            "title": "Equivariant Matrix Function Neural Networks",
            "updated": "2023-10-16T14:17:00Z",
            "published": "2023-10-16T14:17:00Z",
            "summary": "Graph Neural Networks (GNNs), especially message-passing neural networks\n(MPNNs), have emerged as powerful architectures for learning on graphs in\ndiverse applications. However, MPNNs face challenges when modeling non-local\ninteractions in systems such as large conjugated molecules, metals, or\namorphous materials. Although Spectral GNNs and traditional neural networks\nsuch as recurrent neural networks and transformers mitigate these challenges,\nthey often lack extensivity, adaptability, generalizability, computational\nefficiency, or fail to capture detailed structural relationships or symmetries\nin the data. To address these concerns, we introduce Matrix Function Neural\nNetworks (MFNs), a novel architecture that parameterizes non-local interactions\nthrough analytic matrix equivariant functions. Employing resolvent expansions\noffers a straightforward implementation and the potential for linear scaling\nwith system size. The MFN architecture achieves state-of-the-art performance in\nstandard graph benchmarks, such as the ZINC and TU datasets, and is able to\ncapture intricate non-local interactions in quantum systems, paving the way to\nnew state-of-the-art force fields.",
            "author": [
                "Ilyes Batatia",
                "Lars L. Schaaf",
                "Huajie Chen",
                "G\u00e1bor Cs\u00e1nyi",
                "Christoph Ortner",
                "Felix A. Faber"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10434v1",
                "http://arxiv.org/pdf/2310.10434v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cond-mat.mtrl-sci",
                "cs.LG",
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10433v1",
            "title": "Object Detection in Aerial Images in Scarce Data Regimes",
            "updated": "2023-10-16T14:16:47Z",
            "published": "2023-10-16T14:16:47Z",
            "summary": "Most contributions on Few-Shot Object Detection (FSOD) evaluate their methods\non natural images only, yet the transferability of the announced performance is\nnot guaranteed for applications on other kinds of images. We demonstrate this\nwith an in-depth analysis of existing FSOD methods on aerial images and\nobserved a large performance gap compared to natural images. Small objects,\nmore numerous in aerial images, are the cause for the apparent performance gap\nbetween natural and aerial images. As a consequence, we improve FSOD\nperformance on small objects with a carefully designed attention mechanism. In\naddition, we also propose a scale-adaptive box similarity criterion, that\nimproves the training and evaluation of FSOD methods, particularly for small\nobjects. We also contribute to generic FSOD with two distinct approaches based\non metric learning and fine-tuning. Impressive results are achieved with the\nfine-tuning method, which encourages tackling more complex scenarios such as\nCross-Domain FSOD. We conduct preliminary experiments in this direction and\nobtain promising results. Finally, we address the deployment of the detection\nmodels inside COSE's systems. Detection must be done in real-time in extremely\nlarge images (more than 100 megapixels), with limited computation power.\nLeveraging existing optimization tools such as TensorRT, we successfully tackle\nthis engineering challenge.",
            "author": [
                "Pierre Le Jeune"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10433v1",
                "http://arxiv.org/pdf/2310.10433v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10431v1",
            "title": "Longitudinal Self-supervised Learning Using Neural Ordinary Differential\n  Equation",
            "updated": "2023-10-16T14:16:04Z",
            "published": "2023-10-16T14:16:04Z",
            "summary": "Longitudinal analysis in medical imaging is crucial to investigate the\nprogressive changes in anatomical structures or disease progression over time.\nIn recent years, a novel class of algorithms has emerged with the goal of\nlearning disease progression in a self-supervised manner, using either pairs of\nconsecutive images or time series of images. By capturing temporal patterns\nwithout external labels or supervision, longitudinal self-supervised learning\n(LSSL) has become a promising avenue. To better understand this core method, we\nexplore in this paper the LSSL algorithm under different scenarios. The\noriginal LSSL is embedded in an auto-encoder (AE) structure. However,\nconventional self-supervised strategies are usually implemented in a\nSiamese-like manner. Therefore, (as a first novelty) in this study, we explore\nthe use of Siamese-like LSSL. Another new core framework named neural ordinary\ndifferential equation (NODE). NODE is a neural network architecture that learns\nthe dynamics of ordinary differential equations (ODE) through the use of neural\nnetworks. Many temporal systems can be described by ODE, including modeling\ndisease progression. We believe that there is an interesting connection to make\nbetween LSSL and NODE. This paper aims at providing a better understanding of\nthose core algorithms for learning the disease progression with the mentioned\nchange. In our different experiments, we employ a longitudinal dataset, named\nOPHDIAT, targeting diabetic retinopathy (DR) follow-up. Our results demonstrate\nthe application of LSSL without including a reconstruction term, as well as the\npotential of incorporating NODE in conjunction with LSSL.",
            "author": [
                "Rachid Zeghlache",
                "Pierre-Henri Conze",
                "Mostafa El Habib Daho",
                "Yihao Li",
                "Hugo Le Boit\u00e9",
                "Ramin Tadayoni",
                "Pascal Massin",
                "B\u00e9atrice Cochener",
                "Ikram Brahim",
                "Gwenol\u00e9 Quellec",
                "Mathieu Lamard"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-031-46005-0_1",
                "http://arxiv.org/abs/2310.10431v1",
                "http://arxiv.org/pdf/2310.10431v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10429v1",
            "title": "Exploiting User Comments for Early Detection of Fake News Prior to\n  Users' Commenting",
            "updated": "2023-10-16T14:13:38Z",
            "published": "2023-10-16T14:13:38Z",
            "summary": "Both accuracy and timeliness are key factors in detecting fake news on social\nmedia. However, most existing methods encounter an accuracy-timeliness dilemma:\nContent-only methods guarantee timeliness but perform moderately because of\nlimited available information, while social context-based ones generally\nperform better but inevitably lead to latency because of social context\naccumulation needs. To break such a dilemma, a feasible but not well-studied\nsolution is to leverage social contexts (e.g., comments) from historical news\nfor training a detection model and apply it to newly emerging news without\nsocial contexts. This requires the model to (1) sufficiently learn helpful\nknowledge from social contexts, and (2) be well compatible with situations that\nsocial contexts are available or not. To achieve this goal, we propose to\nabsorb and parameterize useful knowledge from comments in historical news and\nthen inject it into a content-only detection model. Specifically, we design the\nComments Assisted Fake News Detection method (CAS-FEND), which transfers useful\nknowledge from a comments-aware teacher model to a content-only student model\nduring training. The student model is further used to detect newly emerging\nfake news. Experiments show that the CAS-FEND student model outperforms all\ncontent-only methods and even those with 1/4 comments as inputs, demonstrating\nits superiority for early detection.",
            "author": [
                "Qiong Nan",
                "Qiang Sheng",
                "Juan Cao",
                "Yongchun Zhu",
                "Danding Wang",
                "Guang Yang",
                "Jintao Li",
                "Kai Shu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10429v1",
                "http://arxiv.org/pdf/2310.10429v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CY",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10425v1",
            "title": "Continuously Adapting Random Sampling (CARS) for Power Electronics\n  Parameter Design",
            "updated": "2023-10-16T14:09:59Z",
            "published": "2023-10-16T14:09:59Z",
            "summary": "To date, power electronics parameter design tasks are usually tackled using\ndetailed optimization approaches with detailed simulations or using brute force\ngrid search grid search with very fast simulations. A new method, named\n\"Continuously Adapting Random Sampling\" (CARS) is proposed, which provides a\ncontinuous method in between. This allows for very fast, and / or large amounts\nof simulations, but increasingly focuses on the most promising parameter\nranges. Inspirations are drawn from multi-armed bandit research and lead to\nprioritized sampling of sub-domains in one high-dimensional parameter tensor.\nPerformance has been evaluated on three exemplary power electronic use-cases,\nwhere resulting designs appear competitive to genetic algorithms, but\nadditionally allow for highly parallelizable simulation, as well as continuous\nprogression between explorative and exploitative settings.",
            "author": [
                "Dominik Happel",
                "Philipp Brendel",
                "Andreas Rosskopf",
                "Stefan Ditze"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10425v1",
                "http://arxiv.org/pdf/2310.10425v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10424v1",
            "title": "A Novel Benchmarking Paradigm and a Scale- and Motion-Aware Model for\n  Egocentric Pedestrian Trajectory Prediction",
            "updated": "2023-10-16T14:08:34Z",
            "published": "2023-10-16T14:08:34Z",
            "summary": "Predicting pedestrian behavior is one of the main challenges for intelligent\ndriving systems. In this paper, we present a new paradigm for evaluating\negocentric pedestrian trajectory prediction algorithms. Based on various\ncontextual information, we extract driving scenarios for a meaningful and\nsystematic approach to identifying challenges for prediction models. In this\nregard, we also propose a new metric for more effective ranking within the\nscenario-based evaluation. We conduct extensive empirical studies of existing\nmodels on these scenarios to expose shortcomings and strengths of different\napproaches. The scenario-based analysis highlights the importance of using\nmultimodal sources of information and challenges caused by inadequate modeling\nof ego-motion and scale of pedestrians. To this end, we propose a novel\negocentric trajectory prediction model that benefits from multimodal sources of\ndata fused in an effective and efficient step-wise hierarchical fashion and two\nauxiliary tasks designed to learn more robust representation of scene dynamics.\nWe show that our approach achieves significant improvement by up to 40% in\nchallenging scenarios compared to the past arts via empirical evaluation on\ncommon benchmark datasets.",
            "author": [
                "Amir Rasouli"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10424v1",
                "http://arxiv.org/pdf/2310.10424v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13009v1",
            "title": "Application of Machine Learning Based Top Quark and W Jet Tagging to\n  Hadronic Four-Top Final States Induced by SM as well as BSM Processes",
            "updated": "2023-10-16T14:06:08Z",
            "published": "2023-10-16T14:06:08Z",
            "summary": "We apply gradient boosting machine learning techniques to the problem of\nhadronic jet substructure recognition using classical subjettiness variables\navailable within a common parameterized detector simulation package DELPHES.\nPer-jet tagging classification is being explored. Jets produced in simulated\nproton-proton collisions are identified as consistent with the hypothesis of\ncoming from the decay of a top quark or a W boson and are used to reconstruct\nthe mass of a hypothetical scalar resonance decaying to a pair of top quarks in\nevents where in total four top quarks are produced. Results are compared to the\ncase of a simple cut-based tagging technique for the stacked histograms of a\nmixture of a Standard Model as well as the new physics process.",
            "author": [
                "Petr Baro\u0148",
                "Ji\u0159\u00ed Kvita",
                "Radek P\u0159\u00edvara",
                "Jan Tome\u010dek",
                "Rostislav Vod\u00e1k"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13009v1",
                "http://arxiv.org/pdf/2310.13009v1"
            ],
            "primary_category": "hep-ex",
            "category": [
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10420v1",
            "title": "LMT: Longitudinal Mixing Training, a Framework to Predict Disease\n  Progression from a Single Image",
            "updated": "2023-10-16T14:01:20Z",
            "published": "2023-10-16T14:01:20Z",
            "summary": "Longitudinal imaging is able to capture both static anatomical structures and\ndynamic changes in disease progression toward earlier and better\npatient-specific pathology management. However, conventional approaches rarely\ntake advantage of longitudinal information for detection and prediction\npurposes, especially for Diabetic Retinopathy (DR). In the past years, Mix-up\ntraining and pretext tasks with longitudinal context have effectively enhanced\nDR classification results and captured disease progression. In the meantime, a\nnovel type of neural network named Neural Ordinary Differential Equation (NODE)\nhas been proposed for solving ordinary differential equations, with a neural\nnetwork treated as a black box. By definition, NODE is well suited for solving\ntime-related problems. In this paper, we propose to combine these three aspects\nto detect and predict DR progression. Our framework, Longitudinal Mixing\nTraining (LMT), can be considered both as a regularizer and as a pretext task\nthat encodes the disease progression in the latent space. Additionally, we\nevaluate the trained model weights on a downstream task with a longitudinal\ncontext using standard and longitudinal pretext tasks. We introduce a new way\nto train time-aware models using $t_{mix}$, a weighted average time between two\nconsecutive examinations. We compare our approach to standard mixing training\non DR classification using OPHDIAT a longitudinal retinal Color Fundus\nPhotographs (CFP) dataset. We were able to predict whether an eye would develop\na severe DR in the following visit using a single image, with an AUC of 0.798\ncompared to baseline results of 0.641. Our results indicate that our\nlongitudinal pretext task can learn the progression of DR disease and that\nintroducing $t_{mix}$ augmentation is beneficial for time-aware models.",
            "author": [
                "Rachid Zeghlache",
                "Pierre-Henri Conze",
                "Mostafa El Habib Daho",
                "Yihao Li",
                "Hugo Le boite",
                "Ramin Tadayoni",
                "Pascal Massin",
                "B\u00e9atrice Cochener",
                "Ikram Brahim",
                "Gwenol\u00e9 Quellec",
                "Mathieu Lamard"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-031-45676-3_3",
                "http://arxiv.org/abs/2310.10420v1",
                "http://arxiv.org/pdf/2310.10420v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10418v2",
            "title": "Reading Books is Great, But Not if You Are Driving! Visually Grounded\n  Reasoning about Defeasible Commonsense Norms",
            "updated": "2023-11-11T13:40:27Z",
            "published": "2023-10-16T14:00:07Z",
            "summary": "Commonsense norms are defeasible by context: reading books is usually great,\nbut not when driving a car. While contexts can be explicitly described in\nlanguage, in embodied scenarios, contexts are often provided visually. This\ntype of visually grounded reasoning about defeasible commonsense norms is\ngenerally easy for humans, but (as we show) poses a challenge for machines, as\nit necessitates both visual understanding and reasoning about commonsense\nnorms. We construct a new multimodal benchmark for studying visual-grounded\ncommonsense norms: NORMLENS. NORMLENS consists of 10K human judgments\naccompanied by free-form explanations covering 2K multimodal situations, and\nserves as a probe to address two questions: (1) to what extent can models align\nwith average human judgment? and (2) how well can models explain their\npredicted judgments? We find that state-of-the-art model judgments and\nexplanations are not well-aligned with human annotation. Additionally, we\npresent a new approach to better align models with humans by distilling social\ncommonsense knowledge from large language models. The data and code are\nreleased at https://seungjuhan.me/normlens.",
            "author": [
                "Seungju Han",
                "Junhyeok Kim",
                "Jack Hessel",
                "Liwei Jiang",
                "Jiwan Chung",
                "Yejin Son",
                "Yejin Choi",
                "Youngjae Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10418v2",
                "http://arxiv.org/pdf/2310.10418v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10417v1",
            "title": "Prior-Free Continual Learning with Unlabeled Data in the Wild",
            "updated": "2023-10-16T13:59:56Z",
            "published": "2023-10-16T13:59:56Z",
            "summary": "Continual Learning (CL) aims to incrementally update a trained model on new\ntasks without forgetting the acquired knowledge of old ones. Existing CL\nmethods usually reduce forgetting with task priors, \\ie using task identity or\na subset of previously seen samples for model training. However, these methods\nwould be infeasible when such priors are unknown in real-world applications. To\naddress this fundamental but seldom-studied problem, we propose a Prior-Free\nContinual Learning (PFCL) method, which learns new tasks without knowing the\ntask identity or any previous data. First, based on a fixed single-head\narchitecture, we eliminate the need for task identity to select the\ntask-specific output head. Second, we employ a regularization-based strategy\nfor consistent predictions between the new and old models, avoiding revisiting\nprevious samples. However, using this strategy alone often performs poorly in\nclass-incremental scenarios, particularly for a long sequence of tasks. By\nanalyzing the effectiveness and limitations of conventional\nregularization-based methods, we propose enhancing model consistency with an\nauxiliary unlabeled dataset additionally. Moreover, since some auxiliary data\nmay degrade the performance, we further develop a reliable sample selection\nstrategy to obtain consistent performance improvement. Extensive experiments on\nmultiple image classification benchmark datasets show that our PFCL method\nsignificantly mitigates forgetting in all three learning scenarios.\nFurthermore, when compared to the most recent rehearsal-based methods that\nreplay a limited number of previous samples, PFCL achieves competitive\naccuracy. Our code is available at: https://github.com/visiontao/pfcl",
            "author": [
                "Tao Zhuo",
                "Zhiyong Cheng",
                "Hehe Fan",
                "Mohan Kankanhalli"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10417v1",
                "http://arxiv.org/pdf/2310.10417v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10413v1",
            "title": "Image super-resolution via dynamic network",
            "updated": "2023-10-16T13:56:56Z",
            "published": "2023-10-16T13:56:56Z",
            "summary": "Convolutional neural networks (CNNs) depend on deep network architectures to\nextract accurate information for image super-resolution. However, obtained\ninformation of these CNNs cannot completely express predicted high-quality\nimages for complex scenes. In this paper, we present a dynamic network for\nimage super-resolution (DSRNet), which contains a residual enhancement block,\nwide enhancement block, feature refinement block and construction block. The\nresidual enhancement block is composed of a residual enhanced architecture to\nfacilitate hierarchical features for image super-resolution. To enhance\nrobustness of obtained super-resolution model for complex scenes, a wide\nenhancement block achieves a dynamic architecture to learn more robust\ninformation to enhance applicability of an obtained super-resolution model for\nvarying scenes. To prevent interference of components in a wide enhancement\nblock, a refinement block utilizes a stacked architecture to accurately learn\nobtained features. Also, a residual learning operation is embedded in the\nrefinement block to prevent long-term dependency problem. Finally, a\nconstruction block is responsible for reconstructing high-quality images.\nDesigned heterogeneous architecture can not only facilitate richer structural\ninformation, but also be lightweight, which is suitable for mobile digital\ndevices. Experimental results shows that our method is more competitive in\nterms of performance and recovering time of image super-resolution and\ncomplexity. The code of DSRNet can be obtained at\nhttps://github.com/hellloxiaotian/DSRNet.",
            "author": [
                "Chunwei Tian",
                "Xuanyu Zhang",
                "Qi Zhang",
                "Mingming Yang",
                "Zhaojie Ju"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10413v1",
                "http://arxiv.org/pdf/2310.10413v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10410v1",
            "title": "Loci-Segmented: Improving Scene Segmentation Learning",
            "updated": "2023-10-16T13:53:37Z",
            "published": "2023-10-16T13:53:37Z",
            "summary": "Slot-oriented processing approaches for compositional scene representation\nhave recently undergone a tremendous development. We present Loci-Segmented\n(Loci-s), an advanced scene segmentation neural network that extends the\nslot-based location and identity tracking architecture Loci (Traub et al., ICLR\n2023). The main advancements are (i) the addition of a pre-trained dynamic\nbackground module; (ii) a hyper-convolution encoder module, which enables\nobject-focused bottom-up processing; and (iii) a cascaded decoder module, which\nsuccessively generates object masks, masked depth maps, and masked,\ndepth-map-informed RGB reconstructions. The background module features the\nlearning of both a foreground identifying module and a background re-generator.\nWe further improve performance via (a) the integration of depth information as\nwell as improved slot assignments via (b) slot-location-entity regularization\nand (b) a prior segmentation network. Even without these latter improvements,\nthe results reveal superior segmentation performance in the MOVi datasets and\nin another established dataset collection. With all improvements, Loci-s\nachieves a 32% better intersection over union (IoU) score in MOVi-E than the\nprevious best. We furthermore show that Loci-s generates well-interpretable\nlatent representations. We believe that these representations may serve as a\nfoundation-model-like interpretable basis for solving downstream tasks, such as\ngrounding language and context- and goal-conditioned event processing.",
            "author": [
                "Manuel Traub",
                "Frederic Becker",
                "Adrian Sauter",
                "Sebastian Otte",
                "Martin V. Butz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10410v1",
                "http://arxiv.org/pdf/2310.10410v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10409v1",
            "title": "Einstein Telescope: binary black holes gravitational wave signals\n  detection from three detectors combined data using deep learning",
            "updated": "2023-10-16T13:53:31Z",
            "published": "2023-10-16T13:53:31Z",
            "summary": "Continuing from our prior work (Alhassan et al. 2022), where a single\ndetector data of the Einstein Telescope (ET) was evaluated for the detection of\nbinary black hole (BBHs) using deep learning (DL). In this work we explored the\ndetection efficiency of BBHs using data combined from all the three proposed\ndetectors of ET, with five different lower frequency cutoff (Flow): 5 Hz, 10\nHz, 15 Hz, 20 Hz and 30 Hz, and the same previously used SNR ranges of: 4-5,\n5-6, 6-7, 7-8 and >8. Using ResNet model (which had the best overall\nperformance on single detector data), the detection accuracy has improved from\n60%, 60.5%, 84.5%, 94.5% and 98.5% to 78.5%, 84%, 99.5%, 100% and 100% for\nsources with SNR of 4-5, 5-6, 6-7, 7-8 and >8 respectively. The results show a\ngreat improvement in accuracy for lower SNR ranges: 4-5, 5-6 and 6-7 by 18.5%,\n24.5%, 13% respectively, and by 5.5% and 1.5% for higher SNR ranges: 7-8 and >8\nrespectively. In a qualitative evaluation, ResNet model was able to detect\nsources at 86.601 Gpc, with 3.9 averaged SNR (averaged SNR from the three\ndetectors) and 13.632 chirp mass at 5 Hz. It was also shown that the use of the\nthree detectors combined data is appropriate for near-real-time detection, and\ncan be significantly improved using more powerful setup.",
            "author": [
                "Wathela Alhassan",
                "T. Bulik",
                "M. Suchenek"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10409v1",
                "http://arxiv.org/pdf/2310.10409v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "gr-qc"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10408v1",
            "title": "A cross Transformer for image denoising",
            "updated": "2023-10-16T13:53:19Z",
            "published": "2023-10-16T13:53:19Z",
            "summary": "Deep convolutional neural networks (CNNs) depend on feedforward and feedback\nways to obtain good performance in image denoising. However, how to obtain\neffective structural information via CNNs to efficiently represent given noisy\nimages is key for complex scenes. In this paper, we propose a cross Transformer\ndenoising CNN (CTNet) with a serial block (SB), a parallel block (PB), and a\nresidual block (RB) to obtain clean images for complex scenes. A SB uses an\nenhanced residual architecture to deeply search structural information for\nimage denoising. To avoid loss of key information, PB uses three heterogeneous\nnetworks to implement multiple interactions of multi-level features to broadly\nsearch for extra information for improving the adaptability of an obtained\ndenoiser for complex scenes. Also, to improve denoising performance,\nTransformer mechanisms are embedded into the SB and PB to extract complementary\nsalient features for effectively removing noise in terms of pixel relations.\nFinally, a RB is applied to acquire clean images. Experiments illustrate that\nour CTNet is superior to some popular denoising methods in terms of real and\nsynthetic image denoising. It is suitable to mobile digital devices, i.e.,\nphones. Codes can be obtained at https://github.com/hellloxiaotian/CTNet.",
            "author": [
                "Chunwei Tian",
                "Menghua Zheng",
                "Wangmeng Zuo",
                "Shichao Zhang",
                "Yanning Zhang",
                "Chia-Wen Ling"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10408v1",
                "http://arxiv.org/pdf/2310.10408v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10407v1",
            "title": "Ensemble methods for testing a global null",
            "updated": "2023-10-16T13:53:10Z",
            "published": "2023-10-16T13:53:10Z",
            "summary": "Testing a global null is a canonical problem in statistics and has a wide\nrange of applications. In view of the fact that no uniformly most powerful test\nexists, prior and/or domain knowledge are commonly used to focus on a certain\nclass of alternatives to improve the testing power. However, it is generally\nchallenging to develop tests that are particularly powerful against a certain\nclass of alternatives. In this paper, motivated by the success of ensemble\nlearning methods for prediction or classification, we propose an ensemble\nframework for testing that mimics the spirit of random forests to deal with the\nchallenges. Our ensemble testing framework aggregates a collection of weak base\ntests to form a final ensemble test that maintains strong and robust power for\nglobal nulls. We apply the framework to four problems about global testing in\ndifferent classes of alternatives arising from Whole Genome Sequencing (WGS)\nassociation studies. Specific ensemble tests are proposed for each of these\nproblems, and their theoretical optimality is established in terms of Bahadur\nefficiency. Extensive simulations and an analysis of a real WGS dataset are\nconducted to demonstrate the type I error control and/or power gain of the\nproposed ensemble tests.",
            "author": [
                "Yaowu Liu",
                "Zhonghua Liu",
                "Xihong Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10407v1",
                "http://arxiv.org/pdf/2310.10407v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10404v5",
            "title": "LLM4SGG: Large Language Model for Weakly Supervised Scene Graph\n  Generation",
            "updated": "2023-11-27T11:41:32Z",
            "published": "2023-10-16T13:49:46Z",
            "summary": "Weakly-Supervised Scene Graph Generation (WSSGG) research has recently\nemerged as an alternative to the fully-supervised approach that heavily relies\non costly annotations. In this regard, studies on WSSGG have utilized image\ncaptions to obtain unlocalized triplets while primarily focusing on grounding\nthe unlocalized triplets over image regions. However, they have overlooked the\ntwo issues involved in the triplet formation process from the captions: 1)\nSemantic over-simplification issue arises when extracting triplets from\ncaptions, where fine-grained predicates in captions are undesirably converted\ninto coarse-grained predicates, resulting in a long-tailed predicate\ndistribution, and 2) Low-density scene graph issue arises when aligning the\ntriplets in the caption with entity/predicate classes of interest, where many\ntriplets are discarded and not used in training, leading to insufficient\nsupervision. To tackle the two issues, we propose a new approach, i.e., Large\nLanguage Model for weakly-supervised SGG (LLM4SGG), where we mitigate the two\nissues by leveraging the LLM's in-depth understanding of language and reasoning\nability during the extraction of triplets from captions and alignment of\nentity/predicate classes with target data. To further engage the LLM in these\nprocesses, we adopt the idea of Chain-of-Thought and the in-context few-shot\nlearning strategy. To validate the effectiveness of LLM4SGG, we conduct\nextensive experiments on Visual Genome and GQA datasets, showing significant\nimprovements in both Recall@K and mean Recall@K compared to the\nstate-of-the-art WSSGG methods. A further appeal is that LLM4SGG is\ndata-efficient, enabling effective model training with a small amount of\ntraining images.",
            "author": [
                "Kibum Kim",
                "Kanghoon Yoon",
                "Jaehyeong Jeon",
                "Yeonjun In",
                "Jinyoung Moon",
                "Donghyun Kim",
                "Chanyoung Park"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10404v5",
                "http://arxiv.org/pdf/2310.10404v5"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10402v1",
            "title": "Real-Fake: Effective Training Data Synthesis Through Distribution\n  Matching",
            "updated": "2023-10-16T13:45:26Z",
            "published": "2023-10-16T13:45:26Z",
            "summary": "Synthetic training data has gained prominence in numerous learning tasks and\nscenarios, offering advantages such as dataset augmentation, generalization\nevaluation, and privacy preservation. Despite these benefits, the efficiency of\nsynthetic data generated by current methodologies remains inferior when\ntraining advanced deep models exclusively, limiting its practical utility. To\naddress this challenge, we analyze the principles underlying training data\nsynthesis for supervised learning and elucidate a principled theoretical\nframework from the distribution-matching perspective that explicates the\nmechanisms governing synthesis efficacy. Through extensive experiments, we\ndemonstrate the effectiveness of our synthetic data across diverse image\nclassification tasks, both as a replacement for and augmentation to real\ndatasets, while also benefits challenging tasks such as out-of-distribution\ngeneralization and privacy preservation.",
            "author": [
                "Jianhao Yuan",
                "Jie Zhang",
                "Shuyang Sun",
                "Philip Torr",
                "Bo Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10402v1",
                "http://arxiv.org/pdf/2310.10402v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10400v1",
            "title": "Can Word Sense Distribution Detect Semantic Changes of Words?",
            "updated": "2023-10-16T13:41:27Z",
            "published": "2023-10-16T13:41:27Z",
            "summary": "Semantic Change Detection (SCD) of words is an important task for various NLP\napplications that must make time-sensitive predictions. Some words are used\nover time in novel ways to express new meanings, and these new meanings\nestablish themselves as novel senses of existing words. On the other hand, Word\nSense Disambiguation (WSD) methods associate ambiguous words with sense ids,\ndepending on the context in which they occur. Given this relationship between\nWSD and SCD, we explore the possibility of predicting whether a target word has\nits meaning changed between two corpora collected at different time steps, by\ncomparing the distributions of senses of that word in each corpora. For this\npurpose, we use pretrained static sense embeddings to automatically annotate\neach occurrence of the target word in a corpus with a sense id. Next, we\ncompute the distribution of sense ids of a target word in a given corpus.\nFinally, we use different divergence or distance measures to quantify the\nsemantic change of the target word across the two given corpora. Our\nexperimental results on SemEval 2020 Task 1 dataset show that word sense\ndistributions can be accurately used to predict semantic changes of words in\nEnglish, German, Swedish and Latin.",
            "author": [
                "Xiaohang Tang",
                "Yi Zhou",
                "Taichi Aida",
                "Procheta Sen",
                "Danushka Bollegala"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10400v1",
                "http://arxiv.org/pdf/2310.10400v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10399v1",
            "title": "Towards Fair and Calibrated Models",
            "updated": "2023-10-16T13:41:09Z",
            "published": "2023-10-16T13:41:09Z",
            "summary": "Recent literature has seen a significant focus on building machine learning\nmodels with specific properties such as fairness, i.e., being non-biased with\nrespect to a given set of attributes, calibration i.e., model confidence being\naligned with its predictive accuracy, and explainability, i.e., ability to be\nunderstandable to humans. While there has been work focusing on each of these\naspects individually, researchers have shied away from simultaneously\naddressing more than one of these dimensions. In this work, we address the\nproblem of building models which are both fair and calibrated. We work with a\nspecific definition of fairness, which closely matches [Biswas et. al. 2019],\nand has the nice property that Bayes optimal classifier has the maximum\npossible fairness under our definition. We show that an existing negative\nresult towards achieving a fair and calibrated model [Kleinberg et. al. 2017]\ndoes not hold for our definition of fairness. Further, we show that ensuring\ngroup-wise calibration with respect to the sensitive attributes automatically\nresults in a fair model under our definition. Using this result, we provide a\nfirst cut approach for achieving fair and calibrated models, via a simple\npost-processing technique based on temperature scaling. We then propose\nmodifications of existing calibration losses to perform group-wise calibration,\nas a way of achieving fair and calibrated models in a variety of settings.\nFinally, we perform extensive experimentation of these techniques on a diverse\nbenchmark of datasets, and present insights on the pareto-optimality of the\nresulting solutions.",
            "author": [
                "Anand Brahmbhatt",
                "Vipul Rathore",
                "Mausam",
                "Parag Singla"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10399v1",
                "http://arxiv.org/pdf/2310.10399v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10391v1",
            "title": "Towards Open World Active Learning for 3D Object Detection",
            "updated": "2023-10-16T13:32:53Z",
            "published": "2023-10-16T13:32:53Z",
            "summary": "Significant strides have been made in closed world 3D object detection,\ntesting systems in environments with known classes. However, the challenge\narises in open world scenarios where new object classes appear. Existing\nefforts sequentially learn novel classes from streams of labeled data at a\nsignificant annotation cost, impeding efficient deployment to the wild. To seek\neffective solutions, we investigate a more practical yet challenging research\ntask: Open World Active Learning for 3D Object Detection (OWAL-3D), aiming at\nselecting a small number of 3D boxes to annotate while maximizing detection\nperformance on both known and unknown classes. The core difficulty centers on\nstriking a balance between mining more unknown instances and minimizing the\nlabeling expenses of point clouds. Empirically, our study finds the harmonious\nand inverse relationship between box quantities and their confidences can help\nalleviate the dilemma, avoiding the repeated selection of common known\ninstances and focusing on uncertain objects that are potentially unknown. We\nunify both relational constraints into a simple and effective AL strategy\nnamely OpenCRB, which guides to acquisition of informative point clouds with\nthe least amount of boxes to label. Furthermore, we develop a comprehensive\ncodebase for easy reproducing and future research, supporting 15 baseline\nmethods (i.e., active learning, out-of-distribution detection and open world\ndetection), 2 types of modern 3D detectors (i.e., one-stage SECOND and\ntwo-stage PV-RCNN) and 3 benchmark 3D datasets (i.e., KITTI, nuScenes and\nWaymo). Extensive experiments evidence that the proposed Open-CRB demonstrates\nsuperiority and flexibility in recognizing both novel and shared categories\nwith very limited labeling costs, compared to state-of-the-art baselines.",
            "author": [
                "Zhuoxiao Chen",
                "Yadan Luo",
                "Zixin Wang",
                "Zijian Wang",
                "Xin Yu",
                "Zi Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10391v1",
                "http://arxiv.org/pdf/2310.10391v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10385v2",
            "title": "Towards a Better Understanding of Variations in Zero-Shot Neural Machine\n  Translation Performance",
            "updated": "2023-10-31T10:35:17Z",
            "published": "2023-10-16T13:26:05Z",
            "summary": "Multilingual Neural Machine Translation (MNMT) facilitates knowledge sharing\nbut often suffers from poor zero-shot (ZS) translation qualities. While prior\nwork has explored the causes of overall low ZS performance, our work introduces\na fresh perspective: the presence of high variations in ZS performance. This\nsuggests that MNMT does not uniformly exhibit poor ZS capability; instead,\ncertain translation directions yield reasonable results. Through systematic\nexperimentation involving 1,560 language directions spanning 40 languages, we\nidentify three key factors contributing to high variations in ZS NMT\nperformance: 1) target side translation capability 2) vocabulary overlap 3)\nlinguistic properties. Our findings highlight that the target side translation\nquality is the most influential factor, with vocabulary overlap consistently\nimpacting ZS performance. Additionally, linguistic properties, such as language\nfamily and writing system, play a role, particularly with smaller models.\nFurthermore, we suggest that the off-target issue is a symptom of inadequate ZS\nperformance, emphasizing that zero-shot translation challenges extend beyond\naddressing the off-target problem. We release the data and models serving as a\nbenchmark to study zero-shot for future research at\nhttps://github.com/Smu-Tan/ZS-NMT-Variations",
            "author": [
                "Shaomu Tan",
                "Christof Monz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10385v2",
                "http://arxiv.org/pdf/2310.10385v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10380v1",
            "title": "Contextual Data Augmentation for Task-Oriented Dialog Systems",
            "updated": "2023-10-16T13:22:34Z",
            "published": "2023-10-16T13:22:34Z",
            "summary": "Collection of annotated dialogs for training task-oriented dialog systems\nhave been one of the key bottlenecks in improving current models. While dialog\nresponse generation has been widely studied on the agent side, it is not\nevident if similar generative models can be used to generate a large variety\nof, and often unexpected, user inputs that real dialog systems encounter in\npractice. Existing data augmentation techniques such as paraphrase generation\ndo not take the dialog context into consideration. In this paper, we develop a\nnovel dialog augmentation model that generates a user turn, conditioning on\nfull dialog context. Additionally, with a new prompt design for language model,\nand output re-ranking, the dialogs generated from our model can be directly\nused to train downstream dialog systems. On common benchmark datasets MultiWoZ\nand SGD, we show that our dialog augmentation model generates high quality\ndialogs and improves dialog success rate by as much as $8\\%$ over baseline.",
            "author": [
                "Dustin Axman",
                "Avik Ray",
                "Shubham Garg",
                "Jing Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10380v1",
                "http://arxiv.org/pdf/2310.10380v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10379v1",
            "title": "Revisiting Logistic-softmax Likelihood in Bayesian Meta-Learning for\n  Few-Shot Classification",
            "updated": "2023-10-16T13:20:13Z",
            "published": "2023-10-16T13:20:13Z",
            "summary": "Meta-learning has demonstrated promising results in few-shot classification\n(FSC) by learning to solve new problems using prior knowledge. Bayesian methods\nare effective at characterizing uncertainty in FSC, which is crucial in\nhigh-risk fields. In this context, the logistic-softmax likelihood is often\nemployed as an alternative to the softmax likelihood in multi-class Gaussian\nprocess classification due to its conditional conjugacy property. However, the\ntheoretical property of logistic-softmax is not clear and previous research\nindicated that the inherent uncertainty of logistic-softmax leads to suboptimal\nperformance. To mitigate these issues, we revisit and redesign the\nlogistic-softmax likelihood, which enables control of the \\textit{a priori}\nconfidence level through a temperature parameter. Furthermore, we theoretically\nand empirically show that softmax can be viewed as a special case of\nlogistic-softmax and logistic-softmax induces a larger family of data\ndistribution than softmax. Utilizing modified logistic-softmax, we integrate\nthe data augmentation technique into the deep kernel based Gaussian process\nmeta-learning framework, and derive an analytical mean-field approximation for\ntask-specific updates. Our approach yields well-calibrated uncertainty\nestimates and achieves comparable or superior results on standard benchmark\ndatasets. Code is publicly available at\n\\url{https://github.com/keanson/revisit-logistic-softmax}.",
            "author": [
                "Tianjun Ke",
                "Haoqun Cao",
                "Zenan Ling",
                "Feng Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10379v1",
                "http://arxiv.org/pdf/2310.10379v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10378v4",
            "title": "Cross-Lingual Consistency of Factual Knowledge in Multilingual Language\n  Models",
            "updated": "2023-11-09T12:04:45Z",
            "published": "2023-10-16T13:19:17Z",
            "summary": "Multilingual large-scale Pretrained Language Models (PLMs) have been shown to\nstore considerable amounts of factual knowledge, but large variations are\nobserved across languages. With the ultimate goal of ensuring that users with\ndifferent language backgrounds obtain consistent feedback from the same model,\nwe study the cross-lingual consistency (CLC) of factual knowledge in various\nmultilingual PLMs. To this end, we propose a Ranking-based Consistency (RankC)\nmetric to evaluate knowledge consistency across languages independently from\naccuracy. Using this metric, we conduct an in-depth analysis of the determining\nfactors for CLC, both at model level and at language-pair level. Among other\nresults, we find that increasing model size leads to higher factual probing\naccuracy in most languages, but does not improve cross-lingual consistency.\nFinally, we conduct a case study on CLC when new factual associations are\ninserted in the PLMs via model editing. Results on a small sample of facts\ninserted in English reveal a clear pattern whereby the new piece of knowledge\ntransfers only to languages with which English has a high RankC score.",
            "author": [
                "Jirui Qi",
                "Raquel Fern\u00e1ndez",
                "Arianna Bisazza"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10378v4",
                "http://arxiv.org/pdf/2310.10378v4"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10375v1",
            "title": "GTA: A Geometry-Aware Attention Mechanism for Multi-View Transformers",
            "updated": "2023-10-16T13:16:09Z",
            "published": "2023-10-16T13:16:09Z",
            "summary": "As transformers are equivariant to the permutation of input tokens, encoding\nthe positional information of tokens is necessary for many tasks. However,\nsince existing positional encoding schemes have been initially designed for NLP\ntasks, their suitability for vision tasks, which typically exhibit different\nstructural properties in their data, is questionable. We argue that existing\npositional encoding schemes are suboptimal for 3D vision tasks, as they do not\nrespect their underlying 3D geometric structure. Based on this hypothesis, we\npropose a geometry-aware attention mechanism that encodes the geometric\nstructure of tokens as relative transformation determined by the geometric\nrelationship between queries and key-value pairs. By evaluating on multiple\nnovel view synthesis (NVS) datasets in the sparse wide-baseline multi-view\nsetting, we show that our attention, called Geometric Transform Attention\n(GTA), improves learning efficiency and performance of state-of-the-art\ntransformer-based NVS models without any additional learned parameters and only\nminor computational overhead.",
            "author": [
                "Takeru Miyato",
                "Bernhard Jaeger",
                "Max Welling",
                "Andreas Geiger"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10375v1",
                "http://arxiv.org/pdf/2310.10375v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10374v1",
            "title": "Multi-Factor Spatio-Temporal Prediction based on Graph Decomposition\n  Learning",
            "updated": "2023-10-16T13:12:27Z",
            "published": "2023-10-16T13:12:27Z",
            "summary": "Spatio-temporal (ST) prediction is an important and widely used technique in\ndata mining and analytics, especially for ST data in urban systems such as\ntransportation data. In practice, the ST data generation is usually influenced\nby various latent factors tied to natural phenomena or human socioeconomic\nactivities, impacting specific spatial areas selectively. However, existing ST\nprediction methods usually do not refine the impacts of different factors, but\ndirectly model the entangled impacts of multiple factors. This amplifies the\nmodeling complexity of ST data and compromises model interpretability. To this\nend, we propose a multi-factor ST prediction task that predicts partial ST data\nevolution under different factors, and combines them for a final prediction. We\nmake two contributions to this task: an effective theoretical solution and a\nportable instantiation framework. Specifically, we first propose a theoretical\nsolution called decomposed prediction strategy and prove its effectiveness from\nthe perspective of information entropy theory. On top of that, we instantiate a\nnovel model-agnostic framework, named spatio-temporal graph decomposition\nlearning (STGDL), for multi-factor ST prediction. The framework consists of two\nmain components: an automatic graph decomposition module that decomposes the\noriginal graph structure inherent in ST data into subgraphs corresponding to\ndifferent factors, and a decomposed learning network that learns the partial ST\ndata on each subgraph separately and integrates them for the final prediction.\nWe conduct extensive experiments on four real-world ST datasets of two types of\ngraphs, i.e., grid graph and network graph. Results show that our framework\nsignificantly reduces prediction errors of various ST models by 9.41% on\naverage (35.36% at most). Furthermore, a case study reveals the\ninterpretability potential of our framework.",
            "author": [
                "Jiahao Ji",
                "Jingyuan Wang",
                "Yu Mou",
                "Cheng Long"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10374v1",
                "http://arxiv.org/pdf/2310.10374v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10978v2",
            "title": "NeuroQuantify -- An Image Analysis Software for Detection and\n  Quantification of Neurons and Neurites using Deep Learning",
            "updated": "2023-10-19T08:33:52Z",
            "published": "2023-10-16T13:11:59Z",
            "summary": "The segmentation of cells and neurites in microscopy images of neuronal\nnetworks provides valuable quantitative information about neuron growth and\nneuronal differentiation, including the number of cells, neurites, neurite\nlength and neurite orientation. This information is essential for assessing the\ndevelopment of neuronal networks in response to extracellular stimuli, which is\nuseful for studying neuronal structures, for example, the study of\nneurodegenerative diseases and pharmaceuticals. However, automatic and accurate\nanalysis of neuronal structures from phase contrast images has remained\nchallenging. To address this, we have developed NeuroQuantify, an open-source\nsoftware that uses deep learning to efficiently and quickly segment cells and\nneurites in phase contrast microscopy images. NeuroQuantify offers several key\nfeatures: (i) automatic detection of cells and neurites; (ii) post-processing\nof the images for the quantitative neurite length measurement based on\nsegmentation of phase contrast microscopy images, and (iii) identification of\nneurite orientations. The user-friendly NeuroQuantify software can be installed\nand freely downloaded from GitHub\nhttps://github.com/StanleyZ0528/neural-image-segmentation.",
            "author": [
                "Ka My Dang",
                "Yi Jia Zhang",
                "Tianchen Zhang",
                "Chao Wang",
                "Anton Sinner",
                "Piero Coronica",
                "Joyce K. S. Poon"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10978v2",
                "http://arxiv.org/pdf/2310.10978v2"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10372v1",
            "title": "Looping LOCI: Developing Object Permanence from Videos",
            "updated": "2023-10-16T13:11:35Z",
            "published": "2023-10-16T13:11:35Z",
            "summary": "Recent compositional scene representation learning models have become\nremarkably good in segmenting and tracking distinct objects within visual\nscenes. Yet, many of these models require that objects are continuously, at\nleast partially, visible. Moreover, they tend to fail on intuitive physics\ntests, which infants learn to solve over the first months of their life. Our\ngoal is to advance compositional scene representation algorithms with an\nembedded algorithm that fosters the progressive learning of intuitive physics,\nakin to infant development. As a fundamental component for such an algorithm,\nwe introduce Loci-Looped, which advances a recently published unsupervised\nobject location, identification, and tracking neural network architecture\n(Loci, Traub et al., ICLR 2023) with an internal processing loop. The loop is\ndesigned to adaptively blend pixel-space information with anticipations\nyielding information-fused activities as percepts. Moreover, it is designed to\nlearn compositional representations of both individual object dynamics and\nbetween-objects interaction dynamics. We show that Loci-Looped learns to track\nobjects through extended periods of object occlusions, indeed simulating their\nhidden trajectories and anticipating their reappearance, without the need for\nan explicit history buffer. We even find that Loci-Looped surpasses\nstate-of-the-art models on the ADEPT and the CLEVRER dataset, when confronted\nwith object occlusions or temporary sensory data interruptions. This indicates\nthat Loci-Looped is able to learn the physical concepts of object permanence\nand inertia in a fully unsupervised emergent manner. We believe that even\nfurther architectural advancements of the internal loop - also in other\ncompositional scene representation learning models - can be developed in the\nnear future.",
            "author": [
                "Manuel Traub",
                "Frederic Becker",
                "Sebastian Otte",
                "Martin V. Butz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10372v1",
                "http://arxiv.org/pdf/2310.10372v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10368v1",
            "title": "Machine learning in physics: a short guide",
            "updated": "2023-10-16T13:05:47Z",
            "published": "2023-10-16T13:05:47Z",
            "summary": "Machine learning is a rapidly growing field with the potential to\nrevolutionize many areas of science, including physics. This review provides a\nbrief overview of machine learning in physics, covering the main concepts of\nsupervised, unsupervised, and reinforcement learning, as well as more\nspecialized topics such as causal inference, symbolic regression, and deep\nlearning. We present some of the principal applications of machine learning in\nphysics and discuss the associated challenges and perspectives.",
            "author": [
                "Francisco A. Rodrigues"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10368v1",
                "http://arxiv.org/pdf/2310.10368v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cond-mat.stat-mech",
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19810v1",
            "title": "Advantages of Machine Learning in Bus Transport Analysis",
            "updated": "2023-10-16T13:02:43Z",
            "published": "2023-10-16T13:02:43Z",
            "summary": "Supervised Machine Learning is an innovative method that aims to mimic human\nlearning by using past experiences. In this study, we utilize supervised\nmachine learning algorithms to analyze the factors that contribute to the\npunctuality of Tehran BRT bus system. We gather publicly available datasets of\n2020 to 2022 from Municipality of Tehran to train and test our models. By\nemploying various algorithms and leveraging Python's Sci Kit Learn and Stats\nModels libraries, we construct accurate models capable of predicting whether a\nbus route will meet the prescribed standards for on-time performance on any\ngiven day. Furthermore, we delve deeper into the decision-making process of\neach algorithm to determine the most influential factor it considers. This\ninvestigation allows us to uncover the key feature that significantly impacts\nthe effectiveness of bus routes, providing valuable insights for improving\ntheir performance.",
            "author": [
                "Amirsadegh Roshanzamir"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19810v1",
                "http://arxiv.org/pdf/2310.19810v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19809v1",
            "title": "MgNO: Efficient Parameterization of Linear Operators via Multigrid",
            "updated": "2023-10-16T13:01:35Z",
            "published": "2023-10-16T13:01:35Z",
            "summary": "In this work, we propose a concise neural operator architecture for operator\nlearning. Drawing an analogy with a conventional fully connected neural\nnetwork, we define the neural operator as follows: the output of the $i$-th\nneuron in a nonlinear operator layer is defined by $\\mathcal O_i(u) =\n\\sigma\\left( \\sum_j \\mathcal W_{ij} u + \\mathcal B_{ij}\\right)$. Here,\n$\\mathcal W_{ij}$ denotes the bounded linear operator connecting $j$-th input\nneuron to $i$-th output neuron, and the bias $\\mathcal B_{ij}$ takes the form\nof a function rather than a scalar. Given its new universal approximation\nproperty, the efficient parameterization of the bounded linear operators\nbetween two neurons (Banach spaces) plays a critical role. As a result, we\nintroduce MgNO, utilizing multigrid structures to parameterize these linear\noperators between neurons. This approach offers both mathematical rigor and\npractical expressivity. Additionally, MgNO obviates the need for conventional\nlifting and projecting operators typically required in previous neural\noperators. Moreover, it seamlessly accommodates diverse boundary conditions.\nOur empirical observations reveal that MgNO exhibits superior ease of training\ncompared to other CNN-based models, while also displaying a reduced\nsusceptibility to overfitting when contrasted with spectral-type neural\noperators. We demonstrate the efficiency and accuracy of our method with\nconsistently state-of-the-art performance on different types of partial\ndifferential equations (PDEs).",
            "author": [
                "Juncai He",
                "Xinliang Liu",
                "Jinchao Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19809v1",
                "http://arxiv.org/pdf/2310.19809v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10362v1",
            "title": "Prompt Tuning for Multi-View Graph Contrastive Learning",
            "updated": "2023-10-16T12:58:04Z",
            "published": "2023-10-16T12:58:04Z",
            "summary": "In recent years, \"pre-training and fine-tuning\" has emerged as a promising\napproach in addressing the issues of label dependency and poor generalization\nperformance in traditional GNNs. To reduce labeling requirement, the\n\"pre-train, fine-tune\" and \"pre-train, prompt\" paradigms have become\nincreasingly common. In particular, prompt tuning is a popular alternative to\n\"pre-training and fine-tuning\" in natural language processing, which is\ndesigned to narrow the gap between pre-training and downstream objectives.\nHowever, existing study of prompting on graphs is still limited, lacking a\nframework that can accommodate commonly used graph pre-training methods and\ndownstream tasks. In this paper, we propose a multi-view graph contrastive\nlearning method as pretext and design a prompting tuning for it. Specifically,\nwe first reformulate graph pre-training and downstream tasks into a common\nformat. Second, we construct multi-view contrasts to capture relevant\ninformation of graphs by GNN. Third, we design a prompting tuning method for\nour multi-view graph contrastive learning method to bridge the gap between\npretexts and downsteam tasks. Finally, we conduct extensive experiments on\nbenchmark datasets to evaluate and analyze our proposed method.",
            "author": [
                "Chenghua Gong",
                "Xiang Li",
                "Jianxiang Yu",
                "Cheng Yao",
                "Jiaqi Tan",
                "Chengcheng Yu",
                "Dawei Yin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10362v1",
                "http://arxiv.org/pdf/2310.10362v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10359v1",
            "title": "An Anytime Algorithm for Good Arm Identification",
            "updated": "2023-10-16T12:51:26Z",
            "published": "2023-10-16T12:51:26Z",
            "summary": "In good arm identification (GAI), the goal is to identify one arm whose\naverage performance exceeds a given threshold, referred to as good arm, if it\nexists. Few works have studied GAI in the fixed-budget setting, when the\nsampling budget is fixed beforehand, or the anytime setting, when a\nrecommendation can be asked at any time. We propose APGAI, an anytime and\nparameter-free sampling rule for GAI in stochastic bandits. APGAI can be\nstraightforwardly used in fixed-confidence and fixed-budget settings. First, we\nderive upper bounds on its probability of error at any time. They show that\nadaptive strategies are more efficient in detecting the absence of good arms\nthan uniform sampling. Second, when APGAI is combined with a stopping rule, we\nprove upper bounds on the expected sampling complexity, holding at any\nconfidence level. Finally, we show good empirical performance of APGAI on\nsynthetic and real-world data. Our work offers an extensive overview of the GAI\nproblem in all settings.",
            "author": [
                "Marc Jourdan",
                "Cl\u00e9mence R\u00e9da"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10359v1",
                "http://arxiv.org/pdf/2310.10359v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10358v1",
            "title": "Tabular Representation, Noisy Operators, and Impacts on Table Structure\n  Understanding Tasks in LLMs",
            "updated": "2023-10-16T12:51:24Z",
            "published": "2023-10-16T12:51:24Z",
            "summary": "Large language models (LLMs) are increasingly applied for tabular tasks using\nin-context learning. The prompt representation for a table may play a role in\nthe LLMs ability to process the table. Inspired by prior work, we generate a\ncollection of self-supervised structural tasks (e.g. navigate to a cell and\nrow; transpose the table) and evaluate the performance differences when using 8\nformats. In contrast to past work, we introduce 8 noise operations inspired by\nreal-world messy data and adversarial inputs, and show that such operations can\nimpact LLM performance across formats for different structural understanding\ntasks.",
            "author": [
                "Ananya Singha",
                "Jos\u00e9 Cambronero",
                "Sumit Gulwani",
                "Vu Le",
                "Chris Parnin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10358v1",
                "http://arxiv.org/pdf/2310.10358v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10357v1",
            "title": "BEVGPT: Generative Pre-trained Large Model for Autonomous Driving\n  Prediction, Decision-Making, and Planning",
            "updated": "2023-10-16T12:50:19Z",
            "published": "2023-10-16T12:50:19Z",
            "summary": "Prediction, decision-making, and motion planning are essential for autonomous\ndriving. In most contemporary works, they are considered as individual modules\nor combined into a multi-task learning paradigm with a shared backbone but\nseparate task heads. However, we argue that they should be integrated into a\ncomprehensive framework. Although several recent approaches follow this scheme,\nthey suffer from complicated input representations and redundant framework\ndesigns. More importantly, they can not make long-term predictions about future\ndriving scenarios. To address these issues, we rethink the necessity of each\nmodule in an autonomous driving task and incorporate only the required modules\ninto a minimalist autonomous driving framework. We propose BEVGPT, a generative\npre-trained large model that integrates driving scenario prediction,\ndecision-making, and motion planning. The model takes the bird's-eye-view (BEV)\nimages as the only input source and makes driving decisions based on\nsurrounding traffic scenarios. To ensure driving trajectory feasibility and\nsmoothness, we develop an optimization-based motion planning method. We\ninstantiate BEVGPT on Lyft Level 5 Dataset and use Woven Planet L5Kit for\nrealistic driving simulation. The effectiveness and robustness of the proposed\nframework are verified by the fact that it outperforms previous methods in 100%\ndecision-making metrics and 66% motion planning metrics. Furthermore, the\nability of our framework to accurately generate BEV images over the long term\nis demonstrated through the task of driving scenario prediction. To the best of\nour knowledge, this is the first generative pre-trained large model for\nautonomous driving prediction, decision-making, and motion planning with only\nBEV images as input.",
            "author": [
                "Pengqin Wang",
                "Meixin Zhu",
                "Hongliang Lu",
                "Hui Zhong",
                "Xianda Chen",
                "Shaojie Shen",
                "Xuesong Wang",
                "Yinhai Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10357v1",
                "http://arxiv.org/pdf/2310.10357v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15119v1",
            "title": "Compressed Sensing of Generative Sparse-latent (GSL) Signals",
            "updated": "2023-10-16T12:49:33Z",
            "published": "2023-10-16T12:49:33Z",
            "summary": "We consider reconstruction of an ambient signal in a compressed sensing (CS)\nsetup where the ambient signal has a neural network based generative model. The\ngenerative model has a sparse-latent input and we refer to the generated\nambient signal as generative sparse-latent signal (GSL). The proposed sparsity\ninducing reconstruction algorithm is inherently non-convex, and we show that a\ngradient based search provides a good reconstruction performance. We evaluate\nour proposed algorithm using simulated data.",
            "author": [
                "Antoine Honor\u00e9",
                "Anubhab Ghosh",
                "Saikat Chatterjee"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15119v1",
                "http://arxiv.org/pdf/2310.15119v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10353v1",
            "title": "Multimodal Object Query Initialization for 3D Object Detection",
            "updated": "2023-10-16T12:42:44Z",
            "published": "2023-10-16T12:42:44Z",
            "summary": "3D object detection models that exploit both LiDAR and camera sensor features\nare top performers in large-scale autonomous driving benchmarks. A transformer\nis a popular network architecture used for this task, in which so-called object\nqueries act as candidate objects. Initializing these object queries based on\ncurrent sensor inputs is a common practice. For this, existing methods strongly\nrely on LiDAR data however, and do not fully exploit image features. Besides,\nthey introduce significant latency. To overcome these limitations we propose\nEfficientQ3M, an efficient, modular, and multimodal solution for object query\ninitialization for transformer-based 3D object detection models. The proposed\ninitialization method is combined with a \"modality-balanced\" transformer\ndecoder where the queries can access all sensor modalities throughout the\ndecoder. In experiments, we outperform the state of the art in\ntransformer-based LiDAR object detection on the competitive nuScenes benchmark\nand showcase the benefits of input-dependent multimodal query initialization,\nwhile being more efficient than the available alternatives for LiDAR-camera\ninitialization. The proposed method can be applied with any combination of\nsensor modalities as input, demonstrating its modularity.",
            "author": [
                "Mathijs R. van Geerenstein",
                "Felicia Ruppel",
                "Klaus Dietmayer",
                "Dariu M. Gavrila"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10353v1",
                "http://arxiv.org/pdf/2310.10353v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10352v2",
            "title": "Semi-Supervised Crowd Counting with Contextual Modeling: Facilitating\n  Holistic Understanding of Crowd Scenes",
            "updated": "2023-10-23T14:45:07Z",
            "published": "2023-10-16T12:42:43Z",
            "summary": "To alleviate the heavy annotation burden for training a reliable crowd\ncounting model and thus make the model more practicable and accurate by being\nable to benefit from more data, this paper presents a new semi-supervised\nmethod based on the mean teacher framework. When there is a scarcity of labeled\ndata available, the model is prone to overfit local patches. Within such\ncontexts, the conventional approach of solely improving the accuracy of local\npatch predictions through unlabeled data proves inadequate. Consequently, we\npropose a more nuanced approach: fostering the model's intrinsic 'subitizing'\ncapability. This ability allows the model to accurately estimate the count in\nregions by leveraging its understanding of the crowd scenes, mirroring the\nhuman cognitive process. To achieve this goal, we apply masking on unlabeled\ndata, guiding the model to make predictions for these masked patches based on\nthe holistic cues. Furthermore, to help with feature learning, herein we\nincorporate a fine-grained density classification task. Our method is general\nand applicable to most existing crowd counting methods as it doesn't have\nstrict structural or loss constraints. In addition, we observe that the model\ntrained with our framework exhibits a 'subitizing'-like behavior. It accurately\npredicts low-density regions with only a 'glance', while incorporating local\ndetails to predict high-density regions. Our method achieves the\nstate-of-the-art performance, surpassing previous approaches by a large margin\non challenging benchmarks such as ShanghaiTech A and UCF-QNRF. The code is\navailable at: https://github.com/cha15yq/MRC-Crowd.",
            "author": [
                "Yifei Qian",
                "Xiaopeng Hong",
                "Ognjen Arandjelovi\u0107",
                "Zhongliang Guo",
                "Carl R. Donovan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10352v2",
                "http://arxiv.org/pdf/2310.10352v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10348v2",
            "title": "Attribution Patching Outperforms Automated Circuit Discovery",
            "updated": "2023-11-20T11:31:16Z",
            "published": "2023-10-16T12:34:43Z",
            "summary": "Automated interpretability research has recently attracted attention as a\npotential research direction that could scale explanations of neural network\nbehavior to large models. Existing automated circuit discovery work applies\nactivation patching to identify subnetworks responsible for solving specific\ntasks (circuits). In this work, we show that a simple method based on\nattribution patching outperforms all existing methods while requiring just two\nforward passes and a backward pass. We apply a linear approximation to\nactivation patching to estimate the importance of each edge in the\ncomputational subgraph. Using this approximation, we prune the least important\nedges of the network. We survey the performance and limitations of this method,\nfinding that averaged over all tasks our method has greater AUC from circuit\nrecovery than other methods.",
            "author": [
                "Aaquib Syed",
                "Can Rager",
                "Arthur Conmy"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10348v2",
                "http://arxiv.org/pdf/2310.10348v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10343v1",
            "title": "ConsistNet: Enforcing 3D Consistency for Multi-view Images Diffusion",
            "updated": "2023-10-16T12:29:29Z",
            "published": "2023-10-16T12:29:29Z",
            "summary": "Given a single image of a 3D object, this paper proposes a novel method\n(named ConsistNet) that is able to generate multiple images of the same object,\nas if seen they are captured from different viewpoints, while the 3D\n(multi-view) consistencies among those multiple generated images are\neffectively exploited. Central to our method is a multi-view consistency block\nwhich enables information exchange across multiple single-view diffusion\nprocesses based on the underlying multi-view geometry principles. ConsistNet is\nan extension to the standard latent diffusion model, and consists of two\nsub-modules: (a) a view aggregation module that unprojects multi-view features\ninto global 3D volumes and infer consistency, and (b) a ray aggregation module\nthat samples and aggregate 3D consistent features back to each view to enforce\nconsistency. Our approach departs from previous methods in multi-view image\ngeneration, in that it can be easily dropped-in pre-trained LDMs without\nrequiring explicit pixel correspondences or depth prediction. Experiments show\nthat our method effectively learns 3D consistency over a frozen Zero123\nbackbone and can generate 16 surrounding views of the object within 40 seconds\non a single A100 GPU. Our code will be made available on\nhttps://github.com/JiayuYANG/ConsistNet",
            "author": [
                "Jiayu Yang",
                "Ziang Cheng",
                "Yunfei Duan",
                "Pan Ji",
                "Hongdong Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10343v1",
                "http://arxiv.org/pdf/2310.10343v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10336v1",
            "title": "A Multilayered Security Infrastructure for Connected Vehicles -- First\n  Lessons from the Field",
            "updated": "2023-10-16T12:22:29Z",
            "published": "2023-10-16T12:22:29Z",
            "summary": "Connected vehicles are vulnerable to manipulation and a broad attack surface\ncan be used to intrude in-vehicle networks from anywhere on earth. In this\nwork, we present an integrated security infrastructure comprising network\nprotection, monitoring, incident management, and counteractions, which we built\ninto a prototype based on a production car. Our vehicle implements a\nSoftware-Defined Networking Ethernet backbone to restrict communication routes,\nnetwork anomaly detection to make misbehavior evident, virtual controller\nfunctions to enable agile countermeasures, and an automotive cloud defense\ncenter to analyse and manage incidents on vehicle fleets. We present first\nmeasurements and lessons learned from operating the prototype: many network\nattacks can be prevented through software-defined access control in the\nbackbone; anomaly detection can reliably detect misbehavior but needs to\nimprove on false positive rate; controller virtualization needs tailored\nframeworks to meet in-car requirements; and cloud defence enables fleet\nmanagement and advanced countermeasures. Our findings indicate attack\nmitigation times in the vehicle from 257 ms to 328 ms and from 2,168 ms to\n2,713 ms traversing the cloud.",
            "author": [
                "Timo H\u00e4ckel",
                "Philipp Meyer",
                "Lukas Stahlbock",
                "Falk Langer",
                "Sebastian A. Eckhardt",
                "Franz Korf",
                "Thomas C. Schmidt"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10336v1",
                "http://arxiv.org/pdf/2310.10336v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10330v1",
            "title": "Unlocking Metasurface Practicality for B5G Networks: AI-assisted RIS\n  Planning",
            "updated": "2023-10-16T12:14:42Z",
            "published": "2023-10-16T12:14:42Z",
            "summary": "The advent of reconfigurable intelligent surfaces(RISs) brings along\nsignificant improvements for wireless technology on the verge of\nbeyond-fifth-generation networks (B5G).The proven flexibility in influencing\nthe propagation environment opens up the possibility of programmatically\naltering the wireless channel to the advantage of network designers, enabling\nthe exploitation of higher-frequency bands for superior throughput overcoming\nthe challenging electromagnetic (EM) propagation properties at these frequency\nbands.\n  However, RISs are not magic bullets. Their employment comes with significant\ncomplexity, requiring ad-hoc deployments and management operations to come to\nfruition. In this paper, we tackle the open problem of bringing RISs to the\nfield, focusing on areas with little or no coverage. In fact, we present a\nfirst-of-its-kind deep reinforcement learning (DRL) solution, dubbed as D-RISA,\nwhich trains a DRL agent and, in turn, obtain san optimal RIS deployment. We\nvalidate our framework in the indoor scenario of the Rennes railway station in\nFrance, assessing the performance of our algorithm against state-of-the-art\n(SOA) approaches. Our benchmarks showcase better coverage, i.e., 10-dB increase\nin minimum signal-to-noise ratio (SNR), at lower computational time (up to -25\npercent) while improving scalability towards denser network deployments.",
            "author": [
                "Guillermo Encinas-Lago",
                "Antonio Albanese",
                "Vincenzo Sciancalepore",
                "Marco Di Renzo",
                "Xavier Costa-P\u00e9rez"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10330v1",
                "http://arxiv.org/pdf/2310.10330v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.AI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10329v1",
            "title": "Towards Data-Conditional Simulation for ABC Inference in Stochastic\n  Differential Equations",
            "updated": "2023-10-16T12:10:43Z",
            "published": "2023-10-16T12:10:43Z",
            "summary": "We develop a Bayesian inference method for discretely-observed stochastic\ndifferential equations (SDEs). Inference is challenging for most SDEs, due to\nthe analytical intractability of the likelihood function. Nevertheless, forward\nsimulation via numerical methods is straightforward, motivating the use of\napproximate Bayesian computation (ABC). We propose a conditional simulation\nscheme for SDEs that is based on lookahead strategies for sequential Monte\nCarlo (SMC) and particle smoothing using backward simulation. This leads to the\nsimulation of trajectories that are consistent with the observed trajectory,\nthereby increasing the ABC acceptance rate. We additionally employ an invariant\nneural network, previously developed for Markov processes, to learn the summary\nstatistics function required in ABC. The neural network is incrementally\nretrained by exploiting an ABC-SMC sampler, which provides new training data at\neach round. Since the SDE simulation scheme differs from standard forward\nsimulation, we propose a suitable importance sampling correction, which has the\nadded advantage of guiding the parameters towards regions of high posterior\ndensity, especially in the first ABC-SMC round. Our approach achieves accurate\ninference and is about three times faster than standard (forward-only) ABC-SMC.\nWe illustrate our method in four simulation studies, including three examples\nfrom the Chan-Karaolyi-Longstaff-Sanders SDE family.",
            "author": [
                "Petar Jovanovski",
                "Andrew Golightly",
                "Umberto Picchini"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10329v1",
                "http://arxiv.org/pdf/2310.10329v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10324v1",
            "title": "Assessing univariate and bivariate risks of late-frost and drought using\n  vine copulas: A historical study for Bavaria",
            "updated": "2023-10-16T12:08:14Z",
            "published": "2023-10-16T12:08:14Z",
            "summary": "In light of climate change's impacts on forests, including extreme drought\nand late-frost, leading to vitality decline and regional forest die-back, we\nassess univariate drought and late-frost risks and perform a joint risk\nanalysis in Bavaria, Germany, from 1952 to 2020. Utilizing a vast dataset with\n26 bioclimatic and topographic variables, we employ vine copula models due to\nthe data's non-Gaussian and asymmetric dependencies. We use D-vine regression\nfor univariate and Y-vine regression for bivariate analysis, and propose\ncorresponding univariate and bivariate conditional probability risk measures.\nWe identify \"at-risk\" regions, emphasizing the need for forest adaptation due\nto climate change.",
            "author": [
                "Marija Tepegjozova",
                "Benjamin F. Meyer",
                "Anja Rammig",
                "Christian S. Zang",
                "Claudia Czado"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10324v1",
                "http://arxiv.org/pdf/2310.10324v1"
            ],
            "primary_category": "stat.AP",
            "category": [
                "stat.AP",
                "stat.ME",
                "stat.ML",
                "62H05, 62P12, 91G70",
                "G.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10321v2",
            "title": "Hamming Encoder: Mining Discriminative k-mers for Discrete Sequence\n  Classification",
            "updated": "2023-10-20T10:30:49Z",
            "published": "2023-10-16T12:03:27Z",
            "summary": "Sequence classification has numerous applications in various fields. Despite\nextensive studies in the last decades, many challenges still exist,\nparticularly in pattern-based methods. Existing pattern-based methods measure\nthe discriminative power of each feature individually during the mining\nprocess, leading to the result of missing some combinations of features with\ndiscriminative power. Furthermore, it is difficult to ensure the overall\ndiscriminative performance after converting sequences into feature vectors. To\naddress these challenges, we propose a novel approach called Hamming Encoder,\nwhich utilizes a binarized 1D-convolutional neural network (1DCNN) architecture\nto mine discriminative k-mer sets. In particular, we adopt a Hamming\ndistance-based similarity measure to ensure consistency in the feature mining\nand classification procedure. Our method involves training an interpretable CNN\nencoder for sequential data and performing a gradient-based search for\ndiscriminative k-mer combinations. Experiments show that the Hamming Encoder\nmethod proposed in this paper outperforms existing state-of-the-art methods in\nterms of classification accuracy.",
            "author": [
                "Junjie Dong",
                "Mudi Jiang",
                "Lianyu Hu",
                "Zengyou He"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10321v2",
                "http://arxiv.org/pdf/2310.10321v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10318v1",
            "title": "Interpreting and Exploiting Functional Specialization in Multi-Head\n  Attention under Multi-task Learning",
            "updated": "2023-10-16T11:55:53Z",
            "published": "2023-10-16T11:55:53Z",
            "summary": "Transformer-based models, even though achieving super-human performance on\nseveral downstream tasks, are often regarded as a black box and used as a\nwhole. It is still unclear what mechanisms they have learned, especially their\ncore module: multi-head attention. Inspired by functional specialization in the\nhuman brain, which helps to efficiently handle multiple tasks, this work\nattempts to figure out whether the multi-head attention module will evolve\nsimilar function separation under multi-tasking training. If it is, can this\nmechanism further improve the model performance? To investigate these\nquestions, we introduce an interpreting method to quantify the degree of\nfunctional specialization in multi-head attention. We further propose a simple\nmulti-task training method to increase functional specialization and mitigate\nnegative information transfer in multi-task learning. Experimental results on\nseven pre-trained transformer models have demonstrated that multi-head\nattention does evolve functional specialization phenomenon after multi-task\ntraining which is affected by the similarity of tasks. Moreover, the multi-task\ntraining strategy based on functional specialization boosts performance in both\nmulti-task learning and transfer learning without adding any parameters.",
            "author": [
                "Chong Li",
                "Shaonan Wang",
                "Yunhao Zhang",
                "Jiajun Zhang",
                "Chengqing Zong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10318v1",
                "http://arxiv.org/pdf/2310.10318v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10315v1",
            "title": "A Survey on Quantum Machine Learning: Current Trends, Challenges,\n  Opportunities, and the Road Ahead",
            "updated": "2023-10-16T11:52:54Z",
            "published": "2023-10-16T11:52:54Z",
            "summary": "Quantum Computing (QC) claims to improve the efficiency of solving complex\nproblems, compared to classical computing. When QC is applied to Machine\nLearning (ML) applications, it forms a Quantum Machine Learning (QML) system.\nAfter discussing the basic concepts of QC and its advantages over classical\ncomputing, this paper reviews the key aspects of QML in a comprehensive manner.\nWe discuss different QML algorithms and their domain applicability, quantum\ndatasets, hardware technologies, software tools, simulators, and applications.\nIn this survey, we provide valuable information and resources for readers to\njumpstart into the current state-of-the-art techniques in the QML field.",
            "author": [
                "Kamila Zaman",
                "Alberto Marchisio",
                "Muhammad Abdullah Hanif",
                "Muhammad Shafique"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10315v1",
                "http://arxiv.org/pdf/2310.10315v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10312v1",
            "title": "End-to-end Offline Reinforcement Learning for Glycemia Control",
            "updated": "2023-10-16T11:46:45Z",
            "published": "2023-10-16T11:46:45Z",
            "summary": "The development of closed-loop systems for glycemia control in type I\ndiabetes relies heavily on simulated patients. Improving the performances and\nadaptability of these close-loops raises the risk of over-fitting the\nsimulator. This may have dire consequences, especially in unusual cases which\nwere not faithfully-if at all-captured by the simulator. To address this, we\npropose to use offline RL agents, trained on real patient data, to perform the\nglycemia control. To further improve the performances, we propose an end-to-end\npersonalization pipeline, which leverages offline-policy evaluation methods to\nremove altogether the need of a simulator, while still enabling an estimation\nof clinically relevant metrics for diabetes.",
            "author": [
                "Tristan Beolet",
                "Alice Adenis",
                "Erik Huneker",
                "Maxime Louis"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10312v1",
                "http://arxiv.org/pdf/2310.10312v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10702v2",
            "title": "Transparent Anomaly Detection via Concept-based Explanations",
            "updated": "2023-11-01T09:56:52Z",
            "published": "2023-10-16T11:46:26Z",
            "summary": "Advancements in deep learning techniques have given a boost to the\nperformance of anomaly detection. However, real-world and safety-critical\napplications demand a level of transparency and reasoning beyond accuracy. The\ntask of anomaly detection (AD) focuses on finding whether a given sample\nfollows the learned distribution. Existing methods lack the ability to reason\nwith clear explanations for their outcomes. Hence to overcome this challenge,\nwe propose Transparent {A}nomaly Detection {C}oncept {E}xplanations (ACE). ACE\nis able to provide human interpretable explanations in the form of concepts\nalong with anomaly prediction. To the best of our knowledge, this is the first\npaper that proposes interpretable by-design anomaly detection. In addition to\npromoting transparency in AD, it allows for effective human-model interaction.\nOur proposed model shows either higher or comparable results to black-box\nuninterpretable models. We validate the performance of ACE across three\nrealistic datasets - bird classification on CUB-200-2011, challenging\nhistopathology slide image classification on TIL-WSI-TCGA, and gender\nclassification on CelebA. We further demonstrate that our concept learning\nparadigm can be seamlessly integrated with other classification-based AD\nmethods.",
            "author": [
                "Laya Rafiee Sevyeri",
                "Ivaxi Sheth",
                "Farhood Farahnak",
                "Samira Ebrahimi Kahou",
                "Shirin Abbasinejad Enger"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10702v2",
                "http://arxiv.org/pdf/2310.10702v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10308v1",
            "title": "Time integration schemes based on neural networks for solving partial\n  differential equations on coarse grids",
            "updated": "2023-10-16T11:43:08Z",
            "published": "2023-10-16T11:43:08Z",
            "summary": "The accuracy of solving partial differential equations (PDEs) on coarse grids\nis greatly affected by the choice of discretization schemes. In this work, we\npropose to learn time integration schemes based on neural networks which\nsatisfy three distinct sets of mathematical constraints, i.e., unconstrained,\nsemi-constrained with the root condition, and fully-constrained with both root\nand consistency conditions. We focus on the learning of 3-step linear multistep\nmethods, which we subsequently applied to solve three model PDEs, i.e., the\none-dimensional heat equation, the one-dimensional wave equation, and the\none-dimensional Burgers' equation. The results show that the prediction error\nof the learned fully-constrained scheme is close to that of the Runge-Kutta\nmethod and Adams-Bashforth method. Compared to the traditional methods, the\nlearned unconstrained and semi-constrained schemes significantly reduce the\nprediction error on coarse grids. On a grid that is 4 times coarser than the\nreference grid, the mean square error shows a reduction of up to an order of\nmagnitude for some of the heat equation cases, and a substantial improvement in\nphase prediction for the wave equation. On a 32 times coarser grid, the mean\nsquare error for the Burgers' equation can be reduced by up to 35% to 40%.",
            "author": [
                "Xinxin Yan",
                "Zhideng Zhou",
                "Xiaohan Cheng",
                "Xiaolei Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10308v1",
                "http://arxiv.org/pdf/2310.10308v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.LG",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10307v1",
            "title": "Learning visual-based deformable object rearrangement with local graph\n  neural networks",
            "updated": "2023-10-16T11:42:54Z",
            "published": "2023-10-16T11:42:54Z",
            "summary": "Goal-conditioned rearrangement of deformable objects (e.g. straightening a\nrope and folding a cloth) is one of the most common deformable manipulation\ntasks, where the robot needs to rearrange a deformable object into a prescribed\ngoal configuration with only visual observations. These tasks are typically\nconfronted with two main challenges: the high dimensionality of deformable\nconfiguration space and the underlying complexity, nonlinearity and uncertainty\ninherent in deformable dynamics. To address these challenges, we propose a\nnovel representation strategy that can efficiently model the deformable object\nstates with a set of keypoints and their interactions. We further propose\nlocal-graph neural network (GNN), a light local GNN learning to jointly model\nthe deformable rearrangement dynamics and infer the optimal manipulation\nactions (e.g. pick and place) by constructing and updating two dynamic graphs.\nBoth simulated and real experiments have been conducted to demonstrate that the\nproposed dynamic graph representation shows superior expressiveness in modeling\ndeformable rearrangement dynamics. Our method reaches much higher success rates\non a variety of deformable rearrangement tasks (96.3% on average) than\nstate-of-the-art method in simulation experiments. Besides, our method is much\nmore lighter and has a 60% shorter inference time than state-of-the-art\nmethods. We also demonstrate that our method performs well in the multi-task\nlearning scenario and can be transferred to real-world applications with an\naverage success rate of 95% by solely fine tuning a keypoint detector.",
            "author": [
                "Yuhong Deng",
                "Xueqian Wang",
                "Lipeng chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10307v1",
                "http://arxiv.org/pdf/2310.10307v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10300v1",
            "title": "BeatDance: A Beat-Based Model-Agnostic Contrastive Learning Framework\n  for Music-Dance Retrieval",
            "updated": "2023-10-16T11:36:38Z",
            "published": "2023-10-16T11:36:38Z",
            "summary": "Dance and music are closely related forms of expression, with mutual\nretrieval between dance videos and music being a fundamental task in various\nfields like education, art, and sports. However, existing methods often suffer\nfrom unnatural generation effects or fail to fully explore the correlation\nbetween music and dance. To overcome these challenges, we propose BeatDance, a\nnovel beat-based model-agnostic contrastive learning framework. BeatDance\nincorporates a Beat-Aware Music-Dance InfoExtractor, a Trans-Temporal Beat\nBlender, and a Beat-Enhanced Hubness Reducer to improve dance-music retrieval\nperformance by utilizing the alignment between music beats and dance movements.\nWe also introduce the Music-Dance (MD) dataset, a large-scale collection of\nover 10,000 music-dance video pairs for training and testing. Experimental\nresults on the MD dataset demonstrate the superiority of our method over\nexisting baselines, achieving state-of-the-art performance. The code and\ndataset will be made public available upon acceptance.",
            "author": [
                "Kaixing Yang",
                "Xukun Zhou",
                "Xulong Tang",
                "Ran Diao",
                "Hongyan Liu",
                "Jun He",
                "Zhaoxin Fan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10300v1",
                "http://arxiv.org/pdf/2310.10300v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.IR",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10299v1",
            "title": "Forking Uncertainties: Reliable Prediction and Model Predictive Control\n  with Sequence Models via Conformal Risk Control",
            "updated": "2023-10-16T11:35:41Z",
            "published": "2023-10-16T11:35:41Z",
            "summary": "In many real-world problems, predictions are leveraged to monitor and control\ncyber-physical systems, demanding guarantees on the satisfaction of reliability\nand safety requirements. However, predictions are inherently uncertain, and\nmanaging prediction uncertainty presents significant challenges in environments\ncharacterized by complex dynamics and forking trajectories. In this work, we\nassume access to a pre-designed probabilistic implicit or explicit sequence\nmodel, which may have been obtained using model-based or model-free methods. We\nintroduce probabilistic time series-conformal risk prediction (PTS-CRC), a\nnovel post-hoc calibration procedure that operates on the predictions produced\nby any pre-designed probabilistic forecaster to yield reliable error bars. In\ncontrast to existing art, PTS-CRC produces predictive sets based on an ensemble\nof multiple prototype trajectories sampled from the sequence model, supporting\nthe efficient representation of forking uncertainties. Furthermore, unlike the\nstate of the art, PTS-CRC can satisfy reliability definitions beyond coverage.\nThis property is leveraged to devise a novel model predictive control (MPC)\nframework that addresses open-loop and closed-loop control problems under\ngeneral average constraints on the quality or safety of the control policy. We\nexperimentally validate the performance of PTS-CRC prediction and control by\nstudying a number of use cases in the context of wireless networking. Across\nall the considered tasks, PTS-CRC predictors are shown to provide more\ninformative predictive sets, as well as safe control policies with larger\nreturns.",
            "author": [
                "Matteo Zecchin",
                "Sangwoo Park",
                "Osvaldo Simeone"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10299v1",
                "http://arxiv.org/pdf/2310.10299v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.AI",
                "cs.LG",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10296v1",
            "title": "Soft Demodulator for Symbol-Level Precoding in Coded Multiuser MISO\n  Systems",
            "updated": "2023-10-16T11:32:05Z",
            "published": "2023-10-16T11:32:05Z",
            "summary": "In this paper, we consider symbol-level precoding (SLP) in channel-coded\nmultiuser multi-input single-output (MISO) systems. It is observed that the\nreceived SLP signals do not always follow Gaussian distribution, rendering the\nconventional soft demodulation with the Gaussian assumption unsuitable for the\ncoded SLP systems. It, therefore, calls for novel soft demodulator designs for\nnon-Gaussian distributed SLP signals with accurate log-likelihood ratio (LLR)\ncalculation. To this end, we first investigate the non-Gaussian characteristics\nof both phase-shift keying (PSK) and quadrature amplitude modulation (QAM)\nreceived signals with existing SLP schemes and categorize the signals into two\ndistinct types. The first type exhibits an approximate-Gaussian distribution\nwith the outliers extending along the constructive interference region (CIR).\nIn contrast, the second type follows some distribution that significantly\ndeviates from the Gaussian distribution. To obtain accurate LLR, we propose the\nmodified Gaussian soft demodulator and Gaussian mixture model (GMM) soft\ndemodulators to deal with two types of signals respectively. Subsequently, to\nfurther reduce the computational complexity and pilot overhead, we put forward\na novel neural soft demodulator, named pilot feature extraction network (PFEN),\nleveraging the transformer mechanism in deep learning. Simulation results show\nthat the proposed soft demodulators dramatically improve the throughput of\nexisting SLPs for both PSK and QAM transmission in coded systems.",
            "author": [
                "Yafei Wang",
                "Hongwei Hou",
                "Wenjin Wang",
                "Xinping Yi",
                "Shi Jin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10296v1",
                "http://arxiv.org/pdf/2310.10296v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10280v1",
            "title": "Mimicking the Maestro: Exploring the Efficacy of a Virtual AI Teacher in\n  Fine Motor Skill Acquisition",
            "updated": "2023-10-16T11:11:43Z",
            "published": "2023-10-16T11:11:43Z",
            "summary": "Motor skills, especially fine motor skills like handwriting, play an\nessential role in academic pursuits and everyday life. Traditional methods to\nteach these skills, although effective, can be time-consuming and inconsistent.\nWith the rise of advanced technologies like robotics and artificial\nintelligence, there is increasing interest in automating such teaching\nprocesses using these technologies, via human-robot and human-computer\ninteractions. In this study, we examine the potential of a virtual AI teacher\nin emulating the techniques of human educators for motor skill acquisition. We\nintroduce an AI teacher model that captures the distinct characteristics of\nhuman instructors. Using a Reinforcement Learning environment tailored to mimic\nteacher-learner interactions, we tested our AI model against four guiding\nhypotheses, emphasizing improved learner performance, enhanced rate of skill\nacquisition, and reduced variability in learning outcomes. Our findings,\nvalidated on synthetic learners, revealed significant improvements across all\ntested hypotheses. Notably, our model showcased robustness across different\nlearners and settings and demonstrated adaptability to handwriting. This\nresearch underscores the potential of integrating Reinforcement Learning and\nImitation Learning models with robotics in revolutionizing the teaching of\ncritical motor skills.",
            "author": [
                "Hadar Mulian",
                "Segev Shlomov",
                "Lior Limonad"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10280v1",
                "http://arxiv.org/pdf/2310.10280v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10266v1",
            "title": "Generative Calibration for In-context Learning",
            "updated": "2023-10-16T10:45:02Z",
            "published": "2023-10-16T10:45:02Z",
            "summary": "As one of the most exciting features of large language models (LLMs),\nin-context learning is a mixed blessing. While it allows users to\nfast-prototype a task solver with only a few training examples, the performance\nis generally sensitive to various configurations of the prompt such as the\nchoice or order of the training examples. In this paper, we for the first time\ntheoretically and empirically identify that such a paradox is mainly due to the\nlabel shift of the in-context model to the data distribution, in which LLMs\nshift the label marginal $p(y)$ while having a good label conditional $p(x|y)$.\nWith this understanding, we can simply calibrate the in-context predictive\ndistribution by adjusting the label marginal, which is estimated via\nMonte-Carlo sampling over the in-context model, i.e., generation of LLMs. We\ncall our approach as generative calibration. We conduct exhaustive experiments\nwith 12 text classification tasks and 12 LLMs scaling from 774M to 33B,\ngenerally find that the proposed method greatly and consistently outperforms\nthe ICL as well as state-of-the-art calibration methods, by up to 27% absolute\nin macro-F1. Meanwhile, the proposed method is also stable under different\nprompt configurations.",
            "author": [
                "Zhongtao Jiang",
                "Yuanzhe Zhang",
                "Cao Liu",
                "Jun Zhao",
                "Kang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10266v1",
                "http://arxiv.org/pdf/2310.10266v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10264v1",
            "title": "Towards Open-World Co-Salient Object Detection with Generative\n  Uncertainty-aware Group Selective Exchange-Masking",
            "updated": "2023-10-16T10:40:40Z",
            "published": "2023-10-16T10:40:40Z",
            "summary": "The traditional definition of co-salient object detection (CoSOD) task is to\nsegment the common salient objects in a group of relevant images. This\ndefinition is based on an assumption of group consensus consistency that is not\nalways reasonable in the open-world setting, which results in robustness issue\nin the model when dealing with irrelevant images in the inputting image group\nunder the open-word scenarios. To tackle this problem, we introduce a group\nselective exchange-masking (GSEM) approach for enhancing the robustness of the\nCoSOD model. GSEM takes two groups of images as input, each containing\ndifferent types of salient objects. Based on the mixed metric we designed, GSEM\nselects a subset of images from each group using a novel learning-based\nstrategy, then the selected images are exchanged. To simultaneously consider\nthe uncertainty introduced by irrelevant images and the consensus features of\nthe remaining relevant images in the group, we designed a latent variable\ngenerator branch and CoSOD transformer branch. The former is composed of a\nvector quantised-variational autoencoder to generate stochastic global\nvariables that model uncertainty. The latter is designed to capture\ncorrelation-based local features that include group consensus. Finally, the\noutputs of the two branches are merged and passed to a transformer-based\ndecoder to generate robust predictions. Taking into account that there are\ncurrently no benchmark datasets specifically designed for open-world scenarios,\nwe constructed three open-world benchmark datasets, namely OWCoSal, OWCoSOD,\nand OWCoCA, based on existing datasets. By breaking the group-consistency\nassumption, these datasets provide effective simulations of real-world\nscenarios and can better evaluate the robustness and practicality of models.",
            "author": [
                "Yang Wu",
                "Shenglong Hu",
                "Huihui Song",
                "Kaihua Zhang",
                "Bo Liu",
                "Dong Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10264v1",
                "http://arxiv.org/pdf/2310.10264v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10262v1",
            "title": "Enhancing Interpretability using Human Similarity Judgements to Prune\n  Word Embeddings",
            "updated": "2023-10-16T10:38:49Z",
            "published": "2023-10-16T10:38:49Z",
            "summary": "Interpretability methods in NLP aim to provide insights into the semantics\nunderlying specific system architectures. Focusing on word embeddings, we\npresent a supervised-learning method that, for a given domain (e.g., sports,\nprofessions), identifies a subset of model features that strongly improve\nprediction of human similarity judgments. We show this method keeps only 20-40%\nof the original embeddings, for 8 independent semantic domains, and that it\nretains different feature sets across domains. We then present two approaches\nfor interpreting the semantics of the retained features. The first obtains the\nscores of the domain words (co-hyponyms) on the first principal component of\nthe retained embeddings, and extracts terms whose co-occurrence with the\nco-hyponyms tracks these scores' profile. This analysis reveals that humans\ndifferentiate e.g. sports based on how gender-inclusive and international they\nare. The second approach uses the retained sets as variables in a probing task\nthat predicts values along 65 semantically annotated dimensions for a dataset\nof 535 words. The features retained for professions are best at predicting\ncognitive, emotional and social dimensions, whereas features retained for\nfruits or vegetables best predict the gustation (taste) dimension. We discuss\nimplications for alignment between AI systems and human knowledge.",
            "author": [
                "Natalia Flechas Manrique",
                "Wanqian Bao",
                "Aurelie Herbelot",
                "Uri Hasson"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10262v1",
                "http://arxiv.org/pdf/2310.10262v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10260v1",
            "title": "Prediction of Arabic Legal Rulings using Large Language Models",
            "updated": "2023-10-16T10:37:35Z",
            "published": "2023-10-16T10:37:35Z",
            "summary": "In the intricate field of legal studies, the analysis of court decisions is a\ncornerstone for the effective functioning of the judicial system. The ability\nto predict court outcomes helps judges during the decision-making process and\nequips lawyers with invaluable insights, enhancing their strategic approaches\nto cases. Despite its significance, the domain of Arabic court analysis remains\nunder-explored. This paper pioneers a comprehensive predictive analysis of\nArabic court decisions on a dataset of 10,813 commercial court real cases,\nleveraging the advanced capabilities of the current state-of-the-art large\nlanguage models. Through a systematic exploration, we evaluate three prevalent\nfoundational models (LLaMA-7b, JAIS-13b, and GPT3.5-turbo) and three training\nparadigms: zero-shot, one-shot, and tailored fine-tuning. Besides, we assess\nthe benefit of summarizing and/or translating the original Arabic input texts.\nThis leads to a spectrum of 14 model variants, for which we offer a granular\nperformance assessment with a series of different metrics (human assessment,\nGPT evaluation, ROUGE, and BLEU scores). We show that all variants of LLaMA\nmodels yield limited performance, whereas GPT-3.5-based models outperform all\nother models by a wide margin, surpassing the average score of the dedicated\nArabic-centric JAIS model by 50%. Furthermore, we show that all scores except\nhuman evaluation are inconsistent and unreliable for assessing the performance\nof large language models on court decision predictions. This study paves the\nway for future research, bridging the gap between computational linguistics and\nArabic legal analytics.",
            "author": [
                "Adel Ammar",
                "Anis Koubaa",
                "Bilel Benjdira",
                "Omar Najar",
                "Serry Sibaee"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10260v1",
                "http://arxiv.org/pdf/2310.10260v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10259v1",
            "title": "Leveraging heterogeneous spillover effects in maximizing contextual\n  bandit rewards",
            "updated": "2023-10-16T10:34:41Z",
            "published": "2023-10-16T10:34:41Z",
            "summary": "Recommender systems relying on contextual multi-armed bandits continuously\nimprove relevant item recommendations by taking into account the contextual\ninformation. The objective of these bandit algorithms is to learn the best arm\n(i.e., best item to recommend) for each user and thus maximize the cumulative\nrewards from user engagement with the recommendations. However, current\napproaches ignore potential spillover between interacting users, where the\naction of one user can impact the actions and rewards of other users. Moreover,\nspillover may vary for different people based on their preferences and the\ncloseness of ties to other users. This leads to heterogeneity in the spillover\neffects, i.e., the extent to which the action of one user can impact the action\nof another. Here, we propose a framework that allows contextual multi-armed\nbandits to account for such heterogeneous spillovers when choosing the best arm\nfor each user. By experimenting on several real-world datasets using prominent\nlinear and non-linear contextual bandit algorithms, we observe that our\nproposed method leads to significantly higher rewards than existing solutions\nthat ignore spillover.",
            "author": [
                "Ahmed Sayeed Faruk",
                "Elena Zheleva"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10259v1",
                "http://arxiv.org/pdf/2310.10259v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10255v1",
            "title": "Charged particle reconstruction for future high energy colliders with\n  Quantum Approximate Optimization Algorithm",
            "updated": "2023-10-16T10:26:37Z",
            "published": "2023-10-16T10:26:37Z",
            "summary": "Usage of cutting-edge artificial intelligence will be the baseline at future\nhigh energy colliders such as the High Luminosity Large Hadron Collider, to\ncope with the enormously increasing demand of the computing resources. The\nrapid development of quantum machine learning could bring in further\nparadigm-shifting improvement to this challenge. One of the two highest\nCPU-consuming components, the charged particle reconstruction, the so-called\ntrack reconstruction, can be considered as a quadratic unconstrained binary\noptimization (QUBO) problem. The Quantum Approximate Optimization Algorithm\n(QAOA) is one of the most promising algorithms to solve such combinatorial\nproblems and to seek for a quantum advantage in the era of the Noisy\nIntermediate-Scale Quantum computers. It is found that the QAOA shows promising\nperformance and demonstrated itself as one of the candidates for the track\nreconstruction using quantum computers.",
            "author": [
                "Hideki Okawa"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10255v1",
                "http://arxiv.org/pdf/2310.10255v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10254v1",
            "title": "Towards a dissipative quantum classifier",
            "updated": "2023-10-16T10:26:24Z",
            "published": "2023-10-16T10:26:24Z",
            "summary": "In this paper, we propose a novel quantum classifier utilizing dissipative\nengineering. Unlike standard quantum circuit models, the classifier consists of\na central spin-qubit model. By subjecting the auxiliary qubits to carefully\ntailored strong dissipations, we establish a one-to-one mapping between\nclassical data and dissipative modes. This mapping enables the encoding of\nclassical data within a decoherence-free subspace, where the central qubit\nundergoes evolution. The dynamics of the central qubit are governed by an\neffective Lindblad master equation, resulting in relaxation towards a steady\nstate. We first demonstrate the capability of our model to prepare arbitrary\nsingle-qubit states by training the inter-coupling of the system and the\nexternal dissipations. By elucidating the underlying classification rule, we\nsubsequently derive a quantum classifier. Leveraging a training set with\nlabeled data, we train the dissipative central spin-qubit system to perform\nspecific classification tasks akin to classical neural networks. Our study\nilluminates the untapped potential of the dissipative system for efficient and\neffective classification tasks in the realm of quantum machine learning.",
            "author": [
                "He Wang",
                "Chuanbo Liu",
                "Jin Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10254v1",
                "http://arxiv.org/pdf/2310.10254v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10250v1",
            "title": "Leveraging Topological Maps in Deep Reinforcement Learning for\n  Multi-Object Navigation",
            "updated": "2023-10-16T10:19:45Z",
            "published": "2023-10-16T10:19:45Z",
            "summary": "This work addresses the challenge of navigating expansive spaces with sparse\nrewards through Reinforcement Learning (RL). Using topological maps, we elevate\nelementary actions to object-oriented macro actions, enabling a simple Deep\nQ-Network (DQN) agent to solve otherwise practically impossible environments.",
            "author": [
                "Simon Hakenes",
                "Tobias Glasmachers"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10250v1",
                "http://arxiv.org/pdf/2310.10250v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10245v1",
            "title": "Mask wearing object detection algorithm based on improved YOLOv5",
            "updated": "2023-10-16T10:06:42Z",
            "published": "2023-10-16T10:06:42Z",
            "summary": "Wearing a mask is one of the important measures to prevent infectious\ndiseases. However, it is difficult to detect people's mask-wearing situation in\npublic places with high traffic flow. To address the above problem, this paper\nproposes a mask-wearing face detection model based on YOLOv5l. Firstly,\nMulti-Head Attentional Self-Convolution not only improves the convergence speed\nof the model but also enhances the accuracy of the model detection. Secondly,\nthe introduction of Swin Transformer Block is able to extract more useful\nfeature information, enhance the detection ability of small targets, and\nimprove the overall accuracy of the model. Our designed I-CBAM module can\nimprove target detection accuracy. In addition, using enhanced feature fusion\nenables the model to better adapt to object detection tasks of different\nscales. In the experimentation on the MASK dataset, the results show that the\nmodel proposed in this paper achieved a 1.1% improvement in mAP(0.5) and a 1.3%\nimprovement in mAP(0.5:0.95) compared to the YOLOv5l model. Our proposed method\nsignificantly enhances the detection capability of mask-wearing.",
            "author": [
                "Peng Wen",
                "Junhu Zhang",
                "Haitao Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10245v1",
                "http://arxiv.org/pdf/2310.10245v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10240v1",
            "title": "The Mixtures and the Neural Critics: On the Pointwise Mutual Information\n  Profiles of Fine Distributions",
            "updated": "2023-10-16T10:02:24Z",
            "published": "2023-10-16T10:02:24Z",
            "summary": "Mutual information quantifies the dependence between two random variables and\nremains invariant under diffeomorphisms. In this paper, we explore the\npointwise mutual information profile, an extension of mutual information that\nmaintains this invariance. We analytically describe the profiles of\nmultivariate normal distributions and introduce the family of fine\ndistributions, for which the profile can be accurately approximated using Monte\nCarlo methods. We then show how fine distributions can be used to study the\nlimitations of existing mutual information estimators, investigate the behavior\nof neural critics used in variational estimators, and understand the effect of\nexperimental outliers on mutual information estimation. Finally, we show how\nfine distributions can be used to obtain model-based Bayesian estimates of\nmutual information, suitable for problems with available domain expertise in\nwhich uncertainty quantification is necessary.",
            "author": [
                "Pawe\u0142 Czy\u017c",
                "Frederic Grabowski",
                "Julia E. Vogt",
                "Niko Beerenwinkel",
                "Alexander Marx"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10240v1",
                "http://arxiv.org/pdf/2310.10240v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.IT",
                "cs.LG",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10239v1",
            "title": "Structural transfer learning of non-Gaussian DAG",
            "updated": "2023-10-16T10:01:27Z",
            "published": "2023-10-16T10:01:27Z",
            "summary": "Directed acyclic graph (DAG) has been widely employed to represent\ndirectional relationships among a set of collected nodes. Yet, the available\ndata in one single study is often limited for accurate DAG reconstruction,\nwhereas heterogeneous data may be collected from multiple relevant studies. It\nremains an open question how to pool the heterogeneous data together for better\nDAG structure reconstruction in the target study. In this paper, we first\nintroduce a novel set of structural similarity measures for DAG and then\npresent a transfer DAG learning framework by effectively leveraging information\nfrom auxiliary DAGs of different levels of similarities. Our theoretical\nanalysis shows substantial improvement in terms of DAG reconstruction in the\ntarget study, even when no auxiliary DAG is overall similar to the target DAG,\nwhich is in sharp contrast to most existing transfer learning methods. The\nadvantage of the proposed transfer DAG learning is also supported by extensive\nnumerical experiments on both synthetic data and multi-site brain functional\nconnectivity network data.",
            "author": [
                "Mingyang Ren",
                "Xin He",
                "Junhui Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10239v1",
                "http://arxiv.org/pdf/2310.10239v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10237v1",
            "title": "SGOOD: Substructure-enhanced Graph-Level Out-of-Distribution Detection",
            "updated": "2023-10-16T09:51:24Z",
            "published": "2023-10-16T09:51:24Z",
            "summary": "Graph-level representation learning is important in a wide range of\napplications. However, existing graph-level models are generally built on\ni.i.d. assumption for both training and testing graphs, which is not realistic\nin an open world, where models can encounter out-of-distribution (OOD) testing\ngraphs that are from different distributions unknown during training. A\ntrustworthy model should not only produce accurate predictions for\nin-distribution (ID) data, but also detect OOD graphs to avoid unreliable\nprediction. In this paper, we present SGOOD, a novel graph-level OOD detection\nframework. We find that substructure differences commonly exist between ID and\nOOD graphs. Hence, SGOOD explicitly utilizes substructures to learn powerful\nrepresentations to achieve superior performance. Specifically, we build a super\ngraph of substructures for every graph, and design a two-level graph encoding\npipeline that works on both original graphs and super graphs to obtain\nsubstructure-enhanced graph representations. To further distinguish ID and OOD\ngraphs, we develop three graph augmentation techniques that preserve\nsubstructures and increase expressiveness. Extensive experiments against 10\ncompetitors on numerous graph datasets demonstrate the superiority of SGOOD,\noften surpassing existing methods by a significant margin. The code is\navailable at https://anonymous.4open.science/r/SGOOD-0958.",
            "author": [
                "Zhihao Ding",
                "Jieming Shi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10237v1",
                "http://arxiv.org/pdf/2310.10237v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10224v1",
            "title": "Generalizing Medical Image Representations via Quaternion Wavelet\n  Networks",
            "updated": "2023-10-16T09:34:06Z",
            "published": "2023-10-16T09:34:06Z",
            "summary": "Neural network generalizability is becoming a broad research field due to the\nincreasing availability of datasets from different sources and for various\ntasks. This issue is even wider when processing medical data, where a lack of\nmethodological standards causes large variations being provided by different\nimaging centers or acquired with various devices and cofactors. To overcome\nthese limitations, we introduce a novel, generalizable, data- and task-agnostic\nframework able to extract salient features from medical images. The proposed\nquaternion wavelet network (QUAVE) can be easily integrated with any\npre-existing medical image analysis or synthesis task, and it can be involved\nwith real, quaternion, or hypercomplex-valued models, generalizing their\nadoption to single-channel data. QUAVE first extracts different sub-bands\nthrough the quaternion wavelet transform, resulting in both\nlow-frequency/approximation bands and high-frequency/fine-grained features.\nThen, it weighs the most representative set of sub-bands to be involved as\ninput to any other neural model for image processing, replacing standard data\nsamples. We conduct an extensive experimental evaluation comprising different\ndatasets, diverse image analysis, and synthesis tasks including reconstruction,\nsegmentation, and modality translation. We also evaluate QUAVE in combination\nwith both real and quaternion-valued models. Results demonstrate the\neffectiveness and the generalizability of the proposed framework that improves\nnetwork performance while being flexible to be adopted in manifold scenarios.",
            "author": [
                "Luigi Sigillo",
                "Eleonora Grassucci",
                "Aurelio Uncini",
                "Danilo Comminiello"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10224v1",
                "http://arxiv.org/pdf/2310.10224v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10219v1",
            "title": "Using Global Land Cover Product as Prompt for Cropland Mapping via\n  Visual Foundation Model",
            "updated": "2023-10-16T09:29:52Z",
            "published": "2023-10-16T09:29:52Z",
            "summary": "Data-driven deep learning methods have shown great potential in cropland\nmapping. However, due to multiple factors such as attributes of cropland\n(topography, climate, crop type) and imaging conditions (viewing angle,\nillumination, scale), croplands under different scenes demonstrate a great\ndomain gap. This makes it difficult for models trained in the specific scenes\nto directly generalize to other scenes. A common way to handle this problem is\nthrough the \"Pretrain+Fine-tuning\" paradigm. Unfortunately, considering the\nvariety of features of cropland that are affected by multiple factors, it is\nhardly to handle the complex domain gap between pre-trained data and target\ndata using only sparse fine-tuned samples as general constraints. Moreover, as\nthe number of model parameters grows, fine-tuning is no longer an easy and\nlow-cost task. With the emergence of prompt learning via visual foundation\nmodels, the \"Pretrain+Prompting\" paradigm redesigns the optimization target by\nintroducing individual prompts for each single sample. This simplifies the\ndomain adaption from generic to specific scenes during model reasoning\nprocesses. Therefore, we introduce the \"Pretrain+Prompting\" paradigm to\ninterpreting cropland scenes and design the auto-prompting (APT) method based\non freely available global land cover product. It can achieve a fine-grained\nadaptation process from generic scenes to specialized cropland scenes without\nintroducing additional label costs. To our best knowledge, this work pioneers\nthe exploration of the domain adaption problems for cropland mapping under\nprompt learning perspectives. Our experiments using two sub-meter cropland\ndatasets from southern and northern China demonstrated that the proposed method\nvia visual foundation models outperforms traditional supervised learning and\nfine-tuning approaches in the field of remote sensing.",
            "author": [
                "Chao Tao",
                "Aoran Hu",
                "Rong Xiao",
                "Haifeng Li",
                "Yuze Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10219v1",
                "http://arxiv.org/pdf/2310.10219v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10211v1",
            "title": "GEVO-ML: Optimizing Machine Learning Code with Evolutionary Computation",
            "updated": "2023-10-16T09:24:20Z",
            "published": "2023-10-16T09:24:20Z",
            "summary": "Parallel accelerators, such as GPUs, are key enablers for large-scale Machine\nLearning (ML) applications. However, ML model developers often lack detailed\nknowledge of the underlying system architectures, while system programmers\nusually do not have a high-level understanding of the ML model that runs on the\nspecific system. To mitigate this gap between two relevant aspects of domain\nknowledge, this paper proposes GEVO-ML, a tool for automatically discovering\noptimization opportunities and tuning the performance of ML kernels, where the\nmodel and training/prediction processes are uniformly represented in a single\nintermediate language, the Multiple-Layer Intermediate Representation (MLIR).\nGEVO-ML uses multi-objective evolutionary search to find edits (mutations) to\nMLIR code that ultimately runs on GPUs, improving performance on desired\ncriteria while retaining required functionality.\n  We demonstrate GEVO-ML on two different ML workloads for both model training\nand prediction. GEVO-ML finds significant Pareto improvements for these models,\nachieving 90.43% performance improvement when model accuracy is relaxed by 2%,\nfrom 91.2% to 89.3%. For the training workloads, GEVO-ML finds a 4.88%\nimprovement in model accuracy, from 91% to 96%, without sacrificing training or\ntesting speed. Our analysis of key GEVO-ML mutations reveals diverse code\nmodifications, while might be foreign to human developers, achieving similar\neffects with how human developers improve model design, for example, by\nchanging learning rates or pruning non-essential layer parameters.",
            "author": [
                "Jhe-Yu Liou",
                "Stephanie Forrest",
                "Carole-Jean Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10211v1",
                "http://arxiv.org/pdf/2310.10211v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10209v1",
            "title": "Self-supervised Fetal MRI 3D Reconstruction Based on Radiation Diffusion\n  Generation Model",
            "updated": "2023-10-16T09:22:00Z",
            "published": "2023-10-16T09:22:00Z",
            "summary": "Although the use of multiple stacks can handle slice-to-volume motion\ncorrection and artifact removal problems, there are still several problems: 1)\nThe slice-to-volume method usually uses slices as input, which cannot solve the\nproblem of uniform intensity distribution and complementarity in regions of\ndifferent fetal MRI stacks; 2) The integrity of 3D space is not considered,\nwhich adversely affects the discrimination and generation of globally\nconsistent information in fetal MRI; 3) Fetal MRI with severe motion artifacts\nin the real-world cannot achieve high-quality super-resolution reconstruction.\nTo address these issues, we propose a novel fetal brain MRI high-quality volume\nreconstruction method, called the Radiation Diffusion Generation Model (RDGM).\nIt is a self-supervised generation method, which incorporates the idea of\nNeural Radiation Field (NeRF) based on the coordinate generation and diffusion\nmodel based on super-resolution generation. To solve regional intensity\nheterogeneity in different directions, we use a pre-trained transformer model\nfor slice registration, and then, a new regionally Consistent Implicit Neural\nRepresentation (CINR) network sub-module is proposed. CINR can generate the\ninitial volume by combining a coordinate association map of two different\ncoordinate mapping spaces. To enhance volume global consistency and\ndiscrimination, we introduce the Volume Diffusion Super-resolution Generation\n(VDSG) mechanism. The global intensity discriminant generation from\nvolume-to-volume is carried out using the idea of diffusion generation, and\nCINR becomes the deviation intensity generation network of the volume-to-volume\ndiffusion model. Finally, the experimental results on real-world fetal brain\nMRI stacks demonstrate the state-of-the-art performance of our method.",
            "author": [
                "Junpeng Tan",
                "Xin Zhang",
                "Yao Lv",
                "Xiangmin Xu",
                "Gang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10209v1",
                "http://arxiv.org/pdf/2310.10209v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10207v1",
            "title": "Bongard-OpenWorld: Few-Shot Reasoning for Free-form Visual Concepts in\n  the Real World",
            "updated": "2023-10-16T09:19:18Z",
            "published": "2023-10-16T09:19:18Z",
            "summary": "We introduce Bongard-OpenWorld, a new benchmark for evaluating real-world\nfew-shot reasoning for machine vision. It originates from the classical Bongard\nProblems (BPs): Given two sets of images (positive and negative), the model\nneeds to identify the set that query images belong to by inducing the visual\nconcepts, which is exclusively depicted by images from the positive set. Our\nbenchmark inherits the few-shot concept induction of the original BPs while\nadding the two novel layers of challenge: 1) open-world free-form concepts, as\nthe visual concepts in Bongard-OpenWorld are unique compositions of terms from\nan open vocabulary, ranging from object categories to abstract visual\nattributes and commonsense factual knowledge; 2) real-world images, as opposed\nto the synthetic diagrams used by many counterparts. In our exploration,\nBongard-OpenWorld already imposes a significant challenge to current few-shot\nreasoning algorithms. We further investigate to which extent the recently\nintroduced Large Language Models (LLMs) and Vision-Language Models (VLMs) can\nsolve our task, by directly probing VLMs, and combining VLMs and LLMs in an\ninteractive reasoning scheme. We even designed a neuro-symbolic reasoning\napproach that reconciles LLMs & VLMs with logical reasoning to emulate the\nhuman problem-solving process for Bongard Problems. However, none of these\napproaches manage to close the human-machine gap, as the best learner achieves\n64% accuracy while human participants easily reach 91%. We hope\nBongard-OpenWorld can help us better understand the limitations of current\nvisual intelligence and facilitate future research on visual agents with\nstronger few-shot visual reasoning capabilities.",
            "author": [
                "Rujie Wu",
                "Xiaojian Ma",
                "Qing Li",
                "Wei Wang",
                "Zhenliang Zhang",
                "Song-Chun Zhu",
                "Yizhou Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10207v1",
                "http://arxiv.org/pdf/2310.10207v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10204v1",
            "title": "Hierarchical MTC User Activity Detection and Channel Estimation with\n  Unknown Spatial Covariance",
            "updated": "2023-10-16T09:17:14Z",
            "published": "2023-10-16T09:17:14Z",
            "summary": "This paper addresses the joint user identification and channel estimation\n(JUICE) problem in machine-type communications under the practical spatially\ncorrelated channels model with unknown covariance matrices. Furthermore, we\nconsider an MTC network with hierarchical user activity patterns following an\nevent-triggered traffic mode. Therein the users are distributed over clusters\nwith a structured sporadic activity behaviour that exhibits both cluster-level\nand intra-cluster sparsity patterns. To solve the JUICE problem, we first\nleverage the concept of strong priors and propose a\nhierarchical-sparsity-inducing spike-and-slab prior to model the structured\nsparse activity pattern. Subsequently, we derive a Bayesian inference scheme by\ncoupling the expectation propagation (EP) algorithm with the expectation\nmaximization (EM) framework. Second, we reformulate the JUICE as a maximum a\nposteriori (MAP) estimation problem and propose a computationally-efficient\nsolution based on the alternating direction method of multipliers (ADMM). More\nprecisely, we relax the strong spike-and-slab prior with a\ncluster-sparsity-promoting prior based on the long-sum penalty. We then derive\nan ADMM algorithm that solves the MAP problem through a sequence of closed-form\nupdates. Numerical results highlight the significant performance significant\ngains obtained by the proposed algorithms, as well as their robustness against\nvarious assumptions on the users sparse activity behaviour.",
            "author": [
                "Hamza Djelouat",
                "Mikko J. Sillanp\u00e4\u00e4",
                "Markus Leinonen",
                "Markku Juntti"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10204v1",
                "http://arxiv.org/pdf/2310.10204v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10203v1",
            "title": "Interpretable Predictive Models to Understand Risk Factors for Maternal\n  and Fetal Outcomes",
            "updated": "2023-10-16T09:17:10Z",
            "published": "2023-10-16T09:17:10Z",
            "summary": "Although most pregnancies result in a good outcome, complications are not\nuncommon and can be associated with serious implications for mothers and\nbabies. Predictive modeling has the potential to improve outcomes through\nbetter understanding of risk factors, heightened surveillance for high risk\npatients, and more timely and appropriate interventions, thereby helping\nobstetricians deliver better care. We identify and study the most important\nrisk factors for four types of pregnancy complications: (i) severe maternal\nmorbidity, (ii) shoulder dystocia, (iii) preterm preeclampsia, and (iv)\nantepartum stillbirth. We use an Explainable Boosting Machine (EBM), a\nhigh-accuracy glass-box learning method, for prediction and identification of\nimportant risk factors. We undertake external validation and perform an\nextensive robustness analysis of the EBM models. EBMs match the accuracy of\nother black-box ML methods such as deep neural networks and random forests, and\noutperform logistic regression, while being more interpretable. EBMs prove to\nbe robust. The interpretability of the EBM models reveals surprising insights\ninto the features contributing to risk (e.g. maternal height is the second most\nimportant feature for shoulder dystocia) and may have potential for clinical\napplication in the prediction and prevention of serious complications in\npregnancy.",
            "author": [
                "Tomas M. Bosschieter",
                "Zifei Xu",
                "Hui Lan",
                "Benjamin J. Lengerich",
                "Harsha Nori",
                "Ian Painter",
                "Vivienne Souter",
                "Rich Caruana"
            ],
            "link": [
                "http://dx.doi.org/10.1007/s41666-023-00151-4",
                "http://arxiv.org/abs/2310.10203v1",
                "http://arxiv.org/pdf/2310.10203v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10198v2",
            "title": "MoConVQ: Unified Physics-Based Motion Control via Scalable Discrete\n  Representations",
            "updated": "2023-10-17T04:53:30Z",
            "published": "2023-10-16T09:09:02Z",
            "summary": "In this work, we present MoConVQ, a novel unified framework for physics-based\nmotion control leveraging scalable discrete representations. Building upon\nvector quantized variational autoencoders (VQ-VAE) and model-based\nreinforcement learning, our approach effectively learns motion embeddings from\na large, unstructured dataset spanning tens of hours of motion examples. The\nresultant motion representation not only captures diverse motion skills but\nalso offers a robust and intuitive interface for various applications. We\ndemonstrate the versatility of MoConVQ through several applications: universal\ntracking control from various motion sources, interactive character control\nwith latent motion representations using supervised learning, physics-based\nmotion generation from natural language descriptions using the GPT framework,\nand, most interestingly, seamless integration with large language models (LLMs)\nwith in-context learning to tackle complex and abstract tasks.",
            "author": [
                "Heyuan Yao",
                "Zhenhua Song",
                "Yuyang Zhou",
                "Tenglong Ao",
                "Baoquan Chen",
                "Libin Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10198v2",
                "http://arxiv.org/pdf/2310.10198v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10196v2",
            "title": "Large Models for Time Series and Spatio-Temporal Data: A Survey and\n  Outlook",
            "updated": "2023-10-20T12:17:37Z",
            "published": "2023-10-16T09:06:00Z",
            "summary": "Temporal data, notably time series and spatio-temporal data, are prevalent in\nreal-world applications. They capture dynamic system measurements and are\nproduced in vast quantities by both physical and virtual sensors. Analyzing\nthese data types is vital to harnessing the rich information they encompass and\nthus benefits a wide range of downstream tasks. Recent advances in large\nlanguage and other foundational models have spurred increased use of these\nmodels in time series and spatio-temporal data mining. Such methodologies not\nonly enable enhanced pattern recognition and reasoning across diverse domains\nbut also lay the groundwork for artificial general intelligence capable of\ncomprehending and processing common temporal data. In this survey, we offer a\ncomprehensive and up-to-date review of large models tailored (or adapted) for\ntime series and spatio-temporal data, spanning four key facets: data types,\nmodel categories, model scopes, and application areas/tasks. Our objective is\nto equip practitioners with the knowledge to develop applications and further\nresearch in this underexplored domain. We primarily categorize the existing\nliterature into two major clusters: large models for time series analysis\n(LM4TS) and spatio-temporal data mining (LM4STD). On this basis, we further\nclassify research based on model scopes (i.e., general vs. domain-specific) and\napplication areas/tasks. We also provide a comprehensive collection of\npertinent resources, including datasets, model assets, and useful tools,\ncategorized by mainstream applications. This survey coalesces the latest\nstrides in large model-centric research on time series and spatio-temporal\ndata, underscoring the solid foundations, current advances, practical\napplications, abundant resources, and future research opportunities.",
            "author": [
                "Ming Jin",
                "Qingsong Wen",
                "Yuxuan Liang",
                "Chaoli Zhang",
                "Siqiao Xue",
                "Xue Wang",
                "James Zhang",
                "Yi Wang",
                "Haifeng Chen",
                "Xiaoli Li",
                "Shirui Pan",
                "Vincent S. Tseng",
                "Yu Zheng",
                "Lei Chen",
                "Hui Xiong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10196v2",
                "http://arxiv.org/pdf/2310.10196v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10195v2",
            "title": "AdaLomo: Low-memory Optimization with Adaptive Learning Rate",
            "updated": "2023-10-22T13:37:33Z",
            "published": "2023-10-16T09:04:28Z",
            "summary": "Large language models have achieved remarkable success, but their extensive\nparameter size necessitates substantial memory for training, thereby setting a\nhigh threshold. While the recently proposed low-memory optimization (LOMO)\nreduces memory footprint, its optimization technique, akin to stochastic\ngradient descent, is sensitive to hyper-parameters and exhibits suboptimal\nconvergence, failing to match the performance of the prevailing optimizer for\nlarge language models, AdamW. Through empirical analysis of the Adam optimizer,\nwe found that, compared to momentum, the adaptive learning rate is more\ncritical for bridging the gap. Building on this insight, we introduce the\nlow-memory optimization with adaptive learning rate (AdaLomo), which offers an\nadaptive learning rate for each parameter. To maintain memory efficiency, we\nemploy non-negative matrix factorization for the second-order moment estimation\nin the optimizer state. Additionally, we suggest the use of a grouped update\nnormalization to stabilize convergence. Our experiments with instruction-tuning\nand further pre-training demonstrate that AdaLomo achieves results on par with\nAdamW, while significantly reducing memory requirements, thereby lowering the\nhardware barrier to training large language models.",
            "author": [
                "Kai Lv",
                "Hang Yan",
                "Qipeng Guo",
                "Haijun Lv",
                "Xipeng Qiu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10195v2",
                "http://arxiv.org/pdf/2310.10195v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10191v4",
            "title": "VIBE: Topic-Driven Temporal Adaptation for Twitter Classification",
            "updated": "2023-11-15T12:41:57Z",
            "published": "2023-10-16T08:53:57Z",
            "summary": "Language features are evolving in real-world social media, resulting in the\ndeteriorating performance of text classification in dynamics. To address this\nchallenge, we study temporal adaptation, where models trained on past data are\ntested in the future. Most prior work focused on continued pretraining or\nknowledge updating, which may compromise their performance on noisy social\nmedia data. To tackle this issue, we reflect feature change via modeling latent\ntopic evolution and propose a novel model, VIBE: Variational Information\nBottleneck for Evolutions. Concretely, we first employ two Information\nBottleneck (IB) regularizers to distinguish past and future topics. Then, the\ndistinguished topics work as adaptive features via multi-task training with\ntimestamp and class label prediction. In adaptive learning, VIBE utilizes\nretrieved unlabeled data from online streams created posterior to training data\ntime. Substantial Twitter experiments on three classification tasks show that\nour model, with only 3% of data, significantly outperforms previous\nstate-of-the-art continued-pretraining methods.",
            "author": [
                "Yuji Zhang",
                "Jing Li",
                "Wenjie Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10191v4",
                "http://arxiv.org/pdf/2310.10191v4"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10187v1",
            "title": "An Interpretable Deep-Learning Framework for Predicting Hospital\n  Readmissions From Electronic Health Records",
            "updated": "2023-10-16T08:48:52Z",
            "published": "2023-10-16T08:48:52Z",
            "summary": "With the increasing availability of patients' data, modern medicine is\nshifting towards prospective healthcare. Electronic health records contain a\nvariety of information useful for clinical patient description and can be\nexploited for the construction of predictive models, given that similar medical\nhistories will likely lead to similar progressions. One example is unplanned\nhospital readmission prediction, an essential task for reducing hospital costs\nand improving patient health. Despite predictive models showing very good\nperformances especially with deep-learning models, they are often criticized\nfor the poor interpretability of their results, a fundamental characteristic in\nthe medical field, where incorrect predictions might have serious consequences\nfor the patient health. In this paper we propose a novel, interpretable\ndeep-learning framework for predicting unplanned hospital readmissions,\nsupported by NLP findings on word embeddings and by neural-network models\n(ConvLSTM) for better handling temporal data. We validate our system on the two\npredictive tasks of hospital readmission within 30 and 180 days, using\nreal-world data. In addition, we introduce and test a model-dependent technique\nto make the representation of results easily interpretable by the medical\nstaff. Our solution achieves better performances compared to traditional models\nbased on machine learning, while providing at the same time more interpretable\nresults.",
            "author": [
                "Fabio Azzalini",
                "Tommaso Dolci",
                "Marco Vagaggini"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10187v1",
                "http://arxiv.org/pdf/2310.10187v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10186v1",
            "title": "High-resolution spectroscopy of the $\u03bd_3$ antisymmetric C-H stretch of\n  C$_2$H$_2^+$ using leak-out action spectroscopy",
            "updated": "2023-10-16T08:48:23Z",
            "published": "2023-10-16T08:48:23Z",
            "summary": "The antisymmetric C-H stretching vibration $\\nu_3$ ($^2\\Pi$ $\\leftarrow$\n$^2\\Pi$) of ionized acetylene, C$_2$H$_2^+$, has been revisited using a\ncryogenic 22-pole ion trap machine. Two action spectroscopic techniques, the\nnovel leak-out spectroscopy (LOS) method and the more established laser-induced\nreactions (LIR) method, are applied and compared. Mass selectivity and\ncryogenic temperatures down to 4~K enabled the observation of uncontaminated\nspectra in which the $\\Lambda$-doubling components of this open-shell molecule\nare mostly well resolved, leading to a slight refinement of the spectroscopic\nparameters.",
            "author": [
                "Stephan Schlemmer",
                "Eline Plaar",
                "Divita Gupta",
                "Weslley Guilherme Dias de Paiva Silva",
                "Thomas Salomon",
                "Oskar Asvany"
            ],
            "link": [
                "http://dx.doi.org/10.1080/00268976.2023.2241567",
                "http://arxiv.org/abs/2310.10186v1",
                "http://arxiv.org/pdf/2310.10186v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10184v1",
            "title": "Continual Generalized Intent Discovery: Marching Towards Dynamic and\n  Open-world Intent Recognition",
            "updated": "2023-10-16T08:48:07Z",
            "published": "2023-10-16T08:48:07Z",
            "summary": "In a practical dialogue system, users may input out-of-domain (OOD) queries.\nThe Generalized Intent Discovery (GID) task aims to discover OOD intents from\nOOD queries and extend them to the in-domain (IND) classifier. However, GID\nonly considers one stage of OOD learning, and needs to utilize the data in all\nprevious stages for joint training, which limits its wide application in\nreality. In this paper, we introduce a new task, Continual Generalized Intent\nDiscovery (CGID), which aims to continuously and automatically discover OOD\nintents from dynamic OOD data streams and then incrementally add them to the\nclassifier with almost no previous data, thus moving towards dynamic intent\nrecognition in an open world. Next, we propose a method called Prototype-guided\nLearning with Replay and Distillation (PLRD) for CGID, which bootstraps new\nintent discovery through class prototypes and balances new and old intents\nthrough data replay and feature distillation. Finally, we conduct detailed\nexperiments and analysis to verify the effectiveness of PLRD and understand the\nkey challenges of CGID for future research.",
            "author": [
                "Xiaoshuai Song",
                "Yutao Mou",
                "Keqing He",
                "Yueyan Qiu",
                "Pei Wang",
                "Weiran Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10184v1",
                "http://arxiv.org/pdf/2310.10184v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10177v1",
            "title": "Hypergraph Echo State Network",
            "updated": "2023-10-16T08:35:23Z",
            "published": "2023-10-16T08:35:23Z",
            "summary": "A hypergraph as a generalization of graphs records higher-order interactions\namong nodes, yields a more flexible network model, and allows non-linear\nfeatures for a group of nodes. In this article, we propose a hypergraph echo\nstate network (HypergraphESN) as a generalization of graph echo state network\n(GraphESN) designed for efficient processing of hypergraph-structured data,\nderive convergence conditions for the algorithm, and discuss its versatility in\ncomparison to GraphESN. The numerical experiments on the binary classification\ntasks demonstrate that HypergraphESN exhibits comparable or superior accuracy\nperformance to GraphESN for hypergraph-structured data, and accuracy increases\nif more higher-order interactions in a network are identified.",
            "author": [
                "Justin Lien"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10177v1",
                "http://arxiv.org/pdf/2310.10177v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10176v1",
            "title": "Large Language Models Meet Open-World Intent Discovery and Recognition:\n  An Evaluation of ChatGPT",
            "updated": "2023-10-16T08:34:44Z",
            "published": "2023-10-16T08:34:44Z",
            "summary": "The tasks of out-of-domain (OOD) intent discovery and generalized intent\ndiscovery (GID) aim to extend a closed intent classifier to open-world intent\nsets, which is crucial to task-oriented dialogue (TOD) systems. Previous\nmethods address them by fine-tuning discriminative models. Recently, although\nsome studies have been exploring the application of large language models\n(LLMs) represented by ChatGPT to various downstream tasks, it is still unclear\nfor the ability of ChatGPT to discover and incrementally extent OOD intents. In\nthis paper, we comprehensively evaluate ChatGPT on OOD intent discovery and\nGID, and then outline the strengths and weaknesses of ChatGPT. Overall, ChatGPT\nexhibits consistent advantages under zero-shot settings, but is still at a\ndisadvantage compared to fine-tuned models. More deeply, through a series of\nanalytical experiments, we summarize and discuss the challenges faced by LLMs\nincluding clustering, domain-specific understanding, and cross-domain\nin-context learning scenarios. Finally, we provide empirical guidance for\nfuture directions to address these challenges.",
            "author": [
                "Xiaoshuai Song",
                "Keqing He",
                "Pei Wang",
                "Guanting Dong",
                "Yutao Mou",
                "Jingang Wang",
                "Yunsen Xian",
                "Xunliang Cai",
                "Weiran Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10176v1",
                "http://arxiv.org/pdf/2310.10176v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10171v1",
            "title": "On permutation symmetries in Bayesian neural network posteriors: a\n  variational perspective",
            "updated": "2023-10-16T08:26:50Z",
            "published": "2023-10-16T08:26:50Z",
            "summary": "The elusive nature of gradient-based optimization in neural networks is tied\nto their loss landscape geometry, which is poorly understood. However recent\nwork has brought solid evidence that there is essentially no loss barrier\nbetween the local solutions of gradient descent, once accounting for\nweight-permutations that leave the network's computation unchanged. This raises\nquestions for approximate inference in Bayesian neural networks (BNNs), where\nwe are interested in marginalizing over multiple points in the loss landscape.\nIn this work, we first extend the formalism of marginalized loss barrier and\nsolution interpolation to BNNs, before proposing a matching algorithm to search\nfor linearly connected solutions. This is achieved by aligning the\ndistributions of two independent approximate Bayesian solutions with respect to\npermutation matrices. We build on the results of Ainsworth et al. (2023),\nreframing the problem as a combinatorial optimization one, using an\napproximation to the sum of bilinear assignment problem. We then experiment on\na variety of architectures and datasets, finding nearly zero marginalized loss\nbarriers for linearly connected solutions.",
            "author": [
                "Simone Rossi",
                "Ankit Singh",
                "Thomas Hannagan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10171v1",
                "http://arxiv.org/pdf/2310.10171v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10170v1",
            "title": "Leveraging Knowledge Distillation for Efficient Deep Reinforcement\n  Learning in Resource-Constrained Environments",
            "updated": "2023-10-16T08:26:45Z",
            "published": "2023-10-16T08:26:45Z",
            "summary": "This paper aims to explore the potential of combining Deep Reinforcement\nLearning (DRL) with Knowledge Distillation (KD) by distilling various DRL\nalgorithms and studying their distillation effects. By doing so, the\ncomputational burden of deep models could be reduced while maintaining the\nperformance. The primary objective is to provide a benchmark for evaluating the\nperformance of different DRL algorithms that have been refined using KD\ntechniques. By distilling these algorithms, the goal is to develop efficient\nand fast DRL models. This research is expected to provide valuable insights\nthat can facilitate further advancements in this promising direction. By\nexploring the combination of DRL and KD, this work aims to promote the\ndevelopment of models that require fewer GPU resources, learn more quickly, and\nmake faster decisions in complex environments. The results of this research\nhave the capacity to significantly advance the field of DRL and pave the way\nfor the future deployment of resource-efficient, decision-making intelligent\nsystems.",
            "author": [
                "Guanlin Meng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10170v1",
                "http://arxiv.org/pdf/2310.10170v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10169v1",
            "title": "DemoNSF: A Multi-task Demonstration-based Generative Framework for Noisy\n  Slot Filling Task",
            "updated": "2023-10-16T08:16:53Z",
            "published": "2023-10-16T08:16:53Z",
            "summary": "Recently, prompt-based generative frameworks have shown impressive\ncapabilities in sequence labeling tasks. However, in practical dialogue\nscenarios, relying solely on simplistic templates and traditional corpora\npresents a challenge for these methods in generalizing to unknown input\nperturbations. To address this gap, we propose a multi-task demonstration based\ngenerative framework for noisy slot filling, named DemoNSF. Specifically, we\nintroduce three noisy auxiliary tasks, namely noisy recovery (NR), random mask\n(RM), and hybrid discrimination (HD), to implicitly capture semantic structural\ninformation of input perturbations at different granularities. In the\ndownstream main task, we design a noisy demonstration construction strategy for\nthe generative framework, which explicitly incorporates task-specific\ninformation and perturbed distribution during training and inference.\nExperiments on two benchmarks demonstrate that DemoNSF outperforms all baseline\nmethods and achieves strong generalization. Further analysis provides empirical\nguidance for the practical application of generative frameworks. Our code is\nreleased at https://github.com/dongguanting/Demo-NSF.",
            "author": [
                "Guanting Dong",
                "Tingfeng Hui",
                "Zhuoma GongQue",
                "Jinxu Zhao",
                "Daichi Guo",
                "Gang Zhao",
                "Keqing He",
                "Weiran Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10169v1",
                "http://arxiv.org/pdf/2310.10169v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10166v1",
            "title": "The Road to On-board Change Detection: A Lightweight Patch-Level Change\n  Detection Network via Exploring the Potential of Pruning and Pooling",
            "updated": "2023-10-16T08:11:41Z",
            "published": "2023-10-16T08:11:41Z",
            "summary": "Existing satellite remote sensing change detection (CD) methods often crop\noriginal large-scale bi-temporal image pairs into small patch pairs and then\nuse pixel-level CD methods to fairly process all the patch pairs. However, due\nto the sparsity of change in large-scale satellite remote sensing images,\nexisting pixel-level CD methods suffer from a waste of computational cost and\nmemory resources on lots of unchanged areas, which reduces the processing\nefficiency of on-board platform with extremely limited computation and memory\nresources. To address this issue, we propose a lightweight patch-level CD\nnetwork (LPCDNet) to rapidly remove lots of unchanged patch pairs in\nlarge-scale bi-temporal image pairs. This is helpful to accelerate the\nsubsequent pixel-level CD processing stage and reduce its memory costs. In our\nLPCDNet, a sensitivity-guided channel pruning method is proposed to remove\nunimportant channels and construct the lightweight backbone network on basis of\nResNet18 network. Then, the multi-layer feature compression (MLFC) module is\ndesigned to compress and fuse the multi-level feature information of\nbi-temporal image patch. The output of MLFC module is fed into the\nfully-connected decision network to generate the predicted binary label.\nFinally, a weighted cross-entropy loss is utilized in the training process of\nnetwork to tackle the change/unchange class imbalance problem. Experiments on\ntwo CD datasets demonstrate that our LPCDNet achieves more than 1000 frames per\nsecond on an edge computation platform, i.e., NVIDIA Jetson AGX Orin, which is\nmore than 3 times that of the existing methods without noticeable CD\nperformance loss. In addition, our method reduces more than 60% memory costs of\nthe subsequent pixel-level CD processing stage.",
            "author": [
                "Lihui Xue",
                "Zhihao Wang",
                "Xueqian Wang",
                "Gang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10166v1",
                "http://arxiv.org/pdf/2310.10166v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10165v1",
            "title": "Machine Learning Catalysis of Quantum Tunneling",
            "updated": "2023-10-16T08:10:41Z",
            "published": "2023-10-16T08:10:41Z",
            "summary": "Optimizing the probability of quantum tunneling between two states, while\nkeeping the resources of the underlying physical system constant, is a task of\nkey importance due to its critical role in various applications. We show that,\nby applying Machine Learning techniques when the system is coupled to an\nancilla, one optimizes the parameters of both the ancillary component and the\ncoupling, ultimately resulting in the maximization of the tunneling\nprobability. We provide illustrative examples for the paradigmatic scenario\ninvolving a two-mode system and a two-mode ancilla in the presence of several\ninteracting particles. Physically, the increase of the tunneling probability is\nrooted in the decrease of the two-well asymmetry due to the coherent\noscillations induced by the coupling to the ancilla. We also argue that the\nenhancement of the tunneling probability is not hampered by weak coupling to\nnoisy environments.",
            "author": [
                "Renzo Testa",
                "Alex Rodriguez",
                "Alberto d'Onofrio",
                "Andrea Trombettoni",
                "Fabio Benatti",
                "Fabio Anselmi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10165v1",
                "http://arxiv.org/pdf/2310.10165v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17657v1",
            "title": "Deep Learning Algorithm for Advanced Level-3 Inverse-Modeling of\n  Silicon-Carbide Power MOSFET Devices",
            "updated": "2023-10-16T08:07:40Z",
            "published": "2023-10-16T08:07:40Z",
            "summary": "Inverse modelling with deep learning algorithms involves training deep\narchitecture to predict device's parameters from its static behaviour. Inverse\ndevice modelling is suitable to reconstruct drifted physical parameters of\ndevices temporally degraded or to retrieve physical configuration. There are\nmany variables that can influence the performance of an inverse modelling\nmethod. In this work the authors propose a deep learning method trained for\nretrieving physical parameters of Level-3 model of Power Silicon-Carbide MOSFET\n(SiC Power MOS). The SiC devices are used in applications where classical\nsilicon devices failed due to high-temperature or high switching capability.\nThe key application of SiC power devices is in the automotive field (i.e. in\nthe field of electrical vehicles). Due to physiological degradation or\nhigh-stressing environment, SiC Power MOS shows a significant drift of physical\nparameters which can be monitored by using inverse modelling. The aim of this\nwork is to provide a possible deep learning-based solution for retrieving\nphysical parameters of the SiC Power MOSFET. Preliminary results based on the\nretrieving of channel length of the device are reported. Channel length of\npower MOSFET is a key parameter involved in the static and dynamic behaviour of\nthe device. The experimental results reported in this work confirmed the\neffectiveness of a multi-layer perceptron designed to retrieve this parameter.",
            "author": [
                "Massimo Orazio Spata",
                "Sebastiano Battiato",
                "Alessandro Ortis",
                "Francesco Rundo",
                "Michele Calabretta",
                "Carmelo Pino",
                "Angelo Messina"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17657v1",
                "http://arxiv.org/pdf/2310.17657v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10157v1",
            "title": "Adaptive Workload Distribution for Accuracy-aware DNN Inference on\n  Collaborative Edge Platforms",
            "updated": "2023-10-16T07:55:30Z",
            "published": "2023-10-16T07:55:30Z",
            "summary": "DNN inference can be accelerated by distributing the workload among a cluster\nof collaborative edge nodes. Heterogeneity among edge devices and\naccuracy-performance trade-offs of DNN models present a complex exploration\nspace while catering to the inference performance requirements. In this work,\nwe propose adaptive workload distribution for DNN inference, jointly\nconsidering node-level heterogeneity of edge devices, and application-specific\naccuracy and performance requirements. Our proposed approach combinatorially\noptimizes heterogeneity-aware workload partitioning and dynamic accuracy\nconfiguration of DNN models to ensure performance and accuracy guarantees. We\ntested our approach on an edge cluster of Odroid XU4, Raspberry Pi4, and Jetson\nNano boards and achieved an average gain of 41.52% in performance and 5.2% in\noutput accuracy as compared to state-of-the-art workload distribution\nstrategies.",
            "author": [
                "Zain Taufique",
                "Antonio Miele",
                "Pasi Liljeberg",
                "Anil Kanduri"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10157v1",
                "http://arxiv.org/pdf/2310.10157v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.AI",
                "cs.LG",
                "cs.PF",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10701v2",
            "title": "Theory of Mind for Multi-Agent Collaboration via Large Language Models",
            "updated": "2023-10-22T03:49:34Z",
            "published": "2023-10-16T07:51:19Z",
            "summary": "While Large Language Models (LLMs) have demonstrated impressive\naccomplishments in both reasoning and planning, their abilities in multi-agent\ncollaborations remains largely unexplored. This study evaluates LLM-based\nagents in a multi-agent cooperative text game with Theory of Mind (ToM)\ninference tasks, comparing their performance with Multi-Agent Reinforcement\nLearning (MARL) and planning-based baselines. We observed evidence of emergent\ncollaborative behaviors and high-order Theory of Mind capabilities among\nLLM-based agents. Our results reveal limitations in LLM-based agents' planning\noptimization due to systematic failures in managing long-horizon contexts and\nhallucination about the task state. We explore the use of explicit belief state\nrepresentations to mitigate these issues, finding that it enhances task\nperformance and the accuracy of ToM inferences for LLM-based agents.",
            "author": [
                "Huao Li",
                "Yu Quan Chong",
                "Simon Stepputtis",
                "Joseph Campbell",
                "Dana Hughes",
                "Michael Lewis",
                "Katia Sycara"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10701v2",
                "http://arxiv.org/pdf/2310.10701v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10151v1",
            "title": "DNA: Denoised Neighborhood Aggregation for Fine-grained Category\n  Discovery",
            "updated": "2023-10-16T07:43:30Z",
            "published": "2023-10-16T07:43:30Z",
            "summary": "Discovering fine-grained categories from coarsely labeled data is a practical\nand challenging task, which can bridge the gap between the demand for\nfine-grained analysis and the high annotation cost. Previous works mainly focus\non instance-level discrimination to learn low-level features, but ignore\nsemantic similarities between data, which may prevent these models learning\ncompact cluster representations. In this paper, we propose Denoised\nNeighborhood Aggregation (DNA), a self-supervised framework that encodes\nsemantic structures of data into the embedding space. Specifically, we retrieve\nk-nearest neighbors of a query as its positive keys to capture semantic\nsimilarities between data and then aggregate information from the neighbors to\nlearn compact cluster representations, which can make fine-grained categories\nmore separatable. However, the retrieved neighbors can be noisy and contain\nmany false-positive keys, which can degrade the quality of learned embeddings.\nTo cope with this challenge, we propose three principles to filter out these\nfalse neighbors for better representation learning. Furthermore, we\ntheoretically justify that the learning objective of our framework is\nequivalent to a clustering loss, which can capture semantic similarities\nbetween data to form compact fine-grained clusters. Extensive experiments on\nthree benchmark datasets show that our method can retrieve more accurate\nneighbors (21.31% accuracy improvement) and outperform state-of-the-art models\nby a large margin (average 9.96% improvement on three metrics). Our code and\ndata are available at https://github.com/Lackel/DNA.",
            "author": [
                "Wenbin An",
                "Feng Tian",
                "Wenkai Shi",
                "Yan Chen",
                "Qinghua Zheng",
                "QianYing Wang",
                "Ping Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10151v1",
                "http://arxiv.org/pdf/2310.10151v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10143v1",
            "title": "An Empirical Study of Simplicial Representation Learning with\n  Wasserstein Distance",
            "updated": "2023-10-16T07:31:30Z",
            "published": "2023-10-16T07:31:30Z",
            "summary": "In this paper, we delve into the problem of simplicial representation\nlearning utilizing the 1-Wasserstein distance on a tree structure (a.k.a.,\nTree-Wasserstein distance (TWD)), where TWD is defined as the L1 distance\nbetween two tree-embedded vectors. Specifically, we consider a framework for\nsimplicial representation estimation employing a self-supervised learning\napproach based on SimCLR with a negative TWD as a similarity measure. In\nSimCLR, the cosine similarity with real-vector embeddings is often utilized;\nhowever, it has not been well studied utilizing L1-based measures with\nsimplicial embeddings. A key challenge is that training the L1 distance is\nnumerically challenging and often yields unsatisfactory outcomes, and there are\nnumerous choices for probability models. Thus, this study empirically\ninvestigates a strategy for optimizing self-supervised learning with TWD and\nfind a stable training procedure. More specifically, we evaluate the\ncombination of two types of TWD (total variation and ClusterTree) and several\nsimplicial models including the softmax function, the ArcFace probability\nmodel, and simplicial embedding. Moreover, we propose a simple yet effective\nJeffrey divergence-based regularization method to stabilize the optimization.\nThrough empirical experiments on STL10, CIFAR10, CIFAR100, and SVHN, we first\nfound that the simple combination of softmax function and TWD can obtain\nsignificantly lower results than the standard SimCLR (non-simplicial model and\ncosine similarity). We found that the model performance depends on the\ncombination of TWD and the simplicial model, and the Jeffrey divergence\nregularization usually helps model training. Finally, we inferred that the\nappropriate choice of combination of TWD and simplicial models outperformed\ncosine similarity based representation learning.",
            "author": [
                "Makoto Yamada",
                "Yuki Takezawa",
                "Guillaume Houry",
                "Kira Michaela Dusterwald",
                "Deborah Sulem",
                "Han Zhao",
                "Yao-Hung Hubert Tsai"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10143v1",
                "http://arxiv.org/pdf/2310.10143v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10141v1",
            "title": "A Search for Prompts: Generating Structured Answers from Contracts",
            "updated": "2023-10-16T07:29:38Z",
            "published": "2023-10-16T07:29:38Z",
            "summary": "In many legal processes being able to action on the concrete implication of a\nlegal question can be valuable to automating human review or signalling certain\nconditions (e.g., alerts around automatic renewal). To support such tasks, we\npresent a form of legal question answering that seeks to return one (or more)\nfixed answers for a question about a contract clause. After showing that\nunstructured generative question answering can have questionable outcomes for\nsuch a task, we discuss our exploration methodology for legal question\nanswering prompts using OpenAI's \\textit{GPT-3.5-Turbo} and provide a summary\nof insights.\n  Using insights gleaned from our qualitative experiences, we compare our\nproposed template prompts against a common semantic matching approach and find\nthat our prompt templates are far more accurate despite being less reliable in\nthe exact response return. With some additional tweaks to prompts and the use\nof in-context learning, we are able to further improve the performance of our\nproposed strategy while maximizing the reliability of responses as best we can.",
            "author": [
                "Adam Roegiest",
                "Radha Chitta",
                "Jonathan Donnelly",
                "Maya Lash",
                "Alexandra Vtyurina",
                "Fran\u00e7ois Longtin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10141v1",
                "http://arxiv.org/pdf/2310.10141v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10138v1",
            "title": "Node-based Knowledge Graph Contrastive Learning for Medical Relationship\n  Prediction",
            "updated": "2023-10-16T07:27:43Z",
            "published": "2023-10-16T07:27:43Z",
            "summary": "The embedding of Biomedical Knowledge Graphs (BKGs) generates robust\nrepresentations, valuable for a variety of artificial intelligence\napplications, including predicting drug combinations and reasoning disease-drug\nrelationships. Meanwhile, contrastive learning (CL) is widely employed to\nenhance the distinctiveness of these representations. However, constructing\nsuitable contrastive pairs for CL, especially within Knowledge Graphs (KGs),\nhas been challenging. In this paper, we proposed a novel node-based contrastive\nlearning method for knowledge graph embedding, NC-KGE. NC-KGE enhances\nknowledge extraction in embeddings and speeds up training convergence by\nconstructing appropriate contrastive node pairs on KGs. This scheme can be\neasily integrated with other knowledge graph embedding (KGE) methods. For\ndownstream task such as biochemical relationship prediction, we have\nincorporated a relation-aware attention mechanism into NC-KGE, focusing on the\nsemantic relationships and node interactions. Extensive experiments show that\nNC-KGE performs competitively with state-of-the-art models on public datasets\nlike FB15k-237 and WN18RR. Particularly in biomedical relationship prediction\ntasks, NC-KGE outperforms all baselines on datasets such as PharmKG8k-28,\nDRKG17k-21, and BioKG72k-14, especially in predicting drug combination\nrelationships. We release our code at https://github.com/zhi520/NC-KGE.",
            "author": [
                "Zhiguang Fan",
                "Yuedong Yang",
                "Mingyuan Xu",
                "Hongming Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10138v1",
                "http://arxiv.org/pdf/2310.10138v1"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB",
                "cs.CL",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13008v1",
            "title": "LoBaSS: Gauging Learnability in Supervised Fine-tuning Data",
            "updated": "2023-10-16T07:26:24Z",
            "published": "2023-10-16T07:26:24Z",
            "summary": "Supervised Fine-Tuning (SFT) serves as a crucial phase in aligning Large\nLanguage Models (LLMs) to specific task prerequisites. The selection of\nfine-tuning data profoundly influences the model's performance, whose principle\nis traditionally grounded in data quality and distribution. In this paper, we\nintroduce a new dimension in SFT data selection: learnability. This new\ndimension is motivated by the intuition that SFT unlocks capabilities acquired\nby a LLM during the pretraining phase. Given that different pretrained models\nhave disparate capabilities, the SFT data appropriate for one may not suit\nanother. Thus, we introduce the term learnability to define the suitability of\ndata for effective learning by the model. We present the Loss Based SFT Data\nSelection (LoBaSS) method, utilizing data learnability as the principal\ncriterion for the selection SFT data. This method provides a nuanced approach,\nallowing the alignment of data selection with inherent model capabilities,\nensuring optimal compatibility and learning efficiency. In experimental\ncomparisons involving 7B and 13B models, our LoBaSS method is able to surpass\nfull-data fine-tuning at merely 6% of the total training data. When employing\n16.7% of the data, LoBaSS harmonizes the model's capabilities across\nconversational and mathematical domains, proving its efficacy and adaptability.",
            "author": [
                "Haotian Zhou",
                "Tingkai Liu",
                "Qianli Ma",
                "Jianbo Yuan",
                "Pengfei Liu",
                "Yang You",
                "Hongxia Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13008v1",
                "http://arxiv.org/pdf/2310.13008v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10137v1",
            "title": "A Stiffness-Oriented Model Order Reduction Method for Low-Inertia Power\n  Systems",
            "updated": "2023-10-16T07:21:58Z",
            "published": "2023-10-16T07:21:58Z",
            "summary": "This paper presents a novel model order reduction technique tailored for\npower systems with a large share of inverter-based energy resources. Such\nsystems exhibit an increased level of dynamic stiffness compared to traditional\npower systems, posing challenges for time-domain simulations and control\ndesign. Our approach involves rotation of the coordinate system of a linearized\nsystem using a transformation matrix derived from the real Jordan canonical\nform, leading to mode decoupling. The fast modes are then truncated in the\nrotated coordinate system to obtain a lower-order model with reduced stiffness.\nApplying the same transformation to the original nonlinear system results in an\napproximate separation of slow and fast states, which can be truncated to\nreduce the stiffness. The resulting reduced-order model demonstrates an\naccurate time-domain performance, the slow eigenvalues of the linearized system\nare correctly preserved, and a reduction in the model stiffness is achieved,\nallowing for accurate integration with increased step size. Our methodology is\nassessed in detail for a 3-bus system with generation units involving\ngrid-forming/following converters and synchronous machines, where it allows for\na computational speed-up of up to 100x compared to the original system. Several\nstandard larger test systems are also considered.",
            "author": [
                "Simon Muntwiler",
                "Ognjen Stanojev",
                "Andrea Zanelli",
                "Gabriela Hug",
                "Melanie N. Zeilinger"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10137v1",
                "http://arxiv.org/pdf/2310.10137v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10700v2",
            "title": "PELA: Learning Parameter-Efficient Models with Low-Rank Approximation",
            "updated": "2023-11-17T06:41:01Z",
            "published": "2023-10-16T07:17:33Z",
            "summary": "Applying a pre-trained large model to downstream tasks is prohibitive under\nresource-constrained conditions. Recent dominant approaches for addressing\nefficiency issues involve adding a few learnable parameters to the fixed\nbackbone model. This strategy, however, leads to more challenges in loading\nlarge models for downstream fine-tuning with limited resources. In this paper,\nwe propose a novel method for increasing the parameter efficiency of\npre-trained models by introducing an intermediate pre-training stage. To this\nend, we first employ low-rank approximation to compress the original large\nmodel and then devise a feature distillation module and a weight perturbation\nregularization module. These modules are specifically designed to enhance the\nlow-rank model. In particular, we update only the low-rank model while freezing\nthe backbone parameters during pre-training. This allows for direct and\nefficient utilization of the low-rank model for downstream fine-tuning tasks.\nThe proposed method achieves both efficiencies in terms of required parameters\nand computation time while maintaining comparable results with minimal\nmodifications to the backbone architecture. Specifically, when applied to three\nvision-only and one vision-language Transformer models, our approach often\ndemonstrates a merely $\\sim$0.6 point decrease in performance while reducing\nthe original parameter size by 1/3 to 2/3.",
            "author": [
                "Yangyang Guo",
                "Guangzhi Wang",
                "Mohan Kankanhalli"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10700v2",
                "http://arxiv.org/pdf/2310.10700v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10134v1",
            "title": "CLIN: A Continually Learning Language Agent for Rapid Task Adaptation\n  and Generalization",
            "updated": "2023-10-16T07:17:27Z",
            "published": "2023-10-16T07:17:27Z",
            "summary": "Language agents have shown some ability to interact with an external\nenvironment, e.g., a virtual world such as ScienceWorld, to perform complex\ntasks, e.g., growing a plant, without the startup costs of reinforcement\nlearning. However, despite their zero-shot capabilities, these agents to date\ndo not continually improve over time beyond performance refinement on a\nspecific task. Here we present CLIN, the first language-based agent to achieve\nthis, so that it continually improves over multiple trials, including when both\nthe environment and task are varied, and without requiring parameter updates.\nOur approach is to use a persistent, dynamic, textual memory centered on causal\nabstractions (rather than general \"helpful hints\") that is regularly updated\nafter each trial so that the agent gradually learns useful knowledge for new\ntrials. In the ScienceWorld benchmark, CLIN is able to continually improve on\nrepeated trials on the same task and environment, outperforming\nstate-of-the-art reflective language agents like Reflexion by 23 absolute\npoints. CLIN can also transfer its learning to new environments (or new tasks),\nimproving its zero-shot performance by 4 points (13 for new tasks) and can\nfurther improve performance there through continual memory updates, enhancing\nperformance by an additional 17 points (7 for new tasks). This suggests a new\narchitecture for agents built on frozen models that can still continually and\nrapidly improve over time.",
            "author": [
                "Bodhisattwa Prasad Majumder",
                "Bhavana Dalvi Mishra",
                "Peter Jansen",
                "Oyvind Tafjord",
                "Niket Tandon",
                "Li Zhang",
                "Chris Callison-Burch",
                "Peter Clark"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10134v1",
                "http://arxiv.org/pdf/2310.10134v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10133v1",
            "title": "Empowering SMPC: Bridging the Gap Between Scalability, Memory Efficiency\n  and Privacy in Neural Network Inference",
            "updated": "2023-10-16T07:16:09Z",
            "published": "2023-10-16T07:16:09Z",
            "summary": "This paper aims to develop an efficient open-source Secure Multi-Party\nComputation (SMPC) repository, that addresses the issue of practical and\nscalable implementation of SMPC protocol on machines with moderate\ncomputational resources, while aiming to reduce the execution time. We\nimplement the ABY2.0 protocol for SMPC, providing developers with effective\ntools for building applications on the ABY 2.0 protocol. This article addresses\nthe limitations of the C++ based MOTION2NX framework for secure neural network\ninference, including memory constraints and operation compatibility issues. Our\nenhancements include optimizing the memory usage, reducing execution time using\na third-party Helper node, and enhancing efficiency while still preserving data\nprivacy. These optimizations enable MNIST dataset inference in just 32 seconds\nwith only 0.2 GB of RAM for a 5-layer neural network. In contrast, the previous\nbaseline implementation required 8.03 GB of RAM and 200 seconds of execution\ntime.",
            "author": [
                "Ramya Burra",
                "Anshoo Tandon",
                "Srishti Mittal"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10133v1",
                "http://arxiv.org/pdf/2310.10133v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10130v1",
            "title": "Ferroelastic twin wall mediated ferro-flexoelectricity and bulk\n  photovoltaic effect in SrTiO$_3$",
            "updated": "2023-10-16T07:14:00Z",
            "published": "2023-10-16T07:14:00Z",
            "summary": "Ferroelastic twin walls in nonpolar materials can give rise to a spontaneous\npolarization due to symmetry breaking. Nevertheless, the bi-stable polarity of\ntwin walls and its reversal have not yet been demonstrated. Here, we report\nthat the polarity of SrTiO$_3$ twin walls can be switched by ultra-low strain\ngradient. Using first-principles-based machine-learning potential, we\ndemonstrate that the twin walls can be deterministically rotated and realigned\nin specific directions under strain gradient, which breaks the inversion\nsymmetry of a sequence of walls and leads to a macroscopic polarization. The\nsystem can maintain polarity even after the strain gradient is removed. As a\nresult, the polarization of twin walls can exhibit ferroelectric-like\nhysteresis loop upon cyclic bending, namely ferro-flexoelectricity. Finally, we\npropose a scheme to experimentally detect the polarity of twin wall by\nmeasuring the bulk photovoltaic responses. Our findings suggest a\ntwin-wall-mediated ferro-flexoelectricity in SrTiO$_3$, which could be\npotentially exploited as functional elements in nano-electronic devices design.",
            "author": [
                "Ri He",
                "Haowei Xu",
                "Peijun Yang",
                "Kai Chang",
                "Hua Wang",
                "Zhicheng Zhong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10130v1",
                "http://arxiv.org/pdf/2310.10130v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10126v1",
            "title": "A Non-monotonic Smooth Activation Function",
            "updated": "2023-10-16T07:09:47Z",
            "published": "2023-10-16T07:09:47Z",
            "summary": "Activation functions are crucial in deep learning models since they introduce\nnon-linearity into the networks, allowing them to learn from errors and make\nadjustments, which is essential for learning complex patterns. The essential\npurpose of activation functions is to transform unprocessed input signals into\nsignificant output activations, promoting information transmission throughout\nthe neural network. In this study, we propose a new activation function called\nSqish, which is a non-monotonic and smooth function and an alternative to\nexisting ones. We showed its superiority in classification, object detection,\nsegmentation tasks, and adversarial robustness experiments. We got an 8.21%\nimprovement over ReLU on the CIFAR100 dataset with the ShuffleNet V2 model in\nthe FGSM adversarial attack. We also got a 5.87% improvement over ReLU on image\nclassification on the CIFAR100 dataset with the ShuffleNet V2 model.",
            "author": [
                "Koushik Biswas",
                "Meghana Karri",
                "Ula\u015f Ba\u011fc\u0131"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10126v1",
                "http://arxiv.org/pdf/2310.10126v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10124v1",
            "title": "A Comprehensive Study of Privacy Risks in Curriculum Learning",
            "updated": "2023-10-16T07:06:38Z",
            "published": "2023-10-16T07:06:38Z",
            "summary": "Training a machine learning model with data following a meaningful order,\ni.e., from easy to hard, has been proven to be effective in accelerating the\ntraining process and achieving better model performance. The key enabling\ntechnique is curriculum learning (CL), which has seen great success and has\nbeen deployed in areas like image and text classification. Yet, how CL affects\nthe privacy of machine learning is unclear. Given that CL changes the way a\nmodel memorizes the training data, its influence on data privacy needs to be\nthoroughly evaluated. To fill this knowledge gap, we perform the first study\nand leverage membership inference attack (MIA) and attribute inference attack\n(AIA) as two vectors to quantify the privacy leakage caused by CL.\n  Our evaluation of nine real-world datasets with attack methods (NN-based,\nmetric-based, label-only MIA, and NN-based AIA) revealed new insights about CL.\nFirst, MIA becomes slightly more effective when CL is applied, but the impact\nis much more prominent to a subset of training samples ranked as difficult.\nSecond, a model trained under CL is less vulnerable under AIA, compared to MIA.\nThird, the existing defense techniques like DP-SGD, MemGuard, and MixupMMD are\nstill effective under CL, though DP-SGD has a significant impact on target\nmodel accuracy. Finally, based on our insights into CL, we propose a new MIA,\ntermed Diff-Cali, which exploits the difficulty scores for result calibration\nand is demonstrated to be effective against all CL methods and the normal\ntraining method. With this study, we hope to draw the community's attention to\nthe unintended privacy risks of emerging machine-learning techniques and\ndevelop new attack benchmarks and defense solutions.",
            "author": [
                "Joann Qiongna Chen",
                "Xinlei He",
                "Zheng Li",
                "Yang Zhang",
                "Zhou Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10124v1",
                "http://arxiv.org/pdf/2310.10124v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10121v2",
            "title": "From Continuous Dynamics to Graph Neural Networks: Neural Diffusion and\n  Beyond",
            "updated": "2023-10-29T21:31:53Z",
            "published": "2023-10-16T06:57:24Z",
            "summary": "Graph neural networks (GNNs) have demonstrated significant promise in\nmodelling relational data and have been widely applied in various fields of\ninterest. The key mechanism behind GNNs is the so-called message passing where\ninformation is being iteratively aggregated to central nodes from their\nneighbourhood. Such a scheme has been found to be intrinsically linked to a\nphysical process known as heat diffusion, where the propagation of GNNs\nnaturally corresponds to the evolution of heat density. Analogizing the process\nof message passing to the heat dynamics allows to fundamentally understand the\npower and pitfalls of GNNs and consequently informs better model design.\nRecently, there emerges a plethora of works that proposes GNNs inspired from\nthe continuous dynamics formulation, in an attempt to mitigate the known\nlimitations of GNNs, such as oversmoothing and oversquashing. In this survey,\nwe provide the first systematic and comprehensive review of studies that\nleverage the continuous perspective of GNNs. To this end, we introduce\nfoundational ingredients for adapting continuous dynamics to GNNs, along with a\ngeneral framework for the design of graph neural dynamics. We then review and\ncategorize existing works based on their driven mechanisms and underlying\ndynamics. We also summarize how the limitations of classic GNNs can be\naddressed under the continuous framework. We conclude by identifying multiple\nopen research directions.",
            "author": [
                "Andi Han",
                "Dai Shi",
                "Lequan Lin",
                "Junbin Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10121v2",
                "http://arxiv.org/pdf/2310.10121v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10118v2",
            "title": "Learning to Rank Context for Named Entity Recognition Using a Synthetic\n  Dataset",
            "updated": "2023-11-06T10:09:22Z",
            "published": "2023-10-16T06:53:12Z",
            "summary": "While recent pre-trained transformer-based models can perform named entity\nrecognition (NER) with great accuracy, their limited range remains an issue\nwhen applied to long documents such as whole novels. To alleviate this issue, a\nsolution is to retrieve relevant context at the document level. Unfortunately,\nthe lack of supervision for such a task means one has to settle for\nunsupervised approaches. Instead, we propose to generate a synthetic context\nretrieval training dataset using Alpaca, an instructiontuned large language\nmodel (LLM). Using this dataset, we train a neural context retriever based on a\nBERT model that is able to find relevant context for NER. We show that our\nmethod outperforms several retrieval baselines for the NER task on an English\nliterary dataset composed of the first chapter of 40 books.",
            "author": [
                "Arthur Amalvy",
                "Vincent Labatut",
                "Richard Dufour"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10118v2",
                "http://arxiv.org/pdf/2310.10118v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10117v1",
            "title": "A proximal augmented Lagrangian based algorithm for federated learning\n  with global and local convex conic constraints",
            "updated": "2023-10-16T06:51:32Z",
            "published": "2023-10-16T06:51:32Z",
            "summary": "This paper considers federated learning (FL) with constraints, where the\ncentral server and all local clients collectively minimize a sum of convex\nlocal objective functions subject to global and local convex conic constraints.\nTo train the model without moving local data from clients to the central\nserver, we propose an FL framework in which each local client performs multiple\nupdates using the local objective and local constraint, while the central\nserver handles the global constraint and performs aggregation based on the\nupdated local models. In particular, we develop a proximal augmented Lagrangian\n(AL) based algorithm for FL with global and local convex conic constraints. The\nsubproblems arising in this algorithm are solved by an inexact alternating\ndirection method of multipliers (ADMM) in a federated fashion. Under a local\nLipschitz condition and mild assumptions, we establish the worst-case\ncomplexity bounds of the proposed algorithm for finding an approximate KKT\nsolution. To the best of our knowledge, this work proposes the first algorithm\nfor FL with global and local constraints. Our numerical experiments demonstrate\nthe practical advantages of our algorithm in performing Neyman-Pearson\nclassification and enhancing model fairness in the context of FL.",
            "author": [
                "Chuan He",
                "Le Peng",
                "Ju Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10117v1",
                "http://arxiv.org/pdf/2310.10117v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10107v1",
            "title": "Regret Analysis of the Posterior Sampling-based Learning Algorithm for\n  Episodic POMDPs",
            "updated": "2023-10-16T06:41:13Z",
            "published": "2023-10-16T06:41:13Z",
            "summary": "Compared to Markov Decision Processes (MDPs), learning in Partially\nObservable Markov Decision Processes (POMDPs) can be significantly harder due\nto the difficulty of interpreting observations. In this paper, we consider\nepisodic learning problems in POMDPs with unknown transition and observation\nmodels. We consider the Posterior Sampling-based Reinforcement Learning (PSRL)\nalgorithm for POMDPs and show that its Bayesian regret scales as the square\nroot of the number of episodes. In general, the regret scales exponentially\nwith the horizon length $H$, and we show that this is inevitable by providing a\nlower bound. However, under the condition that the POMDP is undercomplete and\nweakly revealing, we establish a polynomial Bayesian regret bound that improves\nthe regret bound by a factor of $\\Omega(H^2\\sqrt{SA})$ over the recent result\nby arXiv:2204.08967.",
            "author": [
                "Dengwang Tang",
                "Rahul Jain",
                "Ashutosh Nayyar",
                "Pierluigi Nuzzo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10107v1",
                "http://arxiv.org/pdf/2310.10107v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.SY",
                "eess.SY",
                "stat.ML",
                "93E35"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10103v1",
            "title": "Navigation with Large Language Models: Semantic Guesswork as a Heuristic\n  for Planning",
            "updated": "2023-10-16T06:21:06Z",
            "published": "2023-10-16T06:21:06Z",
            "summary": "Navigation in unfamiliar environments presents a major challenge for robots:\nwhile mapping and planning techniques can be used to build up a representation\nof the world, quickly discovering a path to a desired goal in unfamiliar\nsettings with such methods often requires lengthy mapping and exploration.\nHumans can rapidly navigate new environments, particularly indoor environments\nthat are laid out logically, by leveraging semantics -- e.g., a kitchen often\nadjoins a living room, an exit sign indicates the way out, and so forth.\nLanguage models can provide robots with such knowledge, but directly using\nlanguage models to instruct a robot how to reach some destination can also be\nimpractical: while language models might produce a narrative about how to reach\nsome goal, because they are not grounded in real-world observations, this\nnarrative might be arbitrarily wrong. Therefore, in this paper we study how the\n``semantic guesswork'' produced by language models can be utilized as a guiding\nheuristic for planning algorithms. Our method, Language Frontier Guide (LFG),\nuses the language model to bias exploration of novel real-world environments by\nincorporating the semantic knowledge stored in language models as a search\nheuristic for planning with either topological or metric maps. We evaluate LFG\nin challenging real-world environments and simulated benchmarks, outperforming\nuninformed exploration and other ways of using language models.",
            "author": [
                "Dhruv Shah",
                "Michael Equi",
                "Blazej Osinski",
                "Fei Xia",
                "Brian Ichter",
                "Sergey Levine"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10103v1",
                "http://arxiv.org/pdf/2310.10103v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10102v1",
            "title": "KAKURENBO: Adaptively Hiding Samples in Deep Neural Network Training",
            "updated": "2023-10-16T06:19:29Z",
            "published": "2023-10-16T06:19:29Z",
            "summary": "This paper proposes a method for hiding the least-important samples during\nthe training of deep neural networks to increase efficiency, i.e., to reduce\nthe cost of training. Using information about the loss and prediction\nconfidence during training, we adaptively find samples to exclude in a given\nepoch based on their contribution to the overall learning process, without\nsignificantly degrading accuracy. We explore the converge properties when\naccounting for the reduction in the number of SGD updates. Empirical results on\nvarious large-scale datasets and models used directly in image classification\nand segmentation show that while the with-replacement importance sampling\nalgorithm performs poorly on large datasets, our method can reduce total\ntraining time by up to 22% impacting accuracy only by 0.4% compared to the\nbaseline. Code available at https://github.com/TruongThaoNguyen/kakurenbo",
            "author": [
                "Truong Thao Nguyen",
                "Balazs Gerofi",
                "Edgar Josafat Martinez-Noriega",
                "Fran\u00e7ois Trahay",
                "Mohamed Wahib"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10102v1",
                "http://arxiv.org/pdf/2310.10102v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10699v1",
            "title": "Reusing Pretrained Models by Multi-linear Operators for Efficient\n  Training",
            "updated": "2023-10-16T06:16:47Z",
            "published": "2023-10-16T06:16:47Z",
            "summary": "Training large models from scratch usually costs a substantial amount of\nresources. Towards this problem, recent studies such as bert2BERT and LiGO have\nreused small pretrained models to initialize a large model (termed the ``target\nmodel''), leading to a considerable acceleration in training. Despite the\nsuccesses of these previous studies, they grew pretrained models by mapping\npartial weights only, ignoring potential correlations across the entire model.\nAs we show in this paper, there are inter- and intra-interactions among the\nweights of both the pretrained and the target models. As a result, the partial\nmapping may not capture the complete information and lead to inadequate growth.\nIn this paper, we propose a method that linearly correlates each weight of the\ntarget model to all the weights of the pretrained model to further enhance\nacceleration ability. We utilize multi-linear operators to reduce computational\nand spacial complexity, enabling acceptable resource requirements. Experiments\ndemonstrate that our method can save 76\\% computational costs on DeiT-base\ntransferred from DeiT-small, which outperforms bert2BERT by +12.0\\% and LiGO by\n+20.7\\%, respectively.",
            "author": [
                "Yu Pan",
                "Ye Yuan",
                "Yichun Yin",
                "Zenglin Xu",
                "Lifeng Shang",
                "Xin Jiang",
                "Qun Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10699v1",
                "http://arxiv.org/pdf/2310.10699v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10098v1",
            "title": "PAC Learning Linear Thresholds from Label Proportions",
            "updated": "2023-10-16T05:59:34Z",
            "published": "2023-10-16T05:59:34Z",
            "summary": "Learning from label proportions (LLP) is a generalization of supervised\nlearning in which the training data is available as sets or bags of\nfeature-vectors (instances) along with the average instance-label of each bag.\nThe goal is to train a good instance classifier. While most previous works on\nLLP have focused on training models on such training data, computational\nlearnability of LLP was only recently explored by [Saket'21, Saket'22] who\nshowed worst case intractability of properly learning linear threshold\nfunctions (LTFs) from label proportions. However, their work did not rule out\nefficient algorithms for this problem on natural distributions.\n  In this work we show that it is indeed possible to efficiently learn LTFs\nusing LTFs when given access to random bags of some label proportion in which\nfeature-vectors are, conditioned on their labels, independently sampled from a\nGaussian distribution $N(\\mathbf{\\mu}, \\mathbf{\\Sigma})$. Our work shows that a\ncertain matrix -- formed using covariances of the differences of\nfeature-vectors sampled from the bags with and without replacement --\nnecessarily has its principal component, after a transformation, in the\ndirection of the normal vector of the LTF. Our algorithm estimates the means\nand covariance matrices using subgaussian concentration bounds which we show\ncan be applied to efficiently sample bags for approximating the normal\ndirection. Using this in conjunction with novel generalization error bounds in\nthe bag setting, we show that a low error hypothesis LTF can be identified. For\nsome special cases of the $N(\\mathbf{0}, \\mathbf{I})$ distribution we provide a\nsimpler mean estimation based algorithm. We include an experimental evaluation\nof our learning algorithms along with a comparison with those of [Saket'21,\nSaket'22] and random LTFs, demonstrating the effectiveness of our techniques.",
            "author": [
                "Anand Brahmbhatt",
                "Rishi Saket",
                "Aravindan Raghuveer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10098v1",
                "http://arxiv.org/pdf/2310.10098v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10096v1",
            "title": "LLP-Bench: A Large Scale Tabular Benchmark for Learning from Label\n  Proportions",
            "updated": "2023-10-16T05:58:25Z",
            "published": "2023-10-16T05:58:25Z",
            "summary": "In the task of Learning from Label Proportions (LLP), a model is trained on\ngroups (a.k.a bags) of instances and their corresponding label proportions to\npredict labels for individual instances. LLP has been applied pre-dominantly on\ntwo types of datasets - image and tabular. In image LLP, bags of fixed size are\ncreated by randomly sampling instances from an underlying dataset. Bags created\nvia this methodology are called random bags. Experimentation on Image LLP has\nbeen mostly on random bags on CIFAR-* and MNIST datasets. Despite being a very\ncrucial task in privacy sensitive applications, tabular LLP does not yet have a\nopen, large scale LLP benchmark. One of the unique properties of tabular LLP is\nthe ability to create feature bags where all the instances in a bag have the\nsame value for a given feature. It has been shown in prior research that\nfeature bags are very common in practical, real world applications [Chen et. al\n'23, Saket et. al. '22].\n  In this paper, we address the lack of a open, large scale tabular benchmark.\nFirst we propose LLP-Bench, a suite of 56 LLP datasets (52 feature bag and 4\nrandom bag datasets) created from the Criteo CTR prediction dataset consisting\nof 45 million instances. The 56 datasets represent diverse ways in which bags\ncan be constructed from underlying tabular data. To the best of our knowledge,\nLLP-Bench is the first large scale tabular LLP benchmark with an extensive\ndiversity in constituent datasets. Second, we propose four metrics that\ncharacterize and quantify the hardness of a LLP dataset. Using these four\nmetrics we present deep analysis of the 56 datasets in LLP-Bench. Finally we\npresent the performance of 9 SOTA and popular tabular LLP techniques on all the\n56 datasets. To the best of our knowledge, our study consisting of more than\n2500 experiments is the most extensive study of popular tabular LLP techniques\nin literature.",
            "author": [
                "Anand Brahmbhatt",
                "Mohith Pokala",
                "Rishi Saket",
                "Aravindan Raghuveer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10096v1",
                "http://arxiv.org/pdf/2310.10096v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10095v1",
            "title": "A Multi-Scale Spatial Transformer U-Net for Simultaneously Automatic\n  Reorientation and Segmentation of 3D Nuclear Cardiac Images",
            "updated": "2023-10-16T05:56:53Z",
            "published": "2023-10-16T05:56:53Z",
            "summary": "Accurate reorientation and segmentation of the left ventricular (LV) is\nessential for the quantitative analysis of myocardial perfusion imaging (MPI),\nin which one critical step is to reorient the reconstructed transaxial nuclear\ncardiac images into standard short-axis slices for subsequent image processing.\nSmall-scale LV myocardium (LV-MY) region detection and the diverse cardiac\nstructures of individual patients pose challenges to LV segmentation operation.\nTo mitigate these issues, we propose an end-to-end model, named as multi-scale\nspatial transformer UNet (MS-ST-UNet), that involves the multi-scale spatial\ntransformer network (MSSTN) and multi-scale UNet (MSUNet) modules to perform\nsimultaneous reorientation and segmentation of LV region from nuclear cardiac\nimages. The proposed method is trained and tested using two different nuclear\ncardiac image modalities: 13N-ammonia PET and 99mTc-sestamibi SPECT. We use a\nmulti-scale strategy to generate and extract image features with different\nscales. Our experimental results demonstrate that the proposed method\nsignificantly improves the reorientation and segmentation performance. This\njoint learning framework promotes mutual enhancement between reorientation and\nsegmentation tasks, leading to cutting edge performance and an efficient image\nprocessing workflow. The proposed end-to-end deep network has the potential to\nreduce the burden of manual delineation for cardiac images, thereby providing\nmultimodal quantitative analysis assistance for physicists.",
            "author": [
                "Yangfan Ni",
                "Duo Zhang",
                "Gege Ma",
                "Lijun Lu",
                "Zhongke Huang",
                "Wentao Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10095v1",
                "http://arxiv.org/pdf/2310.10095v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10092v3",
            "title": "Label Differential Privacy via Aggregation",
            "updated": "2023-11-27T11:57:36Z",
            "published": "2023-10-16T05:54:30Z",
            "summary": "In many real-world applications, due to recent developments in the privacy\nlandscape, training data may be aggregated to preserve the privacy of sensitive\ntraining labels. In the learning from label proportions (LLP) framework, the\ndataset is partitioned into bags of feature-vectors which are available only\nwith the sum of the labels per bag. A further restriction, which we call\nlearning from bag aggregates (LBA) is where instead of individual\nfeature-vectors, only the (possibly weighted) sum of the feature-vectors per\nbag is available. We study whether such aggregation techniques can provide\nprivacy guarantees under the notion of label differential privacy (label-DP)\npreviously studied in for e.g. [Chaudhuri-Hsu'11, Ghazi et al.'21, Esfandiari\net al.'22].\n  It is easily seen that naive LBA and LLP do not provide label-DP. Our main\nresult however, shows that weighted LBA using iid Gaussian weights with $m$\nrandomly sampled disjoint $k$-sized bags is in fact $(\\varepsilon,\n\\delta)$-label-DP for any $\\varepsilon > 0$ with $\\delta \\approx\n\\exp(-\\Omega(\\sqrt{k}))$ assuming a lower bound on the linear-mse regression\nloss. Further, the $\\ell_2^2$-regressor which minimizes the loss on the\naggregated dataset has a loss within $\\left(1 + o(1)\\right)$-factor of the\noptimum on the original dataset w.p. $\\approx 1 - exp(-\\Omega(m))$. We\nemphasize that no additive label noise is required.\n  The analogous weighted-LLP does not however admit label-DP. Nevertheless, we\nshow that if additive $N(0, 1)$ noise can be added to any constant fraction of\nthe instance labels, then the noisy weighted-LLP admits similar label-DP\nguarantees without assumptions on the dataset, while preserving the utility of\nLipschitz-bounded neural mse-regression tasks.\n  Our work is the first to demonstrate that label-DP can be achieved by\nrandomly weighted aggregation for regression tasks, using no or little additive\nnoise.",
            "author": [
                "Anand Brahmbhatt",
                "Rishi Saket",
                "Shreyas Havaldar",
                "Anshul Nasery",
                "Aravindan Raghuveer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10092v3",
                "http://arxiv.org/pdf/2310.10092v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10090v1",
            "title": "Orthogonal Uncertainty Representation of Data Manifold for Robust\n  Long-Tailed Learning",
            "updated": "2023-10-16T05:50:34Z",
            "published": "2023-10-16T05:50:34Z",
            "summary": "In scenarios with long-tailed distributions, the model's ability to identify\ntail classes is limited due to the under-representation of tail samples. Class\nrebalancing, information augmentation, and other techniques have been proposed\nto facilitate models to learn the potential distribution of tail classes. The\ndisadvantage is that these methods generally pursue models with balanced class\naccuracy on the data manifold, while ignoring the ability of the model to\nresist interference. By constructing noisy data manifold, we found that the\nrobustness of models trained on unbalanced data has a long-tail phenomenon.\nThat is, even if the class accuracy is balanced on the data domain, it still\nhas bias on the noisy data manifold. However, existing methods cannot\neffectively mitigate the above phenomenon, which makes the model vulnerable in\nlong-tailed scenarios. In this work, we propose an Orthogonal Uncertainty\nRepresentation (OUR) of feature embedding and an end-to-end training strategy\nto improve the long-tail phenomenon of model robustness. As a general\nenhancement tool, OUR has excellent compatibility with other methods and does\nnot require additional data generation, ensuring fast and efficient training.\nComprehensive evaluations on long-tailed datasets show that our method\nsignificantly improves the long-tail phenomenon of robustness, bringing\nconsistent performance gains to other long-tailed learning methods.",
            "author": [
                "Yanbiao Ma",
                "Licheng Jiao",
                "Fang Liu",
                "Shuyuan Yang",
                "Xu Liu",
                "Lingling Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10090v1",
                "http://arxiv.org/pdf/2310.10090v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10089v1",
            "title": "Over-the-Air Federated Learning and Optimization",
            "updated": "2023-10-16T05:49:28Z",
            "published": "2023-10-16T05:49:28Z",
            "summary": "Federated learning (FL), as an emerging distributed machine learning\nparadigm, allows a mass of edge devices to collaboratively train a global model\nwhile preserving privacy. In this tutorial, we focus on FL via over-the-air\ncomputation (AirComp), which is proposed to reduce the communication overhead\nfor FL over wireless networks at the cost of compromising in the learning\nperformance due to model aggregation error arising from channel fading and\nnoise. We first provide a comprehensive study on the convergence of\nAirComp-based FedAvg (AirFedAvg) algorithms under both strongly convex and\nnon-convex settings with constant and diminishing learning rates in the\npresence of data heterogeneity. Through convergence and asymptotic analysis, we\ncharacterize the impact of aggregation error on the convergence bound and\nprovide insights for system design with convergence guarantees. Then we derive\nconvergence rates for AirFedAvg algorithms for strongly convex and non-convex\nobjectives. For different types of local updates that can be transmitted by\nedge devices (i.e., local model, gradient, and model difference), we reveal\nthat transmitting local model in AirFedAvg may cause divergence in the training\nprocedure. In addition, we consider more practical signal processing schemes to\nimprove the communication efficiency and further extend the convergence\nanalysis to different forms of model aggregation error caused by these signal\nprocessing schemes. Extensive simulation results under different settings of\nobjective functions, transmitted local information, and communication schemes\nverify the theoretical conclusions.",
            "author": [
                "Jingyang Zhu",
                "Yuanming Shi",
                "Yong Zhou",
                "Chunxiao Jiang",
                "Wei Chen",
                "Khaled B. Letaief"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10089v1",
                "http://arxiv.org/pdf/2310.10089v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10088v1",
            "title": "PUCA: Patch-Unshuffle and Channel Attention for Enhanced Self-Supervised\n  Image Denoising",
            "updated": "2023-10-16T05:42:49Z",
            "published": "2023-10-16T05:42:49Z",
            "summary": "Although supervised image denoising networks have shown remarkable\nperformance on synthesized noisy images, they often fail in practice due to the\ndifference between real and synthesized noise. Since clean-noisy image pairs\nfrom the real world are extremely costly to gather, self-supervised learning,\nwhich utilizes noisy input itself as a target, has been studied. To prevent a\nself-supervised denoising model from learning identical mapping, each output\npixel should not be influenced by its corresponding input pixel; This\nrequirement is known as J-invariance. Blind-spot networks (BSNs) have been a\nprevalent choice to ensure J-invariance in self-supervised image denoising.\nHowever, constructing variations of BSNs by injecting additional operations\nsuch as downsampling can expose blinded information, thereby violating\nJ-invariance. Consequently, convolutions designed specifically for BSNs have\nbeen allowed only, limiting architectural flexibility. To overcome this\nlimitation, we propose PUCA, a novel J-invariant U-Net architecture, for\nself-supervised denoising. PUCA leverages patch-unshuffle/shuffle to\ndramatically expand receptive fields while maintaining J-invariance and dilated\nattention blocks (DABs) for global context incorporation. Experimental results\ndemonstrate that PUCA achieves state-of-the-art performance, outperforming\nexisting methods in self-supervised image denoising.",
            "author": [
                "Hyemi Jang",
                "Junsung Park",
                "Dahuin Jung",
                "Jaihyun Lew",
                "Ho Bae",
                "Sungroh Yoon"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10088v1",
                "http://arxiv.org/pdf/2310.10088v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10085v1",
            "title": "Solution to Advanced Manufacturing Process Problems using Cohort\n  Intelligence Algorithm with Improved Constraint Handling Approaches",
            "updated": "2023-10-16T05:40:23Z",
            "published": "2023-10-16T05:40:23Z",
            "summary": "Recently, various Artificial Intelligence (AI) based optimization\nmetaheuristics are proposed and applied for a variety of problems. Cohort\nIntelligence (CI) algorithm is a socio inspired optimization technique which is\nsuccessfully applied for solving several unconstrained & constrained real-world\nproblems from the domains such as design, manufacturing, supply chain,\nhealthcare, etc. Generally, real-world problems are constrained in nature. Even\nthough most of the Evolutionary Algorithms (EAs) can efficiently solve\nunconstrained problems, their performance degenerates when the constraints are\ninvolved. In this paper, two novel constraint handling approaches based on\nmodulus and hyperbolic tangent probability distributions are proposed.\nConstrained CI algorithm with constraint handling approaches based on\ntriangular, modulus and hyperbolic tangent is presented and applied for\noptimizing advanced manufacturing processes such as Water Jet Machining (WJM),\nAbrasive Jet Machining (AJM), Ultrasonic Machining (USM) and Grinding process.\nThe solutions obtained using proposed CI algorithm are compared with\ncontemporary algorithms such as Genetic Algorithm, Simulated Annealing,\nTeaching Learning Based Optimization, etc. The proposed approaches achieved\n2%-127% maximization of material removal rate satisfying hard constraints. As\ncompared to the GA, CI with Hyperbolic tangent probability distribution\nachieved 15%, 2%, 2%, 127%, and 4% improvement in MRR for AJMB, AJMD, WJM, USM,\nand Grinding processes, respectively contributing to the productivity\nimprovement. The contributions in this paper have opened several avenues for\nfurther applicability of the proposed constraint handling approaches for\nsolving complex constrained problems.",
            "author": [
                "Aniket Nargundkar",
                "Madhav Rawal",
                "Aryaman Patel",
                "Anand J Kulkarni",
                "Apoorva S Shastri"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10085v1",
                "http://arxiv.org/pdf/2310.10085v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10082v2",
            "title": "A simple uniformly optimal method without line search for convex\n  optimization",
            "updated": "2023-10-27T01:59:04Z",
            "published": "2023-10-16T05:26:03Z",
            "summary": "Line search (or backtracking) procedures have been widely employed into\nfirst-order methods for solving convex optimization problems, especially those\nwith unknown problem parameters (e.g., Lipschitz constant). In this paper, we\nshow that line search is superfluous in attaining the optimal rate of\nconvergence for solving a convex optimization problem whose parameters are not\ngiven a priori. In particular, we present a novel accelerated gradient descent\ntype algorithm called auto-conditioned fast gradient method (AC-FGM) that can\nachieve an optimal $\\mathcal{O}(1/k^2)$ rate of convergence for smooth convex\noptimization without requiring the estimate of a global Lipschitz constant or\nthe employment of line search procedures. We then extend AC-FGM to solve convex\noptimization problems with H\\\"{o}lder continuous gradients and show that it\nautomatically achieves the optimal rates of convergence uniformly for all\nproblem classes with the desired accuracy of the solution as the only input.\nFinally, we report some encouraging numerical results that demonstrate the\nadvantages of AC-FGM over the previously developed parameter-free methods for\nconvex optimization.",
            "author": [
                "Tianjiao Li",
                "Guanghui Lan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10082v2",
                "http://arxiv.org/pdf/2310.10082v2"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10081v1",
            "title": "Sensing of quantum nonlinear noise correlations via thermodynamic\n  variables",
            "updated": "2023-10-16T05:22:11Z",
            "published": "2023-10-16T05:22:11Z",
            "summary": "We put forth the concept of quantum noise sensors based on nonlinear two-mode\ninterferometers coupled to mechanical oscillators. These simple, autonomous\nmachines are capable of a hitherto unexplored quantum thermodynamic\nfunctionality: the ability to sense quantum nonlinear correlations of noisy\nfields via the thermodynamic variable of extractable work. The machines filter\nthermal noise input and turn it into quantum correlated output. Such nonlinear\ncorrelations arise in feasible experimental setups involving Rydberg polaritons\ncoupled via dipole-dipole interactions or cavity modes that exchange quanta via\ntheir coupling to multi-level atoms. By monitoring a mechanical oscillator\ncoupled to the interferometer, one can sense the work capacity of one of the\ninterferometer output modes and thereby reveal its quantum nonlinear\ncorrelations. The proposed quantum sensing method can provide a much simpler\nalternative to quantum multiport interferometry supplemented by process\ntomography.",
            "author": [
                "Nilakantha Meher",
                "Tom\u00e1\u0161 Opatrn\u00fd",
                "Gershon Kurizki"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10081v1",
                "http://arxiv.org/pdf/2310.10081v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10076v1",
            "title": "Verbosity Bias in Preference Labeling by Large Language Models",
            "updated": "2023-10-16T05:19:02Z",
            "published": "2023-10-16T05:19:02Z",
            "summary": "In recent years, Large Language Models (LLMs) have witnessed a remarkable\nsurge in prevalence, altering the landscape of natural language processing and\nmachine learning. One key factor in improving the performance of LLMs is\nalignment with humans achieved with Reinforcement Learning from Human Feedback\n(RLHF), as for many LLMs such as GPT-4, Bard, etc. In addition, recent studies\nare investigating the replacement of human feedback with feedback from other\nLLMs named Reinforcement Learning from AI Feedback (RLAIF). We examine the\nbiases that come along with evaluating LLMs with other LLMs and take a closer\nlook into verbosity bias -- a bias where LLMs sometimes prefer more verbose\nanswers even if they have similar qualities. We see that in our problem\nsetting, GPT-4 prefers longer answers more than humans. We also propose a\nmetric to measure this bias.",
            "author": [
                "Keita Saito",
                "Akifumi Wachi",
                "Koki Wataoka",
                "Youhei Akimoto"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10076v1",
                "http://arxiv.org/pdf/2310.10076v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10074v1",
            "title": "SoTTA: Robust Test-Time Adaptation on Noisy Data Streams",
            "updated": "2023-10-16T05:15:35Z",
            "published": "2023-10-16T05:15:35Z",
            "summary": "Test-time adaptation (TTA) aims to address distributional shifts between\ntraining and testing data using only unlabeled test data streams for continual\nmodel adaptation. However, most TTA methods assume benign test streams, while\ntest samples could be unexpectedly diverse in the wild. For instance, an unseen\nobject or noise could appear in autonomous driving. This leads to a new threat\nto existing TTA algorithms; we found that prior TTA algorithms suffer from\nthose noisy test samples as they blindly adapt to incoming samples. To address\nthis problem, we present Screening-out Test-Time Adaptation (SoTTA), a novel\nTTA algorithm that is robust to noisy samples. The key enabler of SoTTA is\ntwo-fold: (i) input-wise robustness via high-confidence uniform-class sampling\nthat effectively filters out the impact of noisy samples and (ii)\nparameter-wise robustness via entropy-sharpness minimization that improves the\nrobustness of model parameters against large gradients from noisy samples. Our\nevaluation with standard TTA benchmarks with various noisy scenarios shows that\nour method outperforms state-of-the-art TTA methods under the presence of noisy\nsamples and achieves comparable accuracy to those methods without noisy\nsamples. The source code is available at https://github.com/taeckyung/SoTTA .",
            "author": [
                "Taesik Gong",
                "Yewon Kim",
                "Taeckyung Lee",
                "Sorn Chottananurak",
                "Sung-Ju Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10074v1",
                "http://arxiv.org/pdf/2310.10074v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10698v2",
            "title": "Bridging Code Semantic and LLMs: Semantic Chain-of-Thought Prompting for\n  Code Generation",
            "updated": "2023-10-22T10:21:12Z",
            "published": "2023-10-16T05:09:58Z",
            "summary": "Large language models (LLMs) have showcased remarkable prowess in code\ngeneration. However, automated code generation is still challenging since it\nrequires a high-level semantic mapping between natural language requirements\nand codes. Most existing LLMs-based approaches for code generation rely on\ndecoder-only causal language models often treate codes merely as plain text\ntokens, i.e., feeding the requirements as a prompt input, and outputing code as\nflat sequence of tokens, potentially missing the rich semantic features\ninherent in source code. To bridge this gap, this paper proposes the \"Semantic\nChain-of-Thought\" approach to intruduce semantic information of code, named\nSeCoT. Our motivation is that the semantic information of the source code (\\eg\ndata flow and control flow) describes more precise program execution behavior,\nintention and function. By guiding LLM consider and integrate semantic\ninformation, we can achieve a more granular understanding and representation of\ncode, enhancing code generation accuracy. Meanwhile, while traditional\ntechniques leveraging such semantic information require complex static or\ndynamic code analysis to obtain features such as data flow and control flow,\nSeCoT demonstrates that this process can be fully automated via the intrinsic\ncapabilities of LLMs (i.e., in-context learning), while being generalizable and\napplicable to challenging domains. While SeCoT can be applied with different\nLLMs, this paper focuses on the powerful GPT-style models: ChatGPT(close-source\nmodel) and WizardCoder(open-source model). The experimental study on three\npopular DL benchmarks (i.e., HumanEval, HumanEval-ET and MBPP) shows that SeCoT\ncan achieves state-of-the-art performance, greatly improving the potential for\nlarge models and code generation.",
            "author": [
                "Yingwei Ma",
                "Yue Yu",
                "Shanshan Li",
                "Yu Jiang",
                "Yong Guo",
                "Yuanliang Zhang",
                "Yutao Xie",
                "Xiangke Liao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10698v2",
                "http://arxiv.org/pdf/2310.10698v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10068v1",
            "title": "Generalizable Person Search on Open-world User-Generated Video Content",
            "updated": "2023-10-16T04:59:50Z",
            "published": "2023-10-16T04:59:50Z",
            "summary": "Person search is a challenging task that involves detecting and retrieving\nindividuals from a large set of un-cropped scene images. Existing person search\napplications are mostly trained and deployed in the same-origin scenarios.\nHowever, collecting and annotating training samples for each scene is often\ndifficult due to the limitation of resources and the labor cost. Moreover,\nlarge-scale intra-domain data for training are generally not legally available\nfor common developers, due to the regulation of privacy and public security.\nLeveraging easily accessible large-scale User Generated Video Contents\n(\\emph{i.e.} UGC videos) to train person search models can fit the open-world\ndistribution, but still suffering a performance gap from the domain difference\nto surveillance scenes. In this work, we explore enhancing the out-of-domain\ngeneralization capabilities of person search models, and propose a\ngeneralizable framework on both feature-level and data-level generalization to\nfacilitate downstream tasks in arbitrary scenarios. Specifically, we focus on\nlearning domain-invariant representations for both detection and ReID by\nintroducing a multi-task prototype-based domain-specific batch normalization,\nand a channel-wise ID-relevant feature decorrelation strategy. We also identify\nand address typical sources of noise in open-world training frames, including\ninaccurate bounding boxes, the omission of identity labels, and the absence of\ncross-camera data. Our framework achieves promising performance on two\nchallenging person search benchmarks without using any human annotation or\nsamples from the target domain.",
            "author": [
                "Junjie Li",
                "Guanshuo Wang",
                "Yichao Yan",
                "Fufu Yu",
                "Qiong Jia",
                "Jie Qin",
                "Shouhong Ding",
                "Xiaokang Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10068v1",
                "http://arxiv.org/pdf/2310.10068v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10064v1",
            "title": "Learning Graph Filters for Spectral GNNs via Newton Interpolation",
            "updated": "2023-10-16T04:57:30Z",
            "published": "2023-10-16T04:57:30Z",
            "summary": "Spectral Graph Neural Networks (GNNs) are gaining attention because they can\nsurpass the limitations of message-passing GNNs by learning spectral filters\nthat capture essential frequency information in graph data through task\nsupervision. However, previous research suggests that the choice of filter\nfrequency is tied to the graph's homophily level, a connection that hasn't been\nthoroughly explored in existing spectral GNNs. To address this gap, the study\nconducts both theoretical and empirical analyses, revealing that low-frequency\nfilters have a positive correlation with homophily, while high-frequency\nfilters have a negative correlation. This leads to the introduction of a\nshape-aware regularization technique applied to a Newton Interpolation-based\nspectral filter, enabling the customization of polynomial spectral filters that\nalign with desired homophily levels. Extensive experiments demonstrate that\nNewtonNet successfully achieves the desired filter shapes and exhibits superior\nperformance on both homophilous and heterophilous datasets.",
            "author": [
                "Junjie Xu",
                "Enyan Dai",
                "Dongsheng Luo",
                "Xiang Zhang",
                "Suhang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10064v1",
                "http://arxiv.org/pdf/2310.10064v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10060v2",
            "title": "Data Augmentation for Time-Series Classification: An Extensive Empirical\n  Study and Comprehensive Survey",
            "updated": "2023-10-19T12:11:22Z",
            "published": "2023-10-16T04:49:51Z",
            "summary": "Data Augmentation (DA) has emerged as an indispensable strategy in Time\nSeries Classification (TSC), primarily due to its capacity to amplify training\nsamples, thereby bolstering model robustness, diversifying datasets, and\ncurtailing overfitting. However, the current landscape of DA in TSC is plagued\nwith fragmented literature reviews, nebulous methodological taxonomies,\ninadequate evaluative measures, and a dearth of accessible, user-oriented\ntools. In light of these challenges, this study embarks on an exhaustive\ndissection of DA methodologies within the TSC realm. Our initial approach\ninvolved an extensive literature review spanning a decade, revealing that\ncontemporary surveys scarcely capture the breadth of advancements in DA for\nTSC, prompting us to meticulously analyze over 100 scholarly articles to\ndistill more than 60 unique DA techniques. This rigorous analysis precipitated\nthe formulation of a novel taxonomy, purpose-built for the intricacies of DA in\nTSC, categorizing techniques into five principal echelons:\nTransformation-Based, Pattern-Based, Generative, Decomposition-Based, and\nAutomated Data Augmentation. Our taxonomy promises to serve as a robust\nnavigational aid for scholars, offering clarity and direction in method\nselection. Addressing the conspicuous absence of holistic evaluations for\nprevalent DA techniques, we executed an all-encompassing empirical assessment,\nwherein upwards of 15 DA strategies were subjected to scrutiny across 8 UCR\ntime-series datasets, employing ResNet and a multi-faceted evaluation paradigm\nencompassing Accuracy, Method Ranking, and Residual Analysis, yielding a\nbenchmark accuracy of 88.94 +- 11.83%. Our investigation underscored the\ninconsistent efficacies of DA techniques, with...",
            "author": [
                "Zijun Gao",
                "Lingbo Li",
                "Tianhua Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10060v2",
                "http://arxiv.org/pdf/2310.10060v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10059v1",
            "title": "Flow Dynamics Correction for Action Recognition",
            "updated": "2023-10-16T04:49:06Z",
            "published": "2023-10-16T04:49:06Z",
            "summary": "Various research studies indicate that action recognition performance highly\ndepends on the types of motions being extracted and how accurate the human\nactions are represented. In this paper, we investigate different optical flow,\nand features extracted from these optical flow that capturing both short-term\nand long-term motion dynamics. We perform power normalization on the magnitude\ncomponent of optical flow for flow dynamics correction to boost subtle or\ndampen sudden motions. We show that existing action recognition models which\nrely on optical flow are able to get performance boosted with our corrected\noptical flow. To further improve performance, we integrate our corrected flow\ndynamics into popular models through a simple hallucination step by selecting\nonly the best performing optical flow features, and we show that by\n'translating' the CNN feature maps into these optical flow features with\ndifferent scales of motions leads to the new state-of-the-art performance on\nseveral benchmarks including HMDB-51, YUP++, fine-grained action recognition on\nMPII Cooking Activities, and large-scale Charades.",
            "author": [
                "Lei Wang",
                "Piotr Koniusz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10059v1",
                "http://arxiv.org/pdf/2310.10059v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10056v1",
            "title": "Latent Conservative Objective Models for Data-Driven Crystal Structure\n  Prediction",
            "updated": "2023-10-16T04:35:44Z",
            "published": "2023-10-16T04:35:44Z",
            "summary": "In computational chemistry, crystal structure prediction (CSP) is an\noptimization problem that involves discovering the lowest energy stable crystal\nstructure for a given chemical formula. This problem is challenging as it\nrequires discovering globally optimal designs with the lowest energies on\ncomplex manifolds. One approach to tackle this problem involves building\nsimulators based on density functional theory (DFT) followed by running search\nin simulation, but these simulators are painfully slow. In this paper, we study\npresent and study an alternate, data-driven approach to crystal structure\nprediction: instead of directly searching for the most stable structures in\nsimulation, we train a surrogate model of the crystal formation energy from a\ndatabase of existing crystal structures, and then optimize this model with\nrespect to the parameters of the crystal structure. This surrogate model is\ntrained to be conservative so as to prevent exploitation of its errors by the\noptimizer. To handle optimization in the non-Euclidean space of crystal\nstructures, we first utilize a state-of-the-art graph diffusion auto-encoder\n(CD-VAE) to convert a crystal structure into a vector-based search space and\nthen optimize a conservative surrogate model of the crystal energy, trained on\ntop of this vector representation. We show that our approach, dubbed LCOMs\n(latent conservative objective models), performs comparably to the best current\napproaches in terms of success rate of structure prediction, while also\ndrastically reducing computational cost.",
            "author": [
                "Han Qi",
                "Xinyang Geng",
                "Stefano Rando",
                "Iku Ohama",
                "Aviral Kumar",
                "Sergey Levine"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10056v1",
                "http://arxiv.org/pdf/2310.10056v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10054v1",
            "title": "NASH: A Simple Unified Framework of Structured Pruning for Accelerating\n  Encoder-Decoder Language Models",
            "updated": "2023-10-16T04:27:36Z",
            "published": "2023-10-16T04:27:36Z",
            "summary": "Structured pruning methods have proven effective in reducing the model size\nand accelerating inference speed in various network architectures such as\nTransformers. Despite the versatility of encoder-decoder models in numerous NLP\ntasks, the structured pruning methods on such models are relatively less\nexplored compared to encoder-only models. In this study, we investigate the\nbehavior of the structured pruning of the encoder-decoder models in the\ndecoupled pruning perspective of the encoder and decoder component,\nrespectively. Our findings highlight two insights: (1) the number of decoder\nlayers is the dominant factor of inference speed, and (2) low sparsity in the\npruned encoder network enhances generation quality. Motivated by these\nfindings, we propose a simple and effective framework, NASH, that narrows the\nencoder and shortens the decoder networks of encoder-decoder models. Extensive\nexperiments on diverse generation and inference tasks validate the\neffectiveness of our method in both speedup and output quality.",
            "author": [
                "Jongwoo Ko",
                "Seungjoon Park",
                "Yujin Kim",
                "Sumyeong Ahn",
                "Du-Seong Chang",
                "Euijai Ahn",
                "Se-Young Yun"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10054v1",
                "http://arxiv.org/pdf/2310.10054v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10697v1",
            "title": "Synthetic IMU Datasets and Protocols Can Simplify Fall Detection\n  Experiments and Optimize Sensor Configuration",
            "updated": "2023-10-16T04:27:00Z",
            "published": "2023-10-16T04:27:00Z",
            "summary": "Falls represent a significant cause of injury among the elderly population.\nExtensive research has been devoted to the utilization of wearable IMU sensors\nin conjunction with machine learning techniques for fall detection. To address\nthe challenge of acquiring costly training data, this paper presents a novel\nmethod that generates a substantial volume of synthetic IMU data with minimal\nreal fall experiments. First, unmarked 3D motion capture technology is employed\nto reconstruct human movements. Subsequently, utilizing the biomechanical\nsimulation platform Opensim and forward kinematic methods, an ample amount of\ntraining data from various body segments can be custom generated. An LSTM model\nis trained, achieving testing accuracies of 91.99% and 86.62% on two distinct\ndatasets of actual fall-related IMU data, demonstrated the comparable\nperformance of models trained using genuine IMU data. Building upon the\nsimulation framework, this paper further optimized the single IMU attachment\nposition and multiple IMU combinations on fall detection. The proposed method\nsimplifies fall detection data acquisition experiments, provides novel venue\nfor generating low cost synthetic data in scenario where acquiring data for\nmachine learning is challenging and paves the way for customizing machine\nlearning configurations.",
            "author": [
                "Jie Tang",
                "Bin He",
                "Junkai Xu",
                "Tian Tan",
                "Zhipeng Wang",
                "Yanmin Zhou",
                "Shuo Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10697v1",
                "http://arxiv.org/pdf/2310.10697v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10053v1",
            "title": "Fast and Low-Cost Approximate Multiplier for FPGAs using Dynamic\n  Reconfiguration",
            "updated": "2023-10-16T04:25:17Z",
            "published": "2023-10-16T04:25:17Z",
            "summary": "Multipliers are widely-used arithmetic operators in digital signal processing\nand machine learning circuits. Due to their relatively high complexity, they\ncan have high latency and be a significant source of power consumption. One\nstrategy to alleviate these limitations is to use approximate computing. This\npaper thus introduces an original FPGA-based approximate multiplier\nspecifically optimized for machine learning computations. It utilizes\ndynamically reconfigurable lookup table (LUT) primitives in AMD-Xilinx\ntechnology to realize the core part of the computations. The paper provides an\nin-depth analysis of the hardware architecture, implementation outcomes, and\naccuracy evaluations of the multiplier proposed in INT8 precision.\nImplementation results on an AMD-Xilinx Kintex Ultrascale+ FPGA demonstrate\nremarkable savings of 64% and 67% in LUT utilization for signed multiplication\nand multiply-and-accumulation configurations, respectively, when compared to\nthe standard Xilinx multiplier core. Accuracy measurements on four popular deep\nlearning (DL) benchmarks indicate a minimal average accuracy decrease of less\nthan 0.29% during post-training deployment, with the maximum reduction staying\nless than 0.33%. The source code of this work is available on GitHub.",
            "author": [
                "Shervin Vakili",
                "Mobin Vaziri",
                "Amirhossein Zarei",
                "J. M. Pierre Langlois"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10053v1",
                "http://arxiv.org/pdf/2310.10053v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10696v1",
            "title": "Robust Collaborative Filtering to Popularity Distribution Shift",
            "updated": "2023-10-16T04:20:52Z",
            "published": "2023-10-16T04:20:52Z",
            "summary": "In leading collaborative filtering (CF) models, representations of users and\nitems are prone to learn popularity bias in the training data as shortcuts. The\npopularity shortcut tricks are good for in-distribution (ID) performance but\npoorly generalized to out-of-distribution (OOD) data, i.e., when popularity\ndistribution of test data shifts w.r.t. the training one. To close the gap,\ndebiasing strategies try to assess the shortcut degrees and mitigate them from\nthe representations. However, there exist two deficiencies: (1) when measuring\nthe shortcut degrees, most strategies only use statistical metrics on a single\naspect (i.e., item frequency on item and user frequency on user aspect),\nfailing to accommodate the compositional degree of a user-item pair; (2) when\nmitigating shortcuts, many strategies assume that the test distribution is\nknown in advance. This results in low-quality debiased representations. Worse\nstill, these strategies achieve OOD generalizability with a sacrifice on ID\nperformance. In this work, we present a simple yet effective debiasing\nstrategy, PopGo, which quantifies and reduces the interaction-wise popularity\nshortcut without any assumptions on the test data. It first learns a shortcut\nmodel, which yields a shortcut degree of a user-item pair based on their\npopularity representations. Then, it trains the CF model by adjusting the\npredictions with the interaction-wise shortcut degrees. By taking both causal-\nand information-theoretical looks at PopGo, we can justify why it encourages\nthe CF model to capture the critical popularity-agnostic features while leaving\nthe spurious popularity-relevant patterns out. We use PopGo to debias two\nhigh-performing CF models (MF, LightGCN) on four benchmark datasets. On both ID\nand OOD test sets, PopGo achieves significant gains over the state-of-the-art\ndebiasing strategies (e.g., DICE, MACR).",
            "author": [
                "An Zhang",
                "Wenchang Ma",
                "Jingnan Zheng",
                "Xiang Wang",
                "Tat-seng Chua"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3627159",
                "http://arxiv.org/abs/2310.10696v1",
                "http://arxiv.org/pdf/2310.10696v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10050v1",
            "title": "EfficientOCR: An Extensible, Open-Source Package for Efficiently\n  Digitizing World Knowledge",
            "updated": "2023-10-16T04:20:16Z",
            "published": "2023-10-16T04:20:16Z",
            "summary": "Billions of public domain documents remain trapped in hard copy or lack an\naccurate digitization. Modern natural language processing methods cannot be\nused to index, retrieve, and summarize their texts; conduct computational\ntextual analyses; or extract information for statistical analyses, and these\ntexts cannot be incorporated into language model training. Given the diversity\nand sheer quantity of public domain texts, liberating them at scale requires\noptical character recognition (OCR) that is accurate, extremely cheap to\ndeploy, and sample-efficient to customize to novel collections, languages, and\ncharacter sets. Existing OCR engines, largely designed for small-scale\ncommercial applications in high resource languages, often fall short of these\nrequirements. EffOCR (EfficientOCR), a novel open-source OCR package, meets\nboth the computational and sample efficiency requirements for liberating texts\nat scale by abandoning the sequence-to-sequence architecture typically used for\nOCR, which takes representations from a learned vision model as inputs to a\nlearned language model. Instead, EffOCR models OCR as a character or word-level\nimage retrieval problem. EffOCR is cheap and sample efficient to train, as the\nmodel only needs to learn characters' visual appearance and not how they are\nused in sequence to form language. Models in the EffOCR model zoo can be\ndeployed off-the-shelf with only a few lines of code. Importantly, EffOCR also\nallows for easy, sample efficient customization with a simple model training\ninterface and minimal labeling requirements due to its sample efficiency. We\nillustrate the utility of EffOCR by cheaply and accurately digitizing 20\nmillion historical U.S. newspaper scans, evaluating zero-shot performance on\nrandomly selected documents from the U.S. National Archives, and accurately\ndigitizing Japanese documents for which all other OCR solutions failed.",
            "author": [
                "Tom Bryan",
                "Jacob Carlson",
                "Abhishek Arora",
                "Melissa Dell"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10050v1",
                "http://arxiv.org/pdf/2310.10050v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL",
                "econ.GN",
                "q-fin.EC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10049v1",
            "title": "FATE-LLM: A Industrial Grade Federated Learning Framework for Large\n  Language Models",
            "updated": "2023-10-16T04:17:13Z",
            "published": "2023-10-16T04:17:13Z",
            "summary": "Large Language Models (LLMs), such as ChatGPT, LLaMA, GLM, and PaLM, have\nexhibited remarkable performances across various tasks in recent years.\nHowever, LLMs face two main challenges in real-world applications. One\nchallenge is that training LLMs consumes vast computing resources, preventing\nLLMs from being adopted by small and medium-sized enterprises with limited\ncomputing resources. Another is that training LLM requires a large amount of\nhigh-quality data, which are often scattered among enterprises. To address\nthese challenges, we propose FATE-LLM, an industrial-grade federated learning\nframework for large language models. FATE-LLM (1) facilitates federated\nlearning for large language models (coined FedLLM); (2) promotes efficient\ntraining of FedLLM using parameter-efficient fine-tuning methods; (3) protects\nthe intellectual property of LLMs; (4) preserves data privacy during training\nand inference through privacy-preserving mechanisms. We release the code of\nFATE-LLM at https://github.com/FederatedAI/FATE-LLM to facilitate the research\nof FedLLM and enable a broad range of industrial applications.",
            "author": [
                "Tao Fan",
                "Yan Kang",
                "Guoqiang Ma",
                "Weijing Chen",
                "Wenbin Wei",
                "Lixin Fan",
                "Qiang Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10049v1",
                "http://arxiv.org/pdf/2310.10049v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10045v1",
            "title": "Symmetrical SyncMap for Imbalanced General Chunking Problems",
            "updated": "2023-10-16T04:03:36Z",
            "published": "2023-10-16T04:03:36Z",
            "summary": "Recently, SyncMap pioneered an approach to learn complex structures from\nsequences as well as adapt to any changes in underlying structures. This is\nachieved by using only nonlinear dynamical equations inspired by neuron group\nbehaviors, i.e., without loss functions. Here we propose Symmetrical SyncMap\nthat goes beyond the original work to show how to create dynamical equations\nand attractor-repeller points which are stable over the long run, even dealing\nwith imbalanced continual general chunking problems (CGCPs). The main idea is\nto apply equal updates from negative and positive feedback loops by symmetrical\nactivation. We then introduce the concept of memory window to allow for more\npositive updates. Our algorithm surpasses or ties other unsupervised\nstate-of-the-art baselines in all 12 imbalanced CGCPs with various\ndifficulties, including dynamically changing ones. To verify its performance in\nreal-world scenarios, we conduct experiments on several well-studied structure\nlearning problems. The proposed method surpasses substantially other methods in\n3 out of 4 scenarios, suggesting that symmetrical activation plays a critical\nrole in uncovering topological structures and even hierarchies encoded in\ntemporal data.",
            "author": [
                "Heng Zhang",
                "Danilo Vasconcellos Vargas"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.physd.2023.133923",
                "http://arxiv.org/abs/2310.10045v1",
                "http://arxiv.org/pdf/2310.10045v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10039v1",
            "title": "TpopT: Efficient Trainable Template Optimization on Low-Dimensional\n  Manifolds",
            "updated": "2023-10-16T03:51:13Z",
            "published": "2023-10-16T03:51:13Z",
            "summary": "In scientific and engineering scenarios, a recurring task is the detection of\nlow-dimensional families of signals or patterns. A classic family of\napproaches, exemplified by template matching, aims to cover the search space\nwith a dense template bank. While simple and highly interpretable, it suffers\nfrom poor computational efficiency due to unfavorable scaling in the signal\nspace dimensionality. In this work, we study TpopT (TemPlate OPTimization) as\nan alternative scalable framework for detecting low-dimensional families of\nsignals which maintains high interpretability. We provide a theoretical\nanalysis of the convergence of Riemannian gradient descent for TpopT, and prove\nthat it has a superior dimension scaling to covering. We also propose a\npractical TpopT framework for nonparametric signal sets, which incorporates\ntechniques of embedding and kernel interpolation, and is further configurable\ninto a trainable network architecture by unrolled optimization. The proposed\ntrainable TpopT exhibits significantly improved efficiency-accuracy tradeoffs\nfor gravitational wave detection, where matched filtering is currently a method\nof choice. We further illustrate the general applicability of this approach\nwith experiments on handwritten digit data.",
            "author": [
                "Jingkai Yan",
                "Shiyu Wang",
                "Xinyu Rain Wei",
                "Jimmy Wang",
                "Zsuzsanna M\u00e1rka",
                "Szabolcs M\u00e1rka",
                "John Wright"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10039v1",
                "http://arxiv.org/pdf/2310.10039v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10038v1",
            "title": "Smart City Transportation: Deep Learning Ensemble Approach for Traffic\n  Accident Detection",
            "updated": "2023-10-16T03:47:08Z",
            "published": "2023-10-16T03:47:08Z",
            "summary": "The dynamic and unpredictable nature of road traffic necessitates effective\naccident detection methods for enhancing safety and streamlining traffic\nmanagement in smart cities. This paper offers a comprehensive exploration study\nof prevailing accident detection techniques, shedding light on the nuances of\nother state-of-the-art methodologies while providing a detailed overview of\ndistinct traffic accident types like rear-end collisions, T-bone collisions,\nand frontal impact accidents. Our novel approach introduces the I3D-CONVLSTM2D\nmodel architecture, a lightweight solution tailored explicitly for accident\ndetection in smart city traffic surveillance systems by integrating RGB frames\nwith optical flow information. Our experimental study's empirical analysis\nunderscores our approach's efficacy, with the I3D-CONVLSTM2D RGB + Optical-Flow\n(Trainable) model outperforming its counterparts, achieving an impressive 87\\%\nMean Average Precision (MAP). Our findings further elaborate on the challenges\nposed by data imbalances, particularly when working with a limited number of\ndatasets, road structures, and traffic scenarios. Ultimately, our research\nilluminates the path towards a sophisticated vision-based accident detection\nsystem primed for real-time integration into edge IoT devices within smart\nurban infrastructures.",
            "author": [
                "Victor Adewopo",
                "Nelly Elsayed"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10038v1",
                "http://arxiv.org/pdf/2310.10038v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10036v1",
            "title": "Evading Detection Actively: Toward Anti-Forensics against Forgery\n  Localization",
            "updated": "2023-10-16T03:44:10Z",
            "published": "2023-10-16T03:44:10Z",
            "summary": "Anti-forensics seeks to eliminate or conceal traces of tampering artifacts.\nTypically, anti-forensic methods are designed to deceive binary detectors and\npersuade them to misjudge the authenticity of an image. However, to the best of\nour knowledge, no attempts have been made to deceive forgery detectors at the\npixel level and mis-locate forged regions. Traditional adversarial attack\nmethods cannot be directly used against forgery localization due to the\nfollowing defects: 1) they tend to just naively induce the target forensic\nmodels to flip their pixel-level pristine or forged decisions; 2) their\nanti-forensics performance tends to be severely degraded when faced with the\nunseen forensic models; 3) they lose validity once the target forensic models\nare retrained with the anti-forensics images generated by them. To tackle the\nthree defects, we propose SEAR (Self-supErvised Anti-foRensics), a novel\nself-supervised and adversarial training algorithm that effectively trains\ndeep-learning anti-forensic models against forgery localization. SEAR sets a\npretext task to reconstruct perturbation for self-supervised learning. In\nadversarial training, SEAR employs a forgery localization model as a supervisor\nto explore tampering features and constructs a deep-learning concealer to erase\ncorresponding traces. We have conducted largescale experiments across diverse\ndatasets. The experimental results demonstrate that, through the combination of\nself-supervised learning and adversarial learning, SEAR successfully deceives\nthe state-of-the-art forgery localization methods, as well as tackle the three\ndefects regarding traditional adversarial attack methods mentioned above.",
            "author": [
                "Long Zhuo",
                "Shenghai Luo",
                "Shunquan Tan",
                "Han Chen",
                "Bin Li",
                "Jiwu Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10036v1",
                "http://arxiv.org/pdf/2310.10036v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10030v2",
            "title": "Unraveling Fundamental Properties of Power System Resilience Curves\n  using Unsupervised Machine Learning",
            "updated": "2023-11-01T20:13:47Z",
            "published": "2023-10-16T03:16:21Z",
            "summary": "The standard model of infrastructure resilience, the resilience triangle, has\nbeen the primary way of characterizing and quantifying infrastructure\nresilience. However, the theoretical model merely provides a one-size-fits-all\nframework for all infrastructure systems. Most of the existing studies examine\nthe characteristics of infrastructure resilience curves based on analytical\nmodels constructed upon simulated system performance. Limited empirical studies\nhindered our ability to fully understand and predict resilience characteristics\nin infrastructure systems. To address this gap, this study examined over 200\nresilience curves related to power outages in three major extreme weather\nevents. Using unsupervised machine learning, we examined different curve\narchetypes, as well as the fundamental properties of each resilience curve\narchetype. The results show two primary archetypes for power system resilience\ncurves, triangular, and trapezoidal curves. Triangular curves characterize\nresilience behavior based on 1. critical functionality threshold, 2. critical\nfunctionality recovery rate, and 3. recovery pivot point. Trapezoidal\narchetypes explain resilience curves based on 1. duration of sustained function\nloss and 2. constant recovery rate. The longer the duration of sustained\nfunction loss, the slower the constant rate of recovery. The findings of this\nstudy provide novel perspectives enabling better understanding and prediction\nof resilience performance of power system infrastructures.",
            "author": [
                "Bo Li",
                "Ali Mostafavi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10030v2",
                "http://arxiv.org/pdf/2310.10030v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10026v1",
            "title": "Real-time Speech Enhancement and Separation with a Unified Deep Neural\n  Network for Single/Dual Talker Scenarios",
            "updated": "2023-10-16T03:02:29Z",
            "published": "2023-10-16T03:02:29Z",
            "summary": "This paper introduces a practical approach for leveraging a real-time deep\nlearning model to alternate between speech enhancement and joint speech\nenhancement and separation depending on whether the input mixture contains one\nor two active speakers. Scale-invariant signal-to-distortion ratio (SI-SDR) has\nshown to be a highly effective training measure in time-domain speech\nseparation. However, the SI-SDR metric is ill-defined for zero-energy target\nsignals, which is a problem when training a speech separation model using\nutterances with varying numbers of talkers. Unlike existing solutions that\nfocus on modifying the loss function to accommodate zero-energy target signals,\nthe proposed approach circumvents this problem by training the model to extract\nspeech on both its output channels regardless if the input is a single or\ndual-talker mixture. A lightweight speaker overlap detection (SOD) module is\nalso introduced to differentiate between single and dual-talker segments in\nreal-time. The proposed module takes advantage of the new formulation by\noperating directly on the separated masks, given by the separation model,\ninstead of the original mixture, thus effectively simplifying the detection\ntask. Experimental results show that the proposed training approach outperforms\nexisting solutions, and the SOD module exhibits high accuracy.",
            "author": [
                "Kashyap Patel",
                "Anton Kovalyov",
                "Issa Panahi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10026v1",
                "http://arxiv.org/pdf/2310.10026v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10025v1",
            "title": "Dual-Scale Interest Extraction Framework with Self-Supervision for\n  Sequential Recommendation",
            "updated": "2023-10-16T03:00:17Z",
            "published": "2023-10-16T03:00:17Z",
            "summary": "In the sequential recommendation task, the recommender generally learns\nmultiple embeddings from a user's historical behaviors, to catch the diverse\ninterests of the user. Nevertheless, the existing approaches just extract each\ninterest independently for the corresponding sub-sequence while ignoring the\nglobal correlation of the entire interaction sequence, which may fail to\ncapture the user's inherent preference for the potential interests\ngeneralization and unavoidably make the recommended items homogeneous with the\nhistorical behaviors. In this paper, we propose a novel Dual-Scale Interest\nExtraction framework (DSIE) to precisely estimate the user's current interests.\nSpecifically, DSIE explicitly models the user's inherent preference with\ncontrastive learning by attending over his/her entire interaction sequence at\nthe global scale and catches the user's diverse interests in a fine granularity\nat the local scale. Moreover, we develop a novel interest aggregation module to\nintegrate the multi-interests according to the inherent preference to generate\nthe user's current interests for the next-item prediction. Experiments\nconducted on three real-world benchmark datasets demonstrate that DSIE\noutperforms the state-of-the-art models in terms of recommendation preciseness\nand novelty.",
            "author": [
                "Liangliang Chen",
                "Hongzhan Lin",
                "Jinshan Ma",
                "Guang Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10025v1",
                "http://arxiv.org/pdf/2310.10025v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10695v1",
            "title": "Data-Driven Score-Based Models for Generating Stable Structures with\n  Adaptive Crystal Cells",
            "updated": "2023-10-16T02:53:24Z",
            "published": "2023-10-16T02:53:24Z",
            "summary": "The discovery of new functional and stable materials is a big challenge due\nto its complexity. This work aims at the generation of new crystal structures\nwith desired properties, such as chemical stability and specified chemical\ncomposition, by using machine learning generative models. Compared to the\ngeneration of molecules, crystal structures pose new difficulties arising from\nthe periodic nature of the crystal and from the specific symmetry constraints\nrelated to the space group. In this work, score-based probabilistic models\nbased on annealed Langevin dynamics, which have shown excellent performance in\nvarious applications, are adapted to the task of crystal generation. The\nnovelty of the presented approach resides in the fact that the lattice of the\ncrystal cell is not fixed. During the training of the model, the lattice is\nlearned from the available data, whereas during the sampling of a new chemical\nstructure, two denoising processes are used in parallel to generate the lattice\nalong the generation of the atomic positions. A multigraph crystal\nrepresentation is introduced that respects symmetry constraints, yielding\ncomputational advantages and a better quality of the sampled structures. We\nshow that our model is capable of generating new candidate structures in any\nchosen chemical system and crystal group without any additional training. To\nillustrate the functionality of the proposed method, a comparison of our model\nto other recent generative models, based on descriptor-based metrics, is\nprovided.",
            "author": [
                "Arsen Sultanov",
                "Jean-Claude Crivello",
                "Tabea Rebafka",
                "Nataliya Sokolovska"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10695v1",
                "http://arxiv.org/pdf/2310.10695v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10021v2",
            "title": "Bootstrap Your Own Skills: Learning to Solve New Tasks with Large\n  Language Model Guidance",
            "updated": "2023-10-17T12:01:17Z",
            "published": "2023-10-16T02:43:47Z",
            "summary": "We propose BOSS, an approach that automatically learns to solve new\nlong-horizon, complex, and meaningful tasks by growing a learned skill library\nwith minimal supervision. Prior work in reinforcement learning require expert\nsupervision, in the form of demonstrations or rich reward functions, to learn\nlong-horizon tasks. Instead, our approach BOSS (BOotStrapping your own Skills)\nlearns to accomplish new tasks by performing \"skill bootstrapping,\" where an\nagent with a set of primitive skills interacts with the environment to practice\nnew skills without receiving reward feedback for tasks outside of the initial\nskill set. This bootstrapping phase is guided by large language models (LLMs)\nthat inform the agent of meaningful skills to chain together. Through this\nprocess, BOSS builds a wide range of complex and useful behaviors from a basic\nset of primitive skills. We demonstrate through experiments in realistic\nhousehold environments that agents trained with our LLM-guided bootstrapping\nprocedure outperform those trained with naive bootstrapping as well as prior\nunsupervised skill acquisition methods on zero-shot execution of unseen,\nlong-horizon tasks in new environments. Website at clvrai.com/boss.",
            "author": [
                "Jesse Zhang",
                "Jiahui Zhang",
                "Karl Pertsch",
                "Ziyi Liu",
                "Xiang Ren",
                "Minsuk Chang",
                "Shao-Hua Sun",
                "Joseph J. Lim"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10021v2",
                "http://arxiv.org/pdf/2310.10021v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10015v1",
            "title": "The Reality of the Situation: A Survey of Situated Analytics",
            "updated": "2023-10-16T02:24:07Z",
            "published": "2023-10-16T02:24:07Z",
            "summary": "The advent of low cost, accessible, and high performance augmented reality\n(AR) has shed light on a situated form of analytics where in-situ\nvisualizations embedded in the real world can facilitate sensemaking based on\nthe user's physical location. In this work, we identify prior literature in\nthis emerging field with a focus on situated analytics. After collecting 47\nrelevant situated analytics systems, we classify them using a taxonomy of three\ndimensions: situating triggers, view situatedness, and data depiction. We then\nidentify four archetypical patterns in our classification using an ensemble\ncluster analysis. We also assess the level which these systems support the\nsensemaking process. Finally, we discuss insights and design guidelines that we\nlearned from our analysis.",
            "author": [
                "Sungbok Shin",
                "Andrea Batch",
                "Peter W. S. Butcher",
                "Panagiotis D. Ritsos",
                "Niklas Elmqvist"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TVCG.2023.3285546",
                "http://arxiv.org/abs/2310.10015v1",
                "http://arxiv.org/pdf/2310.10015v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10013v1",
            "title": "Riemannian Residual Neural Networks",
            "updated": "2023-10-16T02:12:32Z",
            "published": "2023-10-16T02:12:32Z",
            "summary": "Recent methods in geometric deep learning have introduced various neural\nnetworks to operate over data that lie on Riemannian manifolds. Such networks\nare often necessary to learn well over graphs with a hierarchical structure or\nto learn over manifold-valued data encountered in the natural sciences. These\nnetworks are often inspired by and directly generalize standard Euclidean\nneural networks. However, extending Euclidean networks is difficult and has\nonly been done for a select few manifolds. In this work, we examine the\nresidual neural network (ResNet) and show how to extend this construction to\ngeneral Riemannian manifolds in a geometrically principled manner. Originally\nintroduced to help solve the vanishing gradient problem, ResNets have become\nubiquitous in machine learning due to their beneficial learning properties,\nexcellent empirical results, and easy-to-incorporate nature when building\nvaried neural networks. We find that our Riemannian ResNets mirror these\ndesirable properties: when compared to existing manifold neural networks\ndesigned to learn over hyperbolic space and the manifold of symmetric positive\ndefinite matrices, we outperform both kinds of networks in terms of relevant\ntesting metrics and training dynamics.",
            "author": [
                "Isay Katsman",
                "Eric Ming Chen",
                "Sidhanth Holalkere",
                "Anna Asch",
                "Aaron Lou",
                "Ser-Nam Lim",
                "Christopher De Sa"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10013v1",
                "http://arxiv.org/pdf/2310.10013v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10012v1",
            "title": "Ring-A-Bell! How Reliable are Concept Removal Methods for Diffusion\n  Models?",
            "updated": "2023-10-16T02:11:20Z",
            "published": "2023-10-16T02:11:20Z",
            "summary": "Diffusion models for text-to-image (T2I) synthesis, such as Stable Diffusion\n(SD), have recently demonstrated exceptional capabilities for generating\nhigh-quality content. However, this progress has raised several concerns of\npotential misuse, particularly in creating copyrighted, prohibited, and\nrestricted content, or NSFW (not safe for work) images. While efforts have been\nmade to mitigate such problems, either by implementing a safety filter at the\nevaluation stage or by fine-tuning models to eliminate undesirable concepts or\nstyles, the effectiveness of these safety measures in dealing with a wide range\nof prompts remains largely unexplored. In this work, we aim to investigate\nthese safety mechanisms by proposing one novel concept retrieval algorithm for\nevaluation. We introduce Ring-A-Bell, a model-agnostic red-teaming tool for T2I\ndiffusion models, where the whole evaluation can be prepared in advance without\nprior knowledge of the target model. Specifically, Ring-A-Bell first performs\nconcept extraction to obtain holistic representations for sensitive and\ninappropriate concepts. Subsequently, by leveraging the extracted concept,\nRing-A-Bell automatically identifies problematic prompts for diffusion models\nwith the corresponding generation of inappropriate content, allowing the user\nto assess the reliability of deployed safety mechanisms. Finally, we\nempirically validate our method by testing online services such as Midjourney\nand various methods of concept removal. Our results show that Ring-A-Bell, by\nmanipulating safe prompting benchmarks, can transform prompts that were\noriginally regarded as safe to evade existing safety mechanisms, thus revealing\nthe defects of the so-called safety mechanisms which could practically lead to\nthe generation of harmful contents.",
            "author": [
                "Yu-Lin Tsai",
                "Chia-Yi Hsu",
                "Chulin Xie",
                "Chih-Hsun Lin",
                "Jia-You Chen",
                "Bo Li",
                "Pin-Yu Chen",
                "Chia-Mu Yu",
                "Chun-Ying Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10012v1",
                "http://arxiv.org/pdf/2310.10012v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10008v1",
            "title": "Towards Unified and Effective Domain Generalization",
            "updated": "2023-10-16T02:05:03Z",
            "published": "2023-10-16T02:05:03Z",
            "summary": "We propose $\\textbf{UniDG}$, a novel and $\\textbf{Uni}$fied framework for\n$\\textbf{D}$omain $\\textbf{G}$eneralization that is capable of significantly\nenhancing the out-of-distribution generalization performance of foundation\nmodels regardless of their architectures. The core idea of UniDG is to finetune\nmodels during the inference stage, which saves the cost of iterative training.\nSpecifically, we encourage models to learn the distribution of test data in an\nunsupervised manner and impose a penalty regarding the updating step of model\nparameters. The penalty term can effectively reduce the catastrophic forgetting\nissue as we would like to maximally preserve the valuable knowledge in the\noriginal model. Empirically, across 12 visual backbones, including CNN-, MLP-,\nand Transformer-based models, ranging from 1.89M to 303M parameters, UniDG\nshows an average accuracy improvement of +5.4% on DomainBed. These performance\nresults demonstrate the superiority and versatility of UniDG. The code is\npublicly available at https://github.com/invictus717/UniDG",
            "author": [
                "Yiyuan Zhang",
                "Kaixiong Gong",
                "Xiaohan Ding",
                "Kaipeng Zhang",
                "Fangrui Lv",
                "Kurt Keutzer",
                "Xiangyu Yue"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10008v1",
                "http://arxiv.org/pdf/2310.10008v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10006v1",
            "title": "Implicit regularization via soft ascent-descent",
            "updated": "2023-10-16T02:02:56Z",
            "published": "2023-10-16T02:02:56Z",
            "summary": "As models grow larger and more complex, achieving better off-sample\ngeneralization with minimal trial-and-error is critical to the reliability and\neconomy of machine learning workflows. As a proxy for the well-studied\nheuristic of seeking \"flat\" local minima, gradient regularization is a natural\navenue, and first-order approximations such as Flooding and sharpness-aware\nminimization (SAM) have received significant attention, but their performance\ndepends critically on hyperparameters (flood threshold and neighborhood radius,\nrespectively) that are non-trivial to specify in advance. In order to develop a\nprocedure which is more resilient to misspecified hyperparameters, with the\nhard-threshold \"ascent-descent\" switching device used in Flooding as\nmotivation, we propose a softened, pointwise mechanism called SoftAD that\ndownweights points on the borderline, limits the effects of outliers, and\nretains the ascent-descent effect. We contrast formal stationarity guarantees\nwith those for Flooding, and empirically demonstrate how SoftAD can realize\nclassification accuracy competitive with SAM and Flooding while maintaining a\nmuch smaller loss generalization gap and model norm. Our empirical tests range\nfrom simple binary classification on the plane to image classification using\nneural networks with millions of parameters; the key trends are observed across\nall datasets and models studied, and suggest a potential new approach to\nimplicit regularization.",
            "author": [
                "Matthew J. Holland",
                "Kosuke Nakatani"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10006v1",
                "http://arxiv.org/pdf/2310.10006v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10003v1",
            "title": "Conformal Contextual Robust Optimization",
            "updated": "2023-10-16T01:58:27Z",
            "published": "2023-10-16T01:58:27Z",
            "summary": "Data-driven approaches to predict-then-optimize decision-making problems seek\nto mitigate the risk of uncertainty region misspecification in safety-critical\nsettings. Current approaches, however, suffer from considering overly\nconservative uncertainty regions, often resulting in suboptimal decisionmaking.\nTo this end, we propose Conformal-Predict-Then-Optimize (CPO), a framework for\nleveraging highly informative, nonconvex conformal prediction regions over\nhigh-dimensional spaces based on conditional generative models, which have the\ndesired distribution-free coverage guarantees. Despite guaranteeing robustness,\nsuch black-box optimization procedures alone inspire little confidence owing to\nthe lack of explanation of why a particular decision was found to be optimal.\nWe, therefore, augment CPO to additionally provide semantically meaningful\nvisual summaries of the uncertainty regions to give qualitative intuition for\nthe optimal decision. We highlight the CPO framework by demonstrating results\non a suite of simulation-based inference benchmark tasks and a vehicle routing\ntask based on probabilistic weather prediction.",
            "author": [
                "Yash Patel",
                "Sahana Rayan",
                "Ambuj Tewari"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10003v1",
                "http://arxiv.org/pdf/2310.10003v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10002v1",
            "title": "Assessing Encoder-Decoder Architectures for Robust Coronary Artery\n  Segmentation",
            "updated": "2023-10-16T01:55:37Z",
            "published": "2023-10-16T01:55:37Z",
            "summary": "Coronary artery diseases are among the leading causes of mortality worldwide.\nTimely and accurate diagnosis, facilitated by precise coronary artery\nsegmentation, is pivotal in changing patient outcomes. In the realm of\nbiomedical imaging, convolutional neural networks, especially the U-Net\narchitecture, have revolutionised segmentation processes. However, one of the\nprimary challenges remains the lack of benchmarking datasets specific to\ncoronary arteries. However through the use of the recently published public\ndataset ASOCA, the potential of deep learning for accurate coronary\nsegmentation can be improved. This paper delves deep into examining the\nperformance of 25 distinct encoder-decoder combinations. Through analysis of\nthe 40 cases provided to ASOCA participants, it is revealed that the\nEfficientNet-LinkNet combination, serving as encoder and decoder, stands out.\nIt achieves a Dice coefficient of 0.882 and a 95th percentile Hausdorff\ndistance of 4.753. These findings not only underscore the superiority of our\nmodel in comparison to those presented at the MICCAI 2020 challenge but also\nset the stage for future advancements in coronary artery segmentation, opening\ndoors to enhanced diagnostic and treatment strategies.",
            "author": [
                "Shisheng Zhang",
                "Ramtin Gharleghi",
                "Sonit Singh",
                "Arcot Sowmya",
                "Susann Beier"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10002v1",
                "http://arxiv.org/pdf/2310.10002v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09999v1",
            "title": "Outlier Detection Using Generative Models with Theoretical Performance\n  Guarantees",
            "updated": "2023-10-16T01:25:34Z",
            "published": "2023-10-16T01:25:34Z",
            "summary": "This paper considers the problem of recovering signals modeled by generative\nmodels from linear measurements contaminated with sparse outliers. We propose\nan outlier detection approach for reconstructing the ground-truth signals\nmodeled by generative models under sparse outliers. We establish theoretical\nrecovery guarantees for reconstruction of signals using generative models in\nthe presence of outliers, giving lower bounds on the number of correctable\noutliers. Our results are applicable to both linear generator neural networks\nand the nonlinear generator neural networks with an arbitrary number of layers.\nWe propose an iterative alternating direction method of multipliers (ADMM)\nalgorithm for solving the outlier detection problem via $\\ell_1$ norm\nminimization, and a gradient descent algorithm for solving the outlier\ndetection problem via squared $\\ell_1$ norm minimization. We conduct extensive\nexperiments using variational auto-encoder and deep convolutional generative\nadversarial networks, and the experimental results show that the signals can be\nsuccessfully reconstructed under outliers using our approach. Our approach\noutperforms the traditional Lasso and $\\ell_2$ minimization approach.",
            "author": [
                "Jirong Yi",
                "Jingchao Gao",
                "Tianming Wang",
                "Xiaodong Wu",
                "Weiyu Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09999v1",
                "http://arxiv.org/pdf/2310.09999v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09998v3",
            "title": "SeUNet-Trans: A Simple yet Effective UNet-Transformer Model for Medical\n  Image Segmentation",
            "updated": "2023-11-10T15:01:01Z",
            "published": "2023-10-16T01:13:38Z",
            "summary": "Automated medical image segmentation is becoming increasingly crucial to\nmodern clinical practice, driven by the growing demand for precise diagnosis,\nthe push towards personalized treatment plans, and the advancements in machine\nlearning algorithms, especially the incorporation of deep learning methods.\nWhile convolutional neural networks (CNN) have been prevalent among these\nmethods, the remarkable potential of Transformer-based models for computer\nvision tasks is gaining more acknowledgment. To harness the advantages of both\nCNN-based and Transformer-based models, we propose a simple yet effective\nUNet-Transformer (seUNet-Trans) model for medical image segmentation. In our\napproach, the UNet model is designed as a feature extractor to generate\nmultiple feature maps from the input images, then the maps are propagated into\na bridge layer, which is introduced to sequentially connect the UNet and the\nTransformer. In this stage, we approach the pixel-level embedding technique\nwithout position embedding vectors, aiming to make the model more efficient.\nMoreover, we apply spatial-reduction attention in the Transformer to reduce the\ncomputational/memory overhead. By leveraging the UNet architecture and the\nself-attention mechanism, our model not only retains the preservation of both\nlocal and global context information but also is capable of capturing\nlong-range dependencies between input elements. The proposed model is\nextensively experimented on seven medical image segmentation datasets including\npolyp segmentation to demonstrate its efficacy. Comparison with several\nstate-of-the-art segmentation models on these datasets shows the superior\nperformance of our proposed seUNet-Trans network.",
            "author": [
                "Tan-Hanh Pham",
                "Xianqi Li",
                "Kim-Doang Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09998v3",
                "http://arxiv.org/pdf/2310.09998v3"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09997v1",
            "title": "Forecaster: Towards Temporally Abstract Tree-Search Planning from Pixels",
            "updated": "2023-10-16T01:13:26Z",
            "published": "2023-10-16T01:13:26Z",
            "summary": "The ability to plan at many different levels of abstraction enables agents to\nenvision the long-term repercussions of their decisions and thus enables\nsample-efficient learning. This becomes particularly beneficial in complex\nenvironments from high-dimensional state space such as pixels, where the goal\nis distant and the reward sparse. We introduce Forecaster, a deep hierarchical\nreinforcement learning approach which plans over high-level goals leveraging a\ntemporally abstract world model. Forecaster learns an abstract model of its\nenvironment by modelling the transitions dynamics at an abstract level and\ntraining a world model on such transition. It then uses this world model to\nchoose optimal high-level goals through a tree-search planning procedure. It\nadditionally trains a low-level policy that learns to reach those goals. Our\nmethod not only captures building world models with longer horizons, but also,\nplanning with such models in downstream tasks. We empirically demonstrate\nForecaster's potential in both single-task learning and generalization to new\ntasks in the AntMaze domain.",
            "author": [
                "Thomas Jiralerspong",
                "Flemming Kondrup",
                "Doina Precup",
                "Khimya Khetarpal"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09997v1",
                "http://arxiv.org/pdf/2310.09997v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09994v1",
            "title": "A Survey of Graph and Attention Based Hyperspectral Image Classification\n  Methods for Remote Sensing Data",
            "updated": "2023-10-16T00:42:25Z",
            "published": "2023-10-16T00:42:25Z",
            "summary": "The use of Deep Learning techniques for classification in Hyperspectral\nImaging (HSI) is rapidly growing and achieving improved performances. Due to\nthe nature of the data captured by sensors that produce HSI images, a common\nissue is the dimensionality of the bands that may or may not contribute to the\nlabel class distinction. Due to the widespread nature of class labels,\nPrincipal Component Analysis is a common method used for reducing the\ndimensionality. However,there may exist methods that incorporate all bands of\nthe Hyperspectral image with the help of the Attention mechanism. Furthermore,\nto yield better spectral spatial feature extraction, recent methods have also\nexplored the usage of Graph Convolution Networks and their unique ability to\nuse node features in prediction, which is akin to the pixel spectral makeup. In\nthis survey we present a comprehensive summary of Graph based and Attention\nbased methods to perform Hyperspectral Image Classification for remote sensing\nand aerial HSI images. We also summarize relevant datasets on which these\ntechniques have been evaluated and benchmark the processing techniques.",
            "author": [
                "Aryan Vats",
                "Manan Suri"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09994v1",
                "http://arxiv.org/pdf/2310.09994v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10693v1",
            "title": "Network Analysis of the iNaturalist Citizen Science Community",
            "updated": "2023-10-16T00:41:13Z",
            "published": "2023-10-16T00:41:13Z",
            "summary": "In recent years, citizen science has become a larger and larger part of the\nscientific community. Its ability to crowd source data and expertise from\nthousands of citizen scientists makes it invaluable. Despite the field's\ngrowing popularity, the interactions and structure of citizen science projects\nare still poorly understood and under analyzed. We use the iNaturalist citizen\nscience platform as a case study to analyze the structure of citizen science\nprojects. We frame the data from iNaturalist as a bipartite network and use\nvisualizations as well as established network science techniques to gain\ninsights into the structure and interactions between users in citizen science\nprojects. Finally, we propose a novel unique benchmark for network science\nresearch by using the iNaturalist data to create a network which has an unusual\nstructure relative to other common benchmark networks. We demonstrate using a\nlink prediction task that this network can be used to gain novel insights into\na variety of network science methods.",
            "author": [
                "Yu Lu Liu",
                "Thomas Jiralerspong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10693v1",
                "http://arxiv.org/pdf/2310.10693v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09991v1",
            "title": "Applications of Machine Learning in Biopharmaceutical Process\n  Development and Manufacturing: Current Trends, Challenges, and Opportunities",
            "updated": "2023-10-16T00:35:24Z",
            "published": "2023-10-16T00:35:24Z",
            "summary": "While machine learning (ML) has made significant contributions to the\nbiopharmaceutical field, its applications are still in the early stages in\nterms of providing direct support for quality-by-design based development and\nmanufacturing of biopharmaceuticals, hindering the enormous potential for\nbioprocesses automation from their development to manufacturing. However, the\nadoption of ML-based models instead of conventional multivariate data analysis\nmethods is significantly increasing due to the accumulation of large-scale\nproduction data. This trend is primarily driven by the real-time monitoring of\nprocess variables and quality attributes of biopharmaceutical products through\nthe implementation of advanced process analytical technologies. Given the\ncomplexity and multidimensionality of a bioproduct design, bioprocess\ndevelopment, and product manufacturing data, ML-based approaches are\nincreasingly being employed to achieve accurate, flexible, and high-performing\npredictive models to address the problems of analytics, monitoring, and control\nwithin the biopharma field. This paper aims to provide a comprehensive review\nof the current applications of ML solutions in a bioproduct design, monitoring,\ncontrol, and optimisation of upstream, downstream, and product formulation\nprocesses. Finally, this paper thoroughly discusses the main challenges related\nto the bioprocesses themselves, process data, and the use of machine learning\nmodels in biopharmaceutical process development and manufacturing. Moreover, it\noffers further insights into the adoption of innovative machine learning\nmethods and novel trends in the development of new digital biopharma solutions.",
            "author": [
                "Thanh Tung Khuat",
                "Robert Bassett",
                "Ellen Otte",
                "Alistair Grevis-James",
                "Bogdan Gabrys"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09991v1",
                "http://arxiv.org/pdf/2310.09991v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "A.1; J.3; I.2.0; I.2.6; I.2.m; I.5.4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09988v1",
            "title": "Personalization of CTC-based End-to-End Speech Recognition Using\n  Pronunciation-Driven Subword Tokenization",
            "updated": "2023-10-16T00:06:32Z",
            "published": "2023-10-16T00:06:32Z",
            "summary": "Recent advances in deep learning and automatic speech recognition have\nimproved the accuracy of end-to-end speech recognition systems, but recognition\nof personal content such as contact names remains a challenge. In this work, we\ndescribe our personalization solution for an end-to-end speech recognition\nsystem based on connectionist temporal classification. Building on previous\nwork, we present a novel method for generating additional subword tokenizations\nfor personal entities from their pronunciations. We show that using this\ntechnique in combination with two established techniques, contextual biasing\nand wordpiece prior normalization, we are able to achieve personal named entity\naccuracy on par with a competitive hybrid system.",
            "author": [
                "Zhihong Lei",
                "Ernest Pusateri",
                "Shiyi Han",
                "Leo Liu",
                "Mingbin Xu",
                "Tim Ng",
                "Ruchir Travadi",
                "Youyuan Zhang",
                "Mirko Hannemann",
                "Man-Hung Siu",
                "Zhen Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09988v1",
                "http://arxiv.org/pdf/2310.09988v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09986v2",
            "title": "On Statistical Learning of Branch and Bound for Vehicle Routing\n  Optimization",
            "updated": "2023-10-17T17:50:36Z",
            "published": "2023-10-15T23:59:57Z",
            "summary": "Recently, machine learning of the branch and bound algorithm has shown\npromise in approximating competent solutions to NP-hard problems. In this\npaper, we utilize and comprehensively compare the outcomes of three neural\nnetworks--graph convolutional neural network (GCNN), GraphSAGE, and graph\nattention network (GAT)--to solve the capacitated vehicle routing problem. We\ntrain these neural networks to emulate the decision-making process of the\ncomputationally expensive Strong Branching strategy. The neural networks are\ntrained on six instances with distinct topologies from the CVRPLIB and\nevaluated on eight additional instances. Moreover, we reduced the minimum\nnumber of vehicles required to solve a CVRP instance to a bin-packing problem,\nwhich was addressed in a similar manner. Through rigorous experimentation, we\nfound that this approach can match or improve upon the performance of the\nbranch and bound algorithm with the Strong Branching strategy while requiring\nsignificantly less computational time. The source code that corresponds to our\nresearch findings and methodology is readily accessible and available for\nreference at the following web address: https://isotlaboratory.github.io/ml4vrp",
            "author": [
                "Andrew Naguib",
                "Waleed A. Yousef",
                "Issa Traor\u00e9",
                "Mohammad Mamun"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09986v2",
                "http://arxiv.org/pdf/2310.09986v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09983v1",
            "title": "Farzi Data: Autoregressive Data Distillation",
            "updated": "2023-10-15T23:23:27Z",
            "published": "2023-10-15T23:23:27Z",
            "summary": "We study data distillation for auto-regressive machine learning tasks, where\nthe input and output have a strict left-to-right causal structure. More\nspecifically, we propose Farzi, which summarizes an event sequence dataset into\na small number of synthetic sequences -- Farzi Data -- which are optimized to\nmaintain (if not improve) model performance compared to training on the full\ndataset. Under the hood, Farzi conducts memory-efficient data distillation by\n(i) deriving efficient reverse-mode differentiation of the Adam optimizer by\nleveraging Hessian-Vector Products; and (ii) factorizing the high-dimensional\ndiscrete event-space into a latent-space which provably promotes implicit\nregularization. Empirically, for sequential recommendation and language\nmodeling tasks, we are able to achieve 98-120% of downstream full-data\nperformance when training state-of-the-art models on Farzi Data of size as\nlittle as 0.1% of the original dataset. Notably, being able to train better\nmodels with significantly less data sheds light on the design of future large\nauto-regressive models, and opens up new opportunities to further scale up\nmodel and data sizes.",
            "author": [
                "Noveen Sachdeva",
                "Zexue He",
                "Wang-Cheng Kang",
                "Jianmo Ni",
                "Derek Zhiyuan Cheng",
                "Julian McAuley"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09983v1",
                "http://arxiv.org/pdf/2310.09983v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09981v1",
            "title": "Class-Specific Data Augmentation: Bridging the Imbalance in Multiclass\n  Breast Cancer Classification",
            "updated": "2023-10-15T23:19:35Z",
            "published": "2023-10-15T23:19:35Z",
            "summary": "Breast Cancer is the most common cancer among women, which is also visible in\nmen, and accounts for more than 1 in 10 new cancer diagnoses each year. It is\nalso the second most common cause of women who die from cancer. Hence, it\nnecessitates early detection and tailored treatment. Early detection can\nprovide appropriate and patient-based therapeutic schedules. Moreover, early\ndetection can also provide the type of cyst. This paper employs class-level\ndata augmentation, addressing the undersampled classes and raising their\ndetection rate. This approach suggests two key components: class-level data\naugmentation on structure-preserving stain normalization techniques to\nhematoxylin and eosin-stained images and transformer-based ViTNet architecture\nvia transfer learning for multiclass classification of breast cancer images.\nThis merger enables categorizing breast cancer images with advanced image\nprocessing and deep learning as either benign or as one of four distinct\nmalignant subtypes by focusing on class-level augmentation and catering to\nunique characteristics of each class with increasing precision of\nclassification on undersampled classes, which leads to lower mortality rates\nassociated with breast cancer. The paper aims to ease the duties of the medical\nspecialist by operating multiclass classification and categorizing the image\ninto benign or one of four different malignant types of breast cancers.",
            "author": [
                "Kanan Mahammadli",
                "Abdullah Burkan Bereketoglu",
                "Ayse Gul Kabakci"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09981v1",
                "http://arxiv.org/pdf/2310.09981v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09978v2",
            "title": "Chinese Painting Style Transfer Using Deep Generative Models",
            "updated": "2023-10-17T18:15:15Z",
            "published": "2023-10-15T23:05:17Z",
            "summary": "Artistic style transfer aims to modify the style of the image while\npreserving its content. Style transfer using deep learning models has been\nwidely studied since 2015, and most of the applications are focused on specific\nartists like Van Gogh, Monet, Cezanne. There are few researches and\napplications on traditional Chinese painting style transfer. In this paper, we\nwill study and leverage different state-of-the-art deep generative models for\nChinese painting style transfer and evaluate the performance both qualitatively\nand quantitatively. In addition, we propose our own algorithm that combines\nseveral style transfer models for our task. Specifically, we will transfer two\nmain types of traditional Chinese painting style, known as \"Gong-bi\" and\n\"Shui-mo\" (to modern images like nature objects, portraits and landscapes.",
            "author": [
                "Weijian Ma",
                "Yanyang Kong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09978v2",
                "http://arxiv.org/pdf/2310.09978v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09971v3",
            "title": "AMAGO: Scalable In-Context Reinforcement Learning for Adaptive Agents",
            "updated": "2023-12-04T18:51:54Z",
            "published": "2023-10-15T22:20:39Z",
            "summary": "We introduce AMAGO, an in-context Reinforcement Learning (RL) agent that uses\nsequence models to tackle the challenges of generalization, long-term memory,\nand meta-learning. Recent works have shown that off-policy learning can make\nin-context RL with recurrent policies viable. Nonetheless, these approaches\nrequire extensive tuning and limit scalability by creating key bottlenecks in\nagents' memory capacity, planning horizon, and model size. AMAGO revisits and\nredesigns the off-policy in-context approach to successfully train\nlong-sequence Transformers over entire rollouts in parallel with end-to-end RL.\nOur agent is uniquely scalable and applicable to a wide range of problems. We\ndemonstrate its strong performance empirically in meta-RL and long-term memory\ndomains. AMAGO's focus on sparse rewards and off-policy data also allows\nin-context learning to extend to goal-conditioned problems with challenging\nexploration. When combined with a novel hindsight relabeling scheme, AMAGO can\nsolve a previously difficult category of open-world domains, where agents\ncomplete many possible instructions in procedurally generated environments. We\nevaluate our agent on three goal-conditioned domains and study how its\nindividual improvements connect to create a generalist policy.",
            "author": [
                "Jake Grigsby",
                "Linxi Fan",
                "Yuke Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09971v3",
                "http://arxiv.org/pdf/2310.09971v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09969v1",
            "title": "Socially Acceptable Bipedal Navigation: A Signal-Temporal-Logic- Driven\n  Approach for Safe Locomotion",
            "updated": "2023-10-15T22:18:28Z",
            "published": "2023-10-15T22:18:28Z",
            "summary": "Social navigation for bipedal robots remains relatively unexplored due to the\nhighly complex, nonlinear dynamics of bipedal locomotion. This study presents a\npreliminary exploration of social navigation for bipedal robots in a human\ncrowded environment. We propose a social path planner that ensures the\nlocomotion safety of the bipedal robot while navigating under a social norm.\nThe proposed planner leverages a conditional variational autoencoder\narchitecture and learns from human crowd datasets to produce a socially\nacceptable path plan. Robot-specific locomotion safety is formally enforced by\nincorporating signal temporal logic specifications during the learning process.\nWe demonstrate the integration of the social path planner with a model\npredictive controller and a low-level passivity controller to enable\ncomprehensive full-body joint control of Digit in a dynamic simulation.",
            "author": [
                "Abdulaziz Shamsah",
                "Ye Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09969v1",
                "http://arxiv.org/pdf/2310.09969v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14788v1",
            "title": "Specialized Deep Residual Policy Safe Reinforcement Learning-Based\n  Controller for Complex and Continuous State-Action Spaces",
            "updated": "2023-10-15T21:53:23Z",
            "published": "2023-10-15T21:53:23Z",
            "summary": "Traditional controllers have limitations as they rely on prior knowledge\nabout the physics of the problem, require modeling of dynamics, and struggle to\nadapt to abnormal situations. Deep reinforcement learning has the potential to\naddress these problems by learning optimal control policies through exploration\nin an environment. For safety-critical environments, it is impractical to\nexplore randomly, and replacing conventional controllers with black-box models\nis also undesirable. Also, it is expensive in continuous state and action\nspaces, unless the search space is constrained. To address these challenges we\npropose a specialized deep residual policy safe reinforcement learning with a\ncycle of learning approach adapted for complex and continuous state-action\nspaces. Residual policy learning allows learning a hybrid control architecture\nwhere the reinforcement learning agent acts in synchronous collaboration with\nthe conventional controller. The cycle of learning initiates the policy through\nthe expert trajectory and guides the exploration around it. Further, the\nspecialization through the input-output hidden Markov model helps to optimize\npolicy that lies within the region of interest (such as abnormality), where the\nreinforcement learning agent is required and is activated. The proposed\nsolution is validated on the Tennessee Eastman process control.",
            "author": [
                "Ammar N. Abbas",
                "Georgios C. Chasparis",
                "John D. Kelleher"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14788v1",
                "http://arxiv.org/pdf/2310.14788v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09961v1",
            "title": "Theoretical Evaluation of Asymmetric Shapley Values for Root-Cause\n  Analysis",
            "updated": "2023-10-15T21:40:16Z",
            "published": "2023-10-15T21:40:16Z",
            "summary": "In this work, we examine Asymmetric Shapley Values (ASV), a variant of the\npopular SHAP additive local explanation method. ASV proposes a way to improve\nmodel explanations incorporating known causal relations between variables, and\nis also considered as a way to test for unfair discrimination in model\npredictions. Unexplored in previous literature, relaxing symmetry in Shapley\nvalues can have counter-intuitive consequences for model explanation. To better\nunderstand the method, we first show how local contributions correspond to\nglobal contributions of variance reduction. Using variance, we demonstrate\nmultiple cases where ASV yields counter-intuitive attributions, arguably\nproducing incorrect results for root-cause analysis. Second, we identify\ngeneralized additive models (GAM) as a restricted class for which ASV exhibits\ndesirable properties. We support our arguments by proving multiple theoretical\nresults about the method. Finally, we demonstrate the use of asymmetric\nattributions on multiple real-world datasets, comparing the results with and\nwithout restricted model families using gradient boosting and deep learning\nmodels.",
            "author": [
                "Domokos M. Kelen",
                "Mih\u00e1ly Petreczky",
                "P\u00e9ter Kersch",
                "Andr\u00e1s A. Bencz\u00far"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09961v1",
                "http://arxiv.org/pdf/2310.09961v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09952v1",
            "title": "Seeking Next Layer Neurons' Attention for Error-Backpropagation-Like\n  Training in a Multi-Agent Network Framework",
            "updated": "2023-10-15T21:07:09Z",
            "published": "2023-10-15T21:07:09Z",
            "summary": "Despite considerable theoretical progress in the training of neural networks\nviewed as a multi-agent system of neurons, particularly concerning biological\nplausibility and decentralized training, their applicability to real-world\nproblems remains limited due to scalability issues. In contrast,\nerror-backpropagation has demonstrated its effectiveness for training deep\nnetworks in practice. In this study, we propose a local objective for neurons\nthat, when pursued by neurons individually, align them to exhibit similarities\nto error-backpropagation in terms of efficiency and scalability during\ntraining. For this purpose, we examine a neural network comprising\ndecentralized, self-interested neurons seeking to maximize their local\nobjective -- attention from subsequent layer neurons -- and identify the\noptimal strategy for neurons. We also analyze the relationship between this\nstrategy and backpropagation, establishing conditions under which the derived\nstrategy is equivalent to error-backpropagation. Lastly, we demonstrate the\nlearning capacity of these multi-agent neural networks through experiments on\nthree datasets and showcase their superior performance relative to\nerror-backpropagation in a catastrophic forgetting benchmark.",
            "author": [
                "Arshia Soltani Moakhar",
                "Mohammad Azizmalayeri",
                "Hossein Mirzaei",
                "Mohammad Taghi Manzuri",
                "Mohammad Hossein Rohban"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09952v1",
                "http://arxiv.org/pdf/2310.09952v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.AI",
                "cs.GT",
                "cs.LG",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09950v1",
            "title": "Heterogeneous anomalous transport in cellular and molecular biology",
            "updated": "2023-10-15T21:00:19Z",
            "published": "2023-10-15T21:00:19Z",
            "summary": "It is well established that a wide variety of phenomena in cellular and\nmolecular biology involve anomalous transport e.g. the statistics for the\nmotility of cells and molecules are fractional and do not conform to the\narchetypes of simple diffusion or ballistic transport. Recent research\ndemonstrates that anomalous transport is in many cases heterogeneous in both\ntime and space. Thus single anomalous exponents and single generalized\ndiffusion coefficients are unable to satisfactorily describe many crucial\nphenomena in cellular and molecular biology. We consider advances in the field\nof heterogeneous anomalous transport (HAT) highlighting: experimental\ntechniques (single molecule methods, microscopy, image analysis, fluorescence\ncorrelation spectroscopy, inelastic neutron scattering, and NMR), theoretical\ntools for data analysis (robust statistical methods such as first passage\nprobabilities, survival analysis, different varieties of mean square\ndisplacements, etc), analytic theory and generative theoretical models based on\nsimulations. Special emphasis is made on high throughput analysis techniques\nbased on machine learning and neural networks. Furthermore, we consider\nanomalous transport in the context of microrheology and the heterogeneous\nviscoelasticity of complex fluids. HAT in the wavefronts of reaction-diffusion\nsystems is also considered since it plays an important role in morphogenesis\nand signalling. In addition, we present specific examples from cellular biology\nincluding embryonic cells, leukocytes, cancer cells, bacterial cells, bacterial\nbiofilms, and eukaryotic microorganisms. Case studies from molecular biology\ninclude DNA, membranes, endosomal transport, endoplasmic reticula, mucins,\nglobular proteins, and amyloids.",
            "author": [
                "Thomas A. Waigh",
                "Nickolay Korabel"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09950v1",
                "http://arxiv.org/pdf/2310.09950v1"
            ],
            "primary_category": "physics.bio-ph",
            "category": [
                "physics.bio-ph",
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09949v3",
            "title": "Chameleon: a heterogeneous and disaggregated accelerator system for\n  retrieval-augmented language models",
            "updated": "2023-11-29T16:34:49Z",
            "published": "2023-10-15T20:57:25Z",
            "summary": "A Retrieval-Augmented Language Model (RALM) augments a generative language\nmodel by retrieving context-specific knowledge from an external database. This\nstrategy facilitates impressive text generation quality even with smaller\nmodels, thus reducing orders of magnitude of computational demands. However,\nRALMs introduce unique system design challenges due to (a) the diverse workload\ncharacteristics between LM inference and retrieval and (b) the various system\nrequirements and bottlenecks for different RALM configurations such as model\nsizes, database sizes, and retrieval frequencies. We propose Chameleon, a\nheterogeneous accelerator system that integrates both LM and retrieval\naccelerators in a disaggregated architecture. The heterogeneity ensures\nefficient acceleration of both LM inference and retrieval, while the\naccelerator disaggregation enables the system to independently scale both types\nof accelerators to fulfill diverse RALM requirements. Our Chameleon prototype\nimplements retrieval accelerators on FPGAs and assigns LM inference to GPUs,\nwith a CPU server orchestrating these accelerators over the network. Compared\nto CPU-based and CPU-GPU vector search systems, Chameleon achieves up to 23.72x\nspeedup and 26.2x energy efficiency. Evaluated on various RALMs, Chameleon\nexhibits up to 2.16x reduction in latency and 3.18x speedup in throughput\ncompared to the hybrid CPU-GPU architecture. These promising results pave the\nway for bringing accelerator heterogeneity and disaggregation into future RALM\nsystems.",
            "author": [
                "Wenqi Jiang",
                "Marco Zeller",
                "Roger Waleffe",
                "Torsten Hoefler",
                "Gustavo Alonso"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09949v3",
                "http://arxiv.org/pdf/2310.09949v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.AR",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09946v1",
            "title": "UvA-MT's Participation in the WMT23 General Translation Shared Task",
            "updated": "2023-10-15T20:49:31Z",
            "published": "2023-10-15T20:49:31Z",
            "summary": "This paper describes the UvA-MT's submission to the WMT 2023 shared task on\ngeneral machine translation. We participate in the constrained track in two\ndirections: English <-> Hebrew. In this competition, we show that by using one\nmodel to handle bidirectional tasks, as a minimal setting of Multilingual\nMachine Translation (MMT), it is possible to achieve comparable results with\nthat of traditional bilingual translation for both directions. By including\neffective strategies, like back-translation, re-parameterized embedding table,\nand task-oriented fine-tuning, we obtained competitive final results in the\nautomatic evaluation for both English -> Hebrew and Hebrew -> English\ndirections.",
            "author": [
                "Di Wu",
                "Shaomu Tan",
                "David Stap",
                "Ali Araabi",
                "Christof Monz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09946v1",
                "http://arxiv.org/pdf/2310.09946v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09943v2",
            "title": "Evaluating Robustness of Visual Representations for Object Assembly Task\n  Requiring Spatio-Geometrical Reasoning",
            "updated": "2023-10-22T21:09:34Z",
            "published": "2023-10-15T20:41:07Z",
            "summary": "This paper primarily focuses on evaluating and benchmarking the robustness of\nvisual representations in the context of object assembly tasks. Specifically,\nit investigates the alignment and insertion of objects with geometrical\nextrusions and intrusions, commonly referred to as a peg-in-hole task. The\naccuracy required to detect and orient the peg and the hole geometry in SE(3)\nspace for successful assembly poses significant challenges. Addressing this, we\nemploy a general framework in visuomotor policy learning that utilizes visual\npretraining models as vision encoders. Our study investigates the robustness of\nthis framework when applied to a dual-arm manipulation setup, specifically to\nthe grasp variations. Our quantitative analysis shows that existing pretrained\nmodels fail to capture the essential visual features necessary for this task.\nHowever, a visual encoder trained from scratch consistently outperforms the\nfrozen pretrained models. Moreover, we discuss rotation representations and\nassociated loss functions that substantially improve policy learning. We\npresent a novel task scenario designed to evaluate the progress in visuomotor\npolicy learning, with a specific focus on improving the robustness of intricate\nassembly tasks that require both geometrical and spatial reasoning. Videos,\nadditional experiments, dataset, and code are available at\nhttps://bit.ly/geometric-peg-in-hole .",
            "author": [
                "Chahyon Ku",
                "Carl Winge",
                "Ryan Diaz",
                "Wentao Yuan",
                "Karthik Desingh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09943v2",
                "http://arxiv.org/pdf/2310.09943v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09940v1",
            "title": "Semi-Supervised End-to-End Learning for Integrated Sensing and\n  Communications",
            "updated": "2023-10-15T20:33:35Z",
            "published": "2023-10-15T20:33:35Z",
            "summary": "Integrated sensing and communications (ISAC) is envisioned as one of the key\nenablers of next-generation wireless systems, offering improved hardware,\nspectral, and energy efficiencies. In this paper, we consider an ISAC\ntransceiver with an impaired uniform linear array that performs single-target\ndetection and position estimation, and multiple-input single-output\ncommunications. A differentiable model-based learning approach is considered,\nwhich optimizes both the transmitter and the sensing receiver in an end-to-end\nmanner. An unsupervised loss function that enables impairment compensation\nwithout the need for labeled data is proposed. Semi-supervised learning\nstrategies are also proposed, which use a combination of small amounts of\nlabeled data and unlabeled data. Our results show that semi-supervised learning\ncan achieve similar performance to supervised learning with 98.8% less required\nlabeled data.",
            "author": [
                "Jos\u00e9 Miguel Mateos-Ramos",
                "Baptiste Chatelier",
                "Christian H\u00e4ger",
                "Musa Furkan Keskin",
                "Luc Le Magoarou",
                "Henk Wymeersch"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09940v1",
                "http://arxiv.org/pdf/2310.09940v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09937v1",
            "title": "Joint Sparse Representations and Coupled Dictionary Learning in\n  Multi-Source Heterogeneous Image Pseudo-color Fusion",
            "updated": "2023-10-15T20:04:57Z",
            "published": "2023-10-15T20:04:57Z",
            "summary": "Considering that Coupled Dictionary Learning (CDL) method can obtain a\nreasonable linear mathematical relationship between resource images, we propose\na novel CDL-based Synthetic Aperture Radar (SAR) and multispectral pseudo-color\nfusion method. Firstly, the traditional Brovey transform is employed as a\npre-processing method on the paired SAR and multispectral images. Then, CDL is\nused to capture the correlation between the pre-processed image pairs based on\nthe dictionaries generated from the source images via enforced joint sparse\ncoding. Afterward, the joint sparse representation in the pair of dictionaries\nis utilized to construct an image mask via calculating the reconstruction\nerrors, and therefore generate the final fusion image. The experimental\nverification results of the SAR images from the Sentinel-1 satellite and the\nmultispectral images from the Landsat-8 satellite show that the proposed method\ncan achieve superior visual effects, and excellent quantitative performance in\nterms of spectral distortion, correlation coefficient, MSE, NIQE, BRISQUE, and\nPIQE.",
            "author": [
                "Long Bai",
                "Shilong Yao",
                "Kun Gao",
                "Yanjun Huang",
                "Ruijie Tang",
                "Hong Yan",
                "Max Q. -H. Meng",
                "Hongliang Ren"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09937v1",
                "http://arxiv.org/pdf/2310.09937v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09931v1",
            "title": "Sub-optimality of the Naive Mean Field approximation for proportional\n  high-dimensional Linear Regression",
            "updated": "2023-10-15T19:40:15Z",
            "published": "2023-10-15T19:40:15Z",
            "summary": "The Na\\\"ive Mean Field (NMF) approximation is widely employed in modern\nMachine Learning due to the huge computational gains it bestows on the\nstatistician. Despite its popularity in practice, theoretical guarantees for\nhigh-dimensional problems are only available under strong structural\nassumptions (e.g., sparsity). Moreover, existing theory often does not explain\nempirical observations noted in the existing literature.\n  In this paper, we take a step towards addressing these problems by deriving\nsharp asymptotic characterizations for the NMF approximation in\nhigh-dimensional linear regression. Our results apply to a wide class of\nnatural priors and allow for model mismatch (i.e., the underlying statistical\nmodel can be different from the fitted model). We work under an \\textit{iid}\nGaussian design and the proportional asymptotic regime, where the number of\nfeatures and the number of observations grow at a proportional rate. As a\nconsequence of our asymptotic characterization, we establish two concrete\ncorollaries: (a) we establish the inaccuracy of the NMF approximation for the\nlog-normalizing constant in this regime, and (b) we provide theoretical results\nbacking the empirical observation that the NMF approximation can be\noverconfident in terms of uncertainty quantification.\n  Our results utilize recent advances in the theory of Gaussian comparison\ninequalities. To the best of our knowledge, this is the first application of\nthese ideas to the analysis of Bayesian variational inference problems. Our\ntheoretical results are corroborated by numerical experiments. Lastly, we\nbelieve our results can be generalized to non-Gaussian designs and provide\nempirical evidence to support it.",
            "author": [
                "Jiaze Qiu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09931v1",
                "http://arxiv.org/pdf/2310.09931v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09926v2",
            "title": "Estimating Uncertainty in Multimodal Foundation Models using Public\n  Internet Data",
            "updated": "2023-11-26T05:54:48Z",
            "published": "2023-10-15T19:24:52Z",
            "summary": "Foundation models are trained on vast amounts of data at scale using\nself-supervised learning, enabling adaptation to a wide range of downstream\ntasks. At test time, these models exhibit zero-shot capabilities through which\nthey can classify previously unseen (user-specified) categories. In this paper,\nwe address the problem of quantifying uncertainty in these zero-shot\npredictions. We propose a heuristic approach for uncertainty estimation in\nzero-shot settings using conformal prediction with web data. Given a set of\nclasses at test time, we conduct zero-shot classification with CLIP-style\nmodels using a prompt template, e.g., \"an image of a <category>\", and use the\nsame template as a search query to source calibration data from the open web.\nGiven a web-based calibration set, we apply conformal prediction with a novel\nconformity score that accounts for potential errors in retrieved web data. We\nevaluate the utility of our proposed method in Biomedical foundation models;\nour preliminary results show that web-based conformal prediction sets achieve\nthe target coverage with satisfactory efficiency on a variety of biomedical\ndatasets.",
            "author": [
                "Shiladitya Dutta",
                "Hongbo Wei",
                "Lars van der Laan",
                "Ahmed M. Alaa"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09926v2",
                "http://arxiv.org/pdf/2310.09926v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09925v1",
            "title": "Homophone Disambiguation Reveals Patterns of Context Mixing in Speech\n  Transformers",
            "updated": "2023-10-15T19:24:13Z",
            "published": "2023-10-15T19:24:13Z",
            "summary": "Transformers have become a key architecture in speech processing, but our\nunderstanding of how they build up representations of acoustic and linguistic\nstructure is limited. In this study, we address this gap by investigating how\nmeasures of 'context-mixing' developed for text models can be adapted and\napplied to models of spoken language. We identify a linguistic phenomenon that\nis ideal for such a case study: homophony in French (e.g. livre vs livres),\nwhere a speech recognition model has to attend to syntactic cues such as\ndeterminers and pronouns in order to disambiguate spoken words with identical\npronunciations and transcribe them while respecting grammatical agreement. We\nperform a series of controlled experiments and probing analyses on\nTransformer-based speech models. Our findings reveal that representations in\nencoder-only models effectively incorporate these cues to identify the correct\ntranscription, whereas encoders in encoder-decoder models mainly relegate the\ntask of capturing contextual dependencies to decoder modules.",
            "author": [
                "Hosein Mohebbi",
                "Grzegorz Chrupa\u0142a",
                "Willem Zuidema",
                "Afra Alishahi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09925v1",
                "http://arxiv.org/pdf/2310.09925v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09924v1",
            "title": "Deep Reinforcement Learning with Explicit Context Representation",
            "updated": "2023-10-15T19:23:05Z",
            "published": "2023-10-15T19:23:05Z",
            "summary": "Reinforcement learning (RL) has shown an outstanding capability for solving\ncomplex computational problems. However, most RL algorithms lack an explicit\nmethod that would allow learning from contextual information. Humans use\ncontext to identify patterns and relations among elements in the environment,\nalong with how to avoid making wrong actions. On the other hand, what may seem\nlike an obviously wrong decision from a human perspective could take hundreds\nof steps for an RL agent to learn to avoid. This paper proposes a framework for\ndiscrete environments called Iota explicit context representation (IECR). The\nframework involves representing each state using contextual key frames (CKFs),\nwhich can then be used to extract a function that represents the affordances of\nthe state; in addition, two loss functions are introduced with respect to the\naffordances of the state. The novelty of the IECR framework lies in its\ncapacity to extract contextual information from the environment and learn from\nthe CKFs' representation. We validate the framework by developing four new\nalgorithms that learn using context: Iota deep Q-network (IDQN), Iota double\ndeep Q-network (IDDQN), Iota dueling deep Q-network (IDuDQN), and Iota dueling\ndouble deep Q-network (IDDDQN). Furthermore, we evaluate the framework and the\nnew algorithms in five discrete environments. We show that all the algorithms,\nwhich use contextual information, converge in around 40,000 training steps of\nthe neural networks, significantly outperforming their state-of-the-art\nequivalents.",
            "author": [
                "Francisco Munguia-Galeano",
                "Ah-Hwee Tan",
                "Ze Ji"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09924v1",
                "http://arxiv.org/pdf/2310.09924v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09920v1",
            "title": "BONES: Near-Optimal Neural-Enhanced Video Streaming",
            "updated": "2023-10-15T19:08:18Z",
            "published": "2023-10-15T19:08:18Z",
            "summary": "Accessing high-quality video content can be challenging due to insufficient\nand unstable network bandwidth. Recent advances in neural enhancement have\nshown promising results in improving the quality of degraded videos through\ndeep learning. Neural-Enhanced Streaming (NES) incorporates this new approach\ninto video streaming, allowing users to download low-quality video segments and\nthen enhance them to obtain high-quality content without violating the playback\nof the video stream. We introduce BONES, an NES control algorithm that jointly\nmanages the network and computational resources to maximize the quality of\nexperience (QoE) of the user. BONES formulates NES as a Lyapunov optimization\nproblem and solves it in an online manner with near-optimal performance, making\nit the first NES algorithm to provide a theoretical performance guarantee. Our\ncomprehensive experimental results indicate that BONES increases QoE by 4% to\n13% over state-of-the-art algorithms, demonstrating its potential to enhance\nthe video streaming experience for users. Our code and data will be released to\nthe public.",
            "author": [
                "Lingdong Wang",
                "Simran Singh",
                "Jacob Chakareski",
                "Mohammad Hajiesmaili",
                "Ramesh K. Sitaraman"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09920v1",
                "http://arxiv.org/pdf/2310.09920v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.NI",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09917v2",
            "title": "Empirical study of pretrained multilingual language models for zero-shot\n  cross-lingual generation",
            "updated": "2023-11-15T23:11:47Z",
            "published": "2023-10-15T18:58:53Z",
            "summary": "Zero-shot cross-lingual generation assumes finetuning the multilingual\npretrained language model (mPLM) on a generation task in one language and then\nusing it to make predictions for this task in other languages. Previous works\nnotice a frequent problem of generation in a wrong language and propose\napproaches to address it, usually using mT5 as a backbone model. In this work,\nwe test alternative mPLMs, such as mBART and NLLB-200, and compare various\napproaches proposed in the literature in a unified setting. We first underline\nthe importance of tuning learning rate used for finetuning, which helps to\nsubstantially alleviate the problem of generation in the wrong language. Then,\nwe show that with careful learning rate tuning, the simple full finetuning of\nthe model acts as a very strong baseline; other competitive approaches include\nparameter-efficient tuning with adapters and training on several source\nlanguages. Finally, we find that mBART performs similarly to mT5 of the same\nsize, and NLLB-200 can be competitive in some cases.",
            "author": [
                "Nadezhda Chirkova",
                "Sheng Liang",
                "Vassilina Nikoulina"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09917v2",
                "http://arxiv.org/pdf/2310.09917v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09912v3",
            "title": "Unsupervised Discovery of Interpretable Directions in h-space of\n  Pre-trained Diffusion Models",
            "updated": "2023-11-30T11:03:01Z",
            "published": "2023-10-15T18:44:30Z",
            "summary": "We propose the first unsupervised and learning-based method to identify\ninterpretable directions in h-space of pre-trained diffusion models. Our method\nis derived from an existing technique that operates on the GAN latent space.\nSpecifically, we employ a shift control module that works on h-space of\npre-trained diffusion models to manipulate a sample into a shifted version of\nitself, followed by a reconstructor to reproduce both the type and the strength\nof the manipulation. By jointly optimizing them, the model will spontaneously\ndiscover disentangled and interpretable directions. To prevent the discovery of\nmeaningless and destructive directions, we employ a discriminator to maintain\nthe fidelity of shifted sample. Due to the iterative generative process of\ndiffusion models, our training requires a substantial amount of GPU VRAM to\nstore numerous intermediate tensors for back-propagating gradient. To address\nthis issue, we propose a general VRAM-efficient training algorithm based on\ngradient checkpointing technique to back-propagate any gradient through the\nwhole generative process, with acceptable occupancy of VRAM and sacrifice of\ntraining efficiency. Compared with existing related works on diffusion models,\nour method inherently identifies global and scalable directions, without\nnecessitating any other complicated procedures. Extensive experiments on\nvarious datasets demonstrate the effectiveness of our method.",
            "author": [
                "Zijian Zhang",
                "Luping Liu",
                "Zhijie Lin",
                "Yichen Zhu",
                "Zhou Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09912v3",
                "http://arxiv.org/pdf/2310.09912v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14949v1",
            "title": "Predictive Maintenance Model Based on Anomaly Detection in Induction\n  Motors: A Machine Learning Approach Using Real-Time IoT Data",
            "updated": "2023-10-15T18:43:45Z",
            "published": "2023-10-15T18:43:45Z",
            "summary": "With the support of Internet of Things (IoT) devices, it is possible to\nacquire data from degradation phenomena and design data-driven models to\nperform anomaly detection in industrial equipment. This approach not only\nidentifies potential anomalies but can also serve as a first step toward\nbuilding predictive maintenance policies. In this work, we demonstrate a novel\nanomaly detection system on induction motors used in pumps, compressors, fans,\nand other industrial machines. This work evaluates a combination of\npre-processing techniques and machine learning (ML) models with a low\ncomputational cost. We use a combination of pre-processing techniques such as\nFast Fourier Transform (FFT), Wavelet Transform (WT), and binning, which are\nwell-known approaches for extracting features from raw data. We also aim to\nguarantee an optimal balance between multiple conflicting parameters, such as\nanomaly detection rate, false positive rate, and inference speed of the\nsolution. To this end, multiobjective optimization and analysis are performed\non the evaluated models. Pareto-optimal solutions are presented to select which\nmodels have the best results regarding classification metrics and computational\neffort. Differently from most works in this field that use publicly available\ndatasets to validate their models, we propose an end-to-end solution combining\nlow-cost and readily available IoT sensors. The approach is validated by\nacquiring a custom dataset from induction motors. Also, we fuse vibration,\ntemperature, and noise data from these sensors as the input to the proposed ML\nmodel. Therefore, we aim to propose a methodology general enough to be applied\nin different industrial contexts in the future.",
            "author": [
                "Sergio F. Chevtchenko",
                "Monalisa C. M. dos Santos",
                "Diego M. Vieira",
                "Ricardo L. Mota",
                "Elisson Rocha",
                "Bruna V. Cruz",
                "Danilo Ara\u00fajo",
                "Ermeson Andrade"
            ],
            "link": [
                "http://dx.doi.org/10.3850/978-981-18-8071-1_P578-cd",
                "http://arxiv.org/abs/2310.14949v1",
                "http://arxiv.org/pdf/2310.14949v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09911v2",
            "title": "Machine Learning Many-Body Green's Functions for Molecular Excitation\n  Spectra",
            "updated": "2023-12-04T03:35:56Z",
            "published": "2023-10-15T18:43:39Z",
            "summary": "We present a machine learning (ML) framework for predicting Green's functions\nof molecular systems, from which photoemission spectra and quasiparticle\nenergies at quantum many-body level can be obtained. Kernel ridge regression is\nadopted to predict self-energy matrix elements on compact imaginary frequency\ngrids from static and dynamical mean-field electronic features, which gives\ndirect access to real-frequency many-body Green's functions through analytic\ncontinuation and Dyson's equation. Feature and self-energy matrices are\nrepresented in a symmetry-adapted intrinsic atomic orbital plus projected\natomic orbital basis to enforce rotational invariance. We demonstrate good\ntransferability and high data efficiency of proposed ML method across molecular\nsizes and chemical species by showing accurate predictions of density of states\n(DOS) and quasiparticle energies at the level of many-body perturbation theory\n(GW) or full configuration interaction. For the ML model trained on 48 out of\n1995 molecules randomly sampled from the QM7 and QM9 datasets, we report the\nmean absolute errors of ML-predicted HOMO and LUMO energies to be 0.13 eV and\n0.10 eV compared to GW@PBE0. We further showcase the capability of this method\nby applying the same ML model to predict DOS for significantly larger organic\nmolecules with up to 44 heavy atoms.",
            "author": [
                "Christian Venturella",
                "Christopher Hillenbrand",
                "Jiachen Li",
                "Tianyu Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09911v2",
                "http://arxiv.org/pdf/2310.09911v2"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "cond-mat.mtrl-sci",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09903v4",
            "title": "Feature selection and regression methods for stock price prediction\n  using technical indicators",
            "updated": "2023-11-06T15:50:48Z",
            "published": "2023-10-15T18:09:09Z",
            "summary": "Due to the influence of many factors, including technical indicators on stock\nprice prediction, feature selection is important to choose the best indicators.\nThis study uses technical indicators and features selection and regression\nmethods to solve the problem of closing the stock market price. The aim of this\nresearch is to predict the stock market price with the least error. By the\nproposed method, the data created by the 3-day time window were converted to\nthe appropriate input for regression methods. In this paper, 10 regressor and\n123 technical indicators have been examined on data of the last 13 years of\nApple Company. The results have been investigated by 5 error-based evaluation\ncriteria. Based on results of the proposed method, MLPSF has 56/47% better\nperformance than MLP. Also, SVRSF has 67/42% improved compared to SVR. LRSF was\n76.7 % improved compared to LR. The RISF method also improved 72.82 % of Ridge\nregression. The DTRSB method had 24.23 % improvement over DTR. KNNSB had 15.52\n% improvement over KNN regression. RFSB had a 6 % improvement over RF. GBRSF\nalso improved at 7% over GBR. Finally, ADASF and ADASB also had a 4%\nimprovement over the ADA regression. Also, Ridge and LinearRegression had the\nbest results for stock price prediction. Based on results, the best indicators\nto predict stock price are: the Squeeze_pro, Percentage Price Oscillator,\nThermo, Decay, Archer On-Balance Volume, Bollinger Bands, Squeeze and Ichimoku\nindicator. According to the results, the use of suitable combination of\nsuggested indicators along with regression methods has resulted in high\naccuracy in predicting the closing price.",
            "author": [
                "Fatemeh Moodi",
                "Amir Jahangard-Rafsanjani",
                "Sajad Zarifzadeh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09903v4",
                "http://arxiv.org/pdf/2310.09903v4"
            ],
            "primary_category": "q-fin.ST",
            "category": [
                "q-fin.ST",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09897v1",
            "title": "Reformulating NLP tasks to Capture Longitudinal Manifestation of\n  Language Disorders in People with Dementia",
            "updated": "2023-10-15T17:58:47Z",
            "published": "2023-10-15T17:58:47Z",
            "summary": "Dementia is associated with language disorders which impede communication.\nHere, we automatically learn linguistic disorder patterns by making use of a\nmoderately-sized pre-trained language model and forcing it to focus on\nreformulated natural language processing (NLP) tasks and associated linguistic\npatterns. Our experiments show that NLP tasks that encapsulate contextual\ninformation and enhance the gradient signal with linguistic patterns benefit\nperformance. We then use the probability estimates from the best model to\nconstruct digital linguistic markers measuring the overall quality in\ncommunication and the intensity of a variety of language disorders. We\ninvestigate how the digital markers characterize dementia speech from a\nlongitudinal perspective. We find that our proposed communication marker is\nable to robustly and reliably characterize the language of people with\ndementia, outperforming existing linguistic approaches; and shows external\nvalidity via significant correlation with clinical markers of behaviour.\nFinally, our proposed linguistic disorder markers provide useful insights into\ngradual language impairment associated with disease progression.",
            "author": [
                "Dimitris Gkoumas",
                "Matthew Purver",
                "Maria Liakata"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09897v1",
                "http://arxiv.org/pdf/2310.09897v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09893v1",
            "title": "Adaptive Contact-Implicit Model Predictive Control with Online Residual\n  Learning",
            "updated": "2023-10-15T17:27:45Z",
            "published": "2023-10-15T17:27:45Z",
            "summary": "The hybrid nature of multi-contact robotic systems, due to making and\nbreaking contact with the environment, creates significant challenges for\nhigh-quality control. Existing model-based methods typically rely on either\ngood prior knowledge of the multi-contact model or require significant offline\nmodel tuning effort, thus resulting in low adaptability and robustness. In this\npaper, we propose a real-time adaptive multi-contact model predictive control\nframework, which enables online adaption of the hybrid multi-contact model and\ncontinuous improvement of the control performance for contact-rich tasks. This\nframework includes an adaption module, which continuously learns a residual of\nthe hybrid model to minimize the gap between the prior model and reality, and a\nreal-time multi-contact MPC controller. We demonstrated the effectiveness of\nthe framework in synthetic examples, and applied it on hardware to solve\ncontact-rich manipulation tasks, where a robot uses its end-effector to roll\ndifferent unknown objects on a table to track given paths. The hardware\nexperiments show that with a rough prior model, the multi-contact MPC\ncontroller adapts itself on-the-fly with an adaption rate around 20 Hz and\nsuccessfully manipulates previously unknown objects with non-smooth surface\ngeometries.",
            "author": [
                "Wei-Cheng Huang",
                "Alp Aydinoglu",
                "Wanxin Jin",
                "Michael Posa"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09893v1",
                "http://arxiv.org/pdf/2310.09893v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09891v1",
            "title": "Towards Deep Learning Models Resistant to Transfer-based Adversarial\n  Attacks via Data-centric Robust Learning",
            "updated": "2023-10-15T17:20:42Z",
            "published": "2023-10-15T17:20:42Z",
            "summary": "Transfer-based adversarial attacks raise a severe threat to real-world deep\nlearning systems since they do not require access to target models. Adversarial\ntraining (AT), which is recognized as the strongest defense against white-box\nattacks, has also guaranteed high robustness to (black-box) transfer-based\nattacks. However, AT suffers from heavy computational overhead since it\noptimizes the adversarial examples during the whole training process. In this\npaper, we demonstrate that such heavy optimization is not necessary for AT\nagainst transfer-based attacks. Instead, a one-shot adversarial augmentation\nprior to training is sufficient, and we name this new defense paradigm\nData-centric Robust Learning (DRL). Our experimental results show that DRL\noutperforms widely-used AT techniques (e.g., PGD-AT, TRADES, EAT, and FAT) in\nterms of black-box robustness and even surpasses the top-1 defense on\nRobustBench when combined with diverse data augmentations and loss\nregularizations. We also identify other benefits of DRL, for instance, the\nmodel generalization capability and robust fairness.",
            "author": [
                "Yulong Yang",
                "Chenhao Lin",
                "Xiang Ji",
                "Qiwei Tian",
                "Qian Li",
                "Hongshan Yang",
                "Zhibo Wang",
                "Chao Shen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09891v1",
                "http://arxiv.org/pdf/2310.09891v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09890v1",
            "title": "Score-Based Methods for Discrete Optimization in Deep Learning",
            "updated": "2023-10-15T17:14:17Z",
            "published": "2023-10-15T17:14:17Z",
            "summary": "Discrete optimization problems often arise in deep learning tasks, despite\nthe fact that neural networks typically operate on continuous data. One class\nof these problems involve objective functions which depend on neural networks,\nbut optimization variables which are discrete. Although the discrete\noptimization literature provides efficient algorithms, they are still\nimpractical in these settings due to the high cost of an objective function\nevaluation, which involves a neural network forward-pass. In particular, they\nrequire $O(n)$ complexity per iteration, but real data such as point clouds\nhave values of $n$ in thousands or more. In this paper, we investigate a\nscore-based approximation framework to solve such problems. This framework uses\na score function as a proxy for the marginal gain of the objective, leveraging\nembeddings of the discrete variables and speed of auto-differentiation\nframeworks to compute backward-passes in parallel. We experimentally\ndemonstrate, in adversarial set classification tasks, that our method achieves\na superior trade-off in terms of speed and solution quality compared to\nheuristic methods.",
            "author": [
                "Eric Lei",
                "Arman Adibi",
                "Hamed Hassani"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09890v1",
                "http://arxiv.org/pdf/2310.09890v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09889v2",
            "title": "The Capacity Region of Information Theoretic Secure Aggregation with\n  Uncoded Groupwise Keys",
            "updated": "2023-11-12T14:43:24Z",
            "published": "2023-10-15T17:14:08Z",
            "summary": "This paper considers the secure aggregation problem for federated learning\nunder an information theoretic cryptographic formulation, where distributed\ntraining nodes (referred to as users) train models based on their own local\ndata and a curious-but-honest server aggregates the trained models without\nretrieving other information about users' local data. Secure aggregation\ngenerally contains two phases, namely key sharing phase and model aggregation\nphase. Due to the common effect of user dropouts in federated learning, the\nmodel aggregation phase should contain two rounds, where in the first round the\nusers transmit masked models and, in the second round, according to the\nidentity of surviving users after the first round, these surviving users\ntransmit some further messages to help the server decrypt the sum of users'\ntrained models. The objective of the considered information theoretic\nformulation is to characterize the capacity region of the communication rates\nin the two rounds from the users to the server in the model aggregation phase,\nassuming that key sharing has already been performed offline in prior. In this\ncontext, Zhao and Sun completely characterized the capacity region under the\nassumption that the keys can be arbitrary random variables. More recently, an\nadditional constraint, known as \"uncoded groupwise keys,\" has been introduced.\nThis constraint entails the presence of multiple independent keys within the\nsystem, with each key being shared by precisely S users. The capacity region\nfor the information-theoretic secure aggregation problem with uncoded groupwise\nkeys was established in our recent work subject to the condition S > K - U,\nwhere K is the number of total users and U is the designed minimum number of\nsurviving users. In this paper we fully characterize of the the capacity region\nfor this problem by proposing a new converse bound and an achievable scheme.",
            "author": [
                "Kai Wan",
                "Hua Sun",
                "Mingyue Ji",
                "Tiebin Mi",
                "Giuseppe Caire"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09889v2",
                "http://arxiv.org/pdf/2310.09889v2"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09886v4",
            "title": "Lifelong Sequence Generation with Dynamic Module Expansion and\n  Adaptation",
            "updated": "2023-11-22T06:44:16Z",
            "published": "2023-10-15T16:51:11Z",
            "summary": "Lifelong sequence generation (LSG), a problem in continual learning, aims to\ncontinually train a model on a sequence of generation tasks to learn constantly\nemerging new generation patterns while avoiding the forgetting of previous\nknowledge. Existing LSG methods mainly focus on maintaining old knowledge while\npaying little attention to knowledge transfer across tasks. In contrast, humans\ncan better learn new tasks by leveraging previously acquired knowledge from\nsimilar tasks. Inspired by the learning paradigm of humans, we propose Dynamic\nModule Expansion and Adaptation (DMEA), which enables the model to dynamically\ndetermine the architecture for acquiring new knowledge based on task\ncorrelation and select the most similar previous tasks to facilitate adaptation\nto new tasks. In addition, as the learning process can easily be biased towards\nthe current task which might cause more severe forgetting of previously learned\nknowledge, we propose dynamic gradient scaling to balance the learning of the\ncurrent task and replayed tasks. With extensive experiments, we demonstrate\nthat DMEA can consistently outperform existing methods in different LSG\nsettings.",
            "author": [
                "Chengwei Qin",
                "Chen Chen",
                "Shafiq Joty"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09886v4",
                "http://arxiv.org/pdf/2310.09886v4"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09884v1",
            "title": "Unmasking the Web of Deceit: Uncovering Coordinated Activity to Expose\n  Information Operations on Twitter",
            "updated": "2023-10-15T16:45:18Z",
            "published": "2023-10-15T16:45:18Z",
            "summary": "Social media platforms, particularly Twitter, have become pivotal arenas for\ninfluence campaigns, often orchestrated by state-sponsored information\noperations (IOs). This paper delves into the detection of key players driving\nIOs by employing similarity graphs constructed from behavioral pattern data. We\nunveil that well-known, yet underutilized network properties can help\naccurately identify coordinated IO drivers. Drawing from a comprehensive\ndataset of 49 million tweets from six countries, which includes multiple\nverified IOs, our study reveals that traditional network filtering techniques\ndo not consistently pinpoint IO drivers across campaigns. We first propose a\nframework based on node pruning that emerges superior, particularly when\ncombining multiple behavioral indicators across different networks. Then, we\nintroduce a supervised machine learning model that harnesses a vector\nrepresentation of the fused similarity network. This model, which boasts a\nprecision exceeding 0.95, adeptly classifies IO drivers on a global scale and\nreliably forecasts their temporal engagements. Our findings are crucial in the\nfight against deceptive influence campaigns on social media, helping us better\nunderstand and detect them.",
            "author": [
                "Luca Luceri",
                "Valeria Pant\u00e8",
                "Keith Burghardt",
                "Emilio Ferrara"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09884v1",
                "http://arxiv.org/pdf/2310.09884v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09883v1",
            "title": "Zero-Shot Object Goal Visual Navigation With Class-Independent\n  Relationship Network",
            "updated": "2023-10-15T16:42:14Z",
            "published": "2023-10-15T16:42:14Z",
            "summary": "This paper investigates the zero-shot object goal visual navigation problem.\nIn the object goal visual navigation task, the agent needs to locate navigation\ntargets from its egocentric visual input. \"Zero-shot\" means that the target the\nagent needs to find is not trained during the training phase. To address the\nissue of coupling navigation ability with target features during training, we\npropose the Class-Independent Relationship Network (CIRN). This method combines\ntarget detection information with the relative semantic similarity between the\ntarget and the navigation target, and constructs a brand new state\nrepresentation based on similarity ranking, this state representation does not\ninclude target feature or environment feature, effectively decoupling the\nagent's navigation ability from target features. And a Graph Convolutional\nNetwork (GCN) is employed to learn the relationships between different objects\nbased on their similarities. During testing, our approach demonstrates strong\ngeneralization capabilities, including zero-shot navigation tasks with\ndifferent targets and environments. Through extensive experiments in the\nAI2-THOR virtual environment, our method outperforms the current\nstate-of-the-art approaches in the zero-shot object goal visual navigation\ntask. Furthermore, we conducted experiments in more challenging cross-target\nand cross-scene settings, which further validate the robustness and\ngeneralization ability of our method. Our code is available at:\nhttps://github.com/SmartAndCleverRobot/ICRA-CIRN.",
            "author": [
                "Xinting Li",
                "Shizhou Zhang",
                "Yue LU",
                "Kerry Dan",
                "Lingyan Ran",
                "Peng Wang",
                "Yanning Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09883v1",
                "http://arxiv.org/pdf/2310.09883v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO",
                "I.2.9; I.2.10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09881v2",
            "title": "In-Context Learning with Iterative Demonstration Selection",
            "updated": "2023-10-22T13:40:02Z",
            "published": "2023-10-15T16:40:19Z",
            "summary": "Spurred by advancements in scale, large language models (LLMs) have\ndemonstrated strong few-shot learning ability via in-context learning (ICL).\nHowever, the performance of ICL has been shown to be highly sensitive to the\nselection of few-shot demonstrations. Selecting the most suitable examples as\ncontext remains an ongoing challenge and an open problem. Existing literature\nhas highlighted the importance of selecting examples that are diverse or\nsemantically similar to the test sample while ignoring the fact that the\noptimal selection dimension, i.e., diversity or similarity, is task-specific.\nLeveraging the merits of both dimensions, we propose Iterative Demonstration\nSelection (IDS). Using zero-shot chain-of-thought reasoning (Zero-shot-CoT),\nIDS iteratively selects examples that are diverse but still strongly correlated\nwith the test sample as ICL demonstrations. Specifically, IDS applies\nZero-shot-CoT to the test sample before demonstration selection. The output\nreasoning path is then used to choose demonstrations that are prepended to the\ntest sample for inference. The generated answer is accompanied by its\ncorresponding reasoning path for extracting a new set of demonstrations in the\nnext iteration. After several iterations, IDS adopts majority voting to obtain\nthe final result. Through extensive experiments on tasks including commonsense\nreasoning, question answering, topic classification, and sentiment analysis, we\ndemonstrate that IDS can consistently outperform existing ICL demonstration\nselection methods.",
            "author": [
                "Chengwei Qin",
                "Aston Zhang",
                "Anirudh Dagar",
                "Wenming Ye"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09881v2",
                "http://arxiv.org/pdf/2310.09881v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09877v1",
            "title": "Statistical inference using machine learning and classical techniques\n  based on accumulated local effects (ALE)",
            "updated": "2023-10-15T16:17:21Z",
            "published": "2023-10-15T16:17:21Z",
            "summary": "Accumulated Local Effects (ALE) is a model-agnostic approach for global\nexplanations of the results of black-box machine learning (ML) algorithms.\nThere are at least three challenges with conducting statistical inference based\non ALE: ensuring the reliability of ALE analyses, especially in the context of\nsmall datasets; intuitively characterizing a variable's overall effect in ML;\nand making robust inferences from ML data analysis. In response, we introduce\ninnovative tools and techniques for statistical inference using ALE,\nestablishing bootstrapped confidence intervals tailored to dataset size and\nintroducing ALE effect size measures that intuitively indicate effects on both\nthe outcome variable scale and a normalized scale. Furthermore, we demonstrate\nhow to use these tools to draw reliable statistical inferences, reflecting the\nflexible patterns ALE adeptly highlights, with implementations available in the\n'ale' package in R. This work propels the discourse on ALE and its\napplicability in ML and statistical analysis forward, offering practical\nsolutions to prevailing challenges in the field.",
            "author": [
                "Chitu Okoli"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09877v1",
                "http://arxiv.org/pdf/2310.09877v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09873v1",
            "title": "Reinforcement Learning for Reduced-order Models of Legged Robots",
            "updated": "2023-10-15T16:13:16Z",
            "published": "2023-10-15T16:13:16Z",
            "summary": "Model-based approaches for planning and control for bipedal locomotion have a\nlong history of success. It can provide stability and safety guarantees while\nbeing effective in accomplishing many locomotion tasks. Model-free\nreinforcement learning, on the other hand, has gained much popularity in recent\nyears due to computational advancements. It can achieve high performance in\nspecific tasks, but it lacks physical interpretability and flexibility in\nre-purposing the policy for a different set of tasks. For instance, we can\ninitially train a neural network (NN) policy using velocity commands as inputs.\nHowever, to handle new task commands like desired hand or footstep locations at\na desired walking velocity, we must retrain a new NN policy. In this work, we\nattempt to bridge the gap between these two bodies of work on a bipedal\nplatform. We formulate a model-based reinforcement learning problem to learn a\nreduced-order model (ROM) within a model predictive control (MPC). Results show\na 49% improvement in viable task region size and a 21% reduction in motor\ntorque cost. All videos and code are available at\nhttps://sites.google.com/view/ymchen/research/rl-for-roms.",
            "author": [
                "Yu-Ming Chen",
                "Hien Bui",
                "Michael Posa"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09873v1",
                "http://arxiv.org/pdf/2310.09873v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09872v1",
            "title": "Empower Text-Attributed Graphs Learning with Large Language Models\n  (LLMs)",
            "updated": "2023-10-15T16:04:28Z",
            "published": "2023-10-15T16:04:28Z",
            "summary": "Text-attributed graphs have recently garnered significant attention due to\ntheir wide range of applications in web domains. Existing methodologies employ\nword embedding models for acquiring text representations as node features,\nwhich are subsequently fed into Graph Neural Networks (GNNs) for training.\nRecently, the advent of Large Language Models (LLMs) has introduced their\npowerful capabilities in information retrieval and text generation, which can\ngreatly enhance the text attributes of graph data. Furthermore, the acquisition\nand labeling of extensive datasets are both costly and time-consuming\nendeavors. Consequently, few-shot learning has emerged as a crucial problem in\nthe context of graph learning tasks. In order to tackle this challenge, we\npropose a lightweight paradigm called ENG, which adopts a plug-and-play\napproach to empower text-attributed graphs through node generation using LLMs.\nSpecifically, we utilize LLMs to extract semantic information from the labels\nand generate samples that belong to these categories as exemplars.\nSubsequently, we employ an edge predictor to capture the structural information\ninherent in the raw dataset and integrate the newly generated samples into the\noriginal graph. This approach harnesses LLMs for enhancing class-level\ninformation and seamlessly introduces labeled nodes and edges without modifying\nthe raw dataset, thereby facilitating the node classification task in few-shot\nscenarios. Extensive experiments demonstrate the outstanding performance of our\nproposed paradigm, particularly in low-shot scenarios. For instance, in the\n1-shot setting of the ogbn-arxiv dataset, ENG achieves a 76% improvement over\nthe baseline model.",
            "author": [
                "Jianxiang Yu",
                "Yuxiang Ren",
                "Chenghua Gong",
                "Jiaqi Tan",
                "Xiang Li",
                "Xuecang Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09872v1",
                "http://arxiv.org/pdf/2310.09872v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09866v2",
            "title": "Federated Multi-Objective Learning",
            "updated": "2023-10-30T21:08:51Z",
            "published": "2023-10-15T15:45:51Z",
            "summary": "In recent years, multi-objective optimization (MOO) emerges as a foundational\nproblem underpinning many multi-agent multi-task learning applications.\nHowever, existing algorithms in MOO literature remain limited to centralized\nlearning settings, which do not satisfy the distributed nature and data privacy\nneeds of such multi-agent multi-task learning applications. This motivates us\nto propose a new federated multi-objective learning (FMOL) framework with\nmultiple clients distributively and collaboratively solving an MOO problem\nwhile keeping their training data private. Notably, our FMOL framework allows a\ndifferent set of objective functions across different clients to support a wide\nrange of applications, which advances and generalizes the MOO formulation to\nthe federated learning paradigm for the first time. For this FMOL framework, we\npropose two new federated multi-objective optimization (FMOO) algorithms called\nfederated multi-gradient descent averaging (FMGDA) and federated stochastic\nmulti-gradient descent averaging (FSMGDA). Both algorithms allow local updates\nto significantly reduce communication costs, while achieving the {\\em same}\nconvergence rates as those of their algorithmic counterparts in the\nsingle-objective federated learning. Our extensive experiments also corroborate\nthe efficacy of our proposed FMOO algorithms.",
            "author": [
                "Haibo Yang",
                "Zhuqing Liu",
                "Jia Liu",
                "Chaosheng Dong",
                "Michinari Momma"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09866v2",
                "http://arxiv.org/pdf/2310.09866v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09858v1",
            "title": "Federated Reinforcement Learning for Resource Allocation in V2X Networks",
            "updated": "2023-10-15T15:26:54Z",
            "published": "2023-10-15T15:26:54Z",
            "summary": "Resource allocation significantly impacts the performance of\nvehicle-to-everything (V2X) networks. Most existing algorithms for resource\nallocation are based on optimization or machine learning (e.g., reinforcement\nlearning). In this paper, we explore resource allocation in a V2X network under\nthe framework of federated reinforcement learning (FRL). On one hand, the usage\nof RL overcomes many challenges from the model-based optimization schemes. On\nthe other hand, federated learning (FL) enables agents to deal with a number of\npractical issues, such as privacy, communication overhead, and exploration\nefficiency. The framework of FRL is then implemented by the inexact alternative\ndirection method of multipliers (ADMM), where subproblems are solved\napproximately using policy gradients and accelerated by an adaptive step size\ncalculated from their second moments. The developed algorithm, PASM, is proven\nto be convergent under mild conditions and has a nice numerical performance\ncompared with some baseline methods for solving the resource allocation problem\nin a V2X network.",
            "author": [
                "Kaidi Xu",
                "Shenglong Zhou",
                "Geoffrey Ye Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09858v1",
                "http://arxiv.org/pdf/2310.09858v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09854v1",
            "title": "let data talk: data-regularized operator learning theory for inverse\n  problems",
            "updated": "2023-10-15T15:08:17Z",
            "published": "2023-10-15T15:08:17Z",
            "summary": "Regularization plays a pivotal role in integrating prior information into\ninverse problems. While many deep learning methods have been proposed to solve\ninverse problems, determining where to apply regularization remains a crucial\nconsideration. Typical methods regularize neural networks via architecture,\nwherein neural network functions parametrize the parameter of interest or the\nregularization term. We introduce a novel approach, denoted as the\n\"data-regularized operator learning\" (DaROL) method, designed to address PDE\ninverse problems. The DaROL method trains a neural network on data, regularized\nthrough common techniques such as Tikhonov variational methods and Bayesian\ninference. The DaROL method offers flexibility across different frameworks,\nfaster inverse problem-solving, and a simpler structure that separates\nregularization and neural network training. We demonstrate that training a\nneural network on the regularized data is equivalent to supervised learning for\na regularized inverse map. Furthermore, we provide sufficient conditions for\nthe smoothness of such a regularized inverse map and estimate the learning\nerror in terms of neural network size and the number of training samples.",
            "author": [
                "Ke Chen",
                "Chunmei Wang",
                "Haizhao Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09854v1",
                "http://arxiv.org/pdf/2310.09854v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "65N21",
                "G.1.8"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09853v1",
            "title": "MERTech: Instrument Playing Technique Detection Using Self-Supervised\n  Pretrained Model With Multi-Task Finetuning",
            "updated": "2023-10-15T15:00:00Z",
            "published": "2023-10-15T15:00:00Z",
            "summary": "Instrument playing techniques (IPTs) constitute a pivotal component of\nmusical expression. However, the development of automatic IPT detection methods\nsuffers from limited labeled data and inherent class imbalance issues. In this\npaper, we propose to apply a self-supervised learning model pre-trained on\nlarge-scale unlabeled music data and finetune it on IPT detection tasks. This\napproach addresses data scarcity and class imbalance challenges. Recognizing\nthe significance of pitch in capturing the nuances of IPTs and the importance\nof onset in locating IPT events, we investigate multi-task finetuning with\npitch and onset detection as auxiliary tasks. Additionally, we apply a\npost-processing approach for event-level prediction, where an IPT activation\ninitiates an event only if the onset output confirms an onset in that frame.\nOur method outperforms prior approaches in both frame-level and event-level\nmetrics across multiple IPT benchmark datasets. Further experiments demonstrate\nthe efficacy of multi-task finetuning on each IPT class.",
            "author": [
                "Dichucheng Li",
                "Yinghao Ma",
                "Weixing Wei",
                "Qiuqiang Kong",
                "Yulun Wu",
                "Mingjin Che",
                "Fan Xia",
                "Emmanouil Benetos",
                "Wei Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09853v1",
                "http://arxiv.org/pdf/2310.09853v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.AI",
                "cs.LG",
                "cs.MM",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10692v3",
            "title": "ACES: Generating Diverse Programming Puzzles with Autotelic Language\n  Models and Semantic Descriptors",
            "updated": "2023-10-25T12:01:38Z",
            "published": "2023-10-15T14:57:14Z",
            "summary": "Finding and selecting new and interesting problems to solve is at the heart\nof curiosity, science and innovation. We here study automated problem\ngeneration in the context of the open-ended space of python programming\npuzzles. Existing generative models often aim at modeling a reference\ndistribution without any explicit diversity optimization. Other methods\nexplicitly optimizing for diversity do so either in limited hand-coded\nrepresentation spaces or in uninterpretable learned embedding spaces that may\nnot align with human perceptions of interesting variations. With ACES\n(Autotelic Code Exploration via Semantic descriptors), we introduce a new\nautotelic generation method that leverages semantic descriptors produced by a\nlarge language model (LLM) to directly optimize for interesting diversity, as\nwell as few-shot-based generation. Each puzzle is labeled along 10 dimensions,\neach capturing a programming skill required to solve it. ACES generates and\npursues novel and feasible goals to explore that abstract semantic space,\nslowly discovering a diversity of solvable programming puzzles in any given\nrun. Across a set of experiments, we show that ACES discovers a richer\ndiversity of puzzles than existing diversity-maximizing algorithms as measured\nacross a range of diversity metrics. We further study whether and in which\nconditions this diversity can translate into the successful training of puzzle\nsolving models.",
            "author": [
                "Julien Pourcel",
                "C\u00e9dric Colas",
                "Pierre-Yves Oudeyer",
                "Laetitia Teodorescu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10692v3",
                "http://arxiv.org/pdf/2310.10692v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09852v1",
            "title": "Alpha Elimination: Using Deep Reinforcement Learning to Reduce Fill-In\n  during Sparse Matrix Decomposition",
            "updated": "2023-10-15T14:51:22Z",
            "published": "2023-10-15T14:51:22Z",
            "summary": "A large number of computational and scientific methods commonly require\ndecomposing a sparse matrix into triangular factors as LU decomposition. A\ncommon problem faced during this decomposition is that even though the given\nmatrix may be very sparse, the decomposition may lead to a denser triangular\nfactors due to fill-in. A significant fill-in may lead to prohibitively larger\ncomputational costs and memory requirement during decomposition as well as\nduring the solve phase. To this end, several heuristic sparse matrix reordering\nmethods have been proposed to reduce fill-in before the decomposition. However,\nfinding an optimal reordering algorithm that leads to minimal fill-in during\nsuch decomposition is known to be a NP-hard problem. A reinforcement learning\nbased approach is proposed for this problem. The sparse matrix reordering\nproblem is formulated as a single player game. More specifically, Monte-Carlo\ntree search in combination with neural network is used as a decision making\nalgorithm to search for the best move in our game. The proposed method,\nalphaElimination is found to produce significantly lesser non-zeros in the LU\ndecomposition as compared to existing state-of-the-art heuristic algorithms\nwith little to no increase in overall running time of the algorithm. The code\nfor the project will be publicly available\nhere\\footnote{\\url{https://github.com/misterpawan/alphaEliminationPaper}}.",
            "author": [
                "Arpan Dasgupta",
                "Pawan Kumar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09852v1",
                "http://arxiv.org/pdf/2310.09852v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10691v1",
            "title": "Enhancing ML model accuracy for Digital VLSI circuits using diffusion\n  models: A study on synthetic data generation",
            "updated": "2023-10-15T14:20:09Z",
            "published": "2023-10-15T14:20:09Z",
            "summary": "Generative AI has seen remarkable growth over the past few years, with\ndiffusion models being state-of-the-art for image generation. This study\ninvestigates the use of diffusion models in generating artificial data\ngeneration for electronic circuits for enhancing the accuracy of subsequent\nmachine learning models in tasks such as performance assessment, design, and\ntesting when training data is usually known to be very limited. We utilize\nsimulations in the HSPICE design environment with 22nm CMOS technology nodes to\nobtain representative real training data for our proposed diffusion model. Our\nresults demonstrate the close resemblance of synthetic data using diffusion\nmodel to real data. We validate the quality of generated data, and demonstrate\nthat data augmentation certainly effective in predictive analysis of VLSI\ndesign for digital circuits.",
            "author": [
                "Prasha Srivastava",
                "Pawan Kumar",
                "Zia Abbas"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10691v1",
                "http://arxiv.org/pdf/2310.10691v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09847v1",
            "title": "XRMDN: A Recurrent Mixture Density Networks-based Architecture for\n  Short-Term Probabilistic Demand Forecasting in Mobility-on-Demand Systems\n  with High Volatility",
            "updated": "2023-10-15T14:18:42Z",
            "published": "2023-10-15T14:18:42Z",
            "summary": "In real Mobility-on-Demand (MoD) systems, demand is subject to high and\ndynamic volatility, which is difficult to predict by conventional time-series\nforecasting approaches. Most existing forecasting approaches yield the point\nvalue as the prediction result, which ignores the uncertainty that exists in\nthe forecasting result. This will lead to the forecasting result severely\ndeviating from the true demand value due to the high volatility existing in\ndemand. To fill the gap, we propose an extended recurrent mixture density\nnetwork (XRMDN), which extends the weight and mean neural networks to recurrent\nneural networks. The recurrent neurons for mean and variance can capture the\ntrend of the historical data-series data, which enables a better forecasting\nresult in dynamic and high volatility. We conduct comprehensive experiments on\none taxi trip record and one bike-sharing real MoD data set to validate the\nperformance of XRMDN. Specifically, we compare our model to three types of\nbenchmark models, including statistical, machine learning, and deep learning\nmodels on three evaluation metrics. The validation results show that XRMDN\noutperforms the three groups of benchmark models in terms of the evaluation\nmetrics. Most importantly, XRMDN substantially improves the forecasting\naccuracy with the demands in strong volatility. Last but not least, this\nprobabilistic demand forecasting model contributes not only to the demand\nprediction in MoD systems but also to other optimization application problems,\nespecially optimization under uncertainty, in MoD applications.",
            "author": [
                "Xiaoming Li",
                "Hubert Normandin-Taillon",
                "Chun Wang",
                "Xiao Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09847v1",
                "http://arxiv.org/pdf/2310.09847v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09846v1",
            "title": "Generalizing Few-Shot Named Entity Recognizers to Unseen Domains with\n  Type-Related Features",
            "updated": "2023-10-15T14:15:29Z",
            "published": "2023-10-15T14:15:29Z",
            "summary": "Few-shot named entity recognition (NER) has shown remarkable progress in\nidentifying entities in low-resource domains. However, few-shot NER methods\nstill struggle with out-of-domain (OOD) examples due to their reliance on\nmanual labeling for the target domain. To address this limitation, recent\nstudies enable generalization to an unseen target domain with only a few\nlabeled examples using data augmentation techniques. Two important challenges\nremain: First, augmentation is limited to the training data, resulting in\nminimal overlap between the generated data and OOD examples. Second, knowledge\ntransfer is implicit and insufficient, severely hindering model\ngeneralizability and the integration of knowledge from the source domain. In\nthis paper, we propose a framework, prompt learning with type-related features\n(PLTR), to address these challenges. To identify useful knowledge in the source\ndomain and enhance knowledge transfer, PLTR automatically extracts entity\ntype-related features (TRFs) based on mutual information criteria. To bridge\nthe gap between training and OOD data, PLTR generates a unique prompt for each\nunseen example by selecting relevant TRFs. We show that PLTR achieves\nsignificant performance improvements on in-domain and cross-domain datasets.\nThe use of PLTR facilitates model adaptation and increases representation\nsimilarities between the source and unseen domains.",
            "author": [
                "Zihan Wang",
                "Ziqi Zhao",
                "Zhumin Chen",
                "Pengjie Ren",
                "Maarten de Rijke",
                "Zhaochun Ren"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09846v1",
                "http://arxiv.org/pdf/2310.09846v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12174v1",
            "title": "A Traffic Control Framework for Uncrewed Aircraft Systems",
            "updated": "2023-10-15T14:00:15Z",
            "published": "2023-10-15T14:00:15Z",
            "summary": "The exponential growth of Advanced Air Mobility (AAM) services demands\nassurances of safety in the airspace. This research a Traffic Control Framework\n(TCF) for developing digital flight rules for Uncrewed Aircraft System (UAS)\nflying in designated air corridors. The proposed TCF helps model, deploy, and\ntest UAS control, agents, regardless of their hardware configurations. This\npaper investigates the importance of digital flight rules in preventing\ncollisions in the context of AAM. TCF is introduced as a platform for\ndeveloping strategies for managing traffic towards enhanced autonomy in the\nairspace. It allows for assessment and evaluation of autonomous navigation,\nroute planning, obstacle avoidance, and adaptive decision making for UAS. It\nalso allows for the introduction and evaluation of advance technologies\nArtificial Intelligence (AI) and Machine Learning (ML) in a simulation\nenvironment before deploying them in the real world. TCF can be used as a tool\nfor comprehensive UAS traffic analysis, including KPI measurements. It offers\nflexibility for further testing and deployment laying the foundation for\nimproved airspace safety - a vital aspect of UAS technological advancement.\nFinally, this papers demonstrates the capabilities of the proposed TCF in\nmanaging UAS traffic at intersections and its impact on overall traffic flow in\nair corridors, noting the bottlenecks and the inverse relationship safety and\ntraffic volume.",
            "author": [
                "Ananay Vikram Gupta",
                "Aaditya Prakash Kattekola",
                "Ansh Vikram Gupta",
                "Dacharla Venkata Abhiram",
                "Kamesh Namuduri",
                "Ravichandran Subramanian"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12174v1",
                "http://arxiv.org/pdf/2310.12174v1"
            ],
            "primary_category": "physics.soc-ph",
            "category": [
                "physics.soc-ph",
                "cs.CE",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09838v1",
            "title": "Explaining How a Neural Network Play the Go Game and Let People Learn",
            "updated": "2023-10-15T13:57:50Z",
            "published": "2023-10-15T13:57:50Z",
            "summary": "The AI model has surpassed human players in the game of Go, and it is widely\nbelieved that the AI model has encoded new knowledge about the Go game beyond\nhuman players. In this way, explaining the knowledge encoded by the AI model\nand using it to teach human players represent a promising-yet-challenging issue\nin explainable AI. To this end, mathematical supports are required to ensure\nthat human players can learn accurate and verifiable knowledge, rather than\nspecious intuitive analysis. Thus, in this paper, we extract interaction\nprimitives between stones encoded by the value network for the Go game, so as\nto enable people to learn from the value network. Experiments show the\neffectiveness of our method.",
            "author": [
                "Huilin Zhou",
                "Huijie Tang",
                "Mingjie Li",
                "Hao Zhang",
                "Zhenyu Liu",
                "Quanshi Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09838v1",
                "http://arxiv.org/pdf/2310.09838v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09835v1",
            "title": "Secure and Robust Communications for Cislunar Space Networks",
            "updated": "2023-10-15T13:40:22Z",
            "published": "2023-10-15T13:40:22Z",
            "summary": "There is no doubt that the Moon has become the center of interest for\ncommercial and international actors. Over the past decade, the number of\nplanned long-term missions has increased dramatically. This makes the\nestablishment of cislunar space networks (CSNs) crucial to orchestrate\nuninterrupted communications between the Moon and Earth. However, there are\nnumerous challenges, unknowns, and uncertainties associated with cislunar\ncommunications that may pose various risks to lunar missions. In this study, we\naim to address these challenges for cislunar communications by proposing a\nmachine learning-based cislunar space domain awareness (SDA) capability that\nenables robust and secure communications. To this end, we first propose a\ndetailed channel model for selected cislunar scenarios. Secondly, we propose\ntwo types of interference that could model anomalies that occur in cislunar\nspace and are so far known only to a limited extent. Finally, we discuss our\ncislunar SDA to work in conjunction with the spacecraft communication system.\nOur proposed cislunar SDA, involving heuristic learning capabilities with\nmachine learning algorithms, detects interference models with over 96%\naccuracy. The results demonstrate the promising performance of our cislunar SDA\napproach for secure and robust cislunar communication.",
            "author": [
                "Selen Gecgel Cetin",
                "Gunes Karabulut Kurt",
                "Angeles Vazquez-Castro"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09835v1",
                "http://arxiv.org/pdf/2310.09835v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.LG",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09834v1",
            "title": "Improved Flow Recovery from Packet Data",
            "updated": "2023-10-15T13:36:33Z",
            "published": "2023-10-15T13:36:33Z",
            "summary": "Typical event datasets such as those used in network intrusion detection\ncomprise hundreds of thousands, sometimes millions, of discrete packet events.\nThese datasets tend to be high dimensional, stateful, and time-series in\nnature, holding complex local and temporal feature associations. Packet data\ncan be abstracted into lower dimensional summary data, such as packet flow\nrecords, where some of the temporal complexities of packet data can be\nmitigated, and smaller well-engineered feature subsets can be created. This\ndata can be invaluable as training data for machine learning and cyber threat\ndetection techniques. Data can be collected in real-time, or from historical\npacket trace archives. In this paper we focus on how flow records and summary\nmetadata can be extracted from packet data with high accuracy and robustness.\nWe identify limitations in current methods, how they may impact datasets, and\nhow these flaws may impact learning models. Finally, we propose methods to\nimprove the state of the art and introduce proof of concept tools to support\nthis work.",
            "author": [
                "Anthony Kenyon",
                "David Elizondo",
                "Lipika Deka"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09834v1",
                "http://arxiv.org/pdf/2310.09834v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09833v2",
            "title": "MIR2: Towards Provably Robust Multi-Agent Reinforcement Learning by\n  Mutual Information Regularization",
            "updated": "2023-10-31T15:49:12Z",
            "published": "2023-10-15T13:35:51Z",
            "summary": "Robust multi-agent reinforcement learning (MARL) necessitates resilience to\nuncertain or worst-case actions by unknown allies. Existing max-min\noptimization techniques in robust MARL seek to enhance resilience by training\nagents against worst-case adversaries, but this becomes intractable as the\nnumber of agents grows, leading to exponentially increasing worst-case\nscenarios. Attempts to simplify this complexity often yield overly pessimistic\npolicies, inadequate robustness across scenarios and high computational\ndemands. Unlike these approaches, humans naturally learn adaptive and resilient\nbehaviors without the necessity of preparing for every conceivable worst-case\nscenario. Motivated by this, we propose MIR2, which trains policy in routine\nscenarios and minimize Mutual Information as Robust Regularization.\nTheoretically, we frame robustness as an inference problem and prove that\nminimizing mutual information between histories and actions implicitly\nmaximizes a lower bound on robustness under certain assumptions. Further\nanalysis reveals that our proposed approach prevents agents from overreacting\nto others through an information bottleneck and aligns the policy with a robust\naction prior. Empirically, our MIR2 displays even greater resilience against\nworst-case adversaries than max-min optimization in StarCraft II, Multi-agent\nMujoco and rendezvous. Our superiority is consistent when deployed in\nchallenging real-world robot swarm control scenario. See code and demo videos\nin Supplementary Materials.",
            "author": [
                "Simin Li",
                "Ruixiao Xu",
                "Jun Guo",
                "Pu Feng",
                "Jiakai Wang",
                "Aishan Liu",
                "Yaodong Yang",
                "Xianglong Liu",
                "Weifeng Lv"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09833v2",
                "http://arxiv.org/pdf/2310.09833v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09831v1",
            "title": "MAGIC: Detecting Advanced Persistent Threats via Masked Graph\n  Representation Learning",
            "updated": "2023-10-15T13:27:06Z",
            "published": "2023-10-15T13:27:06Z",
            "summary": "Advance Persistent Threats (APTs), adopted by most delicate attackers, are\nbecoming increasing common and pose great threat to various enterprises and\ninstitutions. Data provenance analysis on provenance graphs has emerged as a\ncommon approach in APT detection. However, previous works have exhibited\nseveral shortcomings: (1) requiring attack-containing data and a priori\nknowledge of APTs, (2) failing in extracting the rich contextual information\nburied within provenance graphs and (3) becoming impracticable due to their\nprohibitive computation overhead and memory consumption.\n  In this paper, we introduce MAGIC, a novel and flexible self-supervised APT\ndetection approach capable of performing multi-granularity detection under\ndifferent level of supervision. MAGIC leverages masked graph representation\nlearning to model benign system entities and behaviors, performing efficient\ndeep feature extraction and structure abstraction on provenance graphs. By\nferreting out anomalous system behaviors via outlier detection methods, MAGIC\nis able to perform both system entity level and batched log level APT\ndetection. MAGIC is specially designed to handle concept drift with a model\nadaption mechanism and successfully applies to universal conditions and\ndetection scenarios. We evaluate MAGIC on three widely-used datasets, including\nboth real-world and simulated attacks. Evaluation results indicate that MAGIC\nachieves promising detection results in all scenarios and shows enormous\nadvantage over state-of-the-art APT detection approaches in performance\noverhead.",
            "author": [
                "Zian Jia",
                "Yun Xiong",
                "Yuhong Nan",
                "Yao Zhang",
                "Jinjing Zhao",
                "Mi Wen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09831v1",
                "http://arxiv.org/pdf/2310.09831v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09828v1",
            "title": "Top-K Pooling with Patch Contrastive Learning for Weakly-Supervised\n  Semantic Segmentation",
            "updated": "2023-10-15T13:19:59Z",
            "published": "2023-10-15T13:19:59Z",
            "summary": "Weakly Supervised Semantic Segmentation (WSSS) using only image-level labels\nhas gained significant attention due to cost-effectiveness. Recently, Vision\nTransformer (ViT) based methods without class activation map (CAM) have shown\ngreater capability in generating reliable pseudo labels than previous methods\nusing CAM. However, the current ViT-based methods utilize max pooling to select\nthe patch with the highest prediction score to map the patch-level\nclassification to the image-level one, which may affect the quality of pseudo\nlabels due to the inaccurate classification of the patches. In this paper, we\nintroduce a novel ViT-based WSSS method named top-K pooling with patch\ncontrastive learning (TKP-PCL), which employs a top-K pooling layer to\nalleviate the limitations of previous max pooling selection. A patch\ncontrastive error (PCE) is also proposed to enhance the patch embeddings to\nfurther improve the final results. The experimental results show that our\napproach is very efficient and outperforms other state-of-the-art WSSS methods\non the PASCAL VOC 2012 dataset.",
            "author": [
                "Wangyu Wu",
                "Tianhong Dai",
                "Xiaowei Huang",
                "Fei Ma",
                "Jimin Xiao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09828v1",
                "http://arxiv.org/pdf/2310.09828v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09827v1",
            "title": "VFLAIR: A Research Library and Benchmark for Vertical Federated Learning",
            "updated": "2023-10-15T13:18:31Z",
            "published": "2023-10-15T13:18:31Z",
            "summary": "Vertical Federated Learning (VFL) has emerged as a collaborative training\nparadigm that allows participants with different features of the same group of\nusers to accomplish cooperative training without exposing their raw data or\nmodel parameters. VFL has gained significant attention for its research\npotential and real-world applications in recent years, but still faces\nsubstantial challenges, such as in defending various kinds of data inference\nand backdoor attacks. Moreover, most of existing VFL projects are\nindustry-facing and not easily used for keeping track of the current research\nprogress. To address this need, we present an extensible and lightweight VFL\nframework VFLAIR (available at https://github.com/FLAIR-THU/VFLAIR), which\nsupports VFL training with a variety of models, datasets and protocols, along\nwith standardized modules for comprehensive evaluations of attacks and defense\nstrategies. We also benchmark 11 attacks and 8 defenses performance under\ndifferent communication and model partition settings and draw concrete insights\nand recommendations on the choice of defense strategies for different practical\nVFL deployment scenario.",
            "author": [
                "Tianyuan Zou",
                "Zixuan Gu",
                "Yu He",
                "Hideaki Takahashi",
                "Yang Liu",
                "Guangnan Ye",
                "Ya-Qin Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09827v1",
                "http://arxiv.org/pdf/2310.09827v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10690v1",
            "title": "Large Language Models for In-Context Student Modeling: Synthesizing\n  Student's Behavior in Visual Programming from One-Shot Observation",
            "updated": "2023-10-15T12:56:13Z",
            "published": "2023-10-15T12:56:13Z",
            "summary": "Student modeling is central to many educational technologies as it enables\nthe prediction of future learning outcomes and targeted instructional\nstrategies. However, open-ended learning environments pose challenges for\naccurately modeling students due to the diverse behaviors exhibited by students\nand the absence of a well-defined set of learning skills. To approach these\nchallenges, we explore the application of Large Language Models (LLMs) for\nin-context student modeling in open-ended learning environments. We introduce a\nnovel framework, LLM-SS, that leverages LLMs for synthesizing student's\nbehavior. More concretely, given a particular student's solving attempt on a\nreference task as observation, the goal is to synthesize the student's attempt\non a target task. Our framework can be combined with different LLMs; moreover,\nwe fine-tune LLMs using domain-specific expertise to boost their understanding\nof domain background and student behaviors. We evaluate several concrete\nmethods based on LLM-SS using the StudentSyn benchmark, an existing student's\nattempt synthesis benchmark in visual programming. Experimental results show a\nsignificant improvement compared to baseline methods included in the StudentSyn\nbenchmark. Furthermore, our method using the fine-tuned Llama2-70B model\nimproves noticeably compared to using the base model and becomes on par with\nusing the state-of-the-art GPT-4 model.",
            "author": [
                "Manh Hung Nguyen",
                "Sebastian Tschiatschek",
                "Adish Singla"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10690v1",
                "http://arxiv.org/pdf/2310.10690v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09822v1",
            "title": "Turn Passive to Active: A Survey on Active Intellectual Property\n  Protection of Deep Learning Models",
            "updated": "2023-10-15T12:54:32Z",
            "published": "2023-10-15T12:54:32Z",
            "summary": "The intellectual property protection of deep learning (DL) models has\nattracted increasing serious concerns. Many works on intellectual property\nprotection for Deep Neural Networks (DNN) models have been proposed. The vast\nmajority of existing work uses DNN watermarking to verify the ownership of the\nmodel after piracy occurs, which is referred to as passive verification. On the\ncontrary, we focus on a new type of intellectual property protection method\nnamed active copyright protection, which refers to active authorization control\nand user identity management of the DNN model. As of now, there is relatively\nlimited research in the field of active DNN copyright protection. In this\nreview, we attempt to clearly elaborate on the connotation, attributes, and\nrequirements of active DNN copyright protection, provide evaluation methods and\nmetrics for active copyright protection, review and analyze existing work on\nactive DL model intellectual property protection, discuss potential attacks\nthat active DL model copyright protection techniques may face, and provide\nchallenges and future directions for active DL model intellectual property\nprotection. This review is helpful to systematically introduce the new field of\nactive DNN copyright protection and provide reference and foundation for\nsubsequent work.",
            "author": [
                "Mingfu Xue",
                "Leo Yu Zhang",
                "Yushu Zhang",
                "Weiqiang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09822v1",
                "http://arxiv.org/pdf/2310.09822v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09821v1",
            "title": "LICO: Explainable Models with Language-Image Consistency",
            "updated": "2023-10-15T12:44:33Z",
            "published": "2023-10-15T12:44:33Z",
            "summary": "Interpreting the decisions of deep learning models has been actively studied\nsince the explosion of deep neural networks. One of the most convincing\ninterpretation approaches is salience-based visual interpretation, such as\nGrad-CAM, where the generation of attention maps depends merely on categorical\nlabels. Although existing interpretation methods can provide explainable\ndecision clues, they often yield partial correspondence between image and\nsaliency maps due to the limited discriminative information from one-hot\nlabels. This paper develops a Language-Image COnsistency model for explainable\nimage classification, termed LICO, by correlating learnable linguistic prompts\nwith corresponding visual features in a coarse-to-fine manner. Specifically, we\nfirst establish a coarse global manifold structure alignment by minimizing the\ndistance between the distributions of image and language features. We then\nachieve fine-grained saliency maps by applying optimal transport (OT) theory to\nassign local feature maps with class-specific prompts. Extensive experimental\nresults on eight benchmark datasets demonstrate that the proposed LICO achieves\na significant improvement in generating more explainable attention maps in\nconjunction with existing interpretation methods such as Grad-CAM. Remarkably,\nLICO improves the classification performance of existing models without\nintroducing any computational overhead during inference. Source code is made\navailable at https://github.com/ymLeiFDU/LICO.",
            "author": [
                "Yiming Lei",
                "Zilong Li",
                "Yangyang Li",
                "Junping Zhang",
                "Hongming Shan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09821v1",
                "http://arxiv.org/pdf/2310.09821v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09819v2",
            "title": "Optimizing K-means for Big Data: A Comparative Study",
            "updated": "2023-12-07T11:11:18Z",
            "published": "2023-10-15T12:35:27Z",
            "summary": "This paper presents a comparative analysis of different optimization\ntechniques for the K-means algorithm in the context of big data. K-means is a\nwidely used clustering algorithm, but it can suffer from scalability issues\nwhen dealing with large datasets. The paper explores different approaches to\novercome these issues, including parallelization, approximation, and sampling\nmethods. The authors evaluate the performance of these techniques on various\nbenchmark datasets and compare them in terms of speed, quality of clustering,\nand scalability according to the LIMA dominance criterion. The results show\nthat different techniques are more suitable for different types of datasets and\nprovide insights into the trade-offs between speed and accuracy in K-means\nclustering for big data. Overall, the paper offers a comprehensive guide for\npractitioners and researchers on how to optimize K-means for big data\napplications.",
            "author": [
                "Ravil Mussabayev",
                "Rustam Mussabayev"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09819v2",
                "http://arxiv.org/pdf/2310.09819v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09806v1",
            "title": "Can LSH (Locality-Sensitive Hashing) Be Replaced by Neural Network?",
            "updated": "2023-10-15T11:41:54Z",
            "published": "2023-10-15T11:41:54Z",
            "summary": "With the rapid development of GPU (Graphics Processing Unit) technologies and\nneural networks, we can explore more appropriate data structures and\nalgorithms. Recent progress shows that neural networks can partly replace\ntraditional data structures. In this paper, we proposed a novel DNN (Deep\nNeural Network)-based learned locality-sensitive hashing, called LLSH, to\nefficiently and flexibly map high-dimensional data to low-dimensional space.\nLLSH replaces the traditional LSH (Locality-sensitive Hashing) function\nfamilies with parallel multi-layer neural networks, which reduces the time and\nmemory consumption and guarantees query accuracy simultaneously. The proposed\nLLSH demonstrate the feasibility of replacing the hash index with\nlearning-based neural networks and open a new door for developers to design and\nconfigure data organization more accurately to improve information-searching\nperformance. Extensive experiments on different types of datasets show the\nsuperiority of the proposed method in query accuracy, time consumption, and\nmemory usage.",
            "author": [
                "Renyang Liu",
                "Jun Zhao",
                "Xing Chu",
                "Yu Liang",
                "Wei Zhou",
                "Jing He"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09806v1",
                "http://arxiv.org/pdf/2310.09806v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09804v1",
            "title": "Communication Compression for Byzantine Robust Learning: New Efficient\n  Algorithms and Improved Rates",
            "updated": "2023-10-15T11:22:34Z",
            "published": "2023-10-15T11:22:34Z",
            "summary": "Byzantine robustness is an essential feature of algorithms for certain\ndistributed optimization problems, typically encountered in\ncollaborative/federated learning. These problems are usually huge-scale,\nimplying that communication compression is also imperative for their\nresolution. These factors have spurred recent algorithmic and theoretical\ndevelopments in the literature of Byzantine-robust learning with compression.\nIn this paper, we contribute to this research area in two main directions.\nFirst, we propose a new Byzantine-robust method with compression --\nByz-DASHA-PAGE -- and prove that the new method has better convergence rate\n(for non-convex and Polyak-Lojasiewicz smooth optimization problems), smaller\nneighborhood size in the heterogeneous case, and tolerates more Byzantine\nworkers under over-parametrization than the previous method with SOTA\ntheoretical convergence guarantees (Byz-VR-MARINA). Secondly, we develop the\nfirst Byzantine-robust method with communication compression and error feedback\n-- Byz-EF21 -- along with its bidirectional compression version -- Byz-EF21-BC\n-- and derive the convergence rates for these methods for non-convex and\nPolyak-Lojasiewicz smooth case. We test the proposed methods and illustrate our\ntheoretical findings in the numerical experiments.",
            "author": [
                "Ahmad Rammal",
                "Kaja Gruntkowska",
                "Nikita Fedin",
                "Eduard Gorbunov",
                "Peter Richt\u00e1rik"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09804v1",
                "http://arxiv.org/pdf/2310.09804v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG",
                "90C26"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09800v1",
            "title": "Model Inversion Attacks on Homogeneous and Heterogeneous Graph Neural\n  Networks",
            "updated": "2023-10-15T11:16:14Z",
            "published": "2023-10-15T11:16:14Z",
            "summary": "Recently, Graph Neural Networks (GNNs), including Homogeneous Graph Neural\nNetworks (HomoGNNs) and Heterogeneous Graph Neural Networks (HeteGNNs), have\nmade remarkable progress in many physical scenarios, especially in\ncommunication applications. Despite achieving great success, the privacy issue\nof such models has also received considerable attention. Previous studies have\nshown that given a well-fitted target GNN, the attacker can reconstruct the\nsensitive training graph of this model via model inversion attacks, leading to\nsignificant privacy worries for the AI service provider. We advocate that the\nvulnerability comes from the target GNN itself and the prior knowledge about\nthe shared properties in real-world graphs. Inspired by this, we propose a\nnovel model inversion attack method on HomoGNNs and HeteGNNs, namely HomoGMI\nand HeteGMI. Specifically, HomoGMI and HeteGMI are gradient-descent-based\noptimization methods that aim to maximize the cross-entropy loss on the target\nGNN and the $1^{st}$ and $2^{nd}$-order proximities on the reconstructed graph.\nNotably, to the best of our knowledge, HeteGMI is the first attempt to perform\nmodel inversion attacks on HeteGNNs. Extensive experiments on multiple\nbenchmarks demonstrate that the proposed method can achieve better performance\nthan the competitors.",
            "author": [
                "Renyang Liu",
                "Wei Zhou",
                "Jinhong Zhang",
                "Xiaoyuan Liu",
                "Peiyuan Si",
                "Haoran Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09800v1",
                "http://arxiv.org/pdf/2310.09800v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09797v1",
            "title": "A Number Representation Systems Library Supporting New Representations\n  Based on Morris Tapered Floating-point with Hidden Exponent Bit",
            "updated": "2023-10-15T10:59:41Z",
            "published": "2023-10-15T10:59:41Z",
            "summary": "The introduction of posit reopened the debate about the utility of IEEE754 in\nspecific domains. In this context, we propose a high-level language (Scala)\nlibrary that aims to reduce the effort of designing and testing new number\nrepresentation systems (NRSs). The library's efficiency is tested with three\nnew NRSs derived from Morris Tapered Floating-Point by adding a hidden exponent\nbit. We call these NRSs MorrisHEB, MorrisBiasHEB, and MorrisUnaryHEB,\nrespectively. We show that they offer a better dynamic range, better decimal\naccuracy for unary operations, more exact results for addition (37.61% in the\ncase of MorrisUnaryHEB), and better average decimal accuracy for inexact\nresults on binary operations than posit and IEEE754. Going through existing\nbenchmarks in the literature, and favorable/unfavorable examples for\nIEEE754/posit, we show that these new NRSs produce similar (less than one\ndecimal accuracy difference) or even better results than IEEE754 and posit.\nGiven the entire spectrum of results, there are arguments for MorrisBiasHEB to\nbe used as a replacement for IEEE754 in general computations. MorrisUnaryHEB\nhas a more populated ``golden zone'' (+13.6%) and a better dynamic range (149X)\nthan posit, making it a candidate for machine learning computations.",
            "author": [
                "Stefan-Dan Ciocirlan",
                "Dumitrel Loghin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09797v1",
                "http://arxiv.org/pdf/2310.09797v1"
            ],
            "primary_category": "cs.MS",
            "category": [
                "cs.MS",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09791v1",
            "title": "Auto-LfD: Towards Closing the Loop for Learning from Demonstrations",
            "updated": "2023-10-15T10:38:06Z",
            "published": "2023-10-15T10:38:06Z",
            "summary": "Over the past few years, there have been numerous works towards advancing the\ngeneralization capability of robots, among which learning from demonstrations\n(LfD) has drawn much attention by virtue of its user-friendly and\ndata-efficient nature. While many LfD solutions have been reported, a key\nquestion has not been properly addressed: how can we evaluate the\ngeneralization performance of LfD? For instance, when a robot draws a letter\nthat needs to pass through new desired points, how does it ensure the new\ntrajectory maintains a similar shape to the demonstration? This question\nbecomes more relevant when a new task is significantly far from the\ndemonstrated region. To tackle this issue, a user often resorts to manual\ntuning of the hyperparameters of an LfD approach until a satisfactory\ntrajectory is attained. In this paper, we aim to provide closed-loop evaluative\nfeedback for LfD and optimize LfD in an automatic fashion. Specifically, we\nconsider dynamical movement primitives (DMP) and kernelized movement primitives\n(KMP) as examples and develop a generic optimization framework capable of\nmeasuring the generalization performance of DMP and KMP and auto-optimizing\ntheir hyperparameters without any human inputs. Evaluations including a\npeg-in-hole task and a pushing task on a real robot evidence the applicability\nof our framework.",
            "author": [
                "Shaokang Wu",
                "Yijin Wang",
                "Yanlong Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09791v1",
                "http://arxiv.org/pdf/2310.09791v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09789v1",
            "title": "FLrce: Efficient Federated Learning with Relationship-based Client\n  Selection and Early-Stopping Strategy",
            "updated": "2023-10-15T10:13:44Z",
            "published": "2023-10-15T10:13:44Z",
            "summary": "Federated learning (FL) achieves great popularity in broad areas as a\npowerful interface to offer intelligent services to customers while maintaining\ndata privacy. Nevertheless, FL faces communication and computation bottlenecks\ndue to limited bandwidth and resource constraints of edge devices. To\ncomprehensively address the bottlenecks, the technique of dropout is\nintroduced, where resource-constrained edge devices are allowed to\ncollaboratively train a subset of the global model parameters. However, dropout\nimpedes the learning efficiency of FL under unbalanced local data\ndistributions. As a result, FL requires more rounds to achieve appropriate\naccuracy, consuming more communication and computation resources. In this\npaper, we present FLrce, an efficient FL framework with a relationship-based\nclient selection and early-stopping strategy. FLrce accelerates the FL process\nby selecting clients with more significant effects, enabling the global model\nto converge to a high accuracy in fewer rounds. FLrce also leverages an early\nstopping mechanism to terminate FL in advance to save communication and\ncomputation resources. Experiment results show that FLrce increases the\ncommunication and computation efficiency by 6% to 73.9% and 20% to 79.5%,\nrespectively, while maintaining competitive accuracy.",
            "author": [
                "Ziru Niu",
                "Hai Dong",
                "A. Kai Qin",
                "Tao Gu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09789v1",
                "http://arxiv.org/pdf/2310.09789v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "I.2.6"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09787v1",
            "title": "Dynamic Link Prediction for New Nodes in Temporal Graph Networks",
            "updated": "2023-10-15T09:54:18Z",
            "published": "2023-10-15T09:54:18Z",
            "summary": "Modelling temporal networks for dynamic link prediction of new nodes has many\nreal-world applications, such as providing relevant item recommendations to new\ncustomers in recommender systems and suggesting appropriate posts to new users\non social platforms. Unlike old nodes, new nodes have few historical links,\nwhich poses a challenge for the dynamic link prediction task. Most existing\ndynamic models treat all nodes equally and are not specialized for new nodes,\nresulting in suboptimal performances. In this paper, we consider dynamic link\nprediction of new nodes as a few-shot problem and propose a novel model based\non the meta-learning principle to effectively mitigate this problem.\nSpecifically, we develop a temporal encoder with a node-level span memory to\nobtain a new node embedding, and then we use a predictor to determine whether\nthe new node generates a link. To overcome the few-shot challenge, we\nincorporate the encoder-predictor into the meta-learning paradigm, which can\nlearn two types of implicit information during the formation of the temporal\nnetwork through span adaptation and node adaptation. The acquired implicit\ninformation can serve as model initialisation and facilitate rapid adaptation\nto new nodes through a fine-tuning process on just a few links. Experiments on\nthree publicly available datasets demonstrate the superior performance of our\nmodel compared to existing state-of-the-art methods.",
            "author": [
                "Xiaobo Zhu",
                "Yan Wu",
                "Qinhu Zhang",
                "Zhanheng Chen",
                "Ying He"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09787v1",
                "http://arxiv.org/pdf/2310.09787v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09780v1",
            "title": "Notes on Applicability of Explainable AI Methods to Machine Learning\n  Models Using Features Extracted by Persistent Homology",
            "updated": "2023-10-15T08:56:15Z",
            "published": "2023-10-15T08:56:15Z",
            "summary": "Data analysis that uses the output of topological data analysis as input for\nmachine learning algorithms has been the subject of extensive research. This\napproach offers a means of capturing the global structure of data. Persistent\nhomology (PH), a common methodology within the field of TDA, has found\nwide-ranging applications in machine learning. One of the key reasons for the\nsuccess of the PH-ML pipeline lies in the deterministic nature of feature\nextraction conducted through PH. The ability to achieve satisfactory levels of\naccuracy with relatively simple downstream machine learning models, when\nprocessing these extracted features, underlines the pipeline's superior\ninterpretability. However, it must be noted that this interpretation has\nencountered issues. Specifically, it fails to accurately reflect the feasible\nparameter region in the data generation process, and the physical or chemical\nconstraints that restrict this process. Against this backdrop, we explore the\npotential application of explainable AI methodologies to this PH-ML pipeline.\nWe apply this approach to the specific problem of predicting gas adsorption in\nmetal-organic frameworks and demonstrate that it can yield suggestive results.\nThe codes to reproduce our results are available at\nhttps://github.com/naofumihama/xai_ph_ml",
            "author": [
                "Naofumi Hama"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09780v1",
                "http://arxiv.org/pdf/2310.09780v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09772v1",
            "title": "Revisiting Graph Meaning Representations through Decoupling Contextual\n  Representation Learning and Structural Information Propagation",
            "updated": "2023-10-15T08:07:56Z",
            "published": "2023-10-15T08:07:56Z",
            "summary": "In the field of natural language understanding, the intersection of neural\nmodels and graph meaning representations (GMRs) remains a compelling area of\nresearch. Despite the growing interest, a critical gap persists in\nunderstanding the exact influence of GMRs, particularly concerning relation\nextraction tasks. Addressing this, we introduce DAGNN-plus, a simple and\nparameter-efficient neural architecture designed to decouple contextual\nrepresentation learning from structural information propagation. Coupled with\nvarious sequence encoders and GMRs, this architecture provides a foundation for\nsystematic experimentation on two English and two Chinese datasets. Our\nempirical analysis utilizes four different graph formalisms and nine parsers.\nThe results yield a nuanced understanding of GMRs, showing improvements in\nthree out of the four datasets, particularly favoring English over Chinese due\nto highly accurate parsers. Interestingly, GMRs appear less effective in\nliterary-domain datasets compared to general-domain datasets. These findings\nlay the groundwork for better-informed design of GMRs and parsers to improve\nrelation classification, which is expected to tangibly impact the future\ntrajectory of natural language understanding research.",
            "author": [
                "Li Zhou",
                "Wenyu Chen",
                "Dingyi Zeng",
                "Hong Qu",
                "Daniel Hershcovich"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09772v1",
                "http://arxiv.org/pdf/2310.09772v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13715v1",
            "title": "Digital Deception: Generative Artificial Intelligence in Social\n  Engineering and Phishing",
            "updated": "2023-10-15T07:55:59Z",
            "published": "2023-10-15T07:55:59Z",
            "summary": "The advancement of Artificial Intelligence (AI) and Machine Learning (ML) has\nprofound implications for both the utility and security of our digital\ninteractions. This paper investigates the transformative role of Generative AI\nin Social Engineering (SE) attacks. We conduct a systematic review of social\nengineering and AI capabilities and use a theory of social engineering to\nidentify three pillars where Generative AI amplifies the impact of SE attacks:\nRealistic Content Creation, Advanced Targeting and Personalization, and\nAutomated Attack Infrastructure. We integrate these elements into a conceptual\nmodel designed to investigate the complex nature of AI-driven SE attacks - the\nGenerative AI Social Engineering Framework. We further explore human\nimplications and potential countermeasures to mitigate these risks. Our study\naims to foster a deeper understanding of the risks, human implications, and\ncountermeasures associated with this emerging paradigm, thereby contributing to\na more secure and trustworthy human-computer interaction.",
            "author": [
                "Marc Schmitt",
                "Ivan Flechais"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13715v1",
                "http://arxiv.org/pdf/2310.13715v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.CY",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09766v1",
            "title": "Pseudo-Bayesian Optimization",
            "updated": "2023-10-15T07:55:28Z",
            "published": "2023-10-15T07:55:28Z",
            "summary": "Bayesian Optimization is a popular approach for optimizing expensive\nblack-box functions. Its key idea is to use a surrogate model to approximate\nthe objective and, importantly, quantify the associated uncertainty that allows\na sequential search of query points that balance exploitation-exploration.\nGaussian process (GP) has been a primary candidate for the surrogate model,\nthanks to its Bayesian-principled uncertainty quantification power and modeling\nflexibility. However, its challenges have also spurred an array of alternatives\nwhose convergence properties could be more opaque. Motivated by these, we study\nin this paper an axiomatic framework that elicits the minimal requirements to\nguarantee black-box optimization convergence that could apply beyond GP-related\nmethods. Moreover, we leverage the design freedom in our framework, which we\ncall Pseudo-Bayesian Optimization, to construct empirically superior\nalgorithms. In particular, we show how using simple local regression, and a\nsuitable \"randomized prior\" construction to quantify uncertainty, not only\nguarantees convergence but also consistently outperforms state-of-the-art\nbenchmarks in examples ranging from high-dimensional synthetic experiments to\nrealistic hyperparameter tuning and robotic applications.",
            "author": [
                "Haoxian Chen",
                "Henry Lam"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09766v1",
                "http://arxiv.org/pdf/2310.09766v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09765v1",
            "title": "Improving Access to Justice for the Indian Population: A Benchmark for\n  Evaluating Translation of Legal Text to Indian Languages",
            "updated": "2023-10-15T07:49:56Z",
            "published": "2023-10-15T07:49:56Z",
            "summary": "Most legal text in the Indian judiciary is written in complex English due to\nhistorical reasons. However, only about 10% of the Indian population is\ncomfortable in reading English. Hence legal text needs to be made available in\nvarious Indian languages, possibly by translating the available legal text from\nEnglish. Though there has been a lot of research on translation to and between\nIndian languages, to our knowledge, there has not been much prior work on such\ntranslation in the legal domain. In this work, we construct the first\nhigh-quality legal parallel corpus containing aligned text units in English and\nnine Indian languages, that includes several low-resource languages. We also\nbenchmark the performance of a wide variety of Machine Translation (MT) systems\nover this corpus, including commercial MT systems, open-source MT systems and\nLarge Language Models. Through a comprehensive survey by Law practitioners, we\ncheck how satisfied they are with the translations by some of these MT systems,\nand how well automatic MT evaluation metrics agree with the opinions of Law\npractitioners.",
            "author": [
                "Sayan Mahapatra",
                "Debtanu Datta",
                "Shubham Soni",
                "Adrijit Goswami",
                "Saptarshi Ghosh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09765v1",
                "http://arxiv.org/pdf/2310.09765v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09764v1",
            "title": "DropMix: Better Graph Contrastive Learning with Harder Negative Samples",
            "updated": "2023-10-15T07:45:30Z",
            "published": "2023-10-15T07:45:30Z",
            "summary": "While generating better negative samples for contrastive learning has been\nwidely studied in the areas of CV and NLP, very few work has focused on\ngraph-structured data. Recently, Mixup has been introduced to synthesize hard\nnegative samples in graph contrastive learning (GCL). However, due to the\nunsupervised learning nature of GCL, without the help of soft labels, directly\nmixing representations of samples could inadvertently lead to the information\nloss of the original hard negative and further adversely affect the quality of\nthe newly generated harder negative. To address the problem, in this paper, we\npropose a novel method DropMix to synthesize harder negative samples, which\nconsists of two main steps. Specifically, we first select some hard negative\nsamples by measuring their hardness from both local and global views in the\ngraph simultaneously. After that, we mix hard negatives only on partial\nrepresentation dimensions to generate harder ones and decrease the information\nloss caused by Mixup. We conduct extensive experiments to verify the\neffectiveness of DropMix on six benchmark datasets. Our results show that our\nmethod can lead to better GCL performance. Our data and codes are publicly\navailable at https://github.com/Mayueq/DropMix-Code.",
            "author": [
                "Yueqi Ma",
                "Minjie Chen",
                "Xiang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09764v1",
                "http://arxiv.org/pdf/2310.09764v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09762v1",
            "title": "Diversifying the Mixture-of-Experts Representation for Language Models\n  with Orthogonal Optimizer",
            "updated": "2023-10-15T07:20:28Z",
            "published": "2023-10-15T07:20:28Z",
            "summary": "The Mixture of Experts (MoE) has emerged as a highly successful technique in\ndeep learning, based on the principle of divide-and-conquer to maximize model\ncapacity without significant additional computational cost. Even in the era of\nlarge-scale language models (LLMs), MoE continues to play a crucial role, as\nsome researchers have indicated that GPT-4 adopts the MoE structure to ensure\ndiverse inference results. However, MoE is susceptible to performance\ndegeneracy, particularly evident in the issues of imbalance and homogeneous\nrepresentation among experts. While previous studies have extensively addressed\nthe problem of imbalance, the challenge of homogeneous representation remains\nunresolved. In this study, we shed light on the homogeneous representation\nproblem, wherein experts in the MoE fail to specialize and lack diversity,\nleading to frustratingly high similarities in their representations (up to 99%\nin a well-performed MoE model). This problem restricts the expressive power of\nthe MoE and, we argue, contradicts its original intention. To tackle this\nissue, we propose a straightforward yet highly effective solution: OMoE, an\northogonal expert optimizer. Additionally, we introduce an alternating training\nstrategy that encourages each expert to update in a direction orthogonal to the\nsubspace spanned by other experts. Our algorithm facilitates MoE training in\ntwo key ways: firstly, it explicitly enhances representation diversity, and\nsecondly, it implicitly fosters interaction between experts during orthogonal\nweights computation. Through extensive experiments, we demonstrate that our\nproposed optimization algorithm significantly improves the performance of\nfine-tuning the MoE model on the GLUE benchmark, SuperGLUE benchmark,\nquestion-answering task, and name entity recognition tasks.",
            "author": [
                "Boan Liu",
                "Liang Ding",
                "Li Shen",
                "Keqin Peng",
                "Yu Cao",
                "Dazhao Cheng",
                "Dacheng Tao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09762v1",
                "http://arxiv.org/pdf/2310.09762v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09761v1",
            "title": "CAPro: Webly Supervised Learning with Cross-Modality Aligned Prototypes",
            "updated": "2023-10-15T07:20:22Z",
            "published": "2023-10-15T07:20:22Z",
            "summary": "Webly supervised learning has attracted increasing attention for its\neffectiveness in exploring publicly accessible data at scale without manual\nannotation. However, most existing methods of learning with web datasets are\nfaced with challenges from label noise, and they have limited assumptions on\nclean samples under various noise. For instance, web images retrieved with\nqueries of tiger cat (a cat species) and drumstick (a musical instrument) are\nalmost dominated by images of tigers and chickens, which exacerbates the\nchallenge of fine-grained visual concept learning. In this case, exploiting\nboth web images and their associated texts is a requisite solution to combat\nreal-world noise. In this paper, we propose Cross-modality Aligned Prototypes\n(CAPro), a unified prototypical contrastive learning framework to learn visual\nrepresentations with correct semantics. For one thing, we leverage textual\nprototypes, which stem from the distinct concept definition of classes, to\nselect clean images by text matching and thus disambiguate the formation of\nvisual prototypes. For another, to handle missing and mismatched noisy texts,\nwe resort to the visual feature space to complete and enhance individual texts\nand thereafter improve text matching. Such semantically aligned visual\nprototypes are further polished up with high-quality samples, and engaged in\nboth cluster regularization and noise removal. Besides, we propose collective\nbootstrapping to encourage smoother and wiser label reference from\nappearance-similar instances in a manner of dictionary look-up. Extensive\nexperiments on WebVision1k and NUS-WIDE (Web) demonstrate that CAPro well\nhandles realistic noise under both single-label and multi-label scenarios.\nCAPro achieves new state-of-the-art performance and exhibits robustness to\nopen-set recognition. Codes are available at https://github.com/yuleiqin/capro.",
            "author": [
                "Yulei Qin",
                "Xingyu Chen",
                "Yunhang Shen",
                "Chaoyou Fu",
                "Yun Gu",
                "Ke Li",
                "Xing Sun",
                "Rongrong Ji"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09761v1",
                "http://arxiv.org/pdf/2310.09761v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09757v1",
            "title": "MoEmo Vision Transformer: Integrating Cross-Attention and Movement\n  Vectors in 3D Pose Estimation for HRI Emotion Detection",
            "updated": "2023-10-15T06:52:15Z",
            "published": "2023-10-15T06:52:15Z",
            "summary": "Emotion detection presents challenges to intelligent human-robot interaction\n(HRI). Foundational deep learning techniques used in emotion detection are\nlimited by information-constrained datasets or models that lack the necessary\ncomplexity to learn interactions between input data elements, such as the the\nvariance of human emotions across different contexts. In the current effort, we\nintroduce 1) MoEmo (Motion to Emotion), a cross-attention vision transformer\n(ViT) for human emotion detection within robotics systems based on 3D human\npose estimations across various contexts, and 2) a data set that offers\nfull-body videos of human movement and corresponding emotion labels based on\nhuman gestures and environmental contexts. Compared to existing approaches, our\nmethod effectively leverages the subtle connections between movement vectors of\ngestures and environmental contexts through the use of cross-attention on the\nextracted movement vectors of full-body human gestures/poses and feature maps\nof environmental contexts. We implement a cross-attention fusion model to\ncombine movement vectors and environment contexts into a joint representation\nto derive emotion estimation. Leveraging our Naturalistic Motion Database, we\ntrain the MoEmo system to jointly analyze motion and context, yielding emotion\ndetection that outperforms the current state-of-the-art.",
            "author": [
                "David C. Jeong",
                "Tianma Shen",
                "Hongji Liu",
                "Raghav Kapoor",
                "Casey Nguyen",
                "Song Liu",
                "Christopher A. Kitts"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09757v1",
                "http://arxiv.org/pdf/2310.09757v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09753v1",
            "title": "When can transformers reason with abstract symbols?",
            "updated": "2023-10-15T06:45:38Z",
            "published": "2023-10-15T06:45:38Z",
            "summary": "We investigate the capabilities of transformer large language models (LLMs)\non relational reasoning tasks involving abstract symbols. Such tasks have long\nbeen studied in the neuroscience literature as fundamental building blocks for\nmore complex abilities in programming, mathematics, and verbal reasoning. For\n(i) regression tasks, we prove that transformers generalize when trained, but\nrequire astonishingly large quantities of training data. For (ii)\nnext-token-prediction tasks with symbolic labels, we show an \"inverse scaling\nlaw\": transformers fail to generalize as their embedding dimension increases.\nFor both settings (i) and (ii), we propose subtle transformer modifications\nwhich can reduce the amount of data needed by adding two trainable parameters\nper head.",
            "author": [
                "Enric Boix-Adsera",
                "Omid Saremi",
                "Emmanuel Abbe",
                "Samy Bengio",
                "Etai Littwin",
                "Joshua Susskind"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09753v1",
                "http://arxiv.org/pdf/2310.09753v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09751v2",
            "title": "UniTime: A Language-Empowered Unified Model for Cross-Domain Time Series\n  Forecasting",
            "updated": "2023-10-28T13:07:32Z",
            "published": "2023-10-15T06:30:22Z",
            "summary": "Multivariate time series forecasting plays a pivotal role in contemporary web\ntechnologies. In contrast to conventional methods that involve creating\ndedicated models for specific time series application domains, this research\nadvocates for a unified model paradigm that transcends domain boundaries.\nHowever, learning an effective cross-domain model presents the following\nchallenges. First, various domains exhibit disparities in data characteristics,\ne.g., the number of variables, posing hurdles for existing models that impose\ninflexible constraints on these factors. Second, the model may encounter\ndifficulties in distinguishing data from various domains, leading to suboptimal\nperformance in our assessments. Third, the diverse convergence rates of time\nseries domains can also result in compromised empirical performance. To address\nthese issues, we propose UniTime for effective cross-domain time series\nlearning. Concretely, UniTime can flexibly adapt to data with varying\ncharacteristics. It also uses domain instructions and a Language-TS Transformer\nto offer identification information and align two modalities. In addition,\nUniTime employs masking to alleviate domain convergence speed imbalance issues.\nOur extensive experiments demonstrate the effectiveness of UniTime in advancing\nstate-of-the-art forecasting performance and zero-shot transferability.",
            "author": [
                "Xu Liu",
                "Junfeng Hu",
                "Yuan Li",
                "Shizhe Diao",
                "Yuxuan Liang",
                "Bryan Hooi",
                "Roger Zimmermann"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09751v2",
                "http://arxiv.org/pdf/2310.09751v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09749v2",
            "title": "From Torch to Projector: Fundamental Tradeoff of Integrated Sensing and\n  Communications",
            "updated": "2023-10-17T12:30:20Z",
            "published": "2023-10-15T06:14:49Z",
            "summary": "Sensing and communications (S&C) have been historically developed in\nparallel. In recent decade, they have been evolving from separation to\nintegration, giving rise to the integrated sensing and communications (ISAC)\nparadigm, that has been recognized as one of the six key 6G usage scenarios.\nDespite the plethora of research works dedicated to ISAC signal processing, the\nfundamental performance limits of S&C remain widely unexplored in an ISAC\nsystem. In this tutorial paper, we attempt to summarize the recent research\nfindings in characterizing the performance boundary of ISAC systems and the\nresulting S&C tradeoff from an information-theoretical viewpoint. We begin with\na folklore \"torch metaphor\" that depicts the resource competition mechanism of\nS&C. Then, we elaborate on the fundamental capacity-distortion (C-D) theory,\nindicating the incompleteness of this metaphor. Towards that end, we further\nelaborate on the S&C tradeoff by discussing a special case within the C-D\nframework, namely the Cramer-Rao bound (CRB)-rate region. In particular, S&C\nhave preference discrepancies over both the subspace occupied by the\ntransmitted signal and the adopted codebook, leading to a \"projector metaphor\"\ncomplementary to the ISAC torch analogy. We also present two practical design\nexamples by leveraging the lessons learned from fundamental theories. Finally,\nwe conclude the paper by identifying a number of open challenges.",
            "author": [
                "Yifeng Xiong",
                "Fan Liu",
                "Kai Wan",
                "Weijie Yuan",
                "Yuanhao Cui",
                "Giuseppe Caire"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09749v2",
                "http://arxiv.org/pdf/2310.09749v2"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09748v1",
            "title": "Large Language Model-Aware In-Context Learning for Code Generation",
            "updated": "2023-10-15T06:12:58Z",
            "published": "2023-10-15T06:12:58Z",
            "summary": "Large language models (LLMs) have shown impressive in-context learning (ICL)\nability in code generation. LLMs take a prompt consisting of requirement-code\nexamples and a new requirement as input, and output new programs. Existing\nstudies have found that ICL is highly dominated by the examples and thus arises\nresearch on example selection. However, existing approaches randomly select\nexamples or only consider the textual similarity of requirements to retrieve,\nleading to sub-optimal performance. In this paper, we propose a novel\nlearning-based selection approach named LAIL (LLM-Aware In-context Learning)\nfor code generation. Given a candidate example, we exploit LLMs themselves to\nestimate it by considering the generation probabilities of ground-truth\nprograms given a requirement and the example. We then label candidate examples\nas positive or negative through the probability feedback. Based on the labeled\ndata, we import a contrastive learning objective to train an effective\nretriever that acquires the preference of LLMs in code generation. We apply\nLAIL to three LLMs and evaluate it on three representative datasets (e.g.,\nMBJP, MBPP, and MBCPP). LATA outperforms the state-of-the-art baselines by\n11.58%, 6.89%, and 5.07% on CodeGen, and 4.38%, 2.85%, and 2.74% on GPT-3.5 in\nterms of Pass@1, respectively.",
            "author": [
                "Jia Li",
                "Ge Li",
                "Chongyang Tao",
                "Jia Li",
                "Huangzhao Zhang",
                "Fang Liu",
                "Zhi Jin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09748v1",
                "http://arxiv.org/pdf/2310.09748v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09747v1",
            "title": "Staged Depthwise Correlation and Feature Fusion for Siamese Object\n  Tracking",
            "updated": "2023-10-15T06:04:42Z",
            "published": "2023-10-15T06:04:42Z",
            "summary": "In this work, we propose a novel staged depthwise correlation and feature\nfusion network, named DCFFNet, to further optimize the feature extraction for\nvisual tracking. We build our deep tracker upon a siamese network architecture,\nwhich is offline trained from scratch on multiple large-scale datasets in an\nend-to-end manner. The model contains a core component, that is, depthwise\ncorrelation and feature fusion module (correlation-fusion module), which\nfacilitates model to learn a set of optimal weights for a specific object by\nutilizing ensembles of multi-level features from lower and higher layers and\nmulti-channel semantics on the same layer. We combine the modified ResNet-50\nwith the proposed correlation-fusion layer to constitute the feature extractor\nof our model. In training process, we find the training of model become more\nstable, that benifits from the correlation-fusion module. For comprehensive\nevaluations of performance, we implement our tracker on the popular benchmarks,\nincluding OTB100, VOT2018 and LaSOT. Extensive experiment results demonstrate\nthat our proposed method achieves favorably competitive performance against\nmany leading trackers in terms of accuracy and precision, while satisfying the\nreal-time requirements of applications.",
            "author": [
                "Dianbo Ma",
                "Jianqiang Xiao",
                "Ziyan Gao",
                "Satoshi Yamane"
            ],
            "link": [
                "http://dx.doi.org/10.1109/IJCNN54540.2023.10191047",
                "http://arxiv.org/abs/2310.09747v1",
                "http://arxiv.org/pdf/2310.09747v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09729v1",
            "title": "Private Synthetic Data Meets Ensemble Learning",
            "updated": "2023-10-15T04:24:42Z",
            "published": "2023-10-15T04:24:42Z",
            "summary": "When machine learning models are trained on synthetic data and then deployed\non real data, there is often a performance drop due to the distribution shift\nbetween synthetic and real data. In this paper, we introduce a new ensemble\nstrategy for training downstream models, with the goal of enhancing their\nperformance when used on real data. We generate multiple synthetic datasets by\napplying a differential privacy (DP) mechanism several times in parallel and\nthen ensemble the downstream models trained on these datasets. While each\nsynthetic dataset might deviate more from the real data distribution, they\ncollectively increase sample diversity. This may enhance the robustness of\ndownstream models against distribution shifts. Our extensive experiments reveal\nthat while ensembling does not enhance downstream performance (compared with\ntraining a single model) for models trained on synthetic data generated by\nmarginal-based or workload-based DP mechanisms, our proposed ensemble strategy\ndoes improve the performance for models trained using GAN-based DP mechanisms\nin terms of both accuracy and calibration of downstream models.",
            "author": [
                "Haoyuan Sun",
                "Navid Azizan",
                "Akash Srivastava",
                "Hao Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09729v1",
                "http://arxiv.org/pdf/2310.09729v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09728v1",
            "title": "SVM based Multiclass Classifier for Gait phase Classification using\n  Shank IMU Sensor",
            "updated": "2023-10-15T04:23:08Z",
            "published": "2023-10-15T04:23:08Z",
            "summary": "In this study, a gait phase classification method based on SVM multiclass\nclassification is introduced, with a focus on the precise identification of the\nstance and swing phases, which are further subdivided into seven phases. Data\nfrom individual IMU sensors, such as Shank Acceleration X, Y, Z, Shank Gyro X,\nand Knee Angles, are used as features in this classification model. The\nsuggested technique successfully classifies the various gait phases with a\nsignificant accuracy of about 90.3%. Gait phase classification is crucial,\nespecially in the domains of exoskeletons and prosthetics, where accurate\nidentification of gait phases enables seamless integration with assistive\nequipment, improving mobility, stability, and energy economy. This study\nextends the study of gait and offers an effective method for correctly\nidentifying gait phases from Shank IMU sensor data, with potential applications\nin biomechanical research, exoskeletons, rehabilitation, and prosthetics.",
            "author": [
                "Aswadh Khumar G S",
                "Barath Kumar JK"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09728v1",
                "http://arxiv.org/pdf/2310.09728v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09727v2",
            "title": "Provably Fast Convergence of Independent Natural Policy Gradient for\n  Markov Potential Games",
            "updated": "2023-10-27T16:28:19Z",
            "published": "2023-10-15T04:10:44Z",
            "summary": "This work studies an independent natural policy gradient (NPG) algorithm for\nthe multi-agent reinforcement learning problem in Markov potential games. It is\nshown that, under mild technical assumptions and the introduction of the\n\\textit{suboptimality gap}, the independent NPG method with an oracle providing\nexact policy evaluation asymptotically reaches an $\\epsilon$-Nash Equilibrium\n(NE) within $\\mathcal{O}(1/\\epsilon)$ iterations. This improves upon the\nprevious best result of $\\mathcal{O}(1/\\epsilon^2)$ iterations and is of the\nsame order, $\\mathcal{O}(1/\\epsilon)$, that is achievable for the single-agent\ncase. Empirical results for a synthetic potential game and a congestion game\nare presented to verify the theoretical bounds.",
            "author": [
                "Youbang Sun",
                "Tao Liu",
                "Ruida Zhou",
                "P. R. Kumar",
                "Shahin Shahrampour"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09727v2",
                "http://arxiv.org/pdf/2310.09727v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10731v1",
            "title": "Gender-Based Comparative Study of Type 2 Diabetes Risk Factors in\n  Kolkata, India: A Machine Learning Approach",
            "updated": "2023-10-15T03:44:51Z",
            "published": "2023-10-15T03:44:51Z",
            "summary": "Type 2 diabetes mellitus represents a prevalent and widespread global health\nconcern, necessitating a comprehensive assessment of its risk factors. This\nstudy aimed towards learning whether there is any differential impact of age,\nLifestyle, BMI and Waist to height ratio on the risk of Type 2 diabetes\nmellitus in males and females in Kolkata, West Bengal, India based on a sample\nobserved from the out-patient consultation department of Belle Vue Clinic in\nKolkata. Various machine learning models like Logistic Regression, Random\nForest, and Support Vector Classifier, were used to predict the risk of\ndiabetes, and performance was compared based on different predictors. Our\nfindings indicate a significant age-related increase in risk of diabetes for\nboth males and females. Although exercising and BMI was found to have\nsignificant impact on the risk of Type 2 diabetes in males, in females both\nturned out to be statistically insignificant. For both males and females,\npredictive models based on WhtR demonstrated superior performance in risk\nassessment compared to those based on BMI. This study sheds light on the\ngender-specific differences in the risk factors for Type 2 diabetes, offering\nvaluable insights that can be used towards more targeted healthcare\ninterventions and public health strategies.",
            "author": [
                "Rahul Jain",
                "Anoushka Saha",
                "Gourav Daga",
                "Durba Bhattacharya",
                "Madhura Das Gupta",
                "Sourav Chowdhury",
                "Suparna Roychowdhury"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10731v1",
                "http://arxiv.org/pdf/2311.10731v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.med-ph",
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09720v1",
            "title": "HiCL: Hierarchical Contrastive Learning of Unsupervised Sentence\n  Embeddings",
            "updated": "2023-10-15T03:14:33Z",
            "published": "2023-10-15T03:14:33Z",
            "summary": "In this paper, we propose a hierarchical contrastive learning framework,\nHiCL, which considers local segment-level and global sequence-level\nrelationships to improve training efficiency and effectiveness. Traditional\nmethods typically encode a sequence in its entirety for contrast with others,\noften neglecting local representation learning, leading to challenges in\ngeneralizing to shorter texts. Conversely, HiCL improves its effectiveness by\ndividing the sequence into several segments and employing both local and global\ncontrastive learning to model segment-level and sequence-level relationships.\nFurther, considering the quadratic time complexity of transformers over input\ntokens, HiCL boosts training efficiency by first encoding short segments and\nthen aggregating them to obtain the sequence representation. Extensive\nexperiments show that HiCL enhances the prior top-performing SNCSE model across\nseven extensively evaluated STS tasks, with an average increase of +0.2%\nobserved on BERT-large and +0.44% on RoBERTa-large.",
            "author": [
                "Zhuofeng Wu",
                "Chaowei Xiao",
                "VG Vinod Vydiswaran"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09720v1",
                "http://arxiv.org/pdf/2310.09720v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09718v2",
            "title": "Efficient and Effective Deep Multi-view Subspace Clustering",
            "updated": "2023-12-04T01:15:56Z",
            "published": "2023-10-15T03:08:25Z",
            "summary": "Recent multi-view subspace clustering achieves impressive results utilizing\ndeep networks, where the self-expressive correlation is typically modeled by a\nfully connected (FC) layer. However, they still suffer from two limitations. i)\nThe parameter scale of the FC layer is quadratic to sample numbers, resulting\nin high time and memory costs that significantly degrade their feasibility in\nlarge-scale datasets. ii) It is under-explored to extract a unified\nrepresentation that simultaneously satisfies minimal sufficiency and\ndiscriminability. To this end, we propose a novel deep framework, termed\nEfficient and Effective deep Multi-View Subspace Clustering (E$^2$MVSC).\nInstead of a parameterized FC layer, we design a Relation-Metric Net that\ndecouples network parameter scale from sample numbers for greater computational\nefficiency. Most importantly, the proposed method devises a multi-type\nauto-encoder to explicitly decouple consistent, complementary, and superfluous\ninformation from every view, which is supervised by a soft clustering\nassignment similarity constraint. Following information bottleneck theory and\nthe maximal coding rate reduction principle, a sufficient yet minimal unified\nrepresentation can be obtained, as well as pursuing intra-cluster aggregation\nand inter-cluster separability within it. Extensive experiments show that\nE$^2$MVSC yields comparable results to existing methods and achieves\nstate-of-the-art performance in various types of multi-view datasets.",
            "author": [
                "Yuxiu Lin",
                "Hui Liu",
                "Ren Wang",
                "Qiang Guo",
                "Caiming Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09718v2",
                "http://arxiv.org/pdf/2310.09718v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09714v1",
            "title": "Enhancing Task Performance of Learned Simplified Models via\n  Reinforcement Learning",
            "updated": "2023-10-15T03:01:14Z",
            "published": "2023-10-15T03:01:14Z",
            "summary": "In contact-rich tasks, the hybrid, multi-modal nature of contact dynamics\nposes great challenges in model representation, planning, and control. Recent\nefforts have attempted to address these challenges via data-driven methods,\nlearning dynamical models in combination with model predictive control. Those\nmethods, while effective, rely solely on minimizing forward prediction errors\nto hope for better task performance with MPC controllers. This weak correlation\ncan result in data inefficiency as well as limitations to overall performance.\nIn response, we propose a novel strategy: using a policy gradient algorithm to\nfind a simplified dynamics model that explicitly maximizes task performance.\nSpecifically, we parameterize the stochastic policy as the perturbed output of\nthe MPC controller, thus, the learned model representation can directly\nassociate with the policy or task performance. We apply the proposed method to\ncontact-rich tasks where a three-fingered robotic hand manipulates previously\nunknown objects. Our method significantly enhances task success rate by up to\n15% in manipulating diverse objects compared to the existing method while\nsustaining data efficiency. Our method can solve some tasks with success rates\nof 70% or higher using under 30 minutes of data. All videos and codes are\navailable at https://sites.google.com/view/lcs-rl.",
            "author": [
                "Hien Bui",
                "Michael Posa"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09714v1",
                "http://arxiv.org/pdf/2310.09714v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09709v1",
            "title": "New Advances in Body Composition Assessment with ShapedNet: A Single\n  Image Deep Regression Approach",
            "updated": "2023-10-15T02:30:27Z",
            "published": "2023-10-15T02:30:27Z",
            "summary": "We introduce a novel technique called ShapedNet to enhance body composition\nassessment. This method employs a deep neural network capable of estimating\nBody Fat Percentage (BFP), performing individual identification, and enabling\nlocalization using a single photograph. The accuracy of ShapedNet is validated\nthrough comprehensive comparisons against the gold standard method, Dual-Energy\nX-ray Absorptiometry (DXA), utilizing 1273 healthy adults spanning various\nages, sexes, and BFP levels. The results demonstrate that ShapedNet outperforms\nin 19.5% state of the art computer vision-based approaches for body fat\nestimation, achieving a Mean Absolute Percentage Error (MAPE) of 4.91% and Mean\nAbsolute Error (MAE) of 1.42. The study evaluates both gender-based and\nGender-neutral approaches, with the latter showcasing superior performance. The\nmethod estimates BFP with 95% confidence within an error margin of 4.01% to\n5.81%. This research advances multi-task learning and body composition\nassessment theory through ShapedNet.",
            "author": [
                "Navar Medeiros M. Nascimento",
                "Pedro Cavalcante de Sousa Junior",
                "Pedro Yuri Rodrigues Nunes",
                "Suane Pires Pinheiro da Silva",
                "Luiz Lannes Loureiro",
                "Victor Zaban Bittencourt",
                "Valden Luis Matos Capistrano Junior",
                "Pedro Pedrosa Rebou\u00e7as Filho"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09709v1",
                "http://arxiv.org/pdf/2310.09709v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09706v2",
            "title": "AdaptSSR: Pre-training User Model with Augmentation-Adaptive\n  Self-Supervised Ranking",
            "updated": "2023-10-24T08:48:06Z",
            "published": "2023-10-15T02:19:28Z",
            "summary": "User modeling, which aims to capture users' characteristics or interests,\nheavily relies on task-specific labeled data and suffers from the data sparsity\nissue. Several recent studies tackled this problem by pre-training the user\nmodel on massive user behavior sequences with a contrastive learning task.\nGenerally, these methods assume different views of the same behavior sequence\nconstructed via data augmentation are semantically consistent, i.e., reflecting\nsimilar characteristics or interests of the user, and thus maximizing their\nagreement in the feature space. However, due to the diverse interests and heavy\nnoise in user behaviors, existing augmentation methods tend to lose certain\ncharacteristics of the user or introduce noisy behaviors. Thus, forcing the\nuser model to directly maximize the similarity between the augmented views may\nresult in a negative transfer. To this end, we propose to replace the\ncontrastive learning task with a new pretext task: Augmentation-Adaptive\nSelfSupervised Ranking (AdaptSSR), which alleviates the requirement of semantic\nconsistency between the augmented views while pre-training a discriminative\nuser model. Specifically, we adopt a multiple pairwise ranking loss which\ntrains the user model to capture the similarity orders between the implicitly\naugmented view, the explicitly augmented view, and views from other users. We\nfurther employ an in-batch hard negative sampling strategy to facilitate model\ntraining. Moreover, considering the distinct impacts of data augmentation on\ndifferent behavior sequences, we design an augmentation-adaptive fusion\nmechanism to automatically adjust the similarity order constraint applied to\neach sample based on the estimated similarity between the augmented views.\nExtensive experiments on both public and industrial datasets with six\ndownstream tasks verify the effectiveness of AdaptSSR.",
            "author": [
                "Yang Yu",
                "Qi Liu",
                "Kai Zhang",
                "Yuren Zhang",
                "Chao Song",
                "Min Hou",
                "Yuqing Yuan",
                "Zhihao Ye",
                "Zaixi Zhang",
                "Sanshi Lei Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09706v2",
                "http://arxiv.org/pdf/2310.09706v2"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09705v1",
            "title": "SGA: A Graph Augmentation Method for Signed Graph Neural Networks",
            "updated": "2023-10-15T02:19:07Z",
            "published": "2023-10-15T02:19:07Z",
            "summary": "Signed Graph Neural Networks (SGNNs) are vital for analyzing complex patterns\nin real-world signed graphs containing positive and negative links. However,\nthree key challenges hinder current SGNN-based signed graph representation\nlearning: sparsity in signed graphs leaves latent structures undiscovered,\nunbalanced triangles pose representation difficulties for SGNN models, and\nreal-world signed graph datasets often lack supplementary information like node\nlabels and features. These constraints limit the potential of SGNN-based\nrepresentation learning. We address these issues with data augmentation\ntechniques. Despite many graph data augmentation methods existing for unsigned\ngraphs, none are tailored for signed graphs. Our paper introduces the novel\nSigned Graph Augmentation framework (SGA), comprising three main components.\nFirst, we employ the SGNN model to encode the signed graph, extracting latent\nstructural information for candidate augmentation structures. Second, we\nevaluate these candidate samples (edges) and select the most beneficial ones\nfor modifying the original training set. Third, we propose a novel augmentation\nperspective that assigns varying training difficulty to training samples,\nenabling the design of a new training strategy. Extensive experiments on six\nreal-world datasets (Bitcoin-alpha, Bitcoin-otc, Epinions, Slashdot, Wiki-elec,\nand Wiki-RfA) demonstrate that SGA significantly improves performance across\nmultiple benchmarks. Our method outperforms baselines by up to 22.2% in AUC for\nSGCN on Wiki-RfA, 33.3% in F1-binary, 48.8% in F1-micro, and 36.3% in F1-macro\nfor GAT on Bitcoin-alpha in link sign prediction.",
            "author": [
                "Zeyu Zhang",
                "Shuyan Wan",
                "Sijie Wang",
                "Xianda Zheng",
                "Xinrui Zhang",
                "Kaiqi Zhao",
                "Jiamou Liu",
                "Dong Hao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09705v1",
                "http://arxiv.org/pdf/2310.09705v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09702v1",
            "title": "Inference with Mondrian Random Forests",
            "updated": "2023-10-15T01:41:42Z",
            "published": "2023-10-15T01:41:42Z",
            "summary": "Random forests are popular methods for classification and regression, and\nmany different variants have been proposed in recent years. One interesting\nexample is the Mondrian random forest, in which the underlying trees are\nconstructed according to a Mondrian process. In this paper we give a central\nlimit theorem for the estimates made by a Mondrian random forest in the\nregression setting. When combined with a bias characterization and a consistent\nvariance estimator, this allows one to perform asymptotically valid statistical\ninference, such as constructing confidence intervals, on the unknown regression\nfunction. We also provide a debiasing procedure for Mondrian random forests\nwhich allows them to achieve minimax-optimal estimation rates with\n$\\beta$-H\\\"older regression functions, for all $\\beta$ and in arbitrary\ndimension, assuming appropriate parameter tuning.",
            "author": [
                "Matias D. Cattaneo",
                "Jason M. Klusowski",
                "William G. Underwood"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09702v1",
                "http://arxiv.org/pdf/2310.09702v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "stat.ME",
                "stat.ML",
                "stat.TH",
                "62G08 (Primary), 62G05, 62G20 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09696v1",
            "title": "Progressive Evidence Refinement for Open-domain Multimodal Retrieval\n  Question Answering",
            "updated": "2023-10-15T01:18:39Z",
            "published": "2023-10-15T01:18:39Z",
            "summary": "Pre-trained multimodal models have achieved significant success in\nretrieval-based question answering. However, current multimodal retrieval\nquestion-answering models face two main challenges. Firstly, utilizing\ncompressed evidence features as input to the model results in the loss of\nfine-grained information within the evidence. Secondly, a gap exists between\nthe feature extraction of evidence and the question, which hinders the model\nfrom effectively extracting critical features from the evidence based on the\ngiven question. We propose a two-stage framework for evidence retrieval and\nquestion-answering to alleviate these issues. First and foremost, we propose a\nprogressive evidence refinement strategy for selecting crucial evidence. This\nstrategy employs an iterative evidence retrieval approach to uncover the\nlogical sequence among the evidence pieces. It incorporates two rounds of\nfiltering to optimize the solution space, thus further ensuring temporal\nefficiency. Subsequently, we introduce a semi-supervised contrastive learning\ntraining strategy based on negative samples to expand the scope of the question\ndomain, allowing for a more thorough exploration of latent knowledge within\nknown samples. Finally, in order to mitigate the loss of fine-grained\ninformation, we devise a multi-turn retrieval and question-answering strategy\nto handle multimodal inputs. This strategy involves incorporating multimodal\nevidence directly into the model as part of the historical dialogue and\nquestion. Meanwhile, we leverage a cross-modal attention mechanism to capture\nthe underlying connections between the evidence and the question, and the\nanswer is generated through a decoding generation approach. We validate the\nmodel's effectiveness through extensive experiments, achieving outstanding\nperformance on WebQA and MultimodelQA benchmark tests.",
            "author": [
                "Shuwen Yang",
                "Anran Wu",
                "Xingjiao Wu",
                "Luwei Xiao",
                "Tianlong Ma",
                "Cheng Jin",
                "Liang He"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09696v1",
                "http://arxiv.org/pdf/2310.09696v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09693v1",
            "title": "Influence of Acceleration and Deceleration Capability on Machine Tool\n  Feed System Performance",
            "updated": "2023-10-15T01:08:30Z",
            "published": "2023-10-15T01:08:30Z",
            "summary": "With the increasing demand for high speed and high precision machining of\nmachine tools, the problem of which factors of feed system ultimately determine\nthe performance of machine tools is becoming more and more prominent. At\npresent, the feed system is designed mainly by limiting the load inertia ratio.\nThis design method ignores the match between electromechanical system, motion\nprocess and control, and cannot guarantee the optimal performance of the feed\nsystem. And it is also difficult to intuitively explain the relationship\nbetween the inertia ratio and the dynamic performance of the system. Based on\nthe analysis of the relationship between the structural parameters and the\ndynamic performance of the feed system, the viewpoint that the acceleration and\ndeceleration capacity ultimately determine the performance of the feed system\nis put forward in this paper, and the theoretical root of the traditional\ndesign based on the inertia ratio is given. The simulation and experiment show\nthat if the acceleration and deceleration capacity is too small, there will not\nbe enough acceleration ability to follow the movement instruction of the\nsystem, resulting in the system performance decline. However, if the\nacceleration and deceleration capacity is too large, the system stability will\nbe reduced, which can explain the traditional design principle of the machine\ntool that the inertia ratio should not be too large or too small. This study\nprovides a clear theoretical basis for machine tool design.",
            "author": [
                "Dongsheng Zhang",
                "Xuesong Wang",
                "Tingting Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09693v1",
                "http://arxiv.org/pdf/2310.09693v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09692v1",
            "title": "Spike-based Neuromorphic Computing for Next-Generation Computer Vision",
            "updated": "2023-10-15T01:05:35Z",
            "published": "2023-10-15T01:05:35Z",
            "summary": "Neuromorphic Computing promises orders of magnitude improvement in energy\nefficiency compared to traditional von Neumann computing paradigm. The goal is\nto develop an adaptive, fault-tolerant, low-footprint, fast, low-energy\nintelligent system by learning and emulating brain functionality which can be\nrealized through innovation in different abstraction layers including material,\ndevice, circuit, architecture and algorithm. As the energy consumption in\ncomplex vision tasks keep increasing exponentially due to larger data set and\nresource-constrained edge devices become increasingly ubiquitous, spike-based\nneuromorphic computing approaches can be viable alternative to deep\nconvolutional neural network that is dominating the vision field today. In this\nbook chapter, we introduce neuromorphic computing, outline a few representative\nexamples from different layers of the design stack (devices, circuits and\nalgorithms) and conclude with a few exciting applications and future research\ndirections that seem promising for computer vision in the near future.",
            "author": [
                "Md Sakib Hasan",
                "Catherine D. Schuman",
                "Zhongyang Zhang",
                "Tauhidur Rahman",
                "Garrett S. Rose"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09692v1",
                "http://arxiv.org/pdf/2310.09692v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.AI",
                "cs.ET",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09690v1",
            "title": "Configuration Validation with Large Language Models",
            "updated": "2023-10-15T00:50:27Z",
            "published": "2023-10-15T00:50:27Z",
            "summary": "Misconfigurations are the major causes of software failures. Existing\nconfiguration validation techniques rely on manually written rules or test\ncases, which are expensive to implement and maintain, and are hard to be\ncomprehensive. Leveraging machine learning (ML) and natural language processing\n(NLP) for configuration validation is considered a promising direction, but has\nbeen facing challenges such as the need of not only large-scale configuration\ndata, but also system-specific features and models which are hard to\ngeneralize. Recent advances in Large Language Models (LLMs) show the promises\nto address some of the long-lasting limitations of ML/NLP-based configuration\nvalidation techniques. In this paper, we present an exploratory analysis on the\nfeasibility and effectiveness of using LLMs like GPT and Codex for\nconfiguration validation. Specifically, we take a first step to empirically\nevaluate LLMs as configuration validators without additional fine-tuning or\ncode generation. We develop a generic LLM-based validation framework, named\nCiri, which integrates different LLMs. Ciri devises effective prompt\nengineering with few-shot learning based on both valid configuration and\nmisconfiguration data. Ciri also validates and aggregates the outputs of LLMs\nto generate validation results, coping with known hallucination and\nnondeterminism of LLMs. We evaluate the validation effectiveness of Ciri on\nfive popular LLMs using configuration data of six mature, widely deployed\nopen-source systems. Our analysis (1) confirms the potential of using LLMs for\nconfiguration validation, (2) understands the design space of LLMbased\nvalidators like Ciri, especially in terms of prompt engineering with few-shot\nlearning, and (3) reveals open challenges such as ineffectiveness in detecting\ncertain types of misconfigurations and biases to popular configuration\nparameters.",
            "author": [
                "Xinyu Lian",
                "Yinfang Chen",
                "Runxiang Cheng",
                "Jie Huang",
                "Parth Thakkar",
                "Tianyin Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09690v1",
                "http://arxiv.org/pdf/2310.09690v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.AI",
                "cs.OS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09689v2",
            "title": "A Partially Supervised Reinforcement Learning Framework for Visual\n  Active Search",
            "updated": "2023-11-08T03:32:10Z",
            "published": "2023-10-15T00:29:35Z",
            "summary": "Visual active search (VAS) has been proposed as a modeling framework in which\nvisual cues are used to guide exploration, with the goal of identifying regions\nof interest in a large geospatial area. Its potential applications include\nidentifying hot spots of rare wildlife poaching activity, search-and-rescue\nscenarios, identifying illegal trafficking of weapons, drugs, or people, and\nmany others. State of the art approaches to VAS include applications of deep\nreinforcement learning (DRL), which yield end-to-end search policies, and\ntraditional active search, which combines predictions with custom algorithmic\napproaches. While the DRL framework has been shown to greatly outperform\ntraditional active search in such domains, its end-to-end nature does not make\nfull use of supervised information attained either during training, or during\nactual search, a significant limitation if search tasks differ significantly\nfrom those in the training distribution. We propose an approach that combines\nthe strength of both DRL and conventional active search by decomposing the\nsearch policy into a prediction module, which produces a geospatial\ndistribution of regions of interest based on task embedding and search history,\nand a search module, which takes the predictions and search history as input\nand outputs the search distribution. We develop a novel meta-learning approach\nfor jointly learning the resulting combined policy that can make effective use\nof supervised information obtained both at training and decision time. Our\nextensive experiments demonstrate that the proposed representation and\nmeta-learning frameworks significantly outperform state of the art in visual\nactive search on several problem domains.",
            "author": [
                "Anindya Sarkar",
                "Nathan Jacobs",
                "Yevgeniy Vorobeychik"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09689v2",
                "http://arxiv.org/pdf/2310.09689v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09687v1",
            "title": "When Collaborative Filtering is not Collaborative: Unfairness of PCA for\n  Recommendations",
            "updated": "2023-10-15T00:22:12Z",
            "published": "2023-10-15T00:22:12Z",
            "summary": "We study the fairness of dimensionality reduction methods for\nrecommendations. We focus on the established method of principal component\nanalysis (PCA), which identifies latent components and produces a low-rank\napproximation via the leading components while discarding the trailing\ncomponents. Prior works have defined notions of \"fair PCA\"; however, these\ndefinitions do not answer the following question: what makes PCA unfair? We\nidentify two underlying mechanisms of PCA that induce unfairness at the item\nlevel. The first negatively impacts less popular items, due to the fact that\nless popular items rely on trailing latent components to recover their values.\nThe second negatively impacts the highly popular items, since the leading PCA\ncomponents specialize in individual popular items instead of capturing\nsimilarities between items. To address these issues, we develop a\npolynomial-time algorithm, Item-Weighted PCA, a modification of PCA that uses\nitem-specific weights in the objective. On a stylized class of matrices, we\nprove that Item-Weighted PCA using a specific set of weights minimizes a\npopularity-normalized error metric. Our evaluations on real-world datasets show\nthat Item-Weighted PCA not only improves overall recommendation quality by up\nto $0.1$ item-level AUC-ROC but also improves on both popular and less popular\nitems.",
            "author": [
                "David Liu",
                "Jackie Baek",
                "Tina Eliassi-Rad"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09687v1",
                "http://arxiv.org/pdf/2310.09687v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09686v1",
            "title": "Enhancing Column Generation by Reinforcement Learning-Based\n  Hyper-Heuristic for Vehicle Routing and Scheduling Problems",
            "updated": "2023-10-15T00:05:50Z",
            "published": "2023-10-15T00:05:50Z",
            "summary": "Column generation (CG) is a vital method to solve large-scale problems by\ndynamically generating variables. It has extensive applications in common\ncombinatorial optimization, such as vehicle routing and scheduling problems,\nwhere each iteration step requires solving an NP-hard constrained shortest path\nproblem. Although some heuristic methods for acceleration already exist, they\nare not versatile enough to solve different problems. In this work, we propose\na reinforcement learning-based hyper-heuristic framework, dubbed RLHH, to\nenhance the performance of CG. RLHH is a selection module embedded in CG to\naccelerate convergence and get better integer solutions. In each CG iteration,\nthe RL agent selects a low-level heuristic to construct a reduced network only\ncontaining the edges with a greater chance of being part of the optimal\nsolution. In addition, we specify RLHH to solve two typical combinatorial\noptimization problems: Vehicle Routing Problem with Time Windows (VRPTW) and\nBus Driver Scheduling Problem (BDSP). The total cost can be reduced by up to\n27.9\\% in VRPTW and 15.4\\% in BDSP compared to the best lower-level heuristic\nin our tested scenarios, within equivalent or even less computational time. The\nproposed RLHH is the first RL-based CG method that outperforms traditional\napproaches in terms of solution quality, which can promote the application of\nCG in combinatorial optimization.",
            "author": [
                "Kuan Xu",
                "Li Shen",
                "Lindong Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09686v1",
                "http://arxiv.org/pdf/2310.09686v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09685v1",
            "title": "Generative artificial intelligence for de novo protein design",
            "updated": "2023-10-15T00:02:22Z",
            "published": "2023-10-15T00:02:22Z",
            "summary": "Engineering new molecules with desirable functions and properties has the\npotential to extend our ability to engineer proteins beyond what nature has so\nfar evolved. Advances in the so-called \"de novo\" design problem have recently\nbeen brought forward by developments in artificial intelligence. Generative\narchitectures, such as language models and diffusion processes, seem adept at\ngenerating novel, yet realistic proteins that display desirable properties and\nperform specified functions. State-of-the-art design protocols now achieve\nexperimental success rates nearing 20%, thus widening the access to de novo\ndesigned proteins. Despite extensive progress, there are clear field-wide\nchallenges, for example in determining the best in silico metrics to prioritise\ndesigns for experimental testing, and in designing proteins that can undergo\nlarge conformational changes or be regulated by post-translational\nmodifications and other cellular processes. With an increase in the number of\nmodels being developed, this review provides a framework to understand how\nthese tools fit into the overall process of de novo protein design. Throughout,\nwe highlight the power of incorporating biochemical knowledge to improve\nperformance and interpretability.",
            "author": [
                "Adam Winnifrith",
                "Carlos Outeiral",
                "Brian Hie"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09685v1",
                "http://arxiv.org/pdf/2310.09685v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "q-bio.BM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15177v2",
            "title": "A Neuro-mimetic Realization of the Common Model of Cognition via Hebbian\n  Learning and Free Energy Minimization",
            "updated": "2023-11-04T03:23:20Z",
            "published": "2023-10-14T23:28:48Z",
            "summary": "Over the last few years, large neural generative models, capable of\nsynthesizing semantically rich passages of text or producing complex images,\nhave recently emerged as a popular representation of what has come to be known\nas ``generative artificial intelligence'' (generative AI). Beyond opening the\ndoor to new opportunities as well as challenges for the domain of statistical\nmachine learning, the rising popularity of generative AI brings with it\ninteresting questions for Cognitive Science, which seeks to discover the nature\nof the processes that underpin minds and brains as well as to understand how\nsuch functionality might be acquired and instantianted in biological (or\nartificial) substrate. With this goal in mind, we argue that a promising\nresearch program lies in the crafting of cognitive architectures, a\nlong-standing tradition of the field, cast fundamentally in terms of\nneuro-mimetic generative building blocks. Concretely, we discuss the COGnitive\nNeural GENerative system, such an architecture that casts the Common Model of\nCognition in terms of Hebbian adaptation operating in service of optimizing a\nvariational free energy functional.",
            "author": [
                "Alexander Ororbia",
                "Mary Alexandria Kelly"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15177v2",
                "http://arxiv.org/pdf/2310.15177v2"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09680v3",
            "title": "Improved Contextual Recognition In Automatic Speech Recognition Systems\n  By Semantic Lattice Rescoring",
            "updated": "2023-10-27T18:56:51Z",
            "published": "2023-10-14T23:16:05Z",
            "summary": "Automatic Speech Recognition (ASR) has witnessed a profound research\ninterest. Recent breakthroughs have given ASR systems different prospects such\nas faithfully transcribing spoken language, which is a pivotal advancement in\nbuilding conversational agents. However, there is still an imminent challenge\nof accurately discerning context-dependent words and phrases. In this work, we\npropose a novel approach for enhancing contextual recognition within ASR\nsystems via semantic lattice processing leveraging the power of deep learning\nmodels in accurately delivering spot-on transcriptions across a wide variety of\nvocabularies and speaking styles. Our solution consists of using Hidden Markov\nModels and Gaussian Mixture Models (HMM-GMM) along with Deep Neural Networks\n(DNN) models integrating both language and acoustic modeling for better\naccuracy. We infused our network with the use of a transformer-based model to\nproperly rescore the word lattice achieving remarkable capabilities with a\npalpable reduction in Word Error Rate (WER). We demonstrate the effectiveness\nof our proposed framework on the LibriSpeech dataset with empirical analyses.",
            "author": [
                "Ankitha Sudarshan",
                "Vinay Samuel",
                "Parth Patwa",
                "Ibtihel Amara",
                "Aman Chadha"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09680v3",
                "http://arxiv.org/pdf/2310.09680v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09679v1",
            "title": "What Do Deep Saliency Models Learn about Visual Attention?",
            "updated": "2023-10-14T23:15:57Z",
            "published": "2023-10-14T23:15:57Z",
            "summary": "In recent years, deep saliency models have made significant progress in\npredicting human visual attention. However, the mechanisms behind their success\nremain largely unexplained due to the opaque nature of deep neural networks. In\nthis paper, we present a novel analytic framework that sheds light on the\nimplicit features learned by saliency models and provides principled\ninterpretation and quantification of their contributions to saliency\nprediction. Our approach decomposes these implicit features into interpretable\nbases that are explicitly aligned with semantic attributes and reformulates\nsaliency prediction as a weighted combination of probability maps connecting\nthe bases and saliency. By applying our framework, we conduct extensive\nanalyses from various perspectives, including the positive and negative weights\nof semantics, the impact of training data and architectural designs, the\nprogressive influences of fine-tuning, and common failure patterns of\nstate-of-the-art deep saliency models. Additionally, we demonstrate the\neffectiveness of our framework by exploring visual attention characteristics in\nvarious application scenarios, such as the atypical attention of people with\nautism spectrum disorder, attention to emotion-eliciting stimuli, and attention\nevolution over time. Our code is publicly available at\n\\url{https://github.com/szzexpoi/saliency_analysis}.",
            "author": [
                "Shi Chen",
                "Ming Jiang",
                "Qi Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09679v1",
                "http://arxiv.org/pdf/2310.09679v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09677v1",
            "title": "S-Procedure Relaxation: a Case of Exactness Involving Chebyshev Centers",
            "updated": "2023-10-14T22:32:55Z",
            "published": "2023-10-14T22:32:55Z",
            "summary": "Optimal recovery is a mathematical framework for learning functions from\nobservational data by adopting a worst-case perspective tied to model\nassumptions on the functions to be learned. Working in a finite-dimensional\nHilbert space, we consider model assumptions based on approximability and\nobservation inaccuracies modeled as additive errors bounded in $\\ell_2$. We\nfocus on the local recovery problem, which amounts to the determination of\nChebyshev centers. Earlier work by Beck and Eldar presented a semidefinite\nrecipe for the determination of Chebyshev centers. The result was valid in the\ncomplex setting only, but not necessarily in the real setting, since it relied\non the S-procedure with two quadratic constraints, which offers a tight\nrelaxation only in the complex setting. Our contribution consists in proving\nthat this semidefinite recipe is exact in the real setting, too, at least in\nthe particular instance where the quadratic constraints involve orthogonal\nprojectors. Our argument exploits a previous work of ours, where exact\nChebyshev centers were obtained in a different way. We conclude by stating some\nopen questions and by commenting on other recent results in optimal recovery.",
            "author": [
                "Simon Foucart",
                "Chunyang Liao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09677v1",
                "http://arxiv.org/pdf/2310.09677v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09676v1",
            "title": "Mastering Robot Manipulation with Multimodal Prompts through Pretraining\n  and Multi-task Fine-tuning",
            "updated": "2023-10-14T22:24:58Z",
            "published": "2023-10-14T22:24:58Z",
            "summary": "Prompt-based learning has been demonstrated as a compelling paradigm\ncontributing to large language models' tremendous success (LLMs). Inspired by\ntheir success in language tasks, existing research has leveraged LLMs in\nembodied instruction following and task planning. However, not much attention\nhas been paid to embodied tasks with multimodal prompts, combining vision\nsignals with text descriptions. This type of task poses a major challenge to\nrobots' capability to understand the interconnection and complementarity\nbetween vision and language signals. In this work, we introduce an effective\nframework that learns a policy to perform robot manipulation with multimodal\nprompts from multi-task expert trajectories. Our methods consist of a two-stage\ntraining pipeline that performs inverse dynamics pretraining and multi-task\nfinetuning. To facilitate multimodal understanding, we design our multimodal\nprompt encoder by augmenting a pretrained LM with a residual connection to the\nvisual input and model the dependencies among action dimensions. Empirically,\nwe evaluate the efficacy of our method on the VIMA-BENCH and establish a new\nstate-of-the-art (10% improvement in success rate). Moreover, we demonstrate\nthat our model exhibits remarkable in-context learning ability.",
            "author": [
                "Jiachen Li",
                "Qiaozi Gao",
                "Michael Johnston",
                "Xiaofeng Gao",
                "Xuehai He",
                "Suhaila Shakiah",
                "Hangjie Shi",
                "Reza Ghanadan",
                "William Yang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09676v1",
                "http://arxiv.org/pdf/2310.09676v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09675v1",
            "title": "Efficient Model-Agnostic Multi-Group Equivariant Networks",
            "updated": "2023-10-14T22:24:26Z",
            "published": "2023-10-14T22:24:26Z",
            "summary": "Constructing model-agnostic group equivariant networks, such as equitune\n(Basu et al., 2023b) and its generalizations (Kim et al., 2023), can be\ncomputationally expensive for large product groups. We address this by\nproviding efficient model-agnostic equivariant designs for two related\nproblems: one where the network has multiple inputs each with potentially\ndifferent groups acting on them, and another where there is a single input but\nthe group acting on it is a large product group. For the first design, we\ninitially consider a linear model and characterize the entire equivariant space\nthat satisfies this constraint. This characterization gives rise to a novel\nfusion layer between different channels that satisfies an invariance-symmetry\n(IS) constraint, which we call an IS layer. We then extend this design beyond\nlinear models, similar to equitune, consisting of equivariant and IS layers. We\nalso show that the IS layer is a universal approximator of invariant-symmetric\nfunctions. Inspired by the first design, we use the notion of the IS property\nto design a second efficient model-agnostic equivariant design for large\nproduct groups acting on a single input. For the first design, we provide\nexperiments on multi-image classification where each view is transformed\nindependently with transformations such as rotations. We find equivariant\nmodels are robust to such transformations and perform competitively otherwise.\nFor the second design, we consider three applications: language\ncompositionality on the SCAN dataset to product groups; fairness in natural\nlanguage generation from GPT-2 to address intersectionality; and robust\nzero-shot image classification with CLIP. Overall, our methods are simple and\ngeneral, competitive with equitune and its variants, while also being\ncomputationally more efficient.",
            "author": [
                "Razan Baltaji",
                "Sourya Basu",
                "Lav R. Varshney"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09675v1",
                "http://arxiv.org/pdf/2310.09675v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09672v1",
            "title": "Towards Semi-Structured Automatic ICD Coding via Tree-based Contrastive\n  Learning",
            "updated": "2023-10-14T22:07:13Z",
            "published": "2023-10-14T22:07:13Z",
            "summary": "Automatic coding of International Classification of Diseases (ICD) is a\nmulti-label text categorization task that involves extracting disease or\nprocedure codes from clinical notes. Despite the application of\nstate-of-the-art natural language processing (NLP) techniques, there are still\nchallenges including limited availability of data due to privacy constraints\nand the high variability of clinical notes caused by different writing habits\nof medical professionals and various pathological features of patients. In this\nwork, we investigate the semi-structured nature of clinical notes and propose\nan automatic algorithm to segment them into sections. To address the\nvariability issues in existing ICD coding models with limited data, we\nintroduce a contrastive pre-training approach on sections using a soft\nmulti-label similarity metric based on tree edit distance. Additionally, we\ndesign a masked section training strategy to enable ICD coding models to locate\nsections related to ICD codes. Extensive experimental results demonstrate that\nour proposed training strategies effectively enhance the performance of\nexisting ICD coding methods.",
            "author": [
                "Chang Lu",
                "Chandan K. Reddy",
                "Ping Wang",
                "Yue Ning"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09672v1",
                "http://arxiv.org/pdf/2310.09672v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09667v2",
            "title": "Edge-InversionNet: Enabling Efficient Inference of InversionNet on Edge\n  Devices",
            "updated": "2023-10-18T15:43:35Z",
            "published": "2023-10-14T21:19:15Z",
            "summary": "Seismic full waveform inversion (FWI) is a widely used technique in\ngeophysics for inferring subsurface structures from seismic data. And\nInversionNet is one of the most successful data-driven machine learning models\nthat is applied to seismic FWI. However, the high computing costs to run\nInversionNet have made it challenging to be efficiently deployed on edge\ndevices that are usually resource-constrained. Therefore, we propose to employ\nthe structured pruning algorithm to get a lightweight version of InversionNet,\nwhich can make an efficient inference on edge devices. And we also made a\nprototype with Raspberry Pi to run the lightweight InversionNet. Experimental\nresults show that the pruned InversionNet can achieve up to 98.2 % reduction in\ncomputing resources with moderate model performance degradation.",
            "author": [
                "Zhepeng Wang",
                "Isaacshubhanand Putla",
                "Weiwen Jiang",
                "Youzuo Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09667v2",
                "http://arxiv.org/pdf/2310.09667v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "eess.SP",
                "physics.geo-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09665v1",
            "title": "A Blockchain-empowered Multi-Aggregator Federated Learning Architecture\n  in Edge Computing with Deep Reinforcement Learning Optimization",
            "updated": "2023-10-14T20:47:30Z",
            "published": "2023-10-14T20:47:30Z",
            "summary": "Federated learning (FL) is emerging as a sought-after distributed machine\nlearning architecture, offering the advantage of model training without direct\nexposure of raw data. With advancements in network infrastructure, FL has been\nseamlessly integrated into edge computing. However, the limited resources on\nedge devices introduce security vulnerabilities to FL in the context. While\nblockchain technology promises to bolster security, practical deployment on\nresource-constrained edge devices remains a challenge. Moreover, the\nexploration of FL with multiple aggregators in edge computing is still new in\nthe literature. Addressing these gaps, we introduce the Blockchain-empowered\nHeterogeneous Multi-Aggregator Federated Learning Architecture (BMA-FL). We\ndesign a novel light-weight Byzantine consensus mechanism, namely PBCM, to\nenable secure and fast model aggregation and synchronization in BMA-FL. We also\ndive into the heterogeneity problem in BMA-FL that the aggregators are\nassociated with varied number of connected trainers with Non-IID data\ndistributions and diverse training speed. We proposed a multi-agent deep\nreinforcement learning algorithm to help aggregators decide the best training\nstrategies. The experiments on real-word datasets demonstrate the efficiency of\nBMA-FL to achieve better models faster than baselines, showing the efficacy of\nPBCM and proposed deep reinforcement learning algorithm.",
            "author": [
                "Xiao Li",
                "Weili Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09665v1",
                "http://arxiv.org/pdf/2310.09665v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09657v1",
            "title": "Topology-guided Hypergraph Transformer Network: Unveiling Structural\n  Insights for Improved Representation",
            "updated": "2023-10-14T20:08:54Z",
            "published": "2023-10-14T20:08:54Z",
            "summary": "Hypergraphs, with their capacity to depict high-order relationships, have\nemerged as a significant extension of traditional graphs. Although Graph Neural\nNetworks (GNNs) have remarkable performance in graph representation learning,\ntheir extension to hypergraphs encounters challenges due to their intricate\nstructures. Furthermore, current hypergraph transformers, a special variant of\nGNN, utilize semantic feature-based self-attention, ignoring topological\nattributes of nodes and hyperedges. To address these challenges, we propose a\nTopology-guided Hypergraph Transformer Network (THTN). In this model, we first\nformulate a hypergraph from a graph while retaining its structural essence to\nlearn higher-order relations within the graph. Then, we design a simple yet\neffective structural and spatial encoding module to incorporate the topological\nand spatial information of the nodes into their representation. Further, we\npresent a structure-aware self-attention mechanism that discovers the important\nnodes and hyperedges from both semantic and structural viewpoints. By\nleveraging these two modules, THTN crafts an improved node representation,\ncapturing both local and global topological expressions. Extensive experiments\nconducted on node classification tasks demonstrate that the performance of the\nproposed model consistently exceeds that of the existing approaches.",
            "author": [
                "Khaled Mohammed Saifuddin",
                "Mehmet Emin Aktas",
                "Esra Akbas"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09657v1",
                "http://arxiv.org/pdf/2310.09657v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09656v1",
            "title": "Mixed-Type Tabular Data Synthesis with Score-based Diffusion in Latent\n  Space",
            "updated": "2023-10-14T19:59:03Z",
            "published": "2023-10-14T19:59:03Z",
            "summary": "Recent advances in tabular data generation have greatly enhanced synthetic\ndata quality. However, extending diffusion models to tabular data is\nchallenging due to the intricately varied distributions and a blend of data\ntypes of tabular data. This paper introduces TABSYN, a methodology that\nsynthesizes tabular data by leveraging a diffusion model within a variational\nautoencoder (VAE) crafted latent space. The key advantages of the proposed\nTABSYN include (1) Generality: the ability to handle a broad spectrum of data\ntypes by converting them into a single unified space and explicitly capture\ninter-column relations; (2) Quality: optimizing the distribution of latent\nembeddings to enhance the subsequent training of diffusion models, which helps\ngenerate high-quality synthetic data, (3) Speed: much fewer number of reverse\nsteps and faster synthesis speed than existing diffusion-based methods.\nExtensive experiments on six datasets with five metrics demonstrate that TABSYN\noutperforms existing methods. Specifically, it reduces the error rates by 86%\nand 67% for column-wise distribution and pair-wise column correlation\nestimations compared with the most competitive baselines.",
            "author": [
                "Hengrui Zhang",
                "Jiani Zhang",
                "Balasubramaniam Srinivasan",
                "Zhengyuan Shen",
                "Xiao Qin",
                "Christos Faloutsos",
                "Huzefa Rangwala",
                "George Karypis"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09656v1",
                "http://arxiv.org/pdf/2310.09656v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09653v1",
            "title": "SelfVC: Voice Conversion With Iterative Refinement using Self\n  Transformations",
            "updated": "2023-10-14T19:51:17Z",
            "published": "2023-10-14T19:51:17Z",
            "summary": "We propose SelfVC, a training strategy to iteratively improve a voice\nconversion model with self-synthesized examples. Previous efforts on voice\nconversion focus on explicitly disentangling speech representations to\nseparately encode speaker characteristics and linguistic content. However,\ndisentangling speech representations to capture such attributes using\ntask-specific loss terms can lead to information loss by discarding finer\nnuances of the original signal. In this work, instead of explicitly\ndisentangling attributes with loss terms, we present a framework to train a\ncontrollable voice conversion model on entangled speech representations derived\nfrom self-supervised learning and speaker verification models. First, we\ndevelop techniques to derive prosodic information from the audio signal and SSL\nrepresentations to train predictive submodules in the synthesis model. Next, we\npropose a training strategy to iteratively improve the synthesis model for\nvoice conversion, by creating a challenging training objective using\nself-synthesized examples. In this training approach, the current state of the\nsynthesis model is used to generate voice-converted variations of an utterance,\nwhich serve as inputs for the reconstruction task, ensuring a continuous and\npurposeful refinement of the model. We demonstrate that incorporating such\nself-synthesized examples during training improves the speaker similarity of\ngenerated speech as compared to a baseline voice conversion model trained\nsolely on heuristically perturbed inputs. SelfVC is trained without any text\nand is applicable to a range of tasks such as zero-shot voice conversion,\ncross-lingual voice conversion, and controllable speech synthesis with pitch\nand pace modifications. SelfVC achieves state-of-the-art results in zero-shot\nvoice conversion on metrics evaluating naturalness, speaker similarity, and\nintelligibility of synthesized audio.",
            "author": [
                "Paarth Neekhara",
                "Shehzeen Hussain",
                "Rafael Valle",
                "Boris Ginsburg",
                "Rishabh Ranjan",
                "Shlomo Dubnov",
                "Farinaz Koushanfar",
                "Julian McAuley"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09653v1",
                "http://arxiv.org/pdf/2310.09653v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.AI",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09652v1",
            "title": "BufferSearch: Generating Black-Box Adversarial Texts With Lower Queries",
            "updated": "2023-10-14T19:49:02Z",
            "published": "2023-10-14T19:49:02Z",
            "summary": "Machine learning security has recently become a prominent topic in the\nnatural language processing (NLP) area. The existing black-box adversarial\nattack suffers prohibitively from the high model querying complexity, resulting\nin easily being captured by anti-attack monitors. Meanwhile, how to eliminate\nredundant model queries is rarely explored. In this paper, we propose a\nquery-efficient approach BufferSearch to effectively attack general intelligent\nNLP systems with the minimal number of querying requests. In general,\nBufferSearch makes use of historical information and conducts statistical test\nto avoid incurring model queries frequently. Numerically, we demonstrate the\neffectiveness of BufferSearch on various benchmark text-classification\nexperiments by achieving the competitive attacking performance but with a\nsignificant reduction of query quantity. Furthermore, BufferSearch performs\nmultiple times better than competitors within restricted query budget. Our work\nestablishes a strong benchmark for the future study of query-efficiency in NLP\nadversarial attacks.",
            "author": [
                "Wenjie Lv",
                "Zhen Wang",
                "Yitao Zheng",
                "Zhehua Zhong",
                "Qi Xuan",
                "Tianyi Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09652v1",
                "http://arxiv.org/pdf/2310.09652v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09651v1",
            "title": "Lexical Entrainment for Conversational Systems",
            "updated": "2023-10-14T19:47:37Z",
            "published": "2023-10-14T19:47:37Z",
            "summary": "Conversational agents have become ubiquitous in assisting with daily tasks,\nand are expected to possess human-like features. One such feature is lexical\nentrainment (LE), a phenomenon in which speakers in human-human conversations\ntend to naturally and subconsciously align their lexical choices with those of\ntheir interlocutors, leading to more successful and engaging conversations. As\nan example, if a digital assistant replies 'Your appointment for Jinling Noodle\nPub is at 7 pm' to the question 'When is my reservation for Jinling Noodle Bar\ntoday?', it may feel as though the assistant is trying to correct the speaker,\nwhereas a response of 'Your reservation for Jinling Noodle Bar is at 7 pm'\nwould likely be perceived as more positive. This highlights the importance of\nLE in establishing a shared terminology for maximum clarity and reducing\nambiguity in conversations. However, we demonstrate in this work that current\nresponse generation models do not adequately address this crucial humanlike\nphenomenon. To address this, we propose a new dataset, named MULTIWOZ-ENTR, and\na measure for LE for conversational systems. Additionally, we suggest a way to\nexplicitly integrate LE into conversational systems with two new tasks, a LE\nextraction task and a LE generation task. We also present two baseline\napproaches for the LE extraction task, which aim to detect LE expressions from\ndialogue contexts.",
            "author": [
                "Zhengxiang Shi",
                "Procheta Sen",
                "Aldo Lipani"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09651v1",
                "http://arxiv.org/pdf/2310.09651v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09650v1",
            "title": "Multimodal Federated Learning in Healthcare: a review",
            "updated": "2023-10-14T19:43:06Z",
            "published": "2023-10-14T19:43:06Z",
            "summary": "Recent advancements in multimodal machine learning have empowered the\ndevelopment of accurate and robust AI systems in the medical domain, especially\nwithin centralized database systems. Simultaneously, Federated Learning (FL)\nhas progressed, providing a decentralized mechanism where data need not be\nconsolidated, thereby enhancing the privacy and security of sensitive\nhealthcare data. The integration of these two concepts supports the ongoing\nprogress of multimodal learning in healthcare while ensuring the security and\nprivacy of patient records within local data-holding agencies. This paper\noffers a concise overview of the significance of FL in healthcare and outlines\nthe current state-of-the-art approaches to Multimodal Federated Learning (MMFL)\nwithin the healthcare domain. It comprehensively examines the existing\nchallenges in the field, shedding light on the limitations of present models.\nFinally, the paper outlines potential directions for future advancements in the\nfield, aiming to bridge the gap between cutting-edge AI technology and the\nimperative need for patient data privacy in healthcare applications.",
            "author": [
                "Jacob Thrasher",
                "Alina Devkota",
                "Prasiddha Siwakotai",
                "Rohit Chivukula",
                "Pranav Poudel",
                "Chaunbo Hu",
                "Binod Bhattarai",
                "Prashnna Gyawali"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09650v1",
                "http://arxiv.org/pdf/2310.09650v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09639v1",
            "title": "DPZero: Dimension-Independent and Differentially Private Zeroth-Order\n  Optimization",
            "updated": "2023-10-14T18:42:56Z",
            "published": "2023-10-14T18:42:56Z",
            "summary": "The widespread practice of fine-tuning pretrained large language models\n(LLMs) on domain-specific data faces two major challenges in memory and\nprivacy. First, as the size of LLMs continue to grow, encompassing billions of\nparameters, the memory demands of gradient-based training methods via\nbackpropagation become prohibitively high. Second, given the tendency of LLMs\nto memorize and disclose sensitive training data, the privacy of fine-tuning\ndata must be respected. To this end, we explore the potential of zeroth-order\nmethods in differentially private optimization for fine-tuning LLMs.\nZeroth-order methods, which rely solely on forward passes, substantially reduce\nmemory consumption during training. However, directly combining them with\nstandard differential privacy mechanism poses dimension-dependent complexity.\nTo bridge the gap, we introduce DPZero, a novel differentially private\nzeroth-order algorithm with nearly dimension-independent rates. Our theoretical\nanalysis reveals that its complexity hinges primarily on the problem's\nintrinsic dimension and exhibits only a logarithmic dependence on the ambient\ndimension. This renders DPZero a highly practical option for real-world LLMs\ndeployments.",
            "author": [
                "Liang Zhang",
                "Kiran Koshy Thekumparampil",
                "Sewoong Oh",
                "Niao He"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09639v1",
                "http://arxiv.org/pdf/2310.09639v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11467v1",
            "title": "Enhancing Binary Code Comment Quality Classification: Integrating\n  Generative AI for Improved Accuracy",
            "updated": "2023-10-14T18:19:06Z",
            "published": "2023-10-14T18:19:06Z",
            "summary": "This report focuses on enhancing a binary code comment quality classification\nmodel by integrating generated code and comment pairs, to improve model\naccuracy. The dataset comprises 9048 pairs of code and comments written in the\nC programming language, each annotated as \"Useful\" or \"Not Useful.\"\nAdditionally, code and comment pairs are generated using a Large Language Model\nArchitecture, and these generated pairs are labeled to indicate their utility.\nThe outcome of this effort consists of two classification models: one utilizing\nthe original dataset and another incorporating the augmented dataset with the\nnewly generated code comment pairs and labels.",
            "author": [
                "Rohith Arumugam S",
                "Angel Deborah S"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11467v1",
                "http://arxiv.org/pdf/2310.11467v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09636v1",
            "title": "Generative Adversarial Training for Text-to-Speech Synthesis Based on\n  Raw Phonetic Input and Explicit Prosody Modelling",
            "updated": "2023-10-14T18:15:51Z",
            "published": "2023-10-14T18:15:51Z",
            "summary": "We describe an end-to-end speech synthesis system that uses generative\nadversarial training. We train our Vocoder for raw phoneme-to-audio conversion,\nusing explicit phonetic, pitch and duration modeling. We experiment with\nseveral pre-trained models for contextualized and decontextualized word\nembeddings and we introduce a new method for highly expressive character voice\nmatching, based on discreet style tokens.",
            "author": [
                "Tiberiu Boros",
                "Stefan Daniel Dumitrescu",
                "Ionut Mironica",
                "Radu Chivereanu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09636v1",
                "http://arxiv.org/pdf/2310.09636v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09634v1",
            "title": "An End-to-End System for Reproducibility Assessment of Source Code\n  Repositories via Their Readmes",
            "updated": "2023-10-14T18:01:11Z",
            "published": "2023-10-14T18:01:11Z",
            "summary": "Increased reproducibility of machine learning research has been a driving\nforce for dramatic improvements in learning performances. The scientific\ncommunity further fosters this effort by including reproducibility ratings in\nreviewer forms and considering them as a crucial factor for the overall\nevaluation of papers. Accompanying source code is not sufficient to make a work\nreproducible. The shared codes should meet the ML reproducibility checklist as\nwell. This work aims to support reproducibility evaluations of papers with\nsource codes. We propose an end-to-end system that operates on the Readme file\nof the source code repositories. The system checks the compliance of a given\nReadme to a template proposed by a widely used platform for sharing source\ncodes of research. Our system generates scores based on a custom function to\ncombine section scores. We also train a hierarchical transformer model to\nassign a class label to a given Readme. The experimental results show that the\nsection similarity-based system performs better than the hierarchical\ntransformer. Moreover, it has an advantage regarding explainability since one\ncan directly relate the score to the sections of Readme files.",
            "author": [
                "Ey\u00fcp Kaan Akdeniz",
                "Selma Tekir",
                "Malik Nizar Asad Al Hinnawi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09634v1",
                "http://arxiv.org/pdf/2310.09634v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09631v1",
            "title": "Landslide Topology Uncovers Failure Movements",
            "updated": "2023-10-14T17:53:55Z",
            "published": "2023-10-14T17:53:55Z",
            "summary": "The death toll and monetary damages from landslides continue to rise despite\nadvancements in predictive modeling. The predictive capability of these models\nis limited as landslide databases used in training and assessing the models\noften have crucial information missing, such as underlying failure types. Here,\nwe present an approach for identifying failure types based on their movements,\ne.g., slides and flows by leveraging 3D landslide topology. We observe\ntopological proxies reveal prevalent signatures of mass movement mechanics\nembedded in the landslide's morphology or shape, such as detecting coupled\nmovement styles within complex landslides. We find identical failure types\nexhibit similar topological properties, and by using them as predictors, we can\nidentify failure types in historic and event-specific landslide databases\n(including multi-temporal) from various geomorphological and climatic contexts\nsuch as Italy, the US Pacific Northwest region, Denmark, Turkey, and China with\n80 to 94 % accuracy. To demonstrate the real-world application of the method,\nwe implement it in two undocumented datasets from China and publicly release\nthe datasets. These new insights can considerably improve the performance of\nlandslide predictive models and impact assessments. Moreover, our work\nintroduces a new paradigm for studying landslide shapes to understand\nunderlying processes through the lens of landslide topology.",
            "author": [
                "Kamal Rana",
                "Kushanav Bhuyan",
                "Joaquin Vicente Ferrer",
                "Fabrice Cotton",
                "Ugur Ozturk",
                "Filippo Catani",
                "Nishant Malik"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09631v1",
                "http://arxiv.org/pdf/2310.09631v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10689v1",
            "title": "Contrastive Self-Supervised Learning for Spatio-Temporal Analysis of\n  Lung Ultrasound Videos",
            "updated": "2023-10-14T17:53:44Z",
            "published": "2023-10-14T17:53:44Z",
            "summary": "Self-supervised learning (SSL) methods have shown promise for medical imaging\napplications by learning meaningful visual representations, even when the\namount of labeled data is limited. Here, we extend state-of-the-art contrastive\nlearning SSL methods to 2D+time medical ultrasound video data by introducing a\nmodified encoder and augmentation method capable of learning meaningful\nspatio-temporal representations, without requiring constraints on the input\ndata. We evaluate our method on the challenging clinical task of identifying\nlung consolidations (an important pathological feature) in ultrasound videos.\nUsing a multi-center dataset of over 27k lung ultrasound videos acquired from\nover 500 patients, we show that our method can significantly improve\nperformance on downstream localization and classification of lung\nconsolidation. Comparisons against baseline models trained without SSL show\nthat the proposed methods are particularly advantageous when the size of\nlabeled training data is limited (e.g., as little as 5% of the training set).",
            "author": [
                "Li Chen",
                "Jonathan Rubin",
                "Jiahong Ouyang",
                "Naveen Balaraju",
                "Shubham Patil",
                "Courosh Mehanian",
                "Sourabh Kulhare",
                "Rachel Millin",
                "Kenton W Gregory",
                "Cynthia R Gregory",
                "Meihua Zhu",
                "David O Kessler",
                "Laurie Malia",
                "Almaz Dessie",
                "Joni Rabiner",
                "Di Coneybeare",
                "Bo Shopsin",
                "Andrew Hersh",
                "Cristian Madar",
                "Jeffrey Shupp",
                "Laura S Johnson",
                "Jacob Avila",
                "Kristin Dwyer",
                "Peter Weimersheimer",
                "Balasundar Raju",
                "Jochen Kruecker",
                "Alvin Chen"
            ],
            "link": [
                "http://dx.doi.org/10.1109/isbi53787.2023.10230816",
                "http://arxiv.org/abs/2310.10689v1",
                "http://arxiv.org/pdf/2310.10689v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09630v1",
            "title": "Real-Time Traffic Sign Detection: A Case Study in a Santa Clara Suburban\n  Neighborhood",
            "updated": "2023-10-14T17:52:28Z",
            "published": "2023-10-14T17:52:28Z",
            "summary": "This research project aims to develop a real-time traffic sign detection\nsystem using the YOLOv5 architecture and deploy it for efficient traffic sign\nrecognition during a drive in a suburban neighborhood. The project's primary\nobjectives are to train the YOLOv5 model on a diverse dataset of traffic sign\nimages and deploy the model on a suitable hardware platform capable of\nreal-time inference. The project will involve collecting a comprehensive\ndataset of traffic sign images. By leveraging the trained YOLOv5 model, the\nsystem will detect and classify traffic signs from a real-time camera on a\ndashboard inside a vehicle. The performance of the deployed system will be\nevaluated based on its accuracy in detecting traffic signs, real-time\nprocessing speed, and overall reliability. During a case study in a suburban\nneighborhood, the system demonstrated a notable 96% accuracy in detecting\ntraffic signs. This research's findings have the potential to improve road\nsafety and traffic management by providing timely and accurate real-time\ninformation about traffic signs and can pave the way for further research into\nautonomous driving.",
            "author": [
                "Harish Loghashankar",
                "Hieu Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09630v1",
                "http://arxiv.org/pdf/2310.09630v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09629v1",
            "title": "Adaptive Online Replanning with Diffusion Models",
            "updated": "2023-10-14T17:52:04Z",
            "published": "2023-10-14T17:52:04Z",
            "summary": "Diffusion models have risen as a promising approach to data-driven planning,\nand have demonstrated impressive robotic control, reinforcement learning, and\nvideo planning performance. Given an effective planner, an important question\nto consider is replanning -- when given plans should be regenerated due to both\naction execution error and external environment changes. Direct plan execution,\nwithout replanning, is problematic as errors from individual actions rapidly\naccumulate and environments are partially observable and stochastic.\nSimultaneously, replanning at each timestep incurs a substantial computational\ncost, and may prevent successful task execution, as different generated plans\nprevent consistent progress to any particular goal. In this paper, we explore\nhow we may effectively replan with diffusion models. We propose a principled\napproach to determine when to replan, based on the diffusion model's estimated\nlikelihood of existing generated plans. We further present an approach to\nreplan existing trajectories to ensure that new plans follow the same goal\nstate as the original trajectory, which may efficiently bootstrap off\npreviously generated plans. We illustrate how a combination of our proposed\nadditions significantly improves the performance of diffusion planners leading\nto 38\\% gains over past diffusion planning approaches on Maze2D, and further\nenables the handling of stochastic and long-horizon robotic control tasks.\nVideos can be found on the anonymous website:\n\\url{https://vis-www.cs.umass.edu/replandiffuser/}.",
            "author": [
                "Siyuan Zhou",
                "Yilun Du",
                "Shun Zhang",
                "Mengdi Xu",
                "Yikang Shen",
                "Wei Xiao",
                "Dit-Yan Yeung",
                "Chuang Gan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09629v1",
                "http://arxiv.org/pdf/2310.09629v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09628v1",
            "title": "Federated Battery Diagnosis and Prognosis",
            "updated": "2023-10-14T17:46:50Z",
            "published": "2023-10-14T17:46:50Z",
            "summary": "Battery diagnosis, prognosis and health management models play a critical\nrole in the integration of battery systems in energy and mobility fields.\nHowever, large-scale deployment of these models is hindered by a myriad of\nchallenges centered around data ownership, privacy, communication, and\nprocessing. State-of-the-art battery diagnosis and prognosis methods require\ncentralized collection of data, which further aggravates these challenges. Here\nwe propose a federated battery prognosis model, which distributes the\nprocessing of battery standard current-voltage-time-usage data in a\nprivacy-preserving manner. Instead of exchanging raw standard\ncurrent-voltage-time-usage data, our model communicates only the model\nparameters, thus reducing communication load and preserving data\nconfidentiality. The proposed model offers a paradigm shift in battery health\nmanagement through privacy-preserving distributed methods for battery data\nprocessing and remaining lifetime prediction.",
            "author": [
                "Nur Banu Altinpulluk",
                "Deniz Altinpulluk",
                "Paritosh Ramanan",
                "Noah Paulson",
                "Feng Qiu",
                "Susan Babinec",
                "Murat Yildirim"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09628v1",
                "http://arxiv.org/pdf/2310.09628v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09624v2",
            "title": "ASSERT: Automated Safety Scenario Red Teaming for Evaluating the\n  Robustness of Large Language Models",
            "updated": "2023-11-11T05:30:34Z",
            "published": "2023-10-14T17:10:28Z",
            "summary": "As large language models are integrated into society, robustness toward a\nsuite of prompts is increasingly important to maintain reliability in a\nhigh-variance environment.Robustness evaluations must comprehensively\nencapsulate the various settings in which a user may invoke an intelligent\nsystem. This paper proposes ASSERT, Automated Safety Scenario Red Teaming,\nconsisting of three methods -- semantically aligned augmentation, target\nbootstrapping, and adversarial knowledge injection. For robust safety\nevaluation, we apply these methods in the critical domain of AI safety to\nalgorithmically generate a test suite of prompts covering diverse robustness\nsettings -- semantic equivalence, related scenarios, and adversarial. We\npartition our prompts into four safety domains for a fine-grained analysis of\nhow the domain affects model performance. Despite dedicated safeguards in\nexisting state-of-the-art models, we find statistically significant performance\ndifferences of up to 11% in absolute classification accuracy among semantically\nrelated scenarios and error rates of up to 19% absolute error in zero-shot\nadversarial settings, raising concerns for users' physical safety.",
            "author": [
                "Alex Mei",
                "Sharon Levy",
                "William Yang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09624v2",
                "http://arxiv.org/pdf/2310.09624v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09623v1",
            "title": "A Digital Language Coherence Marker for Monitoring Dementia",
            "updated": "2023-10-14T17:10:19Z",
            "published": "2023-10-14T17:10:19Z",
            "summary": "The use of spontaneous language to derive appropriate digital markers has\nbecome an emergent, promising and non-intrusive method to diagnose and monitor\ndementia. Here we propose methods to capture language coherence as a\ncost-effective, human-interpretable digital marker for monitoring cognitive\nchanges in people with dementia. We introduce a novel task to learn the\ntemporal logical consistency of utterances in short transcribed narratives and\ninvestigate a range of neural approaches. We compare such language coherence\npatterns between people with dementia and healthy controls and conduct a\nlongitudinal evaluation against three clinical bio-markers to investigate the\nreliability of our proposed digital coherence marker. The coherence marker\nshows a significant difference between people with mild cognitive impairment,\nthose with Alzheimer's Disease and healthy controls. Moreover our analysis\nshows high association between the coherence marker and the clinical\nbio-markers as well as generalisability potential to other related conditions.",
            "author": [
                "Dimitris Gkoumas",
                "Adam Tsakalidis",
                "Maria Liakata"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09623v1",
                "http://arxiv.org/pdf/2310.09623v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09620v1",
            "title": "Machine Learning for Urban Air Quality Analytics: A Survey",
            "updated": "2023-10-14T17:03:29Z",
            "published": "2023-10-14T17:03:29Z",
            "summary": "The increasing air pollution poses an urgent global concern with far-reaching\nconsequences, such as premature mortality and reduced crop yield, which\nsignificantly impact various aspects of our daily lives. Accurate and timely\nanalysis of air pollution is crucial for understanding its underlying\nmechanisms and implementing necessary precautions to mitigate potential\nsocio-economic losses. Traditional analytical methodologies, such as\natmospheric modeling, heavily rely on domain expertise and often make\nsimplified assumptions that may not be applicable to complex air pollution\nproblems. In contrast, Machine Learning (ML) models are able to capture the\nintrinsic physical and chemical rules by automatically learning from a large\namount of historical observational data, showing great promise in various air\nquality analytical tasks. In this article, we present a comprehensive survey of\nML-based air quality analytics, following a roadmap spanning from data\nacquisition to pre-processing, and encompassing various analytical tasks such\nas pollution pattern mining, air quality inference, and forecasting. Moreover,\nwe offer a systematic categorization and summary of existing methodologies and\napplications, while also providing a list of publicly available air quality\ndatasets to ease the research in this direction. Finally, we identify several\npromising future research directions. This survey can serve as a valuable\nresource for professionals seeking suitable solutions for their specific\nchallenges and advancing their research at the cutting edge.",
            "author": [
                "Jindong Han",
                "Weijia Zhang",
                "Hao Liu",
                "Hui Xiong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09620v1",
                "http://arxiv.org/pdf/2310.09620v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10688v1",
            "title": "A decoder-only foundation model for time-series forecasting",
            "updated": "2023-10-14T17:01:37Z",
            "published": "2023-10-14T17:01:37Z",
            "summary": "Motivated by recent advances in large language models for Natural Language\nProcessing (NLP), we design a time-series foundation model for forecasting\nwhose out-of-the-box zero-shot performance on a variety of public datasets\ncomes close to the accuracy of state-of-the-art supervised forecasting models\nfor each individual dataset. Our model is based on pretraining a\npatched-decoder style attention model on a large time-series corpus, and can\nwork well across different forecasting history lengths, prediction lengths and\ntemporal granularities.",
            "author": [
                "Abhimanyu Das",
                "Weihao Kong",
                "Rajat Sen",
                "Yichen Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10688v1",
                "http://arxiv.org/pdf/2310.10688v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09615v1",
            "title": "STORM: Efficient Stochastic Transformer based World Models for\n  Reinforcement Learning",
            "updated": "2023-10-14T16:42:02Z",
            "published": "2023-10-14T16:42:02Z",
            "summary": "Recently, model-based reinforcement learning algorithms have demonstrated\nremarkable efficacy in visual input environments. These approaches begin by\nconstructing a parameterized simulation world model of the real environment\nthrough self-supervised learning. By leveraging the imagination of the world\nmodel, the agent's policy is enhanced without the constraints of sampling from\nthe real environment. The performance of these algorithms heavily relies on the\nsequence modeling and generation capabilities of the world model. However,\nconstructing a perfectly accurate model of a complex unknown environment is\nnearly impossible. Discrepancies between the model and reality may cause the\nagent to pursue virtual goals, resulting in subpar performance in the real\nenvironment. Introducing random noise into model-based reinforcement learning\nhas been proven beneficial. In this work, we introduce Stochastic\nTransformer-based wORld Model (STORM), an efficient world model architecture\nthat combines the strong sequence modeling and generation capabilities of\nTransformers with the stochastic nature of variational autoencoders. STORM\nachieves a mean human performance of $126.7\\%$ on the Atari $100$k benchmark,\nsetting a new record among state-of-the-art methods that do not employ\nlookahead search techniques. Moreover, training an agent with $1.85$ hours of\nreal-time interaction experience on a single NVIDIA GeForce RTX 3090 graphics\ncard requires only $4.3$ hours, showcasing improved efficiency compared to\nprevious methodologies.",
            "author": [
                "Weipu Zhang",
                "Gang Wang",
                "Jian Sun",
                "Yetian Yuan",
                "Gao Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09615v1",
                "http://arxiv.org/pdf/2310.09615v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09612v1",
            "title": "Deep Neural Networks Can Learn Generalizable Same-Different Visual\n  Relations",
            "updated": "2023-10-14T16:28:57Z",
            "published": "2023-10-14T16:28:57Z",
            "summary": "Although deep neural networks can achieve human-level performance on many\nobject recognition benchmarks, prior work suggests that these same models fail\nto learn simple abstract relations, such as determining whether two objects are\nthe same or different. Much of this prior work focuses on training\nconvolutional neural networks to classify images of two same or two different\nabstract shapes, testing generalization on within-distribution stimuli. In this\narticle, we comprehensively study whether deep neural networks can acquire and\ngeneralize same-different relations both within and out-of-distribution using a\nvariety of architectures, forms of pretraining, and fine-tuning datasets. We\nfind that certain pretrained transformers can learn a same-different relation\nthat generalizes with near perfect accuracy to out-of-distribution stimuli.\nFurthermore, we find that fine-tuning on abstract shapes that lack texture or\ncolor provides the strongest out-of-distribution generalization. Our results\nsuggest that, with the right approach, deep neural networks can learn\ngeneralizable same-different visual relations.",
            "author": [
                "Alexa R. Tartaglini",
                "Sheridan Feucht",
                "Michael A. Lepori",
                "Wai Keen Vong",
                "Charles Lovering",
                "Brenden M. Lake",
                "Ellie Pavlick"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09612v1",
                "http://arxiv.org/pdf/2310.09612v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09609v1",
            "title": "Towards Intelligent Network Management: Leveraging AI for Network\n  Service Detection",
            "updated": "2023-10-14T16:06:11Z",
            "published": "2023-10-14T16:06:11Z",
            "summary": "As the complexity and scale of modern computer networks continue to increase,\nthere has emerged an urgent need for precise traffic analysis, which plays a\npivotal role in cutting-edge wireless connectivity technologies. This study\nfocuses on leveraging Machine Learning methodologies to create an advanced\nnetwork traffic classification system. We introduce a novel data-driven\napproach that excels in identifying various network service types in real-time,\nby analyzing patterns within the network traffic. Our method organizes similar\nkinds of network traffic into distinct categories, referred to as network\nservices, based on latency requirement. Furthermore, it decomposes the network\ntraffic stream into multiple, smaller traffic flows, with each flow uniquely\ncarrying a specific service. Our ML models are trained on a dataset comprised\nof labeled examples representing different network service types collected on\nvarious Wi-Fi network conditions. Upon evaluation, our system demonstrates a\nremarkable accuracy in distinguishing the network services. These results\nemphasize the substantial promise of integrating Artificial Intelligence in\nwireless technologies. Such an approach encourages more efficient energy\nconsumption, enhances Quality of Service assurance, and optimizes the\nallocation of network resources, thus laying a solid groundwork for the\ndevelopment of advanced intelligent networks.",
            "author": [
                "Khuong N. Nguyen",
                "Abhishek Sehgal",
                "Yuming Zhu",
                "Junsu Choi",
                "Guanbo Chen",
                "Hao Chen",
                "Boon Loong Ng",
                "Charlie Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09609v1",
                "http://arxiv.org/pdf/2310.09609v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09605v1",
            "title": "Penetrative AI: Making LLMs Comprehend the Physical World",
            "updated": "2023-10-14T15:48:15Z",
            "published": "2023-10-14T15:48:15Z",
            "summary": "Recent developments in Large Language Models (LLMs) have demonstrated their\nremarkable capabilities across a range of tasks. Questions, however, persist\nabout the nature of LLMs and their potential to integrate common-sense human\nknowledge when performing tasks involving information about the real physical\nworld. This paper delves into these questions by exploring how LLMs can be\nextended to interact with and reason about the physical world through IoT\nsensors and actuators, a concept that we term \"\\textit{Penetrative AI}\". The\npaper explores such an extension at two levels of LLMs' ability to penetrate\ninto the physical world via the processing of sensory signals. Our preliminary\nfindings indicate that LLMs, with ChatGPT being the representative example in\nour exploration, have considerable and unique proficiency in employing the\nknowledge they learned during training for interpreting IoT sensor data and\nreasoning over them about tasks in the physical realm. Not only this opens up\nnew applications for LLMs beyond traditional text-based tasks, but also enables\nnew ways of incorporating human knowledge in cyber-physical systems.",
            "author": [
                "Huatao Xu",
                "Liying Han",
                "Mo Li",
                "Mani Srivastava"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09605v1",
                "http://arxiv.org/pdf/2310.09605v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09604v1",
            "title": "Learning Hierarchical Features with Joint Latent Space Energy-Based\n  Prior",
            "updated": "2023-10-14T15:44:14Z",
            "published": "2023-10-14T15:44:14Z",
            "summary": "This paper studies the fundamental problem of multi-layer generator models in\nlearning hierarchical representations. The multi-layer generator model that\nconsists of multiple layers of latent variables organized in a top-down\narchitecture tends to learn multiple levels of data abstraction. However, such\nmulti-layer latent variables are typically parameterized to be Gaussian, which\ncan be less informative in capturing complex abstractions, resulting in limited\nsuccess in hierarchical representation learning. On the other hand, the\nenergy-based (EBM) prior is known to be expressive in capturing the data\nregularities, but it often lacks the hierarchical structure to capture\ndifferent levels of hierarchical representations. In this paper, we propose a\njoint latent space EBM prior model with multi-layer latent variables for\neffective hierarchical representation learning. We develop a variational joint\nlearning scheme that seamlessly integrates an inference model for efficient\ninference. Our experiments demonstrate that the proposed joint EBM prior is\neffective and expressive in capturing hierarchical representations and\nmodelling data distribution.",
            "author": [
                "Jiali Cui",
                "Ying Nian Wu",
                "Tian Han"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09604v1",
                "http://arxiv.org/pdf/2310.09604v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09603v1",
            "title": "B-Spine: Learning B-Spline Curve Representation for Robust and\n  Interpretable Spinal Curvature Estimation",
            "updated": "2023-10-14T15:34:57Z",
            "published": "2023-10-14T15:34:57Z",
            "summary": "Spinal curvature estimation is important to the diagnosis and treatment of\nthe scoliosis. Existing methods face several issues such as the need of\nexpensive annotations on the vertebral landmarks and being sensitive to the\nimage quality. It is challenging to achieve robust estimation and obtain\ninterpretable results, especially for low-quality images which are blurry and\nhazy. In this paper, we propose B-Spine, a novel deep learning pipeline to\nlearn B-spline curve representation of the spine and estimate the Cobb angles\nfor spinal curvature estimation from low-quality X-ray images. Given a\nlow-quality input, a novel SegRefine network which employs the unpaired\nimage-to-image translation is proposed to generate a high quality spine mask\nfrom the initial segmentation result. Next, a novel mask-based B-spline\nprediction model is proposed to predict the B-spline curve for the spine\ncenterline. Finally, the Cobb angles are estimated by a hybrid approach which\ncombines the curve slope analysis and a curve-based regression model. We\nconduct quantitative and qualitative comparisons with the representative and\nSOTA learning-based methods on the public AASCE2019 dataset and our new\nproposed CJUH-JLU dataset which contains more challenging low-quality images.\nThe superior performance on both datasets shows our method can achieve both\nrobustness and interpretability for spinal curvature estimation.",
            "author": [
                "Hao Wang",
                "Qiang Song",
                "Ruofeng Yin",
                "Rui Ma",
                "Yizhou Yu",
                "Yi Chang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09603v1",
                "http://arxiv.org/pdf/2310.09603v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09600v2",
            "title": "Hawkeye: A PyTorch-based Library for Fine-Grained Image Recognition with\n  Deep Learning",
            "updated": "2023-11-24T15:29:08Z",
            "published": "2023-10-14T15:20:33Z",
            "summary": "Fine-Grained Image Recognition (FGIR) is a fundamental and challenging task\nin computer vision and multimedia that plays a crucial role in Intellectual\nEconomy and Industrial Internet applications. However, the absence of a unified\nopen-source software library covering various paradigms in FGIR poses a\nsignificant challenge for researchers and practitioners in the field. To\naddress this gap, we present Hawkeye, a PyTorch-based library for FGIR with\ndeep learning. Hawkeye is designed with a modular architecture, emphasizing\nhigh-quality code and human-readable configuration, providing a comprehensive\nsolution for FGIR tasks. In Hawkeye, we have implemented 16 state-of-the-art\nfine-grained methods, covering 6 different paradigms, enabling users to explore\nvarious approaches for FGIR. To the best of our knowledge, Hawkeye represents\nthe first open-source PyTorch-based library dedicated to FGIR. It is publicly\navailable at https://github.com/Hawkeye-FineGrained/Hawkeye/, providing\nresearchers and practitioners with a powerful tool to advance their research\nand development in the field of FGIR.",
            "author": [
                "Jiabei He",
                "Yang Shen",
                "Xiu-Shen Wei",
                "Ye Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09600v2",
                "http://arxiv.org/pdf/2310.09600v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09597v1",
            "title": "Adaptive maximization of social welfare",
            "updated": "2023-10-14T15:09:56Z",
            "published": "2023-10-14T15:09:56Z",
            "summary": "We consider the problem of repeatedly choosing policies to maximize social\nwelfare. Welfare is a weighted sum of private utility and public revenue.\nEarlier outcomes inform later policies. Utility is not observed, but indirectly\ninferred. Response functions are learned through experimentation.\n  We derive a lower bound on regret, and a matching adversarial upper bound for\na variant of the Exp3 algorithm. Cumulative regret grows at a rate of\n$T^{2/3}$. This implies that (i) welfare maximization is harder than the\nmulti-armed bandit problem (with a rate of $T^{1/2}$ for finite policy sets),\nand (ii) our algorithm achieves the optimal rate. For the stochastic setting,\nif social welfare is concave, we can achieve a rate of $T^{1/2}$ (for\ncontinuous policy sets), using a dyadic search algorithm.\n  We analyze an extension to nonlinear income taxation, and sketch an extension\nto commodity taxation. We compare our setting to monopoly pricing (which is\neasier), and price setting for bilateral trade (which is harder).",
            "author": [
                "Nicolo Cesa-Bianchi",
                "Roberto Colomboni",
                "Maximilian Kasy"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09597v1",
                "http://arxiv.org/pdf/2310.09597v1"
            ],
            "primary_category": "econ.EM",
            "category": [
                "econ.EM",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09593v1",
            "title": "Context-aware Session-based Recommendation with Graph Neural Networks",
            "updated": "2023-10-14T14:29:52Z",
            "published": "2023-10-14T14:29:52Z",
            "summary": "Session-based recommendation (SBR) is a task that aims to predict items based\non anonymous sequences of user behaviors in a session. While there are methods\nthat leverage rich context information in sessions for SBR, most of them have\nthe following limitations: 1) they fail to distinguish the item-item edge types\nwhen constructing the global graph for exploiting cross-session contexts; 2)\nthey learn a fixed embedding vector for each item, which lacks the flexibility\nto reflect the variation of user interests across sessions; 3) they generally\nuse the one-hot encoded vector of the target item as the hard label to predict,\nthus failing to capture the true user preference. To solve these issues, we\npropose CARES, a novel context-aware session-based recommendation model with\ngraph neural networks, which utilizes different types of contexts in sessions\nto capture user interests. Specifically, we first construct a multi-relation\ncross-session graph to connect items according to intra- and cross-session\nitem-level contexts. Further, to encode the variation of user interests, we\ndesign personalized item representations. Finally, we employ a label\ncollaboration strategy for generating soft user preference distribution as\nlabels. Experiments on three benchmark datasets demonstrate that CARES\nconsistently outperforms state-of-the-art models in terms of P@20 and MRR@20.\nOur data and codes are publicly available at\nhttps://github.com/brilliantZhang/CARES.",
            "author": [
                "Zhihui Zhang",
                "JianXiang Yu",
                "Xiang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09593v1",
                "http://arxiv.org/pdf/2310.09593v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI",
                "F.4.1"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09590v2",
            "title": "Solving Math Word Problems with Reexamination",
            "updated": "2023-11-20T03:29:23Z",
            "published": "2023-10-14T14:23:44Z",
            "summary": "Math word problem (MWP) solving aims to understand the descriptive math\nproblem and calculate the result, for which previous efforts are mostly devoted\nto upgrade different technical modules. This paper brings a different\nperspective of \\textit{reexamination process} during training by introducing a\npseudo-dual task to enhance the MWP solving. We propose a pseudo-dual (PseDual)\nlearning scheme to model such process, which is model-agnostic thus can be\nadapted to any existing MWP solvers. The pseudo-dual task is specifically\ndefined as filling the numbers in the expression back into the original word\nproblem with numbers masked. To facilitate the effective joint learning of the\ntwo tasks, we further design a scheduled fusion strategy for the number\ninfilling task, which smoothly switches the input from the ground-truth math\nexpressions to the predicted ones. Our pseudo-dual learning scheme has been\ntested and proven effective when being equipped in several representative MWP\nsolvers through empirical studies. \\textit{The codes and trained models are\navailable at:} \\url{https://github.com/steven640pixel/PsedualMWP}.\n\\end{abstract}",
            "author": [
                "Yi Bin",
                "Wenhao Shi",
                "Yujuan Ding",
                "Yang Yang",
                "See-Kiong Ng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09590v2",
                "http://arxiv.org/pdf/2310.09590v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09589v1",
            "title": "Airborne Sense and Detect of Drones using LiDAR and adapted PointPillars\n  DNN",
            "updated": "2023-10-14T14:11:46Z",
            "published": "2023-10-14T14:11:46Z",
            "summary": "The safe operation of drone swarms beyond visual line of sight requires\nmultiple safeguards to mitigate the risk of collision between drones flying in\nhyper localised scenarios. Cooperative navigation and flight coordination\nstrategies that rely on pre-planned trajectories and require constant network\nconnectivity are brittle to failure. Drone embedded sense and detect offers a\ncomprehensive mode of separation between drones for deconfliction and collision\navoidance. This paper presents the first airborne LiDAR based solution for\ndrone-swarm detection and localisation using 3D deep learning. It adapts and\nembeds the PointPillars deep learning neural network on the drone. To collect\ntraining data of close-quarter multi drone operations and safety critical\nscenarios, a scenario Digital Twin is used to augment real datasets with high\nfidelity synthetic data. The method has been validated in real-world tests. The\ntrained model achieves over 80% recall and 96% precision when tested on real\ndatasets. By incorporating a detection-by-tracking algorithm the system can\nreliably monitor the separation distance of multiple drones in challenging\nenvironments.",
            "author": [
                "Manduhu Manduhu",
                "Alexander Dow",
                "Petar Trslic",
                "Gerard Dooly",
                "Benjamin Blanck",
                "James Riordan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09589v1",
                "http://arxiv.org/pdf/2310.09589v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09586v2",
            "title": "Causality and Independence Enhancement for Biased Node Classification",
            "updated": "2023-11-05T01:19:21Z",
            "published": "2023-10-14T13:56:24Z",
            "summary": "Most existing methods that address out-of-distribution (OOD) generalization\nfor node classification on graphs primarily focus on a specific type of data\nbiases, such as label selection bias or structural bias. However, anticipating\nthe type of bias in advance is extremely challenging, and designing models\nsolely for one specific type may not necessarily improve overall generalization\nperformance. Moreover, limited research has focused on the impact of mixed\nbiases, which are more prevalent and demanding in real-world scenarios. To\naddress these limitations, we propose a novel Causality and Independence\nEnhancement (CIE) framework, applicable to various graph neural networks\n(GNNs). Our approach estimates causal and spurious features at the node\nrepresentation level and mitigates the influence of spurious correlations\nthrough the backdoor adjustment. Meanwhile, independence constraint is\nintroduced to improve the discriminability and stability of causal and spurious\nfeatures in complex biased environments. Essentially, CIE eliminates different\ntypes of data biases from a unified perspective, without the need to design\nseparate methods for each bias as before. To evaluate the performance under\nspecific types of data biases, mixed biases, and low-resource scenarios, we\nconducted comprehensive experiments on five publicly available datasets.\nExperimental results demonstrate that our approach CIE not only significantly\nenhances the performance of GNNs but outperforms state-of-the-art debiased node\nclassification methods.",
            "author": [
                "Guoxin Chen",
                "Yongqing Wang",
                "Fangda Guo",
                "Qinglang Guo",
                "Jiangli Shao",
                "Huawei Shen",
                "Xueqi Cheng"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583780.3614804",
                "http://arxiv.org/abs/2310.09586v2",
                "http://arxiv.org/pdf/2310.09586v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09583v1",
            "title": "Two Sides of The Same Coin: Bridging Deep Equilibrium Models and Neural\n  ODEs via Homotopy Continuation",
            "updated": "2023-10-14T13:28:36Z",
            "published": "2023-10-14T13:28:36Z",
            "summary": "Deep Equilibrium Models (DEQs) and Neural Ordinary Differential Equations\n(Neural ODEs) are two branches of implicit models that have achieved remarkable\nsuccess owing to their superior performance and low memory consumption. While\nboth are implicit models, DEQs and Neural ODEs are derived from different\nmathematical formulations. Inspired by homotopy continuation, we establish a\nconnection between these two models and illustrate that they are actually two\nsides of the same coin. Homotopy continuation is a classical method of solving\nnonlinear equations based on a corresponding ODE. Given this connection, we\nproposed a new implicit model called HomoODE that inherits the property of high\naccuracy from DEQs and the property of stability from Neural ODEs. Unlike DEQs,\nwhich explicitly solve an equilibrium-point-finding problem via Newton's\nmethods in the forward pass, HomoODE solves the equilibrium-point-finding\nproblem implicitly using a modified Neural ODE via homotopy continuation.\nFurther, we developed an acceleration method for HomoODE with a shared\nlearnable initial point. It is worth noting that our model also provides a\nbetter understanding of why Augmented Neural ODEs work as long as the augmented\npart is regarded as the equilibrium point to find. Comprehensive experiments\nwith several image classification tasks demonstrate that HomoODE surpasses\nexisting implicit models in terms of both accuracy and memory consumption.",
            "author": [
                "Shutong Ding",
                "Tianyu Cui",
                "Jingya Wang",
                "Ye Shi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09583v1",
                "http://arxiv.org/pdf/2310.09583v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09578v1",
            "title": "Sparse Index Tracking via Topological Learning",
            "updated": "2023-10-14T13:00:36Z",
            "published": "2023-10-14T13:00:36Z",
            "summary": "In this research, we introduce a novel methodology for the index tracking\nproblem with sparse portfolios by leveraging topological data analysis (TDA).\nUtilizing persistence homology to measure the riskiness of assets, we introduce\na topological method for data-driven learning of the parameters for\nregularization terms. Specifically, the Vietoris-Rips filtration method is\nutilized to capture the intricate topological features of asset movements,\nproviding a robust framework for portfolio tracking. Our approach has the\nadvantage of accommodating both $\\ell_1$ and $\\ell_2$ penalty terms without the\nrequirement for expensive estimation procedures. We empirically validate the\nperformance of our methodology against state-of-the-art sparse index tracking\ntechniques, such as Elastic-Net and SLOPE, using a dataset that covers 23 years\nof S&P500 index and its constituent data. Our out-of-sample results show that\nthis computationally efficient technique surpasses conventional methods across\nrisk metrics, risk-adjusted performance, and trading expenses in varied market\nconditions. Furthermore, in turbulent markets, it not only maintains but also\nenhances tracking performance.",
            "author": [
                "Anubha Goel",
                "Puneet Pasricha",
                "Juho Kanniainen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09578v1",
                "http://arxiv.org/pdf/2310.09578v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE",
                "q-fin.PM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09575v1",
            "title": "Common Challenges of Deep Reinforcement Learning Applications\n  Development: An Empirical Study",
            "updated": "2023-10-14T12:57:30Z",
            "published": "2023-10-14T12:57:30Z",
            "summary": "Machine Learning (ML) is increasingly being adopted in different industries.\nDeep Reinforcement Learning (DRL) is a subdomain of ML used to produce\nintelligent agents. Despite recent developments in DRL technology, the main\nchallenges that developers face in the development of DRL applications are\nstill unknown. To fill this gap, in this paper, we conduct a large-scale\nempirical study of 927 DRL-related posts extracted from Stack Overflow, the\nmost popular Q&A platform in the software community. Through the process of\nlabeling and categorizing extracted posts, we created a taxonomy of common\nchallenges encountered in the development of DRL applications, along with their\ncorresponding popularity levels. This taxonomy has been validated through a\nsurvey involving 59 DRL developers. Results show that at least 45% of\ndevelopers experienced 18 of the 21 challenges identified in the taxonomy. The\nmost frequent source of difficulty during the development of DRL applications\nare Comprehension, API usage, and Design problems, while Parallel processing,\nand DRL libraries/frameworks are classified as the most difficult challenges to\naddress, with respect to the time required to receive an accepted answer. We\nhope that the research community will leverage this taxonomy to develop\nefficient strategies to address the identified challenges and improve the\nquality of DRL applications.",
            "author": [
                "Mohammad Mehdi Morovati",
                "Florian Tambon",
                "Mina Taraghi",
                "Amin Nikanjam",
                "Foutse Khomh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09575v1",
                "http://arxiv.org/pdf/2310.09575v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09574v1",
            "title": "Reduced Policy Optimization for Continuous Control with Hard Constraints",
            "updated": "2023-10-14T12:55:43Z",
            "published": "2023-10-14T12:55:43Z",
            "summary": "Recent advances in constrained reinforcement learning (RL) have endowed\nreinforcement learning with certain safety guarantees. However, deploying\nexisting constrained RL algorithms in continuous control tasks with general\nhard constraints remains challenging, particularly in those situations with\nnon-convex hard constraints. Inspired by the generalized reduced gradient (GRG)\nalgorithm, a classical constrained optimization technique, we propose a reduced\npolicy optimization (RPO) algorithm that combines RL with GRG to address\ngeneral hard constraints. RPO partitions actions into basic actions and\nnonbasic actions following the GRG method and outputs the basic actions via a\npolicy network. Subsequently, RPO calculates the nonbasic actions by solving\nequations based on equality constraints using the obtained basic actions. The\npolicy network is then updated by implicitly differentiating nonbasic actions\nwith respect to basic actions. Additionally, we introduce an action projection\nprocedure based on the reduced gradient and apply a modified Lagrangian\nrelaxation technique to ensure inequality constraints are satisfied. To the\nbest of our knowledge, RPO is the first attempt that introduces GRG to RL as a\nway of efficiently handling both equality and inequality hard constraints. It\nis worth noting that there is currently a lack of RL environments with complex\nhard constraints, which motivates us to develop three new benchmarks: two\nrobotics manipulation tasks and a smart grid operation control task. With these\nbenchmarks, RPO achieves better performance than previous constrained RL\nalgorithms in terms of both cumulative reward and constraint violation. We\nbelieve RPO, along with the new benchmarks, will open up new opportunities for\napplying RL to real-world problems with complex constraints.",
            "author": [
                "Shutong Ding",
                "Jingya Wang",
                "Yali Du",
                "Ye Shi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09574v1",
                "http://arxiv.org/pdf/2310.09574v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09571v1",
            "title": "On the Feasibility of Cross-Language Detection of Malicious Packages in\n  npm and PyPI",
            "updated": "2023-10-14T12:32:51Z",
            "published": "2023-10-14T12:32:51Z",
            "summary": "Current software supply chains heavily rely on open-source packages hosted in\npublic repositories. Given the popularity of ecosystems like npm and PyPI,\nmalicious users started to spread malware by publishing open-source packages\ncontaining malicious code. Recent works apply machine learning techniques to\ndetect malicious packages in the npm ecosystem. However, the scarcity of\nsamples poses a challenge to the application of machine learning techniques in\nother ecosystems. Despite the differences between JavaScript and Python, the\nopen-source software supply chain attacks targeting such languages show\nnoticeable similarities (e.g., use of installation scripts, obfuscated strings,\nURLs).\n  In this paper, we present a novel approach that involves a set of\nlanguage-independent features and the training of models capable of detecting\nmalicious packages in npm and PyPI by capturing their commonalities. This\nmethodology allows us to train models on a diverse dataset encompassing\nmultiple languages, thereby overcoming the challenge of limited sample\navailability. We evaluate the models both in a controlled experiment (where\nlabels of data are known) and in the wild by scanning newly uploaded packages\nfor both npm and PyPI for 10 days.\n  We find that our approach successfully detects malicious packages for both\nnpm and PyPI. Over an analysis of 31,292 packages, we reported 58 previously\nunknown malicious packages (38 for npm and 20 for PyPI), which were\nconsequently removed from the respective repositories.",
            "author": [
                "Piergiorgio Ladisa",
                "Serena Elisa Ponta",
                "Nicola Ronzoni",
                "Matias Martinez",
                "Olivier Barais"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3627106.3627138",
                "http://arxiv.org/abs/2310.09571v1",
                "http://arxiv.org/pdf/2310.09571v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10685v1",
            "title": "PS-AAS: Portfolio Selection for Automated Algorithm Selection in\n  Black-Box Optimization",
            "updated": "2023-10-14T12:13:41Z",
            "published": "2023-10-14T12:13:41Z",
            "summary": "The performance of automated algorithm selection (AAS) strongly depends on\nthe portfolio of algorithms to choose from. Selecting the portfolio is a\nnon-trivial task that requires balancing the trade-off between the higher\nflexibility of large portfolios with the increased complexity of the AAS task.\nIn practice, probably the most common way to choose the algorithms for the\nportfolio is a greedy selection of the algorithms that perform well in some\nreference tasks of interest.\n  We set out in this work to investigate alternative, data-driven portfolio\nselection techniques. Our proposed method creates algorithm behavior\nmeta-representations, constructs a graph from a set of algorithms based on\ntheir meta-representation similarity, and applies a graph algorithm to select a\nfinal portfolio of diverse, representative, and non-redundant algorithms. We\nevaluate two distinct meta-representation techniques (SHAP and performance2vec)\nfor selecting complementary portfolios from a total of 324 different variants\nof CMA-ES for the task of optimizing the BBOB single-objective problems in\ndimensionalities 5 and 30 with different cut-off budgets. We test two types of\nportfolios: one related to overall algorithm behavior and the `personalized'\none (related to algorithm behavior per each problem separately). We observe\nthat the approach built on the performance2vec-based representations favors\nsmall portfolios with negligible error in the AAS task relative to the virtual\nbest solver from the selected portfolio, whereas the portfolios built from the\nSHAP-based representations gain from higher flexibility at the cost of\ndecreased performance of the AAS. Across most considered scenarios,\npersonalized portfolios yield comparable or slightly better performance than\nthe classical greedy approach. They outperform the full portfolio in all\nscenarios.",
            "author": [
                "Ana Kostovska",
                "Gjorgjina Cenikj",
                "Diederick Vermetten",
                "Anja Jankovic",
                "Ana Nikolikj",
                "Urban Skvorc",
                "Peter Korosec",
                "Carola Doerr",
                "Tome Eftimov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10685v1",
                "http://arxiv.org/pdf/2310.10685v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03365v1",
            "title": "Leveraging Generative AI: Improving Software Metadata Classification\n  with Generated Code-Comment Pairs",
            "updated": "2023-10-14T12:09:43Z",
            "published": "2023-10-14T12:09:43Z",
            "summary": "In software development, code comments play a crucial role in enhancing code\ncomprehension and collaboration. This research paper addresses the challenge of\nobjectively classifying code comments as \"Useful\" or \"Not Useful.\" We propose a\nnovel solution that harnesses contextualized embeddings, particularly BERT, to\nautomate this classification process. We address this task by incorporating\ngenerated code and comment pairs. The initial dataset comprised 9048 pairs of\ncode and comments written in C, labeled as either Useful or Not Useful. To\naugment this dataset, we sourced an additional 739 lines of code-comment pairs\nand generated labels using a Large Language Model Architecture, specifically\nBERT. The primary objective was to build classification models that can\neffectively differentiate between useful and not useful code comments. Various\nmachine learning algorithms were employed, including Logistic Regression,\nDecision Tree, K-Nearest Neighbors (KNN), Support Vector Machine (SVM),\nGradient Boosting, Random Forest, and a Neural Network. Each algorithm was\nevaluated using precision, recall, and F1-score metrics, both with the original\nseed dataset and the augmented dataset. This study showcases the potential of\ngenerative AI for enhancing binary code comment quality classification models,\nproviding valuable insights for software developers and researchers in the\nfield of natural language processing and software engineering.",
            "author": [
                "Samah Syed",
                "Angel Deborah S"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03365v1",
                "http://arxiv.org/pdf/2311.03365v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09563v1",
            "title": "Learning Unified Representations for Multi-Resolution Face Recognition",
            "updated": "2023-10-14T11:26:43Z",
            "published": "2023-10-14T11:26:43Z",
            "summary": "In this work, we propose Branch-to-Trunk network (BTNet), a representation\nlearning method for multi-resolution face recognition. It consists of a trunk\nnetwork (TNet), namely a unified encoder, and multiple branch networks (BNets),\nnamely resolution adapters. As per the input, a resolution-specific BNet is\nused and the output are implanted as feature maps in the feature pyramid of\nTNet, at a layer with the same resolution. The discriminability of tiny faces\nis significantly improved, as the interpolation error introduced by rescaling,\nespecially up-sampling, is mitigated on the inputs. With branch distillation\nand backward-compatible training, BTNet transfers discriminative\nhigh-resolution information to multiple branches while guaranteeing\nrepresentation compatibility. Our experiments demonstrate strong performance on\nface recognition benchmarks, both for multi-resolution identity matching and\nfeature aggregation, with much less computation amount and parameter storage.\nWe establish new state-of-the-art on the challenging QMUL-SurvFace 1: N face\nidentification task. Our code is available at\nhttps://github.com/StevenSmith2000/BTNet.",
            "author": [
                "Hulingxiao He",
                "Wu Yuan",
                "Yidian Huang",
                "Shilong Zhao",
                "Wen Yuan",
                "Hanqing Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09563v1",
                "http://arxiv.org/pdf/2310.09563v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09562v1",
            "title": "Does CLIP's Generalization Performance Mainly Stem from High Train-Test\n  Similarity?",
            "updated": "2023-10-14T11:24:28Z",
            "published": "2023-10-14T11:24:28Z",
            "summary": "Foundation models like CLIP are trained on hundreds of millions of samples\nand effortlessly generalize to new tasks and inputs. Out of the box, CLIP shows\nstellar zero-shot and few-shot capabilities on a wide range of\nout-of-distribution (OOD) benchmarks, which prior works attribute mainly to\ntoday's large and comprehensive training dataset (like LAION). However, it is\nquestionable how meaningful terms like out-of-distribution generalization are\nfor CLIP as it seems likely that web-scale datasets like LAION simply contain\nmany samples that are similar to common OOD benchmarks originally designed for\nImageNet. To test this hypothesis, we retrain CLIP on pruned LAION splits that\nreplicate ImageNet's train-test similarity with respect to common OOD\nbenchmarks. While we observe a performance drop on some benchmarks,\nsurprisingly, CLIP's overall performance remains high. This shows that high\ntrain-test similarity is insufficient to explain CLIP's OOD performance, and\nother properties of the training data must drive CLIP to learn more\ngeneralizable representations. Additionally, by pruning data points that are\ndissimilar to the OOD benchmarks, we uncover a 100M split of LAION\n($\\frac{1}{4}$th of its original size) on which CLIP can be trained to match\nits original OOD performance.",
            "author": [
                "Prasanna Mayilvahanan",
                "Thadd\u00e4us Wiedemer",
                "Evgenia Rusak",
                "Matthias Bethge",
                "Wieland Brendel"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09562v1",
                "http://arxiv.org/pdf/2310.09562v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09561v1",
            "title": "Graph Neural Network approaches for single-cell data: A recent overview",
            "updated": "2023-10-14T11:09:17Z",
            "published": "2023-10-14T11:09:17Z",
            "summary": "Graph Neural Networks (GNN) are reshaping our understanding of biomedicine\nand diseases by revealing the deep connections among genes and cells. As both\nalgorithmic and biomedical technologies have advanced significantly, we're\nentering a transformative phase of personalized medicine. While pioneering\ntools like Graph Attention Networks (GAT) and Graph Convolutional Neural\nNetworks (Graph CNN) are advancing graph-based learning, the rise of\nsingle-cell sequencing techniques is reshaping our insights on cellular\ndiversity and function. Numerous studies have combined GNNs with single-cell\ndata, showing promising results. In this work, we highlight the GNN\nmethodologies tailored for single-cell data over the recent years. We outline\nthe diverse range of graph deep learning architectures that center on GAT\nmethodologies. Furthermore, we underscore the several objectives of GNN\nstrategies in single-cell data contexts, ranging from cell-type annotation,\ndata integration and imputation, gene regulatory network reconstruction,\nclustering and many others. This review anticipates a future where GNNs become\ncentral to single-cell analysis efforts, particularly as vast omics datasets\nare continuously generated and the interconnectedness of cells and genes\nenhances our depth of knowledge in biomedicine.",
            "author": [
                "Konstantinos Lazaros",
                "Dimitris E. Koumadorakis",
                "Panagiotis Vlamos",
                "Aristidis G. Vrahatis"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09561v1",
                "http://arxiv.org/pdf/2310.09561v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "q-bio.GN"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13714v1",
            "title": "A study of the impact of generative AI-based data augmentation on\n  software metadata classification",
            "updated": "2023-10-14T10:47:10Z",
            "published": "2023-10-14T10:47:10Z",
            "summary": "This paper presents the system submitted by the team from IIT(ISM) Dhanbad in\nFIRE IRSE 2023 shared task 1 on the automatic usefulness prediction of\ncode-comment pairs as well as the impact of Large Language Model(LLM) generated\ndata on original base data towards an associated source code. We have developed\na framework where we train a machine learning-based model using the neural\ncontextual representations of the comments and their corresponding codes to\npredict the usefulness of code-comments pair and performance analysis with\nLLM-generated data with base data. In the official assessment, our system\nachieves a 4% increase in F1-score from baseline and the quality of generated\ndata.",
            "author": [
                "Tripti Kumari",
                "Chakali Sai Charan",
                "Ayan Das"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13714v1",
                "http://arxiv.org/pdf/2310.13714v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09554v1",
            "title": "Neural network scoring for efficient computing",
            "updated": "2023-10-14T10:29:52Z",
            "published": "2023-10-14T10:29:52Z",
            "summary": "Much work has been dedicated to estimating and optimizing workloads in\nhigh-performance computing (HPC) and deep learning. However, researchers have\ntypically relied on few metrics to assess the efficiency of those techniques.\nMost notably, the accuracy, the loss of the prediction, and the computational\ntime with regard to GPUs or/and CPUs characteristics. It is rare to see figures\nfor power consumption, partly due to the difficulty of obtaining accurate power\nreadings. In this paper, we introduce a composite score that aims to\ncharacterize the trade-off between accuracy and power consumption measured\nduring the inference of neural networks. For this purpose, we present a new\nopen-source tool allowing researchers to consider more metrics: granular power\nconsumption, but also RAM/CPU/GPU utilization, as well as storage, and network\ninput/output (I/O). To our best knowledge, it is the first fit test for neural\narchitectures on hardware architectures. This is made possible thanks to\nreproducible power efficiency measurements. We applied this procedure to\nstate-of-the-art neural network architectures on miscellaneous hardware. One of\nthe main applications and novelties is the measurement of algorithmic power\nefficiency. The objective is to allow researchers to grasp their algorithms'\nefficiencies better. This methodology was developed to explore trade-offs\nbetween energy usage and accuracy in neural networks. It is also useful when\nfitting hardware for a specific task or to compare two architectures more\naccurately, with architecture exploration in mind.",
            "author": [
                "Hugo Waltsburger",
                "Erwan Libessart",
                "Chengfang Ren",
                "Anthony Kolar",
                "Regis Guinvarc'h"
            ],
            "link": [
                "http://dx.doi.org/10.1109/ISCAS46773.2023.10181766",
                "http://arxiv.org/abs/2310.09554v1",
                "http://arxiv.org/pdf/2310.09554v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "I.2; I.4; C.4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09553v1",
            "title": "ARTree: A Deep Autoregressive Model for Phylogenetic Inference",
            "updated": "2023-10-14T10:26:03Z",
            "published": "2023-10-14T10:26:03Z",
            "summary": "Designing flexible probabilistic models over tree topologies is important for\ndeveloping efficient phylogenetic inference methods. To do that, previous works\noften leverage the similarity of tree topologies via hand-engineered heuristic\nfeatures which would require pre-sampled tree topologies and may suffer from\nlimited approximation capability. In this paper, we propose a deep\nautoregressive model for phylogenetic inference based on graph neural networks\n(GNNs), called ARTree. By decomposing a tree topology into a sequence of leaf\nnode addition operations and modeling the involved conditional distributions\nbased on learnable topological features via GNNs, ARTree can provide a rich\nfamily of distributions over the entire tree topology space that have simple\nsampling algorithms and density estimation procedures, without using heuristic\nfeatures. We demonstrate the effectiveness and efficiency of our method on a\nbenchmark of challenging real data tree topology density estimation and\nvariational Bayesian phylogenetic inference problems.",
            "author": [
                "Tianyu Xie",
                "Cheng Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09553v1",
                "http://arxiv.org/pdf/2310.09553v1"
            ],
            "primary_category": "q-bio.PE",
            "category": [
                "q-bio.PE",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09549v1",
            "title": "Scene Text Recognition Models Explainability Using Local Features",
            "updated": "2023-10-14T10:01:52Z",
            "published": "2023-10-14T10:01:52Z",
            "summary": "Explainable AI (XAI) is the study on how humans can be able to understand the\ncause of a model's prediction. In this work, the problem of interest is Scene\nText Recognition (STR) Explainability, using XAI to understand the cause of an\nSTR model's prediction. Recent XAI literatures on STR only provide a simple\nanalysis and do not fully explore other XAI methods. In this study, we\nspecifically work on data explainability frameworks, called attribution-based\nmethods, that explain the important parts of an input data in deep learning\nmodels. However, integrating them into STR produces inconsistent and\nineffective explanations, because they only explain the model in the global\ncontext. To solve this problem, we propose a new method, STRExp, to take into\nconsideration the local explanations, i.e. the individual character prediction\nexplanations. This is then benchmarked across different attribution-based\nmethods on different STR datasets and evaluated across different STR models.",
            "author": [
                "Mark Vincent Ty",
                "Rowel Atienza"
            ],
            "link": [
                "http://dx.doi.org/10.1109/ICIP49359.2023.10222406",
                "http://arxiv.org/abs/2310.09549v1",
                "http://arxiv.org/pdf/2310.09549v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09545v1",
            "title": "A Semiparametric Instrumented Difference-in-Differences Approach to\n  Policy Learning",
            "updated": "2023-10-14T09:38:32Z",
            "published": "2023-10-14T09:38:32Z",
            "summary": "Recently, there has been a surge in methodological development for the\ndifference-in-differences (DiD) approach to evaluate causal effects. Standard\nmethods in the literature rely on the parallel trends assumption to identify\nthe average treatment effect on the treated. However, the parallel trends\nassumption may be violated in the presence of unmeasured confounding, and the\naverage treatment effect on the treated may not be useful in learning a\ntreatment assignment policy for the entire population. In this article, we\npropose a general instrumented DiD approach for learning the optimal treatment\npolicy. Specifically, we establish identification results using a binary\ninstrumental variable (IV) when the parallel trends assumption fails to hold.\nAdditionally, we construct a Wald estimator, novel inverse probability\nweighting (IPW) estimators, and a class of semiparametric efficient and\nmultiply robust estimators, with theoretical guarantees on consistency and\nasymptotic normality, even when relying on flexible machine learning algorithms\nfor nuisance parameters estimation. Furthermore, we extend the instrumented DiD\nto the panel data setting. We evaluate our methods in extensive simulations and\na real data application.",
            "author": [
                "Pan Zhao",
                "Yifan Cui"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09545v1",
                "http://arxiv.org/pdf/2310.09545v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "econ.EM",
                "math.ST",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09543v1",
            "title": "Benchmarking the Sim-to-Real Gap in Cloth Manipulation",
            "updated": "2023-10-14T09:36:01Z",
            "published": "2023-10-14T09:36:01Z",
            "summary": "Realistic physics engines play a crucial role for learning to manipulate\ndeformable objects such as garments in simulation. By doing so, researchers can\ncircumvent challenges such as sensing the deformation of the object in the\nreal-world. In spite of the extensive use of simulations for this task, few\nworks have evaluated the reality gap between deformable object simulators and\nreal-world data. We present a benchmark dataset to evaluate the sim-to-real gap\nin cloth manipulation. The dataset is collected by performing a dynamic cloth\nmanipulation task involving contact with a rigid table. We use the dataset to\nevaluate the reality gap, computational time, and simulation stability of four\npopular deformable object simulators: MuJoCo, Bullet, Flex, and SOFA.\nAdditionally, we discuss the benefits and drawbacks of each simulator. The\nbenchmark dataset is open-source. Supplementary material, videos, and code, can\nbe found at https://sites.google.com/view/cloth-sim2real-benchmark.",
            "author": [
                "David Blanco-Mulero",
                "Oriol Barbany",
                "Gokhan Alcan",
                "Adri\u00e0 Colom\u00e9",
                "Carme Torras",
                "Ville Kyrki"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09543v1",
                "http://arxiv.org/pdf/2310.09543v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10730v1",
            "title": "ItsSQL: Intelligent Tutoring System for SQL",
            "updated": "2023-10-14T09:11:40Z",
            "published": "2023-10-14T09:11:40Z",
            "summary": "SQL is a central component of any database course. Despite the small number\nof SQL commands, students struggle to practice the concepts. To overcome this\nchallenge, we developed an intelligent tutoring system (ITS) to guide the\nlearning process with a small effort by the lecturer. Other systems often give\nonly basic feedback (correct or incorrect) or require hundreds of instance\nspecific rules defined by a lecturer. In contrast, our system can provide\nindividual feedback based on a semi-automatically/intelligent growing pool of\nreference solutions, i.e., sensible approaches. Moreover, we introduced the\nconcept of good and bad reference solutions. The system was developed and\nevaluated in three steps based on Design Science research guidelines. The\nresults of the study demonstrate that providing multiple reference solutions\nare useful with the support of harmonization to provide individual and\nreal-time feedback and thus improve the learning process for students.",
            "author": [
                "S\u00f6ren Aguirre Reid",
                "Frank Kammer",
                "Johannes Kunz",
                "Timon Pellekoorne",
                "Markus Siepermann",
                "Jonas W\u00f6lfer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10730v1",
                "http://arxiv.org/pdf/2311.10730v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.SE",
                "D.2.0"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10729v1",
            "title": "Chatbot-supported Thesis Writing: An Autoethnographic Report",
            "updated": "2023-10-14T09:09:26Z",
            "published": "2023-10-14T09:09:26Z",
            "summary": "The release of the large language model based chatbot ChatGPT in November\n2022 has brought considerable attention to the subject of artificial\nintelligence, not only in the public. From the perspective of higher education,\nChatGPT challenges various learning and assessment formats as it significantly\nreduces the effectiveness of their learning and assessment functionalities. In\nparticular, ChatGPT might be applied to formats that require learners to\ngenerate text, such as bachelor theses or student research papers. Accordingly,\nthe research question arises to what extent writing of bachelor theses is still\na valid learning and assessment format. Correspondingly, in this study, the\nfirst author was asked to write his bachelor's thesis exploiting ChatGPT. For\ntracing the impact of ChatGPT, methodically an autoethnographic approach was\nused. First, all considerations on the potential use of ChatGPT were documented\nin logs and secondly, all ChatGPT chats were logged. Both logs and chat\nhistories were analyzed and are presented along to the recommendations for\nstudents regarding the use of ChatGPT suggested by Gimpel et al. (2023). In\nconclusion, ChatGPT is beneficial in thesis writing during various activities,\nsuch as brainstorming, structuring and text revision. However, there arise\nlimitations, e.g., in referencing. Thus, ChatGPT requires a continuous\nvalidation of the outcomes generated fostering learning. Currently, ChatGPT is\nto be valued as a beneficial tool in thesis writing. However, writing a\nconclusive thesis still requires the learner's meaningful engagement.\nAccordingly, writing a thesis is still a valid learning and assessment format.\nWith further releases of ChatGPT, an increase in capabilities is to be expected\nand the research question needs to be reevaluated from time to time.",
            "author": [
                "Nicolas Schwenke",
                "Heinrich S\u00f6bke",
                "Eckhard Kraft"
            ],
            "link": [
                "http://dx.doi.org/10.3390/higheredu2040037",
                "http://arxiv.org/abs/2311.10729v1",
                "http://arxiv.org/pdf/2311.10729v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.CL",
                "cs.HC",
                "97U50 (Primary), 68T50 (Secondary)",
                "I.2.7; I.2.1; K.3.1"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09536v1",
            "title": "CarExpert: Leveraging Large Language Models for In-Car Conversational\n  Question Answering",
            "updated": "2023-10-14T08:46:24Z",
            "published": "2023-10-14T08:46:24Z",
            "summary": "Large language models (LLMs) have demonstrated remarkable performance by\nfollowing natural language instructions without fine-tuning them on\ndomain-specific tasks and data. However, leveraging LLMs for domain-specific\nquestion answering suffers from severe limitations. The generated answer tends\nto hallucinate due to the training data collection time (when using\noff-the-shelf), complex user utterance and wrong retrieval (in\nretrieval-augmented generation). Furthermore, due to the lack of awareness\nabout the domain and expected output, such LLMs may generate unexpected and\nunsafe answers that are not tailored to the target domain. In this paper, we\npropose CarExpert, an in-car retrieval-augmented conversational\nquestion-answering system leveraging LLMs for different tasks. Specifically,\nCarExpert employs LLMs to control the input, provide domain-specific documents\nto the extractive and generative answering components, and controls the output\nto ensure safe and domain-specific answers. A comprehensive empirical\nevaluation exhibits that CarExpert outperforms state-of-the-art LLMs in\ngenerating natural, safe and car-specific answers.",
            "author": [
                "Md Rashad Al Hasan Rony",
                "Christian Suess",
                "Sinchana Ramakanth Bhat",
                "Viju Sudhi",
                "Julia Schneider",
                "Maximilian Vogel",
                "Roman Teucher",
                "Ken E. Friedl",
                "Soumya Sahoo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09536v1",
                "http://arxiv.org/pdf/2310.09536v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.11466v2",
            "title": "Protein 3D Graph Structure Learning for Robust Structure-based Protein\n  Property Prediction",
            "updated": "2023-10-19T06:21:10Z",
            "published": "2023-10-14T08:43:42Z",
            "summary": "Protein structure-based property prediction has emerged as a promising\napproach for various biological tasks, such as protein function prediction and\nsub-cellular location estimation. The existing methods highly rely on\nexperimental protein structure data and fail in scenarios where these data are\nunavailable. Predicted protein structures from AI tools (e.g., AlphaFold2) were\nutilized as alternatives. However, we observed that current practices, which\nsimply employ accurately predicted structures during inference, suffer from\nnotable degradation in prediction accuracy. While similar phenomena have been\nextensively studied in general fields (e.g., Computer Vision) as model\nrobustness, their impact on protein property prediction remains unexplored. In\nthis paper, we first investigate the reason behind the performance decrease\nwhen utilizing predicted structures, attributing it to the structure embedding\nbias from the perspective of structure representation learning. To study this\nproblem, we identify a Protein 3D Graph Structure Learning Problem for Robust\nProtein Property Prediction (PGSL-RP3), collect benchmark datasets, and present\na protein Structure embedding Alignment Optimization framework (SAO) to\nmitigate the problem of structure embedding bias between the predicted and\nexperimental protein structures. Extensive experiments have shown that our\nframework is model-agnostic and effective in improving the property prediction\nof both predicted structures and experimental structures. The benchmark\ndatasets and codes will be released to benefit the community.",
            "author": [
                "Yufei Huang",
                "Siyuan Li",
                "Jin Su",
                "Lirong Wu",
                "Odin Zhang",
                "Haitao Lin",
                "Jingqi Qi",
                "Zihan Liu",
                "Zhangyang Gao",
                "Yuyang Liu",
                "Jiangbin Zheng",
                "Stan. ZQ. Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.11466v2",
                "http://arxiv.org/pdf/2310.11466v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09533v1",
            "title": "Towards End-to-End Unsupervised Saliency Detection with Self-Supervised\n  Top-Down Context",
            "updated": "2023-10-14T08:43:22Z",
            "published": "2023-10-14T08:43:22Z",
            "summary": "Unsupervised salient object detection aims to detect salient objects without\nusing supervision signals eliminating the tedious task of manually labeling\nsalient objects. To improve training efficiency, end-to-end methods for USOD\nhave been proposed as a promising alternative. However, current solutions rely\nheavily on noisy handcraft labels and fail to mine rich semantic information\nfrom deep features. In this paper, we propose a self-supervised end-to-end\nsalient object detection framework via top-down context. Specifically,\nmotivated by contrastive learning, we exploit the self-localization from the\ndeepest feature to construct the location maps which are then leveraged to\nlearn the most instructive segmentation guidance. Further considering the lack\nof detailed information in deepest features, we exploit the detail-boosting\nrefiner module to enrich the location labels with details. Moreover, we observe\nthat due to lack of supervision, current unsupervised saliency models tend to\ndetect non-salient objects that are salient in some other samples of\ncorresponding scenarios. To address this widespread issue, we design a novel\nUnsupervised Non-Salient Suppression (UNSS) method developing the ability to\nignore non-salient objects. Extensive experiments on benchmark datasets\ndemonstrate that our method achieves leading performance among the recent\nend-to-end methods and most of the multi-stage solutions. The code is\navailable.",
            "author": [
                "Yicheng Song",
                "Shuyong Gao",
                "Haozhe Xing",
                "Yiting Cheng",
                "Yan Wang",
                "Wenqiang Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09533v1",
                "http://arxiv.org/pdf/2310.09533v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09529v1",
            "title": "Docking Peptides into HIV/FIV Protease with Deep Learning and Focused\n  Peptide Docking Methods",
            "updated": "2023-10-14T08:14:54Z",
            "published": "2023-10-14T08:14:54Z",
            "summary": "Molecular docking is a structure-based computational drug design technique\nfor predicting the interaction between a small molecule (ligand) and a\nmacromolecule (receptor). Over the past three decades various docking software\nprograms have been developed, mostly for drug-like molecules. With the recent\ninterest in peptides as therapeutic molecules, several peptide docking methods\nhave also been developed. AutoDock CrankPep (ADCP), is a state-of-the-art\npeptide docking tool that predicts the interaction of peptide with up to 20\namino acids in a user defined region of a macromolecule, i.e.focused docking.\nRecent advances in deep learning (DL) approaches have shown remarkable success\nin docking linear peptides composed of natural amino acids only. Unlike ADCP,\nthese methods provide a confidence level in their predictions. Here we explore\nwhether ADCP and various DL methods (AlphaFold2 Monomer, AlphaFold2 Multimer,\nand OmegaFold) and their prediction confidence metric can be used to\ndiscriminate native and non-native substrates for HIV and FIV proteases. We\nfound that ADCP successfully predicts the interactions of native peptides but\nfails to discriminate non-native ones. This was expected as conventional\ndocking methods report solutions maximizing ligand receptor interactions for\nany ligand. Surprisingly, DL methods underperform when docking native peptides\ninto these particular docking targets but achieve high success rates with\nnon-native peptides. While AlphaFold managed to successfully dock a few of the\nnative peptides, OmegaFold failed to successfully dock any of them. Overall,\nnone of these methods is currently able to distinguish between native and\nnon-native peptides, warranting further exploration of specialized\nmethodologies.",
            "author": [
                "Katherine Ge",
                "Dayna Olson",
                "Michel F. Sanner"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09529v1",
                "http://arxiv.org/pdf/2310.09529v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09528v1",
            "title": "Hypernetwork-based Meta-Learning for Low-Rank Physics-Informed Neural\n  Networks",
            "updated": "2023-10-14T08:13:43Z",
            "published": "2023-10-14T08:13:43Z",
            "summary": "In various engineering and applied science applications, repetitive numerical\nsimulations of partial differential equations (PDEs) for varying input\nparameters are often required (e.g., aircraft shape optimization over many\ndesign parameters) and solvers are required to perform rapid execution. In this\nstudy, we suggest a path that potentially opens up a possibility for\nphysics-informed neural networks (PINNs), emerging deep-learning-based solvers,\nto be considered as one such solver. Although PINNs have pioneered a proper\nintegration of deep-learning and scientific computing, they require repetitive\ntime-consuming training of neural networks, which is not suitable for\nmany-query scenarios. To address this issue, we propose a lightweight low-rank\nPINNs containing only hundreds of model parameters and an associated\nhypernetwork-based meta-learning algorithm, which allows efficient\napproximation of solutions of PDEs for varying ranges of PDE input parameters.\nMoreover, we show that the proposed method is effective in overcoming a\nchallenging issue, known as \"failure modes\" of PINNs.",
            "author": [
                "Woojin Cho",
                "Kookjin Lee",
                "Donsub Rim",
                "Noseong Park"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09528v1",
                "http://arxiv.org/pdf/2310.09528v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NA",
                "math.NA",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10728v1",
            "title": "Improving Feedback from Automated Reviews of Student Spreadsheets",
            "updated": "2023-10-14T08:12:39Z",
            "published": "2023-10-14T08:12:39Z",
            "summary": "Spreadsheets are one of the most widely used tools for end users. As a\nresult, spreadsheets such as Excel are now included in many curricula. However,\ndigital solutions for assessing spreadsheet assignments are still scarce in the\nteaching context. Therefore, we have developed an Intelligent Tutoring System\n(ITS) to review students' Excel submissions and provide individualized feedback\nautomatically. Although the lecturer only needs to provide one reference\nsolution, the students' submissions are analyzed automatically in several ways:\nvalue matching, detailed analysis of the formulas, and quality assessment of\nthe solution. To take the students' learning level into account, we have\ndeveloped feedback levels for an ITS that provide gradually more information\nabout the error by using one of the different analyses. Feedback at a higher\nlevel has been shown to lead to a higher percentage of correct submissions and\nwas also perceived as well understandable and helpful by the students.",
            "author": [
                "S\u00f6ren Aguirre Reid",
                "Frank Kammer",
                "Jonas-Ian Kuche",
                "Pia-Doreen Ritzke",
                "Markus Siepermann",
                "Max Stephan",
                "Armin Wagenknecht"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10728v1",
                "http://arxiv.org/pdf/2311.10728v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "D.2.0"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13006v1",
            "title": "Software Metadata Classification based on Generative Artificial\n  Intelligence",
            "updated": "2023-10-14T07:38:16Z",
            "published": "2023-10-14T07:38:16Z",
            "summary": "This paper presents a novel approach to enhance the performance of binary\ncode comment quality classification models through the application of\nGenerative Artificial Intelligence (AI). By leveraging the OpenAI API, a\ndataset comprising 1239 newly generated code-comment pairs, extracted from\nvarious GitHub repositories and open-source projects, has been labelled as\n\"Useful\" or \"Not Useful\", and integrated into the existing corpus of 9048 pairs\nin the C programming language. Employing a cutting-edge Large Language Model\nArchitecture, the generated dataset demonstrates notable improvements in model\naccuracy. Specifically, when incorporated into the Support Vector Machine (SVM)\nmodel, a 6% increase in precision is observed, rising from 0.79 to 0.85.\nAdditionally, the Artificial Neural Network (ANN) model exhibits a 1.5%\nincrease in recall, climbing from 0.731 to 0.746. This paper sheds light on the\npotential of Generative AI in augmenting code comment quality classification\nmodels. The results affirm the effectiveness of this methodology, indicating\nits applicability in broader contexts within software development and quality\nassurance domains. The findings underscore the significance of integrating\ngenerative techniques to advance the accuracy and efficacy of machine learning\nmodels in practical software engineering scenarios.",
            "author": [
                "Seetharam Killivalavan",
                "Durairaj Thenmozhi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13006v1",
                "http://arxiv.org/pdf/2310.13006v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.AI",
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09518v1",
            "title": "Instruction Tuning with Human Curriculum",
            "updated": "2023-10-14T07:16:08Z",
            "published": "2023-10-14T07:16:08Z",
            "summary": "The dominant paradigm for instruction tuning is the random-shuffled training\nof maximally diverse instruction-response pairs. This paper explores the\npotential benefits of applying a structured cognitive learning approach to\ninstruction tuning in contemporary large language models like ChatGPT and\nGPT-4. Unlike the previous conventional randomized instruction dataset, we\npropose a highly structured synthetic dataset that mimics the progressive and\norganized nature of human education. We curate our dataset by aligning it with\neducational frameworks, incorporating meta information including its topic and\ncognitive rigor level for each sample. Our dataset covers comprehensive\nfine-grained topics spanning diverse educational stages (from middle school to\ngraduate school) with various questions for each topic to enhance conceptual\ndepth using Bloom's taxonomy-a classification framework distinguishing various\nlevels of human cognition for each concept. The results demonstrate that this\ncognitive rigorous training approach yields significant performance\nenhancements - +3.06 on the MMLU benchmark and an additional +1.28 on AI2\nReasoning Challenge (hard set) - compared to conventional randomized training,\nall while avoiding additional computational costs. This research highlights the\npotential of leveraging human learning principles to enhance the capabilities\nof language models in comprehending and responding to complex instructions and\ntasks.",
            "author": [
                "Bruce W. Lee",
                "Hyunsoo Cho",
                "Kang Min Yoo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09518v1",
                "http://arxiv.org/pdf/2310.09518v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09516v1",
            "title": "Efficient Link Prediction via GNN Layers Induced by Negative Sampling",
            "updated": "2023-10-14T07:02:54Z",
            "published": "2023-10-14T07:02:54Z",
            "summary": "Graph neural networks (GNNs) for link prediction can loosely be divided into\ntwo broad categories. First, \\emph{node-wise} architectures pre-compute\nindividual embeddings for each node that are later combined by a simple decoder\nto make predictions. While extremely efficient at inference time (since node\nembeddings are only computed once and repeatedly reused), model expressiveness\nis limited such that isomorphic nodes contributing to candidate edges may not\nbe distinguishable, compromising accuracy. In contrast, \\emph{edge-wise}\nmethods rely on the formation of edge-specific subgraph embeddings to enrich\nthe representation of pair-wise relationships, disambiguating isomorphic nodes\nto improve accuracy, but with the cost of increased model complexity. To better\nnavigate this trade-off, we propose a novel GNN architecture whereby the\n\\emph{forward pass} explicitly depends on \\emph{both} positive (as is typical)\nand negative (unique to our approach) edges to inform more flexible, yet still\ncheap node-wise embeddings. This is achieved by recasting the embeddings\nthemselves as minimizers of a forward-pass-specific energy function (distinct\nfrom the actual training loss) that favors separation of positive and negative\nsamples. As demonstrated by extensive empirical evaluations, the resulting\narchitecture retains the inference speed of node-wise models, while producing\ncompetitive accuracy with edge-wise alternatives.",
            "author": [
                "Yuxin Wang",
                "Xiannian Hu",
                "Quan Gan",
                "Xuanjing Huang",
                "Xipeng Qiu",
                "David Wipf"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09516v1",
                "http://arxiv.org/pdf/2310.09516v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09512v1",
            "title": "Attentive Multi-Layer Perceptron for Non-autoregressive Generation",
            "updated": "2023-10-14T06:44:24Z",
            "published": "2023-10-14T06:44:24Z",
            "summary": "Autoregressive~(AR) generation almost dominates sequence generation for its\nefficacy. Recently, non-autoregressive~(NAR) generation gains increasing\npopularity for its efficiency and growing efficacy. However, its efficiency is\nstill bottlenecked by quadratic complexity in sequence lengths, which is\nprohibitive for scaling to long sequence generation and few works have been\ndone to mitigate this problem. In this paper, we propose a novel MLP variant,\n\\textbf{A}ttentive \\textbf{M}ulti-\\textbf{L}ayer \\textbf{P}erceptron~(AMLP), to\nproduce a generation model with linear time and space complexity. Different\nfrom classic MLP with static and learnable projection matrices, AMLP leverages\nadaptive projections computed from inputs in an attentive mode. The\nsample-aware adaptive projections enable communications among tokens in a\nsequence, and model the measurement between the query and key space.\nFurthermore, we marry AMLP with popular NAR models, deriving a highly efficient\nNAR-AMLP architecture with linear time and space complexity. Empirical results\nshow that such marriage architecture surpasses competitive efficient NAR\nmodels, by a significant margin on text-to-speech synthesis and machine\ntranslation. We also test AMLP's self- and cross-attention ability separately\nwith extensive ablation experiments, and find them comparable or even superior\nto the other efficient models. The efficiency analysis further shows that AMLP\nextremely reduces the memory cost against vanilla non-autoregressive models for\nlong sequences.",
            "author": [
                "Shuyang Jiang",
                "Jun Zhang",
                "Jiangtao Feng",
                "Lin Zheng",
                "Lingpeng Kong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09512v1",
                "http://arxiv.org/pdf/2310.09512v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09511v1",
            "title": "Online Parameter Identification of Generalized Non-cooperative Game",
            "updated": "2023-10-14T06:43:58Z",
            "published": "2023-10-14T06:43:58Z",
            "summary": "This work studies the parameter identification problem of a generalized\nnon-cooperative game, where each player's cost function is influenced by an\nobservable signal and some unknown parameters. We consider the scenario where\nequilibrium of the game at some observable signals can be observed with noises,\nwhereas our goal is to identify the unknown parameters with the observed data.\nAssuming that the observable signals and the corresponding noise-corrupted\nequilibriums are acquired sequentially, we construct this parameter\nidentification problem as online optimization and introduce a novel online\nparameter identification algorithm. To be specific, we construct a regularized\nloss function that balances conservativeness and correctiveness, where the\nconservativeness term ensures that the new estimates do not deviate\nsignificantly from the current estimates, while the correctiveness term is\ncaptured by the Karush-Kuhn-Tucker conditions. We then prove that when the\nplayers' cost functions are linear with respect to the unknown parameters and\nthe learning rate of the online parameter identification algorithm satisfies\n\\mu_k \\propto 1/\\sqrt{k}, along with other assumptions, the regret bound of the\nproposed algorithm is O(\\sqrt{K}). Finally, we conduct numerical simulations on\na Nash-Cournot problem to demonstrate that the performance of the online\nidentification algorithm is comparable to that of the offline setting.",
            "author": [
                "Jianguo Chen",
                "Jinlong Lei",
                "Hongsheng Qi",
                "Yiguang Hong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09511v1",
                "http://arxiv.org/pdf/2310.09511v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09507v1",
            "title": "Foundation Ark: Accruing and Reusing Knowledge for Superior and Robust\n  Performance",
            "updated": "2023-10-14T06:31:44Z",
            "published": "2023-10-14T06:31:44Z",
            "summary": "Deep learning nowadays offers expert-level and sometimes even\nsuper-expert-level performance, but achieving such performance demands massive\nannotated data for training (e.g., Google's proprietary CXR Foundation Model\n(CXR-FM) was trained on 821,544 labeled and mostly private chest X-rays\n(CXRs)). Numerous datasets are publicly available in medical imaging but\nindividually small and heterogeneous in expert labels. We envision a powerful\nand robust foundation model that can be trained by aggregating numerous small\npublic datasets. To realize this vision, we have developed Ark, a framework\nthat accrues and reuses knowledge from heterogeneous expert annotations in\nvarious datasets. As a proof of concept, we have trained two Ark models on\n335,484 and 704,363 CXRs, respectively, by merging several datasets including\nChestX-ray14, CheXpert, MIMIC-II, and VinDr-CXR, evaluated them on a wide range\nof imaging tasks covering both classification and segmentation via fine-tuning,\nlinear-probing, and gender-bias analysis, and demonstrated our Ark's superior\nand robust performance over the SOTA fully/self-supervised baselines and\nGoogle's proprietary CXR-FM. This enhanced performance is attributed to our\nsimple yet powerful observation that aggregating numerous public datasets\ndiversifies patient populations and accrues knowledge from diverse experts,\nyielding unprecedented performance yet saving annotation cost. With all codes\nand pretrained models released at GitHub.com/JLiangLab/Ark, we hope that Ark\nexerts an important impact on open science, as accruing and reusing knowledge\nfrom expert annotations in public datasets can potentially surpass the\nperformance of proprietary models trained on unusually large data, inspiring\nmany more researchers worldwide to share codes and datasets to build open\nfoundation models, accelerate open science, and democratize deep learning for\nmedical imaging.",
            "author": [
                "DongAo Ma",
                "Jiaxuan Pang",
                "Michael B. Gotway",
                "Jianming Liang"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-031-43907-0_62",
                "http://arxiv.org/abs/2310.09507v1",
                "http://arxiv.org/pdf/2310.09507v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09506v1",
            "title": "Towards Semantic Communication Protocols for 6G: From Protocol Learning\n  to Language-Oriented Approaches",
            "updated": "2023-10-14T06:28:50Z",
            "published": "2023-10-14T06:28:50Z",
            "summary": "The forthcoming 6G systems are expected to address a wide range of\nnon-stationary tasks. This poses challenges to traditional medium access\ncontrol (MAC) protocols that are static and predefined. In response,\ndata-driven MAC protocols have recently emerged, offering ability to tailor\ntheir signaling messages for specific tasks. This article presents a novel\ncategorization of these data-driven MAC protocols into three levels: Level 1\nMAC. task-oriented neural protocols constructed using multi-agent deep\nreinforcement learning (MADRL); Level 2 MAC. neural network-oriented symbolic\nprotocols developed by converting Level 1 MAC outputs into explicit symbols;\nand Level 3 MAC. language-oriented semantic protocols harnessing large language\nmodels (LLMs) and generative models. With this categorization, we aim to\nexplore the opportunities and challenges of each level by delving into their\nfoundational techniques. Drawing from information theory and associated\nprinciples as well as selected case studies, this study provides insights into\nthe trajectory of data-driven MAC protocols and sheds light on future research\ndirections.",
            "author": [
                "Jihong Park",
                "Seung-Woo Ko",
                "Jinho Choi",
                "Seong-Lyun Kim",
                "Mehdi Bennis"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09506v1",
                "http://arxiv.org/pdf/2310.09506v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.AI",
                "cs.LG",
                "cs.NI",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09505v1",
            "title": "Advancing Test-Time Adaptation for Acoustic Foundation Models in\n  Open-World Shifts",
            "updated": "2023-10-14T06:22:08Z",
            "published": "2023-10-14T06:22:08Z",
            "summary": "Test-Time Adaptation (TTA) is a critical paradigm for tackling distribution\nshifts during inference, especially in visual recognition tasks. However, while\nacoustic models face similar challenges due to distribution shifts in test-time\nspeech, TTA techniques specifically designed for acoustic modeling in the\ncontext of open-world data shifts remain scarce. This gap is further\nexacerbated when considering the unique characteristics of acoustic foundation\nmodels: 1) they are primarily built on transformer architectures with layer\nnormalization and 2) they deal with test-time speech data of varying lengths in\na non-stationary manner. These aspects make the direct application of\nvision-focused TTA methods, which are mostly reliant on batch normalization and\nassume independent samples, infeasible. In this paper, we delve into TTA for\npre-trained acoustic models facing open-world data shifts. We find that noisy,\nhigh-entropy speech frames, often non-silent, carry key semantic content.\nTraditional TTA methods might inadvertently filter out this information using\npotentially flawed heuristics. In response, we introduce a heuristic-free,\nlearning-based adaptation enriched by confidence enhancement. Noting that\nspeech signals' short-term consistency, we also apply consistency\nregularization during test-time optimization. Our experiments on synthetic and\nreal-world datasets affirm our method's superiority over existing baselines.",
            "author": [
                "Hongfu Liu",
                "Hengguan Huang",
                "Ye Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09505v1",
                "http://arxiv.org/pdf/2310.09505v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09503v2",
            "title": "JM3D & JM3D-LLM: Elevating 3D Representation with Joint Multi-modal Cues",
            "updated": "2023-10-20T07:05:27Z",
            "published": "2023-10-14T06:13:20Z",
            "summary": "The rising importance of 3D representation learning, pivotal in computer\nvision, autonomous driving, and robotics, is evident. However, a prevailing\ntrend, which straightforwardly resorted to transferring 2D alignment strategies\nto the 3D domain, encounters three distinct challenges: (1) Information\nDegradation: This arises from the alignment of 3D data with mere single-view 2D\nimages and generic texts, neglecting the need for multi-view images and\ndetailed subcategory texts. (2) Insufficient Synergy: These strategies align 3D\nrepresentations to image and text features individually, hampering the overall\noptimization for 3D models. (3) Underutilization: The fine-grained information\ninherent in the learned representations is often not fully exploited,\nindicating a potential loss in detail. To address these issues, we introduce\nJM3D, a comprehensive approach integrating point cloud, text, and image. Key\ncontributions include the Structured Multimodal Organizer (SMO), enriching\nvision-language representation with multiple views and hierarchical text, and\nthe Joint Multi-modal Alignment (JMA), combining language understanding with\nvisual representation. Our advanced model, JM3D-LLM, marries 3D representation\nwith large language models via efficient fine-tuning. Evaluations on ModelNet40\nand ScanObjectNN establish JM3D's superiority. The superior performance of\nJM3D-LLM further underscores the effectiveness of our representation transfer\napproach. Our code and models are available at https://github.com/Mr-Neko/JM3D.",
            "author": [
                "Jiayi Ji",
                "Haowei Wang",
                "Changli Wu",
                "Yiwei Ma",
                "Xiaoshuai Sun",
                "Rongrong Ji"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09503v2",
                "http://arxiv.org/pdf/2310.09503v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09502v1",
            "title": "Deep Nonlinear Adaptive Control for Unmanned Aerial Systems Operating\n  under Dynamic Uncertainties",
            "updated": "2023-10-14T06:12:13Z",
            "published": "2023-10-14T06:12:13Z",
            "summary": "Recent literature in the field of machine learning (ML) control has shown\npromising theoretical results for a Deep Neural Network (DNN) based Nonlinear\nAdaptive Controller (DNAC) capable of achieving trajectory tracking for\nnonlinear systems. Expanding on this work, this paper applies DNAC to the\nAttitude Control System (ACS) of a quadrotor and shows improvement to attitude\ncontrol performance under disturbed flying conditions where the model\nuncertainty is high. Moreover, these results are noteworthy for ML control\nbecause they were achieved with no prior training data and an arbitrary system\ndynamics initialization; simply put, the controller presented in this paper is\npractically modelless, yet yields the ability to force trajectory tracking for\nnonlinear systems while rejecting significant undesirable model disturbances\nlearned through a DNN. The combination of ML techniques to learn a system's\ndynamics and the Lyapunov analysis required to provide stability guarantees\nleads to a controller with applications in safety-critical systems that may\nundergo uncertain model changes, as is the case for most aerial systems.\nExperimental findings are analyzed in the final section of this paper, and DNAC\nis shown to outperform the trajectory tracking capabilities of PID, MRAC, and\nthe recently developed Deep Model Reference Adaptive Control (DMRAC) schemes.",
            "author": [
                "Zachary Lamb",
                "Zachary I. Bell",
                "Matthew Longmire",
                "Jared Paquet",
                "Prashant Ganesh",
                "Ricardo Sanfelice"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09502v1",
                "http://arxiv.org/pdf/2310.09502v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09495v1",
            "title": "Learning In-between Imagery Dynamics via Physical Latent Spaces",
            "updated": "2023-10-14T05:14:51Z",
            "published": "2023-10-14T05:14:51Z",
            "summary": "We present a framework designed to learn the underlying dynamics between two\nimages observed at consecutive time steps. The complex nature of image data and\nthe lack of temporal information pose significant challenges in capturing the\nunique evolving patterns. Our proposed method focuses on estimating the\nintermediary stages of image evolution, allowing for interpretability through\nlatent dynamics while preserving spatial correlations with the image. By\nincorporating a latent variable that follows a physical model expressed in\npartial differential equations (PDEs), our approach ensures the\ninterpretability of the learned model and provides insight into corresponding\nimage dynamics. We demonstrate the robustness and effectiveness of our learning\nframework through a series of numerical tests using geoscientific imagery data.",
            "author": [
                "Jihun Han",
                "Yoonsang Lee",
                "Anne Gelb"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09495v1",
                "http://arxiv.org/pdf/2310.09495v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "stat.ML",
                "37M05, 62F99, 68T45"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09494v1",
            "title": "Computational analyses of linguistic features with schizophrenic and\n  autistic traits along with formal thought disorders",
            "updated": "2023-10-14T05:05:11Z",
            "published": "2023-10-14T05:05:11Z",
            "summary": "[See full abstract in the pdf] Formal Thought Disorder (FTD), which is a\ngroup of symptoms in cognition that affects language and thought, can be\nobserved through language. FTD is seen across such developmental or psychiatric\ndisorders as Autism Spectrum Disorder (ASD) or Schizophrenia, and its related\nSchizotypal Personality Disorder (SPD). This paper collected a Japanese\naudio-report dataset with score labels related to ASD and SPD through a\ncrowd-sourcing service from the general population. We measured language\ncharacteristics with the 2nd edition of the Social Responsiveness Scale (SRS2)\nand the Schizotypal Personality Questionnaire (SPQ), including an odd speech\nsubscale from SPQ to quantify the FTD symptoms. We investigated the following\nfour research questions through machine-learning-based score predictions: (RQ1)\nHow are schizotypal and autistic measures correlated? (RQ2) What is the most\nsuitable task to elicit FTD symptoms? (RQ3) Does the length of speech affect\nthe elicitation of FTD symptoms? (RQ4) Which features are critical for\ncapturing FTD symptoms? We confirmed that an FTD-related subscale, odd speech,\nwas significantly correlated with both the total SPQ and SRS scores, although\nthey themselves were not correlated significantly. Our regression analysis\nindicated that longer speech about a negative memory elicited more FTD\nsymptoms. The ablation study confirmed the importance of function words and\nboth the abstract and temporal features for FTD-related odd speech estimation.\nIn contrast, content words were effective only in the SRS predictions, and\ncontent words were effective only in the SPQ predictions, a result that implies\nthe differences between SPD-like and ASD-like symptoms. Data and programs used\nin this paper can be found here:\nhttps://sites.google.com/view/sagatake/resource.",
            "author": [
                "Takeshi Saga",
                "Hiroki Tanaka",
                "Satoshi Nakamura"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3577190.3614132",
                "http://arxiv.org/abs/2310.09494v1",
                "http://arxiv.org/pdf/2310.09494v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "J.4; J.3; I.2.1; I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09492v1",
            "title": "Perception Reinforcement Using Auxiliary Learning Feature Fusion: A\n  Modified Yolov8 for Head Detection",
            "updated": "2023-10-14T04:52:35Z",
            "published": "2023-10-14T04:52:35Z",
            "summary": "Head detection provides distribution information of pedestrian, which is\ncrucial for scene statistical analysis, traffic management, and risk assessment\nand early warning. However, scene complexity and large-scale variation in the\nreal world make accurate detection more difficult. Therefore, we present a\nmodified Yolov8 which improves head detection performance through reinforcing\ntarget perception. An Auxiliary Learning Feature Fusion (ALFF) module comprised\nof LSTM and convolutional blocks is used as the auxiliary task to help the\nmodel perceive targets. In addition, we introduce Noise Calibration into\nDistribution Focal Loss to facilitate model fitting and improve the accuracy of\ndetection. Considering the requirements of high accuracy and speed for the head\ndetection task, our method is adapted with two kinds of backbone, namely\nYolov8n and Yolov8m. The results demonstrate the superior performance of our\napproach in improving detection accuracy and robustness.",
            "author": [
                "Jiezhou Chen",
                "Guankun Wang",
                "Weixiang Liu",
                "Xiaopin Zhong",
                "Yibin Tian",
                "ZongZe Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09492v1",
                "http://arxiv.org/pdf/2310.09492v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09488v1",
            "title": "ARM: Refining Multivariate Forecasting with Adaptive Temporal-Contextual\n  Learning",
            "updated": "2023-10-14T04:37:38Z",
            "published": "2023-10-14T04:37:38Z",
            "summary": "Long-term time series forecasting (LTSF) is important for various domains but\nis confronted by challenges in handling the complex temporal-contextual\nrelationships. As multivariate input models underperforming some recent\nunivariate counterparts, we posit that the issue lies in the inefficiency of\nexisting multivariate LTSF Transformers to model series-wise relationships: the\ncharacteristic differences between series are often captured incorrectly. To\naddress this, we introduce ARM: a multivariate temporal-contextual adaptive\nlearning method, which is an enhanced architecture specifically designed for\nmultivariate LTSF modelling. ARM employs Adaptive Univariate Effect Learning\n(AUEL), Random Dropping (RD) training strategy, and Multi-kernel Local\nSmoothing (MKLS), to better handle individual series temporal patterns and\ncorrectly learn inter-series dependencies. ARM demonstrates superior\nperformance on multiple benchmarks without significantly increasing\ncomputational costs compared to vanilla Transformer, thereby advancing the\nstate-of-the-art in LTSF. ARM is also generally applicable to other LTSF\narchitecture beyond vanilla Transformer.",
            "author": [
                "Jiecheng Lu",
                "Xu Han",
                "Shihao Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09488v1",
                "http://arxiv.org/pdf/2310.09488v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09486v2",
            "title": "Mirage: Model-Agnostic Graph Distillation for Graph Classification",
            "updated": "2023-10-17T07:55:22Z",
            "published": "2023-10-14T04:21:52Z",
            "summary": "GNNs, like other deep learning models, are data and computation hungry. There\nis a pressing need to scale training of GNNs on large datasets to enable their\nusage on low-resource environments. Graph distillation is an effort in that\ndirection with the aim to construct a smaller synthetic training set from the\noriginal training data without significantly compromising model performance.\nWhile initial efforts are promising, this work is motivated by two key\nobservations: (1) Existing graph distillation algorithms themselves rely on\ntraining with the full dataset, which undermines the very premise of graph\ndistillation. (2) The distillation process is specific to the target GNN\narchitecture and hyper-parameters and thus not robust to changes in the\nmodeling pipeline. We circumvent these limitations by designing a distillation\nalgorithm called Mirage for graph classification. Mirage is built on the\ninsight that a message-passing GNN decomposes the input graph into a multiset\nof computation trees. Furthermore, the frequency distribution of computation\ntrees is often skewed in nature, enabling us to condense this data into a\nconcise distilled summary. By compressing the computation data itself, as\nopposed to emulating gradient flows on the original training set-a prevalent\napproach to date-Mirage transforms into an unsupervised and\narchitecture-agnostic distillation algorithm. Extensive benchmarking on\nreal-world datasets underscores Mirage's superiority, showcasing enhanced\ngeneralization accuracy, data compression, and distillation efficiency when\ncompared to state-of-the-art baselines.",
            "author": [
                "Mridul Gupta",
                "Sahil Manchanda",
                "Hariprasad Kodamana",
                "Sayan Ranu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09486v2",
                "http://arxiv.org/pdf/2310.09486v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09485v3",
            "title": "Applying Bayesian Ridge Regression AI Modeling in Virus Severity\n  Prediction",
            "updated": "2023-12-04T21:11:45Z",
            "published": "2023-10-14T04:17:00Z",
            "summary": "Artificial intelligence (AI) is a powerful tool for reshaping healthcare\nsystems. In healthcare, AI is invaluable for its capacity to manage vast\namounts of data, which can lead to more accurate and speedy diagnoses,\nultimately easing the workload on healthcare professionals. As a result, AI has\nproven itself to be a power tool across various industries, simplifying complex\ntasks and pattern recognition that would otherwise be overwhelming for humans\nor traditional computer algorithms. In this paper, we review the strengths and\nweaknesses of Bayesian Ridge Regression, an AI model that can be used to bring\ncutting edge virus analysis to healthcare professionals around the world. The\nmodel's accuracy assessment revealed promising results, with room for\nimprovement primarily related to data organization. In addition, the severity\nindex serves as a valuable tool to gain a broad overview of patient care needs,\naligning with healthcare professionals' preference for broader categorizations.",
            "author": [
                "Jai Pal",
                "Bryan Hong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09485v3",
                "http://arxiv.org/pdf/2310.09485v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09484v1",
            "title": "Exploring the Design Space of Diffusion Autoencoders for Face Morphing",
            "updated": "2023-10-14T04:11:01Z",
            "published": "2023-10-14T04:11:01Z",
            "summary": "Face morphs created by Diffusion Autoencoders are a recent innovation and the\ndesign space of such an approach has not been well explored. We explore three\naxes of the design space, i.e., 1) sampling algorithms, 2) the reverse DDIM\nsolver, and 3) partial sampling through small amounts of added noise.",
            "author": [
                "Zander Blasingame",
                "Chen Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09484v1",
                "http://arxiv.org/pdf/2310.09484v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09482v1",
            "title": "Answering open questions in biology using spatial genomics and\n  structured methods",
            "updated": "2023-10-14T04:03:56Z",
            "published": "2023-10-14T04:03:56Z",
            "summary": "Genomics methods have uncovered patterns in a range of biological systems,\nbut obscure important aspects of cell behavior: the shape, relative locations\nof, movement of, and interactions between cells in space. Spatial technologies\nthat collect genomic or epigenomic data while preserving spatial information\nhave begun to overcome these limitations. These new data promise a deeper\nunderstanding of the factors that affect cellular behavior, and in particular\nthe ability to directly test existing theories about cell state and variation\nin the context of morphology, location, motility, and signaling that could not\nbe tested before. Rapid advancements in resolution, ease-of-use, and scale of\nspatial genomics technologies to address these questions also require an\nupdated toolkit of statistical methods with which to interrogate these data. We\npresent four open biological questions that can now be answered using spatial\ngenomics data paired with methods for analysis. We outline spatial data\nmodalities for each that may yield specific insight, discuss how conflicting\ntheories may be tested by comparing the data to conceptual models of biological\nbehavior, and highlight statistical and machine learning-based tools that may\nprove particularly helpful to recover biological insight.",
            "author": [
                "Siddhartha G Jena",
                "Archit Verma",
                "Barbara E Engelhardt"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09482v1",
                "http://arxiv.org/pdf/2310.09482v1"
            ],
            "primary_category": "stat.AP",
            "category": [
                "stat.AP",
                "q-bio.CB",
                "q-bio.TO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00009v1",
            "title": "Risk-Aware and Explainable Framework for Ensuring Guaranteed Coverage in\n  Evolving Hardware Trojan Detection",
            "updated": "2023-10-14T03:30:21Z",
            "published": "2023-10-14T03:30:21Z",
            "summary": "As the semiconductor industry has shifted to a fabless paradigm, the risk of\nhardware Trojans being inserted at various stages of production has also\nincreased. Recently, there has been a growing trend toward the use of machine\nlearning solutions to detect hardware Trojans more effectively, with a focus on\nthe accuracy of the model as an evaluation metric. However, in a high-risk and\nsensitive domain, we cannot accept even a small misclassification.\nAdditionally, it is unrealistic to expect an ideal model, especially when\nTrojans evolve over time. Therefore, we need metrics to assess the\ntrustworthiness of detected Trojans and a mechanism to simulate unseen ones. In\nthis paper, we generate evolving hardware Trojans using our proposed novel\nconformalized generative adversarial networks and offer an efficient approach\nto detecting them based on a non-invasive algorithm-agnostic statistical\ninference framework that leverages the Mondrian conformal predictor. The method\nacts like a wrapper over any of the machine learning models and produces set\npredictions along with uncertainty quantification for each new detected Trojan\nfor more robust decision-making. In the case of a NULL set, a novel method to\nreject the decision by providing a calibrated explainability is discussed. The\nproposed approach has been validated on both synthetic and real chip-level\nbenchmarks and proven to pave the way for researchers looking to find informed\nmachine learning solutions to hardware security problems.",
            "author": [
                "Rahul Vishwakarma",
                "Amin Rezaei"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00009v1",
                "http://arxiv.org/pdf/2312.00009v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09479v1",
            "title": "Unified High-binding Watermark for Unconditional Image Generation Models",
            "updated": "2023-10-14T03:26:21Z",
            "published": "2023-10-14T03:26:21Z",
            "summary": "Deep learning techniques have implemented many unconditional image generation\n(UIG) models, such as GAN, Diffusion model, etc. The extremely realistic images\n(also known as AI-Generated Content, AIGC for short) produced by these models\nbring urgent needs for intellectual property protection such as data\ntraceability and copyright certification. An attacker can steal the output\nimages of the target model and use them as part of the training data to train a\nprivate surrogate UIG model. The implementation mechanisms of UIG models are\ndiverse and complex, and there is no unified and effective protection and\nverification method at present. To address these issues, we propose a two-stage\nunified watermark verification mechanism with high-binding effects for such\nmodels. In the first stage, we use an encoder to invisibly write the watermark\nimage into the output images of the original AIGC tool, and reversely extract\nthe watermark image through the corresponding decoder. In the second stage, we\ndesign the decoder fine-tuning process, and the fine-tuned decoder can make\ncorrect judgments on whether the suspicious model steals the original AIGC tool\ndata. Experiments demonstrate our method can complete the verification work\nwith almost zero false positive rate under the condition of only using the\nmodel output images. Moreover, the proposed method can achieve data steal\nverification across different types of UIG models, which further increases the\npracticality of the method.",
            "author": [
                "Ruinan Ma",
                "Yu-an Tan",
                "Shangbo Wu",
                "Tian Chen",
                "Yajie Wang",
                "Yuanzhang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09479v1",
                "http://arxiv.org/pdf/2310.09479v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09478v3",
            "title": "MiniGPT-v2: large language model as a unified interface for\n  vision-language multi-task learning",
            "updated": "2023-11-07T18:25:48Z",
            "published": "2023-10-14T03:22:07Z",
            "summary": "Large language models have shown their remarkable capabilities as a general\ninterface for various language-related applications. Motivated by this, we\ntarget to build a unified interface for completing many vision-language tasks\nincluding image description, visual question answering, and visual grounding,\namong others. The challenge is to use a single model for performing diverse\nvision-language tasks effectively with simple multi-modal instructions. Towards\nthis objective, we introduce MiniGPT-v2, a model that can be treated as a\nunified interface for better handling various vision-language tasks. We propose\nusing unique identifiers for different tasks when training the model. These\nidentifiers enable our model to better distinguish each task instruction\neffortlessly and also improve the model learning efficiency for each task.\nAfter the three-stage training, the experimental results show that MiniGPT-v2\nachieves strong performance on many visual question-answering and visual\ngrounding benchmarks compared to other vision-language generalist models. Our\nmodel and codes are available at https://minigpt-v2.github.io/",
            "author": [
                "Jun Chen",
                "Deyao Zhu",
                "Xiaoqian Shen",
                "Xiang Li",
                "Zechun Liu",
                "Pengchuan Zhang",
                "Raghuraman Krishnamoorthi",
                "Vikas Chandra",
                "Yunyang Xiong",
                "Mohamed Elhoseiny"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09478v3",
                "http://arxiv.org/pdf/2310.09478v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09473v1",
            "title": "Can CNNs Accurately Classify Human Emotions? A Deep-Learning Facial\n  Expression Recognition Study",
            "updated": "2023-10-14T02:44:44Z",
            "published": "2023-10-14T02:44:44Z",
            "summary": "Emotional Artificial Intelligences are currently one of the most anticipated\ndevelopments of AI. If successful, these AIs will be classified as one of the\nmost complex, intelligent nonhuman entities as they will possess sentience, the\nprimary factor that distinguishes living humans and mechanical machines. For\nAIs to be classified as \"emotional,\" they should be able to empathize with\nothers and classify their emotions because without such abilities they cannot\nnormally interact with humans. This study investigates the CNN model's ability\nto recognize and classify human facial expressions (positive, neutral,\nnegative). The CNN model made for this study is programmed in Python and\ntrained with preprocessed data from the Chicago Face Database. The model is\nintentionally designed with less complexity to further investigate its ability.\nWe hypothesized that the model will perform better than chance (33.3%) in\nclassifying each emotion class of input data. The model accuracy was tested\nwith novel images. Accuracy was summarized in a percentage report, comparative\nplot, and confusion matrix. Results of this study supported the hypothesis as\nthe model had 75% accuracy over 10,000 images (data), highlighting the\npossibility of AIs that accurately analyze human emotions and the prospect of\nviable Emotional AIs.",
            "author": [
                "Ashley Jisue Hong",
                "David DiStefano",
                "Sejal Dua"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09473v1",
                "http://arxiv.org/pdf/2310.09473v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NE",
                "I.2.6; I.4.m"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09471v1",
            "title": "Plug-and-Play Feature Generation for Few-Shot Medical Image\n  Classification",
            "updated": "2023-10-14T02:36:14Z",
            "published": "2023-10-14T02:36:14Z",
            "summary": "Few-shot learning (FSL) presents immense potential in enhancing model\ngeneralization and practicality for medical image classification with limited\ntraining data; however, it still faces the challenge of severe overfitting in\nclassifier training due to distribution bias caused by the scarce training\nsamples. To address the issue, we propose MedMFG, a flexible and lightweight\nplug-and-play method designed to generate sufficient class-distinctive features\nfrom limited samples. Specifically, MedMFG first re-represents the limited\nprototypes to assign higher weights for more important information features.\nThen, the prototypes are variationally generated into abundant effective\nfeatures. Finally, the generated features and prototypes are together to train\na more generalized classifier. Experiments demonstrate that MedMFG outperforms\nthe previous state-of-the-art methods on cross-domain benchmarks involving the\ntransition from natural images to medical images, as well as medical images\nwith different lesions. Notably, our method achieves over 10% performance\nimprovement compared to several baselines. Fusion experiments further validate\nthe adaptability of MedMFG, as it seamlessly integrates into various backbones\nand baselines, consistently yielding improvements of over 2.9% across all\nresults.",
            "author": [
                "Qianyu Guo",
                "Huifang Du",
                "Xing Jia",
                "Shuyong Gao",
                "Yan Teng",
                "Haofen Wang",
                "Wenqiang Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09471v1",
                "http://arxiv.org/pdf/2310.09471v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09468v1",
            "title": "Randomized Benchmarking of Local Zeroth-Order Optimizers for Variational\n  Quantum Systems",
            "updated": "2023-10-14T02:13:26Z",
            "published": "2023-10-14T02:13:26Z",
            "summary": "In the field of quantum information, classical optimizers play an important\nrole. From experimentalists optimizing their physical devices to theorists\nexploring variational quantum algorithms, many aspects of quantum information\nrequire the use of a classical optimizer. For this reason, there are many\npapers that benchmark the effectiveness of different optimizers for specific\nquantum optimization tasks and choices of parameterized algorithms. However,\nfor researchers exploring new algorithms or physical devices, the insights from\nthese studies don't necessarily translate. To address this concern, we compare\nthe performance of classical optimizers across a series of partially-randomized\ntasks to more broadly sample the space of quantum optimization problems. We\nfocus on local zeroth-order optimizers due to their generally favorable\nperformance and query-efficiency on quantum systems. We discuss insights from\nthese experiments that can help motivate future works to improve these\noptimizers for use on quantum systems.",
            "author": [
                "Lucas Tecot",
                "Cho-Jui Hsieh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09468v1",
                "http://arxiv.org/pdf/2310.09468v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09462v1",
            "title": "A Framework for Empowering Reinforcement Learning Agents with Causal\n  Analysis: Enhancing Automated Cryptocurrency Trading",
            "updated": "2023-10-14T01:08:52Z",
            "published": "2023-10-14T01:08:52Z",
            "summary": "Despite advances in artificial intelligence-enhanced trading methods,\ndeveloping a profitable automated trading system remains challenging in the\nrapidly evolving cryptocurrency market. This study aims to address these\nchallenges by developing a reinforcement learning-based automated trading\nsystem for five popular altcoins~(cryptocurrencies other than Bitcoin): Binance\nCoin, Ethereum, Litecoin, Ripple, and Tether. To this end, we present\nCausalReinforceNet, a framework framed as a decision support system. Designed\nas the foundational architecture of the trading system, the CausalReinforceNet\nframework enhances the capabilities of the reinforcement learning agent through\ncausal analysis. Within this framework, we use Bayesian networks in the feature\nengineering process to identify the most relevant features with causal\nrelationships that influence cryptocurrency price movements. Additionally, we\nincorporate probabilistic price direction signals from dynamic Bayesian\nnetworks to enhance our reinforcement learning agent's decision-making. Due to\nthe high volatility of the cryptocurrency market, we design our framework to\nadopt a conservative approach that limits sell and buy position sizes to manage\nrisk. We develop two agents using the CausalReinforceNet framework, each based\non distinct reinforcement learning algorithms. The results indicate that our\nframework substantially surpasses the Buy-and-Hold benchmark strategy in\nprofitability. Additionally, both agents generated notable returns on\ninvestment for Binance Coin and Ethereum.",
            "author": [
                "Rasoul Amirzadeh",
                "Dhananjay Thiruvady",
                "Asef Nazari",
                "Mong Shan Ee"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09462v1",
                "http://arxiv.org/pdf/2310.09462v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.10683v1",
            "title": "Large Language Model Unlearning",
            "updated": "2023-10-14T00:32:55Z",
            "published": "2023-10-14T00:32:55Z",
            "summary": "We study how to perform unlearning, i.e. forgetting undesirable\n(mis)behaviors, on large language models (LLMs). We show at least three\nscenarios of aligning LLMs with human preferences can benefit from unlearning:\n(1) removing harmful responses, (2) erasing copyright-protected content as\nrequested, and (3) eliminating hallucinations. Unlearning, as an alignment\ntechnique, has three advantages. (1) It only requires negative (e.g. harmful)\nexamples, which are much easier and cheaper to collect (e.g. via red teaming or\nuser reporting) than positive (e.g. helpful and often human-written) examples\nrequired in RLHF (RL from human feedback). (2) It is computationally efficient.\n(3) It is especially effective when we know which training samples cause the\nmisbehavior. To the best of our knowledge, our work is among the first to\nexplore LLM unlearning. We are also among the first to formulate the settings,\ngoals, and evaluations in LLM unlearning. We show that if practitioners only\nhave limited resources, and therefore the priority is to stop generating\nundesirable outputs rather than to try to generate desirable outputs,\nunlearning is particularly appealing. Despite only having negative samples, our\nablation study shows that unlearning can still achieve better alignment\nperformance than RLHF with just 2% of its computational time.",
            "author": [
                "Yuanshun Yao",
                "Xiaojun Xu",
                "Yang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.10683v1",
                "http://arxiv.org/pdf/2310.10683v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09457v1",
            "title": "UCM-Net: A Lightweight and Efficient Solution for Skin Lesion\n  Segmentation using MLP and CNN",
            "updated": "2023-10-14T00:32:11Z",
            "published": "2023-10-14T00:32:11Z",
            "summary": "Skin cancer is a significant public health problem, and computer-aided\ndiagnosis can help to prevent and treat it. A crucial step for computer-aided\ndiagnosis is accurately segmenting skin lesions in images, which allows for\nlesion detection, classification, and analysis. However, this task is\nchallenging due to the diverse characteristics of lesions, such as appearance,\nshape, size, color, texture, and location, as well as image quality issues like\nnoise, artifacts, and occlusions. Deep learning models have recently been\napplied to skin lesion segmentation, but they have high parameter counts and\ncomputational demands, making them unsuitable for mobile health applications.\nTo address this challenge, we propose UCM-Net, a novel, efficient, and\nlightweight solution that integrates Multi-Layer Perceptions (MLP) and\nConvolutional Neural Networks (CNN). Unlike conventional UNet architectures,\nour UCMNet-Block reduces parameter overhead and enhances UCM-Net's learning\ncapabilities, leading to robust segmentation performance. We validate UCM-Net's\ncompetitiveness through extensive experiments on isic2017 and isic2018\ndatasets. Remarkably, UCM-Net has less than 50KB parameters and less than 0.05\nGiga-Operations Per Second (GLOPs), setting a new possible standard for\nefficiency in skin lesion segmentation. The source code will be publicly\navailable.",
            "author": [
                "Chunyu Yuan",
                "Dongfang Zhao",
                "Sos S. Agaian"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09457v1",
                "http://arxiv.org/pdf/2310.09457v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09454v1",
            "title": "LgTS: Dynamic Task Sampling using LLM-generated sub-goals for\n  Reinforcement Learning Agents",
            "updated": "2023-10-14T00:07:03Z",
            "published": "2023-10-14T00:07:03Z",
            "summary": "Recent advancements in reasoning abilities of Large Language Models (LLM) has\npromoted their usage in problems that require high-level planning for robots\nand artificial agents. However, current techniques that utilize LLMs for such\nplanning tasks make certain key assumptions such as, access to datasets that\npermit finetuning, meticulously engineered prompts that only provide relevant\nand essential information to the LLM, and most importantly, a deterministic\napproach to allow execution of the LLM responses either in the form of existing\npolicies or plan operators. In this work, we propose LgTS (LLM-guided\nTeacher-Student learning), a novel approach that explores the planning\nabilities of LLMs to provide a graphical representation of the sub-goals to a\nreinforcement learning (RL) agent that does not have access to the transition\ndynamics of the environment. The RL agent uses Teacher-Student learning\nalgorithm to learn a set of successful policies for reaching the goal state\nfrom the start state while simultaneously minimizing the number of\nenvironmental interactions. Unlike previous methods that utilize LLMs, our\napproach does not assume access to a propreitary or a fine-tuned LLM, nor does\nit require pre-trained policies that achieve the sub-goals proposed by the LLM.\nThrough experiments on a gridworld based DoorKey domain and a search-and-rescue\ninspired domain, we show that generating a graphical structure of sub-goals\nhelps in learning policies for the LLM proposed sub-goals and the\nTeacher-Student learning algorithm minimizes the number of environment\ninteractions when the transition dynamics are unknown.",
            "author": [
                "Yash Shukla",
                "Wenchang Gao",
                "Vasanth Sarathy",
                "Alvaro Velasquez",
                "Robert Wright",
                "Jivko Sinapov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09454v1",
                "http://arxiv.org/pdf/2310.09454v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09449v1",
            "title": "Pairwise Similarity Learning is SimPLE",
            "updated": "2023-10-13T23:56:47Z",
            "published": "2023-10-13T23:56:47Z",
            "summary": "In this paper, we focus on a general yet important learning problem, pairwise\nsimilarity learning (PSL). PSL subsumes a wide range of important applications,\nsuch as open-set face recognition, speaker verification, image retrieval and\nperson re-identification. The goal of PSL is to learn a pairwise similarity\nfunction assigning a higher similarity score to positive pairs (i.e., a pair of\nsamples with the same label) than to negative pairs (i.e., a pair of samples\nwith different label). We start by identifying a key desideratum for PSL, and\nthen discuss how existing methods can achieve this desideratum. We then propose\na surprisingly simple proxy-free method, called SimPLE, which requires neither\nfeature/proxy normalization nor angular margin and yet is able to generalize\nwell in open-set recognition. We apply the proposed method to three challenging\nPSL tasks: open-set face recognition, image retrieval and speaker verification.\nComprehensive experimental results on large-scale benchmarks show that our\nmethod performs significantly better than current state-of-the-art methods.",
            "author": [
                "Yandong Wen",
                "Weiyang Liu",
                "Yao Feng",
                "Bhiksha Raj",
                "Rita Singh",
                "Adrian Weller",
                "Michael J. Black",
                "Bernhard Sch\u00f6lkopf"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09449v1",
                "http://arxiv.org/pdf/2310.09449v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09446v1",
            "title": "Automatic segmentation of lung findings in CT and application to Long\n  COVID",
            "updated": "2023-10-13T23:42:43Z",
            "published": "2023-10-13T23:42:43Z",
            "summary": "Automated segmentation of lung abnormalities in computed tomography is an\nimportant step for diagnosing and characterizing lung disease. In this work, we\nimprove upon a previous method and propose S-MEDSeg, a deep learning based\napproach for accurate segmentation of lung lesions in chest CT images. S-MEDSeg\ncombines a pre-trained EfficientNet backbone, bidirectional feature pyramid\nnetwork, and modern network advancements to achieve improved segmentation\nperformance. A comprehensive ablation study was performed to evaluate the\ncontribution of the proposed network modifications. The results demonstrate\nmodifications introduced in S-MEDSeg significantly improves segmentation\nperformance compared to the baseline approach. The proposed method is applied\nto an independent dataset of long COVID inpatients to study the effect of\npost-acute infection vaccination on extent of lung findings. Open-source code,\ngraphical user interface and pip package are available at\nhttps://github.com/MICLab-Unicamp/medseg.",
            "author": [
                "Diedre S. Carmo",
                "Rosarie A. Tudas",
                "Alejandro P. Comellas",
                "Leticia Rittner",
                "Roberto A. Lotufo",
                "Joseph M. Reinhardt",
                "Sarah E. Gerard"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09446v1",
                "http://arxiv.org/pdf/2310.09446v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09444v2",
            "title": "Tackling Heterogeneity in Medical Federated learning via Vision\n  Transformers",
            "updated": "2023-11-15T21:46:50Z",
            "published": "2023-10-13T23:36:48Z",
            "summary": "Optimization-based regularization methods have been effective in addressing\nthe challenges posed by data heterogeneity in medical federated learning,\nparticularly in improving the performance of underrepresented clients. However,\nthese methods often lead to lower overall model accuracy and slower convergence\nrates. In this paper, we demonstrate that using Vision Transformers can\nsubstantially improve the performance of underrepresented clients without a\nsignificant trade-off in overall accuracy. This improvement is attributed to\nthe Vision transformer's ability to capture long-range dependencies within the\ninput data.",
            "author": [
                "Erfan Darzi",
                "Yiqing Shen",
                "Yangming Ou",
                "Nanna M. Sijtsema",
                "P. M. A van Ooijen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09444v2",
                "http://arxiv.org/pdf/2310.09444v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09443v1",
            "title": "G10: Enabling An Efficient Unified GPU Memory and Storage Architecture\n  with Smart Tensor Migrations",
            "updated": "2023-10-13T23:32:28Z",
            "published": "2023-10-13T23:32:28Z",
            "summary": "To break the GPU memory wall for scaling deep learning workloads, a variety\nof architecture and system techniques have been proposed recently. Their\ntypical approaches include memory extension with flash memory and direct\nstorage access. However, these techniques still suffer from suboptimal\nperformance and introduce complexity to the GPU memory management, making them\nhard to meet the scalability requirement of deep learning workloads today. In\nthis paper, we present a unified GPU memory and storage architecture named G10\ndriven by the fact that the tensor behaviors of deep learning workloads are\nhighly predictable. G10 integrates the host memory, GPU memory, and flash\nmemory into a unified memory space, to scale the GPU memory capacity while\nenabling transparent data migrations. Based on this unified GPU memory and\nstorage architecture, G10 utilizes compiler techniques to characterize the\ntensor behaviors in deep learning workloads. Therefore, it can schedule data\nmigrations in advance by considering the available bandwidth of flash memory\nand host memory. The cooperative mechanism between deep learning compilers and\nthe unified memory architecture enables G10 to hide data transfer overheads in\na transparent manner. We implement G10 based on an open-source GPU simulator.\nOur experiments demonstrate that G10 outperforms state-of-the-art GPU memory\nsolutions by up to 1.75$\\times$, without code modifications to deep learning\nworkloads. With the smart data migration mechanism, G10 can reach 90.3\\% of the\nperformance of the ideal case assuming unlimited GPU memory.",
            "author": [
                "Haoyang Zhang",
                "Yirui Eric Zhou",
                "Yuqi Xue",
                "Yiqi Liu",
                "Jian Huang"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3613424.3614309",
                "http://arxiv.org/abs/2310.09443v1",
                "http://arxiv.org/pdf/2310.09443v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09442v1",
            "title": "Learning Agile Locomotion and Adaptive Behaviors via RL-augmented MPC",
            "updated": "2023-10-13T23:23:39Z",
            "published": "2023-10-13T23:23:39Z",
            "summary": "In the context of legged robots, adaptive behavior involves adaptive\nbalancing and adaptive swing foot reflection. While adaptive balancing\ncounteracts perturbations to the robot, adaptive swing foot reflection helps\nthe robot to navigate intricate terrains without foot entrapment. In this\npaper, we manage to bring both aspects of adaptive behavior to quadruped\nlocomotion by combining RL and MPC while improving the robustness and agility\nof blind legged locomotion. This integration leverages MPC's strength in\npredictive capabilities and RL's adeptness in drawing from past experiences.\nUnlike traditional locomotion controls that separate stance foot control and\nswing foot trajectory, our innovative approach unifies them, addressing their\nlack of synchronization. At the heart of our contribution is the synthesis of\nstance foot control with swing foot reflection, improving agility and\nrobustness in locomotion with adaptive behavior. A hallmark of our approach is\nrobust blind stair climbing through swing foot reflection. Moreover, we\nintentionally designed the learning module as a general plugin for different\nrobot platforms. We trained the policy and implemented our approach on the\nUnitree A1 robot, achieving impressive results: a peak turn rate of 8.5 rad/s,\na peak running speed of 3 m/s, and steering at a speed of 2.5 m/s. Remarkably,\nthis framework also allows the robot to maintain stable locomotion while\nbearing an unexpected load of 10 kg, or 83\\% of its body mass. We further\ndemonstrate the generalizability and robustness of the same policy where it\nrealizes zero-shot transfer to different robot platforms like Go1 and AlienGo\nrobots for load carrying. Code is made available for the use of the research\ncommunity at https://github.com/DRCL-USC/RL_augmented_MPC.git",
            "author": [
                "Yiyu Chen",
                "Quan Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09442v1",
                "http://arxiv.org/pdf/2310.09442v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09441v1",
            "title": "MEMTRACK: A Deep Learning-Based Approach to Microrobot Tracking in Dense\n  and Low-Contrast Environments",
            "updated": "2023-10-13T23:21:32Z",
            "published": "2023-10-13T23:21:32Z",
            "summary": "Tracking microrobots is challenging, considering their minute size and high\nspeed. As the field progresses towards developing microrobots for biomedical\napplications and conducting mechanistic studies in physiologically relevant\nmedia (e.g., collagen), this challenge is exacerbated by the dense surrounding\nenvironments with feature size and shape comparable to microrobots. Herein, we\nreport Motion Enhanced Multi-level Tracker (MEMTrack), a robust pipeline for\ndetecting and tracking microrobots using synthetic motion features, deep\nlearning-based object detection, and a modified Simple Online and Real-time\nTracking (SORT) algorithm with interpolation for tracking. Our object detection\napproach combines different models based on the object's motion pattern. We\ntrained and validated our model using bacterial micro-motors in collagen\n(tissue phantom) and tested it in collagen and aqueous media. We demonstrate\nthat MEMTrack accurately tracks even the most challenging bacteria missed by\nskilled human annotators, achieving precision and recall of 77% and 48% in\ncollagen and 94% and 35% in liquid media, respectively. Moreover, we show that\nMEMTrack can quantify average bacteria speed with no statistically significant\ndifference from the laboriously-produced manual tracking data. MEMTrack\nrepresents a significant contribution to microrobot localization and tracking,\nand opens the potential for vision-based deep learning approaches to microrobot\ncontrol in dense and low-contrast settings. All source code for training and\ntesting MEMTrack and reproducing the results of the paper have been made\npublicly available https://github.com/sawhney-medha/MEMTrack.",
            "author": [
                "Medha Sawhney",
                "Bhas Karmarkar",
                "Eric J. Leaman",
                "Arka Daw",
                "Anuj Karpatne",
                "Bahareh Behkam"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09441v1",
                "http://arxiv.org/pdf/2310.09441v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "physics.bio-ph",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09440v1",
            "title": "Target Variable Engineering",
            "updated": "2023-10-13T23:12:21Z",
            "published": "2023-10-13T23:12:21Z",
            "summary": "How does the formulation of a target variable affect performance within the\nML pipeline? The experiments in this study examine numeric targets that have\nbeen binarized by comparing against a threshold. We compare the predictive\nperformance of regression models trained to predict the numeric targets vs.\nclassifiers trained to predict their binarized counterparts. Specifically, we\nmake this comparison at every point of a randomized hyperparameter optimization\nsearch to understand the effect of computational resource budget on the\ntradeoff between the two. We find that regression requires significantly more\ncomputational effort to converge upon the optimal performance, and is more\nsensitive to both randomness and heuristic choices in the training process.\nAlthough classification can and does benefit from systematic hyperparameter\ntuning and model selection, the improvements are much less than for regression.\nThis work comprises the first systematic comparison of regression and\nclassification within the framework of computational resource requirements. Our\nfindings contribute to calls for greater replicability and efficiency within\nthe ML pipeline for the sake of building more sustainable and robust AI\nsystems.",
            "author": [
                "Jessica Clark"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09440v1",
                "http://arxiv.org/pdf/2310.09440v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09437v1",
            "title": "Signal reconstruction using determinantal sampling",
            "updated": "2023-10-13T23:02:57Z",
            "published": "2023-10-13T23:02:57Z",
            "summary": "We study the approximation of a square-integrable function from a finite\nnumber of evaluations on a random set of nodes according to a well-chosen\ndistribution. This is particularly relevant when the function is assumed to\nbelong to a reproducing kernel Hilbert space (RKHS). This work proposes to\ncombine several natural finite-dimensional approximations based two possible\nprobability distributions of nodes. These distributions are related to\ndeterminantal point processes, and use the kernel of the RKHS to favor\nRKHS-adapted regularity in the random design. While previous work on\ndeterminantal sampling relied on the RKHS norm, we prove mean-square guarantees\nin $L^2$ norm. We show that determinantal point processes and mixtures thereof\ncan yield fast convergence rates. Our results also shed light on how the rate\nchanges as more smoothness is assumed, a phenomenon known as superconvergence.\nBesides, determinantal sampling generalizes i.i.d. sampling from the\nChristoffel function which is standard in the literature. More importantly,\ndeterminantal sampling guarantees the so-called instance optimality property\nfor a smaller number of function evaluations than i.i.d. sampling.",
            "author": [
                "Ayoub Belhadji",
                "R\u00e9mi Bardenet",
                "Pierre Chainais"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09437v1",
                "http://arxiv.org/pdf/2310.09437v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09436v1",
            "title": "Sub-network Discovery and Soft-masking for Continual Learning of Mixed\n  Tasks",
            "updated": "2023-10-13T23:00:39Z",
            "published": "2023-10-13T23:00:39Z",
            "summary": "Continual learning (CL) has two main objectives: preventing catastrophic\nforgetting (CF) and encouraging knowledge transfer (KT). The existing\nliterature mainly focused on overcoming CF. Some work has also been done on KT\nwhen the tasks are similar. To our knowledge, only one method has been proposed\nto learn a sequence of mixed tasks. However, these techniques still suffer from\nCF and/or limited KT. This paper proposes a new CL method to achieve both. It\novercomes CF by isolating the knowledge of each task via discovering a\nsubnetwork for it. A soft-masking mechanism is also proposed to preserve the\nprevious knowledge and to enable the new task to leverage the past knowledge to\nachieve KT. Experiments using classification, generation, information\nextraction, and their mixture (i.e., heterogeneous tasks) show that the\nproposed method consistently outperforms strong baselines.",
            "author": [
                "Zixuan Ke",
                "Bing Liu",
                "Wenhan Xiong",
                "Asli Celikyilmaz",
                "Haoran Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09436v1",
                "http://arxiv.org/pdf/2310.09436v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18326v1",
            "title": "Using Adaptive Bandit Experiments to Increase and Investigate Engagement\n  in Mental Health",
            "updated": "2023-10-13T22:59:56Z",
            "published": "2023-10-13T22:59:56Z",
            "summary": "Digital mental health (DMH) interventions, such as text-message-based lessons\nand activities, offer immense potential for accessible mental health support.\nWhile these interventions can be effective, real-world experimental testing can\nfurther enhance their design and impact. Adaptive experimentation, utilizing\nalgorithms like Thompson Sampling for (contextual) multi-armed bandit (MAB)\nproblems, can lead to continuous improvement and personalization. However, it\nremains unclear when these algorithms can simultaneously increase user\nexperience rewards and facilitate appropriate data collection for\nsocial-behavioral scientists to analyze with sufficient statistical confidence.\nAlthough a growing body of research addresses the practical and statistical\naspects of MAB and other adaptive algorithms, further exploration is needed to\nassess their impact across diverse real-world contexts. This paper presents a\nsoftware system developed over two years that allows text-messaging\nintervention components to be adapted using bandit and other algorithms while\ncollecting data for side-by-side comparison with traditional uniform random\nnon-adaptive experiments. We evaluate the system by deploying a\ntext-message-based DMH intervention to 1100 users, recruited through a large\nmental health non-profit organization, and share the path forward for deploying\nthis system at scale. This system not only enables applications in mental\nhealth but could also serve as a model testbed for adaptive experimentation\nalgorithms in other domains.",
            "author": [
                "Harsh Kumar",
                "Tong Li",
                "Jiakai Shi",
                "Ilya Musabirov",
                "Rachel Kornfield",
                "Jonah Meyerhoff",
                "Ananya Bhattacharjee",
                "Chris Karr",
                "Theresa Nguyen",
                "David Mohr",
                "Anna Rafferty",
                "Sofia Villar",
                "Nina Deliu",
                "Joseph Jay Williams"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18326v1",
                "http://arxiv.org/pdf/2310.18326v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CY",
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09434v1",
            "title": "Learning nonlinear integral operators via Recurrent Neural Networks and\n  its application in solving Integro-Differential Equations",
            "updated": "2023-10-13T22:57:46Z",
            "published": "2023-10-13T22:57:46Z",
            "summary": "In this paper, we propose using LSTM-RNNs (Long Short-Term Memory-Recurrent\nNeural Networks) to learn and represent nonlinear integral operators that\nappear in nonlinear integro-differential equations (IDEs). The LSTM-RNN\nrepresentation of the nonlinear integral operator allows us to turn a system of\nnonlinear integro-differential equations into a system of ordinary differential\nequations for which many efficient solvers are available. Furthermore, because\nthe use of LSTM-RNN representation of the nonlinear integral operator in an IDE\neliminates the need to perform a numerical integration in each numerical time\nevolution step, the overall temporal cost of the LSTM-RNN-based IDE solver can\nbe reduced to $O(n_T)$ from $O(n_T^2)$ if a $n_T$-step trajectory is to be\ncomputed. We illustrate the efficiency and robustness of this LSTM-RNN-based\nnumerical IDE solver with a model problem. Additionally, we highlight the\ngeneralizability of the learned integral operator by applying it to IDEs driven\nby different external forces. As a practical application, we show how this\nmethodology can effectively solve the Dyson's equation for quantum many-body\nsystems.",
            "author": [
                "Hardeep Bassi",
                "Yuanran Zhu",
                "Senwei Liang",
                "Jia Yin",
                "Cian C. Reeves",
                "Vojtech Vlcek",
                "Chao Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09434v1",
                "http://arxiv.org/pdf/2310.09434v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.DS",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09433v1",
            "title": "Effects of cavity nonlinearities and linear losses on silicon\n  microring-based reservoir computing",
            "updated": "2023-10-13T22:48:50Z",
            "published": "2023-10-13T22:48:50Z",
            "summary": "Microring resonators (MRRs) are promising devices for time-delay photonic\nreservoir computing, but the impact of the different physical effects taking\nplace in the MRRs on the reservoir computing performance is yet to be fully\nunderstood. We numerically analyze the impact of linear losses as well as\nthermo-optic and free-carrier effects relaxation times on the prediction error\nof the time-series task NARMA-10. We demonstrate the existence of three\nregions, defined by the input power and the frequency detuning between the\noptical source and the microring resonance, that reveal the cavity transition\nfrom linear to nonlinear regimes. One of these regions offers very low error in\ntime-series prediction under relatively low input power and number of nodes\nwhile the other regions either lack nonlinearity or become unstable. This study\nprovides insight into the design of the MRR and the optimization of its\nphysical properties for improving the prediction performance of time-delay\nreservoir computing.",
            "author": [
                "Bernard J. Giron Castro",
                "Christophe Peucheret",
                "Darko Zibar",
                "Francesco Da Ros"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09433v1",
                "http://arxiv.org/pdf/2310.09433v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics",
                "cs.ET",
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09432v1",
            "title": "Enhancing BERT-Based Visual Question Answering through Keyword-Driven\n  Sentence Selection",
            "updated": "2023-10-13T22:43:55Z",
            "published": "2023-10-13T22:43:55Z",
            "summary": "The Document-based Visual Question Answering competition addresses the\nautomatic detection of parent-child relationships between elements in\nmulti-page documents. The goal is to identify the document elements that answer\na specific question posed in natural language. This paper describes the\nPoliTo's approach to addressing this task, in particular, our best solution\nexplores a text-only approach, leveraging an ad hoc sampling strategy.\nSpecifically, our approach leverages the Masked Language Modeling technique to\nfine-tune a BERT model, focusing on sentences containing sensitive keywords\nthat also occur in the questions, such as references to tables or images.\nThanks to the effectiveness of this approach, we are able to achieve high\nperformance compared to baselines, demonstrating how our solution contributes\npositively to this task.",
            "author": [
                "Davide Napolitano",
                "Lorenzo Vaiani",
                "Luca Cagliero"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09432v1",
                "http://arxiv.org/pdf/2310.09432v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09426v1",
            "title": "Offline Reinforcement Learning for Optimizing Production Bidding\n  Policies",
            "updated": "2023-10-13T22:14:51Z",
            "published": "2023-10-13T22:14:51Z",
            "summary": "The online advertising market, with its thousands of auctions run per second,\npresents a daunting challenge for advertisers who wish to optimize their spend\nunder a budget constraint. Thus, advertising platforms typically provide\nautomated agents to their customers, which act on their behalf to bid for\nimpression opportunities in real time at scale. Because these proxy agents are\nowned by the platform but use advertiser funds to operate, there is a strong\npractical need to balance reliability and explainability of the agent with\noptimizing power. We propose a generalizable approach to optimizing bidding\npolicies in production environments by learning from real data using offline\nreinforcement learning. This approach can be used to optimize any\ndifferentiable base policy (practically, a heuristic policy based on principles\nwhich the advertiser can easily understand), and only requires data generated\nby the base policy itself. We use a hybrid agent architecture that combines\narbitrary base policies with deep neural networks, where only the optimized\nbase policy parameters are eventually deployed, and the neural network part is\ndiscarded after training. We demonstrate that such an architecture achieves\nstatistically significant performance gains in both simulated and at-scale\nproduction bidding environments. Our approach does not incur additional\ninfrastructure, safety, or explainability costs, as it directly optimizes\nparameters of existing production routines without replacing them with black\nbox-style models like neural networks.",
            "author": [
                "Dmytro Korenkevych",
                "Frank Cheng",
                "Artsiom Balakir",
                "Alex Nikulkov",
                "Lingnan Gao",
                "Zhihao Cen",
                "Zuobing Xu",
                "Zheqing Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09426v1",
                "http://arxiv.org/pdf/2310.09426v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09424v1",
            "title": "SALM: Speech-augmented Language Model with In-context Learning for\n  Speech Recognition and Translation",
            "updated": "2023-10-13T22:07:33Z",
            "published": "2023-10-13T22:07:33Z",
            "summary": "We present a novel Speech Augmented Language Model (SALM) with {\\em\nmultitask} and {\\em in-context} learning capabilities. SALM comprises a frozen\ntext LLM, a audio encoder, a modality adapter module, and LoRA layers to\naccommodate speech input and associated task instructions. The unified SALM not\nonly achieves performance on par with task-specific Conformer baselines for\nAutomatic Speech Recognition (ASR) and Speech Translation (AST), but also\nexhibits zero-shot in-context learning capabilities, demonstrated through\nkeyword-boosting task for ASR and AST. Moreover, {\\em speech supervised\nin-context training} is proposed to bridge the gap between LLM training and\ndownstream speech tasks, which further boosts the in-context learning ability\nof speech-to-text models. Proposed model is open-sourced via NeMo toolkit.",
            "author": [
                "Zhehuai Chen",
                "He Huang",
                "Andrei Andrusenko",
                "Oleksii Hrinchuk",
                "Krishna C. Puvvada",
                "Jason Li",
                "Subhankar Ghosh",
                "Jagadeesh Balam",
                "Boris Ginsburg"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09424v1",
                "http://arxiv.org/pdf/2310.09424v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.HC",
                "cs.SD",
                "eess.AS",
                "68T10",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09413v1",
            "title": "ZeroSwap: Data-driven Optimal Market Making in DeFi",
            "updated": "2023-10-13T21:28:19Z",
            "published": "2023-10-13T21:28:19Z",
            "summary": "Automated Market Makers (AMMs) are major centers of matching liquidity supply\nand demand in Decentralized Finance. Their functioning relies primarily on the\npresence of liquidity providers (LPs) incentivized to invest their assets into\na liquidity pool. However, the prices at which a pooled asset is traded is\noften more stale than the prices on centralized and more liquid exchanges. This\nleads to the LPs suffering losses to arbitrage. This problem is addressed by\nadapting market prices to trader behavior, captured via the classical market\nmicrostructure model of Glosten and Milgrom. In this paper, we propose the\nfirst optimal Bayesian and the first model-free data-driven algorithm to\noptimally track the external price of the asset. The notion of optimality that\nwe use enforces a zero-profit condition on the prices of the market maker,\nhence the name ZeroSwap. This ensures that the market maker balances losses to\ninformed traders with profits from noise traders. The key property of our\napproach is the ability to estimate the external market price without the need\nfor price oracles or loss oracles. Our theoretical guarantees on the\nperformance of both these algorithms, ensuring the stability and convergence of\ntheir price recommendations, are of independent interest in the theory of\nreinforcement learning. We empirically demonstrate the robustness of our\nalgorithms to changing market conditions.",
            "author": [
                "Viraj Nadkarni",
                "Jiachen Hu",
                "Ranvir Rana",
                "Chi Jin",
                "Sanjeev Kulkarni",
                "Pramod Viswanath"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09413v1",
                "http://arxiv.org/pdf/2310.09413v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09412v1",
            "title": "Hybrid Reinforcement Learning for Optimizing Pump Sustainability in\n  Real-World Water Distribution Networks",
            "updated": "2023-10-13T21:26:16Z",
            "published": "2023-10-13T21:26:16Z",
            "summary": "This article addresses the pump-scheduling optimization problem to enhance\nreal-time control of real-world water distribution networks (WDNs). Our primary\nobjectives are to adhere to physical operational constraints while reducing\nenergy consumption and operational costs. Traditional optimization techniques,\nsuch as evolution-based and genetic algorithms, often fall short due to their\nlack of convergence guarantees. Conversely, reinforcement learning (RL) stands\nout for its adaptability to uncertainties and reduced inference time, enabling\nreal-time responsiveness. However, the effective implementation of RL is\ncontingent on building accurate simulation models for WDNs, and prior\napplications have been limited by errors in simulation training data. These\nerrors can potentially cause the RL agent to learn misleading patterns and\nactions and recommend suboptimal operational strategies. To overcome these\nchallenges, we present an improved \"hybrid RL\" methodology. This method\nintegrates the benefits of RL while anchoring it in historical data, which\nserves as a baseline to incrementally introduce optimal control\nrecommendations. By leveraging operational data as a foundation for the agent's\nactions, we enhance the explainability of the agent's actions, foster more\nrobust recommendations, and minimize error. Our findings demonstrate that the\nhybrid RL agent can significantly improve sustainability, operational\nefficiency, and dynamically adapt to emerging scenarios in real-world WDNs.",
            "author": [
                "Harsh Patel",
                "Yuan Zhou",
                "Alexander P Lamb",
                "Shu Wang",
                "Jieliang Luo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09412v1",
                "http://arxiv.org/pdf/2310.09412v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09411v1",
            "title": "Surveying the Landscape of Text Summarization with Deep Learning: A\n  Comprehensive Review",
            "updated": "2023-10-13T21:24:37Z",
            "published": "2023-10-13T21:24:37Z",
            "summary": "In recent years, deep learning has revolutionized natural language processing\n(NLP) by enabling the development of models that can learn complex\nrepresentations of language data, leading to significant improvements in\nperformance across a wide range of NLP tasks. Deep learning models for NLP\ntypically use large amounts of data to train deep neural networks, allowing\nthem to learn the patterns and relationships in language data. This is in\ncontrast to traditional NLP approaches, which rely on hand-engineered features\nand rules to perform NLP tasks. The ability of deep neural networks to learn\nhierarchical representations of language data, handle variable-length input\nsequences, and perform well on large datasets makes them well-suited for NLP\napplications. Driven by the exponential growth of textual data and the\nincreasing demand for condensed, coherent, and informative summaries, text\nsummarization has been a critical research area in the field of NLP. Applying\ndeep learning to text summarization refers to the use of deep neural networks\nto perform text summarization tasks. In this survey, we begin with a review of\nfashionable text summarization tasks in recent years, including extractive,\nabstractive, multi-document, and so on. Next, we discuss most deep\nlearning-based models and their experimental results on these tasks. The paper\nalso covers datasets and data representation for summarization tasks. Finally,\nwe delve into the opportunities and challenges associated with summarization\ntasks and their corresponding methodologies, aiming to inspire future research\nefforts to advance the field further. A goal of our survey is to explain how\nthese methods differ in their requirements as understanding them is essential\nfor choosing a technique suited for a specific setting.",
            "author": [
                "Guanghua Wang",
                "Weili Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09411v1",
                "http://arxiv.org/pdf/2310.09411v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09409v1",
            "title": "Heuristic Algorithms for Placing Geomagnetically Induced Current\n  Blocking Devices",
            "updated": "2023-10-13T21:13:47Z",
            "published": "2023-10-13T21:13:47Z",
            "summary": "We propose a new heuristic approach for solving the challenge of determining\noptimal placements for geomagnetically induced current blocking devices on\nelectrical grids. Traditionally, these determinations are approached by\nformulating the problem as mixed-integer nonlinear programming models and\nsolving them using optimization solvers based on the spatial branch-and-bound\nalgorithm.However, computing an optimal solution using the solvers often\ndemands substantial computational time due to their inability to leverage the\ninherent problem structure. Therefore, in this work we propose a new heuristic\napproach based on a three-block alternating direction method of multipliers\nalgorithm, and we compare it with an existing stochastic learning algorithm.\nBoth heuristics exploit the structure of the problem of interest. We test these\nheuristic approaches through extensive numerical experiments conducted on the\nEPRI-21 and UIUC-150 test systems. The outcomes showcase the superior\nperformance of our methodologies in terms of both solution quality and\ncomputational speed when compared with conventional solvers.",
            "author": [
                "Minseok Ryu",
                "Ahmed Attia",
                "Arthur Barnes",
                "Russell Bent",
                "Sven Leyffer",
                "Adam Mate"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09409v1",
                "http://arxiv.org/pdf/2310.09409v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09404v1",
            "title": "Protecting Voice-Controlled Devices against LASER Injection Attacks",
            "updated": "2023-10-13T21:09:38Z",
            "published": "2023-10-13T21:09:38Z",
            "summary": "Voice-Controllable Devices (VCDs) have seen an increasing trend towards their\nadoption due to the small form factor of the MEMS microphones and their easy\nintegration into modern gadgets. Recent studies have revealed that MEMS\nmicrophones are vulnerable to audio-modulated laser injection attacks. This\npaper aims to develop countermeasures to detect and prevent laser injection\nattacks on MEMS microphones. A time-frequency decomposition based on discrete\nwavelet transform (DWT) is employed to decompose microphone output audio signal\ninto n + 1 frequency subbands to capture photo-acoustic related artifacts.\nHigher-order statistical features consisting of the first four moments of\nsubband audio signals, e.g., variance, skew, and kurtosis are used to\ndistinguish between acoustic and photo-acoustic responses. An SVM classifier is\nused to learn the underlying model that differentiates between an acoustic- and\nlaser-induced (photo-acoustic) response in the MEMS microphone. The proposed\nframework is evaluated on a data set of 190 audios, consisting of 19 speakers.\nThe experimental results indicate that the proposed framework is able to\ncorrectly classify $98\\%$ of the acoustic- and laser-induced audio in a random\ndata partition setting and $100\\%$ of the audio in speaker-independent and\ntext-independent data partition settings.",
            "author": [
                "Hashim Ali",
                "Dhimant Khuttan",
                "Rafi Ud Daula Refat",
                "Hafiz Malik"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09404v1",
                "http://arxiv.org/pdf/2310.09404v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09397v1",
            "title": "Identifiability of Product of Experts Models",
            "updated": "2023-10-13T20:33:33Z",
            "published": "2023-10-13T20:33:33Z",
            "summary": "Product of experts (PoE) are layered networks in which the value at each node\nis an AND (or product) of the values (possibly negated) at its inputs. These\nwere introduced as a neural network architecture that can efficiently learn to\ngenerate high-dimensional data which satisfy many low-dimensional constraints\n-- thereby allowing each individual expert to perform a simple task. PoEs have\nfound a variety of applications in learning.\n  We study the problem of identifiability of a product of experts model having\na layer of binary latent variables, and a layer of binary observables that are\niid conditional on the latents. The previous best upper bound on the number of\nobservables needed to identify the model was exponential in the number of\nparameters. We show: (a) When the latents are uniformly distributed, the model\nis identifiable with a number of observables equal to the number of parameters\n(and hence best possible). (b) In the more general case of arbitrarily\ndistributed latents, the model is identifiable for a number of observables that\nis still linear in the number of parameters (and within a factor of two of\nbest-possible). The proofs rely on root interlacing phenomena for some special\nthree-term recurrences.",
            "author": [
                "Spencer L. Gordon",
                "Manav Kant",
                "Eric Ma",
                "Leonard J. Schulman",
                "Andrei Staicu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09397v1",
                "http://arxiv.org/pdf/2310.09397v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.AG",
                "math.ST",
                "stat.TH",
                "62E10, 62F99, 68T05",
                "I.2.6"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09394v1",
            "title": "Semantics Alignment via Split Learning for Resilient Multi-User Semantic\n  Communication",
            "updated": "2023-10-13T20:29:55Z",
            "published": "2023-10-13T20:29:55Z",
            "summary": "Recent studies on semantic communication commonly rely on neural network (NN)\nbased transceivers such as deep joint source and channel coding (DeepJSCC).\nUnlike traditional transceivers, these neural transceivers are trainable using\nactual source data and channels, enabling them to extract and communicate\nsemantics. On the flip side, each neural transceiver is inherently biased\ntowards specific source data and channels, making different transceivers\ndifficult to understand intended semantics, particularly upon their initial\nencounter. To align semantics over multiple neural transceivers, we propose a\ndistributed learning based solution, which leverages split learning (SL) and\npartial NN fine-tuning techniques. In this method, referred to as SL with layer\nfreezing (SLF), each encoder downloads a misaligned decoder, and locally\nfine-tunes a fraction of these encoder-decoder NN layers. By adjusting this\nfraction, SLF controls computing and communication costs. Simulation results\nconfirm the effectiveness of SLF in aligning semantics under different source\ndata and channel dissimilarities, in terms of classification accuracy,\nreconstruction errors, and recovery time for comprehending intended semantics\nfrom misalignment.",
            "author": [
                "Jinhyuk Choi",
                "Jihong Park",
                "Seung-Woo Ko",
                "Jinho Choi",
                "Mehdi Bennis",
                "Seong-Lyun Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09394v1",
                "http://arxiv.org/pdf/2310.09394v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.IT",
                "cs.NI",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09392v1",
            "title": "Machine Learning Estimation of Maximum Vertical Velocity from Radar",
            "updated": "2023-10-13T20:26:55Z",
            "published": "2023-10-13T20:26:55Z",
            "summary": "Despite being the source region of severe weather hazards, the quantification\nof the fast current of upward moving air (i.e., updraft) remains unavailable\nfor operational forecasting. Updraft proxies, like overshooting top area from\nsatellite images, have been linked to severe weather hazards but only relate to\na limited portion of the total storm updraft. This study investigates if a\nmachine learning model, namely U-Nets, can skillfully retrieve maximum vertical\nvelocity and its areal extent from 3-dimensional (3D) gridded radar\nreflectivity alone. The machine learning model is trained using simulated radar\nreflectivity and vertical velocity from the National Severe Storm Laboratory's\nconvection permitting Warn on Forecast System (WoFS). A parametric regression\ntechnique using the Sinh-arcsinh-normal (SHASH) distribution is adapted to run\nwith UNets, allowing for both deterministic and probabilistic predictions of\nmaximum vertical velocity. The best models after hyperparameter search provided\nless than 50% root mean squared error, a coefficient of determination greater\nthan 0.65 and an intersection over union (IoU) of more than 0.45 on the\nindependent test set composed of WoFS data. Beyond the WoFS analysis, a case\nstudy was conducted using real radar data and corresponding dual-Doppler\nanalyses of vertical velocity within a supercell. The U-Net consistently\nunderestimates the dual-Doppler updraft speed estimates by 50%. Meanwhile, the\narea of the 5 and 10 m s-1 updraft cores show an IoU of 0.25. While the above\nstatistics are not exceptional, the machine learning model enables quick\ndistillation of 3D radar data that is related to the maximum vertical velocity\nwhich could be useful in assessing a storm's severe potential.",
            "author": [
                "Randy J. Chase",
                "Amy McGovern",
                "Cameron Homeyer",
                "Peter Marinescu",
                "Corey Potvin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09392v1",
                "http://arxiv.org/pdf/2310.09392v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09388v1",
            "title": "CORN: Co-Trained Full-Reference And No-Reference Audio Metrics",
            "updated": "2023-10-13T20:17:44Z",
            "published": "2023-10-13T20:17:44Z",
            "summary": "Perceptual evaluation constitutes a crucial aspect of various\naudio-processing tasks. Full reference (FR) or similarity-based metrics rely on\nhigh-quality reference recordings, to which lower-quality or corrupted versions\nof the recording may be compared for evaluation. In contrast, no-reference (NR)\nmetrics evaluate a recording without relying on a reference. Both the FR and NR\napproaches exhibit advantages and drawbacks relative to each other. In this\npaper, we present a novel framework called CORN that amalgamates these dual\napproaches, concurrently training both FR and NR models together. After\ntraining, the models can be applied independently. We evaluate CORN by\npredicting several common objective metrics and across two different\narchitectures. The NR model trained using CORN has access to a reference\nrecording during training, and thus, as one would expect, it consistently\noutperforms baseline NR models trained independently. Perhaps even more\nremarkable is that the CORN FR model also outperforms its baseline counterpart,\neven though it relies on the same training data and the same model\narchitecture. Thus, a single training regime produces two independently useful\nmodels, each outperforming independently trained models.",
            "author": [
                "Pranay Manocha",
                "Donald Williamson",
                "Adam Finkelstein"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09388v1",
                "http://arxiv.org/pdf/2310.09388v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.LG",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09382v1",
            "title": "LL-VQ-VAE: Learnable Lattice Vector-Quantization For Efficient\n  Representations",
            "updated": "2023-10-13T20:03:18Z",
            "published": "2023-10-13T20:03:18Z",
            "summary": "In this paper we introduce learnable lattice vector quantization and\ndemonstrate its effectiveness for learning discrete representations. Our\nmethod, termed LL-VQ-VAE, replaces the vector quantization layer in VQ-VAE with\nlattice-based discretization. The learnable lattice imposes a structure over\nall discrete embeddings, acting as a deterrent against codebook collapse,\nleading to high codebook utilization. Compared to VQ-VAE, our method obtains\nlower reconstruction errors under the same training conditions, trains in a\nfraction of the time, and with a constant number of parameters (equal to the\nembedding dimension $D$), making it a very scalable approach. We demonstrate\nthese results on the FFHQ-1024 dataset and include FashionMNIST and Celeb-A.",
            "author": [
                "Ahmed Khalil",
                "Robert Piechocki",
                "Raul Santos-Rodriguez"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09382v1",
                "http://arxiv.org/pdf/2310.09382v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09373v1",
            "title": "Identifying and examining machine learning biases on Adult dataset",
            "updated": "2023-10-13T19:41:47Z",
            "published": "2023-10-13T19:41:47Z",
            "summary": "This research delves into the reduction of machine learning model bias\nthrough Ensemble Learning. Our rigorous methodology comprehensively assesses\nbias across various categorical variables, ultimately revealing a pronounced\ngender attribute bias. The empirical evidence unveils a substantial\ngender-based wage prediction disparity: wages predicted for males, initially at\n\\$902.91, significantly decrease to \\$774.31 when the gender attribute is\nalternated to females. Notably, Kullback-Leibler divergence scores point to\ngender bias, with values exceeding 0.13, predominantly within tree-based\nmodels. Employing Ensemble Learning elucidates the quest for fairness and\ntransparency. Intriguingly, our findings reveal that the stacked model aligns\nwith individual models, confirming the resilience of model bias. This study\nunderscores ethical considerations and advocates the implementation of hybrid\nmodels for a data-driven society marked by impartiality and inclusivity.",
            "author": [
                "Sahil Girhepuje"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09373v1",
                "http://arxiv.org/pdf/2310.09373v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09368v1",
            "title": "Constrained re-calibration of Reynolds-averaged Navier-Stokes models",
            "updated": "2023-10-13T19:20:27Z",
            "published": "2023-10-13T19:20:27Z",
            "summary": "The constants and functions in Reynolds-averaged Navier Stokes (RANS)\nturbulence models are coupled. Consequently, modifications of a RANS model\noften negatively impact its basic calibrations, which is why machine-learned\naugmentations are often detrimental outside the training dataset. A solution to\nthis is to identify the degrees of freedom that do not affect the basic\ncalibrations and only modify these identified degrees of freedom when\nre-calibrating the baseline model to accommodate a specific application. This\napproach is colloquially known as the \"rubber-band\" approach, which we formally\ncall \"constrained model re-calibration\" in this article. To illustrate the\nefficacy of the approach, we identify the degrees of freedom in the\nSpalart-Allmaras (SA) model that do not affect the log law calibration. By\nsubsequently interfacing data-based methods with these degrees of freedom, we\ntrain models to solve historically challenging flow scenarios, including the\nround-jet/plane-jet anomaly, airfoil stall, secondary flow separation, and\nrecovery after separation. In addition to good performance inside the training\ndataset, the trained models yield similar performance as the baseline model\noutside the training dataset.",
            "author": [
                "Yuanwei Bin",
                "George Huang",
                "Robert Kunz",
                "Xiang I A Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09368v1",
                "http://arxiv.org/pdf/2310.09368v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09366v1",
            "title": "A priori screening of data-enabled turbulence models",
            "updated": "2023-10-13T19:19:48Z",
            "published": "2023-10-13T19:19:48Z",
            "summary": "Assessing the compliance of a white-box turbulence model with known turbulent\nknowledge is straightforward. It enables users to screen conventional\nturbulence models and identify apparent inadequacies, thereby allowing for a\nmore focused and fruitful validation and verification. However, comparing a\nblack-box machine-learning model to known empirical scalings is not\nstraightforward. Unless one implements and tests the model, it would not be\nclear if a machine-learning model, trained at finite Reynolds numbers preserves\nthe known high Reynolds number limit. This is inconvenient, particularly\nbecause model implementation involves retraining and re-interfacing. This work\nattempts to address this issue, allowing fast a priori screening of\nmachine-learning models that are based on feed-forward neural networks (FNN).\nThe method leverages the mathematical theorems we present in the paper. These\ntheorems offer estimates of a network's limits even when the exact weights and\nbiases are unknown. For demonstration purposes, we screen existing\nmachine-learning wall models and RANS models for their compliance with the log\nlayer physics and the viscous layer physics in a priori manner. In addition,\nthe theorems serve as essential guidelines for future machine-learning models.",
            "author": [
                "Peng E S Chen",
                "Yuanwei Bin",
                "Xiang I A Yang",
                "Yipeng Shi",
                "Mahdi Abkar",
                "George I. Park"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09366v1",
                "http://arxiv.org/pdf/2310.09366v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09362v1",
            "title": "From Words and Exercises to Wellness: Farsi Chatbot for Self-Attachment\n  Technique",
            "updated": "2023-10-13T19:09:31Z",
            "published": "2023-10-13T19:09:31Z",
            "summary": "In the wake of the post-pandemic era, marked by social isolation and surging\nrates of depression and anxiety, conversational agents based on digital\npsychotherapy can play an influential role compared to traditional therapy\nsessions. In this work, we develop a voice-capable chatbot in Farsi to guide\nusers through Self-Attachment (SAT), a novel, self-administered, holistic\npsychological technique based on attachment theory. Our chatbot uses a dynamic\narray of rule-based and classification-based modules to comprehend user input\nthroughout the conversation and navigates a dialogue flowchart accordingly,\nrecommending appropriate SAT exercises that depend on the user's emotional and\nmental state. In particular, we collect a dataset of over 6,000 utterances and\ndevelop a novel sentiment-analysis module that classifies user sentiment into\n12 classes, with accuracy above 92%. To keep the conversation novel and\nengaging, the chatbot's responses are retrieved from a large dataset of\nutterances created with the aid of Farsi GPT-2 and a reinforcement learning\napproach, thus requiring minimal human annotation. Our chatbot also offers a\nquestion-answering module, called SAT Teacher, to answer users' questions about\nthe principles of Self-Attachment. Finally, we design a cross-platform\napplication as the bot's user interface. We evaluate our platform in a ten-day\nhuman study with N=52 volunteers from the non-clinical population, who have had\nover 2,000 dialogues in total with the chatbot. The results indicate that the\nplatform was engaging to most users (75%), 72% felt better after the\ninteractions, and 74% were satisfied with the SAT Teacher's performance.",
            "author": [
                "Sina Elahimanesh",
                "Shayan Salehi",
                "Sara Zahedi Movahed",
                "Lisa Alazraki",
                "Ruoyu Hu",
                "Abbas Edalat"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09362v1",
                "http://arxiv.org/pdf/2310.09362v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09361v1",
            "title": "Is Certifying $\\ell_p$ Robustness Still Worthwhile?",
            "updated": "2023-10-13T19:08:21Z",
            "published": "2023-10-13T19:08:21Z",
            "summary": "Over the years, researchers have developed myriad attacks that exploit the\nubiquity of adversarial examples, as well as defenses that aim to guard against\nthe security vulnerabilities posed by such attacks. Of particular interest to\nthis paper are defenses that provide provable guarantees against the class of\n$\\ell_p$-bounded attacks. Certified defenses have made significant progress,\ntaking robustness certification from toy models and datasets to large-scale\nproblems like ImageNet classification. While this is undoubtedly an interesting\nacademic problem, as the field has matured, its impact in practice remains\nunclear, thus we find it useful to revisit the motivation for continuing this\nline of research. There are three layers to this inquiry, which we address in\nthis paper: (1) why do we care about robustness research? (2) why do we care\nabout the $\\ell_p$-bounded threat model? And (3) why do we care about\ncertification as opposed to empirical defenses? In brief, we take the position\nthat local robustness certification indeed confers practical value to the field\nof machine learning. We focus especially on the latter two questions from\nabove. With respect to the first of the two, we argue that the $\\ell_p$-bounded\nthreat model acts as a minimal requirement for safe application of models in\nsecurity-critical domains, while at the same time, evidence has mounted\nsuggesting that local robustness may lead to downstream external benefits not\nimmediately related to robustness. As for the second, we argue that (i)\ncertification provides a resolution to the cat-and-mouse game of adversarial\nattacks; and furthermore, that (ii) perhaps contrary to popular belief, there\nmay not exist a fundamental trade-off between accuracy, robustness, and\ncertifiability, while moreover, certified training techniques constitute a\nparticularly promising way for learning robust models.",
            "author": [
                "Ravi Mangal",
                "Klas Leino",
                "Zifan Wang",
                "Kai Hu",
                "Weicheng Yu",
                "Corina Pasareanu",
                "Anupam Datta",
                "Matt Fredrikson"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09361v1",
                "http://arxiv.org/pdf/2310.09361v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09360v1",
            "title": "Exact Verification of ReLU Neural Control Barrier Functions",
            "updated": "2023-10-13T18:59:04Z",
            "published": "2023-10-13T18:59:04Z",
            "summary": "Control Barrier Functions (CBFs) are a popular approach for safe control of\nnonlinear systems. In CBF-based control, the desired safety properties of the\nsystem are mapped to nonnegativity of a CBF, and the control input is chosen to\nensure that the CBF remains nonnegative for all time. Recently, machine\nlearning methods that represent CBFs as neural networks (neural control barrier\nfunctions, or NCBFs) have shown great promise due to the universal\nrepresentability of neural networks. However, verifying that a learned CBF\nguarantees safety remains a challenging research problem. This paper presents\nnovel exact conditions and algorithms for verifying safety of feedforward NCBFs\nwith ReLU activation functions. The key challenge in doing so is that, due to\nthe piecewise linearity of the ReLU function, the NCBF will be\nnondifferentiable at certain points, thus invalidating traditional safety\nverification methods that assume a smooth barrier function. We resolve this\nissue by leveraging a generalization of Nagumo's theorem for proving invariance\nof sets with nonsmooth boundaries to derive necessary and sufficient conditions\nfor safety. Based on this condition, we propose an algorithm for safety\nverification of NCBFs that first decomposes the NCBF into piecewise linear\nsegments and then solves a nonlinear program to verify safety of each segment\nas well as the intersections of the linear segments. We mitigate the complexity\nby only considering the boundary of the safe region and by pruning the segments\nwith Interval Bound Propagation (IBP) and linear relaxation. We evaluate our\napproach through numerical studies with comparison to state-of-the-art\nSMT-based methods. Our code is available at\nhttps://github.com/HongchaoZhang-HZ/exactverif-reluncbf-nips23.",
            "author": [
                "Hongchao Zhang",
                "Junlin Wu",
                "Yevgeniy Vorobeychik",
                "Andrew Clark"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09360v1",
                "http://arxiv.org/pdf/2310.09360v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09358v1",
            "title": "When are Bandits Robust to Misspecification?",
            "updated": "2023-10-13T18:53:30Z",
            "published": "2023-10-13T18:53:30Z",
            "summary": "Parametric feature-based reward models are widely employed by algorithms for\ndecision making settings such as bandits and contextual bandits. The typical\nassumption under which they are analysed is realizability, i.e., that the true\nrewards of actions are perfectly explained by some parametric model in the\nclass. We are, however, interested in the situation where the true rewards are\n(potentially significantly) misspecified with respect to the model class. For\nparameterized bandits and contextual bandits, we identify sufficient\nconditions, depending on the problem instance and model class, under which\nclassic algorithms such as $\\epsilon$-greedy and LinUCB enjoy sublinear (in the\ntime horizon) regret guarantees under even grossly misspecified rewards. This\nis in contrast to existing worst-case results for misspecified bandits which\nshow regret bounds that scale linearly with time, and shows that there can be a\nnontrivially large set of bandit instances that are robust to misspecification.",
            "author": [
                "Debangshu Banerjee",
                "Aditya Gopalan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09358v1",
                "http://arxiv.org/pdf/2310.09358v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09341v1",
            "title": "Addressing the cold start problem in privacy preserving content-based\n  recommender systems using hypercube graphs",
            "updated": "2023-10-13T18:11:12Z",
            "published": "2023-10-13T18:11:12Z",
            "summary": "The initial interaction of a user with a recommender system is problematic\nbecause, in such a so-called cold start situation, the recommender system has\nvery little information about the user, if any. Moreover, in collaborative\nfiltering, users need to share their preferences with the service provider by\nrating items while in content-based filtering there is no need for such\ninformation sharing. We have recently shown that a content-based model that\nuses hypercube graphs can determine user preferences with a very limited number\nof ratings while better preserving user privacy. In this paper, we confirm\nthese findings on the basis of experiments with more than 1,000 users in the\nrestaurant and movie domains. We show that the proposed method outperforms\nstandard machine learning algorithms when the number of available ratings is at\nmost 10, which often happens, and is competitive with larger training sets. In\naddition, training is simple and does not require large computational efforts.",
            "author": [
                "Noa Tuval",
                "Alain Hertz",
                "Tsvi Kuflik"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09341v1",
                "http://arxiv.org/pdf/2310.09341v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09340v1",
            "title": "Geo-knowledge-guided GPT models improve the extraction of location\n  descriptions from disaster-related social media messages",
            "updated": "2023-10-13T18:09:21Z",
            "published": "2023-10-13T18:09:21Z",
            "summary": "Social media messages posted by people during natural disasters often contain\nimportant location descriptions, such as the locations of victims. Recent\nresearch has shown that many of these location descriptions go beyond simple\nplace names, such as city names and street names, and are difficult to extract\nusing typical named entity recognition (NER) tools. While advanced machine\nlearning models could be trained, they require large labeled training datasets\nthat can be time-consuming and labor-intensive to create. In this work, we\npropose a method that fuses geo-knowledge of location descriptions and a\nGenerative Pre-trained Transformer (GPT) model, such as ChatGPT and GPT-4. The\nresult is a geo-knowledge-guided GPT model that can accurately extract location\ndescriptions from disaster-related social media messages. Also, only 22\ntraining examples encoding geo-knowledge are used in our method. We conduct\nexperiments to compare this method with nine alternative approaches on a\ndataset of tweets from Hurricane Harvey. Our method demonstrates an over 40%\nimprovement over typically used NER approaches. The experiment results also\nshow that geo-knowledge is indispensable for guiding the behavior of GPT\nmodels. The extracted location descriptions can help disaster responders reach\nvictims more quickly and may even save lives.",
            "author": [
                "Yingjie Hu",
                "Gengchen Mai",
                "Chris Cundy",
                "Kristy Choi",
                "Ni Lao",
                "Wei Liu",
                "Gaurish Lakhanpal",
                "Ryan Zhenqi Zhou",
                "Kenneth Joseph"
            ],
            "link": [
                "http://dx.doi.org/10.1080/13658816.2023.2266495",
                "http://arxiv.org/abs/2310.09340v1",
                "http://arxiv.org/pdf/2310.09340v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09338v1",
            "title": "Uncertainty Quantification using Generative Approach",
            "updated": "2023-10-13T18:05:25Z",
            "published": "2023-10-13T18:05:25Z",
            "summary": "We present the Incremental Generative Monte Carlo (IGMC) method, designed to\nmeasure uncertainty in deep neural networks using deep generative approaches.\nIGMC iteratively trains generative models, adding their output to the dataset,\nto compute the posterior distribution of the expectation of a random variable.\nWe provide a theoretical guarantee of the convergence rate of IGMC relative to\nthe sample size and sampling depth. Due to its compatibility with deep\ngenerative approaches, IGMC is adaptable to both neural network classification\nand regression tasks. We empirically study the behavior of IGMC on the MNIST\ndigit classification task.",
            "author": [
                "Yunsheng Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09338v1",
                "http://arxiv.org/pdf/2310.09338v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09336v2",
            "title": "Compositional Abilities Emerge Multiplicatively: Exploring Diffusion\n  Models on a Synthetic Task",
            "updated": "2023-11-14T19:53:26Z",
            "published": "2023-10-13T18:00:59Z",
            "summary": "Modern generative models exhibit unprecedented capabilities to generate\nextremely realistic data. However, given the inherent compositionality of the\nreal world, reliable use of these models in practical applications requires\nthat they exhibit the capability to compose a novel set of concepts to generate\noutputs not seen in the training data set. Prior work demonstrates that recent\ndiffusion models do exhibit intriguing compositional generalization abilities,\nbut also fail unpredictably. Motivated by this, we perform a controlled study\nfor understanding compositional generalization in conditional diffusion models\nin a synthetic setting, varying different attributes of the training data and\nmeasuring the model's ability to generate samples out-of-distribution. Our\nresults show: (i) the order in which the ability to generate samples from a\nconcept and compose them emerges is governed by the structure of the underlying\ndata-generating process; (ii) performance on compositional tasks exhibits a\nsudden \"emergence\" due to multiplicative reliance on the performance of\nconstituent tasks, partially explaining emergent phenomena seen in generative\nmodels; and (iii) composing concepts with lower frequency in the training data\nto generate out-of-distribution samples requires considerably more optimization\nsteps compared to generating in-distribution samples. Overall, our study lays a\nfoundation for understanding capabilities and compositionality in generative\nmodels from a data-centric perspective.",
            "author": [
                "Maya Okawa",
                "Ekdeep Singh Lubana",
                "Robert P. Dick",
                "Hidenori Tanaka"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09336v2",
                "http://arxiv.org/pdf/2310.09336v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09335v1",
            "title": "Statistical guarantees for stochastic Metropolis-Hastings",
            "updated": "2023-10-13T18:00:26Z",
            "published": "2023-10-13T18:00:26Z",
            "summary": "A Metropolis-Hastings step is widely used for gradient-based Markov chain\nMonte Carlo methods in uncertainty quantification. By calculating acceptance\nprobabilities on batches, a stochastic Metropolis-Hastings step saves\ncomputational costs, but reduces the effective sample size. We show that this\nobstacle can be avoided by a simple correction term. We study statistical\nproperties of the resulting stationary distribution of the chain if the\ncorrected stochastic Metropolis-Hastings approach is applied to sample from a\nGibbs posterior distribution in a nonparametric regression setting. Focusing on\ndeep neural network regression, we prove a PAC-Bayes oracle inequality which\nyields optimal contraction rates and we analyze the diameter and show high\ncoverage probability of the resulting credible sets. With a numerical example\nin a high-dimensional parameter space, we illustrate that credible sets and\ncontraction rates of the stochastic Metropolis-Hastings algorithm indeed behave\nsimilar to those obtained from the classical Metropolis-adjusted Langevin\nalgorithm.",
            "author": [
                "Sebastian Bieringer",
                "Gregor Kasieczka",
                "Maximilian F. Steffen",
                "Mathias Trabs"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09335v1",
                "http://arxiv.org/pdf/2310.09335v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09328v1",
            "title": "Exploring the Dependence of Gas Cooling and Heating Functions on the\n  Incident Radiation Field with Machine Learning",
            "updated": "2023-10-13T18:00:02Z",
            "published": "2023-10-13T18:00:02Z",
            "summary": "Gas cooling and heating functions play a crucial role in galaxy formation.\nBut, it is computationally expensive to exactly compute these functions in the\npresence of an incident radiation field. These computations can be greatly sped\nup by using interpolation tables of pre-computed values, at the expense of\nmaking significant and sometimes even unjustified approximations. Here we\nexplore the capacity of machine learning to approximate cooling and heating\nfunctions with a generalized radiation field. Specifically, we use the machine\nlearning algorithm XGBoost to predict cooling and heating functions calculated\nwith the photoionization code Cloudy at fixed metallicity, using different\ncombinations of photoionization rates as features. We perform a constrained\nquadratic fit in metallicity to enable a fair comparison with traditional\ninterpolation methods at arbitrary metallicity. We consider the relative\nimportance of various photoionization rates through both a principal component\nanalysis (PCA) and calculation of SHapley Additive exPlanation (SHAP) values\nfor our XGBoost models. We use feature importance information to select\ndifferent subsets of rates to use in model training. Our XGBoost models\noutperform a traditional interpolation approach at each fixed metallicity,\nregardless of feature selection. At arbitrary metallicity, we are able to\nreduce the frequency of the largest cooling and heating function errors\ncompared to an interpolation table. We find that the primary bottleneck to\nincreasing accuracy lies in accurately capturing the metallicity dependence.\nThis study demonstrates the potential of machine learning methods such as\nXGBoost to capture the non-linear behavior of cooling and heating functions.",
            "author": [
                "David Robinson",
                "Camille Avestruz",
                "Nickolay Y. Gnedin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09328v1",
                "http://arxiv.org/pdf/2310.09328v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09289v1",
            "title": "An Unbiased Look at Datasets for Visuo-Motor Pre-Training",
            "updated": "2023-10-13T17:59:02Z",
            "published": "2023-10-13T17:59:02Z",
            "summary": "Visual representation learning hold great promise for robotics, but is\nseverely hampered by the scarcity and homogeneity of robotics datasets. Recent\nworks address this problem by pre-training visual representations on\nlarge-scale but out-of-domain data (e.g., videos of egocentric interactions)\nand then transferring them to target robotics tasks. While the field is heavily\nfocused on developing better pre-training algorithms, we find that dataset\nchoice is just as important to this paradigm's success. After all, the\nrepresentation can only learn the structures or priors present in the\npre-training dataset. To this end, we flip the focus on algorithms, and instead\nconduct a dataset centric analysis of robotic pre-training. Our findings call\ninto question some common wisdom in the field. We observe that traditional\nvision datasets (like ImageNet, Kinetics and 100 Days of Hands) are\nsurprisingly competitive options for visuo-motor representation learning, and\nthat the pre-training dataset's image distribution matters more than its size.\nFinally, we show that common simulation benchmarks are not a reliable proxy for\nreal world performance and that simple regularization strategies can\ndramatically improve real world policy learning.\nhttps://data4robotics.github.io",
            "author": [
                "Sudeep Dasari",
                "Mohan Kumar Srirama",
                "Unnat Jain",
                "Abhinav Gupta"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09289v1",
                "http://arxiv.org/pdf/2310.09289v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09285v1",
            "title": "SAIR: Learning Semantic-aware Implicit Representation",
            "updated": "2023-10-13T17:52:16Z",
            "published": "2023-10-13T17:52:16Z",
            "summary": "Implicit representation of an image can map arbitrary coordinates in the\ncontinuous domain to their corresponding color values, presenting a powerful\ncapability for image reconstruction. Nevertheless, existing implicit\nrepresentation approaches only focus on building continuous appearance mapping,\nignoring the continuities of the semantic information across pixels. As a\nresult, they can hardly achieve desired reconstruction results when the\nsemantic information within input images is corrupted, for example, a large\nregion misses. To address the issue, we propose to learn semantic-aware\nimplicit representation (SAIR), that is, we make the implicit representation of\neach pixel rely on both its appearance and semantic information (\\eg, which\nobject does the pixel belong to). To this end, we propose a framework with two\nmodules: (1) building a semantic implicit representation (SIR) for a corrupted\nimage whose large regions miss. Given an arbitrary coordinate in the continuous\ndomain, we can obtain its respective text-aligned embedding indicating the\nobject the pixel belongs. (2) building an appearance implicit representation\n(AIR) based on the SIR. Given an arbitrary coordinate in the continuous domain,\nwe can reconstruct its color whether or not the pixel is missed in the input.\nWe validate the novel semantic-aware implicit representation method on the\nimage inpainting task, and the extensive experiments demonstrate that our\nmethod surpasses state-of-the-art approaches by a significant margin.",
            "author": [
                "Canyu Zhang",
                "Xiaoguang Li",
                "Qing Guo",
                "Song Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09285v1",
                "http://arxiv.org/pdf/2310.09285v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09278v1",
            "title": "Disentangled Latent Spaces Facilitate Data-Driven Auxiliary Learning",
            "updated": "2023-10-13T17:40:39Z",
            "published": "2023-10-13T17:40:39Z",
            "summary": "In deep learning, auxiliary objectives are often used to facilitate learning\nin situations where data is scarce, or the principal task is extremely complex.\nThis idea is primarily inspired by the improved generalization capability\ninduced by solving multiple tasks simultaneously, which leads to a more robust\nshared representation. Nevertheless, finding optimal auxiliary tasks that give\nrise to the desired improvement is a crucial problem that often requires\nhand-crafted solutions or expensive meta-learning approaches. In this paper, we\npropose a novel framework, dubbed Detaux, whereby a weakly supervised\ndisentanglement procedure is used to discover new unrelated classification\ntasks and the associated labels that can be exploited with the principal task\nin any Multi-Task Learning (MTL) model. The disentanglement procedure works at\na representation level, isolating a subspace related to the principal task,\nplus an arbitrary number of orthogonal subspaces. In the most disentangled\nsubspaces, through a clustering procedure, we generate the additional\nclassification tasks, and the associated labels become their representatives.\nSubsequently, the original data, the labels associated with the principal task,\nand the newly discovered ones can be fed into any MTL framework. Extensive\nvalidation on both synthetic and real data, along with various ablation\nstudies, demonstrate promising results, revealing the potential in what has\nbeen, so far, an unexplored connection between learning disentangled\nrepresentations and MTL. The code will be made publicly available upon\nacceptance.",
            "author": [
                "Geri Skenderi",
                "Luigi Capogrosso",
                "Andrea Toaiari",
                "Matteo Denitto",
                "Franco Fummi",
                "Simone Melzi",
                "Marco Cristani"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09278v1",
                "http://arxiv.org/pdf/2310.09278v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09277v1",
            "title": "A Hybrid Approach for Depression Classification: Random Forest-ANN\n  Ensemble on Motor Activity Signals",
            "updated": "2023-10-13T17:39:35Z",
            "published": "2023-10-13T17:39:35Z",
            "summary": "Regarding the rising number of people suffering from mental health illnesses\nin today's society, the importance of mental health cannot be overstated.\nWearable sensors, which are increasingly widely available, provide a potential\nway to track and comprehend mental health issues. These gadgets not only\nmonitor everyday activities but also continuously record vital signs like heart\nrate, perhaps providing information on a person's mental state. Recent research\nhas used these sensors in conjunction with machine learning methods to identify\npatterns relating to different mental health conditions, highlighting the\nimmense potential of this data beyond simple activity monitoring. In this\nresearch, we present a novel algorithm called the Hybrid Random forest - Neural\nnetwork that has been tailored to evaluate sensor data from depressed patients.\nOur method has a noteworthy accuracy of 80\\% when evaluated on a special\ndataset that included both unipolar and bipolar depressive patients as well as\nhealthy controls. The findings highlight the algorithm's potential for reliably\ndetermining a person's depression condition using sensor data, making a\nsubstantial contribution to the area of mental health diagnostics.",
            "author": [
                "Anket Patil",
                "Dhairya Shah",
                "Abhishek Shah",
                "Mokshit Gala"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09277v1",
                "http://arxiv.org/pdf/2310.09277v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "68T05"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09276v2",
            "title": "Transformer-based Multimodal Change Detection with Multitask Consistency\n  Constraints",
            "updated": "2023-10-21T12:14:17Z",
            "published": "2023-10-13T17:38:45Z",
            "summary": "Change detection plays a fundamental role in Earth observation for analyzing\ntemporal iterations over time. However, recent studies have largely neglected\nthe utilization of multimodal data that presents significant practical and\ntechnical advantages compared to single-modal approaches. This research focuses\non leveraging digital surface model (DSM) data and aerial images captured at\ndifferent times for detecting change beyond 2D. We observe that the current\nchange detection methods struggle with the multitask conflicts between semantic\nand height change detection tasks. To address this challenge, we propose an\nefficient Transformer-based network that learns shared representation between\ncross-dimensional inputs through cross-attention. It adopts a consistency\nconstraint to establish the multimodal relationship, which involves obtaining\npseudo change through height change thresholding and minimizing the difference\nbetween semantic and pseudo change within their overlapping regions. A\nDSM-to-image multimodal dataset encompassing three cities in the Netherlands\nwas constructed. It lays a new foundation for beyond-2D change detection from\ncross-dimensional inputs. Compared to five state-of-the-art change detection\nmethods, our model demonstrates consistent multitask superiority in terms of\nsemantic and height change detection. Furthermore, the consistency strategy can\nbe seamlessly adapted to the other methods, yielding promising improvements.",
            "author": [
                "Biyuan Liu",
                "Huaixin Chen",
                "Kun Li",
                "Michael Ying Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09276v2",
                "http://arxiv.org/pdf/2310.09276v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09270v1",
            "title": "Retro-fallback: retrosynthetic planning in an uncertain world",
            "updated": "2023-10-13T17:35:04Z",
            "published": "2023-10-13T17:35:04Z",
            "summary": "Retrosynthesis is the task of proposing a series of chemical reactions to\ncreate a desired molecule from simpler, buyable molecules. While previous works\nhave proposed algorithms to find optimal solutions for a range of metrics (e.g.\nshortest, lowest-cost), these works generally overlook the fact that we have\nimperfect knowledge of the space of possible reactions, meaning plans created\nby the algorithm may not work in a laboratory. In this paper we propose a novel\nformulation of retrosynthesis in terms of stochastic processes to account for\nthis uncertainty. We then propose a novel greedy algorithm called\nretro-fallback which maximizes the probability that at least one synthesis plan\ncan be executed in the lab. Using in-silico benchmarks we demonstrate that\nretro-fallback generally produces better sets of synthesis plans than the\npopular MCTS and retro* algorithms.",
            "author": [
                "Austin Tripp",
                "Krzysztof Maziarz",
                "Sarah Lewis",
                "Marwin Segler",
                "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09270v1",
                "http://arxiv.org/pdf/2310.09270v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09267v1",
            "title": "Genetic algorithms are strong baselines for molecule generation",
            "updated": "2023-10-13T17:25:11Z",
            "published": "2023-10-13T17:25:11Z",
            "summary": "Generating molecules, both in a directed and undirected fashion, is a huge\npart of the drug discovery pipeline. Genetic algorithms (GAs) generate\nmolecules by randomly modifying known molecules. In this paper we show that GAs\nare very strong algorithms for such tasks, outperforming many complicated\nmachine learning methods: a result which many researchers may find surprising.\nWe therefore propose insisting during peer review that new algorithms must have\nsome clear advantage over GAs, which we call the GA criterion. Ultimately our\nwork suggests that a lot of research in molecule generation should be\nre-assessed.",
            "author": [
                "Austin Tripp",
                "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09267v1",
                "http://arxiv.org/pdf/2310.09267v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.LG",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09266v1",
            "title": "User Inference Attacks on Large Language Models",
            "updated": "2023-10-13T17:24:52Z",
            "published": "2023-10-13T17:24:52Z",
            "summary": "Fine-tuning is a common and effective method for tailoring large language\nmodels (LLMs) to specialized tasks and applications. In this paper, we study\nthe privacy implications of fine-tuning LLMs on user data. To this end, we\ndefine a realistic threat model, called user inference, wherein an attacker\ninfers whether or not a user's data was used for fine-tuning. We implement\nattacks for this threat model that require only a small set of samples from a\nuser (possibly different from the samples used for training) and black-box\naccess to the fine-tuned LLM. We find that LLMs are susceptible to user\ninference attacks across a variety of fine-tuning datasets, at times with near\nperfect attack success rates. Further, we investigate which properties make\nusers vulnerable to user inference, finding that outlier users (i.e. those with\ndata distributions sufficiently different from other users) and users who\ncontribute large quantities of data are most susceptible to attack. Finally, we\nexplore several heuristics for mitigating privacy attacks. We find that\ninterventions in the training algorithm, such as batch or per-example gradient\nclipping and early stopping fail to prevent user inference. However, limiting\nthe number of fine-tuning samples from a single user can reduce attack\neffectiveness, albeit at the cost of reducing the total amount of fine-tuning\ndata.",
            "author": [
                "Nikhil Kandpal",
                "Krishna Pillutla",
                "Alina Oprea",
                "Peter Kairouz",
                "Christopher A. Choquette-Choo",
                "Zheng Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09266v1",
                "http://arxiv.org/pdf/2310.09266v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09265v1",
            "title": "PromptRE: Weakly-Supervised Document-Level Relation Extraction via\n  Prompting-Based Data Programming",
            "updated": "2023-10-13T17:23:17Z",
            "published": "2023-10-13T17:23:17Z",
            "summary": "Relation extraction aims to classify the relationships between two entities\ninto pre-defined categories. While previous research has mainly focused on\nsentence-level relation extraction, recent studies have expanded the scope to\ndocument-level relation extraction. Traditional relation extraction methods\nheavily rely on human-annotated training data, which is time-consuming and\nlabor-intensive. To mitigate the need for manual annotation, recent\nweakly-supervised approaches have been developed for sentence-level relation\nextraction while limited work has been done on document-level relation\nextraction. Weakly-supervised document-level relation extraction faces\nsignificant challenges due to an imbalanced number \"no relation\" instances and\nthe failure of directly probing pretrained large language models for document\nrelation extraction. To address these challenges, we propose PromptRE, a novel\nweakly-supervised document-level relation extraction method that combines\nprompting-based techniques with data programming. Furthermore, PromptRE\nincorporates the label distribution and entity types as prior knowledge to\nimprove the performance. By leveraging the strengths of both prompting and data\nprogramming, PromptRE achieves improved performance in relation classification\nand effectively handles the \"no relation\" problem. Experimental results on\nReDocRED, a benchmark dataset for document-level relation extraction,\ndemonstrate the superiority of PromptRE over baseline approaches.",
            "author": [
                "Chufan Gao",
                "Xulin Fan",
                "Jimeng Sun",
                "Xuan Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09265v1",
                "http://arxiv.org/pdf/2310.09265v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09259v2",
            "title": "QUIK: Towards End-to-End 4-Bit Inference on Generative Large Language\n  Models",
            "updated": "2023-11-02T14:26:57Z",
            "published": "2023-10-13T17:15:05Z",
            "summary": "Large Language Models (LLMs) from the GPT family have become extremely\npopular, leading to a race towards reducing their inference costs to allow for\nefficient local computation. Yet, the vast majority of existing work focuses on\nweight-only quantization, which can reduce runtime costs in the memory-bound\none-token-at-a-time generative setting, but does not address them in\ncompute-bound scenarios, such as batched inference or prompt processing. In\nthis paper, we address the general quantization problem, where both weights and\nactivations should be quantized. We show, for the first time, that the majority\nof inference computations for large generative models such as LLaMA, OPT, and\nFalcon can be performed with both weights and activations being cast to 4 bits,\nin a way that leads to practical speedups, while at the same time maintaining\ngood accuracy. We achieve this via a hybrid quantization strategy called QUIK,\nwhich compresses most of the weights and activations to 4-bit, while keeping\nsome outlier weights and activations in higher-precision. The key feature of\nour scheme is that it is designed with computational efficiency in mind: we\nprovide GPU kernels matching the QUIK format with highly-efficient layer-wise\nruntimes, which lead to practical end-to-end throughput improvements of up to\n3.4x relative to FP16 execution. We provide detailed studies for models from\nthe OPT, LLaMA-2 and Falcon families, as well as a first instance of accurate\ninference using quantization plus 2:4 sparsity. Code is available at:\nhttps://github.com/IST-DASLab/QUIK.",
            "author": [
                "Saleh Ashkboos",
                "Ilia Markov",
                "Elias Frantar",
                "Tingxuan Zhong",
                "Xincheng Wang",
                "Jie Ren",
                "Torsten Hoefler",
                "Dan Alistarh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09259v2",
                "http://arxiv.org/pdf/2310.09259v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09257v1",
            "title": "A SIMPLE Approach to Provably Reconstruct Ising Model with Global\n  Optimality",
            "updated": "2023-10-13T17:13:46Z",
            "published": "2023-10-13T17:13:46Z",
            "summary": "Reconstruction of interaction network between random events is a critical\nproblem arising from statistical physics and politics to sociology, biology,\nand psychology, and beyond. The Ising model lays the foundation for this\nreconstruction process, but finding the underlying Ising model from the least\namount of observed samples in a computationally efficient manner has been\nhistorically challenging for half a century. By using the idea of sparsity\nlearning, we present a approach named SIMPLE that has a dominant sample\ncomplexity from theoretical limit. Furthermore, a tuning-free algorithm is\ndeveloped to give a statistically consistent solution of SIMPLE in polynomial\ntime with high probability. On extensive benchmarked cases, the SIMPLE approach\nprovably reconstructs underlying Ising models with global optimality. The\napplication on the U.S. senators voting in the last six congresses reveals that\nboth the Republicans and Democrats noticeably assemble in each congresses;\ninterestingly, the assembling of Democrats is particularly pronounced in the\nlatest congress.",
            "author": [
                "Junxian Zhu",
                "Xuanyu Chen",
                "Jin Zhu",
                "Xueqin Wang",
                "Heping Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09257v1",
                "http://arxiv.org/pdf/2310.09257v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09256v1",
            "title": "Political claim identification and categorization in a multilingual\n  setting: First experiments",
            "updated": "2023-10-13T17:13:00Z",
            "published": "2023-10-13T17:13:00Z",
            "summary": "The identification and classification of political claims is an important\nstep in the analysis of political newspaper reports; however, resources for\nthis task are few and far between. This paper explores different strategies for\nthe cross-lingual projection of political claims analysis. We conduct\nexperiments on a German dataset, DebateNet2.0, covering the policy debate\nsparked by the 2015 refugee crisis. Our evaluation involves two tasks (claim\nidentification and categorization), three languages (German, English, and\nFrench) and two methods (machine translation -- the best method in our\nexperiments -- and multilingual embeddings).",
            "author": [
                "Urs Zaberer",
                "Sebastian Pad\u00f3",
                "Gabriella Lapesa"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09256v1",
                "http://arxiv.org/pdf/2310.09256v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09254v2",
            "title": "Generative Entropic Neural Optimal Transport To Map Within and Across\n  Spaces",
            "updated": "2023-10-16T10:16:21Z",
            "published": "2023-10-13T17:12:04Z",
            "summary": "Learning measure-to-measure mappings is a crucial task in machine learning,\nfeatured prominently in generative modeling. Recent years have witnessed a\nsurge of techniques that draw inspiration from optimal transport (OT) theory.\nCombined with neural network models, these methods collectively known as\n\\textit{Neural OT} use optimal transport as an inductive bias: such mappings\nshould be optimal w.r.t. a given cost function, in the sense that they are able\nto move points in a thrifty way, within (by minimizing displacements) or across\nspaces (by being isometric). This principle, while intuitive, is often\nconfronted with several practical challenges that require adapting the OT\ntoolbox: cost functions other than the squared-Euclidean cost can be\nchallenging to handle, the deterministic formulation of Monge maps leaves\nlittle flexibility, mapping across incomparable spaces raises multiple\nchallenges, while the mass conservation constraint inherent to OT can provide\ntoo much credit to outliers. While each of these mismatches between practice\nand theory has been addressed independently in various works, we propose in\nthis work an elegant framework to unify them, called \\textit{generative\nentropic neural optimal transport} (GENOT). GENOT can accommodate any cost\nfunction; handles randomness using conditional generative models; can map\npoints across incomparable spaces, and can be used as an \\textit{unbalanced}\nsolver. We evaluate our approach through experiments conducted on various\nsynthetic datasets and demonstrate its practicality in single-cell biology. In\nthis domain, GENOT proves to be valuable for tasks such as modeling cell\ndevelopment, predicting cellular responses to drugs, and translating between\ndifferent data modalities of cells.",
            "author": [
                "Dominik Klein",
                "Th\u00e9o Uscidda",
                "Fabian Theis",
                "Marco Cuturi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09254v2",
                "http://arxiv.org/pdf/2310.09254v2"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09250v1",
            "title": "It's an Alignment, Not a Trade-off: Revisiting Bias and Variance in Deep\n  Models",
            "updated": "2023-10-13T17:06:34Z",
            "published": "2023-10-13T17:06:34Z",
            "summary": "Classical wisdom in machine learning holds that the generalization error can\nbe decomposed into bias and variance, and these two terms exhibit a\n\\emph{trade-off}. However, in this paper, we show that for an ensemble of deep\nlearning based classification models, bias and variance are \\emph{aligned} at a\nsample level, where squared bias is approximately \\emph{equal} to variance for\ncorrectly classified sample points. We present empirical evidence confirming\nthis phenomenon in a variety of deep learning models and datasets. Moreover, we\nstudy this phenomenon from two theoretical perspectives: calibration and neural\ncollapse. We first show theoretically that under the assumption that the models\nare well calibrated, we can observe the bias-variance alignment. Second,\nstarting from the picture provided by the neural collapse theory, we show an\napproximate correlation between bias and variance.",
            "author": [
                "Lin Chen",
                "Michal Lukasik",
                "Wittawat Jitkrittum",
                "Chong You",
                "Sanjiv Kumar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09250v1",
                "http://arxiv.org/pdf/2310.09250v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09247v1",
            "title": "Hypernymy Understanding Evaluation of Text-to-Image Models via WordNet\n  Hierarchy",
            "updated": "2023-10-13T16:53:25Z",
            "published": "2023-10-13T16:53:25Z",
            "summary": "Text-to-image synthesis has recently attracted widespread attention due to\nrapidly improving quality and numerous practical applications. However, the\nlanguage understanding capabilities of text-to-image models are still poorly\nunderstood, which makes it difficult to reason about prompt formulations that a\ngiven model would understand well. In this work, we measure the capability of\npopular text-to-image models to understand $\\textit{hypernymy}$, or the \"is-a\"\nrelation between words. We design two automatic metrics based on the WordNet\nsemantic hierarchy and existing image classifiers pretrained on ImageNet. These\nmetrics both enable broad quantitative comparison of linguistic capabilities\nfor text-to-image models and offer a way of finding fine-grained qualitative\ndifferences, such as words that are unknown to models and thus are difficult\nfor them to draw. We comprehensively evaluate popular text-to-image models,\nincluding GLIDE, Latent Diffusion, and Stable Diffusion, showing how our\nmetrics can provide a better understanding of the individual strengths and\nweaknesses of these models.",
            "author": [
                "Anton Baryshnikov",
                "Max Ryabinin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09247v1",
                "http://arxiv.org/pdf/2310.09247v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09241v1",
            "title": "Precedent-Enhanced Legal Judgment Prediction with LLM and Domain-Model\n  Collaboration",
            "updated": "2023-10-13T16:47:20Z",
            "published": "2023-10-13T16:47:20Z",
            "summary": "Legal Judgment Prediction (LJP) has become an increasingly crucial task in\nLegal AI, i.e., predicting the judgment of the case in terms of case fact\ndescription. Precedents are the previous legal cases with similar facts, which\nare the basis for the judgment of the subsequent case in national legal\nsystems. Thus, it is worthwhile to explore the utilization of precedents in the\nLJP. Recent advances in deep learning have enabled a variety of techniques to\nbe used to solve the LJP task. These can be broken down into two categories:\nlarge language models (LLMs) and domain-specific models. LLMs are capable of\ninterpreting and generating complex natural language, while domain models are\nefficient in learning task-specific information. In this paper, we propose the\nprecedent-enhanced LJP framework (PLJP), a system that leverages the strength\nof both LLM and domain models in the context of precedents. Specifically, the\ndomain models are designed to provide candidate labels and find the proper\nprecedents efficiently, and the large models will make the final prediction\nwith an in-context precedents comprehension. Experiments on the real-world\ndataset demonstrate the effectiveness of our PLJP. Moreover, our work shows a\npromising direction for LLM and domain-model collaboration that can be\ngeneralized to other vertical domains.",
            "author": [
                "Yiquan Wu",
                "Siying Zhou",
                "Yifei Liu",
                "Weiming Lu",
                "Xiaozhong Liu",
                "Yating Zhang",
                "Changlong Sun",
                "Fei Wu",
                "Kun Kuang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09241v1",
                "http://arxiv.org/pdf/2310.09241v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09238v2",
            "title": "BanglaNLP at BLP-2023 Task 2: Benchmarking different Transformer Models\n  for Sentiment Analysis of Bangla Social Media Posts",
            "updated": "2023-10-18T03:51:38Z",
            "published": "2023-10-13T16:46:38Z",
            "summary": "Bangla is the 7th most widely spoken language globally, with a staggering 234\nmillion native speakers primarily hailing from India and Bangladesh. This\nmorphologically rich language boasts a rich literary tradition, encompassing\ndiverse dialects and language-specific challenges. Despite its linguistic\nrichness and history, Bangla remains categorized as a low-resource language\nwithin the natural language processing (NLP) and speech community. This paper\npresents our submission to Task 2 (Sentiment Analysis of Bangla Social Media\nPosts) of the BLP Workshop. We experiment with various Transformer-based\narchitectures to solve this task. Our quantitative results show that transfer\nlearning really helps in better learning of the models in this low-resource\nlanguage scenario. This becomes evident when we further finetune a model which\nhas already been finetuned on twitter data for sentiment analysis task and that\nfinetuned model performs the best among all other models. We also perform a\ndetailed error analysis where we find some instances where ground truth labels\nneed to be relooked at. We obtain a micro-F1 of 67.02\\% on the test set and our\nperformance in this shared task is ranked at 21 in the leaderboard.",
            "author": [
                "Saumajit Saha",
                "Albert Nanda"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09238v2",
                "http://arxiv.org/pdf/2310.09238v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09237v1",
            "title": "Evaluating Machine Perception of Indigeneity: An Analysis of ChatGPT's\n  Perceptions of Indigenous Roles in Diverse Scenarios",
            "updated": "2023-10-13T16:46:23Z",
            "published": "2023-10-13T16:46:23Z",
            "summary": "Large Language Models (LLMs), like ChatGPT, are fundamentally tools trained\non vast data, reflecting diverse societal impressions. This paper aims to\ninvestigate LLMs' self-perceived bias concerning indigeneity when simulating\nscenarios of indigenous people performing various roles. Through generating and\nanalyzing multiple scenarios, this work offers a unique perspective on how\ntechnology perceives and potentially amplifies societal biases related to\nindigeneity in social computing. The findings offer insights into the broader\nimplications of indigeneity in critical computing.",
            "author": [
                "Cecilia Delgado Solorzano",
                "Carlos Toxtli Hernandez"
            ],
            "link": [
                "http://dx.doi.org/10.13140/RG.2.2.30617.39520",
                "http://arxiv.org/abs/2310.09237v1",
                "http://arxiv.org/pdf/2310.09237v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09236v1",
            "title": "Time CNN and Graph Convolution Network for Epileptic Spike Detection in\n  MEG Data",
            "updated": "2023-10-13T16:40:29Z",
            "published": "2023-10-13T16:40:29Z",
            "summary": "Magnetoencephalography (MEG) recordings of patients with epilepsy exhibit\nspikes, a typical biomarker of the pathology. Detecting those spikes allows\naccurate localization of brain regions triggering seizures. Spike detection is\noften performed manually. However, it is a burdensome and error prone task due\nto the complexity of MEG data. To address this problem, we propose a 1D\ntemporal convolutional neural network (Time CNN) coupled with a graph\nconvolutional network (GCN) to classify short time frames of MEG recording as\ncontaining a spike or not. Compared to other recent approaches, our models have\nfewer parameters to train and we propose to use a GCN to account for MEG\nsensors spatial relationships. Our models produce clinically relevant results\nand outperform deep learning-based state-of-the-art methods reaching a\nclassification f1-score of 76.7% on a balanced dataset and of 25.5% on a\nrealistic, highly imbalanced dataset, for the spike class.",
            "author": [
                "Pauline Mouches",
                "Thibaut Dejean",
                "Julien Jung",
                "Romain Bouet",
                "Carole Lartizien",
                "Romain Quentin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09236v1",
                "http://arxiv.org/pdf/2310.09236v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09233v1",
            "title": "AgentCF: Collaborative Learning with Autonomous Language Agents for\n  Recommender Systems",
            "updated": "2023-10-13T16:37:14Z",
            "published": "2023-10-13T16:37:14Z",
            "summary": "Recently, there has been an emergence of employing LLM-powered agents as\nbelievable human proxies, based on their remarkable decision-making capability.\nHowever, existing studies mainly focus on simulating human dialogue. Human\nnon-verbal behaviors, such as item clicking in recommender systems, although\nimplicitly exhibiting user preferences and could enhance the modeling of users,\nhave not been deeply explored. The main reasons lie in the gap between language\nmodeling and behavior modeling, as well as the incomprehension of LLMs about\nuser-item relations.\n  To address this issue, we propose AgentCF for simulating user-item\ninteractions in recommender systems through agent-based collaborative\nfiltering. We creatively consider not only users but also items as agents, and\ndevelop a collaborative learning approach that optimizes both kinds of agents\ntogether. Specifically, at each time step, we first prompt the user and item\nagents to interact autonomously. Then, based on the disparities between the\nagents' decisions and real-world interaction records, user and item agents are\nprompted to reflect on and adjust the misleading simulations collaboratively,\nthereby modeling their two-sided relations. The optimized agents can also\npropagate their preferences to other agents in subsequent interactions,\nimplicitly capturing the collaborative filtering idea. Overall, the optimized\nagents exhibit diverse interaction behaviors within our framework, including\nuser-item, user-user, item-item, and collective interactions. The results show\nthat these agents can demonstrate personalized behaviors akin to those of\nreal-world individuals, sparking the development of next-generation user\nbehavior simulation.",
            "author": [
                "Junjie Zhang",
                "Yupeng Hou",
                "Ruobing Xie",
                "Wenqi Sun",
                "Julian McAuley",
                "Wayne Xin Zhao",
                "Leyu Lin",
                "Ji-Rong Wen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09233v1",
                "http://arxiv.org/pdf/2310.09233v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09229v1",
            "title": "Insuring Smiles: Predicting routine dental coverage using Spark ML",
            "updated": "2023-10-13T16:31:51Z",
            "published": "2023-10-13T16:31:51Z",
            "summary": "Finding suitable health insurance coverage can be challenging for individuals\nand small enterprises in the USA. The Health Insurance Exchange Public Use\nFiles (Exchange PUFs) dataset provided by CMS offers valuable information on\nhealth and dental policies [1]. In this paper, we leverage machine learning\nalgorithms to predict if a health insurance plan covers routine dental services\nfor adults. By analyzing plan type, region, deductibles, out-of-pocket\nmaximums, and copayments, we employ Logistic Regression, Decision Tree, Random\nForest, Gradient Boost, Factorization Model and Support Vector Machine\nalgorithms. Our goal is to provide a clinical strategy for individuals and\nfamilies to select the most suitable insurance plan based on income and\nexpenses.",
            "author": [
                "Aishwarya Gupta",
                "Rahul S. Bhogale",
                "Priyanka Thota",
                "Prathushkumar Dathuri",
                "Jongwook Woo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09229v1",
                "http://arxiv.org/pdf/2310.09229v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09222v1",
            "title": "Fast & Efficient Learning of Bayesian Networks from Data: Knowledge\n  Discovery and Causality",
            "updated": "2023-10-13T16:20:20Z",
            "published": "2023-10-13T16:20:20Z",
            "summary": "Structure learning is essential for Bayesian networks (BNs) as it uncovers\ncausal relationships, and enables knowledge discovery, predictions, inferences,\nand decision-making under uncertainty. Two novel algorithms, FSBN and SSBN,\nbased on the PC algorithm, employ local search strategy and conditional\nindependence tests to learn the causal network structure from data. They\nincorporate d-separation to infer additional topology information, prioritize\nconditioning sets, and terminate the search immediately and efficiently. FSBN\nachieves up to 52% computation cost reduction, while SSBN surpasses it with a\nremarkable 72% reduction for a 200-node network. SSBN demonstrates further\nefficiency gains due to its intelligent strategy. Experimental studies show\nthat both algorithms match the induction quality of the PC algorithm while\nsignificantly reducing computation costs. This enables them to offer\ninterpretability and adaptability while reducing the computational burden,\nmaking them valuable for various applications in big data analytics.",
            "author": [
                "Minn Sein",
                "Fu Shunkai"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09222v1",
                "http://arxiv.org/pdf/2310.09222v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09213v1",
            "title": "Unseen Image Synthesis with Diffusion Models",
            "updated": "2023-10-13T16:07:31Z",
            "published": "2023-10-13T16:07:31Z",
            "summary": "While the current trend in the generative field is scaling up towards larger\nmodels and more training data for generalized domain representations, we go the\nopposite direction in this work by synthesizing unseen domain images without\nadditional training. We do so via latent sampling and geometric optimization\nusing pre-trained and frozen Denoising Diffusion Probabilistic Models (DDPMs)\non single-domain datasets. Our key observation is that DDPMs pre-trained even\njust on single-domain images are already equipped with sufficient\nrepresentation abilities to reconstruct arbitrary images from the inverted\nlatent encoding following bi-directional deterministic diffusion and denoising\ntrajectories. This motivates us to investigate the statistical and geometric\nbehaviors of the Out-Of-Distribution (OOD) samples from unseen image domains in\nthe latent spaces along the denoising chain. Notably, we theoretically and\nempirically show that the inverted OOD samples also establish Gaussians that\nare distinguishable from the original In-Domain (ID) samples in the\nintermediate latent spaces, which allows us to sample from them directly.\nGeometrical domain-specific and model-dependent information of the unseen\nsubspace (e.g., sample-wise distance and angles) is used to further optimize\nthe sampled OOD latent encodings from the estimated Gaussian prior. We conduct\nextensive analysis and experiments using pre-trained diffusion models (DDPM,\niDDPM) on different datasets (AFHQ, CelebA-HQ, LSUN-Church, and LSUN-Bedroom),\nproving the effectiveness of this novel perspective to explore and re-think the\ndiffusion models' data synthesis generalization ability.",
            "author": [
                "Ye Zhu",
                "Yu Wu",
                "Zhiwei Deng",
                "Olga Russakovsky",
                "Yan Yan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09213v1",
                "http://arxiv.org/pdf/2310.09213v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09210v1",
            "title": "Regularization-Based Methods for Ordinal Quantification",
            "updated": "2023-10-13T16:04:06Z",
            "published": "2023-10-13T16:04:06Z",
            "summary": "Quantification, i.e., the task of training predictors of the class prevalence\nvalues in sets of unlabeled data items, has received increased attention in\nrecent years. However, most quantification research has concentrated on\ndeveloping algorithms for binary and multiclass problems in which the classes\nare not ordered. Here, we study the ordinal case, i.e., the case in which a\ntotal order is defined on the set of n>2 classes. We give three main\ncontributions to this field. First, we create and make available two datasets\nfor ordinal quantification (OQ) research that overcome the inadequacies of the\npreviously available ones. Second, we experimentally compare the most important\nOQ algorithms proposed in the literature so far. To this end, we bring together\nalgorithms proposed by authors from very different research fields, such as\ndata mining and astrophysics, who were unaware of each others' developments.\nThird, we propose a novel class of regularized OQ algorithms, which outperforms\nexisting algorithms in our experiments. The key to this gain in performance is\nthat our regularization prevents ordinally implausible estimates, assuming that\nordinal distributions tend to be smooth in practice. We informally verify this\nassumption for several real-world applications.",
            "author": [
                "Mirko Bunse",
                "Alejandro Moreo",
                "Fabrizio Sebastiani",
                "Martin Senz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09210v1",
                "http://arxiv.org/pdf/2310.09210v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09203v1",
            "title": "SiamAF: Learning Shared Information from ECG and PPG Signals for Robust\n  Atrial Fibrillation Detection",
            "updated": "2023-10-13T15:48:24Z",
            "published": "2023-10-13T15:48:24Z",
            "summary": "Atrial fibrillation (AF) is the most common type of cardiac arrhythmia. It is\nassociated with an increased risk of stroke, heart failure, and other\ncardiovascular complications, but can be clinically silent. Passive AF\nmonitoring with wearables may help reduce adverse clinical outcomes related to\nAF. Detecting AF in noisy wearable data poses a significant challenge, leading\nto the emergence of various deep learning techniques. Previous deep learning\nmodels learn from a single modality, either electrocardiogram (ECG) or\nphotoplethysmography (PPG) signals. However, deep learning models often\nstruggle to learn generalizable features and rely on features that are more\nsusceptible to corruption from noise, leading to sub-optimal performances in\ncertain scenarios, especially with low-quality signals. Given the increasing\navailability of ECG and PPG signal pairs from wearables and bedside monitors,\nwe propose a new approach, SiamAF, leveraging a novel Siamese network\narchitecture and joint learning loss function to learn shared information from\nboth ECG and PPG signals. At inference time, the proposed model is able to\npredict AF from either PPG or ECG and outperforms baseline methods on three\nexternal test sets. It learns medically relevant features as a result of our\nnovel architecture design. The proposed model also achieves comparable\nperformance to traditional learning regimes while requiring much fewer training\nlabels, providing a potential approach to reduce future reliance on manual\nlabeling.",
            "author": [
                "Zhicheng Guo",
                "Cheng Ding",
                "Duc H. Do",
                "Amit Shah",
                "Randall J. Lee",
                "Xiao Hu",
                "Cynthia Rudin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09203v1",
                "http://arxiv.org/pdf/2310.09203v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09202v1",
            "title": "Graph Condensation via Eigenbasis Matching",
            "updated": "2023-10-13T15:48:12Z",
            "published": "2023-10-13T15:48:12Z",
            "summary": "The increasing amount of graph data places requirements on the efficiency and\nscalability of graph neural networks (GNNs), despite their effectiveness in\nvarious graph-related applications. Recently, the emerging graph condensation\n(GC) sheds light on reducing the computational cost of GNNs from a data\nperspective. It aims to replace the real large graph with a significantly\nsmaller synthetic graph so that GNNs trained on both graphs exhibit comparable\nperformance. However, our empirical investigation reveals that existing GC\nmethods suffer from poor generalization, i.e., different GNNs trained on the\nsame synthetic graph have obvious performance gaps. What factors hinder the\ngeneralization of GC and how can we mitigate it? To answer this question, we\ncommence with a detailed analysis and observe that GNNs will inject spectrum\nbias into the synthetic graph, resulting in a distribution shift. To tackle\nthis issue, we propose eigenbasis matching for spectrum-free graph\ncondensation, named GCEM, which has two key steps: First, GCEM matches the\neigenbasis of the real and synthetic graphs, rather than the graph structure,\nwhich eliminates the spectrum bias of GNNs. Subsequently, GCEM leverages the\nspectrum of the real graph and the synthetic eigenbasis to construct the\nsynthetic graph, thereby preserving the essential structural information. We\ntheoretically demonstrate that the synthetic graph generated by GCEM maintains\nthe spectral similarity, i.e., total variation, of the real graph. Extensive\nexperiments conducted on five graph datasets verify that GCEM not only achieves\nstate-of-the-art performance over baselines but also significantly narrows the\nperformance gaps between different GNNs.",
            "author": [
                "Yang Liu",
                "Deyu Bo",
                "Chuan Shi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09202v1",
                "http://arxiv.org/pdf/2310.09202v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09196v2",
            "title": "A 4-approximation algorithm for min max correlation clustering",
            "updated": "2023-10-30T09:15:41Z",
            "published": "2023-10-13T15:42:55Z",
            "summary": "We introduce a lower bounding technique for the min max correlation\nclustering problem and, based on this technique, a combinatorial\n4-approximation algorithm for complete graphs. This improves upon the previous\nbest known approximation guarantees of 5, using a linear program formulation\n(Kalhan et al., 2019), and 40, for a combinatorial algorithm (Davies et al.,\n2023). We extend this algorithm by a greedy joining heuristic and show\nempirically that it improves the state of the art in solution quality and\nruntime on several benchmark datasets.",
            "author": [
                "Holger Heidrich",
                "Jannik Irmai",
                "Bjoern Andres"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09196v2",
                "http://arxiv.org/pdf/2310.09196v2"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.DM",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09194v1",
            "title": "Variational autoencoder with weighted samples for high-dimensional\n  non-parametric adaptive importance sampling",
            "updated": "2023-10-13T15:40:55Z",
            "published": "2023-10-13T15:40:55Z",
            "summary": "Probability density function estimation with weighted samples is the main\nfoundation of all adaptive importance sampling algorithms. Classically, a\ntarget distribution is approximated either by a non-parametric model or within\na parametric family. However, these models suffer from the curse of\ndimensionality or from their lack of flexibility. In this contribution, we\nsuggest to use as the approximating model a distribution parameterised by a\nvariational autoencoder. We extend the existing framework to the case of\nweighted samples by introducing a new objective function. The flexibility of\nthe obtained family of distributions makes it as expressive as a non-parametric\nmodel, and despite the very high number of parameters to estimate, this family\nis much more efficient in high dimension than the classical Gaussian or\nGaussian mixture families. Moreover, in order to add flexibility to the model\nand to be able to learn multimodal distributions, we consider a learnable prior\ndistribution for the variational autoencoder latent variables. We also\nintroduce a new pre-training procedure for the variational autoencoder to find\ngood starting weights of the neural networks to prevent as much as possible the\nposterior collapse phenomenon to happen. At last, we explicit how the resulting\ndistribution can be combined with importance sampling, and we exploit the\nproposed procedure in existing adaptive importance sampling algorithms to draw\npoints from a target distribution and to estimate a rare event probability in\nhigh dimension on two multimodal problems.",
            "author": [
                "Julien Demange-Chryst",
                "Fran\u00e7ois Bachoc",
                "J\u00e9r\u00f4me Morio",
                "Timoth\u00e9 Krauth"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09194v1",
                "http://arxiv.org/pdf/2310.09194v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09322v1",
            "title": "A Note on Analyzing the Stability of Oscillator Ising Machines",
            "updated": "2023-10-13T15:38:47Z",
            "published": "2023-10-13T15:38:47Z",
            "summary": "The rich non-linear dynamics of the coupled oscillators (under second\nharmonic injection) can be leveraged to solve computationally hard problems in\ncombinatorial optimization such as finding the ground state of the Ising\nHamiltonian. While prior work on the stability of the so-called Oscillator\nIsing Machines (OIMs) has used the linearization method, in this letter, we\npresent a complementary method to analyze stability using the second order\nderivative test of the energy / cost function. We establish the equivalence\nbetween the two methods, thus augmenting the tool kit for the design and\nimplementation of OIMs.",
            "author": [
                "Mohammad Khairul Bashar",
                "Zongli Lin",
                "Nikhil Shukla"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09322v1",
                "http://arxiv.org/pdf/2310.09322v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.ET",
                "math.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09192v1",
            "title": "Does Graph Distillation See Like Vision Dataset Counterpart?",
            "updated": "2023-10-13T15:36:48Z",
            "published": "2023-10-13T15:36:48Z",
            "summary": "Training on large-scale graphs has achieved remarkable results in graph\nrepresentation learning, but its cost and storage have attracted increasing\nconcerns. Existing graph condensation methods primarily focus on optimizing the\nfeature matrices of condensed graphs while overlooking the impact of the\nstructure information from the original graphs. To investigate the impact of\nthe structure information, we conduct analysis from the spectral domain and\nempirically identify substantial Laplacian Energy Distribution (LED) shifts in\nprevious works. Such shifts lead to poor performance in cross-architecture\ngeneralization and specific tasks, including anomaly detection and link\nprediction. In this paper, we propose a novel Structure-broadcasting Graph\nDataset Distillation (SGDD) scheme for broadcasting the original structure\ninformation to the generation of the synthetic one, which explicitly prevents\noverlooking the original structure information. Theoretically, the synthetic\ngraphs by SGDD are expected to have smaller LED shifts than previous works,\nleading to superior performance in both cross-architecture settings and\nspecific tasks. We validate the proposed SGDD across 9 datasets and achieve\nstate-of-the-art results on all of them: for example, on the YelpChi dataset,\nour approach maintains 98.6% test accuracy of training on the original graph\ndataset with 1,000 times saving on the scale of the graph. Moreover, we\nempirically evaluate there exist 17.6% ~ 31.4% reductions in LED shift crossing\n9 datasets. Extensive experiments and analysis verify the effectiveness and\nnecessity of the proposed designs. The code is available in the GitHub\nrepository: https://github.com/RingBDStack/SGDD.",
            "author": [
                "Beining Yang",
                "Kai Wang",
                "Qingyun Sun",
                "Cheng Ji",
                "Xingcheng Fu",
                "Hao Tang",
                "Yang You",
                "Jianxin Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09192v1",
                "http://arxiv.org/pdf/2310.09192v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09183v2",
            "title": "PRIOR: Personalized Prior for Reactivating the Information Overlooked in\n  Federated Learning",
            "updated": "2023-11-10T09:53:32Z",
            "published": "2023-10-13T15:21:25Z",
            "summary": "Classical federated learning (FL) enables training machine learning models\nwithout sharing data for privacy preservation, but heterogeneous data\ncharacteristic degrades the performance of the localized model. Personalized FL\n(PFL) addresses this by synthesizing personalized models from a global model\nvia training on local data. Such a global model may overlook the specific\ninformation that the clients have been sampled. In this paper, we propose a\nnovel scheme to inject personalized prior knowledge into the global model in\neach client, which attempts to mitigate the introduced incomplete information\nproblem in PFL. At the heart of our proposed approach is a framework, the PFL\nwith Bregman Divergence (pFedBreD), decoupling the personalized prior from the\nlocal objective function regularized by Bregman divergence for greater\nadaptability in personalized scenarios. We also relax the mirror descent (RMD)\nto extract the prior explicitly to provide optional strategies. Additionally,\nour pFedBreD is backed up by a convergence analysis. Sufficient experiments\ndemonstrate that our method reaches the state-of-the-art performances on 5\ndatasets and outperforms other methods by up to 3.5% across 8 benchmarks.\nExtensive analyses verify the robustness and necessity of proposed designs.",
            "author": [
                "Mingjia Shi",
                "Yuhao Zhou",
                "Kai Wang",
                "Huaizheng Zhang",
                "Shudong Huang",
                "Qing Ye",
                "Jiangcheng Lv"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09183v2",
                "http://arxiv.org/pdf/2310.09183v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DC",
                "68T07",
                "I.2.11"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09175v1",
            "title": "Shedding light on social learning",
            "updated": "2023-10-13T15:09:44Z",
            "published": "2023-10-13T15:09:44Z",
            "summary": "Culture involves the origination and transmission of ideas, but the\nconditions in which culture can emerge and evolve are unclear. We constructed\nand studied a highly simplified neural-network model of these processes. In\nthis model ideas originate by individual learning from the environment and are\ntransmitted by communication between individuals. Individuals (or \"agents\")\ncomprise a single neuron which receives structured data from the environment\nvia plastic synaptic connections. The data are generated in the simplest\npossible way: linear mixing of independently fluctuating sources and the goal\nof learning is to unmix the data. To make this problem tractable we assume that\nat least one of the sources fluctuates in a nonGaussian manner. Linear mixing\ncreates structure in the data, and agents attempt to learn (from the data and\npossibly from other individuals) synaptic weights that will unmix, i.e., to\n\"understand\" the agent's world. For a variety of reasons even this goal can be\ndifficult for a single agent to achieve; we studied one particular type of\ndifficulty (created by imperfection in synaptic plasticity), though our\nconclusions should carry over to many other types of difficulty. We previously\nstudied whether a small population of communicating agents, learning from each\nother, could more easily learn unmixing coefficients than isolated individuals,\nlearning only from their environment. We found, unsurprisingly, that if agents\nlearn indiscriminately from any other agent (whether or not they have learned\ngood solutions), communication does not enhance understanding. Here we extend\nthe model slightly, by allowing successful learners to be more effective\nteachers, and find that now a population of agents can learn more effectively\nthan isolated individuals. We suggest that a key factor in the onset of culture\nmight be the development of selective learning.",
            "author": [
                "Kingsley J. A. Cox",
                "Paul R. Adams"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09175v1",
                "http://arxiv.org/pdf/2310.09175v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "q-bio.PE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09167v1",
            "title": "A Deep Neural Network -- Mechanistic Hybrid Model to Predict\n  Pharmacokinetics in Rat",
            "updated": "2023-10-13T15:01:55Z",
            "published": "2023-10-13T15:01:55Z",
            "summary": "An important aspect in the development of small molecules as drugs or\nagro-chemicals is their systemic availability after intravenous and oral\nadministration.The prediction of the systemic availability from the chemical\nstructure of a poten-tial candidate is highly desirable, as it allows to focus\nthe drug or agrochemicaldevelopment on compounds with a favorable kinetic\nprofile. However, such pre-dictions are challenging as the availability is the\nresult of the complex interplaybetween molecular properties, biology and\nphysiology and training data is rare.In this work we improve the hybrid model\ndeveloped earlier [34]. We reducethe median fold change error for the total\noral exposure from 2.85 to 2.35 andfor intravenous administration from 1.95 to\n1.62. This is achieved by trainingon a larger data set, improving the neural\nnetwork architecture as well as theparametrization of mechanistic model.\nFurther, we extend our approach to predictadditional endpoints and to handle\ndifferent covariates, like sex and dosage form.In contrast to a pure machine\nlearning model, our model is able to predict newend points on which it has not\nbeen trained. We demonstrate this feature by1predicting the exposure over the\nfirst 24h, while the model has only been trainedon the total exposure.",
            "author": [
                "Florian F\u00fchrer",
                "Andrea Gruber",
                "Holger Diedam",
                "Andreas H. G\u00f6ller",
                "Stephan Menz",
                "Sebastian Schneckener"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09167v1",
                "http://arxiv.org/pdf/2310.09167v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.CE",
                "cs.LG",
                "q-bio.BM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09166v2",
            "title": "Developing a Natural Language Understanding Model to Characterize Cable\n  News Bias",
            "updated": "2023-10-17T22:37:58Z",
            "published": "2023-10-13T15:01:17Z",
            "summary": "Media bias has been extensively studied by both social and computational\nsciences. However, current work still has a large reliance on human input and\nsubjective assessment to label biases. This is especially true for cable news\nresearch. To address these issues, we develop an unsupervised machine learning\nmethod to characterize the bias of cable news programs without any human input.\nThis method relies on the analysis of what topics are mentioned through Named\nEntity Recognition and how those topics are discussed through Stance Analysis\nin order to cluster programs with similar biases together. Applying our method\nto 2020 cable news transcripts, we find that program clusters are consistent\nover time and roughly correspond to the cable news network of the program. This\nmethod reveals the potential for future tools to objectively assess media bias\nand characterize unfamiliar media environments.",
            "author": [
                "Seth P. Benson",
                "Iain J. Cruickshank"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09166v2",
                "http://arxiv.org/pdf/2310.09166v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09162v1",
            "title": "Quantum Machine Learning in Climate Change and Sustainability: a Review",
            "updated": "2023-10-13T14:56:38Z",
            "published": "2023-10-13T14:56:38Z",
            "summary": "Climate change and its impact on global sustainability are critical\nchallenges, demanding innovative solutions that combine cutting-edge\ntechnologies and scientific insights. Quantum machine learning (QML) has\nemerged as a promising paradigm that harnesses the power of quantum computing\nto address complex problems in various domains including climate change and\nsustainability. In this work, we survey existing literature that applies\nquantum machine learning to solve climate change and sustainability-related\nproblems. We review promising QML methodologies that have the potential to\naccelerate decarbonization including energy systems, climate data forecasting,\nclimate monitoring, and hazardous events predictions. We discuss the challenges\nand current limitations of quantum machine learning approaches and provide an\noverview of potential opportunities and future work to leverage QML-based\nmethods in the important area of climate change research.",
            "author": [
                "Amal Nammouchi",
                "Andreas Kassler",
                "Andreas Theorachis"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09162v1",
                "http://arxiv.org/pdf/2310.09162v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09163v1",
            "title": "Jointly-Learned Exit and Inference for a Dynamic Neural Network :\n  JEI-DNN",
            "updated": "2023-10-13T14:56:38Z",
            "published": "2023-10-13T14:56:38Z",
            "summary": "Large pretrained models, coupled with fine-tuning, are slowly becoming\nestablished as the dominant architecture in machine learning. Even though these\nmodels offer impressive performance, their practical application is often\nlimited by the prohibitive amount of resources required for every inference.\nEarly-exiting dynamic neural networks (EDNN) circumvent this issue by allowing\na model to make some of its predictions from intermediate layers (i.e.,\nearly-exit). Training an EDNN architecture is challenging as it consists of two\nintertwined components: the gating mechanism (GM) that controls early-exiting\ndecisions and the intermediate inference modules (IMs) that perform inference\nfrom intermediate representations. As a result, most existing approaches rely\non thresholding confidence metrics for the gating mechanism and strive to\nimprove the underlying backbone network and the inference modules. Although\nsuccessful, this approach has two fundamental shortcomings: 1) the GMs and the\nIMs are decoupled during training, leading to a train-test mismatch; and 2) the\nthresholding gating mechanism introduces a positive bias into the predictive\nprobabilities, making it difficult to readily extract uncertainty information.\nWe propose a novel architecture that connects these two modules. This leads to\nsignificant performance improvements on classification datasets and enables\nbetter uncertainty characterization capabilities.",
            "author": [
                "Florence Regol",
                "Joud Chataoui",
                "Mark Coates"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09163v1",
                "http://arxiv.org/pdf/2310.09163v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.09158v1",
            "title": "Learning To Teach Large Language Models Logical Reasoning",
            "updated": "2023-10-13T14:53:06Z",
            "published": "2023-10-13T14:53:06Z",
            "summary": "Large language models (LLMs) have gained enormous attention from both\nacademia and industry, due to their exceptional ability in language generation\nand extremely powerful generalization. However, current LLMs still output\nunreliable content in practical reasoning tasks due to their inherent issues\n(e.g., hallucination). To better disentangle this problem, in this paper, we\nconduct an in-depth investigation to systematically explore the capability of\nLLMs in logical reasoning. More in detail, we first investigate the deficiency\nof LLMs in logical reasoning on different tasks, including event relation\nextraction and deductive reasoning. Our study demonstrates that LLMs are not\ngood reasoners in solving tasks with rigorous reasoning and will produce\ncounterfactual answers, which require us to iteratively refine. Therefore, we\ncomprehensively explore different strategies to endow LLMs with logical\nreasoning ability, and thus enable them to generate more logically consistent\nanswers across different scenarios. Based on our approach, we also contribute a\nsynthesized dataset (LLM-LR) involving multi-hop reasoning for evaluation and\npre-training. Extensive quantitative and qualitative analyses on different\ntasks also validate the effectiveness and necessity of teaching LLMs with logic\nand provide insights for solving practical tasks with LLMs in future work.",
            "author": [
                "Meiqi Chen",
                "Yubo Ma",
                "Kaitao Song",
                "Yixin Cao",
                "Yan Zhang",
                "Dongsheng Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.09158v1",
                "http://arxiv.org/pdf/2310.09158v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    }
]