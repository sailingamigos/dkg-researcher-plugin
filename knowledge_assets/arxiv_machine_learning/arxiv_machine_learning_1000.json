[
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00991v1",
            "title": "Convergences for Minimax Optimization Problems over Infinite-Dimensional\n  Spaces Towards Stability in Adversarial Training",
            "updated": "2023-12-02T01:15:57Z",
            "published": "2023-12-02T01:15:57Z",
            "summary": "Training neural networks that require adversarial optimization, such as\ngenerative adversarial networks (GANs) and unsupervised domain adaptations\n(UDAs), suffers from instability. This instability problem comes from the\ndifficulty of the minimax optimization, and there have been various approaches\nin GANs and UDAs to overcome this problem. In this study, we tackle this\nproblem theoretically through a functional analysis. Specifically, we show the\nconvergence property of the minimax problem by the gradient descent over the\ninfinite-dimensional spaces of continuous functions and probability measures\nunder certain conditions. Using this setting, we can discuss GANs and UDAs\ncomprehensively, which have been studied independently. In addition, we show\nthat the conditions necessary for the convergence property are interpreted as\nstabilization techniques of adversarial training such as the spectral\nnormalization and the gradient penalty.",
            "author": [
                "Takashi Furuya",
                "Satoshi Okuda",
                "Kazuma Suetake",
                "Yoshihide Sawada"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00991v1",
                "http://arxiv.org/pdf/2312.00991v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00975v1",
            "title": "Noisy probing dose facilitated dose prediction for pencil beam scanning\n  proton therapy: physics enhances generalizability",
            "updated": "2023-12-02T00:15:44Z",
            "published": "2023-12-02T00:15:44Z",
            "summary": "Purpose: Prior AI-based dose prediction studies in photon and proton therapy\noften neglect underlying physics, limiting their generalizability to handle\noutlier clinical cases, especially for pencil beam scanning proton therapy\n(PBSPT). Our aim is to design a physics-aware and generalizable AI-based PBSPT\ndose prediction method that has the underlying physics considered to achieve\nhigh generalizability to properly handle the outlier clinical cases. Methods\nand Materials: This study analyzed PBSPT plans of 103 prostate and 78 lung\ncancer patients from our institution,with each case comprising CT images,\nstructure sets, and plan doses from our Monte-Carlo dose engine (serving as the\nground truth). Three methods were evaluated in the ablation study: the\nROI-based method, the beam mask and sliding window method, and the noisy\nprobing dose method. Twelve cases with uncommon beam angles or prescription\ndoses tested the methods' generalizability to rare treatment planning\nscenarios. Performance evaluation used DVH indices, 3D Gamma passing rates\n(3%/2mm/10%), and dice coefficients for dose agreement. Results: The noisy\nprobing dose method showed improved agreement of DVH indices, 3D Gamma passing\nrates, and dice coefficients compared to the conventional methods for the\ntesting cases. The noisy probing dose method showed better generalizability in\nthe 6 outlier cases than the ROI-based and beam mask-based methods with 3D\nGamma passing rates (for prostate cancer, targets: 89.32%$\\pm$1.45% vs.\n93.48%$\\pm$1.51% vs. 96.79%$\\pm$0.83%, OARs: 85.87%$\\pm$1.73% vs.\n91.15%$\\pm$1.13% vs. 94.29%$\\pm$1.01%). The dose predictions were completed\nwithin 0.3 seconds. Conclusions: We've devised a novel noisy probing dose\nmethod for PBSPT dose prediction in prostate and lung cancer patients. With\nmore physics included, it enhances the generalizability of dose prediction in\nhandling outlier clinical cases.",
            "author": [
                "Lian Zhang",
                "Jason M. Holmes",
                "Zhengliang Liu",
                "Hongying Feng",
                "Terence T. Sio",
                "Carlos E. Vargas",
                "Sameer R. Keole",
                "Kristin St\u00fctzer",
                "Sheng Li",
                "Tianming Liu",
                "Jiajian Shen",
                "William W. Wong",
                "Sujay A. Vora",
                "Wei Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00975v1",
                "http://arxiv.org/pdf/2312.00975v1"
            ],
            "primary_category": "physics.med-ph",
            "category": [
                "physics.med-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00968v1",
            "title": "Omni-SMoLA: Boosting Generalist Multimodal Models with Soft Mixture of\n  Low-rank Experts",
            "updated": "2023-12-01T23:04:27Z",
            "published": "2023-12-01T23:04:27Z",
            "summary": "Large multi-modal models (LMMs) exhibit remarkable performance across\nnumerous tasks. However, generalist LMMs often suffer from performance\ndegradation when tuned over a large collection of tasks. Recent research\nsuggests that Mixture of Experts (MoE) architectures are useful for instruction\ntuning, but for LMMs of parameter size around O(50-100B), the prohibitive cost\nof replicating and storing the expert models severely limits the number of\nexperts we can use. We propose Omni-SMoLA, an architecture that uses the Soft\nMoE approach to (softly) mix many multimodal low rank experts, and avoids\nintroducing a significant number of new parameters compared to conventional MoE\nmodels. The core intuition here is that the large model provides a foundational\nbackbone, while different lightweight experts residually learn specialized\nknowledge, either per-modality or multimodally. Extensive experiments\ndemonstrate that the SMoLA approach helps improve the generalist performance\nacross a broad range of generative vision-and-language tasks, achieving new\nSoTA generalist performance that often matches or outperforms single\nspecialized LMM baselines, as well as new SoTA specialist performance.",
            "author": [
                "Jialin Wu",
                "Xia Hu",
                "Yaqing Wang",
                "Bo Pang",
                "Radu Soricut"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00968v1",
                "http://arxiv.org/pdf/2312.00968v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00967v1",
            "title": "Level Set Learning for Poincar\u00e9 Plots of Symplectic Maps",
            "updated": "2023-12-01T22:51:07Z",
            "published": "2023-12-01T22:51:07Z",
            "summary": "Many important qualities of plasma confinement devices can be determined via\nthe Poincar\\'e plot of a symplectic return map. These qualities include the\nlocations of periodic orbits, magnetic islands, and chaotic regions of phase\nspace. However, every evaluation of the magnetic return map requires solving an\nODE, meaning a detailed Poincar\\'e plot can be expensive to create. Here, we\npropose a kernel-based method of learning a single labeling function that is\napproximately invariant under the symplectic map. From the labeling function,\nwe can recover the locations of invariant circles, islands, and chaos with few\nevaluations of the underlying symplectic map. Additionally, the labeling\nfunction comes with a residual, which serves as a measure of how invariant the\nlabel function is, and therefore as an indirect measure of chaos and map\ncomplexity.",
            "author": [
                "Maximilian Ruth",
                "David Bindel"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00967v1",
                "http://arxiv.org/pdf/2312.00967v1"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS",
                "cs.NA",
                "math.NA",
                "physics.plasm-ph",
                "65P10, 70K43, 37N20"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00966v1",
            "title": "Spectral Temporal Contrastive Learning",
            "updated": "2023-12-01T22:48:52Z",
            "published": "2023-12-01T22:48:52Z",
            "summary": "Learning useful data representations without requiring labels is a\ncornerstone of modern deep learning. Self-supervised learning methods,\nparticularly contrastive learning (CL), have proven successful by leveraging\ndata augmentations to define positive pairs. This success has prompted a number\nof theoretical studies to better understand CL and investigate theoretical\nbounds for downstream linear probing tasks. This work is concerned with the\ntemporal contrastive learning (TCL) setting where the sequential structure of\nthe data is used instead to define positive pairs, which is more commonly used\nin RL and robotics contexts. In this paper, we adapt recent work on Spectral CL\nto formulate Spectral Temporal Contrastive Learning (STCL). We discuss a\npopulation loss based on a state graph derived from a time-homogeneous\nreversible Markov chain with uniform stationary distribution. The STCL loss\nenables to connect the linear probing performance to the spectral properties of\nthe graph, and can be estimated by considering previously observed data\nsequences as an ensemble of MCMC chains.",
            "author": [
                "Sacha Morin",
                "Somjit Nath",
                "Samira Ebrahimi Kahou",
                "Guy Wolf"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00966v1",
                "http://arxiv.org/pdf/2312.00966v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00963v1",
            "title": "Spatiotemporal Transformer for Imputing Sparse Data: A Deep Learning\n  Approach",
            "updated": "2023-12-01T22:39:02Z",
            "published": "2023-12-01T22:39:02Z",
            "summary": "Effective management of environmental resources and agricultural\nsustainability heavily depends on accurate soil moisture data. However,\ndatasets like the SMAP/Sentinel-1 soil moisture product often contain missing\nvalues across their spatiotemporal grid, which poses a significant challenge.\nThis paper introduces a novel Spatiotemporal Transformer model (ST-Transformer)\nspecifically designed to address the issue of missing values in sparse\nspatiotemporal datasets, particularly focusing on soil moisture data. The\nST-Transformer employs multiple spatiotemporal attention layers to capture the\ncomplex spatiotemporal correlations in the data and can integrate additional\nspatiotemporal covariates during the imputation process, thereby enhancing its\naccuracy. The model is trained using a self-supervised approach, enabling it to\nautonomously predict missing values from observed data points. Our model's\nefficacy is demonstrated through its application to the SMAP 1km soil moisture\ndata over a 36 x 36 km grid in Texas. It showcases superior accuracy compared\nto well-known imputation methods. Additionally, our simulation studies on other\ndatasets highlight the model's broader applicability in various spatiotemporal\nimputation tasks.",
            "author": [
                "Kehui Yao",
                "Jingyi Huang",
                "Jun Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00963v1",
                "http://arxiv.org/pdf/2312.00963v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00961v2",
            "title": "Biased Random-Key Genetic Algorithms: A Review",
            "updated": "2023-12-06T16:20:27Z",
            "published": "2023-12-01T22:32:58Z",
            "summary": "This paper is a comprehensive literature review of Biased Random-Key Genetic\nAlgorithms (BRKGA). BRKGA is a metaheuristic that employs random-key-based\nchromosomes with biased, uniform, and elitist mating strategies in a genetic\nalgorithm framework. The review encompasses over 150 papers with a wide range\nof applications, including classical combinatorial optimization problems,\nreal-world industrial use cases, and non-orthodox applications such as neural\nnetwork hyperparameter tuning in machine learning. Scheduling is by far the\nmost prevalent application area in this review, followed by network design and\nlocation problems. The most frequent hybridization method employed is local\nsearch, and new features aim to increase population diversity. Overall, this\nsurvey provides a comprehensive overview of the BRKGA metaheuristic and its\napplications and highlights important areas for future research.",
            "author": [
                "Mariana A. Londe",
                "Luciana S. Pessoa",
                "Carlos E. Andrade",
                "Mauricio G. C. Resende"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00961v2",
                "http://arxiv.org/pdf/2312.00961v2"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "90, 68",
                "F.2.2; G.2.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00960v1",
            "title": "The Cost of Compression: Investigating the Impact of Compression on\n  Parametric Knowledge in Language Models",
            "updated": "2023-12-01T22:27:12Z",
            "published": "2023-12-01T22:27:12Z",
            "summary": "Compressing large language models (LLMs), often consisting of billions of\nparameters, provides faster inference, smaller memory footprints, and enables\nlocal deployment. Two standard compression techniques are pruning and\nquantization, with the former eliminating redundant connections in model layers\nand the latter representing model parameters with fewer bits. The key tradeoff\nis between the degree of compression and the impact on the quality of the\ncompressed model. Existing research on LLM compression primarily focuses on\nperformance in terms of general metrics like perplexity or downstream task\naccuracy. More fine-grained metrics, such as those measuring parametric\nknowledge, remain significantly underexplored. To help bridge this gap, we\npresent a comprehensive analysis across multiple model families (ENCODER,\nENCODER-DECODER, and DECODER) using the LAMA and LM-HARNESS benchmarks in order\nto systematically quantify the effect of commonly employed compression\ntechniques on model performance. A particular focus is on tradeoffs involving\nparametric knowledge, with the goal of providing practitioners with practical\ninsights to help make informed decisions on compression. We release our\ncodebase1 to enable further research.",
            "author": [
                "Satya Sai Srinath Namburi",
                "Makesh Sreedhar",
                "Srinath Srinivasan",
                "Frederic Sala"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00960v1",
                "http://arxiv.org/pdf/2312.00960v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00953v1",
            "title": "Deep Image prior with StruCtUred Sparsity (DISCUS) for dynamic MRI\n  reconstruction",
            "updated": "2023-12-01T22:06:22Z",
            "published": "2023-12-01T22:06:22Z",
            "summary": "High-quality training data are not always available in dynamic MRI. To\naddress this, we propose a self-supervised deep learning method called deep\nimage prior with structured sparsity (DISCUS) for reconstructing dynamic\nimages. DISCUS is inspired by deep image prior (DIP) and recovers a series of\nimages through joint optimization of network parameters and input code vectors.\nHowever, DISCUS additionally encourages group sparsity on frame-specific code\nvectors to discover the low-dimensional manifold that describes temporal\nvariations across frames. Compared to prior work on manifold learning, DISCUS\ndoes not require specifying the manifold dimensionality. We validate DISCUS\nusing three numerical studies. In the first study, we simulate a dynamic\nShepp-Logan phantom with frames undergoing random rotations, translations, or\nboth, and demonstrate that DISCUS can discover the dimensionality of the\nunderlying manifold. In the second study, we use data from a realistic late\ngadolinium enhancement (LGE) phantom to compare DISCUS with compressed sensing\n(CS) and DIP and to demonstrate the positive impact of group sparsity. In the\nthird study, we use retrospectively undersampled single-shot LGE data from five\npatients to compare DISCUS with CS reconstructions. The results from these\nstudies demonstrate that DISCUS outperforms CS and DIP and that enforcing group\nsparsity on the code vectors helps discover true manifold dimensionality and\nprovides additional performance gain.",
            "author": [
                "Muhammad Ahmad Sultan",
                "Chong Chen",
                "Yingmin Liu",
                "Rizwan Ahmad"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00953v1",
                "http://arxiv.org/pdf/2312.00953v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00950v1",
            "title": "Improve Supervised Representation Learning with Masked Image Modeling",
            "updated": "2023-12-01T22:03:25Z",
            "published": "2023-12-01T22:03:25Z",
            "summary": "Training visual embeddings with labeled data supervision has been the de\nfacto setup for representation learning in computer vision. Inspired by recent\nsuccess of adopting masked image modeling (MIM) in self-supervised\nrepresentation learning, we propose a simple yet effective setup that can\neasily integrate MIM into existing supervised training paradigms. In our\ndesign, in addition to the original classification task applied to a vision\ntransformer image encoder, we add a shallow transformer-based decoder on top of\nthe encoder and introduce an MIM task which tries to reconstruct image tokens\nbased on masked image inputs. We show with minimal change in architecture and\nno overhead in inference that this setup is able to improve the quality of the\nlearned representations for downstream tasks such as classification, image\nretrieval, and semantic segmentation. We conduct a comprehensive study and\nevaluation of our setup on public benchmarks. On ImageNet-1k, our ViT-B/14\nmodel achieves 81.72% validation accuracy, 2.01% higher than the baseline\nmodel. On K-Nearest-Neighbor image retrieval evaluation with ImageNet-1k, the\nsame model outperforms the baseline by 1.32%. We also show that this setup can\nbe easily scaled to larger models and datasets. Code and checkpoints will be\nreleased.",
            "author": [
                "Kaifeng Chen",
                "Daniel Salz",
                "Huiwen Chang",
                "Kihyuk Sohn",
                "Dilip Krishnan",
                "Mojtaba Seyedhosseini"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00950v1",
                "http://arxiv.org/pdf/2312.00950v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00948v1",
            "title": "A Review of Communicating Robot Learning during Human-Robot Interaction",
            "updated": "2023-12-01T22:03:11Z",
            "published": "2023-12-01T22:03:11Z",
            "summary": "For robots to seamlessly interact with humans, we first need to make sure\nthat humans and robots understand one another. Diverse algorithms have been\ndeveloped to enable robots to learn from humans (i.e., transferring information\nfrom humans to robots). In parallel, visual, haptic, and auditory communication\ninterfaces have been designed to convey the robot's internal state to the human\n(i.e., transferring information from robots to humans). Prior research often\nseparates these two directions of information transfer, and focuses primarily\non either learning algorithms or communication interfaces. By contrast, in this\nreview we take an interdisciplinary approach to identify common themes and\nemerging trends that close the loop between learning and communication.\nSpecifically, we survey state-of-the-art methods and outcomes for communicating\na robot's learning back to the human teacher during human-robot interaction.\nThis discussion connects human-in-the-loop learning methods and explainable\nrobot learning with multi-modal feedback systems and measures of human-robot\ninteraction. We find that -- when learning and communication are developed\ntogether -- the resulting closed-loop system can lead to improved human\nteaching, increased human trust, and human-robot co-adaptation. The paper\nincludes a perspective on several of the interdisciplinary research themes and\nopen questions that could advance how future robots communicate their learning\nto everyday operators. Finally, we implement a selection of the reviewed\nmethods in a case study where participants kinesthetically teach a robot arm.\nThis case study documents and tests an integrated approach for learning in ways\nthat can be communicated, conveying this learning across multi-modal\ninterfaces, and measuring the resulting changes in human and robot behavior.\nSee videos of our case study here: https://youtu.be/EXfQctqFzWs",
            "author": [
                "Soheil Habibian",
                "Antonio Alvarez Valdivia",
                "Laura H. Blumenschein",
                "Dylan P. Losey"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00948v1",
                "http://arxiv.org/pdf/2312.00948v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00947v1",
            "title": "Object 6D pose estimation meets zero-shot learning",
            "updated": "2023-12-01T22:00:14Z",
            "published": "2023-12-01T22:00:14Z",
            "summary": "Object 6D pose estimation methods can achieve high accuracy when trained and\ntested on the same objects. However, estimating the pose of objects that are\nabsent at training time is still a challenge. In this work, we advance the\nstate-of-the-art in zero-shot object 6D pose estimation by proposing the first\nmethod that fuses the contribution of pre-trained geometric and vision\nfoundation models. Unlike state-of-the-art approaches that train their pipeline\non data specifically crafted for the 6D pose estimation task, our method does\nnot require task-specific finetuning. Instead, our method, which we name PoMZ,\ncombines geometric descriptors learned from point cloud data with visual\nfeatures learned from large-scale web images to produce distinctive 3D\npoint-level descriptors. By applying an off-the-shelf registration algorithm,\nlike RANSAC, PoMZ outperforms all state-of-the-art zero-shot object 6D pose\nestimation approaches. We extensively evaluate PoMZ across the seven core\ndatasets of the BOP Benchmark, encompassing over a hundred objects and 20\nthousand images captured in diverse scenarios. PoMZ ranks first in the BOP\nBenchmark under the category Task 4: 6D localization of unseen objects. We will\nrelease the source code publicly.",
            "author": [
                "Andrea Caraffa",
                "Davide Boscaini",
                "Amir Hamza",
                "Fabio Poiesi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00947v1",
                "http://arxiv.org/pdf/2312.00947v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00946v1",
            "title": "Risk-Averse Control of Markov Systems with Value Function Learning",
            "updated": "2023-12-01T21:58:49Z",
            "published": "2023-12-01T21:58:49Z",
            "summary": "We consider a control problem for a finite-state Markov system whose\nperformance is evaluated by a coherent Markov risk measure. For each policy,\nthe risk of a state is approximated by a function of its features, thus leading\nto a lower-dimensional policy evaluation problem, which involves\nnon-differentiable stochastic operators. We introduce mini-batch transition\nrisk mappings, which are particularly suited to our approach, and we use them\nto derive a robust learning algorithm for Markov policy evaluation. Finally, we\ndiscuss structured policy improvement in the feature-based risk-averse setting.\nThe considerations are illustrated with an underwater robot navigation problem\nin which several waypoints must be visited and the observation results must be\nreported from selected transmission locations. We identify the relevant\nfeatures, we test the simulation-based learning method, and we optimize a\nstructured policy in a hyperspace containing all problems with the same number\nof relevant points.",
            "author": [
                "Andrzej Ruszczynski",
                "Shangzhe Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00946v1",
                "http://arxiv.org/pdf/2312.00946v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00942v1",
            "title": "Survey of Security Issues in Memristor-based Machine Learning\n  Accelerators for RF Analysis",
            "updated": "2023-12-01T21:44:35Z",
            "published": "2023-12-01T21:44:35Z",
            "summary": "We explore security aspects of a new computing paradigm that combines novel\nmemristors and traditional Complimentary Metal Oxide Semiconductor (CMOS) to\nconstruct a highly efficient analog and/or digital fabric that is especially\nwell-suited to Machine Learning (ML) inference processors for Radio Frequency\n(RF) signals. Memristors have different properties than traditional CMOS which\ncan potentially be exploited by attackers. In addition, the mixed signal\napproximate computing model has different vulnerabilities than traditional\ndigital implementations. However both the memristor and the ML computation can\nbe leveraged to create security mechanisms and countermeasures ranging from\nlightweight cryptography, identifiers (e.g. Physically Unclonable Functions\n(PUFs), fingerprints, and watermarks), entropy sources, hardware obfuscation\nand leakage/attack detection methods. Three different threat models are\nproposed: 1) Supply Chain, 2) Physical Attacks, and 3) Remote Attacks. For each\nthreat model, potential vulnerabilities and defenses are identified. This\nsurvey reviews a variety of recent work from the hardware and ML security\nliterature and proposes open problems for both attack and defense. The survey\nemphasizes the growing area of RF signal analysis and identification in terms\nof the commercial space, as well as military applications and threat models. We\ndiffer from other other recent surveys that target ML in general, neglecting RF\napplications.",
            "author": [
                "William Lillis",
                "Max Cohen Hoffing",
                "Wayne Burleson"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00942v1",
                "http://arxiv.org/pdf/2312.00942v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00938v1",
            "title": "WATonoBus: An All Weather Autonomous Shuttle",
            "updated": "2023-12-01T21:36:14Z",
            "published": "2023-12-01T21:36:14Z",
            "summary": "Autonomous vehicle all-weather operation poses significant challenges,\nencompassing modules from perception and decision-making to path planning and\ncontrol. The complexity arises from the need to address adverse weather\nconditions like rain, snow, and fog across the autonomy stack. Conventional\nmodel-based and single-module approaches often lack holistic integration with\nupstream or downstream tasks. We tackle this problem by proposing a\nmulti-module and modular system architecture with considerations for adverse\nweather across the perception level, through features such as snow covered curb\ndetection, to decision-making and safety monitoring. Through daily weekday\nservice on the WATonoBus platform for almost a year, we demonstrate that our\nproposed approach is capable of addressing adverse weather conditions and\nprovide valuable learning from edge cases observed during operation.",
            "author": [
                "Neel P. Bhatt",
                "Ruihe Zhang",
                "Minghao Ning",
                "Ahmad Reza Alghooneh",
                "Joseph Sun",
                "Pouya Panahandeh",
                "Ehsan Mohammadbagher",
                "Ted Ecclestone",
                "Ben MacCallum",
                "Ehsan Hashemi",
                "Amir Khajepour"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00938v1",
                "http://arxiv.org/pdf/2312.00938v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00935v1",
            "title": "A Theory of Unimodal Bias in Multimodal Learning",
            "updated": "2023-12-01T21:29:54Z",
            "published": "2023-12-01T21:29:54Z",
            "summary": "Using multiple input streams simultaneously in training multimodal neural\nnetworks is intuitively advantageous, but practically challenging. A key\nchallenge is unimodal bias, where a network overly relies on one modality and\nignores others during joint training. While unimodal bias is well-documented\nempirically, our theoretical understanding of how architecture and data\nstatistics influence this bias remains incomplete. Here we develop a theory of\nunimodal bias with deep multimodal linear networks. We calculate the duration\nof the unimodal phase in learning as a function of the depth at which\nmodalities are fused within the network, dataset statistics, and\ninitialization. We find that the deeper the layer at which fusion occurs, the\nlonger the unimodal phase. A long unimodal phase can lead to a generalization\ndeficit and permanent unimodal bias in the overparametrized regime. In\naddition, our theory reveals the modality learned first is not necessarily the\nmodality that contributes more to the output. Our results, derived for\nmultimodal linear networks, extend to ReLU networks in certain settings. Taken\ntogether, this work illuminates pathologies of multimodal learning under joint\ntraining, showing that late and intermediate fusion architectures can give rise\nto long unimodal phases and permanent unimodal bias.",
            "author": [
                "Yedi Zhang",
                "Peter E. Latham",
                "Andrew Saxe"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00935v1",
                "http://arxiv.org/pdf/2312.00935v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00923v1",
            "title": "Label Delay in Continual Learning",
            "updated": "2023-12-01T20:52:10Z",
            "published": "2023-12-01T20:52:10Z",
            "summary": "Online continual learning, the process of training models on streaming data,\nhas gained increasing attention in recent years. However, a critical aspect\noften overlooked is the label delay, where new data may not be labeled due to\nslow and costly annotation processes. We introduce a new continual learning\nframework with explicit modeling of the label delay between data and label\nstreams over time steps. In each step, the framework reveals both unlabeled\ndata from the current time step $t$ and labels delayed with $d$ steps, from the\ntime step $t-d$. In our extensive experiments amounting to 1060 GPU days, we\nshow that merely augmenting the computational resources is insufficient to\ntackle this challenge. Our findings underline a notable performance decline\nwhen solely relying on labeled data when the label delay becomes significant.\nMore surprisingly, when using state-of-the-art SSL and TTA techniques to\nutilize the newer, unlabeled data, they fail to surpass the performance of a\nna\\\"ive method that simply trains on the delayed supervised stream. To this\nend, we introduce a simple, efficient baseline that rehearses from the labeled\nmemory samples that are most similar to the new unlabeled samples. This method\nbridges the accuracy gap caused by label delay without significantly increasing\ncomputational complexity. We show experimentally that our method is the least\naffected by the label delay factor and in some cases successfully recovers the\naccuracy of the non-delayed counterpart. We conduct various ablations and\nsensitivity experiments, demonstrating the effectiveness of our approach.",
            "author": [
                "Botos Csaba",
                "Wenxuan Zhang",
                "Matthias M\u00fcller",
                "Ser-Nam Lim",
                "Mohamed Elhoseiny",
                "Philip Torr",
                "Adel Bibi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00923v1",
                "http://arxiv.org/pdf/2312.00923v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "I.4.0; I.4.10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00919v1",
            "title": "Rethinking Skip Connections in Spiking Neural Networks with\n  Time-To-First-Spike Coding",
            "updated": "2023-12-01T20:49:37Z",
            "published": "2023-12-01T20:49:37Z",
            "summary": "Time-To-First-Spike (TTFS) coding in Spiking Neural Networks (SNNs) offers\nsignificant advantages in terms of energy efficiency, closely mimicking the\nbehavior of biological neurons. In this work, we delve into the role of skip\nconnections, a widely used concept in Artificial Neural Networks (ANNs), within\nthe domain of SNNs with TTFS coding. Our focus is on two distinct types of skip\nconnection architectures: (1) addition-based skip connections, and (2)\nconcatenation-based skip connections. We find that addition-based skip\nconnections introduce an additional delay in terms of spike timing. On the\nother hand, concatenation-based skip connections circumvent this delay but\nproduce time gaps between after-convolution and skip connection paths, thereby\nrestricting the effective mixing of information from these two paths. To\nmitigate these issues, we propose a novel approach involving a learnable delay\nfor skip connections in the concatenation-based skip connection architecture.\nThis approach successfully bridges the time gap between the convolutional and\nskip branches, facilitating improved information mixing. We conduct experiments\non public datasets including MNIST and Fashion-MNIST, illustrating the\nadvantage of the skip connection in TTFS coding architectures. Additionally, we\ndemonstrate the applicability of TTFS coding on beyond image recognition tasks\nand extend it to scientific machine-learning tasks, broadening the potential\nuses of SNNs.",
            "author": [
                "Youngeun Kim",
                "Adar Kahana",
                "Ruokai Yin",
                "Yuhang Li",
                "Panos Stinis",
                "George Em Karniadakis",
                "Priyadarshini Panda"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00919v1",
                "http://arxiv.org/pdf/2312.00919v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00918v1",
            "title": "PACE: A Program Analysis Framework for Continuous Performance Prediction",
            "updated": "2023-12-01T20:43:34Z",
            "published": "2023-12-01T20:43:34Z",
            "summary": "Software development teams establish elaborate continuous integration\npipelines containing automated test cases to accelerate the development process\nof software. Automated tests help to verify the correctness of code\nmodifications decreasing the response time to changing requirements. However,\nwhen the software teams do not track the performance impact of pending\nmodifications, they may need to spend considerable time refactoring existing\ncode. This paper presents PACE, a program analysis framework that provides\ncontinuous feedback on the performance impact of pending code updates. We\ndesign performance microbenchmarks by mapping the execution time of functional\ntest cases given a code update. We map microbenchmarks to code stylometry\nfeatures and feed them to predictors for performance predictions. Our\nexperiments achieved significant performance in predicting code performance,\noutperforming current state-of-the-art by 75% on neural-represented code\nstylometry features.",
            "author": [
                "Chidera Biringa",
                "Gokhan Kul"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00918v1",
                "http://arxiv.org/pdf/2312.00918v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.LG",
                "cs.PF"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00912v1",
            "title": "Quick Back-Translation for Unsupervised Machine Translation",
            "updated": "2023-12-01T20:27:42Z",
            "published": "2023-12-01T20:27:42Z",
            "summary": "The field of unsupervised machine translation has seen significant\nadvancement from the marriage of the Transformer and the back-translation\nalgorithm. The Transformer is a powerful generative model, and back-translation\nleverages Transformer's high-quality translations for iterative\nself-improvement. However, the Transformer is encumbered by the run-time of\nautoregressive inference during back-translation, and back-translation is\nlimited by a lack of synthetic data efficiency. We propose a two-for-one\nimprovement to Transformer back-translation: Quick Back-Translation (QBT). QBT\nre-purposes the encoder as a generative model, and uses encoder-generated\nsequences to train the decoder in conjunction with the original autoregressive\nback-translation step, improving data throughput and utilization. Experiments\non various WMT benchmarks demonstrate that a relatively small number of\nrefining steps of QBT improve current unsupervised machine translation models,\nand that QBT dramatically outperforms standard back-translation only method in\nterms of training efficiency for comparable translation qualities.",
            "author": [
                "Benjamin Brimacombe",
                "Jiawei Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00912v1",
                "http://arxiv.org/pdf/2312.00912v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00910v1",
            "title": "Effectiveness of probabilistic contact tracing in epidemic containment:\n  the role of super-spreaders and transmission paths reconstruction",
            "updated": "2023-12-01T20:19:12Z",
            "published": "2023-12-01T20:19:12Z",
            "summary": "The recent COVID-19 pandemic underscores the significance of early-stage\nnon-pharmacological intervention strategies. The widespread use of masks and\nthe systematic implementation of contact tracing strategies provide a\npotentially equally effective and socially less impactful alternative to more\nconventional approaches, such as large-scale mobility restrictions. However,\nmanual contact tracing faces strong limitations in accessing the network of\ncontacts, and the scalability of currently implemented protocols for\nsmartphone-based digital contact tracing becomes impractical during the rapid\nexpansion phases of the outbreaks, due to the surge in exposure notifications\nand associated tests. A substantial improvement in digital contact tracing can\nbe obtained through the integration of probabilistic techniques for risk\nassessment that can more effectively guide the allocation of new diagnostic\ntests. In this study, we first quantitatively analyze the diagnostic and social\ncosts associated with these containment measures based on contact tracing,\nemploying three state-of-the-art models of SARS-CoV-2 spreading. Our results\nsuggest that probabilistic techniques allow for more effective mitigation at a\nlower cost. Secondly, our findings reveal a remarkable efficacy of\nprobabilistic contact-tracing techniques in capturing backward propagations and\nsuper-spreading events, relevant features of the diffusion of many pathogens,\nincluding SARS-CoV-2.",
            "author": [
                "A. P. Muntoni",
                "F. Mazza",
                "A. Braunstein",
                "G. Catania",
                "L. Dall'Asta"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00910v1",
                "http://arxiv.org/pdf/2312.00910v1"
            ],
            "primary_category": "q-bio.PE",
            "category": [
                "q-bio.PE",
                "cond-mat.stat-mech",
                "cs.AI",
                "cs.LG",
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02186v1",
            "title": "Identifying Spurious Correlations using Counterfactual Alignment",
            "updated": "2023-12-01T20:16:02Z",
            "published": "2023-12-01T20:16:02Z",
            "summary": "Models driven by spurious correlations often yield poor generalization\nperformance. We propose the counterfactual alignment method to detect and\nexplore spurious correlations of black box classifiers. Counterfactual images\ngenerated with respect to one classifier can be input into other classifiers to\nsee if they also induce changes in the outputs of these classifiers. The\nrelationship between these responses can be quantified and used to identify\nspecific instances where a spurious correlation exists as well as compute\naggregate statistics over a dataset. Our work demonstrates the ability to\ndetect spurious correlations in face attribute classifiers. This is validated\nby observing intuitive trends in a face attribute classifier as well as\nfabricating spurious correlations and detecting their presence, both visually\nand quantitatively. Further, utilizing the CF alignment method, we demonstrate\nthat we can rectify spurious correlations identified in classifiers.",
            "author": [
                "Joseph Paul Cohen",
                "Louis Blankemeier",
                "Akshay Chaudhari"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02186v1",
                "http://arxiv.org/pdf/2312.02186v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03750v1",
            "title": "Analyzing the Influence of Fake News in the 2024 Elections: A\n  Comprehensive Dataset",
            "updated": "2023-12-01T20:14:16Z",
            "published": "2023-12-01T20:14:16Z",
            "summary": "This work introduces a dataset focused on fake news in US political speeches,\nspecifically examining racial slurs and biases. By scraping and annotating\n40,000 news articles, using advanced NLP tools and human verification, we\nprovide a nuanced understanding of misinformation in political discourse. The\ndataset, designed for machine learning and bias analysis, is a critical\nresource for researchers, policymakers, and educators. It facilitates the\ndevelopment of strategies against misinformation and enhances media literacy,\nmarking a significant contribution to the study of fake news and political\ncommunication. Our dataset, focusing on the analysis of fake news in the\ncontext of the 2024 elections, is publicly accessible for community to work on\nfake news identification. Our dataset, focusing on the analysis of fake news in\nthe context of the 2024 elections, is publicly accessible.",
            "author": [
                "Mizanur Rahman",
                "Shaina Raza"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03750v1",
                "http://arxiv.org/pdf/2312.03750v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00907v1",
            "title": "Extreme Event Prediction with Multi-agent Reinforcement Learning-based\n  Parametrization of Atmospheric and Oceanic Turbulence",
            "updated": "2023-12-01T20:12:16Z",
            "published": "2023-12-01T20:12:16Z",
            "summary": "Global climate models (GCMs) are the main tools for understanding and\npredicting climate change. However, due to limited numerical resolutions, these\nmodels suffer from major structural uncertainties; e.g., they cannot resolve\ncritical processes such as small-scale eddies in atmospheric and oceanic\nturbulence. Thus, such small-scale processes have to be represented as a\nfunction of the resolved scales via closures (parametrization). The accuracy of\nthese closures is particularly important for capturing climate extremes.\nTraditionally, such closures are based on heuristics and simplifying\nassumptions about the unresolved physics. Recently, supervised-learned\nclosures, trained offline on high-fidelity data, have been shown to outperform\nthe classical physics-based closures. However, this approach requires a\nsignificant amount of high-fidelity training data and can also lead to\ninstabilities. Reinforcement learning is emerging as a potent alternative for\ndeveloping such closures as it requires only low-order statistics and leads to\nstable closures. In Scientific Multi-Agent Reinforcement Learning (SMARL)\ncomputational elements serve a dual role of discretization points and learning\nagents. We leverage SMARL and fundamentals of turbulence physics to learn\nclosures for prototypes of atmospheric and oceanic turbulence. The policy is\ntrained using only the enstrophy spectrum, which is nearly invariant and can be\nestimated from a few high-fidelity samples (these few samples are far from\nenough for supervised/offline learning). We show that these closures lead to\nstable low-resolution simulations that, at a fraction of the cost, can\nreproduce the high-fidelity simulations' statistics, including the tails of the\nprobability density functions. The results demonstrate the high potential of\nSMARL for closure modeling for GCMs, especially in the regime of scarce data\nand indirect observations.",
            "author": [
                "Rambod Mojgani",
                "Daniel Waelchli",
                "Yifei Guan",
                "Petros Koumoutsakos",
                "Pedram Hassanzadeh"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00907v1",
                "http://arxiv.org/pdf/2312.00907v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CE",
                "physics.ao-ph",
                "physics.comp-ph",
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00902v1",
            "title": "Lennard Jones Token: a blockchain solution to scientific data curation",
            "updated": "2023-12-01T20:08:04Z",
            "published": "2023-12-01T20:08:04Z",
            "summary": "Data science and artificial intelligence have become an indispensable part of\nscientific research. While such methods rely on high-quality and large\nquantities of machine-readable scientific data, the current scientific data\ninfrastructure faces significant challenges that limit effective data curation\nand sharing. These challenges include insufficient return on investment for\nresearchers to share quality data, logistical difficulties in maintaining\nlong-term data repositories, and the absence of standardized methods for\nevaluating the relative importance of various datasets. To address these\nissues, this paper presents the Lennard Jones Token, a blockchain-based\nproof-of-concept solution implemented on the Ethereum network. The token system\nincentivizes users to submit optimized structures of Lennard Jones particles by\noffering token rewards, while also charging for access to these valuable\nstructures. Utilizing smart contracts, the system automates the evaluation of\nsubmitted data, ensuring that only structures with energies lower than those in\nthe existing database for a given cluster size are rewarded. The paper explores\nthe details of the Lennard Jones Token as a proof of concept and proposes\nfuture blockchain-based tokens aimed at enhancing the curation and sharing of\nscientific data.",
            "author": [
                "Brian H. Lee",
                "Alejandro Strachan"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00902v1",
                "http://arxiv.org/pdf/2312.00902v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00894v1",
            "title": "Leveraging Large Language Models to Improve REST API Testing",
            "updated": "2023-12-01T19:53:23Z",
            "published": "2023-12-01T19:53:23Z",
            "summary": "The widespread adoption of REST APIs, coupled with their growing complexity\nand size, has led to the need for automated REST API testing tools. Current\ntesting tools focus on the structured data in REST API specifications but often\nneglect valuable insights available in unstructured natural-language\ndescriptions in the specifications, which leads to suboptimal test coverage.\nRecently, to address this gap, researchers have developed techniques that\nextract rules from these human-readable descriptions and query knowledge bases\nto derive meaningful input values. However, these techniques are limited in the\ntypes of rules they can extract and can produce inaccurate results. This paper\npresents RESTGPT, an innovative approach that leverages the power and intrinsic\ncontext-awareness of Large Language Models (LLMs) to improve REST API testing.\nRESTGPT takes as input an API specification, extracts machine-interpretable\nrules, and generates example parameter values from natural-language\ndescriptions in the specification. It then augments the original specification\nwith these rules and values. Our preliminary evaluation suggests that RESTGPT\noutperforms existing techniques in both rule extraction and value generation.\nGiven these encouraging results, we outline future research directions for\nleveraging LLMs more broadly for improving REST API testing.",
            "author": [
                "Myeongsoo Kim",
                "Tyler Stennett",
                "Dhruv Shah",
                "Saurabh Sinha",
                "Alessandro Orso"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00894v1",
                "http://arxiv.org/pdf/2312.00894v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00892v1",
            "title": "Black-Litterman Portfolio Optimization with Noisy Intermediate-Scale\n  Quantum Computers",
            "updated": "2023-12-01T19:42:04Z",
            "published": "2023-12-01T19:42:04Z",
            "summary": "In this work, we demonstrate a practical application of noisy\nintermediate-scale quantum (NISQ) algorithms to enhance subroutines in the\nBlack-Litterman (BL) portfolio optimization model. As a proof of concept, we\nimplement a 12-qubit example for selecting 6 assets out of a 12-asset pool. Our\napproach involves predicting investor views with quantum machine learning (QML)\nand addressing the subsequent optimization problem using the variational\nquantum eigensolver (VQE). The solutions obtained from VQE exhibit a high\napproximation ratio behavior, and consistently outperform several common\nportfolio models in backtesting over a long period of time. A unique aspect of\nour VQE scheme is that after the quantum circuit is optimized, only a minimal\nnumber of samplings is required to give a high approximation ratio result since\nthe probability distribution should be concentrated on high-quality solutions.\nWe further emphasize the importance of employing only a small number of final\nsamplings in our scheme by comparing the cost with those obtained from an\nexhaustive search and random sampling. The power of quantum computing can be\nanticipated when dealing with a larger-size problem due to the linear growth of\nthe required qubit resources with the problem size. This is in contrast to\nclassical computing where the search space grows exponentially with the problem\nsize and would quickly reach the limit of classical computers.",
            "author": [
                "Chi-Chun Chen",
                "San-Lin Chung",
                "Hsi-Sheng Goan"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00892v1",
                "http://arxiv.org/pdf/2312.00892v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00886v3",
            "title": "Nash Learning from Human Feedback",
            "updated": "2023-12-06T14:07:10Z",
            "published": "2023-12-01T19:26:23Z",
            "summary": "Reinforcement learning from human feedback (RLHF) has emerged as the main\nparadigm for aligning large language models (LLMs) with human preferences.\nTypically, RLHF involves the initial step of learning a reward model from human\nfeedback, often expressed as preferences between pairs of text generations\nproduced by a pre-trained LLM. Subsequently, the LLM's policy is fine-tuned by\noptimizing it to maximize the reward model through a reinforcement learning\nalgorithm. However, an inherent limitation of current reward models is their\ninability to fully represent the richness of human preferences and their\ndependency on the sampling distribution.\n  In this study, we introduce an alternative pipeline for the fine-tuning of\nLLMs using pairwise human feedback. Our approach entails the initial learning\nof a preference model, which is conditioned on two inputs given a prompt,\nfollowed by the pursuit of a policy that consistently generates responses\npreferred over those generated by any competing policy, thus defining the Nash\nequilibrium of this preference model. We term this approach Nash learning from\nhuman feedback (NLHF).\n  In the context of a tabular policy representation, we present a novel\nalgorithmic solution, Nash-MD, founded on the principles of mirror descent.\nThis algorithm produces a sequence of policies, with the last iteration\nconverging to the regularized Nash equilibrium. Additionally, we explore\nparametric representations of policies and introduce gradient descent\nalgorithms for deep-learning architectures. To demonstrate the effectiveness of\nour approach, we present experimental results involving the fine-tuning of a\nLLM for a text summarization task. We believe NLHF offers a compelling avenue\nfor preference learning and policy optimization with the potential of advancing\nthe field of aligning LLMs with human preferences.",
            "author": [
                "R\u00e9mi Munos",
                "Michal Valko",
                "Daniele Calandriello",
                "Mohammad Gheshlaghi Azar",
                "Mark Rowland",
                "Zhaohan Daniel Guo",
                "Yunhao Tang",
                "Matthieu Geist",
                "Thomas Mesnard",
                "Andrea Michi",
                "Marco Selvi",
                "Sertan Girgin",
                "Nikola Momchev",
                "Olivier Bachem",
                "Daniel J. Mankowitz",
                "Doina Precup",
                "Bilal Piot"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00886v3",
                "http://arxiv.org/pdf/2312.00886v3"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.AI",
                "cs.GT",
                "cs.LG",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00875v1",
            "title": "A perspective on protein structure prediction using quantum computers",
            "updated": "2023-12-01T19:04:02Z",
            "published": "2023-12-01T19:04:02Z",
            "summary": "Despite the recent advancements by deep learning methods such as AlphaFold2,\n\\textit{in silico} protein structure prediction remains a challenging problem\nin biomedical research. With the rapid evolution of quantum computing, it is\nnatural to ask whether quantum computers can offer some meaningful benefits for\napproaching this problem. Yet, identifying specific problem instances amenable\nto quantum advantage, and estimating quantum resources required are equally\nchallenging tasks. Here, we share our perspective on how to create a framework\nfor systematically selecting protein structure prediction problems that are\namenable for quantum advantage, and estimate quantum resources for such\nproblems on a utility-scale quantum computer. As a proof-of-concept, we\nvalidate our problem selection framework by accurately predicting the structure\nof a catalytic loop of the Zika Virus NS3 Helicase, on quantum hardware.",
            "author": [
                "Hakan Doga",
                "Bryan Raubenolt",
                "Fabio Cumbo",
                "Jayadev Joshi",
                "Frank P. DiFilippo",
                "Jun Qin",
                "Daniel Blankenberg",
                "Omar Shehab"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00875v1",
                "http://arxiv.org/pdf/2312.00875v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00870v1",
            "title": "3DiFACE: Diffusion-based Speech-driven 3D Facial Animation and Editing",
            "updated": "2023-12-01T19:01:05Z",
            "published": "2023-12-01T19:01:05Z",
            "summary": "We present 3DiFACE, a novel method for personalized speech-driven 3D facial\nanimation and editing. While existing methods deterministically predict facial\nanimations from speech, they overlook the inherent one-to-many relationship\nbetween speech and facial expressions, i.e., there are multiple reasonable\nfacial expression animations matching an audio input. It is especially\nimportant in content creation to be able to modify generated motion or to\nspecify keyframes. To enable stochasticity as well as motion editing, we\npropose a lightweight audio-conditioned diffusion model for 3D facial motion.\nThis diffusion model can be trained on a small 3D motion dataset, maintaining\nexpressive lip motion output. In addition, it can be finetuned for specific\nsubjects, requiring only a short video of the person. Through quantitative and\nqualitative evaluations, we show that our method outperforms existing\nstate-of-the-art techniques and yields speech-driven animations with greater\nfidelity and diversity.",
            "author": [
                "Balamurugan Thambiraja",
                "Sadegh Aliakbarian",
                "Darren Cosker",
                "Justus Thies"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00870v1",
                "http://arxiv.org/pdf/2312.00870v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.GR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00785v1",
            "title": "Sequential Modeling Enables Scalable Learning for Large Vision Models",
            "updated": "2023-12-01T18:59:57Z",
            "published": "2023-12-01T18:59:57Z",
            "summary": "We introduce a novel sequential modeling approach which enables learning a\nLarge Vision Model (LVM) without making use of any linguistic data. To do this,\nwe define a common format, \"visual sentences\", in which we can represent raw\nimages and videos as well as annotated data sources such as semantic\nsegmentations and depth reconstructions without needing any meta-knowledge\nbeyond the pixels. Once this wide variety of visual data (comprising 420\nbillion tokens) is represented as sequences, the model can be trained to\nminimize a cross-entropy loss for next token prediction. By training across\nvarious scales of model architecture and data diversity, we provide empirical\nevidence that our models scale effectively. Many different vision tasks can be\nsolved by designing suitable visual prompts at test time.",
            "author": [
                "Yutong Bai",
                "Xinyang Geng",
                "Karttikeya Mangalam",
                "Amir Bar",
                "Alan Yuille",
                "Trevor Darrell",
                "Jitendra Malik",
                "Alexei A Efros"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00785v1",
                "http://arxiv.org/pdf/2312.00785v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00784v1",
            "title": "Making Large Multimodal Models Understand Arbitrary Visual Prompts",
            "updated": "2023-12-01T18:59:56Z",
            "published": "2023-12-01T18:59:56Z",
            "summary": "While existing large vision-language multimodal models focus on whole image\nunderstanding, there is a prominent gap in achieving region-specific\ncomprehension. Current approaches that use textual coordinates or spatial\nencodings often fail to provide a user-friendly interface for visual prompting.\nTo address this challenge, we introduce a novel multimodal model capable of\ndecoding arbitrary visual prompts. This allows users to intuitively mark images\nand interact with the model using natural cues like a \"red bounding box\" or\n\"pointed arrow\". Our simple design directly overlays visual markers onto the\nRGB image, eliminating the need for complex region encodings, yet achieves\nstate-of-the-art performance on region-understanding tasks like Visual7W,\nPointQA, and Visual Commonsense Reasoning benchmark. Furthermore, we present\nViP-Bench, a comprehensive benchmark to assess the capability of models in\nunderstanding visual prompts across multiple dimensions, enabling future\nresearch in this domain. Code, data, and model are publicly available.",
            "author": [
                "Mu Cai",
                "Haotian Liu",
                "Siva Karthik Mustikovela",
                "Gregory P. Meyer",
                "Yuning Chai",
                "Dennis Park",
                "Yong Jae Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00784v1",
                "http://arxiv.org/pdf/2312.00784v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00775v1",
            "title": "Towards Generalizable Zero-Shot Manipulation via Translating Human\n  Interaction Plans",
            "updated": "2023-12-01T18:54:12Z",
            "published": "2023-12-01T18:54:12Z",
            "summary": "We pursue the goal of developing robots that can interact zero-shot with\ngeneric unseen objects via a diverse repertoire of manipulation skills and show\nhow passive human videos can serve as a rich source of data for learning such\ngeneralist robots. Unlike typical robot learning approaches which directly\nlearn how a robot should act from interaction data, we adopt a factorized\napproach that can leverage large-scale human videos to learn how a human would\naccomplish a desired task (a human plan), followed by translating this plan to\nthe robots embodiment. Specifically, we learn a human plan predictor that,\ngiven a current image of a scene and a goal image, predicts the future hand and\nobject configurations. We combine this with a translation module that learns a\nplan-conditioned robot manipulation policy, and allows following humans plans\nfor generic manipulation tasks in a zero-shot manner with no deployment-time\ntraining. Importantly, while the plan predictor can leverage large-scale human\nvideos for learning, the translation module only requires a small amount of\nin-domain data, and can generalize to tasks not seen during training. We show\nthat our learned system can perform over 16 manipulation skills that generalize\nto 40 objects, encompassing 100 real-world tasks for table-top manipulation and\ndiverse in-the-wild manipulation. https://homangab.github.io/hopman/",
            "author": [
                "Homanga Bharadhwaj",
                "Abhinav Gupta",
                "Vikash Kumar",
                "Shubham Tulsiani"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00775v1",
                "http://arxiv.org/pdf/2312.00775v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00774v1",
            "title": "Context Retrieval via Normalized Contextual Latent Interaction for\n  Conversational Agent",
            "updated": "2023-12-01T18:53:51Z",
            "published": "2023-12-01T18:53:51Z",
            "summary": "Conversational agents leveraging AI, particularly deep learning, are emerging\nin both academic research and real-world applications. However, these\napplications still face challenges, including disrespecting knowledge and\nfacts, not personalizing to user preferences, and enormous demand for\ncomputational resources during training and inference. Recent research efforts\nhave been focused on addressing these challenges from various aspects,\nincluding supplementing various types of auxiliary information to the\nconversational agents. However, existing methods are still not able to\neffectively and efficiently exploit relevant information from these auxiliary\nsupplements to further unleash the power of the conversational agents and the\nlanguage models they use. In this paper, we present a novel method, PK-NCLI,\nthat is able to accurately and efficiently identify relevant auxiliary\ninformation to improve the quality of conversational responses by learning the\nrelevance among persona, chat history, and knowledge background through\nlow-level normalized contextual latent interaction. Our experimental results\nindicate that PK-NCLI outperforms the state-of-the-art method, PK-FoCus, by\n47.80%/30.61%/24.14% in terms of perplexity, knowledge grounding, and training\nefficiency, respectively, and maintained the same level of persona grounding\nperformance. We also provide a detailed analysis of how different factors,\nincluding language model choices and trade-offs on training weights, would\naffect the performance of PK-NCLI.",
            "author": [
                "Junfeng Liu",
                "Zhuocheng Mei",
                "Kewen Peng",
                "Ranga Raju Vatsavai"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00774v1",
                "http://arxiv.org/pdf/2312.00774v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00770v1",
            "title": "Random Forest for Dynamic Risk Prediction or Recurrent Events: A\n  Pseudo-Observation Approach",
            "updated": "2023-12-01T18:48:52Z",
            "published": "2023-12-01T18:48:52Z",
            "summary": "Recurrent events are common in clinical, healthcare, social and behavioral\nstudies. A recent analysis framework for potentially censored recurrent event\ndata is to construct a censored longitudinal data set consisting of times to\nthe first recurrent event in multiple prespecified follow-up windows of length\n$\\tau$. With the staggering number of potential predictors being generated from\ngenetic, -omic, and electronic health records sources, machine learning\napproaches such as the random forest are growing in popularity, as they can\nincorporate information from highly correlated predictors with non-standard\nrelationships. In this paper, we bridge this gap by developing a random forest\napproach for dynamically predicting probabilities of remaining event-free\nduring a subsequent $\\tau$-duration follow-up period from a reconstructed\ncensored longitudinal data set. We demonstrate the increased ability of our\nrandom forest algorithm for predicting the probability of remaining event-free\nover a $\\tau$-duration follow-up period when compared to the recurrent event\nmodeling framework of Xia et al. (2020) in settings where association between\npredictors and recurrent event outcomes is complex in nature. The proposed\nrandom forest algorithm is demonstrated using recurrent exacerbation data from\nthe Azithromycin for the Prevention of Exacerbations of Chronic Obstructive\nPulmonary Disease (Albert et al., 2011).",
            "author": [
                "Abigail Loe",
                "Susan Murray",
                "Zhenke Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00770v1",
                "http://arxiv.org/pdf/2312.00770v1"
            ],
            "primary_category": "stat.AP",
            "category": [
                "stat.AP",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00766v1",
            "title": "Automated Material Properties Extraction For Enhanced Beauty Product\n  Discovery and Makeup Virtual Try-on",
            "updated": "2023-12-01T18:41:22Z",
            "published": "2023-12-01T18:41:22Z",
            "summary": "The multitude of makeup products available can make it challenging to find\nthe ideal match for desired attributes. An intelligent approach for product\ndiscovery is required to enhance the makeup shopping experience to make it more\nconvenient and satisfying. However, enabling accurate and efficient product\ndiscovery requires extracting detailed attributes like color and finish type.\nOur work introduces an automated pipeline that utilizes multiple customized\nmachine learning models to extract essential material attributes from makeup\nproduct images. Our pipeline is versatile and capable of handling various\nmakeup products. To showcase the efficacy of our pipeline, we conduct extensive\nexperiments on eyeshadow products (both single and multi-shade ones), a\nchallenging makeup product known for its diverse range of shapes, colors, and\nfinish types. Furthermore, we demonstrate the applicability of our approach by\nsuccessfully extending it to other makeup categories like lipstick and\nfoundation, showcasing its adaptability and effectiveness across different\nbeauty products. Additionally, we conduct ablation experiments to demonstrate\nthe superiority of our machine learning pipeline over human labeling methods in\nterms of reliability. Our proposed method showcases its effectiveness in\ncross-category product discovery, specifically in recommending makeup products\nthat perfectly match a specified outfit. Lastly, we also demonstrate the\napplication of these material attributes in enabling virtual-try-on experiences\nwhich makes makeup shopping experience significantly more engaging.",
            "author": [
                "Fatemeh Taheri Dezaki",
                "Himanshu Arora",
                "Rahul Suresh",
                "Amin Banitalebi-Dehkordi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00766v1",
                "http://arxiv.org/pdf/2312.00766v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00765v1",
            "title": "Explaining Knock-on Effects of Bias Mitigation",
            "updated": "2023-12-01T18:40:37Z",
            "published": "2023-12-01T18:40:37Z",
            "summary": "In machine learning systems, bias mitigation approaches aim to make outcomes\nfairer across privileged and unprivileged groups. Bias mitigation methods work\nin different ways and have known \"waterfall\" effects, e.g., mitigating bias at\none place may manifest bias elsewhere. In this paper, we aim to characterise\nimpacted cohorts when mitigation interventions are applied. To do so, we treat\nintervention effects as a classification task and learn an explainable\nmeta-classifier to identify cohorts that have altered outcomes. We examine a\nrange of bias mitigation strategies that work at various stages of the model\nlife cycle. We empirically demonstrate that our meta-classifier is able to\nuncover impacted cohorts. Further, we show that all tested mitigation\nstrategies negatively impact a non-trivial fraction of cases, i.e., people who\nreceive unfavourable outcomes solely on account of mitigation efforts. This is\ndespite improvement in fairness metrics. We use these results as a basis to\nargue for more careful audits of static mitigation interventions that go beyond\naggregate metrics.",
            "author": [
                "Svetoslav Nizhnichenkov",
                "Rahul Nair",
                "Elizabeth Daly",
                "Brian Mac Namee"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00765v1",
                "http://arxiv.org/pdf/2312.00765v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00763v1",
            "title": "Beyond ChatBots: ExploreLLM for Structured Thoughts and Personalized\n  Model Responses",
            "updated": "2023-12-01T18:31:28Z",
            "published": "2023-12-01T18:31:28Z",
            "summary": "Large language model (LLM) powered chatbots are primarily text-based today,\nand impose a large interactional cognitive load, especially for exploratory or\nsensemaking tasks such as planning a trip or learning about a new city. Because\nthe interaction is textual, users have little scaffolding in the way of\nstructure, informational \"scent\", or ability to specify high-level preferences\nor goals. We introduce ExploreLLM that allows users to structure thoughts, help\nexplore different options, navigate through the choices and recommendations,\nand to more easily steer models to generate more personalized responses. We\nconduct a user study and show that users find it helpful to use ExploreLLM for\nexploratory or planning tasks, because it provides a useful schema-like\nstructure to the task, and guides users in planning. The study also suggests\nthat users can more easily personalize responses with high-level preferences\nwith ExploreLLM. Together, ExploreLLM points to a future where users interact\nwith LLMs beyond the form of chatbots, and instead designed to support complex\nuser tasks with a tighter integration between natural language and graphical\nuser interfaces.",
            "author": [
                "Xiao Ma",
                "Swaroop Mishra",
                "Ariel Liu",
                "Sophie Su",
                "Jilin Chen",
                "Chinmay Kulkarni",
                "Heng-Tze Cheng",
                "Quoc Le",
                "Ed Chi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00763v1",
                "http://arxiv.org/pdf/2312.00763v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00863v1",
            "title": "EfficientSAM: Leveraged Masked Image Pretraining for Efficient Segment\n  Anything",
            "updated": "2023-12-01T18:31:00Z",
            "published": "2023-12-01T18:31:00Z",
            "summary": "Segment Anything Model (SAM) has emerged as a powerful tool for numerous\nvision applications. A key component that drives the impressive performance for\nzero-shot transfer and high versatility is a super large Transformer model\ntrained on the extensive high-quality SA-1B dataset. While beneficial, the huge\ncomputation cost of SAM model has limited its applications to wider real-world\napplications. To address this limitation, we propose EfficientSAMs,\nlight-weight SAM models that exhibits decent performance with largely reduced\ncomplexity. Our idea is based on leveraging masked image pretraining, SAMI,\nwhich learns to reconstruct features from SAM image encoder for effective\nvisual representation learning. Further, we take SAMI-pretrained light-weight\nimage encoders and mask decoder to build EfficientSAMs, and finetune the models\non SA-1B for segment anything task. We perform evaluations on multiple vision\ntasks including image classification, object detection, instance segmentation,\nand semantic object detection, and find that our proposed pretraining method,\nSAMI, consistently outperforms other masked image pretraining methods. On\nsegment anything task such as zero-shot instance segmentation, our\nEfficientSAMs with SAMI-pretrained lightweight image encoders perform favorably\nwith a significant gain (e.g., ~4 AP on COCO/LVIS) over other fast SAM models.",
            "author": [
                "Yunyang Xiong",
                "Bala Varadarajan",
                "Lemeng Wu",
                "Xiaoyu Xiang",
                "Fanyi Xiao",
                "Chenchen Zhu",
                "Xiaoliang Dai",
                "Dilin Wang",
                "Fei Sun",
                "Forrest Iandola",
                "Raghuraman Krishnamoorthi",
                "Vikas Chandra"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00863v1",
                "http://arxiv.org/pdf/2312.00863v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00761v2",
            "title": "Deep Unlearning: Fast and Efficient Training-free Approach to Controlled\n  Forgetting",
            "updated": "2023-12-04T01:57:38Z",
            "published": "2023-12-01T18:29:08Z",
            "summary": "Machine unlearning has emerged as a prominent and challenging area of\ninterest, driven in large part by the rising regulatory demands for industries\nto delete user data upon request and the heightened awareness of privacy.\nExisting approaches either retrain models from scratch or use several\nfinetuning steps for every deletion request, often constrained by computational\nresource limitations and restricted access to the original training data. In\nthis work, we introduce a novel class unlearning algorithm designed to\nstrategically eliminate an entire class or a group of classes from the learned\nmodel. To that end, our algorithm first estimates the Retain Space and the\nForget Space, representing the feature or activation spaces for samples from\nclasses to be retained and unlearned, respectively. To obtain these spaces, we\npropose a novel singular value decomposition-based technique that requires\nlayer wise collection of network activations from a few forward passes through\nthe network. We then compute the shared information between these spaces and\nremove it from the forget space to isolate class-discriminatory feature space\nfor unlearning. Finally, we project the model weights in the orthogonal\ndirection of the class-discriminatory space to obtain the unlearned model. We\ndemonstrate our algorithm's efficacy on ImageNet using a Vision Transformer\nwith only $\\sim$1.5% drop in retain accuracy compared to the original model\nwhile maintaining under 1% accuracy on the unlearned class samples. Further,\nour algorithm consistently performs well when subject to Membership Inference\nAttacks showing 7.8% improvement on average across a variety of image\nclassification datasets and network architectures, as compared to other\nbaselines while being $\\sim$6x more computationally efficient.",
            "author": [
                "Sangamesh Kodge",
                "Gobinda Saha",
                "Kaushik Roy"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00761v2",
                "http://arxiv.org/pdf/2312.00761v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00752v1",
            "title": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces",
            "updated": "2023-12-01T18:01:34Z",
            "published": "2023-12-01T18:01:34Z",
            "summary": "Foundation models, now powering most of the exciting applications in deep\nlearning, are almost universally based on the Transformer architecture and its\ncore attention module. Many subquadratic-time architectures such as linear\nattention, gated convolution and recurrent models, and structured state space\nmodels (SSMs) have been developed to address Transformers' computational\ninefficiency on long sequences, but they have not performed as well as\nattention on important modalities such as language. We identify that a key\nweakness of such models is their inability to perform content-based reasoning,\nand make several improvements. First, simply letting the SSM parameters be\nfunctions of the input addresses their weakness with discrete modalities,\nallowing the model to selectively propagate or forget information along the\nsequence length dimension depending on the current token. Second, even though\nthis change prevents the use of efficient convolutions, we design a\nhardware-aware parallel algorithm in recurrent mode. We integrate these\nselective SSMs into a simplified end-to-end neural network architecture without\nattention or even MLP blocks (Mamba). Mamba enjoys fast inference (5$\\times$\nhigher throughput than Transformers) and linear scaling in sequence length, and\nits performance improves on real data up to million-length sequences. As a\ngeneral sequence model backbone, Mamba achieves state-of-the-art performance\nacross several modalities such as language, audio, and genomics. On language\nmodeling, our Mamba-3B model outperforms Transformers of the same size and\nmatches Transformers twice its size, both in pretraining and downstream\nevaluation.",
            "author": [
                "Albert Gu",
                "Tri Dao"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00752v1",
                "http://arxiv.org/pdf/2312.00752v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00746v1",
            "title": "Deciphering Digital Detectives: Understanding LLM Behaviors and\n  Capabilities in Multi-Agent Mystery Games",
            "updated": "2023-12-01T17:33:57Z",
            "published": "2023-12-01T17:33:57Z",
            "summary": "In this study, we explore the application of Large Language Models (LLMs) in\n\"Jubensha\" (Chinese murder mystery role-playing games), a novel area in\nAI-driven gaming. We introduce the first Chinese dataset specifically for\nJubensha, including character scripts and game rules, to foster AI agent\ndevelopment in this complex narrative environment. Our work also presents a\nunique multi-agent interaction framework using LLMs, allowing AI agents to\nautonomously engage in the game, enhancing the dynamics of Jubensha gameplay.\nTo evaluate these AI agents, we developed specialized methods targeting their\nmastery of case information and reasoning skills. Furthermore, we incorporated\nthe latest advancements in in-context learning to improve the agents'\nperformance in critical aspects like information gathering, murderer detection,\nand logical reasoning. The experimental results validate the effectiveness of\nour proposed methods. This work aims to offer a fresh perspective on\nunderstanding LLM capabilities and establish a new benchmark for evaluating\nlarge language model-based agents to researchers in the field.",
            "author": [
                "Dekun Wu",
                "Haochen Shi",
                "Zhiyuan Sun",
                "Bang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00746v1",
                "http://arxiv.org/pdf/2312.00746v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "I.2.0; I.2.1; I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00742v1",
            "title": "Scalable Meta-Learning with Gaussian Processes",
            "updated": "2023-12-01T17:25:10Z",
            "published": "2023-12-01T17:25:10Z",
            "summary": "Meta-learning is a powerful approach that exploits historical data to quickly\nsolve new tasks from the same distribution. In the low-data regime, methods\nbased on the closed-form posterior of Gaussian processes (GP) together with\nBayesian optimization have achieved high performance. However, these methods\nare either computationally expensive or introduce assumptions that hinder a\nprincipled propagation of uncertainty between task models. This may disrupt the\nbalance between exploration and exploitation during optimization. In this\npaper, we develop ScaML-GP, a modular GP model for meta-learning that is\nscalable in the number of tasks. Our core contribution is a carefully designed\nmulti-task kernel that enables hierarchical training and task scalability.\nConditioning ScaML-GP on the meta-data exposes its modular nature yielding a\ntest-task prior that combines the posteriors of meta-task GPs. In synthetic and\nreal-world meta-learning experiments, we demonstrate that ScaML-GP can learn\nefficiently both with few and many meta-tasks.",
            "author": [
                "Petru Tighineanu",
                "Lukas Grossberger",
                "Paul Baireuther",
                "Kathrin Skubch",
                "Stefan Falkner",
                "Julia Vinogradska",
                "Felix Berkenkamp"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00742v1",
                "http://arxiv.org/pdf/2312.00742v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00740v1",
            "title": "Computing Networks Enabled Semantic Communications",
            "updated": "2023-12-01T17:21:27Z",
            "published": "2023-12-01T17:21:27Z",
            "summary": "Semantic communication has shown great potential in boosting the\neffectiveness and reliability of communications. However, its systems to date\nare mostly enabled by deep learning, which requires demanding computing\nresources. This article proposes a framework for the computing networks enabled\nsemantic communication system, aiming to offer sufficient computing resources\nfor semantic processing and transmission. Key techniques including semantic\nsampling and reconstruction, semantic-channel coding, semantic-aware resource\nallocation and optimization are introduced based on the cloud-edge-end\ncomputing coordination. Two use cases are demonstrated to show advantages of\nthe proposed framework. The article concludes with several future research\ndirections.",
            "author": [
                "Zhijin Qin",
                "Jingkai Ying",
                "Dingxi Yang",
                "Hengjiang Wang",
                "Xiaoming Tao"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00740v1",
                "http://arxiv.org/pdf/2312.00740v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00733v1",
            "title": "Provable bounds for noise-free expectation values computed from noisy\n  samples",
            "updated": "2023-12-01T17:12:18Z",
            "published": "2023-12-01T17:12:18Z",
            "summary": "In this paper, we explore the impact of noise on quantum computing,\nparticularly focusing on the challenges when sampling bit strings from noisy\nquantum computers as well as the implications for optimization and machine\nlearning applications. We formally quantify the sampling overhead to extract\ngood samples from noisy quantum computers and relate it to the layer fidelity,\na metric to determine the performance of noisy quantum processors. Further, we\nshow how this allows us to use the Conditional Value at Risk of noisy samples\nto determine provable bounds on noise-free expectation values. We discuss how\nto leverage these bounds for different algorithms and demonstrate our findings\nthrough experiments on a real quantum computer involving up to 127 qubits. The\nresults show a strong alignment with theoretical predictions.",
            "author": [
                "Samantha V. Barron",
                "Daniel J. Egger",
                "Elijah Pelofske",
                "Andreas B\u00e4rtschi",
                "Stephan Eidenbenz",
                "Matthis Lehmkuehler",
                "Stefan Woerner"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00733v1",
                "http://arxiv.org/pdf/2312.00733v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.ET"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00728v1",
            "title": "Soft computing for the posterior of a new matrix t graphical network",
            "updated": "2023-12-01T17:05:04Z",
            "published": "2023-12-01T17:05:04Z",
            "summary": "Modelling noisy data in a network context remains an unavoidable obstacle;\nfortunately, random matrix theory may comprehensively describe network\nenvironments effectively. Thus it necessitates the probabilistic\ncharacterisation of these networks (and accompanying noisy data) using matrix\nvariate models. Denoising network data using a Bayes approach is not common in\nsurveyed literature. This paper adopts the Bayesian viewpoint and introduces a\nnew matrix variate t-model in a prior sense by relying on the matrix variate\ngamma distribution for the noise process, following the Gaussian graphical\nnetwork for the cases when the normality assumption is violated. From a\nstatistical learning viewpoint, such a theoretical consideration indubitably\nbenefits the real-world comprehension of structures causing noisy data with\nnetwork-based attributes as part of machine learning in data science. A full\nstructural learning procedure is provided for calculating and approximating the\nresulting posterior of interest to assess the considered model's network\ncentrality measures. Experiments with synthetic and real-world stock price data\nare performed not only to validate the proposed algorithm's capabilities but\nalso to show that this model has wider flexibility than originally implied in\nBillio et al. (2021).",
            "author": [
                "J. Pillay",
                "A. Bekker",
                "J. T. Ferreira",
                "M. Arashi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00728v1",
                "http://arxiv.org/pdf/2312.00728v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02185v1",
            "title": "Virtual Fusion with Contrastive Learning for Single Sensor-based\n  Activity Recognition",
            "updated": "2023-12-01T17:03:27Z",
            "published": "2023-12-01T17:03:27Z",
            "summary": "Various types of sensors can be used for Human Activity Recognition (HAR),\nand each of them has different strengths and weaknesses. Sometimes a single\nsensor cannot fully observe the user's motions from its perspective, which\ncauses wrong predictions. While sensor fusion provides more information for\nHAR, it comes with many inherent drawbacks like user privacy and acceptance,\ncostly set-up, operation, and maintenance. To deal with this problem, we\npropose Virtual Fusion - a new method that takes advantage of unlabeled data\nfrom multiple time-synchronized sensors during training, but only needs one\nsensor for inference. Contrastive learning is adopted to exploit the\ncorrelation among sensors. Virtual Fusion gives significantly better accuracy\nthan training with the same single sensor, and in some cases, it even surpasses\nactual fusion using multiple sensors at test time. We also extend this method\nto a more general version called Actual Fusion within Virtual Fusion (AFVF),\nwhich uses a subset of training sensors during inference. Our method achieves\nstate-of-the-art accuracy and F1-score on UCI-HAR and PAMAP2 benchmark\ndatasets. Implementation is available upon request.",
            "author": [
                "Duc-Anh Nguyen",
                "Cuong Pham",
                "Nhien-An Le-Khac"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02185v1",
                "http://arxiv.org/pdf/2312.02185v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00727v1",
            "title": "Safe Reinforcement Learning in Tensor Reproducing Kernel Hilbert Space",
            "updated": "2023-12-01T17:01:37Z",
            "published": "2023-12-01T17:01:37Z",
            "summary": "This paper delves into the problem of safe reinforcement learning (RL) in a\npartially observable environment with the aim of achieving safe-reachability\nobjectives. In traditional partially observable Markov decision processes\n(POMDP), ensuring safety typically involves estimating the belief in latent\nstates. However, accurately estimating an optimal Bayesian filter in POMDP to\ninfer latent states from observations in a continuous state space poses a\nsignificant challenge, largely due to the intractable likelihood. To tackle\nthis issue, we propose a stochastic model-based approach that guarantees RL\nsafety almost surely in the face of unknown system dynamics and partial\nobservation environments. We leveraged the Predictive State Representation\n(PSR) and Reproducing Kernel Hilbert Space (RKHS) to represent future\nmulti-step observations analytically, and the results in this context are\nprovable. Furthermore, we derived essential operators from the kernel Bayes'\nrule, enabling the recursive estimation of future observations using various\noperators. Under the assumption of \\textit{undercompleness}, a polynomial\nsample complexity is established for the RL algorithm for the infinite size of\nobservation and action spaces, ensuring an $\\epsilon-$suboptimal safe policy\nguarantee.",
            "author": [
                "Xiaoyuan Cheng",
                "Boli Chen",
                "Liz Varga",
                "Yukun Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00727v1",
                "http://arxiv.org/pdf/2312.00727v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00720v1",
            "title": "Efficiently Processing Large Relational Joins on GPUs",
            "updated": "2023-12-01T16:55:17Z",
            "published": "2023-12-01T16:55:17Z",
            "summary": "With the growing interest in Machine Learning (ML), Graphic Processing Units\n(GPUs) have become key elements of any computing infrastructure. Their\nwidespread deployment in data centers and the cloud raises the question of how\nto use them beyond ML use cases, with growing interest in employing them in a\ndatabase context. In this paper, we explore and analyze the implementation of\nrelational joins on GPUs from an end-to-end perspective, meaning that we take\nresult materialization into account. We conduct a comprehensive performance\nstudy of state-of-the-art GPU-based join algorithms over diverse synthetic\nworkloads and TPC-H/TPC-DS benchmarks. Without being restricted to the\nconventional setting where each input relation has only one key and one non-key\nwith all attributes being 4-bytes long, we investigate the effect of various\nfactors (e.g., input sizes, number of non-key columns, skewness, data types,\nmatch ratios, and number of joins) on the end-to-end throughput. Furthermore,\nwe propose a technique called \"Gather-from-Transformed-Relations\" (GFTR) to\nreduce the long-ignored yet high materialization cost in GPU-based joins. The\nexperimental evaluation shows significant performance improvements from GFTR,\nwith throughput gains of up to 2.3 times over previous work. The insights\ngained from the performance study not only advance the understanding of\nGPU-based joins but also introduce a structured approach to selecting the most\nefficient GPU join algorithm based on the input relation characteristics.",
            "author": [
                "Bowen Wu",
                "Dimitrios Koutsoukos",
                "Gustavo Alonso"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00720v1",
                "http://arxiv.org/pdf/2312.00720v1"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00718v1",
            "title": "Removing Biases from Molecular Representations via Information\n  Maximization",
            "updated": "2023-12-01T16:53:15Z",
            "published": "2023-12-01T16:53:15Z",
            "summary": "High-throughput drug screening -- using cell imaging or gene expression\nmeasurements as readouts of drug effect -- is a critical tool in biotechnology\nto assess and understand the relationship between the chemical structure and\nbiological activity of a drug. Since large-scale screens have to be divided\ninto multiple experiments, a key difficulty is dealing with batch effects,\nwhich can introduce systematic errors and non-biological associations in the\ndata. We propose InfoCORE, an Information maximization approach for COnfounder\nREmoval, to effectively deal with batch effects and obtain refined molecular\nrepresentations. InfoCORE establishes a variational lower bound on the\nconditional mutual information of the latent representations given a batch\nidentifier. It adaptively reweighs samples to equalize their implied batch\ndistribution. Extensive experiments on drug screening data reveal InfoCORE's\nsuperior performance in a multitude of tasks including molecular property\nprediction and molecule-phenotype retrieval. Additionally, we show results for\nhow InfoCORE offers a versatile framework and resolves general distribution\nshifts and issues of data fairness by minimizing correlation with spurious\nfeatures or removing sensitive attributes. The code is available at\nhttps://github.com/uhlerlab/InfoCORE.",
            "author": [
                "Chenyu Wang",
                "Sharut Gupta",
                "Caroline Uhler",
                "Tommi Jaakkola"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00718v1",
                "http://arxiv.org/pdf/2312.00718v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "q-bio.BM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00713v1",
            "title": "Nonlinear-manifold reduced order models with domain decomposition",
            "updated": "2023-12-01T16:47:13Z",
            "published": "2023-12-01T16:47:13Z",
            "summary": "A nonlinear-manifold reduced order model (NM-ROM) is a great way of\nincorporating underlying physics principles into a neural network-based\ndata-driven approach. We combine NM-ROMs with domain decomposition (DD) for\nefficient computation. NM-ROMs offer benefits over linear-subspace ROMs\n(LS-ROMs) but can be costly to train due to parameter scaling with the\nfull-order model (FOM) size. To address this, we employ DD on the FOM, compute\nsubdomain NM-ROMs, and then merge them into a global NM-ROM. This approach has\nmultiple advantages: parallel training of subdomain NM-ROMs, fewer parameters\nthan global NM-ROMs, and adaptability to subdomain-specific FOM features. Each\nsubdomain NM-ROM uses a shallow, sparse autoencoder, enabling hyper-reduction\n(HR) for improved computational speed. In this paper, we detail an algebraic DD\nformulation for the FOM, train HR-equipped NM-ROMs for subdomains, and\nnumerically compare them to DD LS-ROMs with HR. Results show a significant\naccuracy boost, on the order of magnitude, for the proposed DD NM-ROMs over DD\nLS-ROMs in solving the 2D steady-state Burgers' equation.",
            "author": [
                "Alejandro N. Diaz",
                "Youngsoo Choi",
                "Matthias Heinkenschloss"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00713v1",
                "http://arxiv.org/pdf/2312.00713v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00710v2",
            "title": "SpaCE: The Spatial Confounding Environment",
            "updated": "2023-12-06T02:00:53Z",
            "published": "2023-12-01T16:42:57Z",
            "summary": "Spatial confounding poses a significant challenge in scientific studies\ninvolving spatial data, where unobserved spatial variables can influence both\ntreatment and outcome, possibly leading to spurious associations. To address\nthis problem, we introduce SpaCE: The Spatial Confounding Environment, the\nfirst toolkit to provide realistic benchmark datasets and tools for\nsystematically evaluating causal inference methods designed to alleviate\nspatial confounding. Each dataset includes training data, true counterfactuals,\na spatial graph with coordinates, and smoothness and confounding scores\ncharacterizing the effect of a missing spatial confounder. It also includes\nrealistic semi-synthetic outcomes and counterfactuals, generated using\nstate-of-the-art machine learning ensembles, following best practices for\ncausal inference benchmarks. The datasets cover real treatment and covariates\nfrom diverse domains, including climate, health and social sciences. SpaCE\nfacilitates an automated end-to-end pipeline, simplifying data loading,\nexperimental setup, and evaluating machine learning and causal inference\nmodels. The SpaCE project provides several dozens of datasets of diverse sizes\nand spatial complexity. It is publicly available as a Python package,\nencouraging community feedback and contributions.",
            "author": [
                "Mauricio Tec",
                "Ana Trisovic",
                "Michelle Audirac",
                "Sophie Woodward",
                "Jie Kate Hu",
                "Naeem Khoshnevis",
                "Francesca Dominici"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00710v2",
                "http://arxiv.org/pdf/2312.00710v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ME",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00708v1",
            "title": "Message-Passing on Hypergraphs: Detectability, Phase Transitions and\n  Higher-Order Information",
            "updated": "2023-12-01T16:42:28Z",
            "published": "2023-12-01T16:42:28Z",
            "summary": "Hypergraphs are widely adopted tools to examine systems with higher-order\ninteractions. Despite recent advancements in methods for community detection in\nthese systems, we still lack a theoretical analysis of their detectability\nlimits. Here, we derive closed-form bounds for community detection in\nhypergraphs. Using a Message-Passing formulation, we demonstrate that\ndetectability depends on hypergraphs' structural properties, such as the\ndistribution of hyperedge sizes or their assortativity. Our formulation enables\na characterization of the entropy of a hypergraph in relation to that of its\nclique expansion, showing that community detection is enhanced when hyperedges\nhighly overlap on pairs of nodes. We develop an efficient Message-Passing\nalgorithm to learn communities and model parameters on large systems.\nAdditionally, we devise an exact sampling routine to generate synthetic data\nfrom our probabilistic model. With these methods, we numerically investigate\nthe boundaries of community detection in synthetic datasets, and extract\ncommunities from real systems. Our results extend the understanding of the\nlimits of community detection in hypergraphs and introduce flexible\nmathematical tools to study systems with higher-order interactions.",
            "author": [
                "Nicol\u00f2 Ruggeri",
                "Alessandro Lonardi",
                "Caterina De Bacco"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00708v1",
                "http://arxiv.org/pdf/2312.00708v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.IT",
                "math.IT",
                "physics.data-an"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00700v1",
            "title": "GIFT: Generative Interpretable Fine-Tuning Transformers",
            "updated": "2023-12-01T16:33:57Z",
            "published": "2023-12-01T16:33:57Z",
            "summary": "We present GIFT (Generative Interpretable Fine-tuning Transformers) for\nfine-tuning pretrained (often large) Transformer models at downstream tasks in\na parameter-efficient way with built-in interpretability. Our GIFT is a deep\nparameter-residual learning method, which addresses two problems in fine-tuning\na pretrained Transformer model: Where to apply the parameter-efficient\nfine-tuning (PEFT) to be extremely lightweight yet sufficiently expressive, and\nHow to learn the PEFT to better exploit the knowledge of the pretrained model\nin a direct way? For the former, we select the final projection (linear) layer\nin the multi-head self-attention of a Transformer model, and verify its\neffectiveness. For the latter, in contrast to the prior art that directly\nintroduce new model parameters (often in low-rank approximation form) to be\nlearned in fine-tuning with downstream data, we propose a method for learning\nto generate the fine-tuning parameters. Our GIFT is a hyper-Transformer which\ntake as input the pretrained parameters of the projection layer to generate its\nfine-tuning parameters using a proposed Parameter-to-Cluster Attention (PaCa).\nThe PaCa results in a simple clustering-based forward explainer that plays the\nrole of semantic segmentation in testing. In experiments, our proposed GIFT is\ntested on the VTAB benchmark and the fine-grained visual classification (FGVC)\nbenchmark. It obtains significantly better performance than the prior art. Our\ncode is available at https://github.com/savadikarc/gift",
            "author": [
                "Chinmay Savadikar",
                "Xi Song",
                "Tianfu Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00700v1",
                "http://arxiv.org/pdf/2312.00700v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00694v1",
            "title": "Object Detector Differences when using Synthetic and Real Training Data",
            "updated": "2023-12-01T16:27:48Z",
            "published": "2023-12-01T16:27:48Z",
            "summary": "To train well-performing generalizing neural networks, sufficiently large and\ndiverse datasets are needed. Collecting data while adhering to privacy\nlegislation becomes increasingly difficult and annotating these large datasets\nis both a resource-heavy and time-consuming task. An approach to overcome these\ndifficulties is to use synthetic data since it is inherently scalable and can\nbe automatically annotated. However, how training on synthetic data affects the\nlayers of a neural network is still unclear. In this paper, we train the YOLOv3\nobject detector on real and synthetic images from city environments. We perform\na similarity analysis using Centered Kernel Alignment (CKA) to explore the\neffects of training on synthetic data on a layer-wise basis. The analysis\ncaptures the architecture of the detector while showing both different and\nsimilar patterns between different models. With this similarity analysis we\nwant to give insights on how training synthetic data affects each layer and to\ngive a better understanding of the inner workings of complex neural networks.\nThe results show that the largest similarity between a detector trained on real\ndata and a detector trained on synthetic data was in the early layers, and the\nlargest difference was in the head part. The results also show that no major\ndifference in performance or similarity could be seen between frozen and\nunfrozen backbone.",
            "author": [
                "Martin Georg Ljungqvist",
                "Otto Nordander",
                "Markus Skans",
                "Arvid Mildner",
                "Tony Liu",
                "Pierre Nugues"
            ],
            "link": [
                "http://dx.doi.org/10.1007/s42979-023-01704-5",
                "http://arxiv.org/abs/2312.00694v1",
                "http://arxiv.org/pdf/2312.00694v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "I.4.0; I.2.10; I.5.0"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00690v2",
            "title": "Open-vocabulary object 6D pose estimation",
            "updated": "2023-12-07T09:41:54Z",
            "published": "2023-12-01T16:17:16Z",
            "summary": "We introduce the new setting of open-vocabulary object 6D pose estimation, in\nwhich a textual prompt is used to specify the object of interest. In contrast\nto existing approaches, in our setting (i) the object of interest is specified\nsolely through the textual prompt, (ii) no object model (e.g. CAD or video\nsequence) is required at inference, (iii) the object is imaged from two\ndifferent viewpoints of two different scenes, and (iv) the object was not\nobserved during the training phase. To operate in this setting, we introduce a\nnovel approach that leverages a Vision-Language Model to segment the object of\ninterest from two distinct scenes and to estimate its relative 6D pose. The key\nof our approach is a carefully devised strategy to fuse object-level\ninformation provided by the prompt with local image features, resulting in a\nfeature space that can generalize to novel concepts. We validate our approach\non a new benchmark based on two popular datasets, REAL275 and Toyota-Light,\nwhich collectively encompass 39 object instances appearing in four thousand\nimage pairs. The results demonstrate that our approach outperforms both a\nwell-established hand-crafted method and a recent deep learning-based baseline\nin estimating the relative 6D pose of objects in different scenes. Project\npage: https://jcorsetti.github.io/oryon/.",
            "author": [
                "Jaime Corsetti",
                "Davide Boscaini",
                "Changjae Oh",
                "Andrea Cavallaro",
                "Fabio Poiesi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00690v2",
                "http://arxiv.org/pdf/2312.00690v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00688v1",
            "title": "Towards Transparency in Coreference Resolution: A Quantum-Inspired\n  Approach",
            "updated": "2023-12-01T16:11:38Z",
            "published": "2023-12-01T16:11:38Z",
            "summary": "Guided by grammatical structure, words compose to form sentences, and guided\nby discourse structure, sentences compose to form dialogues and documents. The\ncompositional aspect of sentence and discourse units is often overlooked by\nmachine learning algorithms. A recent initiative called Quantum Natural\nLanguage Processing (QNLP) learns word meanings as points in a Hilbert space\nand acts on them via a translation of grammatical structure into Parametrised\nQuantum Circuits (PQCs). Previous work extended the QNLP translation to\ndiscourse structure using points in a closure of Hilbert spaces. In this paper,\nwe evaluate this translation on a Winograd-style pronoun resolution task. We\ntrain a Variational Quantum Classifier (VQC) for binary classification and\nimplement an end-to-end pronoun resolution system. The simulations executed on\nIBMQ software converged with an F1 score of 87.20%. The model outperformed two\nout of three classical coreference resolution systems and neared\nstate-of-the-art SpanBERT. A mixed quantum-classical model yet improved these\nresults with an F1 score increase of around 6%.",
            "author": [
                "Hadi Wazni",
                "Mehrnoosh Sadrzadeh"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00688v1",
                "http://arxiv.org/pdf/2312.00688v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00677v1",
            "title": "Unsupervised Adaptive Implicit Neural Representation Learning for\n  Scan-Specific MRI Reconstruction",
            "updated": "2023-12-01T16:00:16Z",
            "published": "2023-12-01T16:00:16Z",
            "summary": "In recent studies on MRI reconstruction, advances have shown significant\npromise for further accelerating the MRI acquisition. Most state-of-the-art\nmethods require a large amount of fully-sampled data to optimise reconstruction\nmodels, which is impractical and expensive under certain clinical settings. On\nthe other hand, for unsupervised scan-specific reconstruction methods,\noverfitting is likely to happen due to insufficient supervision, while\nrestrictions on acceleration rates and under-sampling patterns further limit\ntheir applicability. To this end, we propose an unsupervised, adaptive\ncoarse-to-fine framework that enhances reconstruction quality without being\nconstrained by the sparsity levels or patterns in under-sampling. The framework\nemploys an implicit neural representation for scan-specific MRI reconstruction,\nlearning a mapping from multi-dimensional coordinates to their corresponding\nsignal intensities. Moreover, we integrate a novel learning strategy that\nprogressively refines the use of acquired k-space signals for self-supervision.\nThis approach effectively adjusts the proportion of supervising signals from\nunevenly distributed information across different frequency bands, thus\nmitigating the issue of overfitting while improving the overall reconstruction.\nComprehensive evaluation on a public dataset, including both 2D and 3D data,\nhas shown that our method outperforms current state-of-the-art scan-specific\nMRI reconstruction techniques, for up to 8-fold under-sampling.",
            "author": [
                "Junwei Yang",
                "Pietro Li\u00f2"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00677v1",
                "http://arxiv.org/pdf/2312.00677v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00674v1",
            "title": "LightCLIP: Learning Multi-Level Interaction for Lightweight\n  Vision-Language Models",
            "updated": "2023-12-01T15:54:55Z",
            "published": "2023-12-01T15:54:55Z",
            "summary": "Vision-language pre-training like CLIP has shown promising performance on\nvarious downstream tasks such as zero-shot image classification and image-text\nretrieval. Most of the existing CLIP-alike works usually adopt relatively large\nimage encoders like ResNet50 and ViT, while the lightweight counterparts are\nrarely discussed. In this paper, we propose a multi-level interaction paradigm\nfor training lightweight CLIP models. Firstly, to mitigate the problem that\nsome image-text pairs are not strictly one-to-one correspondence, we improve\nthe conventional global instance-level alignment objective by softening the\nlabel of negative samples progressively. Secondly, a relaxed bipartite matching\nbased token-level alignment objective is introduced for finer-grained alignment\nbetween image patches and textual words. Moreover, based on the observation\nthat the accuracy of CLIP model does not increase correspondingly as the\nparameters of text encoder increase, an extra objective of masked language\nmodeling (MLM) is leveraged for maximizing the potential of the shortened text\nencoder. In practice, an auxiliary fusion module injecting unmasked image\nembedding into masked text embedding at different network stages is proposed\nfor enhancing the MLM. Extensive experiments show that without introducing\nadditional computational cost during inference, the proposed method achieves a\nhigher performance on multiple downstream tasks.",
            "author": [
                "Ying Nie",
                "Wei He",
                "Kai Han",
                "Yehui Tang",
                "Tianyu Guo",
                "Fanyi Du",
                "Yunhe Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00674v1",
                "http://arxiv.org/pdf/2312.00674v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00671v1",
            "title": "CellMixer: Annotation-free Semantic Cell Segmentation of Heterogeneous\n  Cell Populations",
            "updated": "2023-12-01T15:50:20Z",
            "published": "2023-12-01T15:50:20Z",
            "summary": "In recent years, several unsupervised cell segmentation methods have been\npresented, trying to omit the requirement of laborious pixel-level annotations\nfor the training of a cell segmentation model. Most if not all of these methods\nhandle the instance segmentation task by focusing on the detection of different\ncell instances ignoring their type. While such models prove adequate for\ncertain tasks, like cell counting, other applications require the\nidentification of each cell's type. In this paper, we present CellMixer, an\ninnovative annotation-free approach for the semantic segmentation of\nheterogeneous cell populations. Our augmentation-based method enables the\ntraining of a segmentation model from image-level labels of homogeneous cell\npopulations. Our results show that CellMixer can achieve competitive\nsegmentation performance across multiple cell types and imaging modalities,\ndemonstrating the method's scalability and potential for broader applications\nin medical imaging, cellular biology, and diagnostics.",
            "author": [
                "Mehdi Naouar",
                "Gabriel Kalweit",
                "Anusha Klett",
                "Yannick Vogt",
                "Paula Silvestrini",
                "Diana Laura Infante Ramirez",
                "Roland Mertelsmann",
                "Joschka Boedecker",
                "Maria Kalweit"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00671v1",
                "http://arxiv.org/pdf/2312.00671v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00663v1",
            "title": "Generalized Label-Efficient 3D Scene Parsing via Hierarchical Feature\n  Aligned Pre-Training and Region-Aware Fine-tuning",
            "updated": "2023-12-01T15:47:04Z",
            "published": "2023-12-01T15:47:04Z",
            "summary": "Deep neural network models have achieved remarkable progress in 3D scene\nunderstanding while trained in the closed-set setting and with full labels.\nHowever, the major bottleneck for current 3D recognition approaches is that\nthey do not have the capacity to recognize any unseen novel classes beyond the\ntraining categories in diverse kinds of real-world applications. In the\nmeantime, current state-of-the-art 3D scene understanding approaches primarily\nrequire high-quality labels to train neural networks, which merely perform well\nin a fully supervised manner. This work presents a generalized and simple\nframework for dealing with 3D scene understanding when the labeled scenes are\nquite limited. To extract knowledge for novel categories from the pre-trained\nvision-language models, we propose a hierarchical feature-aligned pre-training\nand knowledge distillation strategy to extract and distill meaningful\ninformation from large-scale vision-language models, which helps benefit the\nopen-vocabulary scene understanding tasks. To leverage the boundary\ninformation, we propose a novel energy-based loss with boundary awareness\nbenefiting from the region-level boundary predictions. To encourage latent\ninstance discrimination and to guarantee efficiency, we propose the\nunsupervised region-level semantic contrastive learning scheme for point\nclouds, using confident predictions of the neural network to discriminate the\nintermediate feature embeddings at multiple stages. Extensive experiments with\nboth indoor and outdoor scenes demonstrated the effectiveness of our approach\nin both data-efficient learning and open-world few-shot learning. All codes,\nmodels, and data are made publicly available at:\nhttps://drive.google.com/drive/folders/1M58V-PtR8DBEwD296zJkNg_m2qq-MTAP?usp=sharing.",
            "author": [
                "Kangcheng Liu",
                "Yong-Jin Liu",
                "Kai Tang",
                "Ming Liu",
                "Baoquan Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00663v1",
                "http://arxiv.org/pdf/2312.00663v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00662v1",
            "title": "Nonparametric Variational Regularisation of Pretrained Transformers",
            "updated": "2023-12-01T15:40:30Z",
            "published": "2023-12-01T15:40:30Z",
            "summary": "The current paradigm of large-scale pre-training and fine-tuning Transformer\nlarge language models has lead to significant improvements across the board in\nnatural language processing. However, such large models are susceptible to\noverfitting to their training data, and as a result the models perform poorly\nwhen the domain changes. Also, due to the model's scale, the cost of\nfine-tuning the model to the new domain is large. Nonparametric Variational\nInformation Bottleneck (NVIB) has been proposed as a regulariser for training\ncross-attention in Transformers, potentially addressing the overfitting\nproblem. We extend the NVIB framework to replace all types of attention\nfunctions in Transformers, and show that existing pretrained Transformers can\nbe reinterpreted as Nonparametric Variational (NV) models using a proposed\nidentity initialisation. We then show that changing the initialisation\nintroduces a novel, information-theoretic post-training regularisation in the\nattention mechanism, which improves out-of-domain generalisation without any\ntraining. This success supports the hypothesis that pretrained Transformers are\nimplicitly NV Bayesian models.",
            "author": [
                "Fabio Fehr",
                "James Henderson"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00662v1",
                "http://arxiv.org/pdf/2312.00662v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00661v1",
            "title": "Dual-Domain Multi-Contrast MRI Reconstruction with Synthesis-based\n  Fusion Network",
            "updated": "2023-12-01T15:40:26Z",
            "published": "2023-12-01T15:40:26Z",
            "summary": "Purpose: To develop an efficient dual-domain reconstruction framework for\nmulti-contrast MRI, with the focus on minimising cross-contrast misalignment in\nboth the image and the frequency domains to enhance optimisation. Theory and\nMethods: Our proposed framework, based on deep learning, facilitates the\noptimisation for under-sampled target contrast using fully-sampled reference\ncontrast that is quicker to acquire. The method consists of three key steps: 1)\nLearning to synthesise data resembling the target contrast from the reference\ncontrast; 2) Registering the multi-contrast data to reduce inter-scan motion;\nand 3) Utilising the registered data for reconstructing the target contrast.\nThese steps involve learning in both domains with regularisation applied to\nensure their consistency. We also compare the reconstruction performance with\nexisting deep learning-based methods using a dataset of brain MRI scans.\nResults: Extensive experiments demonstrate the superiority of our proposed\nframework, for up to an 8-fold acceleration rate, compared to state-of-the-art\nalgorithms. Comprehensive analysis and ablation studies further present the\neffectiveness of the proposed components. Conclusion:Our dual-domain framework\noffers a promising approach to multi-contrast MRI reconstruction. It can also\nbe integrated with existing methods to further enhance the reconstruction.",
            "author": [
                "Junwei Yang",
                "Pietro Li\u00f2"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00661v1",
                "http://arxiv.org/pdf/2312.00661v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00660v1",
            "title": "Resource-constrained knowledge diffusion processes inspired by human\n  peer learning",
            "updated": "2023-12-01T15:39:24Z",
            "published": "2023-12-01T15:39:24Z",
            "summary": "We consider a setting where a population of artificial learners is given, and\nthe objective is to optimize aggregate measures of performance, under\nconstraints on training resources. The problem is motivated by the study of\npeer learning in human educational systems. In this context, we study natural\nknowledge diffusion processes in networks of interacting artificial learners.\nBy `natural', we mean processes that reflect human peer learning where the\nstudents' internal state and learning process is mostly opaque, and the main\ndegree of freedom lies in the formation of peer learning groups by a\ncoordinator who can potentially evaluate the learners before assigning them to\npeer groups. Among else, we empirically show that such processes indeed make\neffective use of the training resources, and enable the design of modular\nneural models that have the capacity to generalize without being prone to\noverfitting noisy labels.",
            "author": [
                "Ehsan Beikihassan",
                "Amy K. Hoover",
                "Ioannis Koutis",
                "Ali Parviz",
                "Niloofar Aghaieabiane"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00660v1",
                "http://arxiv.org/pdf/2312.00660v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00659v1",
            "title": "New physics at the Intensity Frontier: how much can we learn and how?",
            "updated": "2023-12-01T15:38:15Z",
            "published": "2023-12-01T15:38:15Z",
            "summary": "Intensity Frontier experiments are often evaluated by the smallest coupling\nit can probe, irrespective of what particle can be found or the scientific\nsignificance of its detection. In this work, we propose a new framework that\ndetermines the number of events required to characterize new particle\nproperties. For example, we show that Heavy Neutral Leptons require 100 events\nto establish the neutrino mass hierarchy, and 1000 events to reveal the\nMajorana phase of active neutrinos. Ultimately, this framework presents a more\nobjective way to connect experiments to their scientific outcomes.",
            "author": [
                "Oleksii Mikulenko",
                "Kyrylo Bondarenko",
                "Alexey Boyarsky",
                "Oleg Ruchayskiy"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00659v1",
                "http://arxiv.org/pdf/2312.00659v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00656v2",
            "title": "Simple Transferability Estimation for Regression Tasks",
            "updated": "2023-12-04T03:26:35Z",
            "published": "2023-12-01T15:30:54Z",
            "summary": "We consider transferability estimation, the problem of estimating how well\ndeep learning models transfer from a source to a target task. We focus on\nregression tasks, which received little previous attention, and propose two\nsimple and computationally efficient approaches that estimate transferability\nbased on the negative regularized mean squared error of a linear regression\nmodel. We prove novel theoretical results connecting our approaches to the\nactual transferability of the optimal target models obtained from the transfer\nlearning process. Despite their simplicity, our approaches significantly\noutperform existing state-of-the-art regression transferability estimators in\nboth accuracy and efficiency. On two large-scale keypoint regression\nbenchmarks, our approaches yield 12% to 36% better results on average while\nbeing at least 27% faster than previous state-of-the-art methods.",
            "author": [
                "Cuong N. Nguyen",
                "Phong Tran",
                "Lam Si Tung Ho",
                "Vu Dinh",
                "Anh T. Tran",
                "Tal Hassner",
                "Cuong V. Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00656v2",
                "http://arxiv.org/pdf/2312.00656v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00655v1",
            "title": "Machine Learning for Health symposium 2023 -- Findings track",
            "updated": "2023-12-01T15:30:43Z",
            "published": "2023-12-01T15:30:43Z",
            "summary": "A collection of the accepted Findings papers that were presented at the 3rd\nMachine Learning for Health symposium (ML4H 2023), which was held on December\n10, 2023, in New Orleans, Louisiana, USA. ML4H 2023 invited high-quality\nsubmissions on relevant problems in a variety of health-related disciplines\nincluding healthcare, biomedicine, and public health. Two submission tracks\nwere offered: the archival Proceedings track, and the non-archival Findings\ntrack. Proceedings were targeted at mature work with strong technical\nsophistication and a high impact to health. The Findings track looked for new\nideas that could spark insightful discussion, serve as valuable resources for\nthe community, or could enable new collaborations. Submissions to the\nProceedings track, if not accepted, were automatically considered for the\nFindings track. All the manuscripts submitted to ML4H Symposium underwent a\ndouble-blind peer-review process.",
            "author": [
                "Stefan Hegselmann",
                "Antonio Parziale",
                "Divya Shanmugam",
                "Shengpu Tang",
                "Mercy Nyamewaa Asiedu",
                "Serina Chang",
                "Thomas Hartvigsen",
                "Harvineet Singh"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00655v1",
                "http://arxiv.org/pdf/2312.00655v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "68Txx",
                "I.2; J.3; I.6; I.4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00857v1",
            "title": "Latent Space Explorer: Visual Analytics for Multimodal Latent Space\n  Exploration",
            "updated": "2023-12-01T15:25:56Z",
            "published": "2023-12-01T15:25:56Z",
            "summary": "Machine learning models built on training data with multiple modalities can\nreveal new insights that are not accessible through unimodal datasets. For\nexample, cardiac magnetic resonance images (MRIs) and electrocardiograms (ECGs)\nare both known to capture useful information about subjects' cardiovascular\nhealth status. A multimodal machine learning model trained from large datasets\ncan potentially predict the onset of heart-related diseases and provide novel\nmedical insights about the cardiovascular system. Despite the potential\nbenefits, it is difficult for medical experts to explore multimodal\nrepresentation models without visual aids and to test the predictive\nperformance of the models on various subpopulations. To address the challenges,\nwe developed a visual analytics system called Latent Space Explorer. Latent\nSpace Explorer provides interactive visualizations that enable users to explore\nthe multimodal representation of subjects, define subgroups of interest,\ninteractively decode data with different modalities with the selected subjects,\nand inspect the accuracy of the embedding in downstream prediction tasks. A\nuser study was conducted with medical experts and their feedback provided\nuseful insights into how Latent Space Explorer can help their analysis and\npossible new direction for further development in the medical domain.",
            "author": [
                "Bum Chul Kwon",
                "Samuel Friedman",
                "Kai Xu",
                "Steven A Lubitz",
                "Anthony Philippakis",
                "Puneet Batra",
                "Patrick T Ellinor",
                "Kenney Ng"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00857v1",
                "http://arxiv.org/pdf/2312.00857v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.HC",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00648v1",
            "title": "SPOT: Self-Training with Patch-Order Permutation for Object-Centric\n  Learning with Autoregressive Transformers",
            "updated": "2023-12-01T15:20:58Z",
            "published": "2023-12-01T15:20:58Z",
            "summary": "Unsupervised object-centric learning aims to decompose scenes into\ninterpretable object entities, termed slots. Slot-based auto-encoders stand out\nas a prominent method for this task. Within them, crucial aspects include\nguiding the encoder to generate object-specific slots and ensuring the decoder\nutilizes them during reconstruction. This work introduces two novel techniques,\n(i) an attention-based self-training approach, which distills superior\nslot-based attention masks from the decoder to the encoder, enhancing object\nsegmentation, and (ii) an innovative patch-order permutation strategy for\nautoregressive transformers that strengthens the role of slot vectors in\nreconstruction. The effectiveness of these strategies is showcased\nexperimentally. The combined approach significantly surpasses prior slot-based\nautoencoder methods in unsupervised object segmentation, especially with\ncomplex real-world images. We provide the implementation code at\nhttps://github.com/gkakogeorgiou/spot .",
            "author": [
                "Ioannis Kakogeorgiou",
                "Spyros Gidaris",
                "Konstantinos Karantzalos",
                "Nikos Komodakis"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00648v1",
                "http://arxiv.org/pdf/2312.00648v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00645v1",
            "title": "Hashmarks: Privacy-Preserving Benchmarks for High-Stakes AI Evaluation",
            "updated": "2023-12-01T15:16:00Z",
            "published": "2023-12-01T15:16:00Z",
            "summary": "There is a growing need to gain insight into language model capabilities that\nrelate to sensitive topics, such as bioterrorism or cyberwarfare. However,\ntraditional open source benchmarks are not fit for the task, due to the\nassociated practice of publishing the correct answers in human-readable form.\nAt the same time, enforcing mandatory closed-quarters evaluations might stifle\ndevelopment and erode trust. In this context, we propose hashmarking, a\nprotocol for evaluating language models in the open without having to disclose\nthe correct answers. In its simplest form, a hashmark is a benchmark whose\nreference solutions have been cryptographically hashed prior to publication.\nFollowing an overview of the proposed evaluation protocol, we go on to assess\nits resilience against traditional attack vectors (e.g. rainbow table attacks),\nas well as against failure modes unique to increasingly capable generative\nmodels.",
            "author": [
                "Paul Bricman"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00645v1",
                "http://arxiv.org/pdf/2312.00645v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00644v1",
            "title": "Neural networks for the approximation of Euler's elastica",
            "updated": "2023-12-01T15:07:25Z",
            "published": "2023-12-01T15:07:25Z",
            "summary": "Euler's elastica is a classical model of flexible slender structures,\nrelevant in many industrial applications. Static equilibrium equations can be\nderived via a variational principle. The accurate approximation of solutions of\nthis problem can be challenging due to nonlinearity and constraints. We here\npresent two neural network based approaches for the simulation of this Euler's\nelastica. Starting from a data set of solutions of the discretised static\nequilibria, we train the neural networks to produce solutions for unseen\nboundary conditions. We present a $\\textit{discrete}$ approach learning\ndiscrete solutions from the discrete data. We then consider a\n$\\textit{continuous}$ approach using the same training data set, but learning\ncontinuous solutions to the problem. We present numerical evidence that the\nproposed neural networks can effectively approximate configurations of the\nplanar Euler's elastica for a range of different boundary conditions.",
            "author": [
                "Elena Celledoni",
                "Ergys \u00c7okaj",
                "Andrea Leone",
                "Sigrid Leyendecker",
                "Davide Murari",
                "Brynjulf Owren",
                "Rodrigo T. Sato Mart\u00edn de Almagro",
                "Martina Stavole"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00644v1",
                "http://arxiv.org/pdf/2312.00644v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00855v1",
            "title": "Refine, Discriminate and Align: Stealing Encoders via Sample-Wise\n  Prototypes and Multi-Relational Extraction",
            "updated": "2023-12-01T15:03:29Z",
            "published": "2023-12-01T15:03:29Z",
            "summary": "This paper introduces RDA, a pioneering approach designed to address two\nprimary deficiencies prevalent in previous endeavors aiming at stealing\npre-trained encoders: (1) suboptimal performances attributed to biased\noptimization objectives, and (2) elevated query costs stemming from the\nend-to-end paradigm that necessitates querying the target encoder every epoch.\nSpecifically, we initially Refine the representations of the target encoder for\neach training sample, thereby establishing a less biased optimization objective\nbefore the steal-training phase. This is accomplished via a sample-wise\nprototype, which consolidates the target encoder's representations for a given\nsample's various perspectives. Demanding exponentially fewer queries compared\nto the end-to-end approach, prototypes can be instantiated to guide subsequent\nquery-free training. For more potent efficacy, we develop a multi-relational\nextraction loss that trains the surrogate encoder to Discriminate mismatched\nembedding-prototype pairs while Aligning those matched ones in terms of both\namplitude and angle. In this way, the trained surrogate encoder achieves\nstate-of-the-art results across the board in various downstream datasets with\nlimited queries. Moreover, RDA is shown to be robust to multiple widely-used\ndefenses.",
            "author": [
                "Shuchi Wu",
                "Chuan Ma",
                "Kang Wei",
                "Xiaogang Xu",
                "Ming Ding",
                "Yuwen Qian",
                "Tao Xiang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00855v1",
                "http://arxiv.org/pdf/2312.00855v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00640v1",
            "title": "One to beat them all: \"RYU'' -- a unifying framework for the\n  construction of safe balls",
            "updated": "2023-12-01T15:00:59Z",
            "published": "2023-12-01T15:00:59Z",
            "summary": "In this paper, we put forth a novel framework (named ``RYU'') for the\nconstruction of ``safe'' balls, i.e. regions that provably contain the dual\nsolution of a target optimization problem. We concentrate on the standard setup\nwhere the cost function is the sum of two terms: a closed, proper, convex\nLipschitz-smooth function and a closed, proper, convex function. The RYU\nframework is shown to generalize or improve upon all the results proposed in\nthe last decade for the considered family of optimization problems.",
            "author": [
                "Thu-Le Tran",
                "Cl\u00e9ment Elvira",
                "Hong-Phuong Dang",
                "C\u00e9dric Herzet"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00640v1",
                "http://arxiv.org/pdf/2312.00640v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00639v1",
            "title": "EvE: Exploiting Generative Priors for Radiance Field Enrichment",
            "updated": "2023-12-01T14:59:43Z",
            "published": "2023-12-01T14:59:43Z",
            "summary": "Modeling large-scale scenes from unconstrained image collections in-the-wild\nhas proven to be a major challenge in computer vision. Existing methods\ntackling in-the-wild neural rendering operate in a closed-world setting, where\nknowledge is limited to a scene's captured images within a training set. We\npropose EvE, which is, to the best of our knowledge, the first method\nleveraging generative priors to improve in-the-wild scene modeling. We employ\npre-trained generative networks to enrich K-Planes representations with\nextrinsic knowledge. To this end, we define an alternating training procedure\nto conduct optimization guidance of K-Planes trained on the training set. We\ncarry out extensive experiments and verify the merit of our method on synthetic\ndata as well as real tourism photo collections. EvE enhances rendered scenes\nwith richer details and outperforms the state of the art on the task of novel\nview synthesis in-the-wild. Our project page can be found at\nhttps://eve-nvs.github.io .",
            "author": [
                "Karim Kassab",
                "Antoine Schnepf",
                "Jean-Yves Franceschi",
                "Laurent Caraffa",
                "Jeremie Mary",
                "Val\u00e9rie Gouet-Brunet"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00639v1",
                "http://arxiv.org/pdf/2312.00639v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00854v1",
            "title": "A Probabilistic Neural Twin for Treatment Planning in Peripheral\n  Pulmonary Artery Stenosis",
            "updated": "2023-12-01T14:54:17Z",
            "published": "2023-12-01T14:54:17Z",
            "summary": "The substantial computational cost of high-fidelity models in numerical\nhemodynamics has, so far, relegated their use mainly to offline treatment\nplanning. New breakthroughs in data-driven architectures and optimization\ntechniques for fast surrogate modeling provide an exciting opportunity to\novercome these limitations, enabling the use of such technology for\ntime-critical decisions. We discuss an application to the repair of multiple\nstenosis in peripheral pulmonary artery disease through either transcatheter\npulmonary artery rehabilitation or surgery, where it is of interest to achieve\ndesired pressures and flows at specific locations in the pulmonary artery tree,\nwhile minimizing the risk for the patient. Since different degrees of success\ncan be achieved in practice during treatment, we formulate the problem in\nprobability, and solve it through a sample-based approach. We propose a new\noffline-online pipeline for probabilsitic real-time treatment planning which\ncombines offline assimilation of boundary conditions, model reduction, and\ntraining dataset generation with online estimation of marginal probabilities,\npossibly conditioned on the degree of augmentation observed in already repaired\nlesions. Moreover, we propose a new approach for the parametrization of\narbitrarily shaped vascular repairs through iterative corrections of a\nzero-dimensional approximant. We demonstrate this pipeline for a diseased model\nof the pulmonary artery tree available through the Vascular Model Repository.",
            "author": [
                "John D. Lee",
                "Jakob Richter",
                "Martin R. Pfaller",
                "Jason M. Szafron",
                "Karthik Menon",
                "Andrea Zanoni",
                "Michael R. Ma",
                "Jeffrey A. Feinstein",
                "Jacqueline Kreutzer",
                "Alison L. Marsden",
                "Daniele E. Schiavazzi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00854v1",
                "http://arxiv.org/pdf/2312.00854v1"
            ],
            "primary_category": "physics.med-ph",
            "category": [
                "physics.med-ph",
                "cs.AI",
                "cs.LG",
                "cs.NA",
                "math.NA",
                "stat.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00626v1",
            "title": "Forecasting Trends in Food Security: a Reservoir Computing Approach",
            "updated": "2023-12-01T14:42:37Z",
            "published": "2023-12-01T14:42:37Z",
            "summary": "Early warning systems are an essential tool for effective humanitarian\naction. Advance warnings on impending disasters facilitate timely and targeted\nresponse which help save lives, livelihoods, and scarce financial resources. In\nthis work we present a new quantitative methodology to forecast levels of food\nconsumption for 60 consecutive days, at the sub-national level, in four\ncountries: Mali, Nigeria, Syria, and Yemen. The methodology is built on\npublicly available data from the World Food Programme's integrated global\nhunger monitoring system which collects, processes, and displays daily updates\non key food security metrics, conflict, weather events, and other drivers of\nfood insecurity across 90 countries (https://hungermap.wfp.org/). In this\nstudy, we assessed the performance of various models including ARIMA, XGBoost,\nLSTMs, CNNs, and Reservoir Computing (RC), by comparing their Root Mean Squared\nError (RMSE) metrics. This comprehensive analysis spanned classical\nstatistical, machine learning, and deep learning approaches. Our findings\nhighlight Reservoir Computing as a particularly well-suited model in the field\nof food security given both its notable resistance to over-fitting on limited\ndata samples and its efficient training capabilities. The methodology we\nintroduce establishes the groundwork for a global, data-driven early warning\nsystem designed to anticipate and detect food insecurity.",
            "author": [
                "Joschka Herteux",
                "Christoph R\u00e4th",
                "Amine Baha",
                "Giulia Martini",
                "Duccio Piovani"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00626v1",
                "http://arxiv.org/pdf/2312.00626v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.soc-ph",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00622v1",
            "title": "Practical Path-based Bayesian Optimization",
            "updated": "2023-12-01T14:39:11Z",
            "published": "2023-12-01T14:39:11Z",
            "summary": "There has been a surge in interest in data-driven experimental design with\napplications to chemical engineering and drug manufacturing. Bayesian\noptimization (BO) has proven to be adaptable to such cases, since we can model\nthe reactions of interest as expensive black-box functions. Sometimes, the cost\nof this black-box functions can be separated into two parts: (a) the cost of\nthe experiment itself, and (b) the cost of changing the input parameters. In\nthis short paper, we extend the SnAKe algorithm to deal with both types of\ncosts simultaneously. We further propose extensions to the case of a maximum\nallowable input change, as well as to the multi-objective setting.",
            "author": [
                "Jose Pablo Folch",
                "James Odgers",
                "Shiqiang Zhang",
                "Robert M Lee",
                "Behrang Shafei",
                "David Walz",
                "Calvin Tsay",
                "Mark van der Wilk",
                "Ruth Misener"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00622v1",
                "http://arxiv.org/pdf/2312.00622v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00852v1",
            "title": "Beyond First-Order Tweedie: Solving Inverse Problems using Latent\n  Diffusion",
            "updated": "2023-12-01T14:36:24Z",
            "published": "2023-12-01T14:36:24Z",
            "summary": "Sampling from the posterior distribution poses a major computational\nchallenge in solving inverse problems using latent diffusion models. Common\nmethods rely on Tweedie's first-order moments, which are known to induce a\nquality-limiting bias. Existing second-order approximations are impractical due\nto prohibitive computational costs, making standard reverse diffusion processes\nintractable for posterior sampling. This paper introduces Second-order Tweedie\nsampler from Surrogate Loss (STSL), a novel sampler that offers efficiency\ncomparable to first-order Tweedie with a tractable reverse process using\nsecond-order approximation. Our theoretical results reveal that the\nsecond-order approximation is lower bounded by our surrogate loss that only\nrequires $O(1)$ compute using the trace of the Hessian, and by the lower bound\nwe derive a new drift term to make the reverse process tractable. Our method\nsurpasses SoTA solvers PSLD and P2L, achieving 4X and 8X reduction in neural\nfunction evaluations, respectively, while notably enhancing sampling quality on\nFFHQ, ImageNet, and COCO benchmarks. In addition, we show STSL extends to\ntext-guided image editing and addresses residual distortions present from\ncorrupted images in leading text-guided image editing methods. To our best\nknowledge, this is the first work to offer an efficient second-order\napproximation in solving inverse problems using latent diffusion and editing\nreal-world images with corruptions.",
            "author": [
                "Litu Rout",
                "Yujia Chen",
                "Abhishek Kumar",
                "Constantine Caramanis",
                "Sanjay Shakkottai",
                "Wen-Sheng Chu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00852v1",
                "http://arxiv.org/pdf/2312.00852v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00616v1",
            "title": "Investigating a domain adaptation approach for integrating different\n  measurement instruments in a longitudinal clinical registry",
            "updated": "2023-12-01T14:28:37Z",
            "published": "2023-12-01T14:28:37Z",
            "summary": "In a longitudinal clinical registry, different measurement instruments might\nhave been used for assessing individuals at different time points. To combine\nthem, we investigate deep learning techniques for obtaining a joint latent\nrepresentation, to which the items of different measurement instruments are\nmapped. This corresponds to domain adaptation, an established concept in\ncomputer science for image data. Using the proposed approach as an example, we\nevaluate the potential of domain adaptation in a longitudinal cohort setting\nwith a rather small number of time points, motivated by an application with\ndifferent motor function measurement instruments in a registry of spinal\nmuscular atrophy (SMA) patients. There, we model trajectories in the latent\nrepresentation by ordinary differential equations (ODEs), where person-specific\nODE parameters are inferred from baseline characteristics. The goodness of fit\nand complexity of the ODE solutions then allows to judge the measurement\ninstrument mappings. We subsequently explore how alignment can be improved by\nincorporating corresponding penalty terms into model fitting. To systematically\ninvestigate the effect of differences between measurement instruments, we\nconsider several scenarios based on modified SMA data, including scenarios\nwhere a mapping should be feasible in principle and scenarios where no perfect\nmapping is available. While misalignment increases in more complex scenarios,\nsome structure is still recovered, even if the availability of measurement\ninstruments depends on patient state. A reasonable mapping is feasible also in\nthe more complex real SMA dataset. These results indicate that domain\nadaptation might be more generally useful in statistical modeling for\nlongitudinal registry data.",
            "author": [
                "Maren Hackenberg",
                "Michelle Pfaffenlehner",
                "Max Behrens",
                "Astrid Pechmann",
                "Janbernd Kirschner",
                "Harald Binder"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00616v1",
                "http://arxiv.org/pdf/2312.00616v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ME",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00601v1",
            "title": "Online Graph Coloring with Predictions",
            "updated": "2023-12-01T14:07:10Z",
            "published": "2023-12-01T14:07:10Z",
            "summary": "We introduce learning augmented algorithms to the online graph coloring\nproblem. Although the simple greedy algorithm FirstFit is known to perform\npoorly in the worst case, we are able to establish a relationship between the\nstructure of any input graph $G$ that is revealed online and the number of\ncolors that FirstFit uses for $G$. Based on this relationship, we propose an\nonline coloring algorithm FirstFitPredictions that extends FirstFit while\nmaking use of machine learned predictions. We show that FirstFitPredictions is\nboth \\emph{consistent} and \\emph{smooth}. Moreover, we develop a novel\nframework for combining online algorithms at runtime specifically for the\nonline graph coloring problem. Finally, we show how this framework can be used\nto robustify by combining it with any classical online coloring algorithm (that\ndisregards the predictions).",
            "author": [
                "Antonios Antoniadis",
                "Hajo Broersma",
                "Yang Meng"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00601v1",
                "http://arxiv.org/pdf/2312.00601v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00600v1",
            "title": "Improving Plasticity in Online Continual Learning via Collaborative\n  Learning",
            "updated": "2023-12-01T14:06:28Z",
            "published": "2023-12-01T14:06:28Z",
            "summary": "Online Continual Learning (CL) solves the problem of learning the\never-emerging new classification tasks from a continuous data stream. Unlike\nits offline counterpart, in online CL, the training data can only be seen once.\nMost existing online CL research regards catastrophic forgetting (i.e., model\nstability) as almost the only challenge. In this paper, we argue that the\nmodel's capability to acquire new knowledge (i.e., model plasticity) is another\nchallenge in online CL. While replay-based strategies have been shown to be\neffective in alleviating catastrophic forgetting, there is a notable gap in\nresearch attention toward improving model plasticity. To this end, we propose\nCollaborative Continual Learning (CCL), a collaborative learning based strategy\nto improve the model's capability in acquiring new concepts. Additionally, we\nintroduce Distillation Chain (DC), a novel collaborative learning scheme to\nboost the training of the models. We adapted CCL-DC to existing representative\nonline CL works. Extensive experiments demonstrate that even if the learners\nare well-trained with state-of-the-art online CL methods, our strategy can\nstill improve model plasticity dramatically, and thereby improve the overall\nperformance by a large margin.",
            "author": [
                "Maorong Wang",
                "Nicolas Michel",
                "Ling Xiao",
                "Toshihiko Yamasaki"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00600v1",
                "http://arxiv.org/pdf/2312.00600v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00598v1",
            "title": "Learning from One Continuous Video Stream",
            "updated": "2023-12-01T14:03:30Z",
            "published": "2023-12-01T14:03:30Z",
            "summary": "We introduce a framework for online learning from a single continuous video\nstream -- the way people and animals learn, without mini-batches, data\naugmentation or shuffling. This poses great challenges given the high\ncorrelation between consecutive video frames and there is very little prior\nwork on it. Our framework allows us to do a first deep dive into the topic and\nincludes a collection of streams and tasks composed from two existing video\ndatasets, plus methodology for performance evaluation that considers both\nadaptation and generalization. We employ pixel-to-pixel modelling as a\npractical and flexible way to switch between pre-training and single-stream\nevaluation as well as between arbitrary tasks, without ever requiring changes\nto models and always using the same pixel loss. Equipped with this framework we\nobtained large single-stream learning gains from pre-training with a novel\nfamily of future prediction tasks, found that momentum hurts, and that the pace\nof weight updates matters. The combination of these insights leads to matching\nthe performance of IID learning with batch size 1, when using the same\narchitecture and without costly replay buffers.",
            "author": [
                "Jo\u00e3o Carreira",
                "Michael King",
                "Viorica P\u0103tr\u0103ucean",
                "Dilara Gokay",
                "C\u0103t\u0103lin Ionescu",
                "Yi Yang",
                "Daniel Zoran",
                "Joseph Heyward",
                "Carl Doersch",
                "Yusuf Aytar",
                "Dima Damen",
                "Andrew Zisserman"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00598v1",
                "http://arxiv.org/pdf/2312.00598v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00596v1",
            "title": "BCN: Batch Channel Normalization for Image Classification",
            "updated": "2023-12-01T14:01:48Z",
            "published": "2023-12-01T14:01:48Z",
            "summary": "Normalization techniques have been widely used in the field of deep learning\ndue to their capability of enabling higher learning rates and are less careful\nin initialization. However, the effectiveness of popular normalization\ntechnologies is typically limited to specific areas. Unlike the standard Batch\nNormalization (BN) and Layer Normalization (LN), where BN computes the mean and\nvariance along the (N,H,W) dimensions and LN computes the mean and variance\nalong the (C,H,W) dimensions (N, C, H and W are the batch, channel, spatial\nheight and width dimension, respectively), this paper presents a novel\nnormalization technique called Batch Channel Normalization (BCN). To exploit\nboth the channel and batch dependence and adaptively and combine the advantages\nof BN and LN based on specific datasets or tasks, BCN separately normalizes\ninputs along the (N, H, W) and (C, H, W) axes, then combines the normalized\noutputs based on adaptive parameters. As a basic block, BCN can be easily\nintegrated into existing models for various applications in the field of\ncomputer vision. Empirical results show that the proposed technique can be\nseamlessly applied to various versions of CNN or Vision Transformer\narchitecture. The code is publicly available at\nhttps://github.com/AfifaKhaled/BatchChannel-Normalization",
            "author": [
                "Afifa Khaled",
                "Chao Li",
                "Jia Ning",
                "Kun He"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00596v1",
                "http://arxiv.org/pdf/2312.00596v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00592v1",
            "title": "Tracking Object Positions in Reinforcement Learning: A Metric for\n  Keypoint Detection (extended version)",
            "updated": "2023-12-01T13:56:28Z",
            "published": "2023-12-01T13:56:28Z",
            "summary": "Reinforcement learning (RL) for robot control typically requires a detailed\nrepresentation of the environment state, including information about\ntask-relevant objects not directly measurable. Keypoint detectors, such as\nspatial autoencoders (SAEs), are a common approach to extracting a\nlow-dimensional representation from high-dimensional image data. SAEs aim at\nspatial features such as object positions, which are often useful\nrepresentations in robotic RL. However, whether an SAE is actually able to\ntrack objects in the scene and thus yields a spatial state representation well\nsuited for RL tasks has rarely been examined due to a lack of established\nmetrics. In this paper, we propose to assess the performance of an SAE instance\nby measuring how well keypoints track ground truth objects in images. We\npresent a computationally lightweight metric and use it to evaluate common\nbaseline SAE architectures on image data from a simulated robot task. We find\nthat common SAEs differ substantially in their spatial extraction capability.\nFurthermore, we validate that SAEs that perform well in our metric achieve\nsuperior performance when used in downstream RL. Thus, our metric is an\neffective and lightweight indicator of RL performance before executing\nexpensive RL training. Building on these insights, we identify three key\nmodifications of SAE architectures to improve tracking performance. We make our\ncode available at anonymous.4open.science/r/sae-rl.",
            "author": [
                "Emma Cramer",
                "Jonas Reiher",
                "Sebastian Trimpe"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00592v1",
                "http://arxiv.org/pdf/2312.00592v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00591v1",
            "title": "Less is More: Learning Reference Knowledge Using No-Reference Image\n  Quality Assessment",
            "updated": "2023-12-01T13:56:01Z",
            "published": "2023-12-01T13:56:01Z",
            "summary": "Image Quality Assessment (IQA) with reference images have achieved great\nsuccess by imitating the human vision system, in which the image quality is\neffectively assessed by comparing the query image with its pristine reference\nimage. However, for the images in the wild, it is quite difficult to access\naccurate reference images. We argue that it is possible to learn reference\nknowledge under the No-Reference Image Quality Assessment (NR-IQA) setting,\nwhich is effective and efficient empirically. Concretely, by innovatively\nintroducing a novel feature distillation method in IQA, we propose a new\nframework to learn comparative knowledge from non-aligned reference images. And\nthen, to achieve fast convergence and avoid overfitting, we further propose an\ninductive bias regularization. Such a framework not only solves the congenital\ndefects of NR-IQA but also improves the feature extraction framework, enabling\nit to express more abundant quality information. Surprisingly, our method\nutilizes less input while obtaining a more significant improvement compared to\nthe teacher models. Extensive experiments on eight standard NR-IQA datasets\ndemonstrate the superior performance to the state-of-the-art NR-IQA methods,\ni.e., achieving the PLCC values of 0.917 (vs. 0.884 in LIVEC) and 0.686 (vs.\n0.661 in LIVEFB).",
            "author": [
                "Xudong Li",
                "Jingyuan Zheng",
                "Xiawu Zheng",
                "Runze Hu",
                "Enwei Zhang",
                "Yuting Gao",
                "Yunhang Shen",
                "Ke Li",
                "Yutao Liu",
                "Pingyang Dai",
                "Yan Zhang",
                "Rongrong Ji"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00591v1",
                "http://arxiv.org/pdf/2312.00591v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00586v1",
            "title": "Explainable Fraud Detection with Deep Symbolic Classification",
            "updated": "2023-12-01T13:50:55Z",
            "published": "2023-12-01T13:50:55Z",
            "summary": "There is a growing demand for explainable, transparent, and data-driven\nmodels within the domain of fraud detection. Decisions made by fraud detection\nmodels need to be explainable in the event of a customer dispute. Additionally,\nthe decision-making process in the model must be transparent to win the trust\nof regulators and business stakeholders. At the same time, fraud detection\nsolutions can benefit from data due to the noisy, dynamic nature of fraud and\nthe availability of large historical data sets. Finally, fraud detection is\nnotorious for its class imbalance: there are typically several orders of\nmagnitude more legitimate transactions than fraudulent ones. In this paper, we\npresent Deep Symbolic Classification (DSC), an extension of the Deep Symbolic\nRegression framework to classification problems. DSC casts classification as a\nsearch problem in the space of all analytic functions composed of a vocabulary\nof variables, constants, and operations and optimizes for an arbitrary\nevaluation metric directly. The search is guided by a deep neural network\ntrained with reinforcement learning. Because the functions are mathematical\nexpressions that are in closed-form and concise, the model is inherently\nexplainable both at the level of a single classification decision and the\nmodel's decision process. Furthermore, the class imbalance problem is\nsuccessfully addressed by optimizing for metrics that are robust to class\nimbalance such as the F1 score. This eliminates the need for oversampling and\nundersampling techniques that plague traditional approaches. Finally, the model\nallows to explicitly balance between the prediction accuracy and the\nexplainability. An evaluation on the PaySim data set demonstrates competitive\npredictive performance with state-of-the-art models, while surpassing them in\nterms of explainability. This establishes DSC as a promising model for fraud\ndetection systems.",
            "author": [
                "Samantha Visbeek",
                "Erman Acar",
                "Floris den Hengst"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00586v1",
                "http://arxiv.org/pdf/2312.00586v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00585v1",
            "title": "Adaptive Parameter-Free Robust Learning using Latent Bernoulli Variables",
            "updated": "2023-12-01T13:50:15Z",
            "published": "2023-12-01T13:50:15Z",
            "summary": "We present an efficient parameter-free approach for statistical learning from\ncorrupted training sets. We identify corrupted and non-corrupted samples using\nlatent Bernoulli variables, and therefore formulate the robust learning problem\nas maximization of the likelihood where latent variables are marginalized out.\nThe resulting optimization problem is solved via variational inference using an\nefficient Expectation-Maximization based method. The proposed approach improves\nover the state-of-the-art by automatically inferring the corruption level and\nidentifying outliers, while adding minimal computational overhead. We\ndemonstrate our robust learning method on a wide variety of machine learning\ntasks including online learning and deep learning where it exhibits ability to\nadapt to different levels of noise and attain high prediction accuracy.",
            "author": [
                "Aleksandr Karakulev",
                "Dave Zachariah",
                "Prashant Singh"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00585v1",
                "http://arxiv.org/pdf/2312.00585v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00584v1",
            "title": "The Ethics of Automating Legal Actors",
            "updated": "2023-12-01T13:48:46Z",
            "published": "2023-12-01T13:48:46Z",
            "summary": "The introduction of large public legal datasets has brought about a\nrenaissance in legal NLP. Many of these datasets are comprised of legal\njudgements - the product of judges deciding cases. This fact, together with the\nway machine learning works, means that several legal NLP models are models of\njudges. While some have argued for the automation of judges, in this position\npiece, we argue that automating the role of the judge raises difficult ethical\nchallenges, in particular for common law legal systems. Our argument follows\nfrom the social role of the judge in actively shaping the law, rather than\nmerely applying it. Since current NLP models come nowhere close to having the\nfacilities necessary for this task, they should not be used to automate judges.\nFurthermore, even in the case the models could achieve human-level\ncapabilities, there would still be remaining ethical concerns inherent in the\nautomation of the legal process.",
            "author": [
                "Josef Valvoda",
                "Alec Thompson",
                "Ryan Cotterell",
                "Simone Teufel"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00584v1",
                "http://arxiv.org/pdf/2312.00584v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00582v1",
            "title": "Design Patterns for Machine Learning Based Systems with\n  Human-in-the-Loop",
            "updated": "2023-12-01T13:46:38Z",
            "published": "2023-12-01T13:46:38Z",
            "summary": "The development and deployment of systems using supervised machine learning\n(ML) remain challenging: mainly due to the limited reliability of prediction\nmodels and the lack of knowledge on how to effectively integrate human\nintelligence into automated decision-making. Humans involvement in the ML\nprocess is a promising and powerful paradigm to overcome the limitations of\npure automated predictions and improve the applicability of ML in practice. We\ncompile a catalog of design patterns to guide developers select and implement\nsuitable human-in-the-loop (HiL) solutions. Our catalog takes into\nconsideration key requirements as the cost of human involvement and model\nretraining. It includes four training patterns, four deployment patterns, and\ntwo orthogonal cooperation patterns.",
            "author": [
                "Jakob Smedegaard Andersen",
                "Walid Maalej"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00582v1",
                "http://arxiv.org/pdf/2312.00582v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00581v1",
            "title": "Pathway to a fully data-driven geotechnics: lessons from materials\n  informatics",
            "updated": "2023-12-01T13:45:42Z",
            "published": "2023-12-01T13:45:42Z",
            "summary": "This paper elucidates the challenges and opportunities inherent in\nintegrating data-driven methodologies into geotechnics, drawing inspiration\nfrom the success of materials informatics. Highlighting the intricacies of soil\ncomplexity, heterogeneity, and the lack of comprehensive data, the discussion\nunderscores the pressing need for community-driven database initiatives and\nopen science movements. By leveraging the transformative power of deep\nlearning, particularly in feature extraction from high-dimensional data and the\npotential of transfer learning, we envision a paradigm shift towards a more\ncollaborative and innovative geotechnics field. The paper concludes with a\nforward-looking stance, emphasizing the revolutionary potential brought about\nby advanced computational tools like large language models in reshaping\ngeotechnics informatics.",
            "author": [
                "Stephen Wu",
                "Yu Otake",
                "Yosuke Higo",
                "Ikumasa Yoshida"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00581v1",
                "http://arxiv.org/pdf/2312.00581v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00851v1",
            "title": "Physics Inspired Criterion for Pruning-Quantization Joint Learning",
            "updated": "2023-12-01T13:25:16Z",
            "published": "2023-12-01T13:25:16Z",
            "summary": "Pruning-quantization joint learning always facilitates the deployment of deep\nneural networks (DNNs) on resource-constrained edge devices. However, most\nexisting methods do not jointly learn a global criterion for pruning and\nquantization in an interpretable way. In this paper, we propose a novel physics\ninspired criterion for pruning-quantization joint learning (PIC-PQ), which is\nexplored from an analogy we first draw between elasticity dynamics (ED) and\nmodel compression (MC). Specifically, derived from Hooke's law in ED, we\nestablish a linear relationship between the filters' importance distribution\nand the filter property (FP) by a learnable deformation scale in the physics\ninspired criterion (PIC). Furthermore, we extend PIC with a relative shift\nvariable for a global view. To ensure feasibility and flexibility, available\nmaximum bitwidth and penalty factor are introduced in quantization bitwidth\nassignment. Experiments on benchmarks of image classification demonstrate that\nPIC-PQ yields a good trade-off between accuracy and bit-operations (BOPs)\ncompression ratio e.g., 54.96X BOPs compression ratio in ResNet56 on CIFAR10\nwith 0.10% accuracy drop and 53.24X in ResNet18 on ImageNet with 0.61% accuracy\ndrop). The code will be available at https://github.com/fanxxxxyi/PIC-PQ.",
            "author": [
                "Weiying Xie",
                "Xiaoyi Fan",
                "Xin Zhang",
                "Yunsong Li",
                "Jie Lei",
                "Leyuan Fang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00851v1",
                "http://arxiv.org/pdf/2312.00851v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00561v1",
            "title": "Interior Point Constrained Reinforcement Learning with Global\n  Convergence Guarantees",
            "updated": "2023-12-01T13:16:39Z",
            "published": "2023-12-01T13:16:39Z",
            "summary": "We consider discounted infinite horizon constrained Markov decision processes\n(CMDPs) where the goal is to find an optimal policy that maximizes the expected\ncumulative reward subject to expected cumulative constraints. Motivated by the\napplication of CMDPs in online learning of safety-critical systems, we focus on\ndeveloping an algorithm that ensures constraint satisfaction during learning.\nTo this end, we develop a zeroth-order interior point approach based on the log\nbarrier function of the CMDP. Under the commonly assumed conditions of Fisher\nnon-degeneracy and bounded transfer error of the policy parameterization, we\nestablish the theoretical properties of the algorithm. In particular, in\ncontrast to existing CMDP approaches that ensure policy feasibility only upon\nconvergence, our algorithm guarantees feasibility of the policies during the\nlearning process and converges to the optimal policy with a sample complexity\nof $O(\\varepsilon^{-6})$. In comparison to the state-of-the-art policy\ngradient-based algorithm, C-NPG-PDA, our algorithm requires an additional\n$O(\\varepsilon^{-2})$ samples to ensure policy feasibility during learning with\nsame Fisher-non-degenerate parameterization.",
            "author": [
                "Tingting Ni",
                "Maryam Kamgarpour"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00561v1",
                "http://arxiv.org/pdf/2312.00561v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00558v2",
            "title": "Initial Results From the First Field Expedition of UAPx to Study\n  Unidentified Anomalous Phenomena",
            "updated": "2023-12-04T17:30:38Z",
            "published": "2023-12-01T13:13:50Z",
            "summary": "In July 2021, faculty from the UAlbany Department of Physics participated in\na week-long field expedition with the organization UAPx to collect data on UAPs\nin Avalon, California, located on Catalina Island, and nearby. This paper\nreviews both the hardware and software techniques which this collaboration\nemployed, and contains a frank discussion of the successes and failures, with a\nsection about how to apply lessons learned to future expeditions. Both\nobservable-light and infrared cameras were deployed, as well as sensors for\nother (non-EM) emissions. A pixel-subtraction method was augmented with other\nsimilarly simple methods to provide initial identification of objects in the\nsky and/or the sea crossing the cameras' fields of view. The first results will\nbe presented based upon approximately one hour in total of triggered\nvisible/night-vision-mode video and over 600 hours of untriggered (far) IR\nvideo recorded, as well as 55 hours of (background) radiation measurements.\nFollowing multiple explanatory resolutions of several ambiguities that were\npotentially anomalous at first, we focus on the primary remaining ambiguity\ncaptured at approximately 4am Pacific Time on Friday, July 16: a dark spot in\nthe visible/near-IR camera possibly coincident with ionizing radiation that has\nthus far resisted a prosaic explanation. We conclude with quantitative\nsuggestions for serious researchers in this still-nascent field of\nhard-science-based UAP studies, with an ultimate goal of identifying UAPs\nwithout confirmation bias toward either mundane or speculative conclusions.",
            "author": [
                "M. Szydagis",
                "K. H. Knuth",
                "B. W. Kugielsky",
                "C. Levy",
                "J. D. McGowan",
                "M. D. Phelan",
                "G. P. Voorhis Jr"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00558v2",
                "http://arxiv.org/pdf/2312.00558v2"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "physics.ins-det",
                "physics.pop-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00553v1",
            "title": "A Spatio-Temporal Graph Convolutional Network for Gesture Recognition\n  from High-Density Electromyography",
            "updated": "2023-12-01T13:00:41Z",
            "published": "2023-12-01T13:00:41Z",
            "summary": "Accurate hand gesture prediction is crucial for effective upper-limb\nprosthetic limbs control. As the high flexibility and multiple degrees of\nfreedom exhibited by human hands, there has been a growing interest in\nintegrating deep networks with high-density surface electromyography (HD-sEMG)\ngrids to enhance gesture recognition capabilities. However, many existing\nmethods fall short in fully exploit the specific spatial topology and temporal\ndependencies present in HD-sEMG data. Additionally, these studies are often\nlimited number of gestures and lack generality. Hence, this study introduces a\nnovel gesture recognition method, named STGCN-GR, which leverages\nspatio-temporal graph convolution networks for HD-sEMG-based human-machine\ninterfaces. Firstly, we construct muscle networks based on functional\nconnectivity between channels, creating a graph representation of HD-sEMG\nrecordings. Subsequently, a temporal convolution module is applied to capture\nthe temporal dependences in the HD-sEMG series and a spatial graph convolution\nmodule is employed to effectively learn the intrinsic spatial topology\ninformation among distinct HD-sEMG channels. We evaluate our proposed model on\na public HD-sEMG dataset comprising a substantial number of gestures (i.e.,\n65). Our results demonstrate the remarkable capability of the STGCN-GR method,\nachieving an impressive accuracy of 91.07% in predicting gestures, which\nsurpasses state-of-the-art deep learning methods applied to the same dataset.",
            "author": [
                "Wenjuan Zhong",
                "Yuyang Zhang",
                "Peiwen Fu",
                "Wenxuan Xiong",
                "Mingming Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00553v1",
                "http://arxiv.org/pdf/2312.00553v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00552v1",
            "title": "Improving Unsupervised Relation Extraction by Augmenting Diverse\n  Sentence Pairs",
            "updated": "2023-12-01T12:59:32Z",
            "published": "2023-12-01T12:59:32Z",
            "summary": "Unsupervised relation extraction (URE) aims to extract relations between\nnamed entities from raw text without requiring manual annotations or\npre-existing knowledge bases. In recent studies of URE, researchers put a\nnotable emphasis on contrastive learning strategies for acquiring relation\nrepresentations. However, these studies often overlook two important aspects:\nthe inclusion of diverse positive pairs for contrastive learning and the\nexploration of appropriate loss functions. In this paper, we propose AugURE\nwith both within-sentence pairs augmentation and augmentation through\ncross-sentence pairs extraction to increase the diversity of positive pairs and\nstrengthen the discriminative power of contrastive learning. We also identify\nthe limitation of noise-contrastive estimation (NCE) loss for relation\nrepresentation learning and propose to apply margin loss for sentence pairs.\nExperiments on NYT-FB and TACRED datasets demonstrate that the proposed\nrelation representation learning and a simple K-Means clustering achieves\nstate-of-the-art performance.",
            "author": [
                "Qing Wang",
                "Kang Zhou",
                "Qiao Qiao",
                "Yuepei Li",
                "Qi Li"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00552v1",
                "http://arxiv.org/pdf/2312.00552v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00551v1",
            "title": "Identifying patterns and recommendations of and for sustainable open\n  data initiatives: a benchmarking-driven analysis of open government data\n  initiatives among European countries",
            "updated": "2023-12-01T12:58:17Z",
            "published": "2023-12-01T12:58:17Z",
            "summary": "Open government and open (government) data are seen as tools to create new\nopportunities, eliminate or at least reduce information inequalities and\nimprove public services. More than a decade of these efforts has provided much\nexperience, practices, and perspectives to learn how to better deal with them.\nThis paper focuses on benchmarking of open data initiatives over the years and\nattempts to identify patterns observed among European countries that could lead\nto disparities in the development, growth, and sustainability of open data\necosystems. To do this, we studied benchmarks and indices published over the\nlast years (57 editions of 8 artifacts) and conducted a comparative case study\nof eight European countries, identifying patterns among them considering\ndifferent potentially relevant contexts such as e-government, open government\ndata, open data indices and rankings, and others relevant for the country under\nconsideration. Using a Delphi method, we reached a consensus within a panel of\nexperts and validated a final list of 94 patterns, including their frequency of\noccurrence among studied countries and their effects on the respective\ncountries. Finally, we took a closer look at the developments in identified\ncontexts over the years and defined 21 recommendations for more resilient and\nsustainable open government data initiatives and ecosystems and future steps in\nthis area.",
            "author": [
                "Martin Lnenicka",
                "Anastasija Nikiforova",
                "Mariusz Luterek",
                "Petar Milic",
                "Daniel Rudmark",
                "Sebastian Neumaier",
                "Caterina Santoro",
                "Cesar Casiano Flores",
                "Marijn Janssen",
                "Manuel Pedro Rodr\u00edguez Bol\u00edvar"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00551v1",
                "http://arxiv.org/pdf/2312.00551v1"
            ],
            "primary_category": "econ.GN",
            "category": [
                "econ.GN",
                "q-fin.EC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00548v1",
            "title": "Domain Adaptive Imitation Learning with Visual Observation",
            "updated": "2023-12-01T12:48:41Z",
            "published": "2023-12-01T12:48:41Z",
            "summary": "In this paper, we consider domain-adaptive imitation learning with visual\nobservation, where an agent in a target domain learns to perform a task by\nobserving expert demonstrations in a source domain. Domain adaptive imitation\nlearning arises in practical scenarios where a robot, receiving visual sensory\ndata, needs to mimic movements by visually observing other robots from\ndifferent angles or observing robots of different shapes. To overcome the\ndomain shift in cross-domain imitation learning with visual observation, we\npropose a novel framework for extracting domain-independent behavioral features\nfrom input observations that can be used to train the learner, based on dual\nfeature extraction and image reconstruction. Empirical results demonstrate that\nour approach outperforms previous algorithms for imitation learning from visual\nobservation with domain shift.",
            "author": [
                "Sungho Choi",
                "Seungyul Han",
                "Woojun Kim",
                "Jongseong Chae",
                "Whiyoung Jung",
                "Youngchul Sung"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00548v1",
                "http://arxiv.org/pdf/2312.00548v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00540v1",
            "title": "Target-agnostic Source-free Domain Adaptation for Regression Tasks",
            "updated": "2023-12-01T12:35:18Z",
            "published": "2023-12-01T12:35:18Z",
            "summary": "Unsupervised domain adaptation (UDA) seeks to bridge the domain gap between\nthe target and source using unlabeled target data. Source-free UDA removes the\nrequirement for labeled source data at the target to preserve data privacy and\nstorage. However, work on source-free UDA assumes knowledge of domain gap\ndistribution, and hence is limited to either target-aware or classification\ntask. To overcome it, we propose TASFAR, a novel target-agnostic source-free\ndomain adaptation approach for regression tasks. Using prediction confidence,\nTASFAR estimates a label density map as the target label distribution, which is\nthen used to calibrate the source model on the target domain. We have conducted\nextensive experiments on four regression tasks with various domain gaps,\nnamely, pedestrian dead reckoning for different users, image-based people\ncounting in different scenes, housing-price prediction at different districts,\nand taxi-trip duration prediction from different departure points. TASFAR is\nshown to substantially outperform the state-of-the-art source-free UDA\napproaches by averagely reducing 22% errors for the four tasks and achieve\nnotably comparable accuracy as source-based UDA without using source data.",
            "author": [
                "Tianlang He",
                "Zhiqiu Xia",
                "Jierun Chen",
                "Haoliang Li",
                "S. -H. Gary Chan"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00540v1",
                "http://arxiv.org/pdf/2312.00540v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00538v1",
            "title": "A Preconditioned Interior Point Method for Support Vector Machines Using\n  an ANOVA-Decomposition and NFFT-Based Matrix-Vector Products",
            "updated": "2023-12-01T12:27:11Z",
            "published": "2023-12-01T12:27:11Z",
            "summary": "In this paper we consider the numerical solution to the soft-margin support\nvector machine optimization problem. This problem is typically solved using the\nSMO algorithm, given the high computational complexity of traditional\noptimization algorithms when dealing with large-scale kernel matrices. In this\nwork, we propose employing an NFFT-accelerated matrix-vector product using an\nANOVA decomposition for the feature space that is used within an interior point\nmethod for the overall optimization problem. As this method requires the\nsolution of a linear system of saddle point form we suggest a preconditioning\napproach that is based on low-rank approximations of the kernel matrix together\nwith a Krylov subspace solver. We compare the accuracy of the ANOVA-based\nkernel with the default LIBSVM implementation. We investigate the performance\nof the different preconditioners as well as the accuracy of the ANOVA kernel on\nseveral large-scale datasets.",
            "author": [
                "Theresa Wagner",
                "John W. Pearson",
                "Martin Stoll"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00538v1",
                "http://arxiv.org/pdf/2312.00538v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.LG",
                "cs.NA",
                "math.OC",
                "05C50, 65F08, 65F10, 65T50, 90C20"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00536v1",
            "title": "Trained MT Metrics Learn to Cope with Machine-translated References",
            "updated": "2023-12-01T12:15:58Z",
            "published": "2023-12-01T12:15:58Z",
            "summary": "Neural metrics trained on human evaluations of MT tend to correlate well with\nhuman judgments, but their behavior is not fully understood. In this paper, we\nperform a controlled experiment and compare a baseline metric that has not been\ntrained on human evaluations (Prism) to a trained version of the same metric\n(Prism+FT). Surprisingly, we find that Prism+FT becomes more robust to\nmachine-translated references, which are a notorious problem in MT evaluation.\nThis suggests that the effects of metric training go beyond the intended effect\nof improving overall correlation with human judgments.",
            "author": [
                "Jannis Vamvas",
                "Tobias Domhan",
                "Sony Trenous",
                "Rico Sennrich",
                "Eva Hasler"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00536v1",
                "http://arxiv.org/pdf/2312.00536v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00535v1",
            "title": "RIS-Based On-the-Air Semantic Communications -- a Diffractional Deep\n  Neural Network Approach",
            "updated": "2023-12-01T12:15:49Z",
            "published": "2023-12-01T12:15:49Z",
            "summary": "Semantic communication has gained significant attention recently due to its\nadvantages in achieving higher transmission efficiency by focusing on semantic\ninformation instead of bit-level information. However, current AI-based\nsemantic communication methods require digital hardware for implementation.\nWith the rapid advancement on reconfigurable intelligence surfaces (RISs), a\nnew approach called on-the-air diffractional deep neural networks (D$^2$NN) can\nbe utilized to enable semantic communications on the wave domain. This paper\nproposes a new paradigm of RIS-based on-the-air semantic communications, where\nthe computational process occurs inherently as wireless signals pass through\nRISs. We present the system model and discuss the data and control flows of\nthis scheme, followed by a performance analysis using image transmission as an\nexample. In comparison to traditional hardware-based approaches, RIS-based\nsemantic communications offer appealing features, such as light-speed\ncomputation, low computational power requirements, and the ability to handle\nmultiple tasks simultaneously.",
            "author": [
                "Shuyi Chen",
                "Yingzhe Hui",
                "Yifan Qin",
                "Yueyi Yuan",
                "Weixiao Meng",
                "Xuewen Luo",
                "Hsiao-Hwa Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00535v1",
                "http://arxiv.org/pdf/2312.00535v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00532v1",
            "title": "DeepDR: Deep Structure-Aware RGB-D Inpainting for Diminished Reality",
            "updated": "2023-12-01T12:12:58Z",
            "published": "2023-12-01T12:12:58Z",
            "summary": "Diminished reality (DR) refers to the removal of real objects from the\nenvironment by virtually replacing them with their background. Modern DR\nframeworks use inpainting to hallucinate unobserved regions. While recent deep\nlearning-based inpainting is promising, the DR use case is complicated by the\nneed to generate coherent structure and 3D geometry (i.e., depth), in\nparticular for advanced applications, such as 3D scene editing. In this paper,\nwe propose DeepDR, a first RGB-D inpainting framework fulfilling all\nrequirements of DR: Plausible image and geometry inpainting with coherent\nstructure, running at real-time frame rates, with minimal temporal artifacts.\nOur structure-aware generative network allows us to explicitly condition color\nand depth outputs on the scene semantics, overcoming the difficulty of\nreconstructing sharp and consistent boundaries in regions with complex\nbackgrounds. Experimental results show that the proposed framework can\noutperform related work qualitatively and quantitatively.",
            "author": [
                "Christina Gsaxner",
                "Shohei Mori",
                "Dieter Schmalstieg",
                "Jan Egger",
                "Gerhard Paar",
                "Werner Bailer",
                "Denis Kalkofen"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00532v1",
                "http://arxiv.org/pdf/2312.00532v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00529v1",
            "title": "Algorithm-based diagnostic application for diabetic retinopathy\n  detection",
            "updated": "2023-12-01T12:09:06Z",
            "published": "2023-12-01T12:09:06Z",
            "summary": "Diabetic retinopathy (DR) is a growing health problem worldwide and is a\nleading cause of visual impairment and blindness, especially among working\npeople aged 20-65. Its incidence is increasing along with the number of\ndiabetes cases, and it is more common in developed countries than in developing\ncountries. Recent research in the field of diabetic retinopathy diagnosis is\nusing advanced technologies, such as analysis of images obtained by\nophthalmoscopy. Automatic methods for analyzing eye images based on neural\nnetworks, deep learning and image analysis algorithms can improve the\nefficiency of diagnosis. This paper describes an automatic DR diagnosis method\nthat includes processing and analysis of ophthalmoscopic images of the eye. It\nuses morphological algorithms to identify the optic disc and lesions\ncharacteristic of DR, such as microaneurysms, hemorrhages and exudates.\nAutomated DR diagnosis has the potential to improve the efficiency of early\ndetection of this disease and contribute to reducing the number of cases of\ndiabetes-related visual impairment. The final step was to create an application\nwith a graphical user interface that allowed retinal images taken at\ncooperating ophthalmology offices to be uploaded to the server. These images\nwere then analyzed using a developed algorithm to make a diagnosis.",
            "author": [
                "Agnieszka Cisek",
                "Karolina Korycinska",
                "Leszek Pyziak",
                "Marzena Malicka",
                "Tomasz Wiecek",
                "Grzegorz Gruzel",
                "Kamil Szmuc",
                "Jozef Cebulski",
                "Mariusz Spyra"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00529v1",
                "http://arxiv.org/pdf/2312.00529v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "q-bio.TO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00525v1",
            "title": "SurreyAI 2023 Submission for the Quality Estimation Shared Task",
            "updated": "2023-12-01T12:01:04Z",
            "published": "2023-12-01T12:01:04Z",
            "summary": "Quality Estimation (QE) systems are important in situations where it is\nnecessary to assess the quality of translations, but there is no reference\navailable. This paper describes the approach adopted by the SurreyAI team for\naddressing the Sentence-Level Direct Assessment shared task in WMT23. The\nproposed approach builds upon the TransQuest framework, exploring various\nautoencoder pre-trained language models within the MonoTransQuest architecture\nusing single and ensemble settings. The autoencoder pre-trained language models\nemployed in the proposed systems are XLMV, InfoXLM-large, and XLMR-large. The\nevaluation utilizes Spearman and Pearson correlation coefficients, assessing\nthe relationship between machine-predicted quality scores and human judgments\nfor 5 language pairs (English-Gujarati, English-Hindi, English-Marathi,\nEnglish-Tamil and English-Telugu). The MonoTQ-InfoXLM-large approach emerges as\na robust strategy, surpassing all other individual models proposed in this\nstudy by significantly improving over the baseline for the majority of the\nlanguage pairs.",
            "author": [
                "Archchana Sindhujan",
                "Diptesh Kanojia",
                "Constantin Orasan",
                "Tharindu Ranasinghe"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00525v1",
                "http://arxiv.org/pdf/2312.00525v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00517v1",
            "title": "Causal propensity as an antecedent of entrepreneurial intentions in\n  tourism students",
            "updated": "2023-12-01T11:46:22Z",
            "published": "2023-12-01T11:46:22Z",
            "summary": "The tourism sector is a sector with many opportunities for business\ndevelopment. Entrepreneurship in this sector promotes economic growth and job\ncreation. Knowing how entrepreneurial intention develops facilitates its\ntransformation into entrepreneurial behaviour. Entrepreneurial behaviour can\nadopt a causal logic, an effectual logic or a combination of both. Considering\nthe causal logic, decision-making is done through prediction. In this way,\nentrepreneurs try to increase their market share by planning strategies and\nanalysing possible deviations from their plans. Previous literature studies\ncausal entrepreneurial behaviour, as well as variables such as creative\ninnovation, proactive decisions and entrepreneurship training when the\nentrepreneur has already created his or her firm. However, there is an obvious\ngap at a stage prior to the start of entrepreneurial activity when the\nentrepreneurial intention is formed. This paper analyses how creativity,\nproactivity, entrepreneurship education and the propensity for causal behaviour\ninfluence entrepreneurial intentions. To achieve the research objective, we\nanalysed a sample of 464 undergraduate tourism students from two universities\nin southern Spain. We used SmartPLS 3 software to apply a structural equation\nmethodology to the measurement model composed of nine hypotheses. The results\nshow, among other relationships, that causal propensity, entrepreneurship\nlearning programmes and proactivity are antecedents of entrepreneurial\nintentions. These findings have implications for theory, as they fill a gap in\nthe field of entrepreneurial intentions. Considering propensity towards causal\nbehaviour before setting up the firm is unprecedented. Furthermore, the results\nof this study have practical implications for the design of public education\npolicies and the promotion of business creation in the tourism sector.",
            "author": [
                "Alicia Martin-Navarro",
                "Felix Velicia-Martin",
                "Jose Aurelio Medina-Garrido",
                "Ricardo Gouveia Rodrigues"
            ],
            "link": [
                "http://dx.doi.org/10.1007/s11365-022-00826-1",
                "http://arxiv.org/abs/2312.00517v1",
                "http://arxiv.org/pdf/2312.00517v1"
            ],
            "primary_category": "econ.GN",
            "category": [
                "econ.GN",
                "q-fin.EC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00516v1",
            "title": "Spatio-Temporal-Decoupled Masked Pre-training for Traffic Forecasting",
            "updated": "2023-12-01T11:43:49Z",
            "published": "2023-12-01T11:43:49Z",
            "summary": "Accurate forecasting of multivariate traffic flow time series remains\nchallenging due to substantial spatio-temporal heterogeneity and complex\nlong-range correlative patterns. To address this, we propose\nSpatio-Temporal-Decoupled Masked Pre-training (STD-MAE), a novel framework that\nemploys masked autoencoders to learn and encode complex spatio-temporal\ndependencies via pre-training. Specifically, we use two decoupled masked\nautoencoders to reconstruct the traffic data along spatial and temporal axes\nusing a self-supervised pre-training approach. These mask reconstruction\nmechanisms capture the long-range correlations in space and time separately.\nThe learned hidden representations are then used to augment the downstream\nspatio-temporal traffic predictor. A series of quantitative and qualitative\nevaluations on four widely-used traffic benchmarks (PEMS03, PEMS04, PEMS07, and\nPEMS08) are conducted to verify the state-of-the-art performance, with STD-MAE\nexplicitly enhancing the downstream spatio-temporal models' ability to capture\nlong-range intricate spatial and temporal patterns. Codes are available at\nhttps://github.com/Jimmy-7664/STD_MAE.",
            "author": [
                "Haotian Gao",
                "Renhe Jiang",
                "Zheng Dong",
                "Jinliang Deng",
                "Xuan Song"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00516v1",
                "http://arxiv.org/pdf/2312.00516v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00513v1",
            "title": "Summarization-based Data Augmentation for Document Classification",
            "updated": "2023-12-01T11:34:37Z",
            "published": "2023-12-01T11:34:37Z",
            "summary": "Despite the prevalence of pretrained language models in natural language\nunderstanding tasks, understanding lengthy text such as document is still\nchallenging due to the data sparseness problem. Inspired by that humans develop\ntheir ability of understanding lengthy text from reading shorter text, we\npropose a simple yet effective summarization-based data augmentation, SUMMaug,\nfor document classification. We first obtain easy-to-learn examples for the\ntarget document classification task by summarizing the input of the original\ntraining examples, while optionally merging the original labels to conform to\nthe summarized input. We then use the generated pseudo examples to perform\ncurriculum learning. Experimental results on two datasets confirmed the\nadvantage of our method compared to existing baseline methods in terms of\nrobustness and accuracy. We release our code and data at\nhttps://github.com/etsurin/summaug.",
            "author": [
                "Yueguan Wang",
                "Naoki Yoshinaga"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00513v1",
                "http://arxiv.org/pdf/2312.00513v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00512v1",
            "title": "Attack Detection Using Item Vector Shift in Matrix Factorisation\n  Recommenders",
            "updated": "2023-12-01T11:34:01Z",
            "published": "2023-12-01T11:34:01Z",
            "summary": "This paper proposes a novel method for detecting shilling attacks in Matrix\nFactorization (MF)-based Recommender Systems (RS), in which attackers use false\nuser-item feedback to promote a specific item. Unlike existing methods that use\neither use supervised learning to distinguish between attack and genuine\nprofiles or analyse target item rating distributions to detect false ratings,\nour method uses an unsupervised technique to detect false ratings by examining\nshifts in item preference vectors that exploit rating deviations and user\ncharacteristics, making it a promising new direction. The experimental results\ndemonstrate the effectiveness of our approach in various attack scenarios,\nincluding those involving obfuscation techniques.",
            "author": [
                "Sulthana Shams",
                "Douglas Leith"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00512v1",
                "http://arxiv.org/pdf/2312.00512v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00509v1",
            "title": "Bayesian causal discovery from unknown general interventions",
            "updated": "2023-12-01T11:30:51Z",
            "published": "2023-12-01T11:30:51Z",
            "summary": "We consider the problem of learning causal Directed Acyclic Graphs (DAGs)\nusing combinations of observational and interventional experimental data.\nCurrent methods tailored to this setting assume that interventions either\ndestroy parent-child relations of the intervened (target) nodes or only alter\nsuch relations without modifying the parent sets, even when the intervention\ntargets are unknown. We relax this assumption by proposing a Bayesian method\nfor causal discovery from general interventions, which allow for modifications\nof the parent sets of the unknown targets. Even in this framework, DAGs and\ngeneral interventions may be identifiable only up to some equivalence classes.\nWe provide graphical characterizations of such interventional Markov\nequivalence and devise compatible priors for Bayesian inference that guarantee\nscore equivalence of indistinguishable structures. We then develop a Markov\nChain Monte Carlo (MCMC) scheme to approximate the posterior distribution over\nDAGs, intervention targets and induced parent sets. Finally, we evaluate the\nproposed methodology on both simulated and real protein expression data.",
            "author": [
                "Alessandro Mascaro",
                "Federico Castelletti"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00509v1",
                "http://arxiv.org/pdf/2312.00509v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00508v2",
            "title": "PyraTrans: Attention-Enriched Pyramid Transformer for Malicious URL\n  Detection",
            "updated": "2023-12-06T16:46:54Z",
            "published": "2023-12-01T11:27:00Z",
            "summary": "Although advancements in machine learning have driven the development of\nmalicious URL detection technology, current techniques still face significant\nchallenges in their capacity to generalize and their resilience against\nevolving threats. In this paper, we propose PyraTrans, a novel method that\nintegrates pretrained Transformers with pyramid feature learning to detect\nmalicious URL. PyraTrans utilizes a pretrained CharBERT as its foundation and\nis augmented with three interconnected feature modules: 1) Encoder Feature\nExtraction, extracting multi-order feature matrices from each CharBERT encoder\nlayer; 2) Multi-Scale Feature Learning, capturing local contextual insights at\nvarious scales and aggregating information across encoder layers; and 3)\nSpatial Pyramid Attention, focusing on regional-level attention to emphasize\nareas rich in expressive information. The proposed approach addresses the\nlimitations of the Transformer in local feature learning and regional\nrelational awareness, which are vital for capturing URL-specific word patterns,\ncharacter combinations, or structural anomalies. In several challenging\nexperimental scenarios, the proposed method has shown significant improvements\nin accuracy, generalization, and robustness in malicious URL detection. For\ninstance, it achieved a peak F1-score improvement of 40% in class-imbalanced\nscenarios, and exceeded the best baseline result by 14.13% in accuracy in\nadversarial attack scenarios. Additionally, we conduct a case study where our\nmethod accurately identifies all 30 active malicious web pages, whereas two\npior SOTA methods miss 4 and 7 malicious web pages respectively. Codes and data\nare available at:https://github.com/Alixyvtte/PyraTrans.",
            "author": [
                "Ruitong Liu",
                "Yanbin Wang",
                "Zhenhao Guo",
                "Haitao Xu",
                "Zhan Qin",
                "Wenrui Ma",
                "Fan Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00508v2",
                "http://arxiv.org/pdf/2312.00508v2"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00507v1",
            "title": "VEXIR2Vec: An Architecture-Neutral Embedding Framework for Binary\n  Similarity",
            "updated": "2023-12-01T11:22:10Z",
            "published": "2023-12-01T11:22:10Z",
            "summary": "We propose VEXIR2Vec, a code embedding framework for finding similar\nfunctions in binaries. Our representations rely on VEX IR, the intermediate\nrepresentation used by binary analysis tools like Valgrind and angr. Our\nproposed embeddings encode both syntactic and semantic information to represent\na function, and is both application and architecture independent. We also\npropose POV, a custom Peephole Optimization engine that normalizes the VEX IR\nfor effective similarity analysis. We design several optimizations like\ncopy/constant propagation, constant folding, common subexpression elimination\nand load-store elimination in POV.\n  We evaluate our framework on two experiments -- diffing and searching --\ninvolving binaries targeting different architectures, compiled using different\ncompilers and versions, optimization sequences, and obfuscations. We show\nresults on several standard projects and on real-world vulnerabilities. Our\nresults show that VEXIR2Vec achieves superior precision and recall values\ncompared to the state-of-the-art works. Our framework is highly scalable and is\nbuilt as a multi-threaded, parallel library by only using open-source tools.\nVEXIR2Vec achieves about $3.2 \\times$ speedup on the closest competitor, and\norders-of-magnitude speedup on other tools.",
            "author": [
                "S. VenkataKeerthy",
                "Yashas Andaluri",
                "Sayan Dey",
                "Soumya Banerjee",
                "Ramakrishna Upadrasta"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00507v1",
                "http://arxiv.org/pdf/2312.00507v1"
            ],
            "primary_category": "cs.PL",
            "category": [
                "cs.PL",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00505v1",
            "title": "Machine learning approaches for parameter reweighting in MC samples of\n  top quark production in CMS",
            "updated": "2023-12-01T11:09:57Z",
            "published": "2023-12-01T11:09:57Z",
            "summary": "In particle physics, Monte Carlo (MC) event generators are needed to compare\ntheory to the measured data. Many MC samples have to be generated to account\nfor theoretical systematic uncertainties, at a significant computational cost.\nTherefore, the MC statistic becomes a limiting factor for most measurements and\nthe significant computational cost of these programs a bottleneck in most\nphysics analyses. In this contribution, the Deep neural network using\nClassification for Tuning and Reweighting (DCTR) approach is evaluated for the\nreweighting of two systematic uncertainties in MC simulations of top quark pair\nproduction within the CMS experiment. DCTR is a method, based on a Deep Neural\nNetwork (DNN) technique, to reweight simulations to different model parameters\nby using the full kinematic information in the event. This methodology avoids\nthe need for simulating the detector response multiple times by incorporating\nthe relevant variations in a single sample.",
            "author": [
                "Valentina Guglielmi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00505v1",
                "http://arxiv.org/pdf/2312.00505v1"
            ],
            "primary_category": "hep-ex",
            "category": [
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00502v1",
            "title": "On the Out-Of-Distribution Robustness of Self-Supervised Representation\n  Learning for Phonocardiogram Signals",
            "updated": "2023-12-01T11:06:00Z",
            "published": "2023-12-01T11:06:00Z",
            "summary": "Objective: Despite the recent increase in research activity, deep-learning\nmodels have not yet been widely accepted in medicine. The shortage of\nhigh-quality annotated data often hinders the development of robust and\ngeneralizable models, which do not suffer from degraded effectiveness when\npresented with newly-collected, out-of-distribution (OOD) datasets. Methods:\nContrastive Self-Supervised Learning (SSL) offers a potential solution to the\nscarcity of labeled data as it takes advantage of unlabeled data to increase\nmodel effectiveness and robustness. In this research, we propose applying\ncontrastive SSL for detecting abnormalities in phonocardiogram (PCG) samples by\nlearning a generalized representation of the signal. Specifically, we perform\nan extensive comparative evaluation of a wide range of audio-based\naugmentations and evaluate trained classifiers on multiple datasets across\ndifferent downstream tasks. Results: We experimentally demonstrate that,\ndepending on its training distribution, the effectiveness of a fully-supervised\nmodel can degrade up to 32% when evaluated on unseen data, while SSL models\nonly lose up to 10% or even improve in some cases. Conclusions: Contrastive SSL\npretraining can assist in providing robust classifiers which can generalize to\nunseen, OOD data, without relying on time- and labor-intensive annotation\nprocesses by medical experts. Furthermore, the proposed extensive evaluation\nprotocol sheds light on the most promising and appropriate augmentations for\nrobust PCG signal processing. Significance: We provide researchers and\npractitioners with a roadmap towards producing robust models for PCG\nclassification, in addition to an open-source codebase for developing novel\napproaches.",
            "author": [
                "Aristotelis Ballas",
                "Vasileios Papapanagiotou",
                "Christos Diou"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00502v1",
                "http://arxiv.org/pdf/2312.00502v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SD",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00500v1",
            "title": "Global Localization: Utilizing Relative Spatio-Temporal Geometric\n  Constraints from Adjacent and Distant Cameras",
            "updated": "2023-12-01T11:03:07Z",
            "published": "2023-12-01T11:03:07Z",
            "summary": "Re-localizing a camera from a single image in a previously mapped area is\nvital for many computer vision applications in robotics and augmented/virtual\nreality. In this work, we address the problem of estimating the 6 DoF camera\npose relative to a global frame from a single image. We propose to leverage a\nnovel network of relative spatial and temporal geometric constraints to guide\nthe training of a Deep Network for localization. We employ simultaneously\nspatial and temporal relative pose constraints that are obtained not only from\nadjacent camera frames but also from camera frames that are distant in the\nspatio-temporal space of the scene. We show that our method, through these\nconstraints, is capable of learning to localize when little or very sparse\nground-truth 3D coordinates are available. In our experiments, this is less\nthan 1% of available ground-truth data. We evaluate our method on 3 common\nvisual localization datasets and show that it outperforms other direct pose\nestimation methods.",
            "author": [
                "Mohammad Altillawi",
                "Zador Pataki",
                "Shile Li",
                "Ziyuan Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00500v1",
                "http://arxiv.org/pdf/2312.00500v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00487v1",
            "title": "Explainable AI in Diagnosing and Anticipating Leukemia Using Transfer\n  Learning Method",
            "updated": "2023-12-01T10:37:02Z",
            "published": "2023-12-01T10:37:02Z",
            "summary": "This research paper focuses on Acute Lymphoblastic Leukemia (ALL), a form of\nblood cancer prevalent in children and teenagers, characterized by the rapid\nproliferation of immature white blood cells (WBCs). These atypical cells can\noverwhelm healthy cells, leading to severe health consequences. Early and\naccurate detection of ALL is vital for effective treatment and improving\nsurvival rates. Traditional diagnostic methods are time-consuming, costly, and\nprone to errors. The paper proposes an automated detection approach using\ncomputer-aided diagnostic (CAD) models, leveraging deep learning techniques to\nenhance the accuracy and efficiency of leukemia diagnosis. The study utilizes\nvarious transfer learning models like ResNet101V2, VGG19, InceptionV3, and\nInceptionResNetV2 for classifying ALL. The methodology includes using the Local\nInterpretable Model-Agnostic Explanations (LIME) for ensuring the validity and\nreliability of the AI system's predictions. This approach is critical for\novercoming the \"black box\" nature of AI, where decisions made by models are\noften opaque and unaccountable. The paper highlights that the proposed method\nusing the InceptionV3 model achieved an impressive 98.38% accuracy,\noutperforming other tested models. The results, verified by the LIME algorithm,\nshowcase the potential of this method in accurately identifying ALL, providing\na valuable tool for medical practitioners. The research underscores the impact\nof explainable artificial intelligence (XAI) in medical diagnostics, paving the\nway for more transparent and trustworthy AI applications in healthcare.",
            "author": [
                "Wahidul Hasan Abir",
                "Md. Fahim Uddin",
                "Faria Rahman Khanam",
                "Mohammad Monirujjaman Khan"
            ],
            "link": [
                "http://dx.doi.org/10.1155/2022/5140148",
                "http://arxiv.org/abs/2312.00487v1",
                "http://arxiv.org/pdf/2312.00487v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00486v1",
            "title": "REDUCR: Robust Data Downsampling Using Class Priority Reweighting",
            "updated": "2023-12-01T10:34:22Z",
            "published": "2023-12-01T10:34:22Z",
            "summary": "Modern machine learning models are becoming increasingly expensive to train\nfor real-world image and text classification tasks, where massive web-scale\ndata is collected in a streaming fashion. To reduce the training cost, online\nbatch selection techniques have been developed to choose the most informative\ndatapoints. However, these techniques can suffer from poor worst-class\ngeneralization performance due to class imbalance and distributional shifts.\nThis work introduces REDUCR, a robust and efficient data downsampling method\nthat uses class priority reweighting. REDUCR reduces the training data while\npreserving worst-class generalization performance. REDUCR assigns priority\nweights to datapoints in a class-aware manner using an online learning\nalgorithm. We demonstrate the data efficiency and robust performance of REDUCR\non vision and text classification tasks. On web-scraped datasets with\nimbalanced class distributions, REDUCR significantly improves worst-class test\naccuracy (and average accuracy), surpassing state-of-the-art methods by around\n15%.",
            "author": [
                "William Bankes",
                "George Hughes",
                "Ilija Bogunovic",
                "Zi Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00486v1",
                "http://arxiv.org/pdf/2312.00486v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00485v1",
            "title": "Backbone-based Dynamic Graph Spatio-Temporal Network for Epidemic\n  Forecasting",
            "updated": "2023-12-01T10:34:03Z",
            "published": "2023-12-01T10:34:03Z",
            "summary": "Accurate epidemic forecasting is a critical task in controlling disease\ntransmission. Many deep learning-based models focus only on static or dynamic\ngraphs when constructing spatial information, ignoring their relationship.\nAdditionally, these models often rely on recurrent structures, which can lead\nto error accumulation and computational time consumption. To address the\naforementioned problems, we propose a novel model called Backbone-based Dynamic\nGraph Spatio-Temporal Network (BDGSTN). Intuitively, the continuous and smooth\nchanges in graph structure, make adjacent graph structures share a basic\npattern. To capture this property, we use adaptive methods to generate static\nbackbone graphs containing the primary information and temporal models to\ngenerate dynamic temporal graphs of epidemic data, fusing them to generate a\nbackbone-based dynamic graph. To overcome potential limitations associated with\nrecurrent structures, we introduce a linear model DLinear to handle temporal\ndependencies and combine it with dynamic graph convolution for epidemic\nforecasting. Extensive experiments on two datasets demonstrate that BDGSTN\noutperforms baseline models and ablation comparison further verifies the\neffectiveness of model components. Furthermore, we analyze and measure the\nsignificance of backbone and temporal graphs by using information metrics from\ndifferent aspects. Finally, we compare model parameter volume and training time\nto confirm the superior complexity and efficiency of BDGSTN.",
            "author": [
                "Junkai Mao",
                "Yuexing Han",
                "Gouhei Tanaka",
                "Bing Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00485v1",
                "http://arxiv.org/pdf/2312.00485v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.PE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00484v1",
            "title": "MultiView Independent Component Analysis with Delays",
            "updated": "2023-12-01T10:33:16Z",
            "published": "2023-12-01T10:33:16Z",
            "summary": "Linear Independent Component Analysis (ICA) is a blind source separation\ntechnique that has been used in various domains to identify independent latent\nsources from observed signals. In order to obtain a higher signal-to-noise\nratio, the presence of multiple views of the same sources can be used. In this\nwork, we present MultiView Independent Component Analysis with Delays (MVICAD).\nThis algorithm builds on the MultiView ICA model by allowing sources to be\ndelayed versions of some shared sources: sources are shared across views up to\nsome unknown latencies that are view- and source-specific. Using simulations,\nwe demonstrate that MVICAD leads to better unmixing of the sources. Moreover,\nas ICA is often used in neuroscience, we show that latencies are age-related\nwhen applied to Cam-CAN, a large-scale magnetoencephalography (MEG) dataset.\nThese results demonstrate that the MVICAD model can reveal rich effects on\nneural signals without human supervision.",
            "author": [
                "Ambroise Heurtebise",
                "Pierre Ablin",
                "Alexandre Gramfort"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00484v1",
                "http://arxiv.org/pdf/2312.00484v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00483v1",
            "title": "MalDicom: A Memory Forensic Framework for Detecting Malicious Payload in\n  DICOM Files",
            "updated": "2023-12-01T10:33:15Z",
            "published": "2023-12-01T10:33:15Z",
            "summary": "Digital Imaging and Communication System (DICOM) is widely used throughout\nthe public health sector for portability in medical imaging. However, these\nDICOM files have vulnerabilities present in the preamble section. Successful\nexploitation of these vulnerabilities can allow attackers to embed executable\ncodes in the 128-Byte preamble of DICOM files. Embedding the malicious\nexecutable will not interfere with the readability or functionality of DICOM\nimagery. However, it will affect the underline system silently upon viewing\nthese files. This paper shows the infiltration of Windows malware executables\ninto DICOM files. On viewing the files, the malicious DICOM will get executed\nand eventually infect the entire hospital network through the radiologist's\nworkstation. The code injection process of executing malware in DICOM files\naffects the hospital networks and workstations' memory. Memory forensics for\nthe infected radiologist's workstation is crucial as it can detect which\nmalware disrupts the hospital environment, and future detection methods can be\ndeployed. In this paper, we consider the machine learning (ML) algorithms to\nconduct memory forensics on three memory dump categories: Trojan, Spyware, and\nRansomware, taken from the CIC-MalMem-2022 dataset. We obtain the highest\naccuracy of 75\\% with the Random Forest model. For estimating the feature\nimportance for ML model prediction, we leveraged the concept of Shapley values.",
            "author": [
                "Ayushi Mishra",
                "Priyanka Bagade"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00483v1",
                "http://arxiv.org/pdf/2312.00483v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00477v1",
            "title": "Interpretable Meta-Learning of Physical Systems",
            "updated": "2023-12-01T10:18:50Z",
            "published": "2023-12-01T10:18:50Z",
            "summary": "Machine learning methods can be a valuable aid in the scientific process, but\nthey need to face challenging settings where data come from inhomogeneous\nexperimental conditions. Recent meta-learning methods have made significant\nprogress in multi-task learning, but they rely on black-box neural networks,\nresulting in high computational costs and limited interpretability. Leveraging\nthe structure of the learning problem, we argue that multi-environment\ngeneralization can be achieved using a simpler learning model, with an affine\nstructure with respect to the learning task. Crucially, we prove that this\narchitecture can identify the physical parameters of the system, enabling\ninterpreable learning. We demonstrate the competitive generalization\nperformance and the low computational cost of our method by comparing it to\nstate-of-the-art algorithms on physical systems, ranging from toy models to\ncomplex, non-analytical systems. The interpretability of our method is\nillustrated with original applications to physical-parameter-induced adaptation\nand to adaptive control.",
            "author": [
                "Matthieu Blanke",
                "Marc Lelarge"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00477v1",
                "http://arxiv.org/pdf/2312.00477v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00476v1",
            "title": "Self-Supervised Learning of Spatial Acoustic Representation with\n  Cross-Channel Signal Reconstruction and Multi-Channel Conformer",
            "updated": "2023-12-01T10:16:02Z",
            "published": "2023-12-01T10:16:02Z",
            "summary": "Supervised learning methods have shown effectiveness in estimating spatial\nacoustic parameters such as time difference of arrival, direct-to-reverberant\nratio and reverberation time. However, they still suffer from the\nsimulation-to-reality generalization problem due to the mismatch between\nsimulated and real-world acoustic characteristics and the deficiency of\nannotated real-world data. To this end, this work proposes a self-supervised\nmethod that takes full advantage of unlabeled data for spatial acoustic\nparameter estimation. First, a new pretext task, i.e. cross-channel signal\nreconstruction (CCSR), is designed to learn a universal spatial acoustic\nrepresentation from unlabeled multi-channel microphone signals. We mask partial\nsignals of one channel and ask the model to reconstruct them, which makes it\npossible to learn spatial acoustic information from unmasked signals and\nextract source information from the other microphone channel. An\nencoder-decoder structure is used to disentangle the two kinds of information.\nBy fine-tuning the pre-trained spatial encoder with a small annotated dataset,\nthis encoder can be used to estimate spatial acoustic parameters. Second, a\nnovel multi-channel audio Conformer (MC-Conformer) is adopted as the encoder\nmodel architecture, which is suitable for both the pretext and downstream\ntasks. It is carefully designed to be able to capture the local and global\ncharacteristics of spatial acoustics exhibited in the time-frequency domain.\nExperimental results of five acoustic parameter estimation tasks on both\nsimulated and real-world data show the effectiveness of the proposed method. To\nthe best of our knowledge, this is the first self-supervised learning method in\nthe field of spatial acoustic representation learning and multi-channel audio\nsignal processing.",
            "author": [
                "Bing Yang",
                "Xiaofei Li"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00476v1",
                "http://arxiv.org/pdf/2312.00476v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00471v1",
            "title": "A Bayesian approach for prompt optimization in pre-trained language\n  models",
            "updated": "2023-12-01T10:10:18Z",
            "published": "2023-12-01T10:10:18Z",
            "summary": "A prompt is a sequence of symbol or tokens, selected from a vocabulary\naccording to some rule, which is prepended/concatenated to a textual query. A\nkey problem is how to select the sequence of tokens: in this paper we formulate\nit as a combinatorial optimization problem. The high dimensionality of the\ntoken space com-pounded by the length of the prompt sequence requires a very\nefficient solution. In this paper we propose a Bayesian optimization method,\nexecuted in a continuous em-bedding of the combinatorial space. In this paper\nwe focus on hard prompt tuning (HPT) which directly searches for discrete\ntokens to be added to the text input with-out requiring access to the large\nlanguage model (LLM) and can be used also when LLM is available only as a\nblack-box. This is critically important if LLMs are made available in the Model\nas a Service (MaaS) manner as in GPT-4. The current manu-script is focused on\nthe optimization of discrete prompts for classification tasks. The discrete\nprompts give rise to difficult combinatorial optimization problem which easily\nbecome intractable given the dimension of the token space in realistic\napplications. The optimization method considered in this paper is Bayesian\noptimization (BO) which has become the dominant approach in black-box\noptimization for its sample efficiency along with its modular structure and\nversatility. In this paper we use BoTorch, a library for Bayesian optimization\nresearch built on top of pyTorch. Albeit preliminary and obtained using a\n'vanilla' version of BO, the experiments on RoB-ERTa on six benchmarks, show a\ngood performance across a variety of tasks and enable an analysis of the\ntradeoff between size of the search space, accuracy and wall clock time.",
            "author": [
                "Antonio Sabbatella",
                "Andrea Ponti",
                "Antonio Candelieri",
                "Ilaria Giordani",
                "Francesco Archetti"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00471v1",
                "http://arxiv.org/pdf/2312.00471v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00462v1",
            "title": "Learning Unorthogonalized Matrices for Rotation Estimation",
            "updated": "2023-12-01T09:56:29Z",
            "published": "2023-12-01T09:56:29Z",
            "summary": "Estimating 3D rotations is a common procedure for 3D computer vision. The\naccuracy depends heavily on the rotation representation. One form of\nrepresentation -- rotation matrices -- is popular due to its continuity,\nespecially for pose estimation tasks. The learning process usually incorporates\northogonalization to ensure orthonormal matrices. Our work reveals, through\ngradient analysis, that common orthogonalization procedures based on the\nGram-Schmidt process and singular value decomposition will slow down training\nefficiency. To this end, we advocate removing orthogonalization from the\nlearning process and learning unorthogonalized `Pseudo' Rotation Matrices\n(PRoM). An optimization analysis shows that PRoM converges faster and to a\nbetter solution. By replacing the orthogonalization incorporated representation\nwith our proposed PRoM in various rotation-related tasks, we achieve\nstate-of-the-art results on large-scale benchmarks for human pose estimation.",
            "author": [
                "Kerui Gu",
                "Zhihao Li",
                "Shiyong Liu",
                "Jianzhuang Liu",
                "Songcen Xu",
                "Youliang Yan",
                "Michael Bi Mi",
                "Kenji Kawaguchi",
                "Angela Yao"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00462v1",
                "http://arxiv.org/pdf/2312.00462v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00456v1",
            "title": "Auto-encoding GPS data to reveal individual and collective behaviour",
            "updated": "2023-12-01T09:41:40Z",
            "published": "2023-12-01T09:41:40Z",
            "summary": "We propose an innovative and generic methodology to analyse individual and\ncollective behaviour through individual trajectory data. The work is motivated\nby the analysis of GPS trajectories of fishing vessels collected from\nregulatory tracking data in the context of marine biodiversity conservation and\necosystem-based fisheries management. We build a low-dimensional latent\nrepresentation of trajectories using convolutional neural networks as\nnon-linear mapping. This is done by training a conditional variational\nauto-encoder taking into account covariates. The posterior distributions of the\nlatent representations can be linked to the characteristics of the actual\ntrajectories. The latent distributions of the trajectories are compared with\nthe Bhattacharyya coefficient, which is well-suited for comparing\ndistributions. Using this coefficient, we analyse the variation of the\nindividual behaviour of each vessel during time. For collective behaviour\nanalysis, we build proximity graphs and use an extension of the stochastic\nblock model for multiple networks. This model results in a clustering of the\nindividuals based on their set of trajectories. The application to French\nfishing vessels enables us to obtain groups of vessels whose individual and\ncollective behaviours exhibit spatio-temporal patterns over the period\n2014-2018.",
            "author": [
                "Saint-Clair Chabert-Liddell",
                "Nicolas Bez",
                "Pierre Gloaguen",
                "Sophie Donnet",
                "St\u00e9phanie Mah\u00e9vas"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00456v1",
                "http://arxiv.org/pdf/2312.00456v1"
            ],
            "primary_category": "stat.AP",
            "category": [
                "stat.AP",
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00455v1",
            "title": "Meta-Diversity Search in Complex Systems, A Recipe for Artificial\n  Open-Endedness ?",
            "updated": "2023-12-01T09:40:27Z",
            "published": "2023-12-01T09:40:27Z",
            "summary": "Can we build an artificial system that would be able to generate endless\nsurprises if ran \"forever\" in Minecraft? While there is not a single path\ntoward solving that grand challenge, this article presents what we believe to\nbe some working ingredients for the endless generation of novel increasingly\ncomplex artifacts in Minecraft. Our framework for an open-ended system includes\ntwo components: a complex system used to recursively grow and complexify\nartifacts over time, and a discovery algorithm that leverages the concept of\nmeta-diversity search. Since complex systems have shown to enable the emergence\nof considerable complexity from set of simple rules, we believe them to be\ngreat candidates to generate all sort of artifacts in Minecraft. Yet, the space\nof possible artifacts that can be generated by these systems is often unknown,\nchallenging to characterize and explore. Therefore automating the long-term\ndiscovery of novel and increasingly complex artifacts in these systems is an\nexciting research field. To approach these challenges, we formulate the problem\nof meta-diversity search where an artificial \"discovery assistant\"\nincrementally learns a diverse set of representations to characterize behaviors\nand searches to discover diverse patterns within each of them. A successful\ndiscovery assistant should continuously seek for novel sources of diversities\nwhile being able to quickly specialize the search toward a new unknown type of\ndiversity. To implement those ideas in the Minecraft environment, we simulate\nan artificial \"chemistry\" system based on Lenia continuous cellular automaton\nfor generating artifacts, as well as an artificial \"discovery assistant\"\n(called Holmes) for the artifact-discovery process. Holmes incrementally learns\na hierarchy of modular representations to characterize divergent sources of\ndiversity and uses a goal-based intrinsically-motivated exploration as the\ndiversity search strategy.",
            "author": [
                "Mayalen Etcheverry",
                "Bert Wang-Chak Chan",
                "Cl\u00e9ment Moulin-Frier",
                "Pierre-Yves Oudeyer"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00455v1",
                "http://arxiv.org/pdf/2312.00455v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "nlin.CG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00454v1",
            "title": "An Encoding Framework for Binarized Images using HyperDimensional\n  Computing",
            "updated": "2023-12-01T09:34:28Z",
            "published": "2023-12-01T09:34:28Z",
            "summary": "Hyperdimensional Computing (HDC) is a brain-inspired and light-weight machine\nlearning method. It has received significant attention in the literature as a\ncandidate to be applied in the wearable internet of things, near-sensor\nartificial intelligence applications and on-device processing. HDC is\ncomputationally less complex than traditional deep learning algorithms and\ntypically achieves moderate to good classification performance. A key aspect\nthat determines the performance of HDC is the encoding of the input data to the\nhyperdimensional (HD) space. This article proposes a novel light-weight\napproach relying only on native HD arithmetic vector operations to encode\nbinarized images that preserves similarity of patterns at nearby locations by\nusing point of interest selection and local linear mapping. The method reaches\nan accuracy of 97.35% on the test set for the MNIST data set and 84.12% for the\nFashion-MNIST data set. These results outperform other studies using baseline\nHDC with different encoding approaches and are on par with more complex hybrid\nHDC models. The proposed encoding approach also demonstrates a higher\nrobustness to noise and blur compared to the baseline encoding.",
            "author": [
                "Laura Smets",
                "Werner Van Leekwijck",
                "Ing Jyh Tsang",
                "Steven Latr\u00e9"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00454v1",
                "http://arxiv.org/pdf/2312.00454v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00847v2",
            "title": "Handling nonlinearities and uncertainties of fed-batch cultivations with\n  difference of convex functions tube MPC",
            "updated": "2023-12-07T14:35:19Z",
            "published": "2023-12-01T09:24:04Z",
            "summary": "Bioprocesses are often characterized by nonlinear and uncertain dynamics.\nThis poses particular challenges in the context of model predictive control\n(MPC). Several approaches have been proposed to solve this problem, such as\nrobust or stochastic MPC, but they can be computationally expensive when the\nsystem is nonlinear. Recent advances in optimal control theory have shown that\nconcepts from convex optimization, tube-based MPC, and difference of convex\nfunctions (DC) enable stable and robust online process control. The approach is\nbased on systematic DC decompositions of the dynamics and successive\nlinearizations around feasible trajectories. By convexity, the linearization\nerrors can be bounded tightly and treated as bounded disturbances in a robust\ntube-based MPC framework. However, finding the DC composition can be a\ndifficult task. To overcome this problem, we used a neural network with special\nconvex structure to learn the dynamics in DC form and express the uncertainty\nsets using simplices to maximize the product formation rate of a cultivation\nwith uncertain substrate concentration in the feed. The results show that this\nis a promising approach for computationally tractable data-driven robust MPC of\nbioprocesses.",
            "author": [
                "Niels Krausch",
                "Martin Doff-Sotta",
                "Mark Canon",
                "Peter Neubauer",
                "Mariano Nicolas Cruz Bournazou"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00847v2",
                "http://arxiv.org/pdf/2312.00847v2"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00438v1",
            "title": "Dolphins: Multimodal Language Model for Driving",
            "updated": "2023-12-01T09:10:33Z",
            "published": "2023-12-01T09:10:33Z",
            "summary": "The quest for fully autonomous vehicles (AVs) capable of navigating complex\nreal-world scenarios with human-like understanding and responsiveness. In this\npaper, we introduce Dolphins, a novel vision-language model architected to\nimbibe human-like abilities as a conversational driving assistant. Dolphins is\nadept at processing multimodal inputs comprising video (or image) data, text\ninstructions, and historical control signals to generate informed outputs\ncorresponding to the provided instructions. Building upon the open-sourced\npretrained Vision-Language Model, OpenFlamingo, we first enhance Dolphins's\nreasoning capabilities through an innovative Grounded Chain of Thought (GCoT)\nprocess. Then we tailored Dolphins to the driving domain by constructing\ndriving-specific instruction data and conducting instruction tuning. Through\nthe utilization of the BDD-X dataset, we designed and consolidated four\ndistinct AV tasks into Dolphins to foster a holistic understanding of intricate\ndriving scenarios. As a result, the distinctive features of Dolphins are\ncharacterized into two dimensions: (1) the ability to provide a comprehensive\nunderstanding of complex and long-tailed open-world driving scenarios and solve\na spectrum of AV tasks, and (2) the emergence of human-like capabilities\nincluding gradient-free instant adaptation via in-context learning and error\nrecovery via reflection.",
            "author": [
                "Yingzi Ma",
                "Yulong Cao",
                "Jiachen Sun",
                "Marco Pavone",
                "Chaowei Xiao"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00438v1",
                "http://arxiv.org/pdf/2312.00438v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00435v1",
            "title": "Enhancing Image Captioning with Neural Models",
            "updated": "2023-12-01T09:06:56Z",
            "published": "2023-12-01T09:06:56Z",
            "summary": "This research explores the realm of neural image captioning using deep\nlearning models. The study investigates the performance of different neural\narchitecture configurations, focusing on the inject architecture, and proposes\na novel quality metric for evaluating caption generation. Through extensive\nexperimentation and analysis, this work sheds light on the challenges and\nopportunities in image captioning, providing insights into model behavior and\noverfitting. The results reveal that while the merge models exhibit a larger\nvocabulary and higher ROUGE scores, the inject architecture generates relevant\nand concise image captions. The study also highlights the importance of\nrefining training data and optimizing hyperparameters for improved model\nperformance. This research contributes to the growing body of knowledge in\nneural image captioning and encourages further exploration in the field,\nemphasizing the democratization of artificial intelligence.",
            "author": [
                "Pooja Bhatnagar",
                "Sai Mrunaal",
                "Sachin Kamnure"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00435v1",
                "http://arxiv.org/pdf/2312.00435v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00434v1",
            "title": "PEFTDebias : Capturing debiasing information using PEFTs",
            "updated": "2023-12-01T09:06:06Z",
            "published": "2023-12-01T09:06:06Z",
            "summary": "The increasing use of foundation models highlights the urgent need to address\nand eliminate implicit biases present in them that arise during pretraining. In\nthis paper, we introduce PEFTDebias, a novel approach that employs\nparameter-efficient fine-tuning (PEFT) to mitigate the biases within foundation\nmodels. PEFTDebias consists of two main phases: an upstream phase for acquiring\ndebiasing parameters along a specific bias axis, and a downstream phase where\nthese parameters are incorporated into the model and frozen during the\nfine-tuning process. By evaluating on four datasets across two bias axes namely\ngender and race, we find that downstream biases can be effectively reduced with\nPEFTs. In addition, we show that these parameters possess axis-specific\ndebiasing characteristics, enabling their effective transferability in\nmitigating biases in various downstream tasks. To ensure reproducibility, we\nrelease the code to do our experiments.",
            "author": [
                "Sumit Agarwal",
                "Aditya Srikanth Veerubhotla",
                "Srijan Bansal"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00434v1",
                "http://arxiv.org/pdf/2312.00434v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00427v1",
            "title": "From Mutual Information to Expected Dynamics: New Generalization Bounds\n  for Heavy-Tailed SGD",
            "updated": "2023-12-01T08:50:42Z",
            "published": "2023-12-01T08:50:42Z",
            "summary": "Understanding the generalization abilities of modern machine learning\nalgorithms has been a major research topic over the past decades. In recent\nyears, the learning dynamics of Stochastic Gradient Descent (SGD) have been\nrelated to heavy-tailed dynamics. This has been successfully applied to\ngeneralization theory by exploiting the fractal properties of those dynamics.\nHowever, the derived bounds depend on mutual information (decoupling) terms\nthat are beyond the reach of computability. In this work, we prove\ngeneralization bounds over the trajectory of a class of heavy-tailed dynamics,\nwithout those mutual information terms. Instead, we introduce a geometric\ndecoupling term by comparing the learning dynamics (depending on the empirical\nrisk) with an expected one (depending on the population risk). We further\nupper-bound this geometric term, by using techniques from the heavy-tailed and\nthe fractal literature, making it fully computable. Moreover, as an attempt to\ntighten the bounds, we propose a PAC-Bayesian setting based on perturbed\ndynamics, in which the same geometric term plays a crucial role and can still\nbe bounded using the techniques described above.",
            "author": [
                "Benjamin Dupuis",
                "Paul Viallard"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00427v1",
                "http://arxiv.org/pdf/2312.00427v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00414v1",
            "title": "Large-scale Vision-Language Models Learn Super Images for Efficient and\n  High-Performance Partially Relevant Video Retrieval",
            "updated": "2023-12-01T08:38:27Z",
            "published": "2023-12-01T08:38:27Z",
            "summary": "In this paper, we propose an efficient and high-performance method for\npartially relevant video retrieval (PRVR), which aims to retrieve untrimmed\nlong videos that contain at least one relevant moment to the input text query.\nIn terms of both efficiency and performance, the overlooked bottleneck of\nprevious studies is the visual encoding of dense frames. This guides\nresearchers to choose lightweight visual backbones, yielding sub-optimal\nretrieval performance due to their limited capabilities of learned visual\nrepresentations. However, it is undesirable to simply replace them with\nhigh-performance large-scale vision-and-language models (VLMs) due to their low\nefficiency. To address these issues, instead of dense frames, we focus on super\nimages, which are created by rearranging the video frames in a $N \\times N$\ngrid layout. This reduces the number of visual encodings to $\\frac{1}{N^2}$ and\ncompensates for the low efficiency of large-scale VLMs, allowing us to adopt\nthem as powerful encoders. Surprisingly, we discover that with a simple\nquery-image attention trick, VLMs generalize well to super images effectively\nand demonstrate promising zero-shot performance against SOTA methods\nefficiently. In addition, we propose a fine-tuning approach by incorporating a\nfew trainable modules into the VLM backbones. The experimental results\ndemonstrate that our approaches efficiently achieve the best performance on\nActivityNet Captions and TVR.",
            "author": [
                "Taichi Nishimura",
                "Shota Nakada",
                "Masayoshi Kondo"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00414v1",
                "http://arxiv.org/pdf/2312.00414v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00413v1",
            "title": "Abstract Syntax Tree for Programming Language Understanding and\n  Representation: How Far Are We?",
            "updated": "2023-12-01T08:37:27Z",
            "published": "2023-12-01T08:37:27Z",
            "summary": "Programming language understanding and representation (a.k.a code\nrepresentation learning) has always been a hot and challenging task in software\nengineering. It aims to apply deep learning techniques to produce numerical\nrepresentations of the source code features while preserving its semantics.\nThese representations can be used for facilitating subsequent code-related\ntasks. The abstract syntax tree (AST), a fundamental code feature, illustrates\nthe syntactic information of the source code and has been widely used in code\nrepresentation learning. However, there is still a lack of systematic and\nquantitative evaluation of how well AST-based code representation facilitates\nsubsequent code-related tasks. In this paper, we first conduct a comprehensive\nempirical study to explore the effectiveness of the AST-based code\nrepresentation in facilitating follow-up code-related tasks. To do so, we\ncompare the performance of models trained with code token sequence (Token for\nshort) based code representation and AST-based code representation on three\npopular types of code-related tasks. Surprisingly, the overall quantitative\nstatistical results demonstrate that models trained with AST-based code\nrepresentation consistently perform worse across all three tasks compared to\nmodels trained with Token-based code representation. Our further quantitative\nanalysis reveals that models trained with AST-based code representation\noutperform models trained with Token-based code representation in certain\nsubsets of samples across all three tasks. We also conduct comprehensive\nexperiments to evaluate and reveal the impact of the choice of AST\nparsing/preprocessing/encoding methods on AST-based code representation and\nsubsequent code-related tasks. Our study provides future researchers with\ndetailed guidance on how to select solutions at each stage to fully exploit\nAST.",
            "author": [
                "Weisong Sun",
                "Chunrong Fang",
                "Yun Miao",
                "Yudu You",
                "Mengzhe Yuan",
                "Yuchen Chen",
                "Quanjun Zhang",
                "An Guo",
                "Xiang Chen",
                "Yang Liu",
                "Zhenyu Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00413v1",
                "http://arxiv.org/pdf/2312.00413v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.AI",
                "cs.CL",
                "cs.PL",
                "68-04, 68T30",
                "D.2.3; I.2.2; I.2.4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00411v1",
            "title": "A framework for mining lifestyle profiles through multi-dimensional and\n  high-order mobility feature clustering",
            "updated": "2023-12-01T08:21:05Z",
            "published": "2023-12-01T08:21:05Z",
            "summary": "Human mobility demonstrates a high degree of regularity, which facilitates\nthe discovery of lifestyle profiles. Existing research has yet to fully utilize\nthe regularities embedded in high-order features extracted from human mobility\nrecords in such profiling. This study proposes a progressive feature extraction\nstrategy that mines high-order mobility features from users' moving trajectory\nrecords from the spatial, temporal, and semantic dimensions. Specific features\nare extracted such as travel motifs, rhythms decomposed by discrete Fourier\ntransform (DFT) of mobility time series, and vectorized place semantics by\nword2vec, respectively to the three dimensions, and they are further clustered\nto reveal the users' lifestyle characteristics. An experiment using a\ntrajectory dataset of over 500k users in Shenzhen, China yields seven user\nclusters with different lifestyle profiles that can be well interpreted by\ncommon sense. The results suggest the possibility of fine-grained user\nprofiling through cross-order trajectory feature engineering and clustering.",
            "author": [
                "Yeshuo Shu",
                "Gangcheng Zhang",
                "Keyi Liu",
                "Jintong Tang",
                "Liyan Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00411v1",
                "http://arxiv.org/pdf/2312.00411v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00404v1",
            "title": "A Causality-Aware Pattern Mining Scheme for Group Activity Recognition\n  in a Pervasive Sensor Space",
            "updated": "2023-12-01T07:54:07Z",
            "published": "2023-12-01T07:54:07Z",
            "summary": "Human activity recognition (HAR) is a key challenge in pervasive computing\nand its solutions have been presented based on various disciplines.\nSpecifically, for HAR in a smart space without privacy and accessibility\nissues, data streams generated by deployed pervasive sensors are leveraged. In\nthis paper, we focus on a group activity by which a group of users perform a\ncollaborative task without user identification and propose an efficient group\nactivity recognition scheme which extracts causality patterns from pervasive\nsensor event sequences generated by a group of users to support as good\nrecognition accuracy as the state-of-the-art graphical model. To filter out\nirrelevant noise events from a given data stream, a set of rules is leveraged\nto highlight causally related events. Then, a pattern-tree algorithm extracts\nfrequent causal patterns by means of a growing tree structure. Based on the\nextracted patterns, a weighted sum-based pattern matching algorithm computes\nthe likelihoods of stored group activities to the given test event sequence by\nmeans of matched event pattern counts for group activity recognition. We\nevaluate the proposed scheme using the data collected from our testbed and\nCASAS datasets where users perform their tasks on a daily basis and validate\nits effectiveness in a real environment. Experiment results show that the\nproposed scheme performs higher recognition accuracy and with a small amount of\nruntime overhead than the existing schemes.",
            "author": [
                "Hyunju Kim",
                "Heesuk Son",
                "Dongman Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00404v1",
                "http://arxiv.org/pdf/2312.00404v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DB"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00401v1",
            "title": "VIoTGPT: Learning to Schedule Vision Tools towards Intelligent Video\n  Internet of Things",
            "updated": "2023-12-01T07:50:53Z",
            "published": "2023-12-01T07:50:53Z",
            "summary": "Video Internet of Things (VIoT) has shown full potential in collecting an\nunprecedented volume of video data. Learning to schedule perceiving models and\nanalyzing the collected videos intelligently will be potential sparks for VIoT.\nIn this paper, to address the challenges posed by the fine-grained and\ninterrelated vision tool usage of VIoT, we build VIoTGPT, the framework based\non LLMs to correctly interact with humans, query knowledge videos, and invoke\nvision models to accomplish complicated tasks. To support VIoTGPT and related\nfuture works, we meticulously crafted the training dataset and established\nbenchmarks involving 11 representative vision models across three categories\nbased on semi-automatic annotations. To guide LLM to act as the intelligent\nagent towards intelligent VIoT, we resort to ReAct instruction tuning based on\nthe collected VIoT dataset to learn the tool capability. Quantitative and\nqualitative experimental results and analyses demonstrate the effectiveness of\nVIoTGPT.",
            "author": [
                "Yaoyao Zhong",
                "Mengshi Qi",
                "Rui Wang",
                "Yuhan Qiu",
                "Yang Zhang",
                "Huadong Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00401v1",
                "http://arxiv.org/pdf/2312.00401v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00398v1",
            "title": "Learning to Estimate Critical Gait Parameters from Single-View RGB\n  Videos with Transformer-Based Attention Network",
            "updated": "2023-12-01T07:45:27Z",
            "published": "2023-12-01T07:45:27Z",
            "summary": "Musculoskeletal diseases and cognitive impairments in patients lead to\ndifficulties in movement as well as negative effects on their psychological\nhealth. Clinical gait analysis, a vital tool for early diagnosis and treatment,\ntraditionally relies on expensive optical motion capture systems. Recent\nadvances in computer vision and deep learning have opened the door to more\naccessible and cost-effective alternatives. This paper introduces a novel\nspatio-temporal Transformer network to estimate critical gait parameters from\nRGB videos captured by a single-view camera. Empirical evaluations on a public\ndataset of cerebral palsy patients indicate that the proposed framework\nsurpasses current state-of-the-art approaches and show significant improvements\nin predicting general gait parameters (including Walking Speed, Gait Deviation\nIndex - GDI, and Knee Flexion Angle at Maximum Extension), while utilizing\nfewer parameters and alleviating the need for manual feature extraction.",
            "author": [
                "Quoc Hung T. Le",
                "Hieu H. Pham"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00398v1",
                "http://arxiv.org/pdf/2312.00398v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00396v1",
            "title": "GFN-SR: Symbolic Regression with Generative Flow Networks",
            "updated": "2023-12-01T07:38:05Z",
            "published": "2023-12-01T07:38:05Z",
            "summary": "Symbolic regression (SR) is an area of interpretable machine learning that\naims to identify mathematical expressions, often composed of simple functions,\nthat best fit in a given set of covariates $X$ and response $y$. In recent\nyears, deep symbolic regression (DSR) has emerged as a popular method in the\nfield by leveraging deep reinforcement learning to solve the complicated\ncombinatorial search problem. In this work, we propose an alternative framework\n(GFN-SR) to approach SR with deep learning. We model the construction of an\nexpression tree as traversing through a directed acyclic graph (DAG) so that\nGFlowNet can learn a stochastic policy to generate such trees sequentially.\nEnhanced with an adaptive reward baseline, our method is capable of generating\na diverse set of best-fitting expressions. Notably, we observe that GFN-SR\noutperforms other SR algorithms in noisy data regimes, owing to its ability to\nlearn a distribution of rewards over a space of candidate solutions.",
            "author": [
                "Sida Li",
                "Ioana Marinescu",
                "Sebastian Musslick"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00396v1",
                "http://arxiv.org/pdf/2312.00396v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00388v1",
            "title": "LinguaLinked: A Distributed Large Language Model Inference System for\n  Mobile Devices",
            "updated": "2023-12-01T07:19:42Z",
            "published": "2023-12-01T07:19:42Z",
            "summary": "Deploying Large Language Models (LLMs) locally on mobile devices presents a\nsignificant challenge due to their extensive memory requirements. In this\npaper, we introduce LinguaLinked, a system for decentralized, distributed LLM\ninference on mobile devices. LinguaLinked enables collaborative execution of\nthe inference task across multiple trusted devices. LinguaLinked ensures data\nprivacy by processing information locally. LinguaLinked uses three key\nstrategies. First, an optimized model assignment technique segments LLMs and\nuses linear optimization to align segments with each device's capabilities.\nSecond, an optimized data transmission mechanism ensures efficient and\nstructured data flow between model segments while also maintaining the\nintegrity of the original model structure. Finally, LinguaLinked incorporates a\nruntime load balancer that actively monitors and redistributes tasks among\nmobile devices to prevent bottlenecks, enhancing the system's overall\nefficiency and responsiveness. We demonstrate that LinguaLinked facilitates\nefficient LLM inference while maintaining consistent throughput and minimal\nlatency through extensive testing across various mobile devices, from high-end\nto low-end Android devices. In our evaluations, compared to the baseline,\nLinguaLinked achieves an inference performance acceleration of $1.11\\times$ to\n$1.61\\times$ in single-threaded settings, $1.73\\times$ to $2.65\\times$ with\nmulti-threading. Additionally, runtime load balancing yields an overall\ninference acceleration of $1.29\\times$ to $1.32\\times$.",
            "author": [
                "Junchen Zhao",
                "Yurun Song",
                "Simeng Liu",
                "Ian G. Harris",
                "Sangeetha Abdu Jyothi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00388v1",
                "http://arxiv.org/pdf/2312.00388v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00386v1",
            "title": "Local monotone operator learning using non-monotone operators: MnM-MOL",
            "updated": "2023-12-01T07:15:51Z",
            "published": "2023-12-01T07:15:51Z",
            "summary": "The recovery of magnetic resonance (MR) images from undersampled measurements\nis a key problem that has seen extensive research in recent years. Unrolled\napproaches, which rely on end-to-end training of convolutional neural network\n(CNN) blocks within iterative reconstruction algorithms, offer state-of-the-art\nperformance. These algorithms require a large amount of memory during training,\nmaking them difficult to employ in high-dimensional applications. Deep\nequilibrium (DEQ) models and the recent monotone operator learning (MOL)\napproach were introduced to eliminate the need for unrolling, thus reducing the\nmemory demand during training. Both approaches require a Lipschitz constraint\non the network to ensure that the forward and backpropagation iterations\nconverge. Unfortunately, the constraint often results in reduced performance\ncompared to unrolled methods. The main focus of this work is to relax the\nconstraint on the CNN block in two different ways. Inspired by\nconvex-non-convex regularization strategies, we now impose the monotone\nconstraint on the sum of the gradient of the data term and the CNN block,\nrather than constrain the CNN itself to be a monotone operator. This approach\nenables the CNN to learn possibly non-monotone score functions, which can\ntranslate to improved performance. In addition, we only restrict the operator\nto be monotone in a local neighborhood around the image manifold. Our\ntheoretical results show that the proposed algorithm is guaranteed to converge\nto the fixed point and that the solution is robust to input perturbations,\nprovided that it is initialized close to the true solution. Our empirical\nresults show that the relaxed constraints translate to improved performance and\nthat the approach enjoys robustness to input perturbations similar to MOL.",
            "author": [
                "Maneesh John",
                "Jyothi Rikhab Chand",
                "Mathews Jacob"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00386v1",
                "http://arxiv.org/pdf/2312.00386v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00379v1",
            "title": "Optimal Sample Complexity of Contrastive Learning",
            "updated": "2023-12-01T06:57:11Z",
            "published": "2023-12-01T06:57:11Z",
            "summary": "Contrastive learning is a highly successful technique for learning\nrepresentations of data from labeled tuples, specifying the distance relations\nwithin the tuple. We study the sample complexity of contrastive learning, i.e.\nthe minimum number of labeled tuples sufficient for getting high generalization\naccuracy. We give tight bounds on the sample complexity in a variety of\nsettings, focusing on arbitrary distance functions, both general\n$\\ell_p$-distances, and tree metrics. Our main result is an (almost) optimal\nbound on the sample complexity of learning $\\ell_p$-distances for integer $p$.\nFor any $p \\ge 1$ we show that $\\tilde \\Theta(\\min(nd,n^2))$ labeled tuples are\nnecessary and sufficient for learning $d$-dimensional representations of\n$n$-point datasets. Our results hold for an arbitrary distribution of the input\nsamples and are based on giving the corresponding bounds on the\nVapnik-Chervonenkis/Natarajan dimension of the associated problems. We further\nshow that the theoretical bounds on sample complexity obtained via VC/Natarajan\ndimension can have strong predictive power for experimental results, in\ncontrast with the folklore belief about a substantial gap between the\nstatistical learning theory and the practice of deep learning.",
            "author": [
                "Noga Alon",
                "Dmitrii Avdiukhin",
                "Dor Elboim",
                "Orr Fischer",
                "Grigory Yaroslavtsev"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00379v1",
                "http://arxiv.org/pdf/2312.00379v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00845v1",
            "title": "VMC: Video Motion Customization using Temporal Attention Adaption for\n  Text-to-Video Diffusion Models",
            "updated": "2023-12-01T06:50:11Z",
            "published": "2023-12-01T06:50:11Z",
            "summary": "Text-to-video diffusion models have advanced video generation significantly.\nHowever, customizing these models to generate videos with tailored motions\npresents a substantial challenge. In specific, they encounter hurdles in (a)\naccurately reproducing motion from a target video, and (b) creating diverse\nvisual variations. For example, straightforward extensions of static image\ncustomization methods to video often lead to intricate entanglements of\nappearance and motion data. To tackle this, here we present the Video Motion\nCustomization (VMC) framework, a novel one-shot tuning approach crafted to\nadapt temporal attention layers within video diffusion models. Our approach\nintroduces a novel motion distillation objective using residual vectors between\nconsecutive frames as a motion reference. The diffusion process then preserves\nlow-frequency motion trajectories while mitigating high-frequency\nmotion-unrelated noise in image space. We validate our method against\nstate-of-the-art video generative models across diverse real-world motions and\ncontexts. Our codes, data and the project demo can be found at\nhttps://video-motion-customization.github.io",
            "author": [
                "Hyeonho Jeong",
                "Geon Yeong Park",
                "Jong Chul Ye"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00845v1",
                "http://arxiv.org/pdf/2312.00845v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00373v1",
            "title": "Streaming Bayesian Modeling for predicting Fat-Tailed Customer Lifetime\n  Value",
            "updated": "2023-12-01T06:33:39Z",
            "published": "2023-12-01T06:33:39Z",
            "summary": "We develop an online learning MCMC approach applicable for hierarchical\nbayesian models and GLMS. We also develop a fat-tailed LTV model that\ngeneralizes over several kinds of fat and thin tails. We demonstrate both\ndevelopments on commercial LTV data from a large mobile app.",
            "author": [
                "Alexey V. Calabourdin",
                "Konstantin A. Aksenov"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00373v1",
                "http://arxiv.org/pdf/2312.00373v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.AP",
                "stat.ME",
                "62C10, 62F15"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00364v1",
            "title": "Benchmarking Multi-Domain Active Learning on Image Classification",
            "updated": "2023-12-01T06:11:14Z",
            "published": "2023-12-01T06:11:14Z",
            "summary": "Active learning aims to enhance model performance by strategically labeling\ninformative data points. While extensively studied, its effectiveness on\nlarge-scale, real-world datasets remains underexplored. Existing research\nprimarily focuses on single-source data, ignoring the multi-domain nature of\nreal-world data. We introduce a multi-domain active learning benchmark to\nbridge this gap. Our benchmark demonstrates that traditional single-domain\nactive learning strategies are often less effective than random selection in\nmulti-domain scenarios. We also introduce CLIP-GeoYFCC, a novel large-scale\nimage dataset built around geographical domains, in contrast to existing\ngenre-based domain datasets. Analysis on our benchmark shows that all\nmulti-domain strategies exhibit significant tradeoffs, with no strategy\noutperforming across all datasets or all metrics, emphasizing the need for\nfuture research.",
            "author": [
                "Jiayi Li",
                "Rohan Taori",
                "Tatsunori B. Hashimoto"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00364v1",
                "http://arxiv.org/pdf/2312.00364v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00844v1",
            "title": "Sparse Beats Dense: Rethinking Supervision in Radar-Camera Depth\n  Completion",
            "updated": "2023-12-01T06:04:49Z",
            "published": "2023-12-01T06:04:49Z",
            "summary": "It is widely believed that the dense supervision is better than the sparse\nsupervision in the field of depth completion, but the underlying reasons for\nthis are rarely discussed. In this paper, we find that the challenge of using\nsparse supervision for training Radar-Camera depth prediction models is the\nProjection Transformation Collapse (PTC). The PTC implies that sparse\nsupervision leads the model to learn unexpected collapsed projection\ntransformations between Image/Radar/LiDAR spaces. Building on this insight, we\npropose a novel ``Disruption-Compensation\" framework to handle the PTC, thereby\nrelighting the use of sparse supervision in depth completion tasks. The\ndisruption part deliberately discards position correspondences among\nImage/Radar/LiDAR, while the compensation part leverages 3D spatial and 2D\nsemantic information to compensate for the discarded beneficial position\ncorrespondence. Extensive experimental results demonstrate that our framework\n(sparse supervision) outperforms the state-of-the-art (dense supervision) with\n11.6$\\%$ improvement in mean absolute error and $1.6 \\times$ speedup. The code\nis available at ...",
            "author": [
                "Huadong Li",
                "Minhao Jing",
                "Jiajun Liang",
                "Haoqiang Fan",
                "Renhe Ji"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00844v1",
                "http://arxiv.org/pdf/2312.00844v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00362v1",
            "title": "Dancing with Images: Video Distillation via Static-Dynamic\n  Disentanglement",
            "updated": "2023-12-01T05:59:08Z",
            "published": "2023-12-01T05:59:08Z",
            "summary": "Recently, dataset distillation has paved the way towards efficient machine\nlearning, especially for image datasets. However, the distillation for videos,\ncharacterized by an exclusive temporal dimension, remains an underexplored\ndomain. In this work, we provide the first systematic study of video\ndistillation and introduce a taxonomy to categorize temporal compression. Our\ninvestigation reveals that the temporal information is usually not well learned\nduring distillation , and the temporal dimension of synthetic data contributes\nlittle. The observations motivate our unified framework of disentangling the\ndynamic and static information in the videos. It first distills the videos into\nstill images as static memory and then compensates the dynamic and motion\ninformation with a learnable dynamic memory block. Our method achieves\nstate-of-the-art on video datasets at different scales, with notably smaller\nstorage expenditure. Our code will be publicly available.",
            "author": [
                "Ziyu Wang",
                "Yue Xu",
                "Cewu Lu",
                "Yong-Lu Li"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00362v1",
                "http://arxiv.org/pdf/2312.00362v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00360v2",
            "title": "Efficient Multimodal Semantic Segmentation via Dual-Prompt Learning",
            "updated": "2023-12-04T04:38:17Z",
            "published": "2023-12-01T05:50:44Z",
            "summary": "Multimodal (e.g., RGB-Depth/RGB-Thermal) fusion has shown great potential for\nimproving semantic segmentation in complex scenes (e.g., indoor/low-light\nconditions). Existing approaches often fully fine-tune a dual-branch\nencoder-decoder framework with a complicated feature fusion strategy for\nachieving multimodal semantic segmentation, which is training-costly due to the\nmassive parameter updates in feature extraction and fusion. To address this\nissue, we propose a surprisingly simple yet effective dual-prompt learning\nnetwork (dubbed DPLNet) for training-efficient multimodal (e.g., RGB-D/T)\nsemantic segmentation. The core of DPLNet is to directly adapt a frozen\npre-trained RGB model to multimodal semantic segmentation, reducing parameter\nupdates. For this purpose, we present two prompt learning modules, comprising\nmultimodal prompt generator (MPG) and multimodal feature adapter (MFA). MPG\nworks to fuse the features from different modalities in a compact manner and is\ninserted from shadow to deep stages to generate the multi-level multimodal\nprompts that are injected into the frozen backbone, while MPG adapts prompted\nmultimodal features in the frozen backbone for better multimodal semantic\nsegmentation. Since both the MPG and MFA are lightweight, only a few trainable\nparameters (3.88M, 4.4% of the pre-trained backbone parameters) are introduced\nfor multimodal feature fusion and learning. Using a simple decoder (3.27M\nparameters), DPLNet achieves new state-of-the-art performance or is on a par\nwith other complex approaches on four RGB-D/T semantic segmentation datasets\nwhile satisfying parameter efficiency. Moreover, we show that DPLNet is general\nand applicable to other multimodal tasks such as salient object detection and\nvideo semantic segmentation. Without special design, DPLNet outperforms many\ncomplicated models. Our code will be available at\ngithub.com/ShaohuaDong2021/DPLNet.",
            "author": [
                "Shaohua Dong",
                "Yunhe Feng",
                "Qing Yang",
                "Yan Huang",
                "Dongfang Liu",
                "Heng Fan"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00360v2",
                "http://arxiv.org/pdf/2312.00360v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00359v1",
            "title": "Temperature Balancing, Layer-wise Weight Analysis, and Neural Network\n  Training",
            "updated": "2023-12-01T05:38:17Z",
            "published": "2023-12-01T05:38:17Z",
            "summary": "Regularization in modern machine learning is crucial, and it can take various\nforms in algorithmic design: training set, model family, error function,\nregularization terms, and optimizations. In particular, the learning rate,\nwhich can be interpreted as a temperature-like parameter within the statistical\nmechanics of learning, plays a crucial role in neural network training. Indeed,\nmany widely adopted training strategies basically just define the decay of the\nlearning rate over time. This process can be interpreted as decreasing a\ntemperature, using either a global learning rate (for the entire model) or a\nlearning rate that varies for each parameter. This paper proposes TempBalance,\na straightforward yet effective layer-wise learning rate method. TempBalance is\nbased on Heavy-Tailed Self-Regularization (HT-SR) Theory, an approach which\ncharacterizes the implicit self-regularization of different layers in trained\nmodels. We demonstrate the efficacy of using HT-SR-motivated metrics to guide\nthe scheduling and balancing of temperature across all network layers during\nmodel training, resulting in improved performance during testing. We implement\nTempBalance on CIFAR10, CIFAR100, SVHN, and TinyImageNet datasets using\nResNets, VGGs, and WideResNets with various depths and widths. Our results show\nthat TempBalance significantly outperforms ordinary SGD and carefully-tuned\nspectral norm regularization. We also show that TempBalance outperforms a\nnumber of state-of-the-art optimizers and learning rate schedulers.",
            "author": [
                "Yefan Zhou",
                "Tianyu Pang",
                "Keqin Liu",
                "Charles H. Martin",
                "Michael W. Mahoney",
                "Yaoqing Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00359v1",
                "http://arxiv.org/pdf/2312.00359v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00358v1",
            "title": "Impact of Data Augmentation on QCNNs",
            "updated": "2023-12-01T05:28:19Z",
            "published": "2023-12-01T05:28:19Z",
            "summary": "In recent years, Classical Convolutional Neural Networks (CNNs) have been\napplied for image recognition successfully. Quantum Convolutional Neural\nNetworks (QCNNs) are proposed as a novel generalization to CNNs by using\nquantum mechanisms. The quantum mechanisms lead to an efficient training\nprocess in QCNNs by reducing the size of input from $N$ to $log_2N$. This paper\nimplements and compares both CNNs and QCNNs by testing losses and prediction\naccuracy on three commonly used datasets. The datasets include the MNIST\nhand-written digits, Fashion MNIST and cat/dog face images. Additionally, data\naugmentation (DA), a technique commonly used in CNNs to improve the performance\nof classification by generating similar images based on original inputs, is\nalso implemented in QCNNs. Surprisingly, the results showed that data\naugmentation didn't improve QCNNs performance. The reasons and logic behind\nthis result are discussed, hoping to expand our understanding of Quantum\nmachine learning theory.",
            "author": [
                "Leting Zhouli",
                "Peiyong Wang",
                "Udaya Parampalli"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00358v1",
                "http://arxiv.org/pdf/2312.00358v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00357v1",
            "title": "A Generalizable Deep Learning System for Cardiac MRI",
            "updated": "2023-12-01T05:27:29Z",
            "published": "2023-12-01T05:27:29Z",
            "summary": "Cardiac MRI allows for a comprehensive assessment of myocardial structure,\nfunction, and tissue characteristics. Here we describe a foundational vision\nsystem for cardiac MRI, capable of representing the breadth of human\ncardiovascular disease and health. Our deep learning model is trained via\nself-supervised contrastive learning, by which visual concepts in cine-sequence\ncardiac MRI scans are learned from the raw text of the accompanying radiology\nreports. We train and evaluate our model on data from four large academic\nclinical institutions in the United States. We additionally showcase the\nperformance of our models on the UK BioBank, and two additional publicly\navailable external datasets. We explore emergent zero-shot capabilities of our\nsystem, and demonstrate remarkable performance across a range of tasks;\nincluding the problem of left ventricular ejection fraction regression, and the\ndiagnosis of 35 different conditions such as cardiac amyloidosis and\nhypertrophic cardiomyopathy. We show that our deep learning system is capable\nof not only understanding the staggering complexity of human cardiovascular\ndisease, but can be directed towards clinical problems of interest yielding\nimpressive, clinical grade diagnostic accuracy with a fraction of the training\ndata typically required for such tasks.",
            "author": [
                "Rohan Shad",
                "Cyril Zakka",
                "Dhamanpreet Kaur",
                "Robyn Fong",
                "Ross Warren Filice",
                "John Mongan",
                "Kimberly Kalianos",
                "Nishith Khandwala",
                "David Eng",
                "Matthew Leipzig",
                "Walter Witschey",
                "Alejandro de Feria",
                "Victor Ferrari",
                "Euan Ashley",
                "Michael A. Acker",
                "Curtis Langlotz",
                "William Hiesinger"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00357v1",
                "http://arxiv.org/pdf/2312.00357v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG",
                "I.2.10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00356v1",
            "title": "Transfer learning for predicting source terms of principal component\n  transport in chemically reactive flow",
            "updated": "2023-12-01T05:18:35Z",
            "published": "2023-12-01T05:18:35Z",
            "summary": "The objective of this study is to evaluate whether the number of requisite\ntraining samples can be reduced with the use of various transfer learning\nmodels for predicting, for example, the chemical source terms of the\ndata-driven reduced-order model that represents the homogeneous ignition\nprocess of a hydrogen/air mixture. Principal component analysis is applied to\nreduce the dimensionality of the hydrogen/air mixture in composition space.\nArtificial neural networks (ANNs) are used to tabulate the reaction rates of\nprincipal components, and subsequently, a system of ordinary differential\nequations is solved. As the number of training samples decreases at the target\ntask (i.e.,for T0 > 1000 K and various phi), the reduced-order model fails to\npredict the ignition evolution of a hydrogen/air mixture. Three transfer\nlearning strategies are then applied to the training of the ANN model with a\nsparse dataset. The performance of the reduced-order model with a sparse\ndataset is found to be remarkably enhanced if the training of the ANN model is\nrestricted by a regularization term that controls the degree of knowledge\ntransfer from source to target tasks. To this end, a novel transfer learning\nmethod is introduced, parameter control via partial initialization and\nregularization (PaPIR), whereby the amount of knowledge transferred is\nsystemically adjusted for the initialization and regularization of the ANN\nmodel in the target task. It is found that an additional performance gain can\nbe achieved by changing the initialization scheme of the ANN model in the\ntarget task when the task similarity between source and target tasks is\nrelatively low.",
            "author": [
                "Ki Sung Jung",
                "Tarek Echekki",
                "Jacqueline H. Chen",
                "Mohammad Khalil"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00356v1",
                "http://arxiv.org/pdf/2312.00356v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00353v1",
            "title": "On Exploring the Reasoning Capability of Large Language Models with\n  Knowledge Graphs",
            "updated": "2023-12-01T05:08:47Z",
            "published": "2023-12-01T05:08:47Z",
            "summary": "This paper examines the capacity of LLMs to reason with knowledge graphs\nusing their internal knowledge graph, i.e., the knowledge graph they learned\nduring pre-training. Two research questions are formulated to investigate the\naccuracy of LLMs in recalling information from pre-training knowledge graphs\nand their ability to infer knowledge graph relations from context. To address\nthese questions, we employ LLMs to perform four distinct knowledge graph\nreasoning tasks. Furthermore, we identify two types of hallucinations that may\noccur during knowledge reasoning with LLMs: content and ontology hallucination.\nOur experimental results demonstrate that LLMs can successfully tackle both\nsimple and complex knowledge graph reasoning tasks from their own memory, as\nwell as infer from input context.",
            "author": [
                "Pei-Chi Lo",
                "Yi-Hang Tsai",
                "Ee-Peng Lim",
                "San-Yih Hwang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00353v1",
                "http://arxiv.org/pdf/2312.00353v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00352v1",
            "title": "Quantum Kernel t-Distributed Stochastic Neighbor Embedding",
            "updated": "2023-12-01T05:00:02Z",
            "published": "2023-12-01T05:00:02Z",
            "summary": "Data visualization is important in understanding the characteristics of data\nthat are difficult to see directly. It is used to visualize loss landscapes and\noptimization trajectories to analyze optimization performance. Popular\noptimization analysis is performed by visualizing a loss landscape around the\nreached local or global minimum using principal component analysis. However,\nthis visualization depends on the variational parameters of a quantum circuit\nrather than quantum states, which makes it difficult to understand the\nmechanism of optimization process through the property of quantum states. Here,\nwe propose a quantum data visualization method using quantum kernels, which\nenables us to offer fast and highly accurate visualization of quantum states.\nIn our numerical experiments, we visualize hand-written digits dataset and\napply $k$-nearest neighbor algorithm to the low-dimensional data to\nquantitatively evaluate our proposed method compared with a classical kernel\nmethod. As a result, our proposed method achieves comparable accuracy to the\nstate-of-the-art classical kernel method, meaning that the proposed\nvisualization method based on quantum machine learning does not degrade the\nseparability of the input higher dimensional data. Furthermore, we visualize\nthe optimization trajectories of finding the ground states of transverse field\nIsing model and successfully find the trajectory characteristics. Since quantum\nstates are higher dimensional objects that can only be seen via observables,\nour visualization method, which inherits the similarity of quantum data, would\nbe useful in understanding the behavior of quantum circuits and algorithms.",
            "author": [
                "Yoshiaki Kawase",
                "Kosuke Mitarai",
                "Keisuke Fujii"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00352v1",
                "http://arxiv.org/pdf/2312.00352v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00351v2",
            "title": "Manipulating the Label Space for In-Context Classification",
            "updated": "2023-12-06T04:19:04Z",
            "published": "2023-12-01T04:57:20Z",
            "summary": "After pre-training by generating the next word conditional on previous words,\nthe Language Model (LM) acquires the ability of In-Context Learning (ICL) that\ncan learn a new task conditional on the context of the given in-context\nexamples (ICEs). Similarly, visually-conditioned Language Modelling is also\nused to train Vision-Language Models (VLMs) with ICL ability. However, such\nVLMs typically exhibit weaker classification abilities compared to contrastive\nlearning-based models like CLIP, since the Language Modelling objective does\nnot directly contrast whether an object is paired with a text. To improve the\nICL of classification, using more ICEs to provide more knowledge is a\nstraightforward way. However, this may largely increase the selection time, and\nmore importantly, the inclusion of additional in-context images tends to extend\nthe length of the in-context sequence beyond the processing capacity of a VLM.\nTo alleviate these limitations, we propose to manipulate the label space of\neach ICE to increase its knowledge density, allowing for fewer ICEs to convey\nas much information as a larger set would. Specifically, we propose two\nstrategies which are Label Distribution Enhancement and Visual Descriptions\nEnhancement to improve In-context classification performance on diverse\ndatasets, including the classic ImageNet and more fine-grained datasets like\nCUB-200. Specifically, using our approach on ImageNet, we increase accuracy\nfrom 74.70\\% in a 4-shot setting to 76.21\\% with just 2 shots. surpassing CLIP\nby 0.67\\%. On CUB-200, our method raises 1-shot accuracy from 48.86\\% to\n69.05\\%, 12.15\\% higher than CLIP. The code is given in\nhttps://anonymous.4open.science/r/MLS_ICC.",
            "author": [
                "Haokun Chen",
                "Xu Yang",
                "Yuhang Huang",
                "Zihan Wu",
                "Jing Wang",
                "Xin Geng"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00351v2",
                "http://arxiv.org/pdf/2312.00351v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00349v1",
            "title": "The Case for Scalable, Data-Driven Theory: A Paradigm for Scientific\n  Progress in NLP",
            "updated": "2023-12-01T04:55:29Z",
            "published": "2023-12-01T04:55:29Z",
            "summary": "I propose a paradigm for scientific progress in NLP centered around\ndeveloping scalable, data-driven theories of linguistic structure. The idea is\nto collect data in tightly scoped, carefully defined ways which allow for\nexhaustive annotation of behavioral phenomena of interest, and then use machine\nlearning to construct explanatory theories of these phenomena which can form\nbuilding blocks for intelligible AI systems. After laying some conceptual\ngroundwork, I describe several investigations into data-driven theories of\nshallow semantic structure using Question-Answer driven Semantic Role Labeling\n(QA-SRL), a schema for annotating verbal predicate-argument relations using\nhighly constrained question-answer pairs. While this only scratches the surface\nof the complex language behaviors of interest in AI, I outline principles for\ndata collection and theoretical modeling which can inform future scientific\nprogress. This note summarizes and draws heavily on my PhD thesis.",
            "author": [
                "Julian Michael"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00349v1",
                "http://arxiv.org/pdf/2312.00349v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00348v1",
            "title": "Student Activity Recognition in Classroom Environments using Transfer\n  Learning",
            "updated": "2023-12-01T04:51:57Z",
            "published": "2023-12-01T04:51:57Z",
            "summary": "The recent advances in artificial intelligence and deep learning facilitate\nautomation in various applications including home automation, smart\nsurveillance systems, and healthcare among others. Human Activity Recognition\nis one of its emerging applications, which can be implemented in a classroom\nenvironment to enhance safety, efficiency, and overall educational quality.\nThis paper proposes a system for detecting and recognizing the activities of\nstudents in a classroom environment. The dataset has been structured and\nrecorded by the authors since a standard dataset for this task was not\navailable at the time of this study. Transfer learning, a widely adopted method\nwithin the field of deep learning, has proven to be helpful in complex tasks\nlike image and video processing. Pretrained models including VGG-16, ResNet-50,\nInceptionV3, and Xception are used for feature extraction and classification\ntasks. Xception achieved an accuracy of 93%, on the novel classroom dataset,\noutperforming the other three models in consideration. The system proposed in\nthis study aims to introduce a safer and more productive learning environment\nfor students and educators.",
            "author": [
                "Anagha Deshpande",
                "Vedant Deshpande"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00348v1",
                "http://arxiv.org/pdf/2312.00348v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00344v1",
            "title": "TRC: Trust Region Conditional Value at Risk for Safe Reinforcement\n  Learning",
            "updated": "2023-12-01T04:40:47Z",
            "published": "2023-12-01T04:40:47Z",
            "summary": "As safety is of paramount importance in robotics, reinforcement learning that\nreflects safety, called safe RL, has been studied extensively. In safe RL, we\naim to find a policy which maximizes the desired return while satisfying the\ndefined safety constraints. There are various types of constraints, among which\nconstraints on conditional value at risk (CVaR) effectively lower the\nprobability of failures caused by high costs since CVaR is a conditional\nexpectation obtained above a certain percentile. In this paper, we propose a\ntrust region-based safe RL method with CVaR constraints, called TRC. We first\nderive the upper bound on CVaR and then approximate the upper bound in a\ndifferentiable form in a trust region. Using this approximation, a subproblem\nto get policy gradients is formulated, and policies are trained by iteratively\nsolving the subproblem. TRC is evaluated through safe navigation tasks in\nsimulations with various robots and a sim-to-real environment with a Jackal\nrobot from Clearpath. Compared to other safe RL methods, the performance is\nimproved by 1.93 times while the constraints are satisfied in all experiments.",
            "author": [
                "Dohyeong Kim",
                "Songhwai Oh"
            ],
            "link": [
                "http://dx.doi.org/10.1109/LRA.2022.3141829",
                "http://arxiv.org/abs/2312.00344v1",
                "http://arxiv.org/pdf/2312.00344v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00342v1",
            "title": "Efficient Off-Policy Safe Reinforcement Learning Using Trust Region\n  Conditional Value at Risk",
            "updated": "2023-12-01T04:29:19Z",
            "published": "2023-12-01T04:29:19Z",
            "summary": "This paper aims to solve a safe reinforcement learning (RL) problem with risk\nmeasure-based constraints. As risk measures, such as conditional value at risk\n(CVaR), focus on the tail distribution of cost signals, constraining risk\nmeasures can effectively prevent a failure in the worst case. An on-policy safe\nRL method, called TRC, deals with a CVaR-constrained RL problem using a trust\nregion method and can generate policies with almost zero constraint violations\nwith high returns. However, to achieve outstanding performance in complex\nenvironments and satisfy safety constraints quickly, RL methods are required to\nbe sample efficient. To this end, we propose an off-policy safe RL method with\nCVaR constraints, called off-policy TRC. If off-policy data from replay buffers\nis directly used to train TRC, the estimation error caused by the\ndistributional shift results in performance degradation. To resolve this issue,\nwe propose novel surrogate functions, in which the effect of the distributional\nshift can be reduced, and introduce an adaptive trust-region constraint to\nensure a policy not to deviate far from replay buffers. The proposed method has\nbeen evaluated in simulation and real-world environments and satisfied safety\nconstraints within a few steps while achieving high returns even in complex\nrobotic tasks.",
            "author": [
                "Dohyeong Kim",
                "Songhwai Oh"
            ],
            "link": [
                "http://dx.doi.org/10.1109/LRA.2022.3184793",
                "http://arxiv.org/abs/2312.00342v1",
                "http://arxiv.org/pdf/2312.00342v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00336v1",
            "title": "Hypergraph Node Representation Learning with One-Stage Message Passing",
            "updated": "2023-12-01T04:10:00Z",
            "published": "2023-12-01T04:10:00Z",
            "summary": "Hypergraphs as an expressive and general structure have attracted\nconsiderable attention from various research domains. Most existing hypergraph\nnode representation learning techniques are based on graph neural networks, and\nthus adopt the two-stage message passing paradigm (i.e. node -> hyperedge ->\nnode). This paradigm only focuses on local information propagation and does not\neffectively take into account global information, resulting in less optimal\nrepresentations. Our theoretical analysis of representative two-stage message\npassing methods shows that, mathematically, they model different ways of local\nmessage passing through hyperedges, and can be unified into one-stage message\npassing (i.e. node -> node). However, they still only model local information.\nMotivated by this theoretical analysis, we propose a novel one-stage message\npassing paradigm to model both global and local information propagation for\nhypergraphs. We integrate this paradigm into HGraphormer, a Transformer-based\nframework for hypergraph node representation learning. HGraphormer injects the\nhypergraph structure information (local information) into Transformers (global\ninformation) by combining the attention matrix and hypergraph Laplacian.\nExtensive experiments demonstrate that HGraphormer outperforms recent\nhypergraph learning methods on five representative benchmark datasets on the\nsemi-supervised hypernode classification task, setting new state-of-the-art\nperformance, with accuracy improvements between 2.52% and 6.70%. Our code and\ndatasets are available.",
            "author": [
                "Shilin Qu",
                "Weiqing Wang",
                "Yuan-Fang Li",
                "Xin Zhou",
                "Fajie Yuan"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00336v1",
                "http://arxiv.org/pdf/2312.00336v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00335v1",
            "title": "Learning Anatomically Consistent Embedding for Chest Radiography",
            "updated": "2023-12-01T04:07:12Z",
            "published": "2023-12-01T04:07:12Z",
            "summary": "Self-supervised learning (SSL) approaches have recently shown substantial\nsuccess in learning visual representations from unannotated images. Compared\nwith photographic images, medical images acquired with the same imaging\nprotocol exhibit high consistency in anatomy. To exploit this anatomical\nconsistency, this paper introduces a novel SSL approach, called PEAC (patch\nembedding of anatomical consistency), for medical image analysis. Specifically,\nin this paper, we propose to learn global and local consistencies via stable\ngrid-based matching, transfer pre-trained PEAC models to diverse downstream\ntasks, and extensively demonstrate that (1) PEAC achieves significantly better\nperformance than the existing state-of-the-art fully/self-supervised methods,\nand (2) PEAC captures the anatomical structure consistency across views of the\nsame patient and across patients of different genders, weights, and healthy\nstatuses, which enhances the interpretability of our method for medical image\nanalysis.",
            "author": [
                "Ziyu Zhou",
                "Haozhe Luo",
                "Jiaxuan Pang",
                "Xiaowei Ding",
                "Michael Gotway",
                "Jianming Liang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00335v1",
                "http://arxiv.org/pdf/2312.00335v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00334v1",
            "title": "UAV-Aided Lifelong Learning for AoI and Energy Optimization in\n  Non-Stationary IoT Networks",
            "updated": "2023-12-01T04:06:45Z",
            "published": "2023-12-01T04:06:45Z",
            "summary": "In this paper, a novel joint energy and age of information (AoI) optimization\nframework for IoT devices in a non-stationary environment is presented. In\nparticular, IoT devices that are distributed in the real-world are required to\nefficiently utilize their computing resources so as to balance the freshness of\ntheir data and their energy consumption. To optimize the performance of IoT\ndevices in such a dynamic setting, a novel lifelong reinforcement learning (RL)\nsolution that enables IoT devices to continuously adapt their policies to each\nnewly encountered environment is proposed. Given that IoT devices have limited\nenergy and computing resources, an unmanned aerial vehicle (UAV) is leveraged\nto visit the IoT devices and update the policy of each device sequentially. As\nsuch, the UAV is exploited as a mobile learning agent that can learn a shared\nknowledge base with a feature base in its training phase, and feature sets of a\nzero-shot learning method in its testing phase, to generalize between the\nenvironments. To optimize the trajectory and flying velocity of the UAV, an\nactor-critic network is leveraged so as to minimize the UAV energy consumption.\nSimulation results show that the proposed lifelong RL solution can outperform\nthe state-of-art benchmarks by enhancing the balanced cost of IoT devices by\n$8.3\\%$ when incorporating warm-start policies for unseen environments. In\naddition, our solution achieves up to $49.38\\%$ reduction in terms of energy\nconsumption by the UAV in comparison to the random flying strategy.",
            "author": [
                "Zhenzhen Gong",
                "Omar Hashash",
                "Yingze Wang",
                "Qimei Cui",
                "Wei Ni",
                "Walid Saad",
                "Kei Sakaguchi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00334v1",
                "http://arxiv.org/pdf/2312.00334v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00333v1",
            "title": "Green Edge AI: A Contemporary Survey",
            "updated": "2023-12-01T04:04:37Z",
            "published": "2023-12-01T04:04:37Z",
            "summary": "Artificial intelligence (AI) technologies have emerged as pivotal enablers\nacross a multitude of industries, including consumer electronics, healthcare,\nand manufacturing, largely due to their resurgence over the past decade. The\ntransformative power of AI is primarily derived from the utilization of deep\nneural networks (DNNs), which require extensive data for training and\nsubstantial computational resources for processing. Consequently, DNN models\nare typically trained and deployed on resource-rich cloud servers. However, due\nto potential latency issues associated with cloud communications, deep learning\n(DL) workflows are increasingly being transitioned to wireless edge networks\nnear end-user devices (EUDs). This shift is designed to support\nlatency-sensitive applications and has given rise to a new paradigm of edge AI,\nwhich will play a critical role in upcoming 6G networks to support ubiquitous\nAI applications. Despite its potential, edge AI faces substantial challenges,\nmostly due to the dichotomy between the resource limitations of wireless edge\nnetworks and the resource-intensive nature of DL. Specifically, the acquisition\nof large-scale data, as well as the training and inference processes of DNNs,\ncan rapidly deplete the battery energy of EUDs. This necessitates an\nenergy-conscious approach to edge AI to ensure both optimal and sustainable\nperformance. In this paper, we present a contemporary survey on green edge AI.\nWe commence by analyzing the principal energy consumption components of edge AI\nsystems to identify the fundamental design principles of green edge AI. Guided\nby these principles, we then explore energy-efficient design methodologies for\nthe three critical tasks in edge AI systems, including training data\nacquisition, edge training, and edge inference. Finally, we underscore\npotential future research directions to further enhance the energy efficiency\nof edge AI.",
            "author": [
                "Yuyi Mao",
                "Xianghao Yu",
                "Kaibin Huang",
                "Ying-Jun Angela Zhang",
                "Jun Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00333v1",
                "http://arxiv.org/pdf/2312.00333v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.IT",
                "cs.NI",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00843v1",
            "title": "Exploring the Robustness of Decentralized Training for Large Language\n  Models",
            "updated": "2023-12-01T04:04:03Z",
            "published": "2023-12-01T04:04:03Z",
            "summary": "Decentralized training of large language models has emerged as an effective\nway to democratize this technology. However, the potential threats associated\nwith this approach have not been carefully discussed, which would hinder the\ndevelopment of decentralized training infrastructures. This paper aims to\ninitiate discussion towards this end by exploring the robustness of\ndecentralized training from three main perspectives. First, we demonstrate the\nvulnerabilities inherent in decentralized training frameworks in terms of\nhardware, data, and models. Second, we highlight the fundamental difference\nbetween decentralized foundation model training and vanilla federated learning,\nwhere the security techniques employed in federated learning cannot be applied\ndirectly. Third, we discuss the essential components required for a robust and\nefficient decentralized training framework and present a case study by modeling\na concrete threat model. Our objective in this vision paper is to emphasize the\nimportance of addressing security concerns in the context of decentralized\ntraining for large language models.",
            "author": [
                "Lin Lu",
                "Chenxi Dai",
                "Wangcheng Tao",
                "Binhang Yuan",
                "Yanan Sun",
                "Pan Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00843v1",
                "http://arxiv.org/pdf/2312.00843v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00842v1",
            "title": "ESM-NBR: fast and accurate nucleic acid-binding residue prediction via\n  protein language model feature representation and multi-task learning",
            "updated": "2023-12-01T04:00:20Z",
            "published": "2023-12-01T04:00:20Z",
            "summary": "Protein-nucleic acid interactions play a very important role in a variety of\nbiological activities. Accurate identification of nucleic acid-binding residues\nis a critical step in understanding the interaction mechanisms. Although many\ncomputationally based methods have been developed to predict nucleic\nacid-binding residues, challenges remain. In this study, a fast and accurate\nsequence-based method, called ESM-NBR, is proposed. In ESM-NBR, we first use\nthe large protein language model ESM2 to extract discriminative biological\nproperties feature representation from protein primary sequences; then, a\nmulti-task deep learning model composed of stacked bidirectional long\nshort-term memory (BiLSTM) and multi-layer perceptron (MLP) networks is\nemployed to explore common and private information of DNA- and RNA-binding\nresidues with ESM2 feature as input. Experimental results on benchmark data\nsets demonstrate that the prediction performance of ESM2 feature representation\ncomprehensively outperforms evolutionary information-based hidden Markov model\n(HMM) features. Meanwhile, the ESM-NBR obtains the MCC values for DNA-binding\nresidues prediction of 0.427 and 0.391 on two independent test sets, which are\n18.61 and 10.45% higher than those of the second-best methods, respectively.\nMoreover, by completely discarding the time-cost multiple sequence alignment\nprocess, the prediction speed of ESM-NBR far exceeds that of existing methods\n(5.52s for a protein sequence of length 500, which is about 16 times faster\nthan the second-fastest method). A user-friendly standalone package and the\ndata of ESM-NBR are freely available for academic use at:\nhttps://github.com/wwzll123/ESM-NBR.",
            "author": [
                "Wenwu Zeng",
                "Dafeng Lv",
                "Wenjuan Liu",
                "Shaoliang Peng"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00842v1",
                "http://arxiv.org/pdf/2312.00842v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00330v1",
            "title": "StyleCrafter: Enhancing Stylized Text-to-Video Generation with Style\n  Adapter",
            "updated": "2023-12-01T03:53:21Z",
            "published": "2023-12-01T03:53:21Z",
            "summary": "Text-to-video (T2V) models have shown remarkable capabilities in generating\ndiverse videos. However, they struggle to produce user-desired stylized videos\ndue to (i) text's inherent clumsiness in expressing specific styles and (ii)\nthe generally degraded style fidelity. To address these challenges, we\nintroduce StyleCrafter, a generic method that enhances pre-trained T2V models\nwith a style control adapter, enabling video generation in any style by\nproviding a reference image. Considering the scarcity of stylized video\ndatasets, we propose to first train a style control adapter using style-rich\nimage datasets, then transfer the learned stylization ability to video\ngeneration through a tailor-made finetuning paradigm. To promote content-style\ndisentanglement, we remove style descriptions from the text prompt and extract\nstyle information solely from the reference image using a decoupling learning\nstrategy. Additionally, we design a scale-adaptive fusion module to balance the\ninfluences of text-based content features and image-based style features, which\nhelps generalization across various text and style combinations. StyleCrafter\nefficiently generates high-quality stylized videos that align with the content\nof the texts and resemble the style of the reference images. Experiments\ndemonstrate that our approach is more flexible and efficient than existing\ncompetitors.",
            "author": [
                "Gongye Liu",
                "Menghan Xia",
                "Yong Zhang",
                "Haoxin Chen",
                "Jinbo Xing",
                "Xintao Wang",
                "Yujiu Yang",
                "Ying Shan"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00330v1",
                "http://arxiv.org/pdf/2312.00330v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00326v1",
            "title": "Agent-OM: Leveraging Large Language Models for Ontology Matching",
            "updated": "2023-12-01T03:44:54Z",
            "published": "2023-12-01T03:44:54Z",
            "summary": "Ontology matching (OM) enables semantic interoperability between different\nontologies and resolves their conceptual heterogeneity by aligning related\nentities. OM systems currently have two prevailing design paradigms:\nconventional knowledge-based expert systems and newer machine learning-based\npredictive systems. While large language models (LLMs) and LLM-based agents\nhave become revolutionary in data engineering and have been applied creatively\nin various domains, their potential for OM remains underexplored. This study\nintroduces a novel agent-powered LLM-based design paradigm for OM systems. With\nthoughtful consideration of several specific challenges to leverage LLMs for\nOM, we propose a generic framework, namely Agent-OM, consisting of two Siamese\nagents for retrieval and matching, with a set of simple prompt-based OM tools.\nOur framework is implemented in a proof-of-concept system. Evaluations of three\nOntology Alignment Evaluation Initiative (OAEI) tracks over state-of-the-art OM\nsystems show that our system can achieve very close results to the best\nlong-standing performance on simple OM tasks and significantly improve the\nperformance on complex and few-shot OM tasks.",
            "author": [
                "Zhangcheng Qiang",
                "Weiqing Wang",
                "Kerry Taylor"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00326v1",
                "http://arxiv.org/pdf/2312.00326v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00324v1",
            "title": "Machine Learning for Actionable Warning Identification: A Comprehensive\n  Survey",
            "updated": "2023-12-01T03:38:21Z",
            "published": "2023-12-01T03:38:21Z",
            "summary": "Actionable Warning Identification (AWI) plays a crucial role in improving the\nusability of static code analyzers. With recent advances in Machine Learning\n(ML), various approaches have been proposed to incorporate ML techniques into\nAWI. These ML-based AWI approaches, benefiting from ML's strong ability to\nlearn subtle and previously unseen patterns from historical data, have\ndemonstrated superior performance. However, a comprehensive overview of these\napproaches is missing, which could hinder researchers/practitioners from\nunderstanding the current process and discovering potential for future\nimprovement in the ML-based AWI community. In this paper, we systematically\nreview the state-of-the-art ML-based AWI approaches. First, we employ a\nmeticulous survey methodology and gather 50 primary studies from 2000/01/01 to\n2023/09/01. Then, we outline the typical ML-based AWI workflow, including\nwarning dataset preparation, preprocessing, AWI model construction, and\nevaluation stages. In such a workflow, we categorize ML-based AWI approaches\nbased on the warning output format. Besides, we analyze the techniques used in\neach stage, along with their strengths, weaknesses, and distribution. Finally,\nwe provide practical research directions for future ML-based AWI approaches,\nfocusing on aspects like data improvement (e.g., enhancing the warning labeling\nstrategy) and model exploration (e.g., exploring large language models for\nAWI).",
            "author": [
                "Xiuting Ge",
                "Chunrong Fang",
                "Xuanye Li",
                "Weisong Sun",
                "Daoyuan Wu",
                "Juan Zhai",
                "Shangwei Lin",
                "Zhihong Zhao",
                "Yang Liu",
                "Zhenyu Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00324v1",
                "http://arxiv.org/pdf/2312.00324v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00313v1",
            "title": "Improving Normalization with the James-Stein Estimator",
            "updated": "2023-12-01T03:12:04Z",
            "published": "2023-12-01T03:12:04Z",
            "summary": "Stein's paradox holds considerable sway in high-dimensional statistics,\nhighlighting that the sample mean, traditionally considered the de facto\nestimator, might not be the most efficacious in higher dimensions. To address\nthis, the James-Stein estimator proposes an enhancement by steering the sample\nmeans toward a more centralized mean vector. In this paper, first, we establish\nthat normalization layers in deep learning use inadmissible estimators for mean\nand variance. Next, we introduce a novel method to employ the James-Stein\nestimator to improve the estimation of mean and variance within normalization\nlayers. We evaluate our method on different computer vision tasks: image\nclassification, semantic segmentation, and 3D object classification. Through\nthese evaluations, it is evident that our improved normalization layers\nconsistently yield superior accuracy across all tasks without extra\ncomputational burden. Moreover, recognizing that a plethora of shrinkage\nestimators surpass the traditional estimator in performance, we study two other\nprominent shrinkage estimators: Ridge and LASSO. Additionally, we provide\nvisual representations to intuitively demonstrate the impact of shrinkage on\nthe estimated layer statistics. Finally, we study the effect of regularization\nand batch size on our modified batch normalization. The studies show that our\nmethod is less sensitive to batch size and regularization, improving accuracy\nunder various setups.",
            "author": [
                "Seyedalireza Khoshsirat",
                "Chandra Kambhamettu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00313v1",
                "http://arxiv.org/pdf/2312.00313v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00312v1",
            "title": "Segment Anything Model-guided Collaborative Learning Network for\n  Scribble-supervised Polyp Segmentation",
            "updated": "2023-12-01T03:07:13Z",
            "published": "2023-12-01T03:07:13Z",
            "summary": "Polyp segmentation plays a vital role in accurately locating polyps at an\nearly stage, which holds significant clinical importance for the prevention of\ncolorectal cancer. Various polyp segmentation methods have been developed using\nfully-supervised deep learning techniques. However, pixel-wise annotation for\npolyp images by physicians during the diagnosis is both time-consuming and\nexpensive. Moreover, visual foundation models such as the Segment Anything\nModel (SAM) have shown remarkable performance. Nevertheless, directly applying\nSAM to medical segmentation may not produce satisfactory results due to the\ninherent absence of medical knowledge. In this paper, we propose a novel\nSAM-guided Collaborative Learning Network (SAM-CLNet) for scribble-supervised\npolyp segmentation, enabling a collaborative learning process between our\nsegmentation network and SAM to boost the model performance. Specifically, we\nfirst propose a Cross-level Enhancement and Aggregation Network (CEA-Net) for\nweakly-supervised polyp segmentation. Within CEA-Net, we propose a Cross-level\nEnhancement Module (CEM) that integrates the adjacent features to enhance the\nrepresentation capabilities of different resolution features. Additionally, a\nFeature Aggregation Module (FAM) is employed to capture richer features across\nmultiple levels. Moreover, we present a box-augmentation strategy that combines\nthe segmentation maps generated by CEA-Net with scribble annotations to create\nmore precise prompts. These prompts are then fed into SAM, generating\nsegmentation SAM-guided masks, which can provide additional supervision to\ntrain CEA-Net effectively. Furthermore, we present an Image-level Filtering\nMechanism to filter out unreliable SAM-guided masks. Extensive experimental\nresults show that our SAM-CLNet outperforms state-of-the-art weakly-supervised\nsegmentation methods.",
            "author": [
                "Yiming Zhao",
                "Tao Zhou",
                "Yunqi Gu",
                "Yi Zhou",
                "Yizhe Zhang",
                "Ye Wu",
                "Huazhu Fu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00312v1",
                "http://arxiv.org/pdf/2312.00312v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00305v1",
            "title": "Multiple Testing of Linear Forms for Noisy Matrix Completion",
            "updated": "2023-12-01T02:53:20Z",
            "published": "2023-12-01T02:53:20Z",
            "summary": "Many important tasks of large-scale recommender systems can be naturally cast\nas testing multiple linear forms for noisy matrix completion. These problems,\nhowever, present unique challenges because of the subtle bias-and-variance\ntradeoff of and an intricate dependence among the estimated entries induced by\nthe low-rank structure. In this paper, we develop a general approach to\novercome these difficulties by introducing new statistics for individual tests\nwith sharp asymptotics both marginally and jointly, and utilizing them to\ncontrol the false discovery rate (FDR) via a data splitting and symmetric\naggregation scheme. We show that valid FDR control can be achieved with\nguaranteed power under nearly optimal sample size requirements using the\nproposed methodology. Extensive numerical simulations and real data examples\nare also presented to further illustrate its practical merits.",
            "author": [
                "Wanteng Ma",
                "Lilun Du",
                "Dong Xia",
                "Ming Yuan"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00305v1",
                "http://arxiv.org/pdf/2312.00305v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "cs.LG",
                "math.ST",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00304v1",
            "title": "Developmental Pretraining (DPT) for Image Classification Networks",
            "updated": "2023-12-01T02:47:00Z",
            "published": "2023-12-01T02:47:00Z",
            "summary": "In the backdrop of increasing data requirements of Deep Neural Networks for\nobject recognition that is growing more untenable by the day, we present\nDevelopmental PreTraining (DPT) as a possible solution. DPT is designed as a\ncurriculum-based pre-training approach designed to rival traditional\npre-training techniques that are data-hungry. These training approaches also\nintroduce unnecessary features that could be misleading when the network is\nemployed in a downstream classification task where the data is sufficiently\ndifferent from the pre-training data and is scarce. We design the curriculum\nfor DPT by drawing inspiration from human infant visual development. DPT\nemploys a phased approach where carefully-selected primitive and universal\nfeatures like edges and shapes are taught to the network participating in our\npre-training regime. A model that underwent the DPT regime is tested against\nmodels with randomised weights to evaluate the viability of DPT.",
            "author": [
                "Niranjan Rajesh",
                "Debayan Gupta"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00304v1",
                "http://arxiv.org/pdf/2312.00304v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00840v1",
            "title": "Towards Redundancy-Free Sub-networks in Continual Learning",
            "updated": "2023-12-01T02:29:52Z",
            "published": "2023-12-01T02:29:52Z",
            "summary": "Catastrophic Forgetting (CF) is a prominent issue in continual learning.\nParameter isolation addresses this challenge by masking a sub-network for each\ntask to mitigate interference with old tasks. However, these sub-networks are\nconstructed relying on weight magnitude, which does not necessarily correspond\nto the importance of weights, resulting in maintaining unimportant weights and\nconstructing redundant sub-networks. To overcome this limitation, inspired by\ninformation bottleneck, which removes redundancy between adjacent network\nlayers, we propose \\textbf{\\underline{I}nformation \\underline{B}ottleneck\n\\underline{M}asked sub-network (IBM)} to eliminate redundancy within\nsub-networks. Specifically, IBM accumulates valuable information into essential\nweights to construct redundancy-free sub-networks, not only effectively\nmitigating CF by freezing the sub-networks but also facilitating new tasks\ntraining through the transfer of valuable knowledge. Additionally, IBM\ndecomposes hidden representations to automate the construction process and make\nit flexible. Extensive experiments demonstrate that IBM consistently\noutperforms state-of-the-art methods. Notably, IBM surpasses the\nstate-of-the-art parameter isolation method with a 70\\% reduction in the number\nof parameters within sub-networks and an 80\\% decrease in training time.",
            "author": [
                "Cheng Chen",
                "Jingkuan Song",
                "LianLi Gao",
                "Heng Tao Shen"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00840v1",
                "http://arxiv.org/pdf/2312.00840v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00296v1",
            "title": "Towards Aligned Canonical Correlation Analysis: Preliminary Formulation\n  and Proof-of-Concept Results",
            "updated": "2023-12-01T02:24:07Z",
            "published": "2023-12-01T02:24:07Z",
            "summary": "Canonical Correlation Analysis (CCA) has been widely applied to jointly embed\nmultiple views of data in a maximally correlated latent space. However, the\nalignment between various data perspectives, which is required by traditional\napproaches, is unclear in many practical cases. In this work we propose a new\nframework Aligned Canonical Correlation Analysis (ACCA), to address this\nchallenge by iteratively solving the alignment and multi-view embedding.",
            "author": [
                "Biqian Cheng",
                "Evangelos E. Papalexakis",
                "Jia Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00296v1",
                "http://arxiv.org/pdf/2312.00296v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00292v1",
            "title": "SEPSIS: I Can Catch Your Lies -- A New Paradigm for Deception Detection",
            "updated": "2023-12-01T02:13:25Z",
            "published": "2023-12-01T02:13:25Z",
            "summary": "Deception is the intentional practice of twisting information. It is a\nnuanced societal practice deeply intertwined with human societal evolution,\ncharacterized by a multitude of facets. This research explores the problem of\ndeception through the lens of psychology, employing a framework that\ncategorizes deception into three forms: lies of omission, lies of commission,\nand lies of influence. The primary focus of this study is specifically on\ninvestigating only lies of omission. We propose a novel framework for deception\ndetection leveraging NLP techniques. We curated an annotated dataset of 876,784\nsamples by amalgamating a popular large-scale fake news dataset and scraped\nnews headlines from the Twitter handle of Times of India, a well-known Indian\nnews media house. Each sample has been labeled with four layers, namely: (i)\nthe type of omission (speculation, bias, distortion, sounds factual, and\nopinion), (ii) colors of lies(black, white, etc), and (iii) the intention of\nsuch lies (to influence, etc) (iv) topic of lies (political, educational,\nreligious, etc). We present a novel multi-task learning pipeline that leverages\nthe dataless merging of fine-tuned language models to address the deception\ndetection task mentioned earlier. Our proposed model achieved an F1 score of\n0.87, demonstrating strong performance across all layers including the type,\ncolor, intent, and topic aspects of deceptive content. Finally, our research\nexplores the relationship between lies of omission and propaganda techniques.\nTo accomplish this, we conducted an in-depth analysis, uncovering compelling\nfindings. For instance, our analysis revealed a significant correlation between\nloaded language and opinion, shedding light on their interconnectedness. To\nencourage further research in this field, we will be making the models and\ndataset available with the MIT License, making it favorable for open-source\nresearch.",
            "author": [
                "Anku Rani",
                "Dwip Dalal",
                "Shreya Gautam",
                "Pankaj Gupta",
                "Vinija Jain",
                "Aman Chadha",
                "Amit Sheth",
                "Amitava Das"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00292v1",
                "http://arxiv.org/pdf/2312.00292v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00290v1",
            "title": "Learning to forecast diagnostic parameters using pre-trained weather\n  embedding",
            "updated": "2023-12-01T02:09:18Z",
            "published": "2023-12-01T02:09:18Z",
            "summary": "Data-driven weather prediction (DDWP) models are increasingly becoming\npopular for weather forecasting. However, while operational weather forecasts\npredict a wide variety of weather variables, DDWPs currently forecast a\nspecific set of key prognostic variables. Non-prognostic (\"diagnostic\")\nvariables are sometimes modeled separately as dependent variables of the\nprognostic variables (c.f. FourCastNet), or by including the diagnostic\nvariable as a target in the DDWP. However, the cost of training and deploying\nbespoke models for each diagnostic variable can increase dramatically with more\ndiagnostic variables, and limit the operational use of such models. Likewise,\nretraining an entire DDWP each time a new diagnostic variable is added is also\ncost-prohibitive. We present an two-stage approach that allows new diagnostic\nvariables to be added to an end-to-end DDWP model without the expensive\nretraining. In the first stage, we train an autoencoder that learns to embed\nprognostic variables into a latent space. In the second stage, the autoencoder\nis frozen and \"downstream\" models are trained to predict diagnostic variables\nusing only the latent representations of prognostic variables as input. Our\nexperiments indicate that models trained using the two-stage approach offer\naccuracy comparable to training bespoke models, while leading to significant\nreduction in resource utilization during training and inference. This approach\nallows for new \"downstream\" models to be developed as needed, without affecting\nexisting models and thus reducing the friction in operationalizing new models.",
            "author": [
                "Peetak P. Mitra",
                "Vivek Ramavajjala"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00290v1",
                "http://arxiv.org/pdf/2312.00290v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00839v2",
            "title": "PipeOptim: Ensuring Effective 1F1B Schedule with Optimizer-Dependent\n  Weight Prediction",
            "updated": "2023-12-05T07:16:55Z",
            "published": "2023-12-01T01:52:38Z",
            "summary": "Asynchronous pipeline model parallelism with a \"1F1B\" (one forward, one\nbackward) schedule generates little bubble overhead and always provides quite a\nhigh throughput. However, the \"1F1B\" schedule inevitably leads to weight\ninconsistency and weight staleness issues due to the cross-training of\ndifferent mini-batches across GPUs. To simultaneously address these two\nproblems, in this paper, we propose an optimizer-dependent weight prediction\nstrategy (a.k.a PipeOptim) for asynchronous pipeline training. The key insight\nof our proposal is that we employ a weight prediction strategy in the forward\npass to ensure that each mini-batch uses consistent and staleness-free weights\nto compute the forward pass. To be concrete, we first construct the weight\nprediction scheme based on the update rule of the used optimizer when training\nthe deep neural network models. Then throughout the \"1F1B\" pipelined training,\neach mini-batch is mandated to execute weight prediction ahead of the forward\npass, subsequently employing the predicted weights to perform the forward pass.\nAs a result, PipeOptim 1) inherits the advantage of the \"1F1B\" schedule and\ngenerates pretty high throughput, and 2) can ensure effective parameter\nlearning regardless of the type of the used optimizer. To verify the\neffectiveness of our proposal, we conducted extensive experimental evaluations\nusing eight different deep-learning models spanning three machine-learning\ntasks including image classification, sentiment analysis, and machine\ntranslation. The experiment results demonstrate that PipeOptim outperforms the\npopular pipelined approaches including GPipe, PipeDream, PipeDream-2BW, and\nSpecTrain. The code of PipeOptim can be accessible at\nhttps://github.com/guanleics/PipeOptim.",
            "author": [
                "Lei Guan",
                "Dongsheng Li",
                "Jiye Liang",
                "Wenjian Wang",
                "Xicheng Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00839v2",
                "http://arxiv.org/pdf/2312.00839v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00279v1",
            "title": "Age-Based Scheduling for Mobile Edge Computing: A Deep Reinforcement\n  Learning Approach",
            "updated": "2023-12-01T01:30:49Z",
            "published": "2023-12-01T01:30:49Z",
            "summary": "With the rapid development of Mobile Edge Computing (MEC), various real-time\napplications have been deployed to benefit people's daily lives. The\nperformance of these applications relies heavily on the freshness of collected\nenvironmental information, which can be quantified by its Age of Information\n(AoI). In the traditional definition of AoI, it is assumed that the status\ninformation can be actively sampled and directly used. However, for many\nMEC-enabled applications, the desired status information is updated in an\nevent-driven manner and necessitates data processing. To better serve these\napplications, we propose a new definition of AoI and, based on the redefined\nAoI, we formulate an online AoI minimization problem for MEC systems. Notably,\nthe problem can be interpreted as a Markov Decision Process (MDP), thus\nenabling its solution through Reinforcement Learning (RL) algorithms.\nNevertheless, the traditional RL algorithms are designed for MDPs with\ncompletely unknown system dynamics and hence usually suffer long convergence\ntimes. To accelerate the learning process, we introduce Post-Decision States\n(PDSs) to exploit the partial knowledge of the system's dynamics. We also\ncombine PDSs with deep RL to further improve the algorithm's applicability,\nscalability, and robustness. Numerical results demonstrate that our algorithm\noutperforms the benchmarks under various scenarios.",
            "author": [
                "Xingqiu He",
                "Chaoqun You",
                "Tony Q. S. Quek"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00279v1",
                "http://arxiv.org/pdf/2312.00279v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00277v1",
            "title": "Text Attribute Control via Closed-Loop Disentanglement",
            "updated": "2023-12-01T01:26:38Z",
            "published": "2023-12-01T01:26:38Z",
            "summary": "Changing an attribute of a text without changing the content usually requires\nto first disentangle the text into irrelevant attributes and content\nrepresentations. After that, in the inference phase, the representation of one\nattribute is tuned to a different value, expecting that the corresponding\nattribute of the text can also be changed accordingly. The usual way of\ndisentanglement is to add some constraints on the latent space of an\nencoder-decoder architecture, including adversarial-based constraints and\nmutual-information-based constraints. However, the previous semi-supervised\nprocesses of attribute change are usually not enough to guarantee the success\nof attribute change and content preservation. In this paper, we propose a novel\napproach to achieve a robust control of attributes while enhancing content\npreservation. In this approach, we use a semi-supervised contrastive learning\nmethod to encourage the disentanglement of attributes in latent spaces.\nDifferently from previous works, we re-disentangle the reconstructed sentence\nand compare the re-disentangled latent space with the original latent space,\nwhich makes a closed-loop disentanglement process. This also helps content\npreservation. In addition, the contrastive learning method is also able to\nreplace the role of minimizing mutual information and adversarial training in\nthe disentanglement process, which alleviates the computation cost. We\nconducted experiments on three text datasets, including the Yelp Service review\ndataset, the Amazon Product review dataset, and the GoEmotions dataset. The\nexperimental results show the effectiveness of our model.",
            "author": [
                "Lei Sha",
                "Thomas Lukasiewicz"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00277v1",
                "http://arxiv.org/pdf/2312.00277v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00276v1",
            "title": "Automating Continual Learning",
            "updated": "2023-12-01T01:25:04Z",
            "published": "2023-12-01T01:25:04Z",
            "summary": "General-purpose learning systems should improve themselves in open-ended\nfashion in ever-changing environments. Conventional learning algorithms for\nneural networks, however, suffer from catastrophic forgetting (CF) --\npreviously acquired skills are forgotten when a new task is learned. Instead of\nhand-crafting new algorithms for avoiding CF, we propose Automated Continual\nLearning (ACL) to train self-referential neural networks to meta-learn their\nown in-context continual (meta-)learning algorithms. ACL encodes all desiderata\n-- good performance on both old and new tasks -- into its meta-learning\nobjectives. Our experiments demonstrate that ACL effectively solves \"in-context\ncatastrophic forgetting\"; our ACL-learned algorithms outperform hand-crafted\nones, e.g., on the Split-MNIST benchmark in the replay-free setting, and\nenables continual learning of diverse tasks consisting of multiple few-shot and\nstandard image classification datasets.",
            "author": [
                "Kazuki Irie",
                "R\u00f3bert Csord\u00e1s",
                "J\u00fcrgen Schmidhuber"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00276v1",
                "http://arxiv.org/pdf/2312.00276v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00273v2",
            "title": "Mark My Words: Analyzing and Evaluating Language Model Watermarks",
            "updated": "2023-12-07T04:37:47Z",
            "published": "2023-12-01T01:22:46Z",
            "summary": "The capabilities of large language models have grown significantly in recent\nyears and so too have concerns about their misuse. In this context, the ability\nto distinguish machine-generated text from human-authored content becomes\nimportant. Prior works have proposed numerous schemes to watermark text, which\nwould benefit from a systematic evaluation framework. This work focuses on text\nwatermarking techniques - as opposed to image watermarks - and proposes\nMARKMYWORDS, a comprehensive benchmark for them under different tasks as well\nas practical attacks. We focus on three main metrics: quality, size (e.g. the\nnumber of tokens needed to detect a watermark), and tamper-resistance. Current\nwatermarking techniques are good enough to be deployed: Kirchenbauer et al. [1]\ncan watermark Llama2-7B-chat with no perceivable loss in quality, the watermark\ncan be detected with fewer than 100 tokens, and the scheme offers good\ntamper-resistance to simple attacks. We argue that watermark\nindistinguishability, a criteria emphasized in some prior works, is too strong\na requirement: schemes that slightly modify logit distributions outperform\ntheir indistinguishable counterparts with no noticeable loss in generation\nquality. We publicly release our benchmark\n(https://github.com/wagner-group/MarkMyWords)",
            "author": [
                "Julien Piet",
                "Chawin Sitawarin",
                "Vivian Fang",
                "Norman Mu",
                "David Wagner"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00273v2",
                "http://arxiv.org/pdf/2312.00273v2"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00837v1",
            "title": "An Adaptive Correspondence Scoring Framework for Unsupervised Image\n  Registration of Medical Images",
            "updated": "2023-12-01T01:11:22Z",
            "published": "2023-12-01T01:11:22Z",
            "summary": "We propose an adaptive training scheme for unsupervised medical image\nregistration. Existing methods rely on image reconstruction as the primary\nsupervision signal. However, nuisance variables (e.g. noise and covisibility)\noften cause the loss of correspondence between medical images, violating the\nLambertian assumption in physical waves (e.g. ultrasound) and consistent\nimaging acquisition. As the unsupervised learning scheme relies on intensity\nconstancy to establish correspondence between images for reconstruction, this\nintroduces spurious error residuals that are not modeled by the typical\ntraining objective. To mitigate this, we propose an adaptive framework that\nre-weights the error residuals with a correspondence scoring map during\ntraining, preventing the parametric displacement estimator from drifting away\ndue to noisy gradients, which leads to performance degradations. To illustrate\nthe versatility and effectiveness of our method, we tested our framework on\nthree representative registration architectures across three medical image\ndatasets along with other baselines. Our proposed adaptive framework\nconsistently outperforms other methods both quantitatively and qualitatively.\nPaired t-tests show that our improvements are statistically significant. The\ncode will be publicly available at\n\\url{https://voldemort108x.github.io/AdaCS/}.",
            "author": [
                "Xiaoran Zhang",
                "John C. Stendahl",
                "Lawrence Staib",
                "Albert J. Sinusas",
                "Alex Wong",
                "James S. Duncan"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00837v1",
                "http://arxiv.org/pdf/2312.00837v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00271v2",
            "title": "Towards Clinical Prediction with Transparency: An Explainable AI\n  Approach to Survival Modelling in Residential Aged Care",
            "updated": "2023-12-07T02:49:11Z",
            "published": "2023-12-01T01:11:16Z",
            "summary": "Background: Accurate survival time estimates aid end-of-life medical\ndecision-making. Objectives: Develop an interpretable survival model for\nelderly residential aged care residents using advanced machine learning.\nSetting: A major Australasian residential aged care provider. Participants:\nResidents aged 65+ admitted for long-term care from July 2017 to August 2023.\nSample size: 11,944 residents across 40 facilities. Predictors: Factors include\nage, gender, health status, co-morbidities, cognitive function, mood,\nnutrition, mobility, smoking, sleep, skin integrity, and continence. Outcome:\nProbability of survival post-admission, specifically calibrated for 6-month\nsurvival estimates. Statistical Analysis: Tested CoxPH, EN, RR, Lasso, GB, XGB,\nand RF models in 20 experiments with a 90/10 train/test split. Evaluated\naccuracy using C-index, Harrell's C-index, dynamic AUROC, IBS, and calibrated\nROC. Chose XGB for its performance and calibrated it for 1, 3, 6, and 12-month\npredictions using Platt scaling. Employed SHAP values to analyze predictor\nimpacts. Results: GB, XGB, and RF models showed the highest C-Index values\n(0.714, 0.712, 0.712). The optimal XGB model demonstrated a 6-month survival\nprediction AUROC of 0.746 (95% CI 0.744-0.749). Key mortality predictors\ninclude age, male gender, mobility, health status, pressure ulcer risk, and\nappetite. Conclusions: The study successfully applies machine learning to\ncreate a survival model for aged care, aligning with clinical insights on\nmortality risk factors and enhancing model interpretability and clinical\nutility through explainable AI.",
            "author": [
                "Teo Susnjak",
                "Elise Griffin",
                "Mitchell McCutcheon",
                "Kathleen Potter"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00271v2",
                "http://arxiv.org/pdf/2312.00271v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00268v1",
            "title": "Academic competitions",
            "updated": "2023-12-01T01:01:04Z",
            "published": "2023-12-01T01:01:04Z",
            "summary": "Academic challenges comprise effective means for (i) advancing the state of\nthe art, (ii) putting in the spotlight of a scientific community specific\ntopics and problems, as well as (iii) closing the gap for under represented\ncommunities in terms of accessing and participating in the shaping of research\nfields. Competitions can be traced back for centuries and their achievements\nhave had great influence in our modern world. Recently, they (re)gained\npopularity, with the overwhelming amounts of data that is being generated in\ndifferent domains, as well as the need of pushing the barriers of existing\nmethods, and available tools to handle such data. This chapter provides a\nsurvey of academic challenges in the context of machine learning and related\nfields. We review the most influential competitions in the last few years and\nanalyze challenges per area of knowledge. The aims of scientific challenges,\ntheir goals, major achievements and expectations for the next few years are\nreviewed.",
            "author": [
                "Hugo Jair Escalante",
                "Aleksandra Kruchinina"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00268v1",
                "http://arxiv.org/pdf/2312.00268v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00267v1",
            "title": "Sample Efficient Reinforcement Learning from Human Feedback via Active\n  Exploration",
            "updated": "2023-12-01T00:54:02Z",
            "published": "2023-12-01T00:54:02Z",
            "summary": "Preference-based feedback is important for many applications in reinforcement\nlearning where direct evaluation of a reward function is not feasible. A\nnotable recent example arises in reinforcement learning from human feedback\n(RLHF) on large language models. For many applications of RLHF, the cost of\nacquiring the human feedback can be substantial. In this work, we take\nadvantage of the fact that one can often choose contexts at which to obtain\nhuman feedback in order to most efficiently identify a good policy, and\nformalize this as an offline contextual dueling bandit problem. We give an\nupper-confidence-bound style algorithm for this problem and prove a polynomial\nworst-case regret bound. We then provide empirical confirmation in a synthetic\nsetting that our approach outperforms existing methods. After, we extend the\nsetting and methodology for practical use in RLHF training of large language\nmodels. Here, our method is able to reach better performance with fewer samples\nof human preferences than multiple baselines on three real-world datasets.",
            "author": [
                "Viraj Mehta",
                "Vikramjeet Das",
                "Ojash Neopane",
                "Yijia Dai",
                "Ilija Bogunovic",
                "Jeff Schneider",
                "Willie Neiswanger"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00267v1",
                "http://arxiv.org/pdf/2312.00267v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00265v1",
            "title": "RoboSync: OS for Social Robots with Customizable Behaviour",
            "updated": "2023-12-01T00:47:44Z",
            "published": "2023-12-01T00:47:44Z",
            "summary": "Traditional robotic systems require complex implementations that are not\nalways accessible or easy to use for Human-Robot Interaction (HRI) application\ndevelopers. With the aim of simplifying the implementation of HRI applications,\nthis paper introduces a novel real-time operating system (RTOS) designed for\ncustomizable HRI - RoboSync. By creating multi-level abstraction layers, the\nsystem enables users to define complex emotional and behavioral models without\nneeding deep technical expertise. The system's modular architecture comprises a\nbehavior modeling layer, a machine learning plugin configuration layer, a\nsensor checks customization layer, a scheduler that fits the need of HRI, and a\ncommunication and synchronization layer. This approach not only promotes ease\nof use without highly specialized skills but also ensures real-time\nresponsiveness and adaptability. The primary functionality of the RTOS has been\nimplemented for proof of concept and was tested on a CortexM4 microcontroller,\ndemonstrating its potential for a wide range of lightweight simple-to-implement\nsocial robotics applications.",
            "author": [
                "Cheng Tang",
                "Yijing Feng",
                "Yue Hu"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-981-99-8718-4_18",
                "http://arxiv.org/abs/2312.00265v1",
                "http://arxiv.org/pdf/2312.00265v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00264v1",
            "title": "Skipper: Improving the Reach and Fidelity of Quantum Annealers by\n  Skipping Long Chains",
            "updated": "2023-12-01T00:42:28Z",
            "published": "2023-12-01T00:42:28Z",
            "summary": "Quantum Annealers (QAs) operate as single-instruction machines, lacking a\nSWAP operation to overcome limited qubit connectivity. Consequently, multiple\nphysical qubits are chained to form a program qubit with higher connectivity,\nresulting in a drastically diminished effective QA capacity by up to 33x. We\nobserve that in QAs: (a) chain lengths exhibit a power-law distribution, a few\ndominant chains holding substantially more qubits than others; and (b) about\n25% of physical qubits remain unused, getting isolated between these chains. We\npropose Skipper, a software technique that enhances the capacity and fidelity\nof QAs by skipping dominant chains and substituting their program qubit with\ntwo readout results. Using a 5761-qubit QA, we demonstrate that Skipper can\ntackle up to 59% (Avg. 28%) larger problems when eleven chains are skipped.\nAdditionally, Skipper can improve QA fidelity by up to 44% (Avg. 33%) when\ncutting five chains (32 runs). Users can specify up to eleven chain cuts in\nSkipper, necessitating about 2,000 distinct quantum executable runs. To\nmitigate this, we introduce Skipper-G, a greedy scheme that skips sub-problems\nless likely to hold the global optimum, executing a maximum of 23 quantum\nexecutables with eleven chain trims. Skipper-G can boost QA fidelity by up to\n41% (Avg. 29%) when cutting five chains (11 runs).",
            "author": [
                "Ramin Ayanzadeh",
                "Moinuddin Qureshi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00264v1",
                "http://arxiv.org/pdf/2312.00264v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.AI",
                "cs.AR",
                "cs.ET",
                "cs.PF"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00260v1",
            "title": "Quantum Multiple Kernel Learning in Financial Classification Tasks",
            "updated": "2023-12-01T00:18:43Z",
            "published": "2023-12-01T00:18:43Z",
            "summary": "Financial services is a prospect industry where unlocked near-term quantum\nutility could yield profitable potential, and, in particular, quantum machine\nlearning algorithms could potentially benefit businesses by improving the\nquality of predictive models. Quantum kernel methods have demonstrated success\nin financial, binary classification tasks, like fraud detection, and avoid\nissues found in variational quantum machine learning approaches. However,\nchoosing a suitable quantum kernel for a classical dataset remains a challenge.\nWe propose a hybrid, quantum multiple kernel learning (QMKL) methodology that\ncan improve classification quality over a single kernel approach. We test the\nrobustness of QMKL on several financially relevant datasets using both fidelity\nand projected quantum kernel approaches. We further demonstrate QMKL on quantum\nhardware using an error mitigation pipeline and show the benefits of QMKL in\nthe large qubit regime.",
            "author": [
                "Shungo Miyabe",
                "Brian Quanz",
                "Noriaki Shimada",
                "Abhijit Mitra",
                "Takahiro Yamamoto",
                "Vladimir Rastunkov",
                "Dimitris Alevras",
                "Mekena Metcalf",
                "Daniel J. M. King",
                "Mohammad Mamouei",
                "Matthew D. Jackson",
                "Martin Brown",
                "Philip Intallura",
                "Jae-Eun Park"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00260v1",
                "http://arxiv.org/pdf/2312.00260v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00252v1",
            "title": "PyNeRF: Pyramidal Neural Radiance Fields",
            "updated": "2023-11-30T23:52:46Z",
            "published": "2023-11-30T23:52:46Z",
            "summary": "Neural Radiance Fields (NeRFs) can be dramatically accelerated by spatial\ngrid representations. However, they do not explicitly reason about scale and so\nintroduce aliasing artifacts when reconstructing scenes captured at different\ncamera distances. Mip-NeRF and its extensions propose scale-aware renderers\nthat project volumetric frustums rather than point samples but such approaches\nrely on positional encodings that are not readily compatible with grid methods.\nWe propose a simple modification to grid-based models by training model heads\nat different spatial grid resolutions. At render time, we simply use coarser\ngrids to render samples that cover larger volumes. Our method can be easily\napplied to existing accelerated NeRF methods and significantly improves\nrendering quality (reducing error rates by 20-90% across synthetic and\nunbounded real-world scenes) while incurring minimal performance overhead (as\neach model head is quick to evaluate). Compared to Mip-NeRF, we reduce error\nrates by 20% while training over 60x faster.",
            "author": [
                "Haithem Turki",
                "Michael Zollh\u00f6fer",
                "Christian Richardt",
                "Deva Ramanan"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00252v1",
                "http://arxiv.org/pdf/2312.00252v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00249v1",
            "title": "Acoustic Prompt Tuning: Empowering Large Language Models with Audition\n  Capabilities",
            "updated": "2023-11-30T23:43:59Z",
            "published": "2023-11-30T23:43:59Z",
            "summary": "The auditory system plays a substantial role in shaping the overall human\nperceptual experience. While prevailing large language models (LLMs) and visual\nlanguage models (VLMs) have shown their promise in solving a wide variety of\nvision and language understanding tasks, only a few of them can be generalised\nto the audio domain without compromising their domain-specific capacity. In\nthis work, we introduce Acoustic Prompt Turning (APT), a new adapter extending\nLLMs and VLMs to the audio domain by soft prompting only. Specifically, APT\napplies an instruction-aware audio aligner to generate soft prompts,\nconditioned on both input text and sounds, as language model inputs. To\nmitigate the data scarcity in the audio domain, a multi-task learning strategy\nis proposed by formulating diverse audio tasks in a sequence-to-sequence\nmanner. Moreover, we improve the framework of audio language model by using\ninterleaved audio-text embeddings as the input sequence. This improved\nframework imposes zero constraints on the input format and thus is capable of\ntackling more understanding tasks, such as few-shot audio classification and\naudio reasoning. To further evaluate the reasoning ability of audio networks,\nwe propose natural language audio reasoning (NLAR), a new task that analyses\nacross two audio clips by comparison and summarization. Experiments show that\nAPT-enhanced LLMs (namely APT-LLMs) achieve competitive results compared to the\nexpert models (i.e., the networks trained on the targeted datasets) across\nvarious tasks. We finally demonstrate the APT's ability in extending frozen\nVLMs to the audio domain without finetuning, achieving promising results in the\naudio-visual question and answering task. Our code and model weights are\nreleased at https://github.com/JinhuaLiang/APT.",
            "author": [
                "Jinhua Liang",
                "Xubo Liu",
                "Wenwu Wang",
                "Mark D. Plumbley",
                "Huy Phan",
                "Emmanouil Benetos"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00249v1",
                "http://arxiv.org/pdf/2312.00249v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00246v1",
            "title": "Curvature Explains Loss of Plasticity",
            "updated": "2023-11-30T23:24:45Z",
            "published": "2023-11-30T23:24:45Z",
            "summary": "Loss of plasticity is a phenomenon in which neural networks lose their\nability to learn from new experience. Despite being empirically observed in\nseveral problem settings, little is understood about the mechanisms that lead\nto loss of plasticity. In this paper, we offer a consistent explanation for\nplasticity loss, based on an assertion that neural networks lose directions of\ncurvature during training and that plasticity loss can be attributed to this\nreduction in curvature. To support such a claim, we provide a systematic\nempirical investigation of plasticity loss across several continual supervised\nlearning problems. Our findings illustrate that curvature loss coincides with\nand sometimes precedes plasticity loss, while also showing that previous\nexplanations are insufficient to explain loss of plasticity in all settings.\nLastly, we show that regularizers which mitigate loss of plasticity also\npreserve curvature, motivating a simple distributional regularizer that proves\nto be effective across the problem settings considered.",
            "author": [
                "Alex Lewandowski",
                "Haruto Tanaka",
                "Dale Schuurmans",
                "Marlos C. Machado"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00246v1",
                "http://arxiv.org/pdf/2312.00246v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00245v1",
            "title": "SPAM: Secure & Private Aircraft Management",
            "updated": "2023-11-30T23:16:45Z",
            "published": "2023-11-30T23:16:45Z",
            "summary": "With the rising use of aircrafts for operations ranging from disaster-relief\nto warfare, there is a growing risk of adversarial attacks. Malicious entities\noften only require the location of the aircraft for these attacks. Current\nsatellite-aircraft communication and tracking protocols put aircrafts at risk\nif the satellite is compromised, due to computation being done in plaintext. In\nthis work, we present \\texttt{SPAM}, a private, secure, and accurate system\nthat allows satellites to efficiently manage and maintain tracking angles for\naircraft fleets without learning aircrafts' locations. \\texttt{SPAM} is built\nupon multi-party computation and zero-knowledge proofs to guarantee privacy and\nhigh efficiency. While catered towards aircrafts, \\texttt{SPAM}'s\nzero-knowledge fleet management can be easily extended to the IoT, with very\nlittle overhead.",
            "author": [
                "Yaman Jandali",
                "Nojan Sheybani",
                "Farinaz Koushanfar"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00245v1",
                "http://arxiv.org/pdf/2312.00245v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00243v1",
            "title": "Low Revenue in Display Ad Auctions: Algorithmic Collusion vs.\n  Non-Quasilinear Preferences",
            "updated": "2023-11-30T23:11:33Z",
            "published": "2023-11-30T23:11:33Z",
            "summary": "The transition of display ad exchanges from second-price to first-price\nauctions has raised questions about its impact on revenue. Evaluating this\nshift empirically proves challenging. One key factor is the behavior of\nautomated bidding agents, who are unlikely to use static game-theoretical\nequilibrium strategies instead of favoring dynamic realms that continuously\nadapt and learn independently through the process of exploration and\nexploitation. Thus revenue equivalence between first- and second-price auctions\nmight not hold. Research on algorithmic collusion in display ad auctions found\nrevenue differences between second-price and first-price auctions. First-price\nauctions can induce Q-learning agents to tacitly collude below the Nash\nequilibrium in repeated complete-information auctions with payoff-maximizing\nagents (i.e., agents maximizing value minus price). Our analysis explores\nwide-spread online learning algorithms' convergence behavior in both complete\nand incomplete information models, but does not find a systematic deviance from\nequilibrium behavior. Convergence for Q-learning depends on hyperparameters and\ninitializations, and algorithmic collusion vanishes when competing against\nother learning algorithms. Apart from their learning behavior, the objectives\nreported in the literature extend payoff maximization, often focusing on\nreturn-on-investment or return-on-spend. We derive equilibrium bid functions\nfor such utility models, revealing that revenue equivalence doesn't hold. In\nlow-competition scenarios, the first-price auction often yields lower revenue\nthan the second-price counterpart. These insights offer an alternative\nrationale for the potential revenue decrease in first-price auctions.\nUnderstanding the intricate interplay of auction rules, learning algorithms,\nand utility models is crucial in maximizing revenue in the ever-evolving world\nof display ad exchanges.",
            "author": [
                "Martin Bichler",
                "Alok Gupta",
                "Laura Mathews",
                "Matthias Oberlechner"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00243v1",
                "http://arxiv.org/pdf/2312.00243v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00834v1",
            "title": "AV-RIR: Audio-Visual Room Impulse Response Estimation",
            "updated": "2023-11-30T22:58:30Z",
            "published": "2023-11-30T22:58:30Z",
            "summary": "Accurate estimation of Room Impulse Response (RIR), which captures an\nenvironment's acoustic properties, is important for speech processing and AR/VR\napplications. We propose AV-RIR, a novel multi-modal multi-task learning\napproach to accurately estimate the RIR from a given reverberant speech signal\nand the visual cues of its corresponding environment. AV-RIR builds on a novel\nneural codec-based architecture that effectively captures environment geometry\nand materials properties and solves speech dereverberation as an auxiliary task\nby using multi-task learning. We also propose Geo-Mat features that augment\nmaterial information into visual cues and CRIP that improves late reverberation\ncomponents in the estimated RIR via image-to-RIR retrieval by 86%. Empirical\nresults show that AV-RIR quantitatively outperforms previous audio-only and\nvisual-only approaches by achieving 36% - 63% improvement across various\nacoustic metrics in RIR estimation. Additionally, it also achieves higher\npreference scores in human evaluation. As an auxiliary benefit, dereverbed\nspeech from AV-RIR shows competitive performance with the state-of-the-art in\nvarious spoken language processing tasks and outperforms reverberation time\nerror score in the real-world AVSpeech dataset. Qualitative examples of both\nsynthesized reverberant speech and enhanced speech can be found at\nhttps://www.youtube.com/watch?v=tTsKhviukAE.",
            "author": [
                "Anton Ratnarajah",
                "Sreyan Ghosh",
                "Sonal Kumar",
                "Purva Chiniya",
                "Dinesh Manocha"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00834v1",
                "http://arxiv.org/pdf/2312.00834v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00833v1",
            "title": "Lasagna: Layered Score Distillation for Disentangled Object Relighting",
            "updated": "2023-11-30T22:54:41Z",
            "published": "2023-11-30T22:54:41Z",
            "summary": "Professional artists, photographers, and other visual content creators use\nobject relighting to establish their photo's desired effect. Unfortunately,\nmanual tools that allow relighting have a steep learning curve and are\ndifficult to master. Although generative editing methods now enable some forms\nof image editing, relighting is still beyond today's capabilities; existing\nmethods struggle to keep other aspects of the image -- colors, shapes, and\ntextures -- consistent after the edit. We propose Lasagna, a method that\nenables intuitive text-guided relighting control. Lasagna learns a lighting\nprior by using score distillation sampling to distill the prior of a diffusion\nmodel, which has been finetuned on synthetic relighting data. To train Lasagna,\nwe curate a new synthetic dataset ReLiT, which contains 3D object assets re-lit\nfrom multiple light source locations. Despite training on synthetic images,\nquantitative results show that Lasagna relights real-world images while\npreserving other aspects of the input image, outperforming state-of-the-art\ntext-guided image editing methods. Lasagna enables realistic and controlled\nresults on natural images and digital art pieces and is preferred by humans\nover other methods in over 91% of cases. Finally, we demonstrate the\nversatility of our learning objective by extending it to allow colorization,\nanother form of image editing.",
            "author": [
                "Dina Bashkirova",
                "Arijit Ray",
                "Rupayan Mallick",
                "Sarah Adel Bargal",
                "Jianming Zhang",
                "Ranjay Krishna",
                "Kate Saenko"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00833v1",
                "http://arxiv.org/pdf/2312.00833v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00238v1",
            "title": "Self-similarity of Communities of the ABCD Model",
            "updated": "2023-11-30T22:52:39Z",
            "published": "2023-11-30T22:52:39Z",
            "summary": "The Artificial Benchmark for Community Detection (ABCD) graph is a random\ngraph model with community structure and power-law distribution for both\ndegrees and community sizes. The model generates graphs similar to the\nwell-known LFR model but it is faster and can be investigated analytically.\n  In this paper, we show that the ABCD model exhibits some interesting\nself-similar behaviour, namely, the degree distribution of ground-truth\ncommunities is asymptotically the same as the degree distribution of the whole\ngraph (appropriately normalized based on their sizes). As a result, we can not\nonly estimate the number of edges induced by each community but also the number\nof self-loops and multi-edges generated during the process. Understanding these\nquantities is important as (a) rewiring self-loops and multi-edges to keep the\ngraph simple is an expensive part of the algorithm, and (b) every rewiring\ncauses the underlying configuration models to deviate slightly from uniform\nsimple graphs on their corresponding degree sequences.",
            "author": [
                "Jordan Barrett",
                "Bogumil Kaminski",
                "Pawel Pralat",
                "Francois Theberge"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00238v1",
                "http://arxiv.org/pdf/2312.00238v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.DM",
                "cs.LG",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00237v1",
            "title": "Negotiated Representations to Prevent Forgetting in Machine Learning\n  Applications",
            "updated": "2023-11-30T22:43:50Z",
            "published": "2023-11-30T22:43:50Z",
            "summary": "Catastrophic forgetting is a significant challenge in the field of machine\nlearning, particularly in neural networks. When a neural network learns to\nperform well on a new task, it often forgets its previously acquired knowledge\nor experiences. This phenomenon occurs because the network adjusts its weights\nand connections to minimize the loss on the new task, which can inadvertently\noverwrite or disrupt the representations that were crucial for the previous\ntasks. As a result, the the performance of the network on earlier tasks\ndeteriorates, limiting its ability to learn and adapt to a sequence of tasks.\nIn this paper, we propose a novel method for preventing catastrophic forgetting\nin machine learning applications, specifically focusing on neural networks. Our\napproach aims to preserve the knowledge of the network across multiple tasks\nwhile still allowing it to learn new information effectively. We demonstrate\nthe effectiveness of our method by conducting experiments on various benchmark\ndatasets, including Split MNIST, Split CIFAR10, Split Fashion MNIST, and Split\nCIFAR100. These datasets are created by dividing the original datasets into\nseparate, non overlapping tasks, simulating a continual learning scenario where\nthe model needs to learn multiple tasks sequentially without forgetting the\nprevious ones. Our proposed method tackles the catastrophic forgetting problem\nby incorporating negotiated representations into the learning process, which\nallows the model to maintain a balance between retaining past experiences and\nadapting to new tasks. By evaluating our method on these challenging datasets,\nwe aim to showcase its potential for addressing catastrophic forgetting and\nimproving the performance of neural networks in continual learning settings.",
            "author": [
                "Nuri Korhan",
                "Ceren \u00d6ner"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00237v1",
                "http://arxiv.org/pdf/2312.00237v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00236v1",
            "title": "Brainformer: Modeling MRI Brain Functions to Machine Vision",
            "updated": "2023-11-30T22:39:23Z",
            "published": "2023-11-30T22:39:23Z",
            "summary": "\"Perception is reality\". Human perception plays a vital role in forming\nbeliefs and understanding reality. Exploring how the human brain works in the\nvisual system facilitates bridging the gap between human visual perception and\ncomputer vision models. However, neuroscientists study the brain via\nNeuroimaging, i.e., Functional Magnetic Resonance Imaging (fMRI), to discover\nthe brain's functions. These approaches face interpretation challenges where\nfMRI data can be complex and require expertise. Therefore, neuroscientists make\ninferences about cognitive processes based on patterns of brain activities,\nwhich can lead to potential misinterpretation or limited functional\nunderstanding. In this work, we first present a simple yet effective\nBrainformer approach, a novel Transformer-based framework, to analyze the\npatterns of fMRI in the human perception system from the machine learning\nperspective. Secondly, we introduce a novel mechanism incorporating fMRI, which\nrepresents the human brain activities, as the supervision for the machine\nvision model. This work also introduces a novel perspective on transferring\nknowledge from human perception to neural networks. Through our experiments, we\ndemonstrated that by leveraging fMRI information, the machine vision model can\nachieve potential results compared to the current State-of-the-art methods in\nvarious image recognition tasks.",
            "author": [
                "Xuan-Bac Nguyen",
                "Xin Li",
                "Samee U. Khan",
                "Khoa Luu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00236v1",
                "http://arxiv.org/pdf/2312.00236v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00234v1",
            "title": "Deep Equilibrium Based Neural Operators for Steady-State PDEs",
            "updated": "2023-11-30T22:34:57Z",
            "published": "2023-11-30T22:34:57Z",
            "summary": "Data-driven machine learning approaches are being increasingly used to solve\npartial differential equations (PDEs). They have shown particularly striking\nsuccesses when training an operator, which takes as input a PDE in some family,\nand outputs its solution. However, the architectural design space, especially\ngiven structural knowledge of the PDE family of interest, is still poorly\nunderstood. We seek to remedy this gap by studying the benefits of weight-tied\nneural network architectures for steady-state PDEs. To achieve this, we first\ndemonstrate that the solution of most steady-state PDEs can be expressed as a\nfixed point of a non-linear operator. Motivated by this observation, we propose\nFNO-DEQ, a deep equilibrium variant of the FNO architecture that directly\nsolves for the solution of a steady-state PDE as the infinite-depth fixed point\nof an implicit operator layer using a black-box root solver and differentiates\nanalytically through this fixed point resulting in $\\mathcal{O}(1)$ training\nmemory. Our experiments indicate that FNO-DEQ-based architectures outperform\nFNO-based baselines with $4\\times$ the number of parameters in predicting the\nsolution to steady-state PDEs such as Darcy Flow and steady-state\nincompressible Navier-Stokes. Finally, we show FNO-DEQ is more robust when\ntrained with datasets with more noisy observations than the FNO-based\nbaselines, demonstrating the benefits of using appropriate inductive biases in\narchitectural design for different neural network based PDE solvers. Further,\nwe show a universal approximation result that demonstrates that FNO-DEQ can\napproximate the solution to any steady-state PDE that can be written as a fixed\npoint equation.",
            "author": [
                "Tanya Marwah",
                "Ashwini Pokle",
                "J. Zico Kolter",
                "Zachary C. Lipton",
                "Jianfeng Lu",
                "Andrej Risteski"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00234v1",
                "http://arxiv.org/pdf/2312.00234v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NA",
                "math.NA",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00232v1",
            "title": "Uncertainty in Graph Contrastive Learning with Bayesian Neural Networks",
            "updated": "2023-11-30T22:32:24Z",
            "published": "2023-11-30T22:32:24Z",
            "summary": "Graph contrastive learning has shown great promise when labeled data is\nscarce, but large unlabeled datasets are available. However, it often does not\ntake uncertainty estimation into account. We show that a variational Bayesian\nneural network approach can be used to improve not only the uncertainty\nestimates but also the downstream performance on semi-supervised\nnode-classification tasks. Moreover, we propose a new measure of uncertainty\nfor contrastive learning, that is based on the disagreement in likelihood due\nto different positive samples.",
            "author": [
                "Alexander M\u00f6llers",
                "Alexander Immer",
                "Elvin Isufi",
                "Vincent Fortuin"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00232v1",
                "http://arxiv.org/pdf/2312.00232v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00231v1",
            "title": "Learning domain-invariant classifiers for infant cry sounds",
            "updated": "2023-11-30T22:27:57Z",
            "published": "2023-11-30T22:27:57Z",
            "summary": "The issue of domain shift remains a problematic phenomenon in most real-world\ndatasets and clinical audio is no exception. In this work, we study the nature\nof domain shift in a clinical database of infant cry sounds acquired across\ndifferent geographies. We find that though the pitches of infant cries are\nsimilarly distributed regardless of the place of birth, other characteristics\nintroduce peculiar biases into the data. We explore methodologies for\nmitigating the impact of domain shift in a model for identifying neurological\ninjury from cry sounds. We adapt unsupervised domain adaptation methods from\ncomputer vision which learn an audio representation that is domain-invariant to\nhospitals and is task discriminative. We also propose a new approach, target\nnoise injection (TNI), for unsupervised domain adaptation which requires\nneither labels nor training data from the target domain. Our best-performing\nmodel significantly improves target accuracy by 7.2%, without negatively\naffecting the source domain.",
            "author": [
                "Charles C. Onu",
                "Hemanth K. Sheetha",
                "Arsenii Gorin",
                "Doina Precup"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00231v1",
                "http://arxiv.org/pdf/2312.00231v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00224v1",
            "title": "Unsupervised textile defect detection using convolutional neural\n  networks",
            "updated": "2023-11-30T22:08:06Z",
            "published": "2023-11-30T22:08:06Z",
            "summary": "In this study, we propose a novel motif-based approach for unsupervised\ntextile anomaly detection that combines the benefits of traditional\nconvolutional neural networks with those of an unsupervised learning paradigm.\nIt consists of five main steps: preprocessing, automatic pattern period\nextraction, patch extraction, features selection and anomaly detection. This\nproposed approach uses a new dynamic and heuristic method for feature selection\nwhich avoids the drawbacks of initialization of the number of filters (neurons)\nand their weights, and those of the backpropagation mechanism such as the\nvanishing gradients, which are common practice in the state-of-the-art methods.\nThe design and training of the network are performed in a dynamic and input\ndomain-based manner and, thus, no ad-hoc configurations are required. Before\nbuilding the model, only the number of layers and the stride are defined. We do\nnot initialize the weights randomly nor do we define the filter size or number\nof filters as conventionally done in CNN-based approaches. This reduces effort\nand time spent on hyperparameter initialization and fine-tuning. Only one\ndefect-free sample is required for training and no further labeled data is\nneeded. The trained network is then used to detect anomalies on defective\nfabric samples. We demonstrate the effectiveness of our approach on the\nPatterned Fabrics benchmark dataset. Our algorithm yields reliable and\ncompetitive results (on recall, precision, accuracy and f1- measure) compared\nto state-of-the-art unsupervised approaches, in less time, with efficient\ntraining in a single epoch and a lower computational cost.",
            "author": [
                "Imane Koulali",
                "M. Taner Eskil"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.asoc.2021.107913",
                "http://arxiv.org/abs/2312.00224v1",
                "http://arxiv.org/pdf/2312.00224v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00223v1",
            "title": "Convolutional Neural Networks for Segmentation of Malignant Pleural\n  Mesothelioma: Analysis of Probability Map Thresholds (CALGB 30901, Alliance)",
            "updated": "2023-11-30T22:07:07Z",
            "published": "2023-11-30T22:07:07Z",
            "summary": "Malignant pleural mesothelioma (MPM) is the most common form of mesothelioma.\nTo assess response to treatment, tumor measurements are acquired and evaluated\nbased on a patient's longitudinal computed tomography (CT) scans. Tumor volume,\nhowever, is the more accurate metric for assessing tumor burden and response.\nAutomated segmentation methods using deep learning can be employed to acquire\nvolume, which otherwise is a tedious task performed manually. The deep\nlearning-based tumor volume and contours can then be compared with a standard\nreference to assess the robustness of the automated segmentations. The purpose\nof this study was to evaluate the impact of probability map threshold on MPM\ntumor delineations generated using a convolutional neural network (CNN).\nEighty-eight CT scans from 21 MPM patients were segmented by a VGG16/U-Net CNN.\nA radiologist modified the contours generated at a 0.5 probability threshold.\nPercent difference of tumor volume and overlap using the Dice Similarity\nCoefficient (DSC) were compared between the standard reference provided by the\nradiologist and CNN outputs for thresholds ranging from 0.001 to 0.9. CNN\nannotations consistently yielded smaller tumor volumes than radiologist\ncontours. Reducing the probability threshold from 0.5 to 0.1 decreased the\nabsolute percent volume difference, on average, from 43.96% to 24.18%. Median\nand mean DSC ranged from 0.58 to 0.60, with a peak at a threshold of 0.5; no\ndistinct threshold was found for percent volume difference. No single output\nthreshold in the CNN probability maps was optimal for both tumor volume and\nDSC. This work underscores the need to assess tumor volume and spatial overlap\nwhen evaluating CNN performance. While automated segmentations may yield\ncomparable tumor volumes to that of the reference standard, the spatial region\ndelineated by the CNN at a specific threshold is equally important.",
            "author": [
                "Mena Shenouda",
                "Eyj\u00f3lfur Gudmundsson",
                "Feng Li",
                "Christopher M. Straus",
                "Hedy L. Kindler",
                "Arkadiusz Z. Dudek",
                "Thomas Stinchcombe",
                "Xiaofei Wang",
                "Adam Starkey",
                "Samuel G. Armato III"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00223v1",
                "http://arxiv.org/pdf/2312.00223v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00220v1",
            "title": "Multi-Modal Video Topic Segmentation with Dual-Contrastive Domain\n  Adaptation",
            "updated": "2023-11-30T21:59:05Z",
            "published": "2023-11-30T21:59:05Z",
            "summary": "Video topic segmentation unveils the coarse-grained semantic structure\nunderlying videos and is essential for other video understanding tasks. Given\nthe recent surge in multi-modal, relying solely on a single modality is\narguably insufficient. On the other hand, prior solutions for similar tasks\nlike video scene/shot segmentation cater to short videos with clear visual\nshifts but falter for long videos with subtle changes, such as livestreams. In\nthis paper, we introduce a multi-modal video topic segmenter that utilizes both\nvideo transcripts and frames, bolstered by a cross-modal attention mechanism.\nFurthermore, we propose a dual-contrastive learning framework adhering to the\nunsupervised domain adaptation paradigm, enhancing our model's adaptability to\nlonger, more semantically complex videos. Experiments on short and long video\ncorpora demonstrate that our proposed solution, significantly surpasses\nbaseline methods in terms of both accuracy and transferability, in both intra-\nand cross-domain settings.",
            "author": [
                "Linzi Xing",
                "Quan Tran",
                "Fabian Caba",
                "Franck Dernoncourt",
                "Seunghyun Yoon",
                "Zhaowen Wang",
                "Trung Bui",
                "Giuseppe Carenini"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00220v1",
                "http://arxiv.org/pdf/2312.00220v1"
            ],
            "primary_category": "cs.MM",
            "category": [
                "cs.MM",
                "cs.CL",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00215v1",
            "title": "Learning active tactile perception through belief-space control",
            "updated": "2023-11-30T21:54:42Z",
            "published": "2023-11-30T21:54:42Z",
            "summary": "Robots operating in an open world will encounter novel objects with unknown\nphysical properties, such as mass, friction, or size. These robots will need to\nsense these properties through interaction prior to performing downstream tasks\nwith the objects. We propose a method that autonomously learns tactile\nexploration policies by developing a generative world model that is leveraged\nto 1) estimate the object's physical parameters using a differentiable Bayesian\nfiltering algorithm and 2) develop an exploration policy using an\ninformation-gathering model predictive controller. We evaluate our method on\nthree simulated tasks where the goal is to estimate a desired object property\n(mass, height or toppling height) through physical interaction. We find that\nour method is able to discover policies that efficiently gather information\nabout the desired property in an intuitive manner. Finally, we validate our\nmethod on a real robot system for the height estimation task, where our method\nis able to successfully learn and execute an information-gathering policy from\nscratch.",
            "author": [
                "Jean-Fran\u00e7ois Tremblay",
                "David Meger",
                "Francois Hogan",
                "Gregory Dudek"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00215v1",
                "http://arxiv.org/pdf/2312.00215v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00214v1",
            "title": "Relevance-guided Neural Machine Translation",
            "updated": "2023-11-30T21:52:02Z",
            "published": "2023-11-30T21:52:02Z",
            "summary": "With the advent of the Transformer architecture, Neural Machine Translation\n(NMT) results have shown great improvement lately. However, results in\nlow-resource conditions still lag behind in both bilingual and multilingual\nsetups, due to the limited amount of available monolingual and/or parallel\ndata; hence, the need for methods addressing data scarcity in an efficient, and\nexplainable way, is eminent. We propose an explainability-based training\napproach for NMT, applied in Unsupervised and Supervised model training, for\ntranslation of three languages of varying resources, French, Gujarati, Kazakh,\nto and from English. Our results show our method can be promising, particularly\nwhen training in low-resource conditions, outperforming simple training\nbaselines; though the improvement is marginal, it sets the ground for further\nexploration of the approach and the parameters, and its extension to other\nlanguages.",
            "author": [
                "Isidora Chara Tourni",
                "Derry Wijaya"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00214v1",
                "http://arxiv.org/pdf/2312.00214v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00209v2",
            "title": "On the Interplay Between Stepsize Tuning and Progressive Sharpening",
            "updated": "2023-12-07T08:57:50Z",
            "published": "2023-11-30T21:42:15Z",
            "summary": "Recent empirical work has revealed an intriguing property of deep learning\nmodels by which the sharpness (largest eigenvalue of the Hessian) increases\nthroughout optimization until it stabilizes around a critical value at which\nthe optimizer operates at the edge of stability, given a fixed stepsize (Cohen\net al, 2022). We investigate empirically how the sharpness evolves when using\nstepsize-tuners, the Armijo linesearch and Polyak stepsizes, that adapt the\nstepsize along the iterations to local quantities such as, implicitly, the\nsharpness itself. We find that the surprisingly poor performance of a classical\nArmijo linesearch may be well explained by its tendency to ever-increase the\nsharpness of the objective in the full or large batch regimes. On the other\nhand, we observe that Polyak stepsizes operate generally at the edge of\nstability or even slightly beyond, while outperforming its Armijo and constant\nstepsizes counterparts. We conclude with an analysis that suggests unlocking\nstepsize tuners requires an understanding of the joint dynamics of the step\nsize and the sharpness.",
            "author": [
                "Vincent Roulet",
                "Atish Agarwala",
                "Fabian Pedregosa"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00209v2",
                "http://arxiv.org/pdf/2312.00209v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00207v1",
            "title": "EpiTESTER: Testing Autonomous Vehicles with Epigenetic Algorithm and\n  Attention Mechanism",
            "updated": "2023-11-30T21:40:14Z",
            "published": "2023-11-30T21:40:14Z",
            "summary": "Testing autonomous vehicles (AVs) under various environmental scenarios that\nlead the vehicles to unsafe situations is known to be challenging. Given the\ninfinite possible environmental scenarios, it is essential to find critical\nscenarios efficiently. To this end, we propose a novel testing method, named\nEpiTESTER, by taking inspiration from epigenetics, which enables species to\nadapt to sudden environmental changes. In particular, EpiTESTER adopts gene\nsilencing as its epigenetic mechanism, which regulates gene expression to\nprevent the expression of a certain gene, and the probability of gene\nexpression is dynamically computed as the environment changes. Given different\ndata modalities (e.g., images, lidar point clouds) in the context of AV,\nEpiTESTER benefits from a multi-model fusion transformer to extract high-level\nfeature representations from environmental factors and then calculates\nprobabilities based on these features with the attention mechanism. To assess\nthe cost-effectiveness of EpiTESTER, we compare it with a classical genetic\nalgorithm (GA) (i.e., without any epigenetic mechanism implemented) and\nEpiTESTER with equal probability for each gene. We evaluate EpiTESTER with four\ninitial environments from CARLA, an open-source simulator for autonomous\ndriving research, and an end-to-end AV controller, Interfuser. Our results show\nthat EpiTESTER achieved a promising performance in identifying critical\nscenarios compared to the baselines, showing that applying epigenetic\nmechanisms is a good option for solving practical problems.",
            "author": [
                "Chengjie Lu",
                "Shaukat Ali",
                "Tao Yue"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00207v1",
                "http://arxiv.org/pdf/2312.00207v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00206v1",
            "title": "SparseGS: Real-Time 360\u00b0 Sparse View Synthesis using Gaussian\n  Splatting",
            "updated": "2023-11-30T21:38:22Z",
            "published": "2023-11-30T21:38:22Z",
            "summary": "The problem of novel view synthesis has grown significantly in popularity\nrecently with the introduction of Neural Radiance Fields (NeRFs) and other\nimplicit scene representation methods. A recent advance, 3D Gaussian Splatting\n(3DGS), leverages an explicit representation to achieve real-time rendering\nwith high-quality results. However, 3DGS still requires an abundance of\ntraining views to generate a coherent scene representation. In few shot\nsettings, similar to NeRF, 3DGS tends to overfit to training views, causing\nbackground collapse and excessive floaters, especially as the number of\ntraining views are reduced. We propose a method to enable training coherent\n3DGS-based radiance fields of 360 scenes from sparse training views. We find\nthat using naive depth priors is not sufficient and integrate depth priors with\ngenerative and explicit constraints to reduce background collapse, remove\nfloaters, and enhance consistency from unseen viewpoints. Experiments show that\nour method outperforms base 3DGS by up to 30.5% and NeRF-based methods by up to\n15.6% in LPIPS on the MipNeRF-360 dataset with substantially less training and\ninference cost.",
            "author": [
                "Haolin Xiong",
                "Sairisheek Muttukuru",
                "Rishi Upadhyay",
                "Pradyumna Chari",
                "Achuta Kadambi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00206v1",
                "http://arxiv.org/pdf/2312.00206v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00201v1",
            "title": "An integrated framework for developing and evaluating an automated\n  lecture style assessment system",
            "updated": "2023-11-30T21:31:21Z",
            "published": "2023-11-30T21:31:21Z",
            "summary": "The aim of the work presented in this paper is to develop and evaluate an\nintegrated system that provides automated lecture style evaluation, allowing\nteachers to get instant feedback related to the goodness of their lecturing\nstyle. The proposed system aims to promote improvement of lecture quality, that\ncould upgrade the overall student learning experience. The proposed application\nutilizes specific measurable biometric characteristics, such as facial\nexpressions, body activity, speech rate and intonation, hand movement, and\nfacial pose, extracted from a video showing the lecturer from the audience\npoint of view. Measurable biometric features extracted during a lecture are\ncombined to provide teachers with a score reflecting lecture style quality both\nat frame rate and by providing lecture quality metrics for the whole lecture.\nThe acceptance of the proposed lecture style evaluation system was evaluated by\nchief education officers, teachers and students regarding the functionality,\nusefulness of the application, and possible improvements. The results indicate\nthat participants found the application novel and useful in providing automated\nfeedback regarding lecture quality. Furthermore, the performance evaluation of\nthe proposed system was compared with the performance of humans in the task of\nlecture style evaluation. Results indicate that the proposed system not only\nachieves similar performance to human observers, but in some cases, it\noutperforms them.",
            "author": [
                "Eleni Dimitriadou",
                "Andreas Lanitis"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00201v1",
                "http://arxiv.org/pdf/2312.00201v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03748v1",
            "title": "Applying Large Language Models and Chain-of-Thought for Automatic\n  Scoring",
            "updated": "2023-11-30T21:22:43Z",
            "published": "2023-11-30T21:22:43Z",
            "summary": "This study investigates the application of large language models (LLMs),\nspecifically GPT-3.5 and GPT-4, with Chain-of-Though (CoT)in the automatic\nscoring of student-written responses to science assessments. We focused on\novercoming the challenges of accessibility, technical complexity, and lack of\nexplainability that have previously limited the use of automatic assessment\ntools among researchers and educators. We used a testing dataset comprising six\nassessment tasks (three binomial and three trinomial) with 1,650 student\nresponses. We employed six prompt engineering strategies, combining zero-shot\nor few-shot learning with CoT, either alone or alongside item stem and scoring\nrubrics. Results indicated that few-shot (acc = .67) outperformed zero-shot\nlearning (acc = .60), with 12.6\\% increase. CoT, when used without item stem\nand scoring rubrics, did not significantly affect scoring accuracy (acc = .60).\nHowever, CoT prompting paired with contextual item stems and rubrics proved to\nbe a significant contributor to scoring accuracy (13.44\\% increase for\nzero-shot; 3.7\\% increase for few-shot). Using a novel approach PPEAS, we found\na more balanced accuracy across different proficiency categories, highlighting\nthe importance of domain-specific reasoning in enhancing the effectiveness of\nLLMs in scoring tasks. Additionally, we also found that GPT-4 demonstrated\nsuperior performance over GPT-3.5 in various scoring tasks, showing 8.64\\%\ndifference. The study revealed that the single-call strategy with GPT-4,\nparticularly using greedy sampling, outperformed other approaches, including\nensemble voting strategies. This study demonstrates the potential of LLMs in\nfacilitating automatic scoring, emphasizing that CoT enhances accuracy,\nparticularly when used with item stem and scoring rubrics.",
            "author": [
                "Gyeong-Geon Lee",
                "Ehsan Latif",
                "Xuansheng Wu",
                "Ninghao Liu",
                "Xiaoming Zhai"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03748v1",
                "http://arxiv.org/pdf/2312.03748v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00198v1",
            "title": "Optimal Attack and Defense for Reinforcement Learning",
            "updated": "2023-11-30T21:21:47Z",
            "published": "2023-11-30T21:21:47Z",
            "summary": "To ensure the usefulness of Reinforcement Learning (RL) in real systems, it\nis crucial to ensure they are robust to noise and adversarial attacks. In\nadversarial RL, an external attacker has the power to manipulate the victim\nagent's interaction with the environment. We study the full class of online\nmanipulation attacks, which include (i) state attacks, (ii) observation attacks\n(which are a generalization of perceived-state attacks), (iii) action attacks,\nand (iv) reward attacks. We show the attacker's problem of designing a stealthy\nattack that maximizes its own expected reward, which often corresponds to\nminimizing the victim's value, is captured by a Markov Decision Process (MDP)\nthat we call a meta-MDP since it is not the true environment but a higher level\nenvironment induced by the attacked interaction. We show that the attacker can\nderive optimal attacks by planning in polynomial time or learning with\npolynomial sample complexity using standard RL techniques. We argue that the\noptimal defense policy for the victim can be computed as the solution to a\nstochastic Stackelberg game, which can be further simplified into a\npartially-observable turn-based stochastic game (POTBSG). Neither the attacker\nnor the victim would benefit from deviating from their respective optimal\npolicies, thus such solutions are truly robust. Although the defense problem is\nNP-hard, we show that optimal Markovian defenses can be computed (learned) in\npolynomial time (sample complexity) in many scenarios.",
            "author": [
                "Jeremy McMahan",
                "Young Wu",
                "Xiaojin Zhu",
                "Qiaomin Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00198v1",
                "http://arxiv.org/pdf/2312.00198v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00194v1",
            "title": "Robust Concept Erasure via Kernelized Rate-Distortion Maximization",
            "updated": "2023-11-30T21:10:44Z",
            "published": "2023-11-30T21:10:44Z",
            "summary": "Distributed representations provide a vector space that captures meaningful\nrelationships between data instances. The distributed nature of these\nrepresentations, however, entangles together multiple attributes or concepts of\ndata instances (e.g., the topic or sentiment of a text, characteristics of the\nauthor (age, gender, etc), etc). Recent work has proposed the task of concept\nerasure, in which rather than making a concept predictable, the goal is to\nremove an attribute from distributed representations while retaining other\ninformation from the original representation space as much as possible. In this\npaper, we propose a new distance metric learning-based objective, the\nKernelized Rate-Distortion Maximizer (KRaM), for performing concept erasure.\nKRaM fits a transformation of representations to match a specified distance\nmeasure (defined by a labeled concept to erase) using a modified\nrate-distortion function. Specifically, KRaM's objective function aims to make\ninstances with similar concept labels dissimilar in the learned representation\nspace while retaining other information. We find that optimizing KRaM\neffectively erases various types of concepts: categorical, continuous, and\nvector-valued variables from data representations across diverse domains. We\nalso provide a theoretical analysis of several properties of KRaM's objective.\nTo assess the quality of the learned representations, we propose an alignment\nscore to evaluate their similarity with the original representation space.\nAdditionally, we conduct experiments to showcase KRaM's efficacy in various\nsettings, from erasing binary gender variables in word embeddings to\nvector-valued variables in GPT-3 representations.",
            "author": [
                "Somnath Basu Roy Chowdhury",
                "Nicholas Monath",
                "Avinava Dubey",
                "Amr Ahmed",
                "Snigdha Chaturvedi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00194v1",
                "http://arxiv.org/pdf/2312.00194v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00192v1",
            "title": "Benchmarking and Enhancing Disentanglement in Concept-Residual Models",
            "updated": "2023-11-30T21:07:26Z",
            "published": "2023-11-30T21:07:26Z",
            "summary": "Concept bottleneck models (CBMs) are interpretable models that first predict\na set of semantically meaningful features, i.e., concepts, from observations\nthat are subsequently used to condition a downstream task. However, the model's\nperformance strongly depends on the engineered features and can severely suffer\nfrom incomplete sets of concepts. Prior works have proposed a side channel -- a\nresidual -- that allows for unconstrained information flow to the downstream\ntask, thus improving model performance but simultaneously introducing\ninformation leakage, which is undesirable for interpretability. This work\nproposes three novel approaches to mitigate information leakage by\ndisentangling concepts and residuals, investigating the critical balance\nbetween model performance and interpretability. Through extensive empirical\nanalysis on the CUB, OAI, and CIFAR 100 datasets, we assess the performance of\neach disentanglement method and provide insights into when they work best.\nFurther, we show how each method impacts the ability to intervene over the\nconcepts and their subsequent impact on task performance.",
            "author": [
                "Renos Zabounidis",
                "Ini Oguntola",
                "Konghao Zhao",
                "Joseph Campbell",
                "Simon Stepputtis",
                "Katia Sycara"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00192v1",
                "http://arxiv.org/pdf/2312.00192v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00191v1",
            "title": "Enhancing Ligand Pose Sampling for Molecular Docking",
            "updated": "2023-11-30T21:02:37Z",
            "published": "2023-11-30T21:02:37Z",
            "summary": "Deep learning promises to dramatically improve scoring functions for\nmolecular docking, leading to substantial advances in binding pose prediction\nand virtual screening. To train scoring functions-and to perform molecular\ndocking-one must generate a set of candidate ligand binding poses.\nUnfortunately, the sampling protocols currently used to generate candidate\nposes frequently fail to produce any poses close to the correct, experimentally\ndetermined pose, unless information about the correct pose is provided. This\nlimits the accuracy of learned scoring functions and molecular docking. Here,\nwe describe two improved protocols for pose sampling: GLOW (auGmented sampLing\nwith sOftened vdW potential) and a novel technique named IVES (IteratiVe\nEnsemble Sampling). Our benchmarking results demonstrate the effectiveness of\nour methods in improving the likelihood of sampling accurate poses, especially\nfor binding pockets whose shape changes substantially when different ligands\nbind. This improvement is observed across both experimentally determined and\nAlphaFold-generated protein structures. Additionally, we present datasets of\ncandidate ligand poses generated using our methods for each of around 5,000\nprotein-ligand cross-docking pairs, for training and testing scoring functions.\nTo benefit the research community, we provide these cross-docking datasets and\nan open-source Python implementation of GLOW and IVES at\nhttps://github.com/drorlab/GLOW_IVES .",
            "author": [
                "Patricia Suriana",
                "Ron O. Dror"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00191v1",
                "http://arxiv.org/pdf/2312.00191v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00189v1",
            "title": "HeTriNet: Heterogeneous Graph Triplet Attention Network for\n  Drug-Target-Disease Interaction",
            "updated": "2023-11-30T20:55:57Z",
            "published": "2023-11-30T20:55:57Z",
            "summary": "Modeling the interactions between drugs, targets, and diseases is paramount\nin drug discovery and has significant implications for precision medicine and\npersonalized treatments. Current approaches frequently consider drug-target or\ndrug-disease interactions individually, ignoring the interdependencies among\nall three entities. Within human metabolic systems, drugs interact with protein\ntargets in cells, influencing target activities and subsequently impacting\nbiological pathways to promote healthy functions and treat diseases. Moving\nbeyond binary relationships and exploring tighter triple relationships is\nessential to understanding drugs' mechanism of action (MoAs). Moreover,\nidentifying the heterogeneity of drugs, targets, and diseases, along with their\ndistinct characteristics, is critical to model these complex interactions\nappropriately. To address these challenges, we effectively model the\ninterconnectedness of all entities in a heterogeneous graph and develop a novel\nHeterogeneous Graph Triplet Attention Network (\\texttt{HeTriNet}).\n\\texttt{HeTriNet} introduces a novel triplet attention mechanism within this\nheterogeneous graph structure. Beyond pairwise attention as the importance of\nan entity for the other one, we define triplet attention to model the\nimportance of pairs for entities in the drug-target-disease triplet prediction\nproblem. Experimental results on real-world datasets show that\n\\texttt{HeTriNet} outperforms several baselines, demonstrating its remarkable\nproficiency in uncovering novel drug-target-disease relationships.",
            "author": [
                "Farhan Tanvir",
                "Khaled Mohammed Saifuddin",
                "Tanvir Hossain",
                "Arunkumar Bagavathi",
                "Esra Akbas"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00189v1",
                "http://arxiv.org/pdf/2312.00189v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "q-bio.BM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00184v1",
            "title": "Galaxy Classification: A machine learning approach for classifying\n  shapes using numerical data",
            "updated": "2023-11-30T20:47:16Z",
            "published": "2023-11-30T20:47:16Z",
            "summary": "The classification of galaxies as spirals or ellipticals is a crucial task in\nunderstanding their formation and evolution. With the arrival of large-scale\nastronomical surveys, such as the Sloan Digital Sky Survey (SDSS), astronomers\nnow have access to images of a vast number of galaxies. However, the visual\ninspection of these images is an impossible task for humans due to the sheer\nnumber of galaxies to be analyzed. To solve this problem, the Galaxy Zoo\nproject was created to engage thousands of citizen scientists to classify the\ngalaxies based on their visual features. In this paper, we present a machine\nlearning model for galaxy classification using numerical data from the Galaxy\nZoo[5] project. Our model utilizes a convolutional neural network architecture\nto extract features from galaxy images and classify them into spirals or\nellipticals. We demonstrate the effectiveness of our model by comparing its\nperformance with that of human classifiers using a subset of the Galaxy Zoo\ndataset. Our results show that our model achieves high accuracy in classifying\ngalaxies and has the potential to significantly enhance our understanding of\nthe formation and evolution of galaxies.",
            "author": [
                "Anusha Guruprasad"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00184v1",
                "http://arxiv.org/pdf/2312.00184v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00175v1",
            "title": "Advances in soft grasping in agriculture",
            "updated": "2023-11-30T20:16:48Z",
            "published": "2023-11-30T20:16:48Z",
            "summary": "Agricultural robotics and automation are facing some challenges rooted in the\nhigh variability 9 of products, task complexity, crop quality requirement, and\ndense vegetation. Such a set of 10 challenges demands a more versatile and safe\nrobotic system. Soft robotics is a young yet 11 promising field of research\naimed to enhance these aspects of current rigid robots which 12 makes it a good\ncandidate solution for that challenge. In general, it aimed to provide robots\n13 and machines with adaptive locomotion (Ansari et al., 2015), safe and\nadaptive manipulation 14 (Arleo et al., 2020) and versatile grasping (Langowski\net al., 2020). But in agriculture, soft 15 robots have been mainly used in\nharvesting tasks and more specifically in grasping. In this 16 chapter, we\nreview a candidate group of soft grippers that were used for handling and 17\nharvesting crops regarding agricultural challenges i.e. safety in handling and\nadaptability to 18 the high variation of crops. The review is aimed to show why\nand to what extent soft grippers 19 have been successful in handling\nagricultural tasks. The analysis carried out on the results 20 provides future\ndirections for the systematic design of soft robots in agricultural tasks.",
            "author": [
                "Ali Leylavi Shoushtari"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00175v1",
                "http://arxiv.org/pdf/2312.00175v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00173v1",
            "title": "Fool the Hydra: Adversarial Attacks against Multi-view Object Detection\n  Systems",
            "updated": "2023-11-30T20:11:44Z",
            "published": "2023-11-30T20:11:44Z",
            "summary": "Adversarial patches exemplify the tangible manifestation of the threat posed\nby adversarial attacks on Machine Learning (ML) models in real-world scenarios.\nRobustness against these attacks is of the utmost importance when designing\ncomputer vision applications, especially for safety-critical domains such as\nCCTV systems. In most practical situations, monitoring open spaces requires\nmulti-view systems to overcome acquisition challenges such as occlusion\nhandling. Multiview object systems are able to combine data from multiple\nviews, and reach reliable detection results even in difficult environments.\nDespite its importance in real-world vision applications, the vulnerability of\nmultiview systems to adversarial patches is not sufficiently investigated. In\nthis paper, we raise the following question: Does the increased performance and\ninformation sharing across views offer as a by-product robustness to\nadversarial patches? We first conduct a preliminary analysis showing promising\nrobustness against off-the-shelf adversarial patches, even in an extreme\nsetting where we consider patches applied to all views by all persons in\nWildtrack benchmark. However, we challenged this observation by proposing two\nnew attacks: (i) In the first attack, targeting a multiview CNN, we maximize\nthe global loss by proposing gradient projection to the different views and\naggregating the obtained local gradients. (ii) In the second attack, we focus\non a Transformer-based multiview framework. In addition to the focal loss, we\nalso maximize the transformer-specific loss by dissipating its attention\nblocks. Our results show a large degradation in the detection performance of\nvictim multiview systems with our first patch attack reaching an attack success\nrate of 73% , while our second proposed attack reduced the performance of its\ntarget detector by 62%",
            "author": [
                "Bilel Tarchoun",
                "Quazi Mishkatul Alam",
                "Nael Abu-Ghazaleh",
                "Ihsen Alouani"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00173v1",
                "http://arxiv.org/pdf/2312.00173v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00170v1",
            "title": "Non-uniform Online Learning: Towards Understanding Induction",
            "updated": "2023-11-30T20:02:25Z",
            "published": "2023-11-30T20:02:25Z",
            "summary": "Can a physicist make only finite errors in the endless pursuit of the law of\nnature? This millennium-old question of inductive inference is a fundamental,\nyet mysterious problem in philosophy, lacking rigorous justifications. While\nclassic online learning theory and inductive inference share a similar\nsequential decision-making spirit, the former's reliance on an adaptive\nadversary and worst-case error bounds limits its applicability to the latter.\nIn this work, we introduce the concept of non-uniform online learning, which we\nargue aligns more closely with the principles of inductive reasoning. This\nsetting assumes a predetermined ground-truth hypothesis and considers\nnon-uniform, hypothesis-wise error bounds. In the realizable setting, we\nprovide a complete characterization of learnability with finite error: a\nhypothesis class is non-uniform learnable if and only if it's a countable union\nof Littlestone classes, no matter the observations are adaptively chosen or iid\nsampled. Additionally, we propose a necessary condition for the weaker\ncriterion of consistency which we conjecture to be tight. To further promote\nour theory, we extend our result to the more realistic agnostic setting,\nshowing that any countable union of Littlestone classes can be learnt with\nregret $\\tilde{O}(\\sqrt{T})$. We hope this work could offer a new perspective\nof interpreting the power of induction from an online learning viewpoint.",
            "author": [
                "Zhou Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00170v1",
                "http://arxiv.org/pdf/2312.00170v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00157v1",
            "title": "Universal Backdoor Attacks",
            "updated": "2023-11-30T19:37:47Z",
            "published": "2023-11-30T19:37:47Z",
            "summary": "Web-scraped datasets are vulnerable to data poisoning, which can be used for\nbackdooring deep image classifiers during training. Since training on large\ndatasets is expensive, a model is trained once and re-used many times. Unlike\nadversarial examples, backdoor attacks often target specific classes rather\nthan any class learned by the model. One might expect that targeting many\nclasses through a naive composition of attacks vastly increases the number of\npoison samples. We show this is not necessarily true and more efficient,\nuniversal data poisoning attacks exist that allow controlling\nmisclassifications from any source class into any target class with a small\nincrease in poison samples. Our idea is to generate triggers with salient\ncharacteristics that the model can learn. The triggers we craft exploit a\nphenomenon we call inter-class poison transferability, where learning a trigger\nfrom one class makes the model more vulnerable to learning triggers for other\nclasses. We demonstrate the effectiveness and robustness of our universal\nbackdoor attacks by controlling models with up to 6,000 classes while poisoning\nonly 0.15% of the training dataset.",
            "author": [
                "Benjamin Schneider",
                "Nils Lukas",
                "Florian Kerschbaum"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00157v1",
                "http://arxiv.org/pdf/2312.00157v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00827v1",
            "title": "A Unified Framework for Connecting Noise Modeling to Boost Noise\n  Detection",
            "updated": "2023-11-30T19:24:47Z",
            "published": "2023-11-30T19:24:47Z",
            "summary": "Noisy labels can impair model performance, making the study of learning with\nnoisy labels an important topic. Two conventional approaches are noise modeling\nand noise detection. However, these two methods are typically studied\nindependently, and there has been limited work on their collaboration. In this\nwork, we explore the integration of these two approaches, proposing an\ninterconnected structure with three crucial blocks: noise modeling, source\nknowledge identification, and enhanced noise detection using noise\nsource-knowledge-integration methods. This collaboration structure offers\nadvantages such as discriminating hard negatives and preserving genuinely clean\nlabels that might be suspiciously noisy. Our experiments on four datasets,\nfeaturing three types of noise and different combinations of each block,\ndemonstrate the efficacy of these components' collaboration. Our collaborative\nstructure methods achieve up to a 10% increase in top-1 classification accuracy\nin synthesized noise datasets and 3-5% in real-world noisy datasets. The\nresults also suggest that these components make distinct contributions to\noverall performance across various noise scenarios. These findings provide\nvaluable insights for designing noisy label learning methods customized for\nspecific noise scenarios in the future. Our code is accessible to the public.",
            "author": [
                "Siqi Wang",
                "Chau Pham",
                "Bryan A. Plummer"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00827v1",
                "http://arxiv.org/pdf/2312.00827v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00143v1",
            "title": "The ZTF Source Classification Project: III. A Catalog of Variable\n  Sources",
            "updated": "2023-11-30T19:05:10Z",
            "published": "2023-11-30T19:05:10Z",
            "summary": "The classification of variable objects provides insight into a wide variety\nof astrophysics ranging from stellar interiors to galactic nuclei. The Zwicky\nTransient Facility (ZTF) provides time series observations that record the\nvariability of more than a billion sources. The scale of these data\nnecessitates automated approaches to make a thorough analysis. Building on\nprevious work, this paper reports the results of the ZTF Source Classification\nProject (SCoPe), which trains neural network and XGBoost machine learning (ML)\nalgorithms to perform dichotomous classification of variable ZTF sources using\na manually constructed training set containing 170,632 light curves. We find\nthat several classifiers achieve high precision and recall scores, suggesting\nthe reliability of their predictions for 112,476,749 light curves across 40 ZTF\nfields. We also identify the most important features for XGB classification and\ncompare the performance of the two ML algorithms, finding a pattern of higher\nprecision among XGB classifiers. The resulting classification catalog is\navailable to the public, and the software developed for SCoPe is open-source\nand adaptable to future time-domain surveys.",
            "author": [
                "Brian F. Healy",
                "Michael W. Coughlin",
                "Ashish A. Mahabal",
                "Theophile J. du Laz",
                "Andrew Drake",
                "Matthew J. Graham",
                "Lynne A. Hillenbrand",
                "Jan van Roestel",
                "Paula Szkody",
                "LeighAnna Zielske",
                "Mohammed Guiga",
                "Muhammad Yusuf Hassan",
                "Jill L. Hughes",
                "Guy Nir",
                "Saagar Parikh",
                "Sungmin Park",
                "Palak Purohit",
                "Umaa Rebbapragada",
                "Draco Reed",
                "Avery Wold",
                "Joshua S. Bloom",
                "Frank J. Masci",
                "Reed Riddle",
                "Roger Smith"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00143v1",
                "http://arxiv.org/pdf/2312.00143v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00137v1",
            "title": "The Multiverse of Dynamic Mode Decomposition Algorithms",
            "updated": "2023-11-30T19:00:50Z",
            "published": "2023-11-30T19:00:50Z",
            "summary": "Dynamic Mode Decomposition (DMD) is a popular data-driven analysis technique\nused to decompose complex, nonlinear systems into a set of modes, revealing\nunderlying patterns and dynamics through spectral analysis. This review\npresents a comprehensive and pedagogical examination of DMD, emphasizing the\nrole of Koopman operators in transforming complex nonlinear dynamics into a\nlinear framework. A distinctive feature of this review is its focus on the\nrelationship between DMD and the spectral properties of Koopman operators, with\nparticular emphasis on the theory and practice of DMD algorithms for spectral\ncomputations. We explore the diverse \"multiverse\" of DMD methods, categorized\ninto three main areas: linear regression-based methods, Galerkin\napproximations, and structure-preserving techniques. Each category is studied\nfor its unique contributions and challenges, providing a detailed overview of\nsignificant algorithms and their applications as outlined in Table 1. We\ninclude a MATLAB package with examples and applications to enhance the\npractical understanding of these methods. This review serves as both a\npractical guide and a theoretical reference for various DMD methods, accessible\nto both experts and newcomers, and enabling readers to delve into their areas\nof interest in the expansive field of DMD.",
            "author": [
                "Matthew J. Colbrook"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00137v1",
                "http://arxiv.org/pdf/2312.00137v1"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS",
                "cs.LG",
                "cs.NA",
                "math.NA",
                "math.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00128v1",
            "title": "Low latency optical-based mode tracking with machine learning deployed\n  on FPGAs on a tokamak",
            "updated": "2023-11-30T19:00:03Z",
            "published": "2023-11-30T19:00:03Z",
            "summary": "Active feedback control in magnetic confinement fusion devices is desirable\nto mitigate plasma instabilities and enable robust operation. Optical\nhigh-speed cameras provide a powerful, non-invasive diagnostic and can be\nsuitable for these applications. In this study, we process fast camera data, at\nrates exceeding 100kfps, on $\\textit{in situ}$ Field Programmable Gate Array\n(FPGA) hardware to track magnetohydrodynamic (MHD) mode evolution and generate\ncontrol signals in real-time. Our system utilizes a convolutional neural\nnetwork (CNN) model which predicts the $n$=1 MHD mode amplitude and phase using\ncamera images with better accuracy than other tested non-deep-learning-based\nmethods. By implementing this model directly within the standard FPGA readout\nhardware of the high-speed camera diagnostic, our mode tracking system achieves\na total trigger-to-output latency of 17.6$\\mu$s and a throughput of up to\n120kfps. This study at the High Beta Tokamak-Extended Pulse (HBT-EP) experiment\ndemonstrates an FPGA-based high-speed camera data acquisition and processing\nsystem, enabling application in real-time machine-learning-based tokamak\ndiagnostic and control as well as potential applications in other scientific\ndomains.",
            "author": [
                "Yumou Wei",
                "Ryan F. Forelli",
                "Chris Hansen",
                "Jeffrey P. Levesque",
                "Nhan Tran",
                "Joshua C. Agar",
                "Giuseppe Di Guglielmo",
                "Michael E. Mauel",
                "Gerald A. Navratil"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00128v1",
                "http://arxiv.org/pdf/2312.00128v1"
            ],
            "primary_category": "physics.plasm-ph",
            "category": [
                "physics.plasm-ph",
                "cs.AR",
                "cs.LG",
                "physics.ins-det"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00123v1",
            "title": "Flow Matching Beyond Kinematics: Generating Jets with Particle-ID and\n  Trajectory Displacement Information",
            "updated": "2023-11-30T19:00:02Z",
            "published": "2023-11-30T19:00:02Z",
            "summary": "We introduce the first generative model trained on the JetClass dataset. Our\nmodel generates jets at the constituent level, and it is a\npermutation-equivariant continuous normalizing flow (CNF) trained with the flow\nmatching technique. It is conditioned on the jet type, so that a single model\ncan be used to generate the ten different jet types of JetClass. For the first\ntime, we also introduce a generative model that goes beyond the kinematic\nfeatures of jet constituents. The JetClass dataset includes more features, such\nas particle-ID and track impact parameter, and we demonstrate that our CNF can\naccurately model all of these additional features as well. Our generative model\nfor JetClass expands on the versatility of existing jet generation techniques,\nenhancing their potential utility in high-energy physics research, and offering\na more comprehensive understanding of the generated jets.",
            "author": [
                "Joschka Birk",
                "Erik Buhmann",
                "Cedric Ewen",
                "Gregor Kasieczka",
                "David Shih"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00123v1",
                "http://arxiv.org/pdf/2312.00123v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "cs.LG",
                "hep-ex",
                "physics.data-an"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00125v1",
            "title": "Scalable Bayesian uncertainty quantification with data-driven priors for\n  radio interferometric imaging",
            "updated": "2023-11-30T19:00:02Z",
            "published": "2023-11-30T19:00:02Z",
            "summary": "Next-generation radio interferometers like the Square Kilometer Array have\nthe potential to unlock scientific discoveries thanks to their unprecedented\nangular resolution and sensitivity. One key to unlocking their potential\nresides in handling the deluge and complexity of incoming data. This challenge\nrequires building radio interferometric imaging methods that can cope with the\nmassive data sizes and provide high-quality image reconstructions with\nuncertainty quantification (UQ). This work proposes a method coined QuantifAI\nto address UQ in radio-interferometric imaging with data-driven (learned)\npriors for high-dimensional settings. Our model, rooted in the Bayesian\nframework, uses a physically motivated model for the likelihood. The model\nexploits a data-driven convex prior, which can encode complex information\nlearned implicitly from simulations and guarantee the log-concavity of the\nposterior. We leverage probability concentration phenomena of high-dimensional\nlog-concave posteriors that let us obtain information about the posterior,\navoiding MCMC sampling techniques. We rely on convex optimisation methods to\ncompute the MAP estimation, which is known to be faster and better scale with\ndimension than MCMC sampling strategies. Our method allows us to compute local\ncredible intervals, i.e., Bayesian error bars, and perform hypothesis testing\nof structure on the reconstructed image. In addition, we propose a novel\nblazing-fast method to compute pixel-wise uncertainties at different scales. We\ndemonstrate our method by reconstructing radio-interferometric images in a\nsimulated setting and carrying out fast and scalable UQ, which we validate with\nMCMC sampling. Our method shows an improved image quality and more meaningful\nuncertainties than the benchmark method based on a sparsity-promoting prior.\nQuantifAI's source code: https://github.com/astro-informatics/QuantifAI.",
            "author": [
                "Tob\u00edas I. Liaudat",
                "Matthijs Mars",
                "Matthew A. Price",
                "Marcelo Pereyra",
                "Marta M. Betcke",
                "Jason D. McEwen"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00125v1",
                "http://arxiv.org/pdf/2312.00125v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00119v1",
            "title": "Anomaly Detection in Collider Physics via Factorized Observables",
            "updated": "2023-11-30T19:00:00Z",
            "published": "2023-11-30T19:00:00Z",
            "summary": "To maximize the discovery potential of high-energy colliders, experimental\nsearches should be sensitive to unforeseen new physics scenarios. This goal has\nmotivated the use of machine learning for unsupervised anomaly detection. In\nthis paper, we introduce a new anomaly detection strategy called FORCE:\nfactorized observables for regressing conditional expectations. Our approach is\nbased on the inductive bias of factorization, which is the idea that the\nphysics governing different energy scales can be treated as approximately\nindependent. Assuming factorization holds separately for signal and background\nprocesses, the appearance of non-trivial correlations between low- and\nhigh-energy observables is a robust indicator of new physics. Under the most\nrestrictive form of factorization, a machine-learned model trained to identify\nsuch correlations will in fact converge to the optimal new physics classifier.\nWe test FORCE on a benchmark anomaly detection task for the Large Hadron\nCollider involving collimated sprays of particles called jets. By teasing out\ncorrelations between the kinematics and substructure of jets, our method can\nreliably extract percent-level signal fractions. This strategy for uncovering\nnew physics adds to the growing toolbox of anomaly detection methods for\ncollider physics with a complementary set of assumptions.",
            "author": [
                "Eric M. Metodiev",
                "Jesse Thaler",
                "Raymond Wynne"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00119v1",
                "http://arxiv.org/pdf/2312.00119v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-ex",
                "physics.data-an"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00093v1",
            "title": "GraphDreamer: Compositional 3D Scene Synthesis from Scene Graphs",
            "updated": "2023-11-30T18:59:58Z",
            "published": "2023-11-30T18:59:58Z",
            "summary": "As pretrained text-to-image diffusion models become increasingly powerful,\nrecent efforts have been made to distill knowledge from these text-to-image\npretrained models for optimizing a text-guided 3D model. Most of the existing\nmethods generate a holistic 3D model from a plain text input. This can be\nproblematic when the text describes a complex scene with multiple objects,\nbecause the vectorized text embeddings are inherently unable to capture a\ncomplex description with multiple entities and relationships. Holistic 3D\nmodeling of the entire scene further prevents accurate grounding of text\nentities and concepts. To address this limitation, we propose GraphDreamer, a\nnovel framework to generate compositional 3D scenes from scene graphs, where\nobjects are represented as nodes and their interactions as edges. By exploiting\nnode and edge information in scene graphs, our method makes better use of the\npretrained text-to-image diffusion model and is able to fully disentangle\ndifferent objects without image-level supervision. To facilitate modeling of\nobject-wise relationships, we use signed distance fields as representation and\nimpose a constraint to avoid inter-penetration of objects. To avoid manual\nscene graph creation, we design a text prompt for ChatGPT to generate scene\ngraphs based on text inputs. We conduct both qualitative and quantitative\nexperiments to validate the effectiveness of GraphDreamer in generating\nhigh-fidelity compositional 3D scenes with disentangled object entities.",
            "author": [
                "Gege Gao",
                "Weiyang Liu",
                "Anpei Chen",
                "Andreas Geiger",
                "Bernhard Sch\u00f6lkopf"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00093v1",
                "http://arxiv.org/pdf/2312.00093v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18838v1",
            "title": "Dataset Distillation in Large Data Era",
            "updated": "2023-11-30T18:59:56Z",
            "published": "2023-11-30T18:59:56Z",
            "summary": "Dataset distillation aims to generate a smaller but representative subset\nfrom a large dataset, which allows a model to be trained efficiently, meanwhile\nevaluating on the original testing data distribution to achieve decent\nperformance. Many prior works have aimed to align with diverse aspects of the\noriginal datasets, such as matching the training weight trajectories, gradient,\nfeature/BatchNorm distributions, etc. In this work, we show how to distill\nvarious large-scale datasets such as full ImageNet-1K/21K under a conventional\ninput resolution of 224$\\times$224 to achieve the best accuracy over all\nprevious approaches, including SRe$^2$L, TESLA and MTT. To achieve this, we\nintroduce a simple yet effective ${\\bf C}$urriculum ${\\bf D}$ata ${\\bf\nA}$ugmentation ($\\texttt{CDA}$) during data synthesis that obtains the accuracy\non large-scale ImageNet-1K and 21K with 63.2% under IPC (Images Per Class) 50\nand 36.1% under IPC 20, respectively. Finally, we show that, by integrating all\nour enhancements together, the proposed model beats the current\nstate-of-the-art by more than 4% Top-1 accuracy on ImageNet-1K/21K and for the\nfirst time, reduces the gap to its full-data training counterpart to less than\nabsolute 15%. Moreover, this work represents the inaugural success in dataset\ndistillation on larger-scale ImageNet-21K under the standard 224$\\times$224\nresolution. Our code and distilled ImageNet-21K dataset of 20 IPC, 2K recovery\nbudget are available at https://github.com/VILA-Lab/SRe2L/tree/main/CDA.",
            "author": [
                "Zeyuan Yin",
                "Zhiqiang Shen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18838v1",
                "http://arxiv.org/pdf/2311.18838v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18839v1",
            "title": "TrafficMOT: A Challenging Dataset for Multi-Object Tracking in Complex\n  Traffic Scenarios",
            "updated": "2023-11-30T18:59:56Z",
            "published": "2023-11-30T18:59:56Z",
            "summary": "Multi-object tracking in traffic videos is a crucial research area, offering\nimmense potential for enhancing traffic monitoring accuracy and promoting road\nsafety measures through the utilisation of advanced machine learning\nalgorithms. However, existing datasets for multi-object tracking in traffic\nvideos often feature limited instances or focus on single classes, which cannot\nwell simulate the challenges encountered in complex traffic scenarios. To\naddress this gap, we introduce TrafficMOT, an extensive dataset designed to\nencompass diverse traffic situations with complex scenarios. To validate the\ncomplexity and challenges presented by TrafficMOT, we conducted comprehensive\nempirical studies using three different settings: fully-supervised,\nsemi-supervised, and a recent powerful zero-shot foundation model Tracking\nAnything Model (TAM). The experimental results highlight the inherent\ncomplexity of this dataset, emphasising its value in driving advancements in\nthe field of traffic monitoring and multi-object tracking.",
            "author": [
                "Lihao Liu",
                "Yanqi Cheng",
                "Zhongying Deng",
                "Shujun Wang",
                "Dongdong Chen",
                "Xiaowei Hu",
                "Pietro Li\u00f2",
                "Carola-Bibiane Sch\u00f6nlieb",
                "Angelica Aviles-Rivero"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18839v1",
                "http://arxiv.org/pdf/2311.18839v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18840v1",
            "title": "Just Add $\u03c0$! Pose Induced Video Transformers for Understanding\n  Activities of Daily Living",
            "updated": "2023-11-30T18:59:56Z",
            "published": "2023-11-30T18:59:56Z",
            "summary": "Video transformers have become the de facto standard for human action\nrecognition, yet their exclusive reliance on the RGB modality still limits\ntheir adoption in certain domains. One such domain is Activities of Daily\nLiving (ADL), where RGB alone is not sufficient to distinguish between visually\nsimilar actions, or actions observed from multiple viewpoints. To facilitate\nthe adoption of video transformers for ADL, we hypothesize that the\naugmentation of RGB with human pose information, known for its sensitivity to\nfine-grained motion and multiple viewpoints, is essential. Consequently, we\nintroduce the first Pose Induced Video Transformer: PI-ViT (or $\\pi$-ViT), a\nnovel approach that augments the RGB representations learned by video\ntransformers with 2D and 3D pose information. The key elements of $\\pi$-ViT are\ntwo plug-in modules, 2D Skeleton Induction Module and 3D Skeleton Induction\nModule, that are responsible for inducing 2D and 3D pose information into the\nRGB representations. These modules operate by performing pose-aware auxiliary\ntasks, a design choice that allows $\\pi$-ViT to discard the modules during\ninference. Notably, $\\pi$-ViT achieves the state-of-the-art performance on\nthree prominent ADL datasets, encompassing both real-world and large-scale\nRGB-D datasets, without requiring poses or additional computational overhead at\ninference.",
            "author": [
                "Dominick Reilly",
                "Srijan Das"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18840v1",
                "http://arxiv.org/pdf/2311.18840v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18837v1",
            "title": "VIDiff: Translating Videos via Multi-Modal Instructions with Diffusion\n  Models",
            "updated": "2023-11-30T18:59:52Z",
            "published": "2023-11-30T18:59:52Z",
            "summary": "Diffusion models have achieved significant success in image and video\ngeneration. This motivates a growing interest in video editing tasks, where\nvideos are edited according to provided text descriptions. However, most\nexisting approaches only focus on video editing for short clips and rely on\ntime-consuming tuning or inference. We are the first to propose Video\nInstruction Diffusion (VIDiff), a unified foundation model designed for a wide\nrange of video tasks. These tasks encompass both understanding tasks (such as\nlanguage-guided video object segmentation) and generative tasks (video editing\nand enhancement). Our model can edit and translate the desired results within\nseconds based on user instructions. Moreover, we design an iterative\nauto-regressive method to ensure consistency in editing and enhancing long\nvideos. We provide convincing generative results for diverse input videos and\nwritten instructions, both qualitatively and quantitatively. More examples can\nbe found at our website https://ChenHsing.github.io/VIDiff.",
            "author": [
                "Zhen Xing",
                "Qi Dai",
                "Zihao Zhang",
                "Hui Zhang",
                "Han Hu",
                "Zuxuan Wu",
                "Yu-Gang Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18837v1",
                "http://arxiv.org/pdf/2311.18837v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00116v1",
            "title": "S2ST: Image-to-Image Translation in the Seed Space of Latent Diffusion",
            "updated": "2023-11-30T18:59:49Z",
            "published": "2023-11-30T18:59:49Z",
            "summary": "Image-to-image translation (I2IT) refers to the process of transforming\nimages from a source domain to a target domain while maintaining a fundamental\nconnection in terms of image content. In the past few years, remarkable\nadvancements in I2IT were achieved by Generative Adversarial Networks (GANs),\nwhich nevertheless struggle with translations requiring high precision.\nRecently, Diffusion Models have established themselves as the engine of choice\nfor image generation. In this paper we introduce S2ST, a novel framework\ndesigned to accomplish global I2IT in complex photorealistic images, such as\nday-to-night or clear-to-rain translations of automotive scenes. S2ST operates\nwithin the seed space of a Latent Diffusion Model, thereby leveraging the\npowerful image priors learned by the latter. We show that S2ST surpasses\nstate-of-the-art GAN-based I2IT methods, as well as diffusion-based approaches,\nfor complex automotive scenes, improving fidelity while respecting the target\ndomain's appearance across a variety of domains. Notably, S2ST obviates the\nnecessity for training domain-specific translation networks.",
            "author": [
                "Or Greenberg",
                "Eran Kishon",
                "Dani Lischinski"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00116v1",
                "http://arxiv.org/pdf/2312.00116v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18834v1",
            "title": "ART$\\boldsymbol{\\cdot}$V: Auto-Regressive Text-to-Video Generation with\n  Diffusion Models",
            "updated": "2023-11-30T18:59:47Z",
            "published": "2023-11-30T18:59:47Z",
            "summary": "We present ART$\\boldsymbol{\\cdot}$V, an efficient framework for\nauto-regressive video generation with diffusion models. Unlike existing methods\nthat generate entire videos in one-shot, ART$\\boldsymbol{\\cdot}$V generates a\nsingle frame at a time, conditioned on the previous ones. The framework offers\nthree distinct advantages. First, it only learns simple continual motions\nbetween adjacent frames, therefore avoiding modeling complex long-range motions\nthat require huge training data. Second, it preserves the high-fidelity\ngeneration ability of the pre-trained image diffusion models by making only\nminimal network modifications. Third, it can generate arbitrarily long videos\nconditioned on a variety of prompts such as text, image or their combinations,\nmaking it highly versatile and flexible. To combat the common drifting issue in\nAR models, we propose masked diffusion model which implicitly learns which\ninformation can be drawn from reference images rather than network predictions,\nin order to reduce the risk of generating inconsistent appearances that cause\ndrifting. Moreover, we further enhance generation coherence by conditioning it\non the initial frame, which typically contains minimal noise. This is\nparticularly useful for long video generation. When trained for only two weeks\non four GPUs, ART$\\boldsymbol{\\cdot}$V already can generate videos with natural\nmotions, rich details and a high level of aesthetic quality. Besides, it\nenables various appealing applications, e.g., composing a long video from\nmultiple text prompts.",
            "author": [
                "Wenming Weng",
                "Ruoyu Feng",
                "Yanhui Wang",
                "Qi Dai",
                "Chunyu Wang",
                "Dacheng Yin",
                "Zhiyuan Zhao",
                "Kai Qiu",
                "Jianmin Bao",
                "Yuhui Yuan",
                "Chong Luo",
                "Yueyi Zhang",
                "Zhiwei Xiong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18834v1",
                "http://arxiv.org/pdf/2311.18834v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00115v1",
            "title": "A Video is Worth 10,000 Words: Training and Benchmarking with Diverse\n  Captions for Better Long Video Retrieval",
            "updated": "2023-11-30T18:59:45Z",
            "published": "2023-11-30T18:59:45Z",
            "summary": "Existing long video retrieval systems are trained and tested in the\nparagraph-to-video retrieval regime, where every long video is described by a\nsingle long paragraph. This neglects the richness and variety of possible valid\ndescriptions of a video, which could be described in moment-by-moment detail,\nor in a single phrase summary, or anything in between. To provide a more\nthorough evaluation of the capabilities of long video retrieval systems, we\npropose a pipeline that leverages state-of-the-art large language models to\ncarefully generate a diverse set of synthetic captions for long videos. We\nvalidate this pipeline's fidelity via rigorous human inspection. We then\nbenchmark a representative set of video language models on these synthetic\ncaptions using a few long video datasets, showing that they struggle with the\ntransformed data, especially the shortest captions. We also propose a\nlightweight fine-tuning method, where we use a contrastive loss to learn a\nhierarchical embedding loss based on the differing levels of information among\nthe various captions. Our method improves performance both on the downstream\nparagraph-to-video retrieval task (+1.1% R@1 on ActivityNet), as well as for\nthe various long video retrieval metrics we compute using our synthetic data\n(+3.6% R@1 for short descriptions on ActivityNet). For data access and other\ndetails, please refer to our project website at\nhttps://mgwillia.github.io/10k-words.",
            "author": [
                "Matthew Gwilliam",
                "Michael Cogswell",
                "Meng Ye",
                "Karan Sikka",
                "Abhinav Shrivastava",
                "Ajay Divakaran"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00115v1",
                "http://arxiv.org/pdf/2312.00115v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18829v1",
            "title": "MicroCinema: A Divide-and-Conquer Approach for Text-to-Video Generation",
            "updated": "2023-11-30T18:59:30Z",
            "published": "2023-11-30T18:59:30Z",
            "summary": "We present MicroCinema, a straightforward yet effective framework for\nhigh-quality and coherent text-to-video generation. Unlike existing approaches\nthat align text prompts with video directly, MicroCinema introduces a\nDivide-and-Conquer strategy which divides the text-to-video into a two-stage\nprocess: text-to-image generation and image\\&text-to-video generation. This\nstrategy offers two significant advantages. a) It allows us to take full\nadvantage of the recent advances in text-to-image models, such as Stable\nDiffusion, Midjourney, and DALLE, to generate photorealistic and highly\ndetailed images. b) Leveraging the generated image, the model can allocate less\nfocus to fine-grained appearance details, prioritizing the efficient learning\nof motion dynamics. To implement this strategy effectively, we introduce two\ncore designs. First, we propose the Appearance Injection Network, enhancing the\npreservation of the appearance of the given image. Second, we introduce the\nAppearance Noise Prior, a novel mechanism aimed at maintaining the capabilities\nof pre-trained 2D diffusion models. These design elements empower MicroCinema\nto generate high-quality videos with precise motion, guided by the provided\ntext prompts. Extensive experiments demonstrate the superiority of the proposed\nframework. Concretely, MicroCinema achieves SOTA zero-shot FVD of 342.86 on\nUCF-101 and 377.40 on MSR-VTT. See\nhttps://wangyanhui666.github.io/MicroCinema.github.io/ for video samples.",
            "author": [
                "Yanhui Wang",
                "Jianmin Bao",
                "Wenming Weng",
                "Ruoyu Feng",
                "Dacheng Yin",
                "Tao Yang",
                "Jingxu Zhang",
                "Qi Dai Zhiyuan Zhao",
                "Chunyu Wang",
                "Kai Qiu",
                "Yuhui Yuan",
                "Xiaoyan Sun",
                "Chong Luo",
                "Baining Guo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18829v1",
                "http://arxiv.org/pdf/2311.18829v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00112v1",
            "title": "DynMF: Neural Motion Factorization for Real-time Dynamic View Synthesis\n  with 3D Gaussian Splatting",
            "updated": "2023-11-30T18:59:11Z",
            "published": "2023-11-30T18:59:11Z",
            "summary": "Accurately and efficiently modeling dynamic scenes and motions is considered\nso challenging a task due to temporal dynamics and motion complexity. To\naddress these challenges, we propose DynMF, a compact and efficient\nrepresentation that decomposes a dynamic scene into a few neural trajectories.\nWe argue that the per-point motions of a dynamic scene can be decomposed into a\nsmall set of explicit or learned trajectories. Our carefully designed neural\nframework consisting of a tiny set of learned basis queried only in time allows\nfor rendering speed similar to 3D Gaussian Splatting, surpassing 120 FPS, while\nat the same time, requiring only double the storage compared to static scenes.\nOur neural representation adequately constrains the inherently underconstrained\nmotion field of a dynamic scene leading to effective and fast optimization.\nThis is done by biding each point to motion coefficients that enforce the\nper-point sharing of basis trajectories. By carefully applying a sparsity loss\nto the motion coefficients, we are able to disentangle the motions that\ncomprise the scene, independently control them, and generate novel motion\ncombinations that have never been seen before. We can reach state-of-the-art\nrender quality within just 5 minutes of training and in less than half an hour,\nwe can synthesize novel views of dynamic scenes with superior photorealistic\nquality. Our representation is interpretable, efficient, and expressive enough\nto offer real-time view synthesis of complex dynamic scene motions, in\nmonocular and multi-view scenarios.",
            "author": [
                "Agelos Kratimenos",
                "Jiahui Lei",
                "Kostas Daniilidis"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00112v1",
                "http://arxiv.org/pdf/2312.00112v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18827v1",
            "title": "Motion-Conditioned Image Animation for Video Editing",
            "updated": "2023-11-30T18:59:06Z",
            "published": "2023-11-30T18:59:06Z",
            "summary": "We introduce MoCA, a Motion-Conditioned Image Animation approach for video\nediting. It leverages a simple decomposition of the video editing problem into\nimage editing followed by motion-conditioned image animation. Furthermore,\ngiven the lack of robust evaluation datasets for video editing, we introduce a\nnew benchmark that measures edit capability across a wide variety of tasks,\nsuch as object replacement, background changes, style changes, and motion\nedits. We present a comprehensive human evaluation of the latest video editing\nmethods along with MoCA, on our proposed benchmark. MoCA establishes a new\nstate-of-the-art, demonstrating greater human preference win-rate, and\noutperforming notable recent approaches including Dreamix (63%), MasaCtrl\n(75%), and Tune-A-Video (72%), with especially significant improvements for\nmotion edits.",
            "author": [
                "Wilson Yan",
                "Andrew Brown",
                "Pieter Abbeel",
                "Rohit Girdhar",
                "Samaneh Azadi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18827v1",
                "http://arxiv.org/pdf/2311.18827v1"
            ],
            "primary_category": "cs.GR",
            "category": [
                "cs.GR",
                "cs.AI",
                "cs.CV",
                "cs.LG",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18826v2",
            "title": "Geometry-Aware Normalizing Wasserstein Flows for Optimal Causal\n  Inference",
            "updated": "2023-12-05T18:57:28Z",
            "published": "2023-11-30T18:59:05Z",
            "summary": "This manuscript enriches the framework of continuous normalizing flows (CNFs)\nwithin causal inference, primarily to augment the geometric properties of\nparametric submodels used in targeted maximum likelihood estimation (TMLE). By\nintroducing an innovative application of CNFs, we construct a refined series of\nparametric submodels that enable a directed interpolation between the prior\ndistribution $p_0$ and the empirical distribution $p_1$. This proposed\nmethodology serves to optimize the semiparametric efficiency bound in causal\ninference by orchestrating CNFs to align with Wasserstein gradient flows. Our\napproach not only endeavors to minimize the mean squared error in the\nestimation but also imbues the estimators with geometric sophistication,\nthereby enhancing robustness against misspecification. This robustness is\ncrucial, as it alleviates the dependence on the standard $n^{\\frac{1}{4}}$ rate\nfor a doubly-robust perturbation direction in TMLE. By incorporating robust\noptimization principles and differential geometry into the estimators, the\ndeveloped geometry-aware CNFs represent a significant advancement in the\npursuit of doubly robust causal inference.",
            "author": [
                "Kaiwen Hou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18826v2",
                "http://arxiv.org/pdf/2311.18826v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00826v1",
            "title": "DEVIAS: Learning Disentangled Video Representations of Action and Scene\n  for Holistic Video Understanding",
            "updated": "2023-11-30T18:58:44Z",
            "published": "2023-11-30T18:58:44Z",
            "summary": "When watching a video, humans can naturally extract human actions from the\nsurrounding scene context, even when action-scene combinations are unusual.\nHowever, unlike humans, video action recognition models often learn\nscene-biased action representations from the spurious correlation in training\ndata, leading to poor performance in out-of-context scenarios. While\nscene-debiased models achieve improved performance in out-of-context scenarios,\nthey often overlook valuable scene information in the data. Addressing this\nchallenge, we propose Disentangled VIdeo representations of Action and Scene\n(DEVIAS), which aims to achieve holistic video understanding. Disentangled\naction and scene representations with our method could provide flexibility to\nadjust the emphasis on action or scene information depending on downstream task\nand dataset characteristics. Disentangled action and scene representations\ncould be beneficial for both in-context and out-of-context video understanding.\nTo this end, we employ slot attention to learn disentangled action and scene\nrepresentations with a single model, along with auxiliary tasks that further\nguide slot attention. We validate the proposed method on both in-context\ndatasets: UCF-101 and Kinetics-400, and out-of-context datasets: SCUBA and HAT.\nOur proposed method shows favorable performance across different datasets\ncompared to the baselines, demonstrating its effectiveness in diverse video\nunderstanding scenarios.",
            "author": [
                "Kyungho Bae",
                "Geo Ahn",
                "Youngrae Kim",
                "Jinwoo Choi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00826v1",
                "http://arxiv.org/pdf/2312.00826v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18824v1",
            "title": "An Adaptive Framework for Generalizing Network Traffic Prediction\n  towards Uncertain Environments",
            "updated": "2023-11-30T18:58:38Z",
            "published": "2023-11-30T18:58:38Z",
            "summary": "We have developed a new framework using time-series analysis for dynamically\nassigning mobile network traffic prediction models in previously unseen\nwireless environments. Our framework selectively employs learned behaviors,\noutperforming any single model with over a 50% improvement relative to current\nstudies. More importantly, it surpasses traditional approaches without needing\nprior knowledge of a cell. While this paper focuses on network traffic\nprediction using our adaptive forecasting framework, this framework can also be\napplied to other machine learning applications in uncertain environments.\n  The framework begins with unsupervised clustering of time-series data to\nidentify unique trends and seasonal patterns. Subsequently, we apply supervised\nlearning for traffic volume prediction within each cluster. This specialization\ntowards specific traffic behaviors occurs without penalties from spatial and\ntemporal variations. Finally, the framework adaptively assigns trained models\nto new, previously unseen cells. By analyzing real-time measurements of a cell,\nour framework intelligently selects the most suitable cluster for that cell at\nany given time, with cluster assignment dynamically adjusting to\nspatio-temporal fluctuations.",
            "author": [
                "Alexander Downey",
                "Evren Tuna",
                "Alkan Soysal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18824v1",
                "http://arxiv.org/pdf/2311.18824v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.LG",
                "cs.NI",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18823v1",
            "title": "Initializing Models with Larger Ones",
            "updated": "2023-11-30T18:58:26Z",
            "published": "2023-11-30T18:58:26Z",
            "summary": "Weight initialization plays an important role in neural network training.\nWidely used initialization methods are proposed and evaluated for networks that\nare trained from scratch. However, the growing number of pretrained models now\noffers new opportunities for tackling this classical problem of weight\ninitialization. In this work, we introduce weight selection, a method for\ninitializing smaller models by selecting a subset of weights from a pretrained\nlarger model. This enables the transfer of knowledge from pretrained weights to\nsmaller models. Our experiments demonstrate that weight selection can\nsignificantly enhance the performance of small models and reduce their training\ntime. Notably, it can also be used together with knowledge distillation. Weight\nselection offers a new approach to leverage the power of pretrained models in\nresource-constrained settings, and we hope it can be a useful tool for training\nsmall models in the large-model era. Code is available at\nhttps://github.com/OscarXZQ/weight-selection.",
            "author": [
                "Zhiqiu Xu",
                "Yanjie Chen",
                "Kirill Vishniakov",
                "Yida Yin",
                "Zhiqiang Shen",
                "Trevor Darrell",
                "Lingjie Liu",
                "Zhuang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18823v1",
                "http://arxiv.org/pdf/2311.18823v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18817v1",
            "title": "Dichotomy of Early and Late Phase Implicit Biases Can Provably Induce\n  Grokking",
            "updated": "2023-11-30T18:55:38Z",
            "published": "2023-11-30T18:55:38Z",
            "summary": "Recent work by Power et al. (2022) highlighted a surprising \"grokking\"\nphenomenon in learning arithmetic tasks: a neural net first \"memorizes\" the\ntraining set, resulting in perfect training accuracy but near-random test\naccuracy, and after training for sufficiently longer, it suddenly transitions\nto perfect test accuracy. This paper studies the grokking phenomenon in\ntheoretical setups and shows that it can be induced by a dichotomy of early and\nlate phase implicit biases. Specifically, when training homogeneous neural nets\nwith large initialization and small weight decay on both classification and\nregression tasks, we prove that the training process gets trapped at a solution\ncorresponding to a kernel predictor for a long time, and then a very sharp\ntransition to min-norm/max-margin predictors occurs, leading to a dramatic\nchange in test accuracy.",
            "author": [
                "Kaifeng Lyu",
                "Jikai Jin",
                "Zhiyuan Li",
                "Simon S. Du",
                "Jason D. Lee",
                "Wei Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18817v1",
                "http://arxiv.org/pdf/2311.18817v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18815v1",
            "title": "IMMA: Immunizing text-to-image Models against Malicious Adaptation",
            "updated": "2023-11-30T18:55:16Z",
            "published": "2023-11-30T18:55:16Z",
            "summary": "Advancements in text-to-image models and fine-tuning methods have led to the\nincreasing risk of malicious adaptation, i.e., fine-tuning to generate harmful\nunauthorized content. Recent works, e.g., Glaze or MIST, have developed\ndata-poisoning techniques which protect the data against adaptation methods. In\nthis work, we consider an alternative paradigm for protection. We propose to\n``immunize'' the model by learning model parameters that are difficult for the\nadaptation methods when fine-tuning malicious content; in short IMMA. Empirical\nresults show IMMA's effectiveness against malicious adaptations, including\nmimicking the artistic style and learning of inappropriate/unauthorized\ncontent, over three adaptation methods: LoRA, Textual-Inversion, and\nDreamBooth.",
            "author": [
                "Yijia Zheng",
                "Raymond A. Yeh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18815v1",
                "http://arxiv.org/pdf/2311.18815v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18814v1",
            "title": "Is Underwater Image Enhancement All Object Detectors Need?",
            "updated": "2023-11-30T18:54:08Z",
            "published": "2023-11-30T18:54:08Z",
            "summary": "Underwater object detection is a crucial and challenging problem in marine\nengineering and aquatic robot. The difficulty is partly because of the\ndegradation of underwater images caused by light selective absorption and\nscattering. Intuitively, enhancing underwater images can benefit high-level\napplications like underwater object detection. However, it is still unclear\nwhether all object detectors need underwater image enhancement as\npre-processing. We therefore pose the questions \"Does underwater image\nenhancement really improve underwater object detection?\" and \"How does\nunderwater image enhancement contribute to underwater object detection?\". With\nthese two questions, we conduct extensive studies. Specifically, we use 18\nstate-of-the-art underwater image enhancement algorithms, covering traditional,\nCNN-based, and GAN-based algorithms, to pre-process underwater object detection\ndata. Then, we retrain 7 popular deep learning-based object detectors using the\ncorresponding results enhanced by different algorithms, obtaining 126\nunderwater object detection models. Coupled with 7 object detection models\nretrained using raw underwater images, we employ these 133 models to\ncomprehensively analyze the effect of underwater image enhancement on\nunderwater object detection. We expect this study can provide sufficient\nexploration to answer the aforementioned questions and draw more attention of\nthe community to the joint problem of underwater image enhancement and\nunderwater object detection. The pre-trained models and results are publicly\navailable and will be regularly updated. Project page:\nhttps://github.com/BIGWangYuDong/lqit/tree/main/configs/detection/uw_enhancement_affect_detection.",
            "author": [
                "Yudong Wang",
                "Jichang Guo",
                "Wanru He",
                "Huan Gao",
                "Huihui Yue",
                "Zenan Zhang",
                "Chongyi Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18814v1",
                "http://arxiv.org/pdf/2311.18814v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00583v1",
            "title": "MD-Splatting: Learning Metric Deformation from 4D Gaussians in Highly\n  Deformable Scenes",
            "updated": "2023-11-30T18:53:03Z",
            "published": "2023-11-30T18:53:03Z",
            "summary": "Accurate 3D tracking in highly deformable scenes with occlusions and shadows\ncan facilitate new applications in robotics, augmented reality, and generative\nAI. However, tracking under these conditions is extremely challenging due to\nthe ambiguity that arises with large deformations, shadows, and occlusions. We\nintroduce MD-Splatting, an approach for simultaneous 3D tracking and novel view\nsynthesis, using video captures of a dynamic scene from various camera poses.\nMD-Splatting builds on recent advances in Gaussian splatting, a method that\nlearns the properties of a large number of Gaussians for state-of-the-art and\nfast novel view synthesis. MD-Splatting learns a deformation function to\nproject a set of Gaussians with non-metric, thus canonical, properties into\nmetric space. The deformation function uses a neural-voxel encoding and a\nmultilayer perceptron (MLP) to infer Gaussian position, rotation, and a shadow\nscalar. We enforce physics-inspired regularization terms based on local\nrigidity, conservation of momentum, and isometry, which leads to trajectories\nwith smaller trajectory errors. MD-Splatting achieves high-quality 3D tracking\non highly deformable scenes with shadows and occlusions. Compared to\nstate-of-the-art, we improve 3D tracking by an average of 23.9 %, while\nsimultaneously achieving high-quality novel view synthesis. With sufficient\ntexture such as in scene 6, MD-Splatting achieves a median tracking error of\n3.39 mm on a cloth of 1 x 1 meters in size. Project website:\nhttps://md-splatting.github.io/.",
            "author": [
                "Bardienus P. Duisterhof",
                "Zhao Mandi",
                "Yunchao Yao",
                "Jia-Wei Liu",
                "Mike Zheng Shou",
                "Shuran Song",
                "Jeffrey Ichnowski"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00583v1",
                "http://arxiv.org/pdf/2312.00583v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18807v1",
            "title": "Pre-registration for Predictive Modeling",
            "updated": "2023-11-30T18:52:10Z",
            "published": "2023-11-30T18:52:10Z",
            "summary": "Amid rising concerns of reproducibility and generalizability in predictive\nmodeling, we explore the possibility and potential benefits of introducing\npre-registration to the field. Despite notable advancements in predictive\nmodeling, spanning core machine learning tasks to various scientific\napplications, challenges such as overlooked contextual factors, data-dependent\ndecision-making, and unintentional re-use of test data have raised questions\nabout the integrity of results. To address these issues, we propose adapting\npre-registration practices from explanatory modeling to predictive modeling. We\ndiscuss current best practices in predictive modeling and their limitations,\nintroduce a lightweight pre-registration template, and present a qualitative\nstudy with machine learning researchers to gain insight into the effectiveness\nof pre-registration in preventing biased estimates and promoting more reliable\nresearch outcomes. We conclude by exploring the scope of problems that\npre-registration can address in predictive modeling and acknowledging its\nlimitations within this context.",
            "author": [
                "Jake M. Hofman",
                "Angelos Chatzimparmpas",
                "Amit Sharma",
                "Duncan J. Watts",
                "Jessica Hullman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18807v1",
                "http://arxiv.org/pdf/2311.18807v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18806v1",
            "title": "Efficient Baseline for Quantitative Precipitation Forecasting in\n  Weather4cast 2023",
            "updated": "2023-11-30T18:51:50Z",
            "published": "2023-11-30T18:51:50Z",
            "summary": "Accurate precipitation forecasting is indispensable for informed\ndecision-making across various industries. However, the computational demands\nof current models raise environmental concerns. We address the critical need\nfor accurate precipitation forecasting while considering the environmental\nimpact of computational resources and propose a minimalist U-Net architecture\nto be used as a baseline for future weather forecasting initiatives.",
            "author": [
                "Akshay Punjabi",
                "Pablo Izquierdo Ayala"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18806v1",
                "http://arxiv.org/pdf/2311.18806v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.ao-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18803v2",
            "title": "BioCLIP: A Vision Foundation Model for the Tree of Life",
            "updated": "2023-12-04T16:13:21Z",
            "published": "2023-11-30T18:49:43Z",
            "summary": "Images of the natural world, collected by a variety of cameras, from drones\nto individual phones, are increasingly abundant sources of biological\ninformation. There is an explosion of computational methods and tools,\nparticularly computer vision, for extracting biologically relevant information\nfrom images for science and conservation. Yet most of these are bespoke\napproaches designed for a specific task and are not easily adaptable or\nextendable to new questions, contexts, and datasets. A vision model for general\norganismal biology questions on images is of timely need. To approach this, we\ncurate and release TreeOfLife-10M, the largest and most diverse ML-ready\ndataset of biology images. We then develop BioCLIP, a foundation model for the\ntree of life, leveraging the unique properties of biology captured by\nTreeOfLife-10M, namely the abundance and variety of images of plants, animals,\nand fungi, together with the availability of rich structured biological\nknowledge. We rigorously benchmark our approach on diverse fine-grained biology\nclassification tasks, and find that BioCLIP consistently and substantially\noutperforms existing baselines (by 17% to 20% absolute). Intrinsic evaluation\nreveals that BioCLIP has learned a hierarchical representation conforming to\nthe tree of life, shedding light on its strong generalizability. Our code,\nmodels and data will be made available at\nhttps://github.com/Imageomics/bioclip.",
            "author": [
                "Samuel Stevens",
                "Jiaman Wu",
                "Matthew J Thompson",
                "Elizabeth G Campolongo",
                "Chan Hee Song",
                "David Edward Carlyn",
                "Li Dong",
                "Wasila M Dahdul",
                "Charles Stewart",
                "Tanya Berger-Wolf",
                "Wei-Lun Chao",
                "Yu Su"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18803v2",
                "http://arxiv.org/pdf/2311.18803v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18801v1",
            "title": "Distributed Global Structure-from-Motion with a Deep Front-End",
            "updated": "2023-11-30T18:47:18Z",
            "published": "2023-11-30T18:47:18Z",
            "summary": "While initial approaches to Structure-from-Motion (SfM) revolved around both\nglobal and incremental methods, most recent applications rely on incremental\nsystems to estimate camera poses due to their superior robustness. Though there\nhas been tremendous progress in SfM `front-ends' powered by deep models learned\nfrom data, the state-of-the-art (incremental) SfM pipelines still rely on\nclassical SIFT features, developed in 2004. In this work, we investigate\nwhether leveraging the developments in feature extraction and matching helps\nglobal SfM perform on par with the SOTA incremental SfM approach (COLMAP). To\ndo so, we design a modular SfM framework that allows us to easily combine\ndevelopments in different stages of the SfM pipeline. Our experiments show that\nwhile developments in deep-learning based two-view correspondence estimation do\ntranslate to improvements in point density for scenes reconstructed with global\nSfM, none of them outperform SIFT when comparing with incremental SfM results\non a range of datasets. Our SfM system is designed from the ground up to\nleverage distributed computation, enabling us to parallelize computation on\nmultiple machines and scale to large scenes.",
            "author": [
                "Ayush Baid",
                "John Lambert",
                "Travis Driver",
                "Akshay Krishnan",
                "Hayk Stepanyan",
                "Frank Dellaert"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18801v1",
                "http://arxiv.org/pdf/2311.18801v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18789v1",
            "title": "Unsupervised learning architecture based on neural Darwinism and\n  Hopfield networks recognizes symbols with high accuracy",
            "updated": "2023-11-30T18:39:20Z",
            "published": "2023-11-30T18:39:20Z",
            "summary": "This paper introduces a novel unsupervised learning paradigm inspired by\nGerald Edelman's theory of neuronal group selection (\"Neural Darwinism\"). The\npresented automaton learns to recognize arbitrary symbols (e.g., letters of an\nalphabet) when they are presented repeatedly, as they are when children learn\nto read. On a second hierarchical level, the model creates abstract categories\nrepresenting the learnt symbols. The fundamental computational unit are simple\nMcCulloch-Pitts neurons arranged into fully-connected groups (Hopfield networks\nwith randomly initialized weights), which are \"selected\", in an evolutionary\nsense, through symbol presentation. The learning process is fully tractable and\neasily interpretable for humans, in contrast to most neural network\narchitectures. Computational properties of Hopfield networks enabling pattern\nrecognition are discussed. In simulations, the model achieves high accuracy in\nlearning the letters of the Latin alphabet, presented as binary patterns on a\ngrid. This paper is a proof of concept with no claims to state-of-the-art\nperformance in letter recognition, but hopefully inspires new thinking in\nbio-inspired machine learning.",
            "author": [
                "Mario Stepanik"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18789v1",
                "http://arxiv.org/pdf/2311.18789v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18787v1",
            "title": "Communication-Efficient Federated Optimization over Semi-Decentralized\n  Networks",
            "updated": "2023-11-30T18:37:15Z",
            "published": "2023-11-30T18:37:15Z",
            "summary": "In large-scale federated and decentralized learning, communication efficiency\nis one of the most challenging bottlenecks. While gossip communication -- where\nagents can exchange information with their connected neighbors -- is more\ncost-effective than communicating with the remote server, it often requires a\ngreater number of communication rounds, especially for large and sparse\nnetworks. To tackle the trade-off, we examine the communication efficiency\nunder a semi-decentralized communication protocol, in which agents can perform\nboth agent-to-agent and agent-to-server communication in a probabilistic\nmanner. We design a tailored communication-efficient algorithm over\nsemi-decentralized networks, referred to as PISCO, which inherits the\nrobustness to data heterogeneity thanks to gradient tracking and allows\nmultiple local updates for saving communication. We establish the convergence\nrate of PISCO for nonconvex problems and show that PISCO enjoys a linear\nspeedup in terms of the number of agents and local updates. Our numerical\nresults highlight the superior communication efficiency of PISCO and its\nresilience to data heterogeneity and various network topologies.",
            "author": [
                "He Wang",
                "Yuejie Chi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18787v1",
                "http://arxiv.org/pdf/2311.18787v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00111v1",
            "title": "Multimodal Learning for Crystalline Materials",
            "updated": "2023-11-30T18:35:29Z",
            "published": "2023-11-30T18:35:29Z",
            "summary": "Artificial intelligence (AI) has revolutionized the field of materials\nscience by improving the prediction of properties and accelerating the\ndiscovery of novel materials. In recent years, publicly available material data\nrepositories containing data for various material properties have grown\nrapidly. In this work, we introduce Multimodal Learning for Crystalline\nMaterials (MLCM), a new method for training a foundation model for crystalline\nmaterials via multimodal alignment, where high-dimensional material properties\n(i.e. modalities) are connected in a shared latent space to produce highly\nuseful material representations. We show the utility of MLCM on multiple axes:\n(i) MLCM achieves state-of-the-art performance for material property prediction\non the challenging Materials Project database; (ii) MLCM enables a novel,\nhighly accurate method for inverse design, allowing one to screen for stable\nmaterial with desired properties; and (iii) MLCM allows the extraction of\ninterpretable emergent features that may provide insight to material\nscientists. Further, we explore several novel methods for aligning an arbitrary\nnumber of modalities, improving upon prior art in multimodal learning that\nfocuses on bimodal alignment. Our work brings innovations from the ongoing AI\nrevolution into the domain of materials science and identifies materials as a\ntestbed for the next generation of AI.",
            "author": [
                "Viggo Moro",
                "Charlotte Loh",
                "Rumen Dangovski",
                "Ali Ghorashi",
                "Andrew Ma",
                "Zhuo Chen",
                "Peter Y. Lu",
                "Thomas Christensen",
                "Marin Solja\u010di\u0107"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00111v1",
                "http://arxiv.org/pdf/2312.00111v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03747v1",
            "title": "Classifying patient voice in social media data using neural networks: A\n  comparison of AI models on different data sources and therapeutic domains",
            "updated": "2023-11-30T18:35:24Z",
            "published": "2023-11-30T18:35:24Z",
            "summary": "It is essential that healthcare professionals and members of the healthcare\ncommunity can access and easily understand patient experiences in the real\nworld, so that care standards can be improved and driven towards personalised\ndrug treatment. Social media platforms and message boards are deemed suitable\nsources of patient experience information, as patients have been observed to\ndiscuss and exchange knowledge, look for and provide support online. This paper\ntests the hypothesis that not all online patient experience information can be\ntreated and collected in the same way, as a result of the inherent differences\nin the way individuals talk about their journeys, in different therapeutic\ndomains and or data sources.\n  We used linguistic analysis to understand and identify similarities between\ndatasets, across patient language, between data sources (Reddit, SocialGist)\nand therapeutic domains (cardiovascular, oncology, immunology, neurology). We\ndetected common vocabulary used by patients in the same therapeutic domain\nacross data sources, except for immunology patients, who use unique vocabulary\nbetween the two data sources, and compared to all other datasets. We combined\nlinguistically similar datasets to train classifiers (CNN, transformer) to\naccurately identify patient experience posts from social media, a task we refer\nto as patient voice classification. The cardiovascular and neurology\ntransformer classifiers perform the best in their respective comparisons for\nthe Reddit data source, achieving F1-scores of 0.865 and 1.0 respectively. The\noverall best performing classifier is the transformer classifier trained on all\ndata collected for this experiment, achieving F1-scores ranging between 0.863\nand 0.995 across all therapeutic domain and data source specific test datasets.",
            "author": [
                "Giorgos Lysandrou",
                "Roma English Owen",
                "Vanja Popovic",
                "Grant Le Brun",
                "Beatrice Alex",
                "Elizabeth A. L. Fairley"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03747v1",
                "http://arxiv.org/pdf/2312.03747v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18780v1",
            "title": "MultiResFormer: Transformer with Adaptive Multi-Resolution Modeling for\n  General Time Series Forecasting",
            "updated": "2023-11-30T18:24:33Z",
            "published": "2023-11-30T18:24:33Z",
            "summary": "Transformer-based models have greatly pushed the boundaries of time series\nforecasting recently. Existing methods typically encode time series data into\n$\\textit{patches}$ using one or a fixed set of patch lengths. This, however,\ncould result in a lack of ability to capture the variety of intricate temporal\ndependencies present in real-world multi-periodic time series. In this paper,\nwe propose MultiResFormer, which dynamically models temporal variations by\nadaptively choosing optimal patch lengths. Concretely, at the beginning of each\nlayer, time series data is encoded into several parallel branches, each using a\ndetected periodicity, before going through the transformer encoder block. We\nconduct extensive evaluations on long- and short-term forecasting datasets\ncomparing MultiResFormer with state-of-the-art baselines. MultiResFormer\noutperforms patch-based Transformer baselines on long-term forecasting tasks\nand also consistently outperforms CNN baselines by a large margin, while using\nmuch fewer parameters than these baselines.",
            "author": [
                "Linfeng Du",
                "Ji Xin",
                "Alex Labach",
                "Saba Zuberi",
                "Maksims Volkovs",
                "Rahul G. Krishnan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18780v1",
                "http://arxiv.org/pdf/2311.18780v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18775v1",
            "title": "CoDi-2: In-Context, Interleaved, and Interactive Any-to-Any Generation",
            "updated": "2023-11-30T18:21:25Z",
            "published": "2023-11-30T18:21:25Z",
            "summary": "We present CoDi-2, a versatile and interactive Multimodal Large Language\nModel (MLLM) that can follow complex multimodal interleaved instructions,\nconduct in-context learning (ICL), reason, chat, edit, etc., in an any-to-any\ninput-output modality paradigm. By aligning modalities with language for both\nencoding and generation, CoDi-2 empowers Large Language Models (LLMs) to not\nonly understand complex modality-interleaved instructions and in-context\nexamples, but also autoregressively generate grounded and coherent multimodal\noutputs in the continuous feature space. To train CoDi-2, we build a\nlarge-scale generation dataset encompassing in-context multimodal instructions\nacross text, vision, and audio. CoDi-2 demonstrates a wide range of zero-shot\ncapabilities for multimodal generation, such as in-context learning, reasoning,\nand compositionality of any-to-any modality generation through multi-round\ninteractive conversation. CoDi-2 surpasses previous domain-specific models on\ntasks such as subject-driven image generation, vision transformation, and audio\nediting. CoDi-2 signifies a substantial breakthrough in developing a\ncomprehensive multimodal foundation model adept at interpreting in-context\nlanguage-vision-audio interleaved instructions and producing multimodal\noutputs.",
            "author": [
                "Zineng Tang",
                "Ziyi Yang",
                "Mahmoud Khademi",
                "Yang Liu",
                "Chenguang Zhu",
                "Mohit Bansal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18775v1",
                "http://arxiv.org/pdf/2311.18775v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18773v1",
            "title": "Spacewalk-18: A Benchmark for Multimodal and Long-form Procedural Video\n  Understanding in Novel Domains",
            "updated": "2023-11-30T18:19:23Z",
            "published": "2023-11-30T18:19:23Z",
            "summary": "Learning from videos is an emerging research area that enables robots to\nacquire skills from human demonstrations, such as procedural videos. To do\nthis, video-language models must be able to obtain structured understandings,\nsuch as the temporal segmentation of a demonstration into sequences of actions\nand skills, and to generalize the understandings to novel domains. In pursuit\nof this goal, we introduce Spacewalk-18, a benchmark containing two tasks: (1)\nstep recognition and (2) intra-video retrieval over a dataset of temporally\nsegmented and labeled tasks in International Space Station spacewalk\nrecordings. In tandem, the two tasks quantify a model's ability to make use of:\n(1) out-of-domain visual information; (2) a high temporal context window; and\n(3) multimodal (text + video) domains. This departs from existing benchmarks\nfor procedural video understanding, which typically deal with short context\nlengths and can be solved with a single modality. Spacewalk-18, with its\ninherent multimodal and long-form complexity, exposes the high difficulty of\ntask recognition and segmentation. We find that state-of-the-art methods\nperform poorly on our benchmark, demonstrating that the goal of generalizable\nprocedural video understanding models is far out and underscoring the need to\ndevelop new approaches to these tasks. Data, model, and code will be publicly\nreleased.",
            "author": [
                "Rohan Myer Krishnan",
                "Zitian Tang",
                "Zhiqiu Yu",
                "Chen Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18773v1",
                "http://arxiv.org/pdf/2311.18773v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18769v1",
            "title": "Online Change Points Detection for Linear Dynamical Systems with Finite\n  Sample Guarantees",
            "updated": "2023-11-30T18:08:16Z",
            "published": "2023-11-30T18:08:16Z",
            "summary": "The problem of online change point detection is to detect abrupt changes in\nproperties of time series, ideally as soon as possible after those changes\noccur. Existing work on online change point detection either assumes i.i.d\ndata, focuses on asymptotic analysis, does not present theoretical guarantees\non the trade-off between detection accuracy and detection delay, or is only\nsuitable for detecting single change points. In this work, we study the online\nchange point detection problem for linear dynamical systems with unknown\ndynamics, where the data exhibits temporal correlations and the system could\nhave multiple change points. We develop a data-dependent threshold that can be\nused in our test that allows one to achieve a pre-specified upper bound on the\nprobability of making a false alarm. We further provide a finite-sample-based\nbound for the probability of detecting a change point. Our bound demonstrates\nhow parameters used in our algorithm affect the detection probability and\ndelay, and provides guidance on the minimum required time between changes to\nguarantee detection.",
            "author": [
                "Lei Xin",
                "George Chiu",
                "Shreyas Sundaram"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18769v1",
                "http://arxiv.org/pdf/2311.18769v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SY",
                "eess.SY",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18768v1",
            "title": "Evaluating the Impact of Flaky Simulators on Testing Autonomous Driving\n  Systems",
            "updated": "2023-11-30T18:08:02Z",
            "published": "2023-11-30T18:08:02Z",
            "summary": "Simulators are widely used to test Autonomous Driving Systems (ADS), but\ntheir potential flakiness can lead to inconsistent test results. We investigate\ntest flakiness in simulation-based testing of ADS by addressing two key\nquestions: (1) How do flaky ADS simulations impact automated testing that\nrelies on randomized algorithms? and (2) Can machine learning (ML) effectively\nidentify flaky ADS tests while decreasing the required number of test reruns?\nOur empirical results, obtained from two widely-used open-source ADS simulators\nand five diverse ADS test setups, show that test flakiness in ADS is a common\noccurrence and can significantly impact the test results obtained by randomized\nalgorithms. Further, our ML classifiers effectively identify flaky ADS tests\nusing only a single test run, achieving F1-scores of $85$%, $82$% and $96$% for\nthree different ADS test setups. Our classifiers significantly outperform our\nnon-ML baseline, which requires executing tests at least twice, by $31$%,\n$21$%, and $13$% in F1-score performance, respectively. We conclude with a\ndiscussion on the scope, implications and limitations of our study. We provide\nour complete replication package in a Github repository.",
            "author": [
                "Mohammad Hossein Amini",
                "Shervin Naseri",
                "Shiva Nejati"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18768v1",
                "http://arxiv.org/pdf/2311.18768v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18765v2",
            "title": "MLLMs-Augmented Visual-Language Representation Learning",
            "updated": "2023-12-01T15:38:31Z",
            "published": "2023-11-30T18:05:52Z",
            "summary": "Visual-language pre-training (VLP) has achieved remarkable success in\nmulti-modal tasks, largely attributed to the availability of large-scale\nimage-text datasets. In this work, we demonstrate that multi-modal large\nlanguage models (MLLMs) can enhance visual-language representation learning by\nimproving data quality. Our approach is simple, utilizing MLLMs to extend\nmultiple captions for each image. To prevent the bias introduced by MLLMs'\nhallucinations and intrinsic caption styles, we propose \"text shearing\" to\nmaintain the same length for extended captions as that of the original\ncaptions. In image-text retrieval, our method consistently obtains 5.6 ~ 35.0%\nand 16.8 ~ 46.1% improvement on R@1 under the fine-tuning and zero-shot\nsettings, respectively. Notably, we obtain zero-shot results that are\ncomparable to fine-tuning on target datasets, which encourages more exploration\nof the versatile use of MLLMs.",
            "author": [
                "Yanqing Liu",
                "Kai Wang",
                "Wenqi Shao",
                "Ping Luo",
                "Yu Qiao",
                "Mike Zheng Shou",
                "Kaipeng Zhang",
                "Yang You"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18765v2",
                "http://arxiv.org/pdf/2311.18765v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18763v1",
            "title": "Continual Diffusion with STAMINA: STack-And-Mask INcremental Adapters",
            "updated": "2023-11-30T18:04:21Z",
            "published": "2023-11-30T18:04:21Z",
            "summary": "Recent work has demonstrated a remarkable ability to customize text-to-image\ndiffusion models to multiple, fine-grained concepts in a sequential (i.e.,\ncontinual) manner while only providing a few example images for each concept.\nThis setting is known as continual diffusion. Here, we ask the question: Can we\nscale these methods to longer concept sequences without forgetting? Although\nprior work mitigates the forgetting of previously learned concepts, we show\nthat its capacity to learn new tasks reaches saturation over longer sequences.\nWe address this challenge by introducing a novel method, STack-And-Mask\nINcremental Adapters (STAMINA), which is composed of low-ranked\nattention-masked adapters and customized MLP tokens. STAMINA is designed to\nenhance the robust fine-tuning properties of LoRA for sequential concept\nlearning via learnable hard-attention masks parameterized with low rank MLPs,\nenabling precise, scalable learning via sparse adaptation. Notably, all\nintroduced trainable parameters can be folded back into the model after\ntraining, inducing no additional inference parameter costs. We show that\nSTAMINA outperforms the prior SOTA for the setting of text-to-image continual\ncustomization on a 50-concept benchmark composed of landmarks and human faces,\nwith no stored replay data. Additionally, we extended our method to the setting\nof continual learning for image classification, demonstrating that our gains\nalso translate to state-of-the-art performance in this standard benchmark.",
            "author": [
                "James Seale Smith",
                "Yen-Chang Hsu",
                "Zsolt Kira",
                "Yilin Shen",
                "Hongxia Jin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18763v1",
                "http://arxiv.org/pdf/2311.18763v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00589v1",
            "title": "Merlin:Empowering Multimodal LLMs with Foresight Minds",
            "updated": "2023-11-30T17:57:34Z",
            "published": "2023-11-30T17:57:34Z",
            "summary": "Humans possess the remarkable ability to foresee the future to a certain\nextent based on present observations, a skill we term as foresight minds.\nHowever, this capability remains largely under explored within existing\nMultimodal Large Language Models (MLLMs), hindering their capacity to learn the\nfundamental principles of how things operate and the intentions behind the\nobserved subjects. To address this issue, we introduce the integration of\nfuture modeling into the existing learning frameworks of MLLMs. By utilizing\nthe subject trajectory, a highly structured representation of a consecutive\nframe sequence, as a learning objective, we aim to bridge the gap between the\npast and the future. We propose two innovative methods to empower MLLMs with\nforesight minds, Foresight Pre-Training (FPT) and Foresight Instruction-Tuning\n(FIT), which are inspired by the modern learning paradigm of LLMs.\nSpecifically, FPT jointly training various tasks centered on trajectories,\nenabling MLLMs to learn how to attend and predict entire trajectories from a\ngiven initial observation. Then, FIT requires MLLMs to first predict\ntrajectories of related objects and then reason about potential future events\nbased on them. Aided by FPT and FIT, we build a novel and unified MLLM named\nMerlin that supports multi-images input and analysis about potential actions of\nmultiple objects for the future reasoning. Experimental results show Merlin\npowerful foresight minds with impressive performance on both future reasoning\nand visual comprehension tasks.",
            "author": [
                "En Yu",
                "Liang Zhao",
                "Yana Wei",
                "Jinrong Yang",
                "Dongming Wu",
                "Lingyu Kong",
                "Haoran Wei",
                "Tiancai Wang",
                "Zheng Ge",
                "Xiangyu Zhang",
                "Wenbing Tao"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00589v1",
                "http://arxiv.org/pdf/2312.00589v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18751v1",
            "title": "Language Model Agents Suffer from Compositional Generalization in Web\n  Automation",
            "updated": "2023-11-30T17:50:47Z",
            "published": "2023-11-30T17:50:47Z",
            "summary": "Language model agents (LMA) recently emerged as a promising paradigm on\nmuti-step decision making tasks, often outperforming humans and other\nreinforcement learning agents. Despite the promise, their performance on\nreal-world applications that often involve combinations of tasks is still\nunderexplored. In this work, we introduce a new benchmark, called CompWoB -- 50\nnew compositional web automation tasks reflecting more realistic assumptions.\nWe show that while existing prompted LMAs (gpt-3.5-turbo or gpt-4) achieve\n94.0% average success rate on base tasks, their performance degrades to 24.9%\nsuccess rate on compositional tasks. On the other hand, transferred LMAs\n(finetuned only on base tasks) show less generalization gap, dropping from\n85.4% to 54.8%. By balancing data distribution across tasks, we train a new\nmodel, HTML-T5++, that surpasses human-level performance (95.2%) on MiniWoB,\nand achieves the best zero-shot performance on CompWoB (61.5%). While these\nhighlight the promise of small-scale finetuned and transferred models for\ncompositional generalization, their performance further degrades under\ndifferent instruction compositions changing combinational order. In contrast to\nthe recent remarkable success of LMA, our benchmark and detailed analysis\nemphasize the necessity of building LMAs that are robust and generalizable to\ntask compositionality for real-world deployment.",
            "author": [
                "Hiroki Furuta",
                "Yutaka Matsuo",
                "Aleksandra Faust",
                "Izzeddin Gur"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18751v1",
                "http://arxiv.org/pdf/2311.18751v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18749v1",
            "title": "TransCORALNet: A Two-Stream Transformer CORAL Networks for Supply Chain\n  Credit Assessment Cold Start",
            "updated": "2023-11-30T17:47:02Z",
            "published": "2023-11-30T17:47:02Z",
            "summary": "This paper proposes an interpretable two-stream transformer CORAL networks\n(TransCORALNet) for supply chain credit assessment under the segment industry\nand cold start problem. The model aims to provide accurate credit assessment\nprediction for new supply chain borrowers with limited historical data. Here,\nthe two-stream domain adaptation architecture with correlation alignment\n(CORAL) loss is used as a core model and is equipped with transformer, which\nprovides insights about the learned features and allow efficient\nparallelization during training. Thanks to the domain adaptation capability of\nthe proposed model, the domain shift between the source and target domain is\nminimized. Therefore, the model exhibits good generalization where the source\nand target do not follow the same distribution, and a limited amount of target\nlabeled instances exist. Furthermore, we employ Local Interpretable\nModel-agnostic Explanations (LIME) to provide more insight into the model\nprediction and identify the key features contributing to supply chain credit\nassessment decisions. The proposed model addresses four significant supply\nchain credit assessment challenges: domain shift, cold start, imbalanced-class\nand interpretability. Experimental results on a real-world data set demonstrate\nthe superiority of TransCORALNet over a number of state-of-the-art baselines in\nterms of accuracy. The code is available on GitHub\nhttps://github.com/JieJieNiu/TransCORALN .",
            "author": [
                "Jie Shi",
                "Arno P. J. M. Siebes",
                "Siamak Mehrkanoon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18749v1",
                "http://arxiv.org/pdf/2311.18749v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "q-fin.RM",
                "I.2; I.5"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18746v1",
            "title": "A data-science pipeline to enable the Interpretability of Many-Objective\n  Feature Selection",
            "updated": "2023-11-30T17:44:22Z",
            "published": "2023-11-30T17:44:22Z",
            "summary": "Many-Objective Feature Selection (MOFS) approaches use four or more\nobjectives to determine the relevance of a subset of features in a supervised\nlearning task. As a consequence, MOFS typically returns a large set of\nnon-dominated solutions, which have to be assessed by the data scientist in\norder to proceed with the final choice. Given the multi-variate nature of the\nassessment, which may include criteria (e.g. fairness) not related to\npredictive accuracy, this step is often not straightforward and suffers from\nthe lack of existing tools. For instance, it is common to make use of a tabular\npresentation of the solutions, which provide little information about the\ntrade-offs and the relations between criteria over the set of solutions.\n  This paper proposes an original methodology to support data scientists in the\ninterpretation and comparison of the MOFS outcome by combining post-processing\nand visualisation of the set of solutions. The methodology supports the data\nscientist in the selection of an optimal feature subset by providing her with\nhigh-level information at three different levels: objectives, solutions, and\nindividual features.\n  The methodology is experimentally assessed on two feature selection tasks\nadopting a GA-based MOFS with six objectives (number of selected features,\nbalanced accuracy, F1-Score, variance inflation factor, statistical parity, and\nequalised odds). The results show the added value of the methodology in the\nselection of the final subset of features.",
            "author": [
                "Uchechukwu F. Njoku",
                "Alberto Abell\u00f3",
                "Besim Bilalli",
                "Gianluca Bontempi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18746v1",
                "http://arxiv.org/pdf/2311.18746v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18744v1",
            "title": "$\\mathbb{Z}_2\\times \\mathbb{Z}_2$ Equivariant Quantum Neural Networks:\n  Benchmarking against Classical Neural Networks",
            "updated": "2023-11-30T17:41:46Z",
            "published": "2023-11-30T17:41:46Z",
            "summary": "This paper presents a comprehensive comparative analysis of the performance\nof Equivariant Quantum Neural Networks (EQNN) and Quantum Neural Networks\n(QNN), juxtaposed against their classical counterparts: Equivariant Neural\nNetworks (ENN) and Deep Neural Networks (DNN). We evaluate the performance of\neach network with two toy examples for a binary classification task, focusing\non model complexity (measured by the number of parameters) and the size of the\ntraining data set. Our results show that the $\\mathbb{Z}_2\\times \\mathbb{Z}_2$\nEQNN and the QNN provide superior performance for smaller parameter sets and\nmodest training data samples.",
            "author": [
                "Zhongtian Dong",
                "Mar\u00e7al Comajoan Cara",
                "Gopal Ramesh Dahale",
                "Roy T. Forestano",
                "Sergei Gleyzer",
                "Daniel Justice",
                "Kyoungchul Kong",
                "Tom Magorsch",
                "Konstantin T. Matchev",
                "Katia Matcheva",
                "Eyup B. Unlu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18744v1",
                "http://arxiv.org/pdf/2311.18744v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.LG",
                "hep-ph",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18743v3",
            "title": "AlignBench: Benchmarking Chinese Alignment of Large Language Models",
            "updated": "2023-12-05T16:04:15Z",
            "published": "2023-11-30T17:41:30Z",
            "summary": "Alignment has become a critical step for instruction-tuned Large Language\nModels (LLMs) to become helpful assistants. However, effective evaluation of\nalignment for emerging Chinese LLMs is still significantly lacking, calling for\nreal-scenario grounded, open-ended, challenging and automatic evaluations\ntailored for alignment. To fill in this gap, we introduce AlignBench, a\ncomprehensive multi-dimensional benchmark for evaluating LLMs' alignment in\nChinese. Equipped with a human-in-the-loop data curation pipeline, our\nbenchmark employs a rule-calibrated multi-dimensional LLM-as-Judge with\nChain-of-Thought to generate explanations and final ratings as evaluations,\nensuring high reliability and interpretability. Furthermore, we report\nAlignBench evaluated by CritiqueLLM, a dedicated Chinese evaluator LLM that\nrecovers 95% of GPT-4's evaluation ability. We will provide public APIs for\nevaluating AlignBench with CritiqueLLM to facilitate the evaluation of LLMs'\nChinese alignment. All evaluation codes, data, and LLM generations are\navailable at \\url{https://github.com/THUDM/AlignBench}.",
            "author": [
                "Xiao Liu",
                "Xuanyu Lei",
                "Shengyuan Wang",
                "Yue Huang",
                "Zhuoer Feng",
                "Bosi Wen",
                "Jiale Cheng",
                "Pei Ke",
                "Yifan Xu",
                "Weng Lam Tam",
                "Xiaohan Zhang",
                "Lichao Sun",
                "Hongning Wang",
                "Jing Zhang",
                "Minlie Huang",
                "Yuxiao Dong",
                "Jie Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18743v3",
                "http://arxiv.org/pdf/2311.18743v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18741v1",
            "title": "VREM-FL: Mobility-Aware Computation-Scheduling Co-Design for Vehicular\n  Federated Learning",
            "updated": "2023-11-30T17:38:54Z",
            "published": "2023-11-30T17:38:54Z",
            "summary": "Assisted and autonomous driving are rapidly gaining momentum, and will soon\nbecome a reality. Among their key enablers, artificial intelligence and machine\nlearning are expected to play a prominent role, also thanks to the massive\namount of data that smart vehicles will collect from their onboard sensors. In\nthis domain, federated learning is one of the most effective and promising\ntechniques for training global machine learning models, while preserving data\nprivacy at the vehicles and optimizing communications resource usage. In this\nwork, we propose VREM-FL, a computation-scheduling co-design for vehicular\nfederated learning that leverages mobility of vehicles in conjunction with\nestimated 5G radio environment maps. VREM-FL jointly optimizes the global model\nlearned at the server while wisely allocating communication resources. This is\nachieved by orchestrating local computations at the vehicles in conjunction\nwith the transmission of their local model updates in an adaptive and\npredictive fashion, by exploiting radio channel maps. The proposed algorithm\ncan be tuned to trade model training time for radio resource usage.\nExperimental results demonstrate the efficacy of utilizing radio maps. VREM-FL\noutperforms literature benchmarks for both a linear regression model (learning\ntime reduced by 28%) and a deep neural network for a semantic image\nsegmentation task (doubling the number of model updates within the same time\nwindow).",
            "author": [
                "Luca Ballotta",
                "Nicol\u00f2 Dal Fabbro",
                "Giovanni Perin",
                "Luca Schenato",
                "Michele Rossi",
                "Giuseppe Piro"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18741v1",
                "http://arxiv.org/pdf/2311.18741v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.AI",
                "cs.DC",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18736v1",
            "title": "Controlgym: Large-Scale Safety-Critical Control Environments for\n  Benchmarking Reinforcement Learning Algorithms",
            "updated": "2023-11-30T17:34:05Z",
            "published": "2023-11-30T17:34:05Z",
            "summary": "We introduce controlgym, a library of thirty-six safety-critical industrial\ncontrol settings, and ten infinite-dimensional partial differential equation\n(PDE)-based control problems. Integrated within the OpenAI Gym/Gymnasium (Gym)\nframework, controlgym allows direct applications of standard reinforcement\nlearning (RL) algorithms like stable-baselines3. Our control environments\ncomplement those in Gym with continuous, unbounded action and observation\nspaces, motivated by real-world control applications. Moreover, the PDE control\nenvironments uniquely allow the users to extend the state dimensionality of the\nsystem to infinity while preserving the intrinsic dynamics. This feature is\ncrucial for evaluating the scalability of RL algorithms for control. This\nproject serves the learning for dynamics & control (L4DC) community, aiming to\nexplore key questions: the convergence of RL algorithms in learning control\npolicies; the stability and robustness issues of learning-based controllers;\nand the scalability of RL algorithms to high- and potentially\ninfinite-dimensional systems. We open-source the controlgym project at\nhttps://github.com/xiangyuan-zhang/controlgym.",
            "author": [
                "Xiangyuan Zhang",
                "Weichao Mao",
                "Saviz Mowlavi",
                "Mouhacine Benosman",
                "Tamer Ba\u015far"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18736v1",
                "http://arxiv.org/pdf/2311.18736v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.AI",
                "cs.CE",
                "cs.LG",
                "cs.SY",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18735v1",
            "title": "Dimension Mixer: A Generalized Method for Structured Sparsity in Deep\n  Neural Networks",
            "updated": "2023-11-30T17:30:45Z",
            "published": "2023-11-30T17:30:45Z",
            "summary": "The recent success of multiple neural architectures like CNNs, Transformers,\nand MLP-Mixers motivated us to look for similarities and differences between\nthem. We found that these architectures can be interpreted through the lens of\na general concept of dimension mixing. Research on coupling flows and the\nbutterfly transform shows that partial and hierarchical signal mixing schemes\nare sufficient for efficient and expressive function approximation. In this\nwork, we study group-wise sparse, non-linear, multi-layered and learnable\nmixing schemes of inputs and find that they are complementary to many standard\nneural architectures. Following our observations and drawing inspiration from\nthe Fast Fourier Transform, we generalize Butterfly Structure to use non-linear\nmixer function allowing for MLP as mixing function called Butterfly MLP. We\nwere also able to mix along sequence dimension for Transformer-based\narchitectures called Butterfly Attention. Experiments on CIFAR and LRA datasets\ndemonstrate that the proposed Non-Linear Butterfly Mixers are efficient and\nscale well when the host architectures are used as mixing function.\nAdditionally, we propose Patch-Only MLP-Mixer for processing spatial 2D signals\ndemonstrating a different dimension mixing strategy.",
            "author": [
                "Suman Sapkota",
                "Binod Bhattarai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18735v1",
                "http://arxiv.org/pdf/2311.18735v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18732v1",
            "title": "Indoor Millimeter Wave Localization using Multiple Self-Supervised Tiny\n  Neural Networks",
            "updated": "2023-11-30T17:27:22Z",
            "published": "2023-11-30T17:27:22Z",
            "summary": "We consider the localization of a mobile millimeter-wave client in a large\nindoor environment using multilayer perceptron neural networks (NNs). Instead\nof training and deploying a single deep model, we proceed by choosing among\nmultiple tiny NNs trained in a self-supervised manner. The main challenge then\nbecomes to determine and switch to the best NN among the available ones, as an\nincorrect NN will fail to localize the client. In order to upkeep the\nlocalization accuracy, we propose two switching schemes: one based on a Kalman\nfilter, and one based on the statistical distribution of the training data. We\nanalyze the proposed schemes via simulations, showing that our approach\noutperforms both geometric localization schemes and the use of a single NN.",
            "author": [
                "Anish Shastri",
                "Andres Garcia-Saavedra",
                "Paolo Casari"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18732v1",
                "http://arxiv.org/pdf/2311.18732v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.LG",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18729v1",
            "title": "Learning One-Shot 4D Head Avatar Synthesis using Synthetic Data",
            "updated": "2023-11-30T17:26:33Z",
            "published": "2023-11-30T17:26:33Z",
            "summary": "Existing one-shot 4D head synthesis methods usually learn from monocular\nvideos with the aid of 3DMM reconstruction, yet the latter is evenly\nchallenging which restricts them from reasonable 4D head synthesis. We present\na method to learn one-shot 4D head synthesis via large-scale synthetic data.\nThe key is to first learn a part-wise 4D generative model from monocular images\nvia adversarial learning, to synthesize multi-view images of diverse identities\nand full motions as training data; then leverage a transformer-based animatable\ntriplane reconstructor to learn 4D head reconstruction using the synthetic\ndata. A novel learning strategy is enforced to enhance the generalizability to\nreal images by disentangling the learning process of 3D reconstruction and\nreenactment. Experiments demonstrate our superiority over the prior art.",
            "author": [
                "Yu Deng",
                "Duomin Wang",
                "Xiaohang Ren",
                "Xingyu Chen",
                "Baoyuan Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18729v1",
                "http://arxiv.org/pdf/2311.18729v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18727v1",
            "title": "Automatic Functional Differentiation in JAX",
            "updated": "2023-11-30T17:23:40Z",
            "published": "2023-11-30T17:23:40Z",
            "summary": "We extend JAX with the capability to automatically differentiate higher-order\nfunctions (functionals and operators). By representing functions as a\ngeneralization of arrays, we seamlessly use JAX's existing primitive system to\nimplement higher-order functions. We present a set of primitive operators that\nserve as foundational building blocks for constructing several key types of\nfunctionals. For every introduced primitive operator, we derive and implement\nboth linearization and transposition rules, aligning with JAX's internal\nprotocols for forward and reverse mode automatic differentiation. This\nenhancement allows for functional differentiation in the same syntax\ntraditionally use for functions. The resulting functional gradients are\nthemselves functions ready to be invoked in python. We showcase this tool's\nefficacy and simplicity through applications where functional derivatives are\nindispensable. The source code of this work is released at\nhttps://github.com/sail-sg/autofd .",
            "author": [
                "Min Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18727v1",
                "http://arxiv.org/pdf/2311.18727v1"
            ],
            "primary_category": "cs.PL",
            "category": [
                "cs.PL",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18725v1",
            "title": "AI in Pharma for Personalized Sequential Decision-Making: Methods,\n  Applications and Opportunities",
            "updated": "2023-11-30T17:23:17Z",
            "published": "2023-11-30T17:23:17Z",
            "summary": "In the pharmaceutical industry, the use of artificial intelligence (AI) has\nseen consistent growth over the past decade. This rise is attributed to major\nadvancements in statistical machine learning methodologies, computational\ncapabilities and the increased availability of large datasets. AI techniques\nare applied throughout different stages of drug development, ranging from drug\ndiscovery to post-marketing benefit-risk assessment. Kolluri et al. provided a\nreview of several case studies that span these stages, featuring key\napplications such as protein structure prediction, success probability\nestimation, subgroup identification, and AI-assisted clinical trial monitoring.\nFrom a regulatory standpoint, there was a notable uptick in submissions\nincorporating AI components in 2021. The most prevalent therapeutic areas\nleveraging AI were oncology (27%), psychiatry (15%), gastroenterology (12%),\nand neurology (11%). The paradigm of personalized or precision medicine has\ngained significant traction in recent research, partly due to advancements in\nAI techniques \\cite{hamburg2010path}. This shift has had a transformative\nimpact on the pharmaceutical industry. Departing from the traditional\n\"one-size-fits-all\" model, personalized medicine incorporates various\nindividual factors, such as environmental conditions, lifestyle choices, and\nhealth histories, to formulate customized treatment plans. By utilizing\nsophisticated machine learning algorithms, clinicians and researchers are\nbetter equipped to make informed decisions in areas such as disease prevention,\ndiagnosis, and treatment selection, thereby optimizing health outcomes for each\nindividual.",
            "author": [
                "Yuhan Li",
                "Hongtao Zhang",
                "Keaven Anderson",
                "Songzi Li",
                "Ruoqing Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18725v1",
                "http://arxiv.org/pdf/2311.18725v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "cs.LG",
                "stat.AP",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18724v1",
            "title": "Routing-Guided Learned Product Quantization for Graph-Based Approximate\n  Nearest Neighbor Search",
            "updated": "2023-11-30T17:22:55Z",
            "published": "2023-11-30T17:22:55Z",
            "summary": "Given a vector dataset $\\mathcal{X}$, a query vector $\\vec{x}_q$, graph-based\nApproximate Nearest Neighbor Search (ANNS) aims to build a proximity graph (PG)\nas an index of $\\mathcal{X}$ and approximately return vectors with minimum\ndistances to $\\vec{x}_q$ by searching over the PG index. It suffers from the\nlarge-scale $\\mathcal{X}$ because a PG with full vectors is too large to fit\ninto the memory, e.g., a billion-scale $\\mathcal{X}$ in 128 dimensions would\nconsume nearly 600 GB memory. To solve this, Product Quantization (PQ)\nintegrated graph-based ANNS is proposed to reduce the memory usage, using\nsmaller compact codes of quantized vectors in memory instead of the large\noriginal vectors. Existing PQ methods do not consider the important routing\nfeatures of PG, resulting in low-quality quantized vectors that affect the\nANNS's effectiveness. In this paper, we present an end-to-end Routing-guided\nlearned Product Quantization (RPQ) for graph-based ANNS. It consists of (1) a\n\\textit{differentiable quantizer} used to make the standard discrete PQ\ndifferentiable to suit for back-propagation of end-to-end learning, (2) a\n\\textit{sampling-based feature extractor} used to extract neighborhood and\nrouting features of a PG, and (3) a \\textit{multi-feature joint training\nmodule} with two types of feature-aware losses to continuously optimize the\ndifferentiable quantizer. As a result, the inherent features of a PG would be\nembedded into the learned PQ, generating high-quality quantized vectors.\nMoreover, we integrate our RPQ with the state-of-the-art DiskANN and existing\npopular PGs to improve their performance. Comprehensive experiments on\nreal-world large-scale datasets (from 1M to 1B) demonstrate RPQ's superiority,\ne.g., 1.7$\\times$-4.2$\\times$ improvement on QPS at the same recall@10 of 95\\%.",
            "author": [
                "Qiang Yue",
                "Xiaoliang Xu",
                "Yuxiang Wang",
                "Yikun Tao",
                "Xuliyuan Luo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18724v1",
                "http://arxiv.org/pdf/2311.18724v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18718v1",
            "title": "Steering Deep Feature Learning with Backward Aligned Feature Updates",
            "updated": "2023-11-30T17:19:18Z",
            "published": "2023-11-30T17:19:18Z",
            "summary": "Deep learning succeeds by doing hierarchical feature learning, yet tuning\nHyper-Parameters (HP) such as initialization scales, learning rates etc., only\ngive indirect control over this behavior. In this paper, we propose the\nalignment between the feature updates and the backward pass as a key notion to\npredict, measure and control feature learning. On the one hand, we show that\nwhen alignment holds, the magnitude of feature updates after one SGD step is\nrelated to the magnitude of the forward and backward passes by a simple and\ngeneral formula. This leads to techniques to automatically adjust HPs\n(initialization scales and learning rates) at initialization and throughout\ntraining to attain a desired feature learning behavior. On the other hand, we\nshow that, at random initialization, this alignment is determined by the\nspectrum of a certain kernel, and that well-conditioned layer-to-layer\nJacobians (aka dynamical isometry) implies alignment. Finally, we investigate\nReLU MLPs and ResNets in the large width-then-depth limit. Combining hints from\nrandom matrix theory and numerical experiments, we show that (i) in MLP with\niid initializations, alignment degenerates with depth, making it impossible to\nstart training, and that (ii) in ResNets, the branch scale\n$1/\\sqrt{\\text{depth}}$ is the only one maintaining non-trivial alignment at\ninfinite depth.",
            "author": [
                "L\u00e9na\u00efc Chizat",
                "Praneeth Netrapalli"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18718v1",
                "http://arxiv.org/pdf/2311.18718v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "68T07"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00105v1",
            "title": "Improving the Robustness of Quantized Deep Neural Networks to White-Box\n  Attacks using Stochastic Quantization and Information-Theoretic Ensemble\n  Training",
            "updated": "2023-11-30T17:15:58Z",
            "published": "2023-11-30T17:15:58Z",
            "summary": "Most real-world applications that employ deep neural networks (DNNs) quantize\nthem to low precision to reduce the compute needs. We present a method to\nimprove the robustness of quantized DNNs to white-box adversarial attacks. We\nfirst tackle the limitation of deterministic quantization to fixed ``bins'' by\nintroducing a differentiable Stochastic Quantizer (SQ). We explore the\nhypothesis that different quantizations may collectively be more robust than\neach quantized DNN. We formulate a training objective to encourage different\nquantized DNNs to learn different representations of the input image. The\ntraining objective captures diversity and accuracy via mutual information\nbetween ensemble members. Through experimentation, we demonstrate substantial\nimprovement in robustness against $L_\\infty$ attacks even if the attacker is\nallowed to backpropagate through SQ (e.g., > 50\\% accuracy to PGD(5/255) on\nCIFAR10 without adversarial training), compared to vanilla DNNs as well as\nexisting ensembles of quantized DNNs. We extend the method to detect attacks\nand generate robustness profiles in the adversarial information plane (AIP),\ntowards a unified analysis of different threat models by correlating the MI and\naccuracy.",
            "author": [
                "Saurabh Farkya",
                "Aswin Raghavan",
                "Avi Ziskind"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00105v1",
                "http://arxiv.org/pdf/2312.00105v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18715v1",
            "title": "Accelerating Flow Simulations using Online Dynamic Mode Decomposition",
            "updated": "2023-11-30T17:15:15Z",
            "published": "2023-11-30T17:15:15Z",
            "summary": "We develop an on-the-fly reduced-order model (ROM) integrated with a flow\nsimulation, gradually replacing a corresponding full-order model (FOM) of a\nphysics solver. Unlike offline methods requiring a separate FOM-only simulation\nprior to model reduction, our approach constructs a ROM dynamically during the\nsimulation, replacing the FOM when deemed credible. Dynamic mode decomposition\n(DMD) is employed for online ROM construction, with a single snapshot vector\nused for rank-1 updates in each iteration. Demonstrated on a flow over a\ncylinder with Re = 100, our hybrid FOM/ROM simulation is verified in terms of\nthe Strouhal number, resulting in a 4.4 times speedup compared to the FOM\nsolver.",
            "author": [
                "Seung Won Suh",
                "Seung Whan Chung",
                "Peer-Timo Bremer",
                "Youngsoo Choi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18715v1",
                "http://arxiv.org/pdf/2311.18715v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18711v1",
            "title": "Women Are Beautiful, Men Are Leaders: Gender Stereotypes in Machine\n  Translation and Language Modeling",
            "updated": "2023-11-30T17:06:00Z",
            "published": "2023-11-30T17:06:00Z",
            "summary": "We present GEST -- a new dataset for measuring gender-stereotypical reasoning\nin masked LMs and English-to-X machine translation systems. GEST contains\nsamples that are compatible with 9 Slavic languages and English for 16 gender\nstereotypes about men and women (e.g., Women are beautiful, Men are leaders).\nThe definition of said stereotypes was informed by gender experts. We used GEST\nto evaluate 11 masked LMs and 4 machine translation systems. We discovered\nsignificant and consistent amounts of stereotypical reasoning in almost all the\nevaluated models and languages.",
            "author": [
                "Mat\u00fa\u0161 Pikuliak",
                "Andrea Hrckova",
                "Stefan Oresko",
                "Mari\u00e1n \u0160imko"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18711v1",
                "http://arxiv.org/pdf/2311.18711v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18710v1",
            "title": "Meta-Prior: Meta learning for Adaptive Inverse Problem Solvers",
            "updated": "2023-11-30T17:02:27Z",
            "published": "2023-11-30T17:02:27Z",
            "summary": "Deep neural networks have become a foundational tool for addressing imaging\ninverse problems. They are typically trained for a specific task, with a\nsupervised loss to learn a mapping from the observations to the image to\nrecover. However, real-world imaging challenges often lack ground truth data,\nrendering traditional supervised approaches ineffective. Moreover, for each new\nimaging task, a new model needs to be trained from scratch, wasting time and\nresources. To overcome these limitations, we introduce a novel approach based\non meta-learning. Our method trains a meta-model on a diverse set of imaging\ntasks that allows the model to be efficiently fine-tuned for specific tasks\nwith few fine-tuning steps. We show that the proposed method extends to the\nunsupervised setting, where no ground truth data is available. In its bilevel\nformulation, the outer level uses a supervised loss, that evaluates how well\nthe fine-tuned model performs, while the inner loss can be either supervised or\nunsupervised, relying only on the measurement operator. This allows the\nmeta-model to leverage a few ground truth samples for each task while being\nable to generalize to new imaging tasks. We show that in simple settings, this\napproach recovers the Bayes optimal estimator, illustrating the soundness of\nour approach. We also demonstrate our method's effectiveness on various tasks,\nincluding image processing and magnetic resonance imaging.",
            "author": [
                "Matthieu Terris",
                "Thomas Moreau"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18710v1",
                "http://arxiv.org/pdf/2311.18710v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00103v1",
            "title": "DeepEn2023: Energy Datasets for Edge Artificial Intelligence",
            "updated": "2023-11-30T16:54:36Z",
            "published": "2023-11-30T16:54:36Z",
            "summary": "Climate change poses one of the most significant challenges to humanity. As a\nresult of these climatic changes, the frequency of weather, climate, and\nwater-related disasters has multiplied fivefold over the past 50 years,\nresulting in over 2 million deaths and losses exceeding $3.64 trillion USD.\nLeveraging AI-powered technologies for sustainable development and combating\nclimate change is a promising avenue. Numerous significant publications are\ndedicated to using AI to improve renewable energy forecasting, enhance waste\nmanagement, and monitor environmental changes in real time. However, very few\nresearch studies focus on making AI itself environmentally sustainable. This\noversight regarding the sustainability of AI within the field might be\nattributed to a mindset gap and the absence of comprehensive energy datasets.\nIn addition, with the ubiquity of edge AI systems and applications, especially\non-device learning, there is a pressing need to measure, analyze, and optimize\ntheir environmental sustainability, such as energy efficiency. To this end, in\nthis paper, we propose large-scale energy datasets for edge AI, named\nDeepEn2023, covering a wide range of kernels, state-of-the-art deep neural\nnetwork models, and popular edge AI applications. We anticipate that DeepEn2023\nwill improve transparency in sustainability in on-device deep learning across a\nrange of edge AI systems and applications. For more information, including\naccess to the dataset and code, please visit\nhttps://amai-gsu.github.io/DeepEn2023.",
            "author": [
                "Xiaolong Tu",
                "Anik Mallik",
                "Haoxin Wang",
                "Jiang Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00103v1",
                "http://arxiv.org/pdf/2312.00103v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.PF"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18703v1",
            "title": "Predictable Reinforcement Learning Dynamics through Entropy Rate\n  Minimization",
            "updated": "2023-11-30T16:53:32Z",
            "published": "2023-11-30T16:53:32Z",
            "summary": "In Reinforcement Learning (RL), agents have no incentive to exhibit\npredictable behaviors, and are often pushed (through e.g. policy entropy\nregularization) to randomize their actions in favor of exploration. From a\nhuman perspective, this makes RL agents hard to interpret and predict, and from\na safety perspective, even harder to formally verify. We propose a novel method\nto induce predictable behavior in RL agents, referred to as\nPredictability-Aware RL (PA-RL), which employs the state sequence entropy rate\nas a predictability measure. We show how the entropy rate can be formulated as\nan average reward objective, and since its entropy reward function is\npolicy-dependent, we introduce an action-dependent surrogate entropy enabling\nthe use of PG methods. We prove that deterministic policies minimizing the\naverage surrogate reward exist and also minimize the actual entropy rate, and\nshow how, given a learned dynamical model, we are able to approximate the value\nfunction associated to the true entropy rate. Finally, we demonstrate the\neffectiveness of the approach in RL tasks inspired by human-robot use-cases,\nand show how it produces agents with more predictable behavior while achieving\nnear-optimal rewards.",
            "author": [
                "Daniel Jarne Ornia",
                "Giannis Delimpaltadakis",
                "Jens Kober",
                "Javier Alonso-Mora"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18703v1",
                "http://arxiv.org/pdf/2311.18703v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03746v1",
            "title": "Evaluating Large Language Model Creativity from a Literary Perspective",
            "updated": "2023-11-30T16:46:25Z",
            "published": "2023-11-30T16:46:25Z",
            "summary": "This paper assesses the potential for large language models (LLMs) to serve\nas assistive tools in the creative writing process, by means of a single,\nin-depth case study. In the course of the study, we develop interactive and\nmulti-voice prompting strategies that interleave background descriptions (scene\nsetting, plot elements), instructions that guide composition, samples of text\nin the target style, and critical discussion of the given samples. We\nqualitatively evaluate the results from a literary critical perspective, as\nwell as from the standpoint of computational creativity (a sub-field of\nartificial intelligence). Our findings lend support to the view that the\nsophistication of the results that can be achieved with an LLM mirrors the\nsophistication of the prompting.",
            "author": [
                "Murray Shanahan",
                "Catherine Clarke"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03746v1",
                "http://arxiv.org/pdf/2312.03746v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18695v1",
            "title": "Seg2Reg: Differentiable 2D Segmentation to 1D Regression Rendering for\n  360 Room Layout Reconstruction",
            "updated": "2023-11-30T16:42:24Z",
            "published": "2023-11-30T16:42:24Z",
            "summary": "State-of-the-art single-view 360-degree room layout reconstruction methods\nformulate the problem as a high-level 1D (per-column) regression task. On the\nother hand, traditional low-level 2D layout segmentation is simpler to learn\nand can represent occluded regions, but it requires complex post-processing for\nthe targeting layout polygon and sacrifices accuracy. We present Seg2Reg to\nrender 1D layout depth regression from the 2D segmentation map in a\ndifferentiable and occlusion-aware way, marrying the merits of both sides.\nSpecifically, our model predicts floor-plan density for the input\nequirectangular 360-degree image. Formulating the 2D layout representation as a\ndensity field enables us to employ `flattened' volume rendering to form 1D\nlayout depth regression. In addition, we propose a novel 3D warping\naugmentation on layout to improve generalization. Finally, we re-implement\nrecent room layout reconstruction methods into our codebase for benchmarking\nand explore modern backbones and training techniques to serve as the strong\nbaseline. Our model significantly outperforms previous arts. The code will be\nmade available upon publication.",
            "author": [
                "Cheng Sun",
                "Wei-En Tai",
                "Yu-Lin Shih",
                "Kuan-Wei Chen",
                "Yong-Jing Syu",
                "Kent Selwyn The",
                "Yu-Chiang Frank Wang",
                "Hwann-Tzong Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18695v1",
                "http://arxiv.org/pdf/2311.18695v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18694v1",
            "title": "Balancing Summarization and Change Detection in Graph Streams",
            "updated": "2023-11-30T16:39:46Z",
            "published": "2023-11-30T16:39:46Z",
            "summary": "This study addresses the issue of balancing graph summarization and graph\nchange detection. Graph summarization compresses large-scale graphs into a\nsmaller scale. However, the question remains: To what extent should the\noriginal graph be compressed? This problem is solved from the perspective of\ngraph change detection, aiming to detect statistically significant changes\nusing a stream of summary graphs. If the compression rate is extremely high,\nimportant changes can be ignored, whereas if the compression rate is extremely\nlow, false alarms may increase with more memory. This implies that there is a\ntrade-off between compression rate in graph summarization and accuracy in\nchange detection. We propose a novel quantitative methodology to balance this\ntrade-off to simultaneously realize reliable graph summarization and change\ndetection. We introduce a probabilistic structure of hierarchical latent\nvariable model into a graph, thereby designing a parameterized summary graph on\nthe basis of the minimum description length principle. The parameter specifying\nthe summary graph is then optimized so that the accuracy of change detection is\nguaranteed to suppress Type I error probability (probability of raising false\nalarms) to be less than a given confidence level. First, we provide a\ntheoretical framework for connecting graph summarization with change detection.\nThen, we empirically demonstrate its effectiveness on synthetic and real\ndatasets.",
            "author": [
                "Shintaro Fukushima",
                "Kenji Yamanishi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18694v1",
                "http://arxiv.org/pdf/2311.18694v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.IT",
                "cs.LG",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18684v1",
            "title": "Handling Cost and Constraints with Off-Policy Deep Reinforcement\n  Learning",
            "updated": "2023-11-30T16:31:04Z",
            "published": "2023-11-30T16:31:04Z",
            "summary": "By reusing data throughout training, off-policy deep reinforcement learning\nalgorithms offer improved sample efficiency relative to on-policy approaches.\nFor continuous action spaces, the most popular methods for off-policy learning\ninclude policy improvement steps where a learned state-action ($Q$) value\nfunction is maximized over selected batches of data. These updates are often\npaired with regularization to combat associated overestimation of $Q$ values.\nWith an eye toward safety, we revisit this strategy in environments with\n\"mixed-sign\" reward functions; that is, with reward functions that include\nindependent positive (incentive) and negative (cost) terms. This setting is\ncommon in real-world applications, and may be addressed with or without\nconstraints on the cost terms. We find the combination of function\napproximation and a term that maximizes $Q$ in the policy update to be\nproblematic in such environments, because systematic errors in value estimation\nimpact the contributions from the competing terms asymmetrically. This results\nin overemphasis of either incentives or costs and may severely limit learning.\nWe explore two remedies to this issue. First, consistent with prior work, we\nfind that periodic resetting of $Q$ and policy networks can be used to reduce\nvalue estimation error and improve learning in this setting. Second, we\nformulate novel off-policy actor-critic methods for both unconstrained and\nconstrained learning that do not explicitly maximize $Q$ in the policy update.\nWe find that this second approach, when applied to continuous action spaces\nwith mixed-sign rewards, consistently and significantly outperforms\nstate-of-the-art methods augmented by resetting. We further find that our\napproach produces agents that are both competitive with popular methods overall\nand more reliably competent on frequently-studied control problems that do not\nhave mixed-sign rewards.",
            "author": [
                "Jared Markowitz",
                "Jesse Silverberg",
                "Gary Collins"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18684v1",
                "http://arxiv.org/pdf/2311.18684v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18677v1",
            "title": "Splitwise: Efficient generative LLM inference using phase splitting",
            "updated": "2023-11-30T16:24:42Z",
            "published": "2023-11-30T16:24:42Z",
            "summary": "Recent innovations in generative large language models (LLMs) have made their\napplications and use-cases ubiquitous. This has led to large-scale deployments\nof these models, using complex, expensive, and power-hungry AI accelerators,\nmost commonly GPUs. These developments make LLM inference efficiency an\nimportant challenge. Based on our extensive characterization, we find that\nthere are two main phases during an LLM inference request: a compute-intensive\nprompt computation, and a memory-intensive token generation, each with distinct\nlatency, throughput, memory, and power characteristics. Despite\nstate-of-the-art batching and scheduling, the token generation phase\nunderutilizes compute resources. Specifically, unlike compute-intensive prompt\ncomputation phases, token generation phases do not require the compute\ncapability of the latest GPUs, and can be run with lower power and cost.\n  With Splitwise, we propose splitting the two phases of a LLM inference\nrequest on to separate machines. This allows us to use hardware that is\nwell-suited for each phase, and provision resources independently per phase.\nHowever, splitting an inference request across machines requires state transfer\nfrom the machine running prompt computation over to the machine generating\ntokens. We implement and optimize this state transfer using the fast back-plane\ninterconnects available in today's GPU clusters.\n  We use the Splitwise technique to design LLM inference clusters using the\nsame or different types of machines for the prompt computation and token\ngeneration phases. Our clusters are optimized for three key objectives:\nthroughput, cost, and power. In particular, we show that we can achieve 1.4x\nhigher throughput at 20% lower cost than current designs. Alternatively, we can\nachieve 2.35x more throughput with the same cost and power budgets.",
            "author": [
                "Pratyush Patel",
                "Esha Choukse",
                "Chaojie Zhang",
                "\u00cd\u00f1igo Goiri",
                "Aashaka Shah",
                "Saeed Maleki",
                "Ricardo Bianchini"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18677v1",
                "http://arxiv.org/pdf/2311.18677v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR",
                "cs.DC",
                "I.2.0, I.3.1, C.4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18672v1",
            "title": "A Comparison Between Invariant and Equivariant Classical and Quantum\n  Graph Neural Networks",
            "updated": "2023-11-30T16:19:13Z",
            "published": "2023-11-30T16:19:13Z",
            "summary": "Machine learning algorithms are heavily relied on to understand the vast\namounts of data from high-energy particle collisions at the CERN Large Hadron\nCollider (LHC). The data from such collision events can naturally be\nrepresented with graph structures. Therefore, deep geometric methods, such as\ngraph neural networks (GNNs), have been leveraged for various data analysis\ntasks in high-energy physics. One typical task is jet tagging, where jets are\nviewed as point clouds with distinct features and edge connections between\ntheir constituent particles. The increasing size and complexity of the LHC\nparticle datasets, as well as the computational models used for their analysis,\ngreatly motivate the development of alternative fast and efficient\ncomputational paradigms such as quantum computation. In addition, to enhance\nthe validity and robustness of deep networks, one can leverage the fundamental\nsymmetries present in the data through the use of invariant inputs and\nequivariant layers. In this paper, we perform a fair and comprehensive\ncomparison between classical graph neural networks (GNNs) and equivariant graph\nneural networks (EGNNs) and their quantum counterparts: quantum graph neural\nnetworks (QGNNs) and equivariant quantum graph neural networks (EQGNN). The\nfour architectures were benchmarked on a binary classification task to classify\nthe parton-level particle initiating the jet. Based on their AUC scores, the\nquantum networks were shown to outperform the classical networks. However,\nseeing the computational advantage of the quantum networks in practice may have\nto wait for the further development of quantum technology and its associated\nAPIs.",
            "author": [
                "Roy T. Forestano",
                "Mar\u00e7al Comajoan Cara",
                "Gopal Ramesh Dahale",
                "Zhongtian Dong",
                "Sergei Gleyzer",
                "Daniel Justice",
                "Kyoungchul Kong",
                "Tom Magorsch",
                "Konstantin T. Matchev",
                "Katia Matcheva",
                "Eyup B. Unlu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18672v1",
                "http://arxiv.org/pdf/2311.18672v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.LG",
                "hep-ph",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18664v1",
            "title": "Multi-task learning with cross-task consistency for improved depth\n  estimation in colonoscopy",
            "updated": "2023-11-30T16:13:17Z",
            "published": "2023-11-30T16:13:17Z",
            "summary": "Colonoscopy screening is the gold standard procedure for assessing\nabnormalities in the colon and rectum, such as ulcers and cancerous polyps.\nMeasuring the abnormal mucosal area and its 3D reconstruction can help quantify\nthe surveyed area and objectively evaluate disease burden. However, due to the\ncomplex topology of these organs and variable physical conditions, for example,\nlighting, large homogeneous texture, and image modality estimating distance\nfrom the camera aka depth) is highly challenging. Moreover, most colonoscopic\nvideo acquisition is monocular, making the depth estimation a non-trivial\nproblem. While methods in computer vision for depth estimation have been\nproposed and advanced on natural scene datasets, the efficacy of these\ntechniques has not been widely quantified on colonoscopy datasets. As the\ncolonic mucosa has several low-texture regions that are not well pronounced,\nlearning representations from an auxiliary task can improve salient feature\nextraction, allowing estimation of accurate camera depths. In this work, we\npropose to develop a novel multi-task learning (MTL) approach with a shared\nencoder and two decoders, namely a surface normal decoder and a depth estimator\ndecoder. Our depth estimator incorporates attention mechanisms to enhance\nglobal context awareness. We leverage the surface normal prediction to improve\ngeometric feature extraction. Also, we apply a cross-task consistency loss\namong the two geometrically related tasks, surface normal and camera depth. We\ndemonstrate an improvement of 14.17% on relative error and 10.4% improvement on\n$\\delta_{1}$ accuracy over the most accurate baseline state-of-the-art BTS\napproach. All experiments are conducted on a recently released C3VD dataset;\nthus, we provide a first benchmark of state-of-the-art methods.",
            "author": [
                "Pedro Esteban Chavarrias Solano",
                "Andrew Bulpitt",
                "Venkataraman Subramanian",
                "Sharib Ali"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18664v1",
                "http://arxiv.org/pdf/2311.18664v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18663v1",
            "title": "Choosing the parameter of the Fermat distance: navigating geometry and\n  noise",
            "updated": "2023-11-30T16:11:12Z",
            "published": "2023-11-30T16:11:12Z",
            "summary": "The Fermat distance has been recently established as a useful tool for\nmachine learning tasks when a natural distance is not directly available to the\npractitioner or to improve the results given by Euclidean distances by\nexploding the geometrical and statistical properties of the dataset. This\ndistance depends on a parameter $\\alpha$ that greatly impacts the performance\nof subsequent tasks. Ideally, the value of $\\alpha$ should be large enough to\nnavigate the geometric intricacies inherent to the problem. At the same, it\nshould remain restrained enough to sidestep any deleterious ramifications\nstemming from noise during the process of distance estimation. We study both\ntheoretically and through simulations how to select this parameter.",
            "author": [
                "Fr\u00e9d\u00e9ric Chazal",
                "Laure Ferraris",
                "Pablo Groisman",
                "Matthieu Jonckheere",
                "Fr\u00e9d\u00e9ric Pascal",
                "Facundo Sapienza"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18663v1",
                "http://arxiv.org/pdf/2311.18663v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.AI",
                "cs.LG",
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18662v2",
            "title": "Solving the Team Orienteering Problem with Transformers",
            "updated": "2023-12-01T09:48:02Z",
            "published": "2023-11-30T16:10:35Z",
            "summary": "Route planning for a fleet of vehicles is an important task in applications\nsuch as package delivery, surveillance, or transportation. This problem is\nusually modeled as a Combinatorial Optimization problem named as Team\nOrienteering Problem. The most popular Team Orienteering Problem solvers are\nmainly based on either linear programming, which provides accurate solutions by\nemploying a large computation time that grows with the size of the problem, or\nheuristic methods, which usually find suboptimal solutions in a shorter amount\nof time. In this paper, a multi-agent route planning system capable of solving\nthe Team Orienteering Problem in a very fast and accurate manner is presented.\nThe proposed system is based on a centralized Transformer neural network that\ncan learn to encode the scenario (modeled as a graph) and the context of the\nagents to provide fast and accurate solutions. Several experiments have been\nperformed to demonstrate that the presented system can outperform most of the\nstate-of-the-art works in terms of computation speed. In addition, the code is\npublicly available at http://gti.ssr.upm.es/data.",
            "author": [
                "Daniel Fuertes",
                "Carlos R. del-Blanco",
                "Fernando Jaureguizar",
                "Narciso Garc\u00eda"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18662v2",
                "http://arxiv.org/pdf/2311.18662v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18661v1",
            "title": "Learning Part Segmentation from Synthetic Animals",
            "updated": "2023-11-30T16:10:04Z",
            "published": "2023-11-30T16:10:04Z",
            "summary": "Semantic part segmentation provides an intricate and interpretable\nunderstanding of an object, thereby benefiting numerous downstream tasks.\nHowever, the need for exhaustive annotations impedes its usage across diverse\nobject types. This paper focuses on learning part segmentation from synthetic\nanimals, leveraging the Skinned Multi-Animal Linear (SMAL) models to scale up\nexisting synthetic data generated by computer-aided design (CAD) animal models.\nCompared to CAD models, SMAL models generate data with a wider range of poses\nobserved in real-world scenarios. As a result, our first contribution is to\nconstruct a synthetic animal dataset of tigers and horses with more pose\ndiversity, termed Synthetic Animal Parts (SAP). We then benchmark Syn-to-Real\nanimal part segmentation from SAP to PartImageNet, namely SynRealPart, with\nexisting semantic segmentation domain adaptation methods and further improve\nthem as our second contribution. Concretely, we examine three Syn-to-Real\nadaptation methods but observe relative performance drop due to the innate\ndifference between the two tasks. To address this, we propose a simple yet\neffective method called Class-Balanced Fourier Data Mixing (CB-FDM). Fourier\nData Mixing aligns the spectral amplitudes of synthetic images with real\nimages, thereby making the mixed images have more similar frequency content to\nreal images. We further use Class-Balanced Pseudo-Label Re-Weighting to\nalleviate the imbalanced class distribution. We demonstrate the efficacy of\nCB-FDM on SynRealPart over previous methods with significant performance\nimprovements. Remarkably, our third contribution is to reveal that the learned\nparts from synthetic tiger and horse are transferable across all quadrupeds in\nPartImageNet, further underscoring the utility and potential applications of\nanimal part segmentation.",
            "author": [
                "Jiawei Peng",
                "Ju He",
                "Prakhar Kaushik",
                "Zihao Xiao",
                "Jiteng Mu",
                "Alan Yuille"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18661v1",
                "http://arxiv.org/pdf/2311.18661v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18659v1",
            "title": "Comparison of Autoscaling Frameworks for Containerised\n  Machine-Learning-Applications in a Local and Cloud Environment",
            "updated": "2023-11-30T16:08:17Z",
            "published": "2023-11-30T16:08:17Z",
            "summary": "When deploying machine learning (ML) applications, the automated allocation\nof computing resources-commonly referred to as autoscaling-is crucial for\nmaintaining a consistent inference time under fluctuating workloads. The\nobjective is to maximize the Quality of Service metrics, emphasizing\nperformance and availability, while minimizing resource costs. In this paper,\nwe compare scalable deployment techniques across three levels of scaling: at\nthe application level (TorchServe, RayServe) and the container level (K3s) in a\nlocal environment (production server), as well as at the container and machine\nlevels in a cloud environment (Amazon Web Services Elastic Container Service\nand Elastic Kubernetes Service). The comparison is conducted through the study\nof mean and standard deviation of inference time in a multi-client scenario,\nalong with upscaling response times. Based on this analysis, we propose a\ndeployment strategy for both local and cloud-based environments.",
            "author": [
                "Christian Schroeder",
                "Rene Boehm",
                "Alexander Lampe"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18659v1",
                "http://arxiv.org/pdf/2311.18659v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "94-04",
                "I.2.11"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00102v2",
            "title": "FedEmb: A Vertical and Hybrid Federated Learning Algorithm using Network\n  And Feature Embedding Aggregation",
            "updated": "2023-12-04T14:27:37Z",
            "published": "2023-11-30T16:01:51Z",
            "summary": "Federated learning (FL) is an emerging paradigm for decentralized training of\nmachine learning models on distributed clients, without revealing the data to\nthe central server. The learning scheme may be horizontal, vertical or hybrid\n(both vertical and horizontal). Most existing research work with deep neural\nnetwork (DNN) modelling is focused on horizontal data distributions, while\nvertical and hybrid schemes are much less studied. In this paper, we propose a\ngeneralized algorithm FedEmb, for modelling vertical and hybrid DNN-based\nlearning. The idea of our algorithm is characterised by higher inference\naccuracy, stronger privacy-preserving properties, and lower client-server\ncommunication bandwidth demands as compared with existing work. The\nexperimental results show that FedEmb is an effective method to tackle both\nsplit feature & subject space decentralized problems, shows 0.3% to 4.2%\ninference accuracy improvement with limited privacy revealing for datasets\nstored in local clients, and reduces 88.9 % time complexity over vertical\nbaseline method.",
            "author": [
                "Fanfei Meng",
                "Lele Zhang",
                "Yu Chen",
                "Yuxin Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00102v2",
                "http://arxiv.org/pdf/2312.00102v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18651v1",
            "title": "LL3DA: Visual Interactive Instruction Tuning for Omni-3D Understanding,\n  Reasoning, and Planning",
            "updated": "2023-11-30T16:00:23Z",
            "published": "2023-11-30T16:00:23Z",
            "summary": "Recent advances in Large Multimodal Models (LMM) have made it possible for\nvarious applications in human-machine interactions. However, developing LMMs\nthat can comprehend, reason, and plan in complex and diverse 3D environments\nremains a challenging topic, especially considering the demand for\nunderstanding permutation-invariant point cloud 3D representations of the 3D\nscene. Existing works seek help from multi-view images, and project 2D features\nto 3D space as 3D scene representations. This, however, leads to huge\ncomputational overhead and performance degradation. In this paper, we present\nLL3DA, a Large Language 3D Assistant that takes point cloud as direct input and\nrespond to both textual-instructions and visual-prompts. This help LMMs better\ncomprehend human interactions and further help to remove the ambiguities in\ncluttered 3D scenes. Experiments show that LL3DA achieves remarkable results,\nand surpasses various 3D vision-language models on both 3D Dense Captioning and\n3D Question Answering.",
            "author": [
                "Sijin Chen",
                "Xin Chen",
                "Chi Zhang",
                "Mingsheng Li",
                "Gang Yu",
                "Hao Fei",
                "Hongyuan Zhu",
                "Jiayuan Fan",
                "Tao Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18651v1",
                "http://arxiv.org/pdf/2311.18651v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00101v1",
            "title": "Towards Unsupervised Representation Learning: Learning, Evaluating and\n  Transferring Visual Representations",
            "updated": "2023-11-30T15:57:55Z",
            "published": "2023-11-30T15:57:55Z",
            "summary": "Unsupervised representation learning aims at finding methods that learn\nrepresentations from data without annotation-based signals. Abstaining from\nannotations not only leads to economic benefits but may - and to some extent\nalready does - result in advantages regarding the representation's structure,\nrobustness, and generalizability to different tasks. In the long run,\nunsupervised methods are expected to surpass their supervised counterparts due\nto the reduction of human intervention and the inherently more general setup\nthat does not bias the optimization towards an objective originating from\nspecific annotation-based signals. While major advantages of unsupervised\nrepresentation learning have been recently observed in natural language\nprocessing, supervised methods still dominate in vision domains for most tasks.\nIn this dissertation, we contribute to the field of unsupervised (visual)\nrepresentation learning from three perspectives: (i) Learning representations:\nWe design unsupervised, backpropagation-free Convolutional Self-Organizing\nNeural Networks (CSNNs) that utilize self-organization- and Hebbian-based\nlearning rules to learn convolutional kernels and masks to achieve deeper\nbackpropagation-free models. (ii) Evaluating representations: We build upon the\nwidely used (non-)linear evaluation protocol to define pretext- and\ntarget-objective-independent metrics for measuring and investigating the\nobjective function mismatch between various unsupervised pretext tasks and\ntarget tasks. (iii) Transferring representations: We contribute CARLANE, the\nfirst 3-way sim-to-real domain adaptation benchmark for 2D lane detection, and\na method based on prototypical self-supervised learning. Finally, we contribute\na content-consistent unpaired image-to-image translation method that utilizes\nmasks, global and local discriminators, and similarity sampling to mitigate\ncontent inconsistencies.",
            "author": [
                "Bonifaz Stuhr"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00101v1",
                "http://arxiv.org/pdf/2312.00101v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.GR",
                "cs.LG",
                "I.2; I.3; I.4; I.5; I.6"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18649v1",
            "title": "Simple Semantic-Aided Few-Shot Learning",
            "updated": "2023-11-30T15:57:34Z",
            "published": "2023-11-30T15:57:34Z",
            "summary": "Learning from a limited amount of data, namely Few-Shot Learning, stands out\nas a challenging computer vision task. Several works exploit semantics and\ndesign complicated semantic fusion mechanisms to compensate for rare\nrepresentative features within restricted data. However, relying on naive\nsemantics such as class names introduces biases due to their brevity, while\nacquiring extensive semantics from external knowledge takes a huge time and\neffort. This limitation severely constrains the potential of semantics in\nfew-shot learning. In this paper, we design an automatic way called Semantic\nEvolution to generate high-quality semantics. The incorporation of high-quality\nsemantics alleviates the need for complex network structures and learning\nalgorithms used in previous works. Hence, we employ a simple two-layer network\ntermed Semantic Alignment Network to transform semantics and visual features\ninto robust class prototypes with rich discriminative features for few-shot\nclassification. The experimental results show our framework outperforms all\nprevious methods on five benchmarks, demonstrating a simple network with\nhigh-quality semantics can beat intricate multi-modal modules on few-shot\nclassification tasks.",
            "author": [
                "Hai Zhang",
                "Junzhe Xu",
                "Shanlin Jiang",
                "Zhenan He"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18649v1",
                "http://arxiv.org/pdf/2311.18649v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18645v1",
            "title": "Stochastic Vision Transformers with Wasserstein Distance-Aware Attention",
            "updated": "2023-11-30T15:53:37Z",
            "published": "2023-11-30T15:53:37Z",
            "summary": "Self-supervised learning is one of the most promising approaches to acquiring\nknowledge from limited labeled data. Despite the substantial advancements made\nin recent years, self-supervised models have posed a challenge to\npractitioners, as they do not readily provide insight into the model's\nconfidence and uncertainty. Tackling this issue is no simple feat, primarily\ndue to the complexity involved in implementing techniques that can make use of\nthe latent representations learned during pre-training without relying on\nexplicit labels. Motivated by this, we introduce a new stochastic vision\ntransformer that integrates uncertainty and distance awareness into\nself-supervised learning (SSL) pipelines. Instead of the conventional\ndeterministic vector embedding, our novel stochastic vision transformer encodes\nimage patches into elliptical Gaussian distributional embeddings. Notably, the\nattention matrices of these stochastic representational embeddings are computed\nusing Wasserstein distance-based attention, effectively capitalizing on the\ndistributional nature of these embeddings. Additionally, we propose a\nregularization term based on Wasserstein distance for both pre-training and\nfine-tuning processes, thereby incorporating distance awareness into latent\nrepresentations. We perform extensive experiments across different tasks such\nas in-distribution generalization, out-of-distribution detection, dataset\ncorruption, semi-supervised settings, and transfer learning to other datasets\nand tasks. Our proposed method achieves superior accuracy and calibration,\nsurpassing the self-supervised baseline in a wide range of experiments on a\nvariety of datasets.",
            "author": [
                "Franciskus Xaverius Erick",
                "Mina Rezaei",
                "Johanna Paula M\u00fcller",
                "Bernhard Kainz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18645v1",
                "http://arxiv.org/pdf/2311.18645v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18641v1",
            "title": "CrimeGAT: Leveraging Graph Attention Networks for Enhanced Predictive\n  Policing in Criminal Networks",
            "updated": "2023-11-30T15:47:59Z",
            "published": "2023-11-30T15:47:59Z",
            "summary": "In this paper, we present CrimeGAT, a novel application of Graph Attention\nNetworks (GATs) for predictive policing in criminal networks. Criminal networks\npose unique challenges for predictive analytics due to their complex structure,\nmulti-relational links, and dynamic behavior. Traditional methods often fail to\ncapture these complexities, leading to suboptimal predictions. To address these\nchallenges, we propose the use of GATs, which can effectively leverage both\nnode features and graph structure to make predictions. Our proposed CrimeGAT\nmodel integrates attention mechanisms to weigh the importance of a node's\nneighbors, thereby capturing the local and global structures of criminal\nnetworks. We formulate the problem as learning a function that maps node\nfeatures and graph structure to a prediction of future criminal activity. The\nexperimental results on real-world datasets demonstrate that CrimeGAT\nout-performs conventional methods in predicting criminal activities, thereby\nproviding a powerful tool for law enforcement agencies to proactively deploy\nresources. Furthermore, the interpretable nature of the attentionmechanism\ninGATs offers insights into the key players and relationships in criminal\nnetworks. This research opens new avenues for applying deep learning techniques\nin the Aeld of predictive policing and criminal network analysis.",
            "author": [
                "Chen Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18641v1",
                "http://arxiv.org/pdf/2311.18641v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18640v1",
            "title": "The detection, extraction and parameter estimation of extreme-mass-ratio\n  inspirals with deep learning",
            "updated": "2023-11-30T15:46:44Z",
            "published": "2023-11-30T15:46:44Z",
            "summary": "One of the primary goals of space-borne gravitational wave detectors is to\ndetect and analyze extreme-mass-ratio inspirals (EMRIs). This endeavor presents\na significant challenge due to the complex and lengthy EMRI signals, further\ncompounded by their inherently faint nature. In this letter, we introduce a\n2-layer Convolutional Neural Network (CNN) approach to detect EMRI signals for\nspace-borne detectors, achieving a true positive rate (TPR) of 96.9 % at a 1 %\nfalse positive rate (FPR) for signal-to-noise ratio (SNR) from 50 to 100.\nEspecially, the key intrinsic parameters of EMRIs such as mass and spin of the\nsupermassive black hole (SMBH) and the initial eccentricity of the orbit can be\ninferred directly by employing a VGG network. The mass and spin of the SMBH can\nbe determined at 99 % and 92 % respectively. This will greatly reduce the\nparameter spaces and computing cost for the following Bayesian parameter\nestimation. Our model also has a low dependency on the accuracy of the waveform\nmodel. This study underscores the potential of deep learning methods in EMRI\ndata analysis, enabling the rapid detection of EMRI signals and efficient\nparameter estimation .",
            "author": [
                "Qianyun Yun",
                "Wen-Biao Han",
                "Yi-Yang Guo",
                "He Wang",
                "Minghui Du"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18640v1",
                "http://arxiv.org/pdf/2311.18640v1"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18639v1",
            "title": "Targeted Reduction of Causal Models",
            "updated": "2023-11-30T15:46:22Z",
            "published": "2023-11-30T15:46:22Z",
            "summary": "Why does a phenomenon occur? Addressing this question is central to most\nscientific inquiries based on empirical observations, and often heavily relies\non simulations of scientific models. As models become more intricate,\ndeciphering the causes behind these phenomena in high-dimensional spaces of\ninterconnected variables becomes increasingly challenging. Causal machine\nlearning may assist scientists in the discovery of relevant and interpretable\npatterns of causation in simulations. We introduce Targeted Causal Reduction\n(TCR), a method for turning complex models into a concise set of causal factors\nthat explain a specific target phenomenon. We derive an information theoretic\nobjective to learn TCR from interventional data or simulations and propose\nalgorithms to optimize this objective efficiently. TCR's ability to generate\ninterpretable high-level explanations from complex models is demonstrated on\ntoy and mechanical systems, illustrating its potential to assist scientists in\nthe study of complex phenomena in a broad range of disciplines.",
            "author": [
                "Armin Keki\u0107",
                "Bernhard Sch\u00f6lkopf",
                "Michel Besserve"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18639v1",
                "http://arxiv.org/pdf/2311.18639v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00099v1",
            "title": "Online Influence Maximization: Concept and Algorithm",
            "updated": "2023-11-30T15:24:05Z",
            "published": "2023-11-30T15:24:05Z",
            "summary": "In this survey, we offer an extensive overview of the Online Influence\nMaximization (IM) problem by covering both theoretical aspects and practical\napplications. For the integrity of the article and because the online algorithm\ntakes an offline oracle as a subroutine, we first make a clear definition of\nthe Offline IM problem and summarize those commonly used Offline IM algorithms,\nwhich include traditional approximation or heuristic algorithms and ML-based\nalgorithms. Then, we give a standard definition of the Online IM problem and a\nbasic Combinatorial Multi-Armed Bandit (CMAB) framework, CMAB-T. Here, we\nsummarize three types of feedback in the CMAB model and discuss in detail how\nto study the Online IM problem based on the CMAB-T model. This paves the way\nfor solving the Online IM problem by using online learning methods.\nFurthermore, we have covered almost all Online IM algorithms up to now,\nfocusing on characteristics and theoretical guarantees of online algorithms for\ndifferent feedback types. Here, we elaborately explain their working principle\nand how to obtain regret bounds. Besides, we also collect plenty of innovative\nideas about problem definition and algorithm designs and pioneering works for\nvariants of the Online IM problem and their corresponding algorithms. Finally,\nwe encapsulate current challenges and outline prospective research directions\nfrom four distinct perspectives.",
            "author": [
                "Jianxiong Guo"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00099v1",
                "http://arxiv.org/pdf/2312.00099v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18620v1",
            "title": "Data-driven prediction of tool wear using Bayesian-regularized\n  artificial neural networks",
            "updated": "2023-11-30T15:22:20Z",
            "published": "2023-11-30T15:22:20Z",
            "summary": "The prediction of tool wear helps minimize costs and enhance product quality\nin manufacturing. While existing data-driven models using machine learning and\ndeep learning have contributed to the accurate prediction of tool wear, they\noften lack generality and require substantial training data for high accuracy.\nIn this paper, we propose a new data-driven model that uses Bayesian\nRegularized Artificial Neural Networks (BRANNs) to precisely predict milling\ntool wear. BRANNs combine the strengths and leverage the benefits of artificial\nneural networks (ANNs) and Bayesian regularization, whereby ANNs learn complex\npatterns and Bayesian regularization handles uncertainty and prevents\noverfitting, resulting in a more generalized model. We treat both process\nparameters and monitoring sensor signals as BRANN input parameters. We\nconducted an extensive experimental study featuring four different experimental\ndata sets, including the NASA Ames milling dataset, the 2010 PHM Data Challenge\ndataset, the NUAA Ideahouse tool wear dataset, and an in-house performed\nend-milling of the Ti6Al4V dataset. We inspect the impact of input features,\ntraining data size, hidden units, training algorithms, and transfer functions\non the performance of the proposed BRANN model and demonstrate that it\noutperforms existing state-of-the-art models in terms of accuracy and\nreliability.",
            "author": [
                "Tam T. Truong",
                "Jay Airao",
                "Panagiotis Karras",
                "Faramarz Hojati",
                "Bahman Azarhoushang",
                "Ramin Aghababaei"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18620v1",
                "http://arxiv.org/pdf/2311.18620v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18618v1",
            "title": "JPPF: Multi-task Fusion for Consistent Panoptic-Part Segmentation",
            "updated": "2023-11-30T15:17:46Z",
            "published": "2023-11-30T15:17:46Z",
            "summary": "Part-aware panoptic segmentation is a problem of computer vision that aims to\nprovide a semantic understanding of the scene at multiple levels of\ngranularity. More precisely, semantic areas, object instances, and semantic\nparts are predicted simultaneously. In this paper, we present our Joint\nPanoptic Part Fusion (JPPF) that combines the three individual segmentations\neffectively to obtain a panoptic-part segmentation. Two aspects are of utmost\nimportance for this: First, a unified model for the three problems is desired\nthat allows for mutually improved and consistent representation learning.\nSecond, balancing the combination so that it gives equal importance to all\nindividual results during fusion. Our proposed JPPF is parameter-free and\ndynamically balances its input. The method is evaluated and compared on the\nCityscapes Panoptic Parts (CPP) and Pascal Panoptic Parts (PPP) datasets in\nterms of PartPQ and Part-Whole Quality (PWQ). In extensive experiments, we\nverify the importance of our fair fusion, highlight its most significant impact\nfor areas that can be further segmented into parts, and demonstrate the\ngeneralization capabilities of our design without fine-tuning on 5 additional\ndatasets.",
            "author": [
                "Shishir Muralidhara",
                "Sravan Kumar Jagadeesh",
                "Ren\u00e9 Schuster",
                "Didier Stricker"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18618v1",
                "http://arxiv.org/pdf/2311.18618v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18612v1",
            "title": "Cancer-Net PCa-Gen: Synthesis of Realistic Prostate Diffusion Weighted\n  Imaging Data via Anatomic-Conditional Controlled Latent Diffusion",
            "updated": "2023-11-30T15:11:03Z",
            "published": "2023-11-30T15:11:03Z",
            "summary": "In Canada, prostate cancer is the most common form of cancer in men and\naccounted for 20% of new cancer cases for this demographic in 2022. Due to\nrecent successes in leveraging machine learning for clinical decision support,\nthere has been significant interest in the development of deep neural networks\nfor prostate cancer diagnosis, prognosis, and treatment planning using\ndiffusion weighted imaging (DWI) data. A major challenge hindering widespread\nadoption in clinical use is poor generalization of such networks due to\nscarcity of large-scale, diverse, balanced prostate imaging datasets for\ntraining such networks. In this study, we explore the efficacy of latent\ndiffusion for generating realistic prostate DWI data through the introduction\nof an anatomic-conditional controlled latent diffusion strategy. To the best of\nthe authors' knowledge, this is the first study to leverage conditioning for\nsynthesis of prostate cancer imaging. Experimental results show that the\nproposed strategy, which we call Cancer-Net PCa-Gen, enhances synthesis of\ndiverse prostate images through controllable tumour locations and better\nanatomical and textural fidelity. These crucial features make it well-suited\nfor augmenting real patient data, enabling neural networks to be trained on a\nmore diverse and comprehensive data distribution. The Cancer-Net PCa-Gen\nframework and sample images have been made publicly available at\nhttps://www.kaggle.com/datasets/deetsadi/cancer-net-pca-gen-dataset as a part\nof a global open-source initiative dedicated to accelerating advancement in\nmachine learning to aid clinicians in the fight against cancer.",
            "author": [
                "Aditya Sridhar",
                "Chi-en Amy Tai",
                "Hayden Gunraj",
                "Yuhao Chen",
                "Alexander Wong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18612v1",
                "http://arxiv.org/pdf/2311.18612v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18610v1",
            "title": "DiffCAD: Weakly-Supervised Probabilistic CAD Model Retrieval and\n  Alignment from an RGB Image",
            "updated": "2023-11-30T15:10:21Z",
            "published": "2023-11-30T15:10:21Z",
            "summary": "Perceiving 3D structures from RGB images based on CAD model primitives can\nenable an effective, efficient 3D object-based representation of scenes.\nHowever, current approaches rely on supervision from expensive annotations of\nCAD models associated with real images, and encounter challenges due to the\ninherent ambiguities in the task -- both in depth-scale ambiguity in monocular\nperception, as well as inexact matches of CAD database models to real\nobservations. We thus propose DiffCAD, the first weakly-supervised\nprobabilistic approach to CAD retrieval and alignment from an RGB image. We\nformulate this as a conditional generative task, leveraging diffusion to learn\nimplicit probabilistic models capturing the shape, pose, and scale of CAD\nobjects in an image. This enables multi-hypothesis generation of different\nplausible CAD reconstructions, requiring only a few hypotheses to characterize\nambiguities in depth/scale and inexact shape matches. Our approach is trained\nonly on synthetic data, leveraging monocular depth and mask estimates to enable\nrobust zero-shot adaptation to various real target domains. Despite being\ntrained solely on synthetic data, our multi-hypothesis approach can even\nsurpass the supervised state-of-the-art on the Scan2CAD dataset by 5.9% with 8\nhypotheses.",
            "author": [
                "Daoyi Gao",
                "D\u00e1vid Rozenberszki",
                "Stefan Leutenegger",
                "Angela Dai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18610v1",
                "http://arxiv.org/pdf/2311.18610v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18609v1",
            "title": "ArthModel: Enhance Arithmetic Skills to Large Language Model",
            "updated": "2023-11-30T15:06:50Z",
            "published": "2023-11-30T15:06:50Z",
            "summary": "With the great success of ChatGPT, the research of large language models has\nbecome increasingly popular. However, the models have several limitations, such\nas toxicity and pool performance of arithmetic solving. Meanwhile, LLM may have\nsome potential abilities that have yet to be exploited. In this paper, we\nchoose a different way to enhance the arithmetic ability of LLM. We propose to\ntrain LLM to generate a postfix expression related to the arithmetic problem\nand incorporate it with small pretrained models. Moreover, this small model\ntransfers the token embeddings into real dense numbers and invokes native\nfunctions of a deep learning platform to get the correct answer. To generate\nthe final result, we propose prompt injection for adding the result outputs by\nthe small model to LLM. This work provides different ways of thinking, training\nand using a language model. The codes and models will be released at\n\\url{https://github.com/eteced/arithmetic_finetuning_v1}.",
            "author": [
                "Yingdi Guo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18609v1",
                "http://arxiv.org/pdf/2311.18609v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18608v1",
            "title": "Contrastive Denoising Score for Text-guided Latent Diffusion Image\n  Editing",
            "updated": "2023-11-30T15:06:10Z",
            "published": "2023-11-30T15:06:10Z",
            "summary": "With the remarkable advent of text-to-image diffusion models, image editing\nmethods have become more diverse and continue to evolve. A promising recent\napproach in this realm is Delta Denoising Score (DDS) - an image editing\ntechnique based on Score Distillation Sampling (SDS) framework that leverages\nthe rich generative prior of text-to-image diffusion models. However, relying\nsolely on the difference between scoring functions is insufficient for\npreserving specific structural elements from the original image, a crucial\naspect of image editing. Inspired by the similarity and importance differences\nbetween DDS and the contrastive learning for unpaired image-to-image\ntranslation (CUT), here we present an embarrassingly simple yet very powerful\nmodification of DDS, called Contrastive Denoising Score (CDS), for latent\ndiffusion models (LDM). Specifically, to enforce structural correspondence\nbetween the input and output while maintaining the controllability of contents,\nwe introduce a straightforward approach to regulate structural consistency\nusing CUT loss within the DDS framework. To calculate this loss, instead of\nemploying auxiliary networks, we utilize the intermediate features of LDM, in\nparticular, those from the self-attention layers, which possesses rich spatial\ninformation. Our approach enables zero-shot image-to-image translation and\nneural radiance field (NeRF) editing, achieving a well-balanced interplay\nbetween maintaining the structural details and transforming content.\nQualitative results and comparisons demonstrates the effectiveness of our\nproposed method. Project page with code is available at\nhttps://hyelinnam.github.io/CDS/.",
            "author": [
                "Hyelin Nam",
                "Gihyun Kwon",
                "Geon Yeong Park",
                "Jong Chul Ye"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18608v1",
                "http://arxiv.org/pdf/2311.18608v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18605v2",
            "title": "Learning Triangular Distribution in Visual World",
            "updated": "2023-12-04T05:05:03Z",
            "published": "2023-11-30T15:02:13Z",
            "summary": "Convolution neural network is successful in pervasive vision tasks, including\nlabel distribution learning, which usually takes the form of learning an\ninjection from the non-linear visual features to the well-defined labels.\nHowever, how the discrepancy between features is mapped to the label\ndiscrepancy is ambient, and its correctness is not guaranteed. To address these\nproblems, we study the mathematical connection between feature and its label,\npresenting a general and simple framework for label distribution learning. We\npropose a so-called Triangular Distribution Transform (TDT) to build an\ninjective function between feature and label, guaranteeing that any symmetric\nfeature discrepancy linearly reflects the difference between labels. The\nproposed TDT can be used as a plug-in in mainstream backbone networks to\naddress different label distribution learning tasks. Experiments on Facial Age\nRecognition, Illumination Chromaticity Estimation, and Aesthetics assessment\nshow that TDT achieves on-par or better results than the prior arts.",
            "author": [
                "Ping Chen",
                "Xingpeng Zhang",
                "Chengtao Zhou",
                "Dichao Fan",
                "Peng Tu",
                "Le Zhang",
                "Yanlin Qian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18605v2",
                "http://arxiv.org/pdf/2311.18605v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18603v1",
            "title": "Energy conservative isogeometric techniques for the wave equation",
            "updated": "2023-11-30T14:56:00Z",
            "published": "2023-11-30T14:56:00Z",
            "summary": "We analyze the wave equation in mixed form, with periodic and/or Dirichlet\nhomogeneous boundary conditions, and nonconstant coefficients that depend on\nthe spatial variable. For the discretization, the weak form of the second\nequation is replaced by a strong form, written in terms of a projection\noperator. The system of equations is discretized with B-splines forming a De\nRham complex along with suitable commutative projectors for the approximation\nof the second equation. The discrete scheme is energy conservative when\ndiscretized in time with a conservative method such as Crank-Nicolson. We\npropose a convergence analysis of the method to study the dependence with\nrespect to the mesh size $h$, with focus on the consistency error. Numerical\nresults show optimal convergence of the error in energy norm, and a relative\nerror in energy conservation for long-time simulations of the order of machine\nprecision.",
            "author": [
                "Andrea Bressan",
                "Annalisa Buffa",
                "Alen Kushova",
                "Rafael V\u00e1zquez"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18603v1",
                "http://arxiv.org/pdf/2311.18603v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "65"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18598v1",
            "title": "Generalisable Agents for Neural Network Optimisation",
            "updated": "2023-11-30T14:45:51Z",
            "published": "2023-11-30T14:45:51Z",
            "summary": "Optimising deep neural networks is a challenging task due to complex training\ndynamics, high computational requirements, and long training times. To address\nthis difficulty, we propose the framework of Generalisable Agents for Neural\nNetwork Optimisation (GANNO) -- a multi-agent reinforcement learning (MARL)\napproach that learns to improve neural network optimisation by dynamically and\nresponsively scheduling hyperparameters during training. GANNO utilises an\nagent per layer that observes localised network dynamics and accordingly takes\nactions to adjust these dynamics at a layerwise level to collectively improve\nglobal performance. In this paper, we use GANNO to control the layerwise\nlearning rate and show that the framework can yield useful and responsive\nschedules that are competitive with handcrafted heuristics. Furthermore, GANNO\nis shown to perform robustly across a wide variety of unseen initial\nconditions, and can successfully generalise to harder problems than it was\ntrained on. Our work presents an overview of the opportunities that this\nparadigm offers for training neural networks, along with key challenges that\nremain to be overcome.",
            "author": [
                "Kale-ab Tessera",
                "Callum Rhys Tilbury",
                "Sasha Abramowitz",
                "Ruan de Kock",
                "Omayma Mahjoub",
                "Benjamin Rosman",
                "Sara Hooker",
                "Arnu Pretorius"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18598v1",
                "http://arxiv.org/pdf/2311.18598v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18588v1",
            "title": "Optimizing ZX-Diagrams with Deep Reinforcement Learning",
            "updated": "2023-11-30T14:29:18Z",
            "published": "2023-11-30T14:29:18Z",
            "summary": "ZX-diagrams are a powerful graphical language for the description of quantum\nprocesses with applications in fundamental quantum mechanics, quantum circuit\noptimization, tensor network simulation, and many more. The utility of\nZX-diagrams relies on a set of local transformation rules that can be applied\nto them without changing the underlying quantum process they describe. These\nrules can be exploited to optimize the structure of ZX-diagrams for a range of\napplications. However, finding an optimal sequence of transformation rules is\ngenerally an open problem. In this work, we bring together ZX-diagrams with\nreinforcement learning, a machine learning technique designed to discover an\noptimal sequence of actions in a decision-making problem and show that a\ntrained reinforcement learning agent can significantly outperform other\noptimization techniques like a greedy strategy or simulated annealing. The use\nof graph neural networks to encode the policy of the agent enables\ngeneralization to diagrams much bigger than seen during the training phase.",
            "author": [
                "Maximilian N\u00e4gele",
                "Florian Marquardt"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18588v1",
                "http://arxiv.org/pdf/2311.18588v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18587v2",
            "title": "Continuous 16-bit Training: Accelerating 32-bit Pre-Trained Neural\n  Networks",
            "updated": "2023-12-01T02:51:32Z",
            "published": "2023-11-30T14:28:25Z",
            "summary": "In the field of deep learning, the prevalence of models initially trained\nwith 32-bit precision is a testament to its robustness and accuracy. However,\nthe continuous evolution of these models often demands further training, which\ncan be resource-intensive. This study introduces a novel approach where we\ncontinue the training of these pre-existing 32-bit models using 16-bit\nprecision. This technique not only caters to the need for efficiency in\ncomputational resources but also significantly improves the speed of additional\ntraining phases. By adopting 16-bit precision for ongoing training, we are able\nto substantially decrease memory requirements and computational burden, thereby\naccelerating the training process in a resource-limited setting. Our\nexperiments show that this method maintains the high standards of accuracy set\nby the original 32-bit training while providing a much-needed boost in training\nspeed. This approach is especially pertinent in today's context, where most\nmodels are initially trained in 32-bit and require periodic updates and\nrefinements. The findings from our research suggest that this strategy of\n16-bit continuation training can be a key solution for sustainable and\nefficient deep learning, offering a practical way to enhance pre-trained models\nrapidly and in a resource-conscious manner.",
            "author": [
                "Juyoung Yun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18587v2",
                "http://arxiv.org/pdf/2311.18587v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18578v1",
            "title": "Communication-Efficient Heterogeneous Federated Learning with\n  Generalized Heavy-Ball Momentum",
            "updated": "2023-11-30T14:17:57Z",
            "published": "2023-11-30T14:17:57Z",
            "summary": "Federated Learning (FL) is the state-of-the-art approach for learning from\ndecentralized data in privacy-constrained scenarios. As the current literature\nreports, the main problems associated with FL refer to system and statistical\nchallenges: the former ones demand for efficient learning from edge devices,\nincluding lowering communication bandwidth and frequency, while the latter\nrequire algorithms robust to non-iidness. State-of-art approaches either\nguarantee convergence at increased communication cost or are not sufficiently\nrobust to handle extreme heterogeneous local distributions. In this work we\npropose a novel generalization of the heavy-ball momentum, and present FedHBM\nto effectively address statistical heterogeneity in FL without introducing any\ncommunication overhead. We conduct extensive experimentation on common FL\nvision and NLP datasets, showing that our FedHBM algorithm empirically yields\nbetter model quality and higher convergence speed w.r.t. the state-of-art,\nespecially in pathological non-iid scenarios. While being designed for\ncross-silo settings, we show how FedHBM is applicable in moderate-to-high\ncross-device scenarios, and how good model initializations (e.g. pre-training)\ncan be exploited for prompt acceleration. Extended experimentation on\nlarge-scale real-world federated datasets further corroborates the\neffectiveness of our approach for real-world FL applications.",
            "author": [
                "Riccardo Zaccone",
                "Carlo Masone",
                "Marco Ciccone"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18578v1",
                "http://arxiv.org/pdf/2311.18578v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18575v1",
            "title": "Class Distribution Shifts in Zero-Shot Learning: Learning Robust\n  Representations",
            "updated": "2023-11-30T14:14:31Z",
            "published": "2023-11-30T14:14:31Z",
            "summary": "Distribution shifts between training and deployment data often affect the\nperformance of machine learning models. In this paper, we explore a setting\nwhere a hidden variable induces a shift in the distribution of classes. These\ndistribution shifts are particularly challenging for zero-shot classifiers, as\nthey rely on representations learned from training classes, but are deployed on\nnew, unseen ones. We introduce an algorithm to learn data representations that\nare robust to such class distribution shifts in zero-shot verification tasks.\nWe show that our approach, which combines hierarchical data sampling with\nout-of-distribution generalization techniques, improves generalization to\ndiverse class distributions in both simulations and real-world datasets.",
            "author": [
                "Yuli Slavutsky",
                "Yuval Benjamini"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18575v1",
                "http://arxiv.org/pdf/2311.18575v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18574v1",
            "title": "Multi-scale Iterative Refinement towards Robust and Versatile Molecular\n  Docking",
            "updated": "2023-11-30T14:09:20Z",
            "published": "2023-11-30T14:09:20Z",
            "summary": "Molecular docking is a key computational tool utilized to predict the binding\nconformations of small molecules to protein targets, which is fundamental in\nthe design of novel drugs. Despite recent advancements in geometric deep\nlearning-based approaches leading to improvements in blind docking efficiency,\nthese methods have encountered notable challenges, such as limited\ngeneralization performance on unseen proteins, the inability to concurrently\naddress the settings of blind docking and site-specific docking, and the\nfrequent occurrence of physical implausibilities such as inter-molecular steric\nclash. In this study, we introduce DeltaDock, a robust and versatile framework\ndesigned for efficient molecular docking to overcome these challenges.\nDeltaDock operates in a two-step process: rapid initial complex structures\nsampling followed by multi-scale iterative refinement of the initial\nstructures. In the initial stage, to sample accurate structures with high\nefficiency, we develop a ligand-dependent binding site prediction model founded\non large protein models and graph neural networks. This model is then paired\nwith GPU-accelerated sampling algorithms. The sampled structures are updated\nusing a multi-scale iterative refinement module that captures both\nprotein-ligand atom-atom interactions and residue-atom interactions in the\nfollowing stage. Distinct from previous geometric deep learning methods that\nare conditioned on the blind docking setting, DeltaDock demonstrates superior\nperformance in both blind docking and site-specific docking settings.\nComprehensive experimental results reveal that DeltaDock consistently surpasses\nbaseline methods in terms of docking accuracy. Furthermore, it displays\nremarkable generalization capabilities and proficiency for predicting\nphysically valid structures, thereby attesting to its robustness and\nreliability in various scenarios.",
            "author": [
                "Jiaxian Yan",
                "Zaixi Zhang",
                "Kai Zhang",
                "Qi Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18574v1",
                "http://arxiv.org/pdf/2311.18574v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00098v1",
            "title": "Identifying tourist destinations from movie scenes using Deep Learning",
            "updated": "2023-11-30T14:09:17Z",
            "published": "2023-11-30T14:09:17Z",
            "summary": "Movies wield significant influence in our lives, playing a pivotal role in\nthe tourism industry of any country. The inclusion of picturesque landscapes,\nwaterfalls, and mountains as backdrops in films serves to enhance the allure of\nspecific scenarios. Recognizing the impact of movies on tourism, this paper\nintroduces a method for identifying tourist destinations featured in films. We\npropose the development of a deep learning model capable of recognizing these\nlocations during movie viewing. The model is trained on a dataset comprising\nmajor tourism destinations worldwide. Through this research, the goal is to\nenable viewers to identify the real-world locations depicted in movie scenes,\noffering a novel way to connect cinema with global travel experiences.",
            "author": [
                "Mahendran Narayanan"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00098v1",
                "http://arxiv.org/pdf/2312.00098v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18572v1",
            "title": "Overcoming Label Noise for Source-free Unsupervised Video Domain\n  Adaptation",
            "updated": "2023-11-30T14:06:27Z",
            "published": "2023-11-30T14:06:27Z",
            "summary": "Despite the progress seen in classification methods, current approaches for\nhandling videos with distribution shifts in source and target domains remain\nsource-dependent as they require access to the source data during the\nadaptation stage. In this paper, we present a self-training based source-free\nvideo domain adaptation approach to address this challenge by bridging the gap\nbetween the source and the target domains. We use the source pre-trained model\nto generate pseudo-labels for the target domain samples, which are inevitably\nnoisy. Thus, we treat the problem of source-free video domain adaptation as\nlearning from noisy labels and argue that the samples with correct\npseudo-labels can help us in adaptation. To this end, we leverage the\ncross-entropy loss as an indicator of the correctness of the pseudo-labels and\nuse the resulting small-loss samples from the target domain for fine-tuning the\nmodel. We further enhance the adaptation performance by implementing a\nteacher-student framework, in which the teacher, which is updated gradually,\nproduces reliable pseudo-labels. Meanwhile, the student undergoes fine-tuning\non the target domain videos using these generated pseudo-labels to improve its\nperformance. Extensive experimental evaluations show that our methods, termed\nas CleanAdapt, CleanAdapt + TS, achieve state-of-the-art results, outperforming\nthe existing approaches on various open datasets. Our source code is publicly\navailable at https://avijit9.github.io/CleanAdapt.",
            "author": [
                "Avijit Dasgupta",
                "C. V. Jawahar",
                "Karteek Alahari"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18572v1",
                "http://arxiv.org/pdf/2311.18572v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18561v1",
            "title": "Periodic Vibration Gaussian: Dynamic Urban Scene Reconstruction and\n  Real-time Rendering",
            "updated": "2023-11-30T13:53:50Z",
            "published": "2023-11-30T13:53:50Z",
            "summary": "Modeling dynamic, large-scale urban scenes is challenging due to their highly\nintricate geometric structures and unconstrained dynamics in both space and\ntime. Prior methods often employ high-level architectural priors, separating\nstatic and dynamic elements, resulting in suboptimal capture of their\nsynergistic interactions. To address this challenge, we present a unified\nrepresentation model, called Periodic Vibration Gaussian (PVG). PVG builds upon\nthe efficient 3D Gaussian splatting technique, originally designed for static\nscene representation, by introducing periodic vibration-based temporal\ndynamics. This innovation enables PVG to elegantly and uniformly represent the\ncharacteristics of various objects and elements in dynamic urban scenes. To\nenhance temporally coherent representation learning with sparse training data,\nwe introduce a novel flow-based temporal smoothing mechanism and a\nposition-aware adaptive control strategy. Extensive experiments on Waymo Open\nDataset and KITTI benchmarks demonstrate that PVG surpasses state-of-the-art\nalternatives in both reconstruction and novel view synthesis for both dynamic\nand static scenes. Notably, PVG achieves this without relying on manually\nlabeled object bounding boxes or expensive optical flow estimation. Moreover,\nPVG exhibits 50/6000-fold acceleration in training/rendering over the best\nalternative.",
            "author": [
                "Yurui Chen",
                "Chun Gu",
                "Junzhe Jiang",
                "Xiatian Zhu",
                "Li Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18561v1",
                "http://arxiv.org/pdf/2311.18561v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18559v1",
            "title": "FediOS: Decoupling Orthogonal Subspaces for Personalization in\n  Feature-skew Federated Learning",
            "updated": "2023-11-30T13:50:38Z",
            "published": "2023-11-30T13:50:38Z",
            "summary": "Personalized federated learning (pFL) enables collaborative training among\nmultiple clients to enhance the capability of customized local models. In pFL,\nclients may have heterogeneous (also known as non-IID) data, which poses a key\nchallenge in how to decouple the data knowledge into generic knowledge for\nglobal sharing and personalized knowledge for preserving local personalization.\nA typical way of pFL focuses on label distribution skew, and they adopt a\ndecoupling scheme where the model is split into a common feature extractor and\ntwo prediction heads (generic and personalized). However, such a decoupling\nscheme cannot solve the essential problem of feature skew heterogeneity,\nbecause a common feature extractor cannot decouple the generic and personalized\nfeatures. Therefore, in this paper, we rethink the architecture decoupling\ndesign for feature-skew pFL and propose an effective pFL method called FediOS.\nIn FediOS, we reformulate the decoupling into two feature extractors (generic\nand personalized) and one shared prediction head. Orthogonal projections are\nused for clients to map the generic features into one common subspace and\nscatter the personalized features into different subspaces to achieve\ndecoupling for them. In addition, a shared prediction head is trained to\nbalance the importance of generic and personalized features during inference.\nExtensive experiments on four vision datasets demonstrate our method reaches\nstate-of-the-art pFL performances under feature skew heterogeneity.",
            "author": [
                "Lingzhi Gao",
                "Zexi Li",
                "Yang Lu",
                "Chao Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18559v1",
                "http://arxiv.org/pdf/2311.18559v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18558v1",
            "title": "Learning Radio Environments by Differentiable Ray Tracing",
            "updated": "2023-11-30T13:50:21Z",
            "published": "2023-11-30T13:50:21Z",
            "summary": "Ray tracing (RT) is instrumental in 6G research in order to generate\nspatially-consistent and environment-specific channel impulse responses (CIRs).\nWhile acquiring accurate scene geometries is now relatively straightforward,\ndetermining material characteristics requires precise calibration using channel\nmeasurements. We therefore introduce a novel gradient-based calibration method,\ncomplemented by differentiable parametrizations of material properties,\nscattering and antenna patterns. Our method seamlessly integrates with\ndifferentiable ray tracers that enable the computation of derivatives of CIRs\nwith respect to these parameters. Essentially, we approach field computation as\na large computational graph wherein parameters are trainable akin to weights of\na neural network (NN). We have validated our method using both synthetic data\nand real-world indoor channel measurements, employing a distributed\nmultiple-input multiple-output (MIMO) channel sounder.",
            "author": [
                "Jakob Hoydis",
                "Fay\u00e7al A\u00eft Aoudia",
                "Sebastian Cammerer",
                "Florian Euchner",
                "Merlin Nimier-David",
                "Stephan ten Brink",
                "Alexander Keller"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18558v1",
                "http://arxiv.org/pdf/2311.18558v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.LG",
                "cs.NI",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18557v1",
            "title": "Can semi-supervised learning use all the data effectively? A lower bound\n  perspective",
            "updated": "2023-11-30T13:48:50Z",
            "published": "2023-11-30T13:48:50Z",
            "summary": "Prior works have shown that semi-supervised learning algorithms can leverage\nunlabeled data to improve over the labeled sample complexity of supervised\nlearning (SL) algorithms. However, existing theoretical analyses focus on\nregimes where the unlabeled data is sufficient to learn a good decision\nboundary using unsupervised learning (UL) alone. This begs the question: Can\nSSL algorithms simultaneously improve upon both UL and SL? To this end, we\nderive a tight lower bound for 2-Gaussian mixture models that explicitly\ndepends on the labeled and the unlabeled dataset size as well as the\nsignal-to-noise ratio of the mixture distribution. Surprisingly, our result\nimplies that no SSL algorithm can improve upon the minimax-optimal statistical\nerror rates of SL or UL algorithms for these distributions. Nevertheless, we\nshow empirically on real-world data that SSL algorithms can still outperform UL\nand SL methods. Therefore, our work suggests that, while proving performance\ngains for SSL algorithms is possible, it requires careful tracking of\nconstants.",
            "author": [
                "Alexandru \u0162ifrea",
                "Gizem Y\u00fcce",
                "Amartya Sanyal",
                "Fanny Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18557v1",
                "http://arxiv.org/pdf/2311.18557v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18553v1",
            "title": "Heterogeneous Graph-based Trajectory Prediction using Local Map Context\n  and Social Interactions",
            "updated": "2023-11-30T13:46:05Z",
            "published": "2023-11-30T13:46:05Z",
            "summary": "Precisely predicting the future trajectories of surrounding traffic\nparticipants is a crucial but challenging problem in autonomous driving, due to\ncomplex interactions between traffic agents, map context and traffic rules.\nVector-based approaches have recently shown to achieve among the best\nperformances on trajectory prediction benchmarks. These methods model simple\ninteractions between traffic agents but don't distinguish between relation-type\nand attributes like their distance along the road. Furthermore, they represent\nlanes only by sequences of vectors representing center lines and ignore context\ninformation like lane dividers and other road elements. We present a novel\napproach for vector-based trajectory prediction that addresses these\nshortcomings by leveraging three crucial sources of information: First, we\nmodel interactions between traffic agents by a semantic scene graph, that\naccounts for the nature and important features of their relation. Second, we\nextract agent-centric image-based map features to model the local map context.\nFinally, we generate anchor paths to enforce the policy in multi-modal\nprediction to permitted trajectories only. Each of these three enhancements\nshows advantages over the baseline model HoliGraph.",
            "author": [
                "Daniel Grimm",
                "Maximilian Zipfl",
                "Felix Hertlein",
                "Alexander Naumann",
                "J\u00fcrgen L\u00fcttin",
                "Steffen Thoma",
                "Stefan Schmid",
                "Lavdim Halilaj",
                "Achim Rettinger",
                "J. Marius Z\u00f6llner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18553v1",
                "http://arxiv.org/pdf/2311.18553v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18547v1",
            "title": "Real-Time Vibration-Based Bearing Fault Diagnosis Under Time-Varying\n  Speed Conditions",
            "updated": "2023-11-30T13:30:00Z",
            "published": "2023-11-30T13:30:00Z",
            "summary": "Detection of rolling-element bearing faults is crucial for implementing\nproactive maintenance strategies and for minimizing the economic and\noperational consequences of unexpected failures. However, many existing\ntechniques are developed and tested under strictly controlled conditions,\nlimiting their adaptability to the diverse and dynamic settings encountered in\npractical applications. This paper presents an efficient real-time\nconvolutional neural network (CNN) for diagnosing multiple bearing faults under\nvarious noise levels and time-varying rotational speeds. Additionally, we\npropose a novel Fisher-based spectral separability analysis (SSA) method to\nelucidate the effectiveness of the designed CNN model. We conducted experiments\non both healthy bearings and bearings afflicted with inner race, outer race,\nand roller ball faults. The experimental results show the superiority of our\nmodel over the current state-of-the-art approach in three folds: it achieves\nsubstantial accuracy gains of up to 15.8%, it is robust to noise with high\nperformance across various signal-to-noise ratios, and it runs in real-time\nwith processing durations five times less than acquisition. Additionally, by\nusing the proposed SSA technique, we offer insights into the model's\nperformance and underscore its effectiveness in tackling real-world challenges.",
            "author": [
                "Tuomas Jalonen",
                "Mohammad Al-Sa'd",
                "Serkan Kiranyaz",
                "Moncef Gabbouj"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18547v1",
                "http://arxiv.org/pdf/2311.18547v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18545v2",
            "title": "Decentralized Deepfake Detection Blockchain Network using Dynamic\n  Algorithm management",
            "updated": "2023-12-01T21:23:59Z",
            "published": "2023-11-30T13:27:00Z",
            "summary": "Deepfake technology is a major threat to the integrity of digital media. This\npaper presents a comprehensive framework for a blockchain-based decentralized\nsystem designed to tackle the escalating challenge of digital content\nintegrity. The proposed system integrates advanced deep learning algorithms\nwith the immutable and transparent nature of blockchain technology to create a\ntrustless environment where authenticity can be verified without relying on a\nsingle centralized authority. Furthermore, the system utilizes smart contracts\nfor dynamic algorithm management and token-based incentives further enhances\nthe system's effectiveness and adaptability. The decentralized architecture of\nthe system democratizes the process of verifying digital content and introduces\na novel approach to combat deepfakes. The collaborative and adjustable nature\nof this system sets a new benchmark for digital media integrity, offering a\nmore robust digital media environment.",
            "author": [
                "Dipankar Sarkar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18545v2",
                "http://arxiv.org/pdf/2311.18545v2"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18543v1",
            "title": "CrimeGraphNet: Link Prediction in Criminal Networks with Graph\n  Convolutional Networks",
            "updated": "2023-11-30T13:25:46Z",
            "published": "2023-11-30T13:25:46Z",
            "summary": "In this paper, we introduce CrimeGraphNet, a novel approach for link\nprediction in criminal networks utilizingGraph Convolutional Networks (GCNs).\nCriminal networks are intricate and dynamic, with covert links that are\nchallenging to uncover. Accurate prediction of these links can aid in proactive\ncrime prevention and investigation. Existing methods often fail to capture the\ncomplex interconnections in such networks. They also struggle in scenarios\nwhere only limited labeled data is available for training. To address these\nchallenges, we propose CrimeGraphNet, which leverages the power of GCNs for\nlink prediction in these networks. The GCNmodel effectively captures\ntopological features and node characteristics, making it well-suited for this\ntask. We evaluate CrimeGraphNet on several real-world criminal network\ndatasets. Our results demonstrate that CrimeGraphNet outperforms existing\nmethods in terms of prediction accuracy, robustness, and computational\nefAciency. Furthermore, our approach enables the extraction of meaningful\ninsights from the predicted links, thereby contributing to a better\nunderstanding of the underlying criminal activities. Overall, CrimeGraphNet\nrepresents a signiAcant step forward in the use of deep learning for criminal\nnetwork analysis.",
            "author": [
                "Chen Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18543v1",
                "http://arxiv.org/pdf/2311.18543v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18540v1",
            "title": "Match me if you can: Semantic Correspondence Learning with Unpaired\n  Images",
            "updated": "2023-11-30T13:22:15Z",
            "published": "2023-11-30T13:22:15Z",
            "summary": "Recent approaches for semantic correspondence have focused on obtaining\nhigh-quality correspondences using a complicated network, refining the\nambiguous or noisy matching points. Despite their performance improvements,\nthey remain constrained by the limited training pairs due to costly point-level\nannotations. This paper proposes a simple yet effective method that performs\ntraining with unlabeled pairs to complement both limited image pairs and sparse\npoint pairs, requiring neither extra labeled keypoints nor trainable modules.\nWe fundamentally extend the data quantity and variety by augmenting new\nunannotated pairs not primitively provided as training pairs in benchmarks.\nUsing a simple teacher-student framework, we offer reliable pseudo\ncorrespondences to the student network via machine supervision. Finally, the\nperformance of our network is steadily improved by the proposed iterative\ntraining, putting back the student as a teacher to generate refined labels and\ntrain a new student repeatedly. Our models outperform the milestone baselines,\nincluding state-of-the-art methods on semantic correspondence benchmarks.",
            "author": [
                "Jiwon Kim",
                "Byeongho Heo",
                "Sangdoo Yun",
                "Seungryong Kim",
                "Dongyoon Han"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18540v1",
                "http://arxiv.org/pdf/2311.18540v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18537v1",
            "title": "MaXTron: Mask Transformer with Trajectory Attention for Video Panoptic\n  Segmentation",
            "updated": "2023-11-30T13:20:09Z",
            "published": "2023-11-30T13:20:09Z",
            "summary": "Video panoptic segmentation requires consistently segmenting (for both\n`thing' and `stuff' classes) and tracking objects in a video over time. In this\nwork, we present MaXTron, a general framework that exploits Mask XFormer with\nTrajectory Attention to tackle the task. MaXTron enriches an off-the-shelf mask\ntransformer by leveraging trajectory attention. The deployed mask transformer\ntakes as input a short clip consisting of only a few frames and predicts the\nclip-level segmentation. To enhance the temporal consistency, MaXTron employs\nwithin-clip and cross-clip tracking modules, efficiently utilizing trajectory\nattention. Originally designed for video classification, trajectory attention\nlearns to model the temporal correspondences between neighboring frames and\naggregates information along the estimated motion paths. However, it is\nnontrivial to directly extend trajectory attention to the per-pixel dense\nprediction tasks due to its quadratic dependency on input size. To alleviate\nthe issue, we propose to adapt the trajectory attention for both the dense\npixel features and object queries, aiming to improve the short-term and\nlong-term tracking results, respectively. Particularly, in our within-clip\ntracking module, we propose axial-trajectory attention that effectively\ncomputes the trajectory attention for tracking dense pixels sequentially along\nthe height- and width-axes. The axial decomposition significantly reduces the\ncomputational complexity for dense pixel features. In our cross-clip tracking\nmodule, since the object queries in mask transformer are learned to encode the\nobject information, we are able to capture the long-term temporal connections\nby applying trajectory attention to object queries, which learns to track each\nobject across different clips. Without bells and whistles, MaXTron demonstrates\nstate-of-the-art performances on video segmentation benchmarks.",
            "author": [
                "Ju He",
                "Qihang Yu",
                "Inkyu Shin",
                "Xueqing Deng",
                "Xiaohui Shen",
                "Alan Yuille",
                "Liang-Chieh Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18537v1",
                "http://arxiv.org/pdf/2311.18537v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00095v1",
            "title": "Textual-Knowledge-Guided Numerical Feature Discovery Method for Power\n  Demand Forecasting",
            "updated": "2023-11-30T13:17:22Z",
            "published": "2023-11-30T13:17:22Z",
            "summary": "Power demand forecasting is a crucial and challenging task for new power\nsystem and integrated energy system. However, as public feature databases and\nthe theoretical mechanism of power demand changes are unavailable, the known\nfeatures of power demand fluctuation are much limited. Recently, multimodal\nlearning approaches have shown great vitality in machine learning and AIGC. In\nthis paper, we interact two modal data and propose a textual-knowledge-guided\nnumerical feature discovery (TKNFD) method for short-term power demand\nforecasting. TKNFD extensively accumulates qualitative textual knowledge,\nexpands it into a candidate feature-type set, collects numerical data of these\nfeatures, and eventually builds four-dimensional multivariate source-tracking\ndatabases (4DM-STDs). Next, TKNFD presents a two-level quantitative feature\nidentification strategy independent of forecasting models, finds 43-48\nfeatures, and systematically analyses feature contribution and dependency\ncorrelation. Benchmark experiments in two different regions around the world\ndemonstrate that the forecasting accuracy of TKNFD-discovered features reliably\noutperforms that of SoTA feature schemes by 16.84% to 36.36% MAPE. In\nparticular, TKNFD reveals many unknown features, especially several dominant\nfeatures in the unknown energy and astronomical dimensions, which extend the\nknowledge on the origin of strong randomness and non-linearity in power demand\nfluctuation. Besides, 4DM-STDs can serve as public baseline databases.",
            "author": [
                "Zifan Ning",
                "Min Jin"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00095v1",
                "http://arxiv.org/pdf/2312.00095v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18531v1",
            "title": "Dataset Distillation via the Wasserstein Metric",
            "updated": "2023-11-30T13:15:28Z",
            "published": "2023-11-30T13:15:28Z",
            "summary": "Dataset distillation (DD) offers a compelling approach in computer vision,\nwith the goal of condensing extensive datasets into smaller synthetic versions\nwithout sacrificing much of the model performance. In this paper, we continue\nto study the methods for DD, by addressing its conceptually core objective: how\nto capture the essential representation of extensive datasets in smaller,\nsynthetic forms.\n  We propose a novel approach utilizing the Wasserstein distance, a metric\nrooted in optimal transport theory, to enhance distribution matching in DD. Our\nmethod leverages the Wasserstein barycenter, offering a geometrically\nmeaningful way to quantify distribution differences and effectively capture the\ncentroid of a set of distributions. Our approach retains the computational\nbenefits of distribution matching-based methods while achieving new\nstate-of-the-art performance on several benchmarks.\n  To provide useful prior for learning the images, we embed the synthetic data\ninto the feature space of pretrained classification models to conduct\ndistribution matching. Extensive testing on various high-resolution datasets\nconfirms the effectiveness and adaptability of our method, indicating the\npromising yet unexplored capabilities of Wasserstein metrics in dataset\ndistillation.",
            "author": [
                "Haoyang Liu",
                "Tiancheng Xing",
                "Luwei Li",
                "Vibhu Dalal",
                "Jingrui He",
                "Haohan Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18531v1",
                "http://arxiv.org/pdf/2311.18531v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00094v1",
            "title": "Fast ODE-based Sampling for Diffusion Models in Around 5 Steps",
            "updated": "2023-11-30T13:07:19Z",
            "published": "2023-11-30T13:07:19Z",
            "summary": "Sampling from diffusion models can be treated as solving the corresponding\nordinary differential equations (ODEs), with the aim of obtaining an accurate\nsolution with as few number of function evaluations (NFE) as possible.\nRecently, various fast samplers utilizing higher-order ODE solvers have emerged\nand achieved better performance than the initial first-order one. However,\nthese numerical methods inherently result in certain approximation errors,\nwhich significantly degrades sample quality with extremely small NFE (e.g.,\naround 5). In contrast, based on the geometric observation that each sampling\ntrajectory almost lies in a two-dimensional subspace embedded in the ambient\nspace, we propose Approximate MEan-Direction Solver (AMED-Solver) that\neliminates truncation errors by directly learning the mean direction for fast\ndiffusion sampling. Besides, our method can be easily used as a plugin to\nfurther improve existing ODE-based samplers. Extensive experiments on image\nsynthesis with the resolution ranging from 32 to 256 demonstrate the\neffectiveness of our method. With only 5 NFE, we achieve 7.14 FID on CIFAR-10,\n13.75 FID on ImageNet 64$\\times$64, and 12.79 FID on LSUN Bedroom. Our code is\navailable at https://github.com/zhyzhouu/amed-solver.",
            "author": [
                "Zhenyu Zhou",
                "Defang Chen",
                "Can Wang",
                "Chun Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00094v1",
                "http://arxiv.org/pdf/2312.00094v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18527v1",
            "title": "InfoFlowNet: A Multi-head Attention-based Self-supervised Learning Model\n  with Surrogate Approach for Uncovering Brain Effective Connectivity",
            "updated": "2023-11-30T13:06:04Z",
            "published": "2023-11-30T13:06:04Z",
            "summary": "Deciphering brain network topology can enhance the depth of neuroscientific\nknowledge and facilitate the development of neural engineering methods.\nEffective connectivity, a measure of brain network dynamics, is particularly\nuseful for investigating the directional influences among different brain\nregions. In this study, we introduce a novel brain causal inference model named\nInfoFlowNet, which leverages the self-attention mechanism to capture\nassociations among electroencephalogram (EEG) time series. The proposed method\nestimates the magnitude of directional information flow (dIF) among EEG\nprocesses by measuring the loss of model inference resulting from the shuffling\nof the time order of the original time series. To evaluate the feasibility of\nInfoFlowNet, we conducted experiments using a synthetic time series and two EEG\ndatasets. The results demonstrate that InfoFlowNet can extract time-varying\ncausal relationships among processes, reflected in the fluctuation of dIF\nvalues. Compared with the Granger causality model and temporal causal discovery\nframework, InfoFlowNet can identify more significant causal edges underlying\nEEG processes while maintaining an acceptable computation time. Our work\ndemonstrates the potential of InfoFlowNet for analyzing effective connectivity\nin EEG data. The findings highlight the importance of effective connectivity in\nunderstanding the complex dynamics of the brain network.",
            "author": [
                "Chun-Hsiang Chuang",
                "Shao-Xun Fang",
                "Chih-Sheng Huang",
                "Weiping Ding"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18527v1",
                "http://arxiv.org/pdf/2311.18527v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18526v1",
            "title": "HOT: Higher-Order Dynamic Graph Representation Learning with Efficient\n  Transformers",
            "updated": "2023-11-30T13:05:39Z",
            "published": "2023-11-30T13:05:39Z",
            "summary": "Many graph representation learning (GRL) problems are dynamic, with millions\nof edges added or removed per second. A fundamental workload in this setting is\ndynamic link prediction: using a history of graph updates to predict whether a\ngiven pair of vertices will become connected. Recent schemes for link\nprediction in such dynamic settings employ Transformers, modeling individual\ngraph updates as single tokens. In this work, we propose HOT: a model that\nenhances this line of works by harnessing higher-order (HO) graph structures;\nspecifically, k-hop neighbors and more general subgraphs containing a given\npair of vertices. Harnessing such HO structures by encoding them into the\nattention matrix of the underlying Transformer results in higher accuracy of\nlink prediction outcomes, but at the expense of increased memory pressure. To\nalleviate this, we resort to a recent class of schemes that impose hierarchy on\nthe attention matrix, significantly reducing memory footprint. The final design\noffers a sweetspot between high accuracy and low memory utilization. HOT\noutperforms other dynamic GRL schemes, for example achieving 9%, 7%, and 15%\nhigher accuracy than - respectively - DyGFormer, TGN, and GraphMixer, for the\nMOOC dataset. Our design can be seamlessly extended towards other dynamic GRL\nworkloads.",
            "author": [
                "Maciej Besta",
                "Afonso Claudino Catarino",
                "Lukas Gianinazzi",
                "Nils Blach",
                "Piotr Nyczyk",
                "Hubert Niewiadomski",
                "Torsten Hoefler"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18526v1",
                "http://arxiv.org/pdf/2311.18526v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18525v1",
            "title": "Detecting Anomalous Network Communication Patterns Using Graph\n  Convolutional Networks",
            "updated": "2023-11-30T13:03:49Z",
            "published": "2023-11-30T13:03:49Z",
            "summary": "To protect an organizations' endpoints from sophisticated cyberattacks,\nadvanced detection methods are required. In this research, we present\nGCNetOmaly: a graph convolutional network (GCN)-based variational autoencoder\n(VAE) anomaly detector trained on data that include connection events among\ninternal and external machines. As input, the proposed GCN-based VAE model\nreceives two matrices: (i) the normalized adjacency matrix, which represents\nthe connections among the machines, and (ii) the feature matrix, which includes\nvarious features (demographic, statistical, process-related, and Node2vec\nstructural features) that are used to profile the individual nodes/machines.\nAfter training the model on data collected for a predefined time window, the\nmodel is applied on the same data; the reconstruction score obtained by the\nmodel for a given machine then serves as the machine's anomaly score.\nGCNetOmaly was evaluated on real, large-scale data logged by Carbon Black EDR\nfrom a large financial organization's automated teller machines (ATMs) as well\nas communication with Active Directory (AD) servers in two setups: unsupervised\nand supervised. The results of our evaluation demonstrate GCNetOmaly's\neffectiveness in detecting anomalous behavior of machines on unsupervised data.",
            "author": [
                "Yizhak Vaisman",
                "Gilad Katz",
                "Yuval Elovici",
                "Asaf Shabtai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18525v1",
                "http://arxiv.org/pdf/2311.18525v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18521v1",
            "title": "Combining deep generative models with extreme value theory for synthetic\n  hazard simulation: a multivariate and spatially coherent approach",
            "updated": "2023-11-30T12:55:51Z",
            "published": "2023-11-30T12:55:51Z",
            "summary": "Climate hazards can cause major disasters when they occur simultaneously as\ncompound hazards. To understand the distribution of climate risk and inform\nadaptation policies, scientists need to simulate a large number of physically\nrealistic and spatially coherent events. Current methods are limited by\ncomputational constraints and the probabilistic spatial distribution of\ncompound events is not given sufficient attention. The bottleneck in current\napproaches lies in modelling the dependence structure between variables, as\ninference on parametric models suffers from the curse of dimensionality.\nGenerative adversarial networks (GANs) are well-suited to such a problem due to\ntheir ability to implicitly learn the distribution of data in high-dimensional\nsettings. We employ a GAN to model the dependence structure for daily maximum\nwind speed, significant wave height, and total precipitation over the Bay of\nBengal, combining this with traditional extreme value theory for controlled\nextrapolation of the tails. Once trained, the model can be used to efficiently\ngenerate thousands of realistic compound hazard events, which can inform\nclimate risk assessments for climate adaptation and disaster preparedness. The\nmethod developed is flexible and transferable to other multivariate and spatial\nclimate datasets.",
            "author": [
                "Alison Peard",
                "Jim Hall"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18521v1",
                "http://arxiv.org/pdf/2311.18521v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18520v1",
            "title": "Calibration-free online test-time adaptation for electroencephalography\n  motor imagery decoding",
            "updated": "2023-11-30T12:53:43Z",
            "published": "2023-11-30T12:53:43Z",
            "summary": "Providing a promising pathway to link the human brain with external devices,\nBrain-Computer Interfaces (BCIs) have seen notable advancements in decoding\ncapabilities, primarily driven by increasingly sophisticated techniques,\nespecially deep learning. However, achieving high accuracy in real-world\nscenarios remains a challenge due to the distribution shift between sessions\nand subjects. In this paper we will explore the concept of online test-time\nadaptation (OTTA) to continuously adapt the model in an unsupervised fashion\nduring inference time. Our approach guarantees the preservation of privacy by\neliminating the requirement to access the source data during the adaptation\nprocess. Additionally, OTTA achieves calibration-free operation by not\nrequiring any session- or subject-specific data. We will investigate the task\nof electroencephalography (EEG) motor imagery decoding using a lightweight\narchitecture together with different OTTA techniques like alignment, adaptive\nbatch normalization, and entropy minimization. We examine two datasets and\nthree distinct data settings for a comprehensive analysis. Our adaptation\nmethods produce state-of-the-art results, potentially instigating a shift in\ntransfer learning for BCI decoding towards online adaptation.",
            "author": [
                "Martin Wimpff",
                "Mario D\u00f6bler",
                "Bin Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18520v1",
                "http://arxiv.org/pdf/2311.18520v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI",
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18512v1",
            "title": "Revisiting Proposal-based Object Detection",
            "updated": "2023-11-30T12:40:23Z",
            "published": "2023-11-30T12:40:23Z",
            "summary": "This paper revisits the pipeline for detecting objects in images with\nproposals. For any object detector, the obtained box proposals or queries need\nto be classified and regressed towards ground truth boxes. The common solution\nfor the final predictions is to directly maximize the overlap between each\nproposal and the ground truth box, followed by a winner-takes-all ranking or\nnon-maximum suppression. In this work, we propose a simple yet effective\nalternative. For proposal regression, we solve a simpler problem where we\nregress to the area of intersection between proposal and ground truth. In this\nway, each proposal only specifies which part contains the object, avoiding a\nblind inpainting problem where proposals need to be regressed beyond their\nvisual scope. In turn, we replace the winner-takes-all strategy and obtain the\nfinal prediction by taking the union over the regressed intersections of a\nproposal group surrounding an object. Our revisited approach comes with minimal\nchanges to the detection pipeline and can be plugged into any existing method.\nWe show that our approach directly improves canonical object detection and\ninstance segmentation architectures, highlighting the utility of\nintersection-based regression and grouping.",
            "author": [
                "Aritra Bhowmik",
                "Martin R. Oswald",
                "Pascal Mettes",
                "Cees G. M. Snoek"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18512v1",
                "http://arxiv.org/pdf/2311.18512v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18508v1",
            "title": "DifAugGAN: A Practical Diffusion-style Data Augmentation for GAN-based\n  Single Image Super-resolution",
            "updated": "2023-11-30T12:37:53Z",
            "published": "2023-11-30T12:37:53Z",
            "summary": "It is well known the adversarial optimization of GAN-based image\nsuper-resolution (SR) methods makes the preceding SR model generate unpleasant\nand undesirable artifacts, leading to large distortion. We attribute the cause\nof such distortions to the poor calibration of the discriminator, which hampers\nits ability to provide meaningful feedback to the generator for learning\nhigh-quality images. To address this problem, we propose a simple but\nnon-travel diffusion-style data augmentation scheme for current GAN-based SR\nmethods, known as DifAugGAN. It involves adapting the diffusion process in\ngenerative diffusion models for improving the calibration of the discriminator\nduring training motivated by the successes of data augmentation schemes in the\nfield to achieve good calibration. Our DifAugGAN can be a Plug-and-Play\nstrategy for current GAN-based SISR methods to improve the calibration of the\ndiscriminator and thus improve SR performance. Extensive experimental\nevaluations demonstrate the superiority of DifAugGAN over state-of-the-art\nGAN-based SISR methods across both synthetic and real-world datasets,\nshowcasing notable advancements in both qualitative and quantitative results.",
            "author": [
                "Axi Niu",
                "Kang Zhang",
                "Joshua Tian Jin Tee",
                "Trung X. Pham",
                "Jinqiu Sun",
                "Chang D. Yoo",
                "In So Kweon",
                "Yanning Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18508v1",
                "http://arxiv.org/pdf/2311.18508v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18506v1",
            "title": "Global Convergence of Online Identification for Mixed Linear Regression",
            "updated": "2023-11-30T12:30:42Z",
            "published": "2023-11-30T12:30:42Z",
            "summary": "Mixed linear regression (MLR) is a powerful model for characterizing\nnonlinear relationships by utilizing a mixture of linear regression sub-models.\nThe identification of MLR is a fundamental problem, where most of the existing\nresults focus on offline algorithms, rely on independent and identically\ndistributed (i.i.d) data assumptions, and provide local convergence results\nonly. This paper investigates the online identification and data clustering\nproblems for two basic classes of MLRs, by introducing two corresponding new\nonline identification algorithms based on the expectation-maximization (EM)\nprinciple. It is shown that both algorithms will converge globally without\nresorting to the traditional i.i.d data assumptions. The main challenge in our\ninvestigation lies in the fact that the gradient of the maximum likelihood\nfunction does not have a unique zero, and a key step in our analysis is to\nestablish the stability of the corresponding differential equation in order to\napply the celebrated Ljung's ODE method. It is also shown that the\nwithin-cluster error and the probability that the new data is categorized into\nthe correct cluster are asymptotically the same as those in the case of known\nparameters. Finally, numerical simulations are provided to verify the\neffectiveness of our online algorithms.",
            "author": [
                "Yujing Liu",
                "Zhixin Liu",
                "Lei Guo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18506v1",
                "http://arxiv.org/pdf/2311.18506v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "cs.SY",
                "eess.SY",
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18503v1",
            "title": "End-to-End Retrieval with Learned Dense and Sparse Representations Using\n  Lucene",
            "updated": "2023-11-30T12:28:43Z",
            "published": "2023-11-30T12:28:43Z",
            "summary": "The bi-encoder architecture provides a framework for understanding\nmachine-learned retrieval models based on dense and sparse vector\nrepresentations. Although these representations capture parametric realizations\nof the same underlying conceptual framework, their respective implementations\nof top-$k$ similarity search require the coordination of different software\ncomponents (e.g., inverted indexes, HNSW indexes, and toolkits for neural\ninference), often knitted together in complex architectures. In this work, we\nask the following question: What's the simplest design, in terms of requiring\nthe fewest changes to existing infrastructure, that can support end-to-end\nretrieval with modern dense and sparse representations? The answer appears to\nbe that Lucene is sufficient, as we demonstrate in Anserini, a toolkit for\nreproducible information retrieval research. That is, effective retrieval with\nmodern single-vector neural models can be efficiently performed directly in\nJava on the CPU. We examine the implications of this design for information\nretrieval researchers pushing the state of the art as well as for software\nengineers building production search systems.",
            "author": [
                "Haonan Chen",
                "Carlos Lassance",
                "Jimmy Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18503v1",
                "http://arxiv.org/pdf/2311.18503v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18501v1",
            "title": "Perturbation-based Analysis of Compositional Data",
            "updated": "2023-11-30T12:27:15Z",
            "published": "2023-11-30T12:27:15Z",
            "summary": "Existing statistical methods for compositional data analysis are inadequate\nfor many modern applications for two reasons. First, modern compositional\ndatasets, for example in microbiome research, display traits such as\nhigh-dimensionality and sparsity that are poorly modelled with traditional\napproaches. Second, assessing -- in an unbiased way -- how summary statistics\nof a composition (e.g., racial diversity) affect a response variable is not\nstraightforward. In this work, we propose a framework based on hypothetical\ndata perturbations that addresses both issues. Unlike existing methods for\ncompositional data, we do not transform the data and instead use perturbations\nto define interpretable statistical functionals on the compositions themselves,\nwhich we call average perturbation effects. These average perturbation effects,\nwhich can be employed in many applications, naturally account for confounding\nthat biases frequently used marginal dependence analyses. We show how average\nperturbation effects can be estimated efficiently by deriving a\nperturbation-dependent reparametrization and applying semiparametric estimation\ntechniques. We analyze the proposed estimators empirically on simulated data\nand demonstrate advantages over existing techniques on US census and microbiome\ndata. For all proposed estimators, we provide confidence intervals with uniform\nasymptotic coverage guarantees.",
            "author": [
                "Anton Rask Lundborg",
                "Niklas Pfister"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18501v1",
                "http://arxiv.org/pdf/2311.18501v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "math.ST",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18498v1",
            "title": "Data-Agnostic Model Poisoning against Federated Learning: A Graph\n  Autoencoder Approach",
            "updated": "2023-11-30T12:19:10Z",
            "published": "2023-11-30T12:19:10Z",
            "summary": "This paper proposes a novel, data-agnostic, model poisoning attack on\nFederated Learning (FL), by designing a new adversarial graph autoencoder\n(GAE)-based framework. The attack requires no knowledge of FL training data and\nachieves both effectiveness and undetectability. By listening to the benign\nlocal models and the global model, the attacker extracts the graph structural\ncorrelations among the benign local models and the training data features\nsubstantiating the models. The attacker then adversarially regenerates the\ngraph structural correlations while maximizing the FL training loss, and\nsubsequently generates malicious local models using the adversarial graph\nstructure and the training data features of the benign ones. A new algorithm is\ndesigned to iteratively train the malicious local models using GAE and\nsub-gradient descent. The convergence of FL under attack is rigorously proved,\nwith a considerably large optimality gap. Experiments show that the FL accuracy\ndrops gradually under the proposed attack and existing defense mechanisms fail\nto detect it. The attack can give rise to an infection across all benign\ndevices, making it a serious threat to FL.",
            "author": [
                "Kai Li",
                "Jingjing Zheng",
                "Xin Yuan",
                "Wei Ni",
                "Ozgur B. Akan",
                "H. Vincent Poor"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18498v1",
                "http://arxiv.org/pdf/2311.18498v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18496v1",
            "title": "Accurate Segmentation of Optic Disc And Cup from Multiple Pseudo-labels\n  by Noise-Aware Learning",
            "updated": "2023-11-30T12:17:16Z",
            "published": "2023-11-30T12:17:16Z",
            "summary": "Optic disc and cup segmentation play a crucial role in automating the\nscreening and diagnosis of optic glaucoma. While data-driven convolutional\nneural networks (CNNs) show promise in this area, the inherent ambiguity of\nsegmenting object and background boundaries in the task of optic disc and cup\nsegmentation leads to noisy annotations that impact model performance. To\naddress this, we propose an innovative label-denoising method of Multiple\nPseudo-labels Noise-aware Network (MPNN) for accurate optic disc and cup\nsegmentation. Specifically, the Multiple Pseudo-labels Generation and Guided\nDenoising (MPGGD) module generates pseudo-labels by multiple different\ninitialization networks trained on true labels, and the pixel-level consensus\ninformation extracted from these pseudo-labels guides to differentiate clean\npixels from noisy pixels. The training framework of the MPNN is constructed by\na teacher-student architecture to learn segmentation from clean pixels and\nnoisy pixels. Particularly, such a framework adeptly leverages (i) reliable and\nfundamental insights from clean pixels and (ii) the supplementary knowledge\nwithin noisy pixels via multiple perturbation-based unsupervised consistency.\nCompared to other label-denoising methods, comprehensive experimental results\non the RIGA dataset demonstrate our method's excellent performance and\nsignificant denoising ability.",
            "author": [
                "Tengjin Weng",
                "Yang Shen",
                "Zhidong Zhao",
                "Zhiming Cheng",
                "Shuai Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18496v1",
                "http://arxiv.org/pdf/2311.18496v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18495v1",
            "title": "Improving Adversarial Transferability via Model Alignment",
            "updated": "2023-11-30T12:15:49Z",
            "published": "2023-11-30T12:15:49Z",
            "summary": "Neural networks are susceptible to adversarial perturbations that are\ntransferable across different models. In this paper, we introduce a novel model\nalignment technique aimed at improving a given source model's ability in\ngenerating transferable adversarial perturbations. During the alignment\nprocess, the parameters of the source model are fine-tuned to minimize an\nalignment loss. This loss measures the divergence in the predictions between\nthe source model and another, independently trained model, referred to as the\nwitness model. To understand the effect of model alignment, we conduct a\ngeometric anlaysis of the resulting changes in the loss landscape. Extensive\nexperiments on the ImageNet dataset, using a variety of model architectures,\ndemonstrate that perturbations generated from aligned source models exhibit\nsignificantly higher transferability than those from the original source model.",
            "author": [
                "Avery Ma",
                "Amir-massoud Farahmand",
                "Yangchen Pan",
                "Philip Torr",
                "Jindong Gu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18495v1",
                "http://arxiv.org/pdf/2311.18495v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18494v1",
            "title": "PRS: Sharp Feature Priors for Resolution-Free Surface Remeshing",
            "updated": "2023-11-30T12:15:45Z",
            "published": "2023-11-30T12:15:45Z",
            "summary": "Surface reconstruction with preservation of geometric features is a\nchallenging computer vision task. Despite significant progress in implicit\nshape reconstruction, state-of-the-art mesh extraction methods often produce\naliased, perceptually distorted surfaces and lack scalability to\nhigh-resolution 3D shapes. We present a data-driven approach for automatic\nfeature detection and remeshing that requires only a coarse, aliased mesh as\ninput and scales to arbitrary resolution reconstructions. We define and learn a\ncollection of surface-based fields to (1) capture sharp geometric features in\nthe shape with an implicit vertexwise model and (2) approximate improvements in\nnormals alignment obtained by applying edge-flips with an edgewise model. To\nsupport scaling to arbitrary complexity shapes, we learn our fields using local\ntriangulated patches, fusing estimates on complete surface meshes. Our feature\nremeshing algorithm integrates the learned fields as sharp feature priors and\noptimizes vertex placement and mesh connectivity for maximum expected surface\nimprovement. On a challenging collection of high-resolution shape\nreconstructions in the ABC dataset, our algorithm improves over\nstate-of-the-art by 26% normals F-score and 42% perceptual\n$\\text{RMSE}_{\\text{v}}$.",
            "author": [
                "Natalia Soboleva",
                "Olga Gorbunova",
                "Maria Ivanova",
                "Evgeny Burnaev",
                "Matthias Nie\u00dfner",
                "Denis Zorin",
                "Alexey Artemov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18494v1",
                "http://arxiv.org/pdf/2311.18494v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00823v1",
            "title": "Adaptive Multi-Modality Prompt Learning",
            "updated": "2023-11-30T12:10:22Z",
            "published": "2023-11-30T12:10:22Z",
            "summary": "Although current prompt learning methods have successfully been designed to\neffectively reuse the large pre-trained models without fine-tuning their large\nnumber of parameters, they still have limitations to be addressed, i.e.,\nwithout considering the adverse impact of meaningless patches in every image\nand without simultaneously considering in-sample generalization and\nout-of-sample generalization. In this paper, we propose an adaptive\nmulti-modality prompt learning to address the above issues. To do this, we\nemploy previous text prompt learning and propose a new image prompt learning.\nThe image prompt learning achieves in-sample and out-of-sample generalization,\nby first masking meaningless patches and then padding them with the learnable\nparameters and the information from texts. Moreover, each of the prompts\nprovides auxiliary information to each other, further strengthening these two\nkinds of generalization. Experimental results on real datasets demonstrate that\nour method outperforms SOTA methods, in terms of different downstream tasks.",
            "author": [
                "Zongqian Wu",
                "Yujing Liu",
                "Mengmeng Zhan",
                "Jialie Shen",
                "Ping Hu",
                "Xiaofeng Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00823v1",
                "http://arxiv.org/pdf/2312.00823v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18491v1",
            "title": "ZeST-NeRF: Using temporal aggregation for Zero-Shot Temporal NeRFs",
            "updated": "2023-11-30T12:06:15Z",
            "published": "2023-11-30T12:06:15Z",
            "summary": "In the field of media production, video editing techniques play a pivotal\nrole. Recent approaches have had great success at performing novel view image\nsynthesis of static scenes. But adding temporal information adds an extra layer\nof complexity. Previous models have focused on implicitly representing static\nand dynamic scenes using NeRF. These models achieve impressive results but are\ncostly at training and inference time. They overfit an MLP to describe the\nscene implicitly as a function of position. This paper proposes ZeST-NeRF, a\nnew approach that can produce temporal NeRFs for new scenes without retraining.\nWe can accurately reconstruct novel views using multi-view synthesis techniques\nand scene flow-field estimation, trained only with unrelated scenes. We\ndemonstrate how existing state-of-the-art approaches from a range of fields\ncannot adequately solve this new task and demonstrate the efficacy of our\nsolution. The resulting network improves quantitatively by 15% and produces\nsignificantly better visual results.",
            "author": [
                "Violeta Men\u00e9ndez Gonz\u00e1lez",
                "Andrew Gilbert",
                "Graeme Phillipson",
                "Stephen Jolly",
                "Simon Hadfield"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18491v1",
                "http://arxiv.org/pdf/2311.18491v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.GR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18481v1",
            "title": "ESG Accountability Made Easy: DocQA at Your Service",
            "updated": "2023-11-30T11:47:50Z",
            "published": "2023-11-30T11:47:50Z",
            "summary": "We present Deep Search DocQA. This application enables information extraction\nfrom documents via a question-answering conversational assistant. The system\nintegrates several technologies from different AI disciplines consisting of\ndocument conversion to machine-readable format (via computer vision), finding\nrelevant data (via natural language processing), and formulating an eloquent\nresponse (via large language models). Users can explore over 10,000\nEnvironmental, Social, and Governance (ESG) disclosure reports from over 2000\ncorporations. The Deep Search platform can be accessed at:\nhttps://ds4sd.github.io.",
            "author": [
                "Lokesh Mishra",
                "Cesar Berrospi",
                "Kasper Dinkla",
                "Diego Antognini",
                "Francesco Fusco",
                "Benedikt Bothur",
                "Maksym Lysak",
                "Nikolaos Livathinos",
                "Ahmed Nassar",
                "Panagiotis Vagenas",
                "Lucas Morin",
                "Christoph Auer",
                "Michele Dolfi",
                "Peter Staar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18481v1",
                "http://arxiv.org/pdf/2311.18481v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18473v1",
            "title": "DGMem: Learning Visual Navigation Policy without Any Labels by Dynamic\n  Graph Memory",
            "updated": "2023-11-30T11:29:58Z",
            "published": "2023-11-30T11:29:58Z",
            "summary": "In recent years, learning-based approaches have demonstrated significant\npromise in addressing intricate navigation tasks. Traditional methods for\ntraining deep neural network navigation policies rely on meticulously designed\nreward functions or extensive teleoperation datasets as navigation\ndemonstrations. However, the former is often confined to simulated\nenvironments, and the latter demands substantial human labor, making it a\ntime-consuming process. Our vision is for robots to autonomously learn\nnavigation skills and adapt their behaviors to environmental changes without\nany human intervention. In this work, we discuss the self-supervised navigation\nproblem and present Dynamic Graph Memory (DGMem), which facilitates training\nonly with on-board observations. With the help of DGMem, agents can actively\nexplore their surroundings, autonomously acquiring a comprehensive navigation\npolicy in a data-efficient manner without external feedback. Our method is\nevaluated in photorealistic 3D indoor scenes, and empirical studies demonstrate\nthe effectiveness of DGMem.",
            "author": [
                "Wenzhe Cai",
                "Teng Wang",
                "Guangran Cheng",
                "Lele Xu",
                "Changyin Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18473v1",
                "http://arxiv.org/pdf/2311.18473v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18460v1",
            "title": "Causal Fairness under Unobserved Confounding: A Neural Sensitivity\n  Framework",
            "updated": "2023-11-30T11:11:26Z",
            "published": "2023-11-30T11:11:26Z",
            "summary": "Fairness for machine learning predictions is widely required in practice for\nlegal, ethical, and societal reasons. Existing work typically focuses on\nsettings without unobserved confounding, even though unobserved confounding can\nlead to severe violations of causal fairness and, thus, unfair predictions. In\nthis work, we analyze the sensitivity of causal fairness to unobserved\nconfounding. Our contributions are three-fold. First, we derive bounds for\ncausal fairness metrics under different sources of unobserved confounding. This\nenables practitioners to examine the sensitivity of their machine learning\nmodels to unobserved confounding in fairness-critical applications. Second, we\npropose a novel neural framework for learning fair predictions, which allows us\nto offer worst-case guarantees of the extent to which causal fairness can be\nviolated due to unobserved confounding. Third, we demonstrate the effectiveness\nof our framework in a series of experiments, including a real-world case study\nabout predicting prison sentences. To the best of our knowledge, ours is the\nfirst work to study causal fairness under unobserved confounding. To this end,\nour work is of direct practical value as a refutation strategy to ensure the\nfairness of predictions in high-stakes applications.",
            "author": [
                "Maresa Schr\u00f6der",
                "Dennis Frauen",
                "Stefan Feuerriegel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18460v1",
                "http://arxiv.org/pdf/2311.18460v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CY",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00092v1",
            "title": "Mixture of Gaussian-distributed Prototypes with Generative Modelling for\n  Interpretable Image Classification",
            "updated": "2023-11-30T11:01:37Z",
            "published": "2023-11-30T11:01:37Z",
            "summary": "Prototypical-part interpretable methods, e.g., ProtoPNet, enhance\ninterpretability by connecting classification predictions to class-specific\ntraining prototypes, thereby offering an intuitive insight into their\ndecision-making. Current methods rely on a discriminative classifier trained\nwith point-based learning techniques that provide specific values for\nprototypes. Such prototypes have relatively low representation power due to\ntheir sparsity and potential redundancy, with each prototype containing no\nvariability measure. In this paper, we present a new generative learning of\nprototype distributions, named Mixture of Gaussian-distributed Prototypes\n(MGProto), which are represented by Gaussian mixture models (GMM). Such an\napproach enables the learning of more powerful prototype representations since\neach learned prototype will own a measure of variability, which naturally\nreduces the sparsity given the spread of the distribution around each\nprototype, and we also integrate a prototype diversity objective function into\nthe GMM optimisation to reduce redundancy. Incidentally, the generative nature\nof MGProto offers a new and effective way for detecting out-of-distribution\nsamples. To improve the compactness of MGProto, we further propose to prune\nGaussian-distributed prototypes with a low prior. Experiments on CUB-200-2011,\nStanford Cars, Stanford Dogs, and Oxford-IIIT Pets datasets show that MGProto\nachieves state-of-the-art classification and OoD detection performances with\nencouraging interpretability results.",
            "author": [
                "Chong Wang",
                "Yuanhong Chen",
                "Fengbei Liu",
                "Davis James McCarthy",
                "Helen Frazer",
                "Gustavo Carneiro"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00092v1",
                "http://arxiv.org/pdf/2312.00092v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18451v1",
            "title": "How Much Is Hidden in the NAS Benchmarks? Few-Shot Adaptation of a NAS\n  Predictor",
            "updated": "2023-11-30T10:51:46Z",
            "published": "2023-11-30T10:51:46Z",
            "summary": "Neural architecture search has proven to be a powerful approach to designing\nand refining neural networks, often boosting their performance and efficiency\nover manually-designed variations, but comes with computational overhead. While\nthere has been a considerable amount of research focused on lowering the cost\nof NAS for mainstream tasks, such as image classification, a lot of those\nimprovements stem from the fact that those tasks are well-studied in the\nbroader context. Consequently, applicability of NAS to emerging and\nunder-represented domains is still associated with a relatively high cost\nand/or uncertainty about the achievable gains. To address this issue, we turn\nour focus towards the recent growth of publicly available NAS benchmarks in an\nattempt to extract general NAS knowledge, transferable across different tasks\nand search spaces. We borrow from the rich field of meta-learning for few-shot\nadaptation and carefully study applicability of those methods to NAS, with a\nspecial focus on the relationship between task-level correlation (domain shift)\nand predictor transferability; which we deem critical for improving NAS on\ndiverse tasks. In our experiments, we use 6 NAS benchmarks in conjunction,\nspanning in total 16 NAS settings -- our meta-learning approach not only shows\nsuperior (or matching) performance in the cross-validation experiments but also\nsuccessful extrapolation to a new search space and tasks.",
            "author": [
                "Hrushikesh Loya",
                "\u0141ukasz Dudziak",
                "Abhinav Mehrotra",
                "Royson Lee",
                "Javier Fernandez-Marques",
                "Nicholas D. Lane",
                "Hongkai Wen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18451v1",
                "http://arxiv.org/pdf/2311.18451v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18450v1",
            "title": "Lessons from Building CodeBuddy: A Contextualized AI Coding Assistant",
            "updated": "2023-11-30T10:51:26Z",
            "published": "2023-11-30T10:51:26Z",
            "summary": "With their exceptional natural language processing capabilities, tools based\non Large Language Models (LLMs) like ChatGPT and Co-Pilot have swiftly become\nindispensable resources in the software developer's toolkit. While recent\nstudies suggest the potential productivity gains these tools can unlock, users\nstill encounter drawbacks, such as generic or incorrect answers. Additionally,\nthe pursuit of improved responses often leads to extensive prompt engineering\nefforts, diverting valuable time from writing code that delivers actual value.\nTo address these challenges, a new breed of tools, built atop LLMs, is\nemerging. These tools aim to mitigate drawbacks by employing techniques like\nfine-tuning or enriching user prompts with contextualized information.\n  In this paper, we delve into the lessons learned by a software development\nteam venturing into the creation of such a contextualized LLM-based\napplication, using retrieval-based techniques, called CodeBuddy. Over a\nfour-month period, the team, despite lacking prior professional experience in\nLLM-based applications, built the product from scratch. Following the initial\nproduct release, we engaged with the development team responsible for the code\ngenerative components. Through interviews and analysis of the application's\nissue tracker, we uncover various intriguing challenges that teams working on\nLLM-based applications might encounter. For instance, we found three main group\nof lessons: LLM-based lessons, User-based lessons, and Technical lessons. By\nunderstanding these lessons, software development teams could become better\nprepared to build LLM-based applications.",
            "author": [
                "gustavo Pinto",
                "Cleidson de Souza",
                "Jo\u00e3o Batista Neto",
                "Alberto de Souza",
                "Tarc\u00edsio Gotto",
                "Edward Monteiro"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18450v1",
                "http://arxiv.org/pdf/2311.18450v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18437v1",
            "title": "The Sliding Regret in Stochastic Bandits: Discriminating Index and\n  Randomized Policies",
            "updated": "2023-11-30T10:37:03Z",
            "published": "2023-11-30T10:37:03Z",
            "summary": "This paper studies the one-shot behavior of no-regret algorithms for\nstochastic bandits. Although many algorithms are known to be asymptotically\noptimal with respect to the expected regret, over a single run, their\npseudo-regret seems to follow one of two tendencies: it is either smooth or\nbumpy. To measure this tendency, we introduce a new notion: the sliding regret,\nthat measures the worst pseudo-regret over a time-window of fixed length\nsliding to infinity. We show that randomized methods (e.g. Thompson Sampling\nand MED) have optimal sliding regret, while index policies, although possibly\nasymptotically optimal for the expected regret, have the worst possible sliding\nregret under regularity conditions on their index (e.g. UCB, UCB-V, KL-UCB,\nMOSS, IMED etc.). We further analyze the average bumpiness of the pseudo-regret\nof index policies via the regret of exploration, that we show to be suboptimal\nas well.",
            "author": [
                "Victor Boone"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18437v1",
                "http://arxiv.org/pdf/2311.18437v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SY",
                "eess.SY",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18434v1",
            "title": "Exploring the Temperature-Dependent Phase Transition in Modern Hopfield\n  Networks",
            "updated": "2023-11-30T10:34:29Z",
            "published": "2023-11-30T10:34:29Z",
            "summary": "The recent discovery of a connection between Transformers and Modern Hopfield\nNetworks (MHNs) has reignited the study of neural networks from a physical\nenergy-based perspective. This paper focuses on the pivotal effect of the\ninverse temperature hyperparameter $\\beta$ on the distribution of energy minima\nof the MHN. To achieve this, the distribution of energy minima is tracked in a\nsimplified MHN in which equidistant normalised patterns are stored. This\nnetwork demonstrates a phase transition at a critical temperature\n$\\beta_{\\text{c}}$, from a single global attractor towards highly pattern\nspecific minima as $\\beta$ is increased. Importantly, the dynamics are not\nsolely governed by the hyperparameter $\\beta$ but are instead determined by an\neffective inverse temperature $\\beta_{\\text{eff}}$ which also depends on the\ndistribution and size of the stored patterns. Recognizing the role of\nhyperparameters in the MHN could, in the future, aid researchers in the domain\nof Transformers to optimise their initial choices, potentially reducing the\nnecessity for time and energy expensive hyperparameter fine-tuning.",
            "author": [
                "Felix Koulischer",
                "C\u00e9dric Goemaere",
                "Tom van der Meersch",
                "Johannes Deleu",
                "Thomas Demeester"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18434v1",
                "http://arxiv.org/pdf/2311.18434v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cond-mat.dis-nn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18433v1",
            "title": "E2PNet: Event to Point Cloud Registration with Spatio-Temporal\n  Representation Learning",
            "updated": "2023-11-30T10:33:49Z",
            "published": "2023-11-30T10:33:49Z",
            "summary": "Event cameras have emerged as a promising vision sensor in recent years due\nto their unparalleled temporal resolution and dynamic range. While registration\nof 2D RGB images to 3D point clouds is a long-standing problem in computer\nvision, no prior work studies 2D-3D registration for event cameras. To this\nend, we propose E2PNet, the first learning-based method for event-to-point\ncloud registration. The core of E2PNet is a novel feature representation\nnetwork called Event-Points-to-Tensor (EP2T), which encodes event data into a\n2D grid-shaped feature tensor. This grid-shaped feature enables matured\nRGB-based frameworks to be easily used for event-to-point cloud registration,\nwithout changing hyper-parameters and the training procedure. EP2T treats the\nevent input as spatio-temporal point clouds. Unlike standard 3D learning\narchitectures that treat all dimensions of point clouds equally, the novel\nsampling and information aggregation modules in EP2T are designed to handle the\ninhomogeneity of the spatial and temporal dimensions. Experiments on the MVSEC\nand VECtor datasets demonstrate the superiority of E2PNet over hand-crafted and\nother learning-based methods. Compared to RGB-based registration, E2PNet is\nmore robust to extreme illumination or fast motion due to the use of event\ndata. Beyond 2D-3D registration, we also show the potential of EP2T for other\nvision tasks such as flow estimation, event-to-image reconstruction and object\nrecognition. The source code can be found at:\nhttps://github.com/Xmu-qcj/E2PNet.",
            "author": [
                "Xiuhong Lin",
                "Changjie Qiu",
                "Zhipeng Cai",
                "Siqi Shen",
                "Yu Zang",
                "Weiquan Liu",
                "Xuesheng Bian",
                "Matthias M\u00fcller",
                "Cheng Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18433v1",
                "http://arxiv.org/pdf/2311.18433v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18431v1",
            "title": "On the convergence of adaptive first order methods: proximal gradient\n  and alternating minimization algorithms",
            "updated": "2023-11-30T10:29:43Z",
            "published": "2023-11-30T10:29:43Z",
            "summary": "Building upon recent works on linesearch-free adaptive proximal gradient\nmethods, this paper proposes AdaPG$^{\\pi,r}$, a framework that unifies and\nextends existing results by providing larger stepsize policies and improved\nlower bounds. Different choices of the parameters $\\pi$ and $r$ are discussed\nand the efficacy of the resulting methods is demonstrated through numerical\nsimulations. In an attempt to better understand the underlying theory, its\nconvergence is established in a more general setting that allows for\ntime-varying parameters. Finally, an adaptive alternating minimization\nalgorithm is presented by exploring the dual setting. This algorithm not only\nincorporates additional adaptivity, but also expands its applicability beyond\nstandard strongly convex settings.",
            "author": [
                "Puya Latafat",
                "Andreas Themelis",
                "Panagiotis Patrinos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18431v1",
                "http://arxiv.org/pdf/2311.18431v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG",
                "65K05, 90C06, 90C25, 90C30, 90C47"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18430v1",
            "title": "Vehicular Cooperative Maneuvers -- Quo Vaditis?",
            "updated": "2023-11-30T10:27:29Z",
            "published": "2023-11-30T10:27:29Z",
            "summary": "Vehicles will not only get more and more automated, but they will also\ncooperate in new ways. Currently, human-driven vehicles begin to communicate\nwith each other using vehicle-to-everything technology. Future vehicles will\nuse communication to share sensor data and even negotiate cooperative\nmaneuvers. This lets them learn more about the environment and improves traffic\nflow and passenger comfort as more predictable maneuvers are likely to lead to\na smoother ride. This paper introduces the most important concepts around\ncooperative vehicular maneuvers. We also summarize currently open challenges\nand questions to answer before a deployment can begin. Afterward, we give some\nperspectives on the further evolution of cooperative maneuvers and beyond.",
            "author": [
                "Bernhard H\u00e4fner",
                "J\u00f6rg Ott",
                "Georg Albrecht Schmitt"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18430v1",
                "http://arxiv.org/pdf/2311.18430v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18426v2",
            "title": "Convergence Analysis of Fractional Gradient Descent",
            "updated": "2023-12-04T06:27:04Z",
            "published": "2023-11-30T10:24:07Z",
            "summary": "Fractional derivatives are a well-studied generalization of integer order\nderivatives. Naturally, for optimization, it is of interest to understand the\nconvergence properties of gradient descent using fractional derivatives.\nConvergence analysis of fractional gradient descent is currently limited both\nin the methods analyzed and the settings analyzed. This paper aims to fill in\nthese gaps by analyzing variations of fractional gradient descent in smooth and\nconvex, smooth and strongly convex, and smooth and non-convex settings. First,\nnovel bounds will be established bridging fractional and integer derivatives.\nThen, these bounds will be applied to the aforementioned settings to prove\n$O(1/T)$ convergence for smooth and convex functions and linear convergence for\nsmooth and strongly convex functions. Additionally, we prove $O(1/T)$\nconvergence for smooth and non-convex functions using an extended notion of\nsmoothness that is more natural for fractional derivatives. Finally, empirical\nresults will be presented on the potential speed up of fractional gradient\ndescent over standard gradient descent as well as the challenges of predicting\nwhich will be faster in general.",
            "author": [
                "Ashwani Aggarwal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18426v2",
                "http://arxiv.org/pdf/2311.18426v2"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG",
                "cs.NA",
                "math.NA",
                "G.1.6"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18424v1",
            "title": "Multiple Disciplinary Data Work Practices in Artificial Intelligence\n  Research: a Healthcare Case Study in the UK",
            "updated": "2023-11-30T10:19:33Z",
            "published": "2023-11-30T10:19:33Z",
            "summary": "Developing artificial intelligence (AI) tools for healthcare is a multiple\ndisciplinary effort, bringing data scientists, clinicians, patients and other\ndisciplines together. In this paper, we explore the AI development workflow and\nhow participants navigate the challenges and tensions of sharing and generating\nknowledge across disciplines. Through an inductive thematic analysis of 13\nsemi-structured interviews with participants in a large research consortia, our\nfindings suggest that multiple disciplinarity heavily impacts work practices.\nParticipants faced challenges to learn the languages of other disciplines and\nneeded to adapt the tools used for sharing and communicating with their\naudience, particularly those from a clinical or patient perspective. Large\nhealth datasets also posed certain restrictions on work practices. We\nidentified meetings as a key platform for facilitating exchanges between\ndisciplines and allowing for the blending and creation of knowledge. Finally,\nwe discuss design implications for data science and collaborative tools, and\nrecommendations for future research.",
            "author": [
                "Rafael Henkin",
                "Elizabeth Remfry",
                "Duncan J. Reynolds",
                "Megan Clinch",
                "Michael R. Barnes"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18424v1",
                "http://arxiv.org/pdf/2311.18424v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18398v1",
            "title": "RainAI -- Precipitation Nowcasting from Satellite Data",
            "updated": "2023-11-30T09:49:16Z",
            "published": "2023-11-30T09:49:16Z",
            "summary": "This paper presents a solution to the Weather4Cast 2023 competition, where\nthe goal is to forecast high-resolution precipitation with an 8-hour lead time\nusing lower-resolution satellite radiance images. We propose a simple, yet\neffective method for spatiotemporal feature learning using a 2D U-Net model,\nthat outperforms the official 3D U-Net baseline in both performance and\nefficiency. We place emphasis on refining the dataset, through importance\nsampling and dataset preparation, and show that such techniques have a\nsignificant impact on performance. We further study an alternative\ncross-entropy loss function that improves performance over the standard mean\nsquared error loss, while also enabling models to produce probabilistic\noutputs. Additional techniques are explored regarding the generation of\npredictions at different lead times, specifically through Conditioning Lead\nTime. Lastly, to generate high-resolution forecasts, we evaluate standard and\nlearned upsampling methods. The code and trained parameters are available at\nhttps://github.com/rafapablos/w4c23-rainai.",
            "author": [
                "Rafael Pablos Sarabia",
                "Joachim Nyborg",
                "Morten Birk",
                "Ira Assent"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18398v1",
                "http://arxiv.org/pdf/2311.18398v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "physics.ao-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18393v1",
            "title": "Data-efficient Deep Reinforcement Learning for Vehicle Trajectory\n  Control",
            "updated": "2023-11-30T09:38:59Z",
            "published": "2023-11-30T09:38:59Z",
            "summary": "Advanced vehicle control is a fundamental building block in the development\nof autonomous driving systems. Reinforcement learning (RL) promises to achieve\ncontrol performance superior to classical approaches while keeping\ncomputational demands low during deployment. However, standard RL approaches\nlike soft-actor critic (SAC) require extensive amounts of training data to be\ncollected and are thus impractical for real-world application. To address this\nissue, we apply recently developed data-efficient deep RL methods to vehicle\ntrajectory control. Our investigation focuses on three methods, so far\nunexplored for vehicle control: randomized ensemble double Q-learning (REDQ),\nprobabilistic ensembles with trajectory sampling and model predictive path\nintegral optimizer (PETS-MPPI), and model-based policy optimization (MBPO). We\nfind that in the case of trajectory control, the standard model-based RL\nformulation used in approaches like PETS-MPPI and MBPO is not suitable. We,\ntherefore, propose a new formulation that splits dynamics prediction and\nvehicle localization. Our benchmark study on the CARLA simulator reveals that\nthe three identified data-efficient deep RL approaches learn control strategies\non a par with or better than SAC, yet reduce the required number of environment\ninteractions by more than one order of magnitude.",
            "author": [
                "Bernd Frauenknecht",
                "Tobias Ehlgen",
                "Sebastian Trimpe"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18393v1",
                "http://arxiv.org/pdf/2311.18393v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18392v1",
            "title": "Augmented Reality Technology in Teaching about Physics: A systematic\n  review of opportunities and challenges",
            "updated": "2023-11-30T09:35:36Z",
            "published": "2023-11-30T09:35:36Z",
            "summary": "The use of augmented reality (AR) allows for the integration of digital\ninformation onto our perception of the physical world. In this article, we\npresent a comprehensive review of previously published literature on the\nimplementation of augmented reality in physics education, at the school and the\nuniversity level. Our review includes an analysis of 96 papers from the Scopus\nand Eric databases, all of which were published between January 1st, 2012 and\nJanuary 1st, 2023. We evaluated how AR has been used for facilitating learning\nabout physics. Potential AR-based learning activities for different physics\ntopics have been summarized and opportunities, as well as challenges associated\nwith AR-based learning of physics have been reported. It has been shown that AR\ntechnologies may facilitate physics learning by: providing complementary\nvisualizations, optimizing cognitive load, allowing for haptic learning,\nreducing task completion time and promoting collaborative inquiry. The\npotential disadvantages of using AR in physics teaching are mainly related to\nthe shortcomings of software and hardware technologies (e.g., camera freeze,\nvisualization delay) and extraneous cognitive load (e.g., paying more attention\nto secondary details than to constructing target knowledge).",
            "author": [
                "A. Vidak",
                "I. Movre \u0160api\u0107",
                "V. Me\u0161i\u0107",
                "V. Gomzi"
            ],
            "link": [
                "http://dx.doi.org/10.1088/1361-6404/ad0e84",
                "http://arxiv.org/abs/2311.18392v1",
                "http://arxiv.org/pdf/2311.18392v1"
            ],
            "primary_category": "physics.ed-ph",
            "category": [
                "physics.ed-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18387v1",
            "title": "On Exact Inversion of DPM-Solvers",
            "updated": "2023-11-30T09:30:15Z",
            "published": "2023-11-30T09:30:15Z",
            "summary": "Diffusion probabilistic models (DPMs) are a key component in modern\ngenerative models. DPM-solvers have achieved reduced latency and enhanced\nquality significantly, but have posed challenges to find the exact inverse\n(i.e., finding the initial noise from the given image). Here we investigate the\nexact inversions for DPM-solvers and propose algorithms to perform them when\nsamples are generated by the first-order as well as higher-order DPM-solvers.\nFor each explicit denoising step in DPM-solvers, we formulated the inversions\nusing implicit methods such as gradient descent or forward step method to\nensure the robustness to large classifier-free guidance unlike the prior\napproach using fixed-point iteration. Experimental results demonstrated that\nour proposed exact inversion methods significantly reduced the error of both\nimage and noise reconstructions, greatly enhanced the ability to distinguish\ninvisible watermarks and well prevented unintended background changes\nconsistently during image editing. Project page:\n\\url{https://smhongok.github.io/inv-dpm.html}.",
            "author": [
                "Seongmin Hong",
                "Kyeonghyun Lee",
                "Suh Yoon Jeon",
                "Hyewon Bae",
                "Se Young Chun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18387v1",
                "http://arxiv.org/pdf/2311.18387v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18377v1",
            "title": "Transfer Learning across Different Chemical Domains: Virtual Screening\n  of Organic Materials with Deep Learning Models Pretrained on Small Molecule\n  and Chemical Reaction Data",
            "updated": "2023-11-30T09:20:24Z",
            "published": "2023-11-30T09:20:24Z",
            "summary": "Machine learning prediction of organic materials properties is an efficient\nvirtual screening method ahead of more expensive screening methods. However,\nthis approach has suffered from insufficient labeled data on organic materials\nto train state-of-the-art machine learning models. In this study, we\ndemonstrate that drug-like small molecule and chemical reaction databases can\nbe used to pretrain the BERT model for the virtual screening of organic\nmaterials. Among the BERT models fine-tuned by five virtual screening tasks on\norganic materials, the USPTO-SMILES pretrained BERT model had R2 > 0.90 for two\ntasks and R2 > 0.82 for one, which was generally superior to the same models\npretrained by the small molecule or organic materials databases, as well as to\nthe other three traditional machine learning models trained directly on the\nvirtual screening task data. The superior performance of the USPTO-SMILES\npretrained BERT model is due to the greater variety of organic building blocks\nin the USPTO database and the broader coverage of the chemical space. The even\nbetter performance of the BERT model pretrained externally from a chemical\nreaction database with additional sources of chemical reactions strengthens our\nproof of concept that transfer learning across different chemical domains is\npractical for the virtual screening of organic materials.",
            "author": [
                "Chengwei Zhang",
                "Yushuang Zhai",
                "Ziyang Gong",
                "Yuan-Bin She",
                "Yun-Fang Yang",
                "An Su"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18377v1",
                "http://arxiv.org/pdf/2311.18377v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "cs.LG",
                "q-bio.BM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18376v1",
            "title": "Age Effects on Decision-Making, Drift Diffusion Model",
            "updated": "2023-11-30T09:19:12Z",
            "published": "2023-11-30T09:19:12Z",
            "summary": "Training can improve human decision-making performance. After several\ntraining sessions, a person can quickly and accurately complete a task.\nHowever, decision-making is always a trade-off between accuracy and response\ntime. Factors such as age and drug abuse can affect the decision-making\nprocess. This study examines how training can improve the performance of\ndifferent age groups in completing a random dot motion (RDM) task. The\nparticipants are divided into two groups: old and young. They undergo a\nthree-phase training and then repeat the same RDM task. The hierarchical\ndrift-diffusion model analyzes the subjects' responses and determines how the\nmodel's parameters change after training for both age groups. The results show\nthat after training, the participants were able to accumulate sensory\ninformation faster, and the model drift rate increased. However, their decision\nboundary decreased as they became more confident and had a lower\ndecision-making threshold. Additionally, the old group had a higher boundary\nand lower drift rate in both pre and post-training, and there was less\ndifference between the two group parameters after training.",
            "author": [
                "Zahra Kavian",
                "Kimia Hajisadeghi",
                "Yashar Rezazadeh",
                "Mehrbod Faraji",
                "Reza Ebrahimpour"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18376v1",
                "http://arxiv.org/pdf/2311.18376v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18373v1",
            "title": "A Survey on Deep Learning for Polyp Segmentation: Techniques, Challenges\n  and Future Trends",
            "updated": "2023-11-30T09:14:37Z",
            "published": "2023-11-30T09:14:37Z",
            "summary": "Early detection and assessment of polyps play a crucial role in the\nprevention and treatment of colorectal cancer (CRC). Polyp segmentation\nprovides an effective solution to assist clinicians in accurately locating and\nsegmenting polyp regions. In the past, people often relied on manually\nextracted lower-level features such as color, texture, and shape, which often\nhad issues capturing global context and lacked robustness to complex scenarios.\nWith the advent of deep learning, more and more outstanding medical image\nsegmentation algorithms based on deep learning networks have emerged, making\nsignificant progress in this field. This paper provides a comprehensive review\nof polyp segmentation algorithms. We first review some traditional algorithms\nbased on manually extracted features and deep segmentation algorithms, then\ndetail benchmark datasets related to the topic. Specifically, we carry out a\ncomprehensive evaluation of recent deep learning models and results based on\npolyp sizes, considering the pain points of research topics and differences in\nnetwork structures. Finally, we discuss the challenges of polyp segmentation\nand future trends in this field. The models, benchmark datasets, and source\ncode links we collected are all published at\nhttps://github.com/taozh2017/Awesome-Polyp-Segmentation.",
            "author": [
                "Jiaxin Mei",
                "Tao Zhou",
                "Kaiwen Huang",
                "Yizhe Zhang",
                "Yi Zhou",
                "Ye Wu",
                "Huazhu Fu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18373v1",
                "http://arxiv.org/pdf/2311.18373v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18364v1",
            "title": "Hubness Reduction Improves Sentence-BERT Semantic Spaces",
            "updated": "2023-11-30T09:03:49Z",
            "published": "2023-11-30T09:03:49Z",
            "summary": "Semantic representations of text, i.e. representations of natural language\nwhich capture meaning by geometry, are essential for areas such as information\nretrieval and document grouping. High-dimensional trained dense vectors have\nreceived much attention in recent years as such representations. We investigate\nthe structure of semantic spaces that arise from embeddings made with\nSentence-BERT and find that the representations suffer from a well-known\nproblem in high dimensions called hubness. Hubness results in asymmetric\nneighborhood relations, such that some texts (the hubs) are neighbours of many\nother texts while most texts (so-called anti-hubs), are neighbours of few or no\nother texts. We quantify the semantic quality of the embeddings using hubness\nscores and error rate of a neighbourhood based classifier. We find that when\nhubness is high, we can reduce error rate and hubness using hubness reduction\nmethods. We identify a combination of two methods as resulting in the best\nreduction. For example, on one of the tested pretrained models, this combined\nmethod can reduce hubness by about 75% and error rate by about 9%. Thus, we\nargue that mitigating hubness in the embedding space provides better semantic\nrepresentations of text.",
            "author": [
                "Beatrix M. G. Nielsen",
                "Lars Kai Hansen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18364v1",
                "http://arxiv.org/pdf/2311.18364v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18358v1",
            "title": "TIDE: Test Time Few Shot Object Detection",
            "updated": "2023-11-30T09:00:44Z",
            "published": "2023-11-30T09:00:44Z",
            "summary": "Few-shot object detection (FSOD) aims to extract semantic knowledge from\nlimited object instances of novel categories within a target domain. Recent\nadvances in FSOD focus on fine-tuning the base model based on a few objects via\nmeta-learning or data augmentation. Despite their success, the majority of them\nare grounded with parametric readjustment to generalize on novel objects, which\nface considerable challenges in Industry 5.0, such as (i) a certain amount of\nfine-tuning time is required, and (ii) the parameters of the constructed model\nbeing unavailable due to the privilege protection, making the fine-tuning fail.\nSuch constraints naturally limit its application in scenarios with real-time\nconfiguration requirements or within black-box settings. To tackle the\nchallenges mentioned above, we formalize a novel FSOD task, referred to as Test\nTIme Few Shot DEtection (TIDE), where the model is un-tuned in the\nconfiguration procedure. To that end, we introduce an asymmetric architecture\nfor learning a support-instance-guided dynamic category classifier. Further, a\ncross-attention module and a multi-scale resizer are provided to enhance the\nmodel performance. Experimental results on multiple few-shot object detection\nplatforms reveal that the proposed TIDE significantly outperforms existing\ncontemporary methods. The implementation codes are available at\nhttps://github.com/deku-0621/TIDE",
            "author": [
                "Weikai Li",
                "Hongfeng Wei",
                "Yanlai Wu",
                "Jie Yang",
                "Yudi Ruan",
                "Yuan Li",
                "Ying Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18358v1",
                "http://arxiv.org/pdf/2311.18358v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18356v1",
            "title": "Towards Comparable Active Learning",
            "updated": "2023-11-30T08:54:32Z",
            "published": "2023-11-30T08:54:32Z",
            "summary": "Active Learning has received significant attention in the field of machine\nlearning for its potential in selecting the most informative samples for\nlabeling, thereby reducing data annotation costs. However, we show that the\nreported lifts in recent literature generalize poorly to other domains leading\nto an inconclusive landscape in Active Learning research. Furthermore, we\nhighlight overlooked problems for reproducing AL experiments that can lead to\nunfair comparisons and increased variance in the results. This paper addresses\nthese issues by providing an Active Learning framework for a fair comparison of\nalgorithms across different tasks and domains, as well as a fast and performant\noracle algorithm for evaluation. To the best of our knowledge, we propose the\nfirst AL benchmark that tests algorithms in 3 major domains: Tabular, Image,\nand Text. We report empirical results for 6 widely used algorithms on 7\nreal-world and 2 synthetic datasets and aggregate them into a domain-specific\nranking of AL algorithms.",
            "author": [
                "Thorben Werner",
                "Johannes Burchert",
                "Lars Schmidt-Thieme"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18356v1",
                "http://arxiv.org/pdf/2311.18356v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00090v1",
            "title": "Tree-based Forecasting of Day-ahead Solar Power Generation from Granular\n  Meteorological Features",
            "updated": "2023-11-30T08:47:37Z",
            "published": "2023-11-30T08:47:37Z",
            "summary": "Accurate forecasts for day-ahead photovoltaic (PV) power generation are\ncrucial to support a high PV penetration rate in the local electricity grid and\nto assure stability in the grid. We use state-of-the-art tree-based machine\nlearning methods to produce such forecasts and, unlike previous studies, we\nhereby account for (i) the effects various meteorological as well as\nastronomical features have on PV power production, and this (ii) at coarse as\nwell as granular spatial locations. To this end, we use data from Belgium and\nforecast day-ahead PV power production at an hourly resolution. The insights\nfrom our study can assist utilities, decision-makers, and other stakeholders in\noptimizing grid operations, economic dispatch, and in facilitating the\nintegration of distributed PV power into the electricity grid.",
            "author": [
                "Nick Berlanger",
                "Noah van Ophoven",
                "Tim Verdonck",
                "Ines Wilms"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00090v1",
                "http://arxiv.org/pdf/2312.00090v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18355v1",
            "title": "Guided Demonstrations Using Automated Excuse Generation",
            "updated": "2023-11-30T08:45:19Z",
            "published": "2023-11-30T08:45:19Z",
            "summary": "Teaching task-level directives to robots via demonstration is a popular tool\nto expand the robot's capabilities to interact with its environment. While\ncurrent learning from demonstration systems primarily focuses on abstracting\nthe task-level knowledge to the robot, these systems lack the ability to\nunderstand which part of the task can be already solved given the robot's prior\nknowledge. Therefore, instead of only requiring demonstrations of the missing\npieces, these systems will require a demonstration of the complete task, which\nis cumbersome, repetitive, and can discourage people from helping the robot by\nperforming the demonstrations. Therefore, we propose to use the notion of\n\"excuses\" to identify the smallest change in the robot state that makes a task,\ncurrently not solvable by the robot, solvable -- as a means to solicit more\ntargeted demonstrations from a human. These excuses are generated automatically\nusing combinatorial search over possible changes that can be made to the\nrobot's state and choosing the minimum changes that make it solvable. These\nexcuses then serve as guidance for the demonstrator who can use it to decide\nwhat to demonstrate to the robot in order to make this requested change\npossible, thereby making the original task solvable for the robot without\nhaving to demonstrate it in its entirety. By working with symbolic state\ndescriptions, the excuses can be directly communicated and intuitively\nunderstood by a human demonstrator. We show empirically and in a user study\nthat the use of excuses reduces the demonstration time by 54% and leads to a\n74% reduction in demonstration size.",
            "author": [
                "Maximilian Diehl",
                "Tathagata Chakraborti",
                "Karinne Ramirez-Amaro"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18355v1",
                "http://arxiv.org/pdf/2311.18355v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18352v1",
            "title": "URLLC-Awared Resource Allocation for Heterogeneous Vehicular Edge\n  Computing",
            "updated": "2023-11-30T08:44:46Z",
            "published": "2023-11-30T08:44:46Z",
            "summary": "Vehicular edge computing (VEC) is a promising technology to support real-time\nvehicular applications, where vehicles offload intensive computation tasks to\nthe nearby VEC server for processing. However, the traditional VEC that relies\non single communication technology cannot well meet the communication\nrequirement for task offloading, thus the heterogeneous VEC integrating the\nadvantages of dedicated short-range communications (DSRC), millimeter-wave\n(mmWave) and cellular-based vehicle to infrastructure (C-V2I) is introduced to\nenhance the communication capacity. The communication resource allocation and\ncomputation resource allocation may significantly impact on the ultra-reliable\nlow-latency communication (URLLC) performance and the VEC system utility, in\nthis case, how to do the resource allocations is becoming necessary. In this\npaper, we consider a heterogeneous VEC with multiple communication technologies\nand various types of tasks, and propose an effective resource allocation policy\nto minimize the system utility while satisfying the URLLC requirement. We first\nformulate an optimization problem to minimize the system utility under the\nURLLC constraint which modeled by the moment generating function (MGF)-based\nstochastic network calculus (SNC), then we present a Lyapunov-guided deep\nreinforcement learning (DRL) method to convert and solve the optimization\nproblem. Extensive simulation experiments illustrate that the proposed resource\nallocation approach is effective.",
            "author": [
                "Qiong Wu",
                "Wenhua Wang",
                "Pingyi Fan",
                "Qiang Fan",
                "Jiangzhou Wang",
                "Khaled B. Letaief"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18352v1",
                "http://arxiv.org/pdf/2311.18352v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18350v1",
            "title": "Unveiling Backdoor Risks Brought by Foundation Models in Heterogeneous\n  Federated Learning",
            "updated": "2023-11-30T08:42:32Z",
            "published": "2023-11-30T08:42:32Z",
            "summary": "The foundation models (FMs) have been used to generate synthetic public\ndatasets for the heterogeneous federated learning (HFL) problem where each\nclient uses a unique model architecture. However, the vulnerabilities of\nintegrating FMs, especially against backdoor attacks, are not well-explored in\nthe HFL contexts. In this paper, we introduce a novel backdoor attack mechanism\nfor HFL that circumvents the need for client compromise or ongoing\nparticipation in the FL process. This method plants and transfers the backdoor\nthrough a generated synthetic public dataset, which could help evade existing\nbackdoor defenses in FL by presenting normal client behaviors. Empirical\nexperiments across different HFL configurations and benchmark datasets\ndemonstrate the effectiveness of our attack compared to traditional\nclient-based attacks. Our findings reveal significant security risks in\ndeveloping robust FM-assisted HFL systems. This research contributes to\nenhancing the safety and integrity of FL systems, highlighting the need for\nadvanced security measures in the era of FMs.",
            "author": [
                "Xi Li",
                "Chen Wu",
                "Jiaqi Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18350v1",
                "http://arxiv.org/pdf/2311.18350v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18348v1",
            "title": "Reconstructing Historical Climate Fields With Deep Learning",
            "updated": "2023-11-30T08:34:12Z",
            "published": "2023-11-30T08:34:12Z",
            "summary": "Historical records of climate fields are often sparse due to missing\nmeasurements, especially before the introduction of large-scale satellite\nmissions. Several statistical and model-based methods have been introduced to\nfill gaps and reconstruct historical records. Here, we employ a recently\nintroduced deep-learning approach based on Fourier convolutions, trained on\nnumerical climate model output, to reconstruct historical climate fields. Using\nthis approach we are able to realistically reconstruct large and irregular\nareas of missing data, as well as reconstruct known historical events such as\nstrong El Ni\\~no and La Ni\\~na with very little given information. Our method\noutperforms the widely used statistical kriging method as well as other recent\nmachine learning approaches. The model generalizes to higher resolutions than\nthe ones it was trained on and can be used on a variety of climate fields.\nMoreover, it allows inpainting of masks never seen before during the model\ntraining.",
            "author": [
                "Nils Bochow",
                "Anna Poltronieri",
                "Martin Rypdal",
                "Niklas Boers"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18348v1",
                "http://arxiv.org/pdf/2311.18348v1"
            ],
            "primary_category": "physics.geo-ph",
            "category": [
                "physics.geo-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18346v1",
            "title": "Efficient Model-Based Concave Utility Reinforcement Learning through\n  Greedy Mirror Descent",
            "updated": "2023-11-30T08:32:50Z",
            "published": "2023-11-30T08:32:50Z",
            "summary": "Many machine learning tasks can be solved by minimizing a convex function of\nan occupancy measure over the policies that generate them. These include\nreinforcement learning, imitation learning, among others. This more general\nparadigm is called the Concave Utility Reinforcement Learning problem (CURL).\nSince CURL invalidates classical Bellman equations, it requires new algorithms.\nWe introduce MD-CURL, a new algorithm for CURL in a finite horizon Markov\ndecision process. MD-CURL is inspired by mirror descent and uses a non-standard\nregularization to achieve convergence guarantees and a simple closed-form\nsolution, eliminating the need for computationally expensive projection steps\ntypically found in mirror descent approaches. We then extend CURL to an online\nlearning scenario and present Greedy MD-CURL, a new method adapting MD-CURL to\nan online, episode-based setting with partially unknown dynamics. Like MD-CURL,\nthe online version Greedy MD-CURL benefits from low computational complexity,\nwhile guaranteeing sub-linear or even logarithmic regret, depending on the\nlevel of information available on the underlying dynamics.",
            "author": [
                "Bianca Marin Moreno",
                "Margaux Br\u00e9g\u00e8re",
                "Pierre Gaillard",
                "Nadia Oudjane"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18346v1",
                "http://arxiv.org/pdf/2311.18346v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "physics.data-an",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18345v1",
            "title": "Situating the social issues of image generation models in the model life\n  cycle: a sociotechnical approach",
            "updated": "2023-11-30T08:32:32Z",
            "published": "2023-11-30T08:32:32Z",
            "summary": "The race to develop image generation models is intensifying, with a rapid\nincrease in the number of text-to-image models available. This is coupled with\ngrowing public awareness of these technologies. Though other generative AI\nmodels--notably, large language models--have received recent critical attention\nfor the social and other non-technical issues they raise, there has been\nrelatively little comparable examination of image generation models. This paper\nreports on a novel, comprehensive categorization of the social issues\nassociated with image generation models. At the intersection of machine\nlearning and the social sciences, we report the results of a survey of the\nliterature, identifying seven issue clusters arising from image generation\nmodels: data issues, intellectual property, bias, privacy, and the impacts on\nthe informational, cultural, and natural environments. We situate these social\nissues in the model life cycle, to aid in considering where potential issues\narise, and mitigation may be needed. We then compare these issue clusters with\nwhat has been reported for large language models. Ultimately, we argue that the\nrisks posed by image generation models are comparable in severity to the risks\nposed by large language models, and that the social impact of image generation\nmodels must be urgently considered.",
            "author": [
                "Amelia Katirai",
                "Noa Garcia",
                "Kazuki Ide",
                "Yuta Nakashima",
                "Atsuo Kishimoto"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18345v1",
                "http://arxiv.org/pdf/2311.18345v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18341v2",
            "title": "Learning Robust Precipitation Forecaster by Temporal Frame Interpolation",
            "updated": "2023-12-01T16:46:10Z",
            "published": "2023-11-30T08:22:08Z",
            "summary": "Recent advances in deep learning have significantly elevated weather\nprediction models. However, these models often falter in real-world scenarios\ndue to their sensitivity to spatial-temporal shifts. This issue is particularly\nacute in weather forecasting, where models are prone to overfit to local and\ntemporal variations, especially when tasked with fine-grained predictions. In\nthis paper, we address these challenges by developing a robust precipitation\nforecasting model that demonstrates resilience against such spatial-temporal\ndiscrepancies. We introduce Temporal Frame Interpolation (TFI), a novel\ntechnique that enhances the training dataset by generating synthetic samples\nthrough interpolating adjacent frames from satellite imagery and ground radar\ndata, thus improving the model's robustness against frame noise. Moreover, we\nincorporate a unique Multi-Level Dice (ML-Dice) loss function, leveraging the\nordinal nature of rainfall intensities to improve the model's performance. Our\napproach has led to significant improvements in forecasting precision,\nculminating in our model securing \\textit{1st place} in the transfer learning\nleaderboard of the \\textit{Weather4cast'23} competition. This achievement not\nonly underscores the effectiveness of our methodologies but also establishes a\nnew standard for deep learning applications in weather forecasting. Our code\nand weights have been public on \\url{https://github.com/Secilia-Cxy/UNetTFI}.",
            "author": [
                "Lu Han",
                "Xu-Yang Chen",
                "Han-Jia Ye",
                "De-Chuan Zhan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18341v2",
                "http://arxiv.org/pdf/2311.18341v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.ao-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18340v1",
            "title": "Neuromorphic Incremental on-chip Learning with Hebbian Weight\n  Consolidation",
            "updated": "2023-11-30T08:19:03Z",
            "published": "2023-11-30T08:19:03Z",
            "summary": "As next-generation implantable brain-machine interfaces become pervasive on\nedge device, incrementally learning new tasks in bio-plasticity ways is\nurgently demanded for Neuromorphic chips. Due to the inherent characteristics\nof its structure, spiking neural networks are naturally well-suited for\nBMI-chips. Here we propose Hebbian Weight Consolidation, as well as an on-chip\nlearning framework. HWC selectively masks synapse modifications for previous\ntasks, retaining them to store new knowledge from subsequent tasks while\npreserving the old knowledge. Leveraging the bio-plasticity of dendritic\nspines, the intrinsic self-organizing nature of Hebbian Weight Consolidation\naligns naturally with the incremental learning paradigm, facilitating robust\nlearning outcomes. By reading out spikes layer by layer and performing\nback-propagation on the external micro-controller unit, MLoC can efficiently\naccomplish on-chip learning. Experiments show that our HWC algorithm up to\n23.19% outperforms lower bound that without incremental learning algorithm,\nparticularly in more challenging monkey behavior decoding scenarios. Taking\ninto account on-chip computing on Synsense Speck 2e chip, our proposed\nalgorithm exhibits an improvement of 11.06%. This study demonstrates the\nfeasibility of employing incremental learning for high-performance neural\nsignal decoding in next-generation brain-machine interfaces.",
            "author": [
                "Zifan Ning",
                "Chaojin Chen",
                "Xiang Cheng",
                "Wangzi Yao",
                "Tielin Zhang",
                "Bo Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18340v1",
                "http://arxiv.org/pdf/2311.18340v1"
            ],
            "primary_category": "cs.ET",
            "category": [
                "cs.ET"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18332v1",
            "title": "Multilevel Saliency-Guided Self-Supervised Learning for Image Anomaly\n  Detection",
            "updated": "2023-11-30T08:03:53Z",
            "published": "2023-11-30T08:03:53Z",
            "summary": "Anomaly detection (AD) is a fundamental task in computer vision. It aims to\nidentify incorrect image data patterns which deviate from the normal ones.\nConventional methods generally address AD by preparing augmented negative\nsamples to enforce self-supervised learning. However, these techniques\ntypically do not consider semantics during augmentation, leading to the\ngeneration of unrealistic or invalid negative samples. Consequently, the\nfeature extraction network can be hindered from embedding critical features. In\nthis study, inspired by visual attention learning approaches, we propose\nCutSwap, which leverages saliency guidance to incorporate semantic cues for\naugmentation. Specifically, we first employ LayerCAM to extract multilevel\nimage features as saliency maps and then perform clustering to obtain multiple\ncentroids. To fully exploit saliency guidance, on each map, we select a pixel\npair from the cluster with the highest centroid saliency to form a patch pair.\nSuch a patch pair includes highly similar context information with dense\nsemantic correlations. The resulting negative sample is created by swapping the\nlocations of the patch pair. Compared to prior augmentation methods, CutSwap\ngenerates more subtle yet realistic negative samples to facilitate quality\nfeature learning. Extensive experimental and ablative evaluations demonstrate\nthat our method achieves state-of-the-art AD performance on two mainstream AD\nbenchmark datasets.",
            "author": [
                "Jianjian Qin",
                "Chunzhi Gu",
                "Jun Yu",
                "Chao Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18332v1",
                "http://arxiv.org/pdf/2311.18332v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18331v1",
            "title": "MRFP: Learning Generalizable Semantic Segmentation from Sim-2-Real with\n  Multi-Resolution Feature Perturbation",
            "updated": "2023-11-30T08:02:49Z",
            "published": "2023-11-30T08:02:49Z",
            "summary": "Deep neural networks have shown exemplary performance on semantic scene\nunderstanding tasks on source domains, but due to the absence of style\ndiversity during training, enhancing performance on unseen target domains using\nonly single source domain data remains a challenging task. Generation of\nsimulated data is a feasible alternative to retrieving large style-diverse\nreal-world datasets as it is a cumbersome and budget-intensive process.\nHowever, the large domain-specific inconsistencies between simulated and\nreal-world data pose a significant generalization challenge in semantic\nsegmentation. In this work, to alleviate this problem, we propose a novel\nMultiResolution Feature Perturbation (MRFP) technique to randomize\ndomain-specific fine-grained features and perturb style of coarse features. Our\nexperimental results on various urban-scene segmentation datasets clearly\nindicate that, along with the perturbation of style-information, perturbation\nof fine-feature components is paramount to learn domain invariant robust\nfeature maps for semantic segmentation models. MRFP is a simple and\ncomputationally efficient, transferable module with no additional learnable\nparameters or objective functions, that helps state-of-the-art deep neural\nnetworks to learn robust domain invariant features for simulation-to-real\nsemantic segmentation.",
            "author": [
                "Sumanth Udupa",
                "Prajwal Gurunath",
                "Aniruddh Sikdar",
                "Suresh Sundaram"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18331v1",
                "http://arxiv.org/pdf/2311.18331v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18327v1",
            "title": "Deep Reinforcement Learning Based Optimal Energy Management of\n  Multi-energy Microgrids with Uncertainties",
            "updated": "2023-11-30T07:58:39Z",
            "published": "2023-11-30T07:58:39Z",
            "summary": "Multi-energy microgrid (MEMG) offers an effective approach to deal with\nenergy demand diversification and new energy consumption on the consumer side.\nIn MEMG, it is critical to deploy an energy management system (EMS) for\nefficient utilization of energy and reliable operation of the system. To help\nEMS formulate optimal dispatching schemes, a deep reinforcement learning\n(DRL)-based MEMG energy management scheme with renewable energy source (RES)\nuncertainty is proposed in this paper. To accurately describe the operating\nstate of the MEMG, the off-design performance model of energy conversion\ndevices is considered in scheduling. The nonlinear optimal dispatching model is\nexpressed as a Markov decision process (MDP) and is then addressed by the twin\ndelayed deep deterministic policy gradient (TD3) algorithm. In addition, to\naccurately describe the uncertainty of RES, the conditional-least squares\ngenerative adversarial networks (C-LSGANs) method based on RES forecast power\nis proposed to construct the scenarios set of RES power generation. The\ngenerated data of RES is used for scheduling to obtain caps and floors for the\npurchase of electricity and natural gas. Based on this, the superior energy\nsupply sector can formulate solutions in advance to tackle the uncertainty of\nRES. Finally, the simulation analysis demonstrates the validity and superiority\nof the method.",
            "author": [
                "Yang Cui",
                "Yang Xu",
                "Yang Li",
                "Yijian Wang",
                "Xinpeng Zou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18327v1",
                "http://arxiv.org/pdf/2311.18327v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18326v1",
            "title": "AESTRA: Deep Learning for Precise Radial Velocity Estimation in the\n  Presence of Stellar Activity",
            "updated": "2023-11-30T07:57:02Z",
            "published": "2023-11-30T07:57:02Z",
            "summary": "Stellar activity interferes with precise radial velocity measurements and\nlimits our ability to detect and characterize planets, particularly Earth-like\nplanets. We introduce \\aestra (Auto-Encoding STellar Radial-velocity and\nActivity), a deep learning method for precise radial velocity measurements. It\ncombines a spectrum auto-encoder, which learns to create realistic models of\nthe star's rest-frame spectrum, and a radial-velocity estimator, which learns\nto identify true Doppler shifts in the presence of spurious shifts due to\nline-profile variations. Being self-supervised, \\aestra does not need \"ground\ntruth\" radial velocities for training, making it applicable to exoplanet host\nstars for which the truth is unknown. In tests involving 1,000 simulated\nspectra, \\aestra can detect planetary signals as low as 0.1 m/s even in the\npresence of 3 m/s of activity-induced noise and 0.3 m/s of photon noise per\nspectrum.",
            "author": [
                "Yan Liang",
                "Joshua N. Winn",
                "Peter Melchior"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18326v1",
                "http://arxiv.org/pdf/2311.18326v1"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00088v1",
            "title": "Anomaly Detection via Learning-Based Sequential Controlled Sensing",
            "updated": "2023-11-30T07:49:33Z",
            "published": "2023-11-30T07:49:33Z",
            "summary": "In this paper, we address the problem of detecting anomalies among a given\nset of binary processes via learning-based controlled sensing. Each process is\nparameterized by a binary random variable indicating whether the process is\nanomalous. To identify the anomalies, the decision-making agent is allowed to\nobserve a subset of the processes at each time instant. Also, probing each\nprocess has an associated cost. Our objective is to design a sequential\nselection policy that dynamically determines which processes to observe at each\ntime with the goal to minimize the delay in making the decision and the total\nsensing cost. We cast this problem as a sequential hypothesis testing problem\nwithin the framework of Markov decision processes. This formulation utilizes\nboth a Bayesian log-likelihood ratio-based reward and an entropy-based reward.\nThe problem is then solved using two approaches: 1) a deep reinforcement\nlearning-based approach where we design both deep Q-learning and policy\ngradient actor-critic algorithms; and 2) a deep active inference-based\napproach. Using numerical experiments, we demonstrate the efficacy of our\nalgorithms and show that our algorithms adapt to any unknown statistical\ndependence pattern of the processes.",
            "author": [
                "Geethu Joseph",
                "Chen Zhong",
                "M. Cenk Gursoy",
                "Senem Velipasalar",
                "Pramod K. Varshney"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00088v1",
                "http://arxiv.org/pdf/2312.00088v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SY",
                "eess.SP",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18316v1",
            "title": "Learning for Semantic Knowledge Base-Guided Online Feature Transmission\n  in Dynamic Channels",
            "updated": "2023-11-30T07:35:56Z",
            "published": "2023-11-30T07:35:56Z",
            "summary": "With the proliferation of edge computing, efficient AI inference on edge\ndevices has become essential for intelligent applications such as autonomous\nvehicles and VR/AR. In this context, we address the problem of efficient remote\nobject recognition by optimizing feature transmission between mobile devices\nand edge servers. We propose an online optimization framework to address the\nchallenge of dynamic channel conditions and device mobility in an end-to-end\ncommunication system. Our approach builds upon existing methods by leveraging a\nsemantic knowledge base to drive multi-level feature transmission, accounting\nfor temporal factors and dynamic elements throughout the transmission process.\nTo solve the online optimization problem, we design a novel soft\nactor-critic-based deep reinforcement learning system with a carefully designed\nreward function for real-time decision-making, overcoming the optimization\ndifficulty of the NP-hard problem and achieving the minimization of semantic\nloss while respecting latency constraints. Numerical results showcase the\nsuperiority of our approach compared to traditional greedy methods under\nvarious system setups.",
            "author": [
                "Xiangyu Gao",
                "Yaping Sun",
                "Dongyu Wei",
                "Xiaodong Xu",
                "Hao Chen",
                "Hao Yin",
                "Shuguang Cui"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18316v1",
                "http://arxiv.org/pdf/2311.18316v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.LG",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18313v1",
            "title": "Automatic Implementation of Neural Networks through Reaction Networks --\n  Part I: Circuit Design and Convergence Analysis",
            "updated": "2023-11-30T07:31:36Z",
            "published": "2023-11-30T07:31:36Z",
            "summary": "Information processing relying on biochemical interactions in the cellular\nenvironment is essential for biological organisms. The implementation of\nmolecular computational systems holds significant interest and potential in the\nfields of synthetic biology and molecular computation. This two-part article\naims to introduce a programmable biochemical reaction network (BCRN) system\nendowed with mass action kinetics that realizes the fully connected neural\nnetwork (FCNN) and has the potential to act automatically in vivo. In part I,\nthe feedforward propagation computation, the backpropagation component, and all\nbridging processes of FCNN are ingeniously designed as specific BCRN modules\nbased on their dynamics. This approach addresses a design gap in the\nbiochemical assignment module and judgment termination module and provides a\nnovel precise and robust realization of bi-molecular reactions for the learning\nprocess. Through equilibrium approaching, we demonstrate that the designed BCRN\nsystem achieves FCNN functionality with exponential convergence to target\ncomputational results, thereby enhancing the theoretical support for such work.\nFinally, the performance of this construction is further evaluated on two\ntypical logic classification problems.",
            "author": [
                "Yuzhen Fan",
                "Xiaoyu Zhang",
                "Chuanhou Gao",
                "Denis Dochain"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18313v1",
                "http://arxiv.org/pdf/2311.18313v1"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS",
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18311v1",
            "title": "Anisotropic Neural Representation Learning for High-Quality Neural\n  Rendering",
            "updated": "2023-11-30T07:29:30Z",
            "published": "2023-11-30T07:29:30Z",
            "summary": "Neural radiance fields (NeRFs) have achieved impressive view synthesis\nresults by learning an implicit volumetric representation from multi-view\nimages. To project the implicit representation into an image, NeRF employs\nvolume rendering that approximates the continuous integrals of rays as an\naccumulation of the colors and densities of the sampled points. Although this\napproximation enables efficient rendering, it ignores the direction information\nin point intervals, resulting in ambiguous features and limited reconstruction\nquality. In this paper, we propose an anisotropic neural representation\nlearning method that utilizes learnable view-dependent features to improve\nscene representation and reconstruction. We model the volumetric function as\nspherical harmonic (SH)-guided anisotropic features, parameterized by\nmultilayer perceptrons, facilitating ambiguity elimination while preserving the\nrendering efficiency. To achieve robust scene reconstruction without anisotropy\noverfitting, we regularize the energy of the anisotropic features during\ntraining. Our method is flexiable and can be plugged into NeRF-based\nframeworks. Extensive experiments show that the proposed representation can\nboost the rendering quality of various NeRFs and achieve state-of-the-art\nrendering performance on both synthetic and real-world scenes.",
            "author": [
                "Y. Wang",
                "J. Xu",
                "Y. Zeng",
                "Y. Gong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18311v1",
                "http://arxiv.org/pdf/2311.18311v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00087v1",
            "title": "Generative Artificial Intelligence in Learning Analytics:\n  Contextualising Opportunities and Challenges through the Learning Analytics\n  Cycle",
            "updated": "2023-11-30T07:25:34Z",
            "published": "2023-11-30T07:25:34Z",
            "summary": "Generative artificial intelligence (GenAI), exemplified by ChatGPT,\nMidjourney, and other state-of-the-art large language models and diffusion\nmodels, holds significant potential for transforming education and enhancing\nhuman productivity. While the prevalence of GenAI in education has motivated\nnumerous research initiatives, integrating these technologies within the\nlearning analytics (LA) cycle and their implications for practical\ninterventions remain underexplored. This paper delves into the prospective\nopportunities and challenges GenAI poses for advancing LA. We present a concise\noverview of the current GenAI landscape and contextualise its potential roles\nwithin Clow's generic framework of the LA cycle. We posit that GenAI can play\npivotal roles in analysing unstructured data, generating synthetic learner\ndata, enriching multimodal learner interactions, advancing interactive and\nexplanatory analytics, and facilitating personalisation and adaptive\ninterventions. As the lines blur between learners and GenAI tools, a renewed\nunderstanding of learners is needed. Future research can delve deep into\nframeworks and methodologies that advocate for human-AI collaboration. The LA\ncommunity can play a pivotal role in capturing data about human and AI\ncontributions and exploring how they can collaborate most effectively. As LA\nadvances, it is essential to consider the pedagogical implications and broader\nsocioeconomic impact of GenAI for ensuring an inclusive future.",
            "author": [
                "Lixiang Yan",
                "Roberto Martinez-Maldonado",
                "Dragan Ga\u0161evi\u0107"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00087v1",
                "http://arxiv.org/pdf/2312.00087v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18307v1",
            "title": "Categorical Traffic Transformer: Interpretable and Diverse Behavior\n  Prediction with Tokenized Latent",
            "updated": "2023-11-30T07:25:24Z",
            "published": "2023-11-30T07:25:24Z",
            "summary": "Adept traffic models are critical to both planning and closed-loop simulation\nfor autonomous vehicles (AV), and key design objectives include accuracy,\ndiverse multimodal behaviors, interpretability, and downstream compatibility.\nRecently, with the advent of large language models (LLMs), an additional\ndesirable feature for traffic models is LLM compatibility. We present\nCategorical Traffic Transformer (CTT), a traffic model that outputs both\ncontinuous trajectory predictions and tokenized categorical predictions (lane\nmodes, homotopies, etc.). The most outstanding feature of CTT is its fully\ninterpretable latent space, which enables direct supervision of the latent\nvariable from the ground truth during training and avoids mode collapse\ncompletely. As a result, CTT can generate diverse behaviors conditioned on\ndifferent latent modes with semantic meanings while beating SOTA on prediction\naccuracy. In addition, CTT's ability to input and output tokens enables\nintegration with LLMs for common-sense reasoning and zero-shot generalization.",
            "author": [
                "Yuxiao Chen",
                "Sander Tonkens",
                "Marco Pavone"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18307v1",
                "http://arxiv.org/pdf/2311.18307v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18306v1",
            "title": "PAUNet: Precipitation Attention-based U-Net for rain prediction from\n  satellite radiance data",
            "updated": "2023-11-30T07:22:55Z",
            "published": "2023-11-30T07:22:55Z",
            "summary": "This paper introduces Precipitation Attention-based U-Net (PAUNet), a deep\nlearning architecture for predicting precipitation from satellite radiance\ndata, addressing the challenges of the Weather4cast 2023 competition. PAUNet is\na variant of U-Net and Res-Net, designed to effectively capture the large-scale\ncontextual information of multi-band satellite images in visible, water vapor,\nand infrared bands through encoder convolutional layers with center cropping\nand attention mechanisms. We built upon the Focal Precipitation Loss including\nan exponential component (e-FPL), which further enhanced the importance across\ndifferent precipitation categories, particularly medium and heavy rain. Trained\non a substantial dataset from various European regions, PAUNet demonstrates\nnotable accuracy with a higher Critical Success Index (CSI) score than the\nbaseline model in predicting rainfall over multiple time slots. PAUNet's\narchitecture and training methodology showcase improvements in precipitation\nforecasting, crucial for sectors like emergency services and retail and supply\nchain management.",
            "author": [
                "P. Jyoteeshkumar Reddy",
                "Harish Baki",
                "Sandeep Chinta",
                "Richard Matear",
                "John Taylor"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18306v1",
                "http://arxiv.org/pdf/2311.18306v1"
            ],
            "primary_category": "physics.ao-ph",
            "category": [
                "physics.ao-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00084v1",
            "title": "Can Protective Perturbation Safeguard Personal Data from Being Exploited\n  by Stable Diffusion?",
            "updated": "2023-11-30T07:17:43Z",
            "published": "2023-11-30T07:17:43Z",
            "summary": "Stable Diffusion has established itself as a foundation model in generative\nAI artistic applications, receiving widespread research and application. Some\nrecent fine-tuning methods have made it feasible for individuals to implant\npersonalized concepts onto the basic Stable Diffusion model with minimal\ncomputational costs on small datasets. However, these innovations have also\ngiven rise to issues like facial privacy forgery and artistic copyright\ninfringement. In recent studies, researchers have explored the addition of\nimperceptible adversarial perturbations to images to prevent potential\nunauthorized exploitation and infringements when personal data is used for\nfine-tuning Stable Diffusion. Although these studies have demonstrated the\nability to protect images, it is essential to consider that these methods may\nnot be entirely applicable in real-world scenarios. In this paper, we\nsystematically evaluate the use of perturbations to protect images within a\npractical threat model. The results suggest that these approaches may not be\nsufficient to safeguard image privacy and copyright effectively. Furthermore,\nwe introduce a purification method capable of removing protected perturbations\nwhile preserving the original image structure to the greatest extent possible.\nExperiments reveal that Stable Diffusion can effectively learn from purified\nimages over all protective methods.",
            "author": [
                "Zhengyue Zhao",
                "Jinhao Duan",
                "Kaidi Xu",
                "Chenan Wang",
                "Rui Zhangp Zidong Dup Qi Guo",
                "Xing Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00084v1",
                "http://arxiv.org/pdf/2312.00084v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00083v1",
            "title": "BAM-DETR: Boundary-Aligned Moment Detection Transformer for Temporal\n  Sentence Grounding in Videos",
            "updated": "2023-11-30T07:16:11Z",
            "published": "2023-11-30T07:16:11Z",
            "summary": "Temporal sentence grounding aims to localize moments relevant to a language\ndescription. Recently, DETR-like approaches have shown notable progress by\ndecoding the center and length of a target moment from learnable queries.\nHowever, they suffer from the issue of center misalignment raised by the\ninherent ambiguity of moment centers, leading to inaccurate predictions. To\nremedy this problem, we introduce a novel boundary-oriented moment formulation.\nIn our paradigm, the model no longer needs to find the precise center but\ninstead suffices to predict any anchor point within the interval, from which\nthe onset and offset are directly estimated. Based on this idea, we design a\nBoundary-Aligned Moment Detection Transformer (BAM-DETR), equipped with a\ndual-pathway decoding process. Specifically, it refines the anchor and\nboundaries within parallel pathways using global and boundary-focused\nattention, respectively. This separate design allows the model to focus on\ndesirable regions, enabling precise refinement of moment predictions. Further,\nwe propose a quality-based ranking method, ensuring that proposals with high\nlocalization qualities are prioritized over incomplete ones. Extensive\nexperiments verify the advantages of our methods, where our model records new\nstate-of-the-art results on three benchmarks. Code is at\nhttps://github.com/Pilhyeon/BAM-DETR.",
            "author": [
                "Pilhyeon Lee",
                "Hyeran Byun"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00083v1",
                "http://arxiv.org/pdf/2312.00083v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18303v1",
            "title": "OmniMotionGPT: Animal Motion Generation with Limited Data",
            "updated": "2023-11-30T07:14:00Z",
            "published": "2023-11-30T07:14:00Z",
            "summary": "Our paper aims to generate diverse and realistic animal motion sequences from\ntextual descriptions, without a large-scale animal text-motion dataset. While\nthe task of text-driven human motion synthesis is already extensively studied\nand benchmarked, it remains challenging to transfer this success to other\nskeleton structures with limited data. In this work, we design a model\narchitecture that imitates Generative Pretraining Transformer (GPT), utilizing\nprior knowledge learned from human data to the animal domain. We jointly train\nmotion autoencoders for both animal and human motions and at the same time\noptimize through the similarity scores among human motion encoding, animal\nmotion encoding, and text CLIP embedding. Presenting the first solution to this\nproblem, we are able to generate animal motions with high diversity and\nfidelity, quantitatively and qualitatively outperforming the results of\ntraining human motion generation baselines on animal data. Additionally, we\nintroduce AnimalML3D, the first text-animal motion dataset with 1240 animation\nsequences spanning 36 different animal identities. We hope this dataset would\nmediate the data scarcity problem in text-driven animal motion generation,\nproviding a new playground for the research community.",
            "author": [
                "Zhangsihao Yang",
                "Mingyuan Zhou",
                "Mengyi Shan",
                "Bingbing Wen",
                "Ziwei Xuan",
                "Mitch Hill",
                "Junjie Bai",
                "Guo-Jun Qi",
                "Yalin Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18303v1",
                "http://arxiv.org/pdf/2311.18303v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18300v1",
            "title": "Multi-label Annotation for Visual Multi-Task Learning Models",
            "updated": "2023-11-30T07:10:13Z",
            "published": "2023-11-30T07:10:13Z",
            "summary": "Deep learning requires large amounts of data, and a well-defined pipeline for\nlabeling and augmentation. Current solutions support numerous computer vision\ntasks with dedicated annotation types and formats, such as bounding boxes,\npolygons, and key points. These annotations can be combined into a single data\nformat to benefit approaches such as multi-task models. However, to our\nknowledge, no available labeling tool supports the export functionality for a\ncombined benchmark format, and no augmentation library supports transformations\nfor the combination of all. In this work, these functionalities are presented,\nwith visual data annotation and augmentation to train a multi-task model\n(object detection, segmentation, and key point extraction). The tools are\ndemonstrated in two robot perception use cases.",
            "author": [
                "G. Sharma",
                "A. Angleraud",
                "R. Pieters"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18300v1",
                "http://arxiv.org/pdf/2311.18300v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18296v1",
            "title": "Perceptual Group Tokenizer: Building Perception with Iterative Grouping",
            "updated": "2023-11-30T07:00:14Z",
            "published": "2023-11-30T07:00:14Z",
            "summary": "Human visual recognition system shows astonishing capability of compressing\nvisual information into a set of tokens containing rich representations without\nlabel supervision. One critical driving principle behind it is perceptual\ngrouping. Despite being widely used in computer vision in the early 2010s, it\nremains a mystery whether perceptual grouping can be leveraged to derive a\nneural visual recognition backbone that generates as powerful representations.\nIn this paper, we propose the Perceptual Group Tokenizer, a model that entirely\nrelies on grouping operations to extract visual features and perform\nself-supervised representation learning, where a series of grouping operations\nare used to iteratively hypothesize the context for pixels or superpixels to\nrefine feature representations. We show that the proposed model can achieve\ncompetitive performance compared to state-of-the-art vision architectures, and\ninherits desirable properties including adaptive computation without\nre-training, and interpretability. Specifically, Perceptual Group Tokenizer\nachieves 80.3% on ImageNet-1K self-supervised learning benchmark with linear\nprobe evaluation, marking a new progress under this paradigm.",
            "author": [
                "Zhiwei Deng",
                "Ting Chen",
                "Yang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18296v1",
                "http://arxiv.org/pdf/2311.18296v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18274v1",
            "title": "Semiparametric Efficient Inference in Adaptive Experiments",
            "updated": "2023-11-30T06:25:06Z",
            "published": "2023-11-30T06:25:06Z",
            "summary": "We consider the problem of efficient inference of the Average Treatment\nEffect in a sequential experiment where the policy governing the assignment of\nsubjects to treatment or control can change over time. We first provide a\ncentral limit theorem for the Adaptive Augmented Inverse-Probability Weighted\nestimator, which is semiparametric efficient, under weaker assumptions than\nthose previously made in the literature. This central limit theorem enables\nefficient inference at fixed sample sizes. We then consider a sequential\ninference setting, deriving both asymptotic and nonasymptotic confidence\nsequences that are considerably tighter than previous methods. These\nanytime-valid methods enable inference under data-dependent stopping times\n(sample sizes). Additionally, we use propensity score truncation techniques\nfrom the recent off-policy estimation literature to reduce the finite sample\nvariance of our estimator without affecting the asymptotic variance. Empirical\nresults demonstrate that our methods yield narrower confidence sequences than\nthose previously developed in the literature while maintaining time-uniform\nerror control.",
            "author": [
                "Thomas Cook",
                "Alan Mishler",
                "Aaditya Ramdas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18274v1",
                "http://arxiv.org/pdf/2311.18274v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18273v1",
            "title": "HKUST at SemEval-2023 Task 1: Visual Word Sense Disambiguation with\n  Context Augmentation and Visual Assistance",
            "updated": "2023-11-30T06:23:15Z",
            "published": "2023-11-30T06:23:15Z",
            "summary": "Visual Word Sense Disambiguation (VWSD) is a multi-modal task that aims to\nselect, among a batch of candidate images, the one that best entails the target\nword's meaning within a limited context. In this paper, we propose a\nmulti-modal retrieval framework that maximally leverages pretrained\nVision-Language models, as well as open knowledge bases and datasets. Our\nsystem consists of the following key components: (1) Gloss matching: a\npretrained bi-encoder model is used to match contexts with proper senses of the\ntarget words; (2) Prompting: matched glosses and other textual information,\nsuch as synonyms, are incorporated using a prompting template; (3) Image\nretrieval: semantically matching images are retrieved from large open datasets\nusing prompts as queries; (4) Modality fusion: contextual information from\ndifferent modalities are fused and used for prediction. Although our system\ndoes not produce the most competitive results at SemEval-2023 Task 1, we are\nstill able to beat nearly half of the teams. More importantly, our experiments\nreveal acute insights for the field of Word Sense Disambiguation (WSD) and\nmulti-modal learning. Our code is available on GitHub.",
            "author": [
                "Zhuohao Yin",
                "Xin Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18273v1",
                "http://arxiv.org/pdf/2311.18273v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18266v1",
            "title": "Prompt-Based Exemplar Super-Compression and Regeneration for\n  Class-Incremental Learning",
            "updated": "2023-11-30T05:59:31Z",
            "published": "2023-11-30T05:59:31Z",
            "summary": "Replay-based methods in class-incremental learning (CIL) have attained\nremarkable success, as replaying the exemplars of old classes can significantly\nmitigate catastrophic forgetting. Despite their effectiveness, the inherent\nmemory restrictions of CIL result in saving a limited number of exemplars with\npoor diversity, leading to data imbalance and overfitting issues. In this\npaper, we introduce a novel exemplar super-compression and regeneration method,\nESCORT, which substantially increases the quantity and enhances the diversity\nof exemplars. Rather than storing past images, we compress images into visual\nand textual prompts, e.g., edge maps and class tags, and save the prompts\ninstead, reducing the memory usage of each exemplar to 1/24 of the original\nsize. In subsequent learning phases, diverse high-resolution exemplars are\ngenerated from the prompts by a pre-trained diffusion model, e.g., ControlNet.\nTo minimize the domain gap between generated exemplars and real images, we\npropose partial compression and diffusion-based data augmentation, allowing us\nto utilize an off-the-shelf diffusion model without fine-tuning it on the\ntarget dataset. Therefore, the same diffusion model can be downloaded whenever\nit is needed, incurring no memory consumption. Comprehensive experiments\ndemonstrate that our method significantly improves model performance across\nmultiple CIL benchmarks, e.g., 5.0 percentage points higher than the previous\nstate-of-the-art on 10-phase Caltech-256 dataset.",
            "author": [
                "Ruxiao Duan",
                "Yaoyao Liu",
                "Jieneng Chen",
                "Adam Kortylewski",
                "Alan Yuille"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18266v1",
                "http://arxiv.org/pdf/2311.18266v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00820v1",
            "title": "Non-Cross Diffusion for Semantic Consistency",
            "updated": "2023-11-30T05:53:39Z",
            "published": "2023-11-30T05:53:39Z",
            "summary": "In diffusion models, deviations from a straight generative flow are a common\nissue, resulting in semantic inconsistencies and suboptimal generations. To\naddress this challenge, we introduce `Non-Cross Diffusion', an innovative\napproach in generative modeling for learning ordinary differential equation\n(ODE) models. Our methodology strategically incorporates an ascending dimension\nof input to effectively connect points sampled from two distributions with\nuncrossed paths. This design is pivotal in ensuring enhanced semantic\nconsistency throughout the inference process, which is especially critical for\napplications reliant on consistent generative flows, including various\ndistillation methods and deterministic sampling, which are fundamental in image\nediting and interpolation tasks. Our empirical results demonstrate the\neffectiveness of Non-Cross Diffusion, showing a substantial reduction in\nsemantic inconsistencies at different inference steps and a notable enhancement\nin the overall performance of diffusion models.",
            "author": [
                "Ziyang Zheng",
                "Ruiyuan Gao",
                "Qiang Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00820v1",
                "http://arxiv.org/pdf/2312.00820v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18261v1",
            "title": "Learning Exactly Linearizable Deep Dynamics Models",
            "updated": "2023-11-30T05:40:55Z",
            "published": "2023-11-30T05:40:55Z",
            "summary": "Research on control using models based on machine-learning methods has now\nshifted to the practical engineering stage. Achieving high performance and\ntheoretically guaranteeing the safety of the system is critical for such\napplications. In this paper, we propose a learning method for exactly\nlinearizable dynamical models that can easily apply various control theories to\nensure stability, reliability, etc., and to provide a high degree of freedom of\nexpression. As an example, we present a design that combines simple linear\ncontrol and control barrier functions. The proposed model is employed for the\nreal-time control of an automotive engine, and the results demonstrate good\npredictive performance and stable control under constraints.",
            "author": [
                "Ryuta Moriyasu",
                "Masayuki Kusunoki",
                "Kenji Kashima"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18261v1",
                "http://arxiv.org/pdf/2311.18261v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18260v2",
            "title": "Consensus, dissensus and synergy between clinicians and specialist\n  foundation models in radiology report generation",
            "updated": "2023-12-06T17:16:07Z",
            "published": "2023-11-30T05:38:34Z",
            "summary": "Radiology reports are an instrumental part of modern medicine, informing key\nclinical decisions such as diagnosis and treatment. The worldwide shortage of\nradiologists, however, restricts access to expert care and imposes heavy\nworkloads, contributing to avoidable errors and delays in report delivery.\nWhile recent progress in automated report generation with vision-language\nmodels offer clear potential in ameliorating the situation, the path to\nreal-world adoption has been stymied by the challenge of evaluating the\nclinical quality of AI-generated reports. In this study, we build a\nstate-of-the-art report generation system for chest radiographs,\n\\textit{Flamingo-CXR}, by fine-tuning a well-known vision-language foundation\nmodel on radiology data. To evaluate the quality of the AI-generated reports, a\ngroup of 16 certified radiologists provide detailed evaluations of AI-generated\nand human written reports for chest X-rays from an intensive care setting in\nthe United States and an inpatient setting in India. At least one radiologist\n(out of two per case) preferred the AI report to the ground truth report in\nover 60$\\%$ of cases for both datasets. Amongst the subset of AI-generated\nreports that contain errors, the most frequently cited reasons were related to\nthe location and finding, whereas for human written reports, most mistakes were\nrelated to severity and finding. This disparity suggested potential\ncomplementarity between our AI system and human experts, prompting us to\ndevelop an assistive scenario in which \\textit{Flamingo-CXR} generates a\nfirst-draft report, which is subsequently revised by a clinician. This is the\nfirst demonstration of clinician-AI collaboration for report writing, and the\nresultant reports are assessed to be equivalent or preferred by at least one\nradiologist to reports written by experts alone in 80$\\%$ of in-patient cases\nand 60$\\%$ of intensive care cases.",
            "author": [
                "Ryutaro Tanno",
                "David G. T. Barrett",
                "Andrew Sellergren",
                "Sumedh Ghaisas",
                "Sumanth Dathathri",
                "Abigail See",
                "Johannes Welbl",
                "Karan Singhal",
                "Shekoofeh Azizi",
                "Tao Tu",
                "Mike Schaekermann",
                "Rhys May",
                "Roy Lee",
                "SiWai Man",
                "Zahra Ahmed",
                "Sara Mahdavi",
                "Danielle Belgrave",
                "Vivek Natarajan",
                "Shravya Shetty",
                "Pushmeet Kohli",
                "Po-Sen Huang",
                "Alan Karthikesalingam",
                "Ira Ktena"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18260v2",
                "http://arxiv.org/pdf/2311.18260v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CL",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18257v1",
            "title": "Diffusion Models Without Attention",
            "updated": "2023-11-30T05:15:35Z",
            "published": "2023-11-30T05:15:35Z",
            "summary": "In recent advancements in high-fidelity image generation, Denoising Diffusion\nProbabilistic Models (DDPMs) have emerged as a key player. However, their\napplication at high resolutions presents significant computational challenges.\nCurrent methods, such as patchifying, expedite processes in UNet and\nTransformer architectures but at the expense of representational capacity.\nAddressing this, we introduce the Diffusion State Space Model (DiffuSSM), an\narchitecture that supplants attention mechanisms with a more scalable state\nspace model backbone. This approach effectively handles higher resolutions\nwithout resorting to global compression, thus preserving detailed image\nrepresentation throughout the diffusion process. Our focus on FLOP-efficient\narchitectures in diffusion training marks a significant step forward.\nComprehensive evaluations on both ImageNet and LSUN datasets at two resolutions\ndemonstrate that DiffuSSMs are on par or even outperform existing diffusion\nmodels with attention modules in FID and Inception Score metrics while\nsignificantly reducing total FLOP usage.",
            "author": [
                "Jing Nathan Yan",
                "Jiatao Gu",
                "Alexander M. Rush"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18257v1",
                "http://arxiv.org/pdf/2311.18257v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18254v1",
            "title": "Sketch Input Method Editor: A Comprehensive Dataset and Methodology for\n  Systematic Input Recognition",
            "updated": "2023-11-30T05:05:38Z",
            "published": "2023-11-30T05:05:38Z",
            "summary": "With the recent surge in the use of touchscreen devices, free-hand sketching\nhas emerged as a promising modality for human-computer interaction. While\nprevious research has focused on tasks such as recognition, retrieval, and\ngeneration of familiar everyday objects, this study aims to create a Sketch\nInput Method Editor (SketchIME) specifically designed for a professional C4I\nsystem. Within this system, sketches are utilized as low-fidelity prototypes\nfor recommending standardized symbols in the creation of comprehensive\nsituation maps. This paper also presents a systematic dataset comprising 374\nspecialized sketch types, and proposes a simultaneous recognition and\nsegmentation architecture with multilevel supervision between recognition and\nsegmentation to improve performance and enhance interpretability. By\nincorporating few-shot domain adaptation and class-incremental learning, the\nnetwork's ability to adapt to new users and extend to new task-specific classes\nis significantly enhanced. Results from experiments conducted on both the\nproposed dataset and the SPG dataset illustrate the superior performance of the\nproposed architecture. Our dataset and code are publicly available at\nhttps://github.com/Anony517/SketchIME.",
            "author": [
                "Guangming Zhu",
                "Siyuan Wang",
                "Qing Cheng",
                "Kelong Wu",
                "Hao Li",
                "Liang Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18254v1",
                "http://arxiv.org/pdf/2311.18254v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18252v1",
            "title": "Navigating Privacy and Copyright Challenges Across the Data Lifecycle of\n  Generative AI",
            "updated": "2023-11-30T05:03:08Z",
            "published": "2023-11-30T05:03:08Z",
            "summary": "The advent of Generative AI has marked a significant milestone in artificial\nintelligence, demonstrating remarkable capabilities in generating realistic\nimages, texts, and data patterns. However, these advancements come with\nheightened concerns over data privacy and copyright infringement, primarily due\nto the reliance on vast datasets for model training. Traditional approaches\nlike differential privacy, machine unlearning, and data poisoning only offer\nfragmented solutions to these complex issues. Our paper delves into the\nmultifaceted challenges of privacy and copyright protection within the data\nlifecycle. We advocate for integrated approaches that combines technical\ninnovation with ethical foresight, holistically addressing these concerns by\ninvestigating and devising solutions that are informed by the lifecycle\nperspective. This work aims to catalyze a broader discussion and inspire\nconcerted efforts towards data privacy and copyright integrity in Generative\nAI.",
            "author": [
                "Dawen Zhang",
                "Boming Xia",
                "Yue Liu",
                "Xiwei Xu",
                "Thong Hoang",
                "Zhenchang Xing",
                "Mark Staples",
                "Qinghua Lu",
                "Liming Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18252v1",
                "http://arxiv.org/pdf/2311.18252v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.AI",
                "cs.CY",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18251v1",
            "title": "Can Large Language Models Be Good Companions? An LLM-Based Eyewear\n  System with Conversational Common Ground",
            "updated": "2023-11-30T04:59:34Z",
            "published": "2023-11-30T04:59:34Z",
            "summary": "Developing chatbots as personal companions has long been a goal of artificial\nintelligence researchers. Recent advances in Large Language Models (LLMs) have\ndelivered a practical solution for endowing chatbots with anthropomorphic\nlanguage capabilities. However, it takes more than LLMs to enable chatbots that\ncan act as companions. Humans use their understanding of individual\npersonalities to drive conversations. Chatbots also require this capability to\nenable human-like companionship. They should act based on personalized,\nreal-time, and time-evolving knowledge of their owner. We define such essential\nknowledge as the \\textit{common ground} between chatbots and their owners, and\nwe propose to build a common-ground-aware dialogue system from an LLM-based\nmodule, named \\textit{OS-1}, to enable chatbot companionship. Hosted by\neyewear, OS-1 can sense the visual and audio signals the user receives and\nextract real-time contextual semantics. Those semantics are categorized and\nrecorded to formulate historical contexts from which the user's profile is\ndistilled and evolves over time, i.e., OS-1 gradually learns about its user.\nOS-1 combines knowledge from real-time semantics, historical contexts, and\nuser-specific profiles to produce a common-ground-aware prompt input into the\nLLM module. The LLM's output is converted to audio, spoken to the wearer when\nappropriate.We conduct laboratory and in-field studies to assess OS-1's ability\nto build common ground between the chatbot and its user. The technical\nfeasibility and capabilities of the system are also evaluated. OS-1, with its\ncommon-ground awareness, can significantly improve user satisfaction and\npotentially lead to downstream tasks such as personal emotional support and\nassistance.",
            "author": [
                "Zhenyu Xu",
                "Hailin Xu",
                "Zhouyang Lu",
                "Yingying Zhao",
                "Rui Zhu",
                "Yujiang Wang",
                "Mingzhi Dong",
                "Yuhu Chang",
                "Qin Lv",
                "Robert P. Dick",
                "Fan Yang",
                "Tun Lu",
                "Ning Gu",
                "Li Shang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18251v1",
                "http://arxiv.org/pdf/2311.18251v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18246v1",
            "title": "Combined Scheduling, Memory Allocation and Tensor Replacement for\n  Minimizing Off-Chip Data Accesses of DNN Accelerators",
            "updated": "2023-11-30T04:36:25Z",
            "published": "2023-11-30T04:36:25Z",
            "summary": "Specialized hardware accelerators have been extensively used for Deep Neural\nNetworks (DNNs) to provide power/performance benefits. These accelerators\ncontain specialized hardware that supports DNN operators, and scratchpad memory\nfor storing the tensor operands. Often, the size of the scratchpad is\ninsufficient to store all the tensors needed for the computation, and\nadditional data accesses are needed to move tensors back and forth from host\nmemory during the computation with significant power/performance overhead. The\nvolume of these additional data accesses depends on the operator schedule, and\nmemory allocation (specific locations selected for the tensors in the\nscratchpad). We propose an optimization framework, named COSMA, for mapping\nDNNs to an accelerator that finds the optimal operator schedule, memory\nallocation and tensor replacement that minimizes the additional data accesses.\nCOSMA provides an Integer Linear Programming (ILP) formulation to generate the\noptimal solution for mapping a DNN to the accelerator for a given scratchpad\nsize. We demonstrate that, using an off-the-shelf ILP solver, COSMA obtains the\noptimal solution in seconds for a wide-range of state-of-the-art DNNs for\ndifferent applications. Further, it out-performs existing methods by reducing\non average 84% of the non-compulsory data accesses. We further propose a\ndivide-and-conquer heuristic to scale up to certain complex DNNs generated by\nNeural Architecture Search, and this heuristic solution reduces on average 85%\ndata accesses compared with other works.",
            "author": [
                "Yi Li",
                "Aarti Gupta",
                "Sharad Malik"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18246v1",
                "http://arxiv.org/pdf/2311.18246v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00819v1",
            "title": "Large Language Models for Travel Behavior Prediction",
            "updated": "2023-11-30T04:35:55Z",
            "published": "2023-11-30T04:35:55Z",
            "summary": "Travel behavior prediction is a fundamental task in transportation demand\nmanagement. The conventional methods for travel behavior prediction rely on\nnumerical data to construct mathematical models and calibrate model parameters\nto represent human preferences. Recent advancement in large language models\n(LLMs) has shown great reasoning abilities to solve complex problems. In this\nstudy, we propose to use LLMs to predict travel behavior with prompt\nengineering without data-based parameter learning. Specifically, we carefully\ndesign our prompts that include 1) task description, 2) travel characteristics,\n3) individual attributes, and 4) guides of thinking with domain knowledge, and\nask the LLMs to predict an individual's travel behavior and explain the\nresults. We select the travel mode choice task as a case study. Results show\nthat, though no training samples are provided, LLM-based predictions have\ncompetitive accuracy and F1-score as canonical supervised learning methods such\nas multinomial logit, random forest, and neural networks. LLMs can also output\nreasons that support their prediction. However, though in most of the cases,\nthe output explanations are reasonable, we still observe cases that violate\nlogic or with hallucinations.",
            "author": [
                "Baichuan Mo",
                "Hanyong Xu",
                "Dingyi Zhuang",
                "Ruoyun Ma",
                "Xiaotong Guo",
                "Jinhua Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00819v1",
                "http://arxiv.org/pdf/2312.00819v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18245v1",
            "title": "Automatic Detection of Alzheimer's Disease with Multi-Modal Fusion of\n  Clinical MRI Scans",
            "updated": "2023-11-30T04:32:28Z",
            "published": "2023-11-30T04:32:28Z",
            "summary": "The aging population of the U.S. drives the prevalence of Alzheimer's\ndisease. Brookmeyer et al. forecasts approximately 15 million Americans will\nhave either clinical AD or mild cognitive impairment by 2060. In response to\nthis urgent call, methods for early detection of Alzheimer's disease have been\ndeveloped for prevention and pre-treatment. Notably, literature on the\napplication of deep learning in the automatic detection of the disease has been\nproliferating. This study builds upon previous literature and maintains a focus\non leveraging multi-modal information to enhance automatic detection. We aim to\npredict the stage of the disease - Cognitively Normal (CN), Mildly Cognitive\nImpairment (MCI), and Alzheimer's Disease (AD), based on two different types of\nbrain MRI scans. We design an AlexNet-based deep learning model that learns the\nsynergy of complementary information from both T1 and FLAIR MRI scans.",
            "author": [
                "Long Chen",
                "Liben Chen",
                "Binfeng Xu",
                "Wenxin Zhang",
                "Narges Razavian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18245v1",
                "http://arxiv.org/pdf/2311.18245v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18244v1",
            "title": "Poisoning Attacks Against Contrastive Recommender Systems",
            "updated": "2023-11-30T04:25:28Z",
            "published": "2023-11-30T04:25:28Z",
            "summary": "Contrastive learning (CL) has recently gained significant popularity in the\nfield of recommendation. Its ability to learn without heavy reliance on labeled\ndata is a natural antidote to the data sparsity issue. Previous research has\nfound that CL can not only enhance recommendation accuracy but also\ninadvertently exhibit remarkable robustness against noise. However, this paper\nidentifies a vulnerability of CL-based recommender systems: Compared with their\nnon-CL counterparts, they are even more susceptible to poisoning attacks that\naim to promote target items. Our analysis points to the uniform dispersion of\nrepresentations led by the CL loss as the very factor that accounts for this\nvulnerability. We further theoretically and empirically demonstrate that the\noptimization of CL loss can lead to smooth spectral values of representations.\nBased on these insights, we attempt to reveal the potential poisoning attacks\nagainst CL-based recommender systems. The proposed attack encompasses a\ndual-objective framework: One that induces a smoother spectral value\ndistribution to amplify the CL loss's inherent dispersion effect, named\ndispersion promotion; and the other that directly elevates the visibility of\ntarget items, named rank promotion. We validate the destructiveness of our\nattack model through extensive experimentation on four datasets. By shedding\nlight on these vulnerabilities, we aim to facilitate the development of more\nrobust CL-based recommender systems.",
            "author": [
                "Zongwei Wang",
                "Junliang Yu",
                "Min Gao",
                "Hongzhi Yin",
                "Bin Cui",
                "Shazia Sadiq"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18244v1",
                "http://arxiv.org/pdf/2311.18244v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18243v1",
            "title": "DKiS: Decay weight invertible image steganography with private key",
            "updated": "2023-11-30T04:21:10Z",
            "published": "2023-11-30T04:21:10Z",
            "summary": "Image steganography, the practice of concealing information within another\nimage, traditionally faces security challenges when its methods become publicly\nknown. To counteract this, we introduce a novel private key-based image\nsteganography technique. This approach ensures the security of hidden\ninformation, requiring a corresponding private key for access, irrespective of\nthe public knowledge of the steganography method. We present experimental\nevidence demonstrating our method's effectiveness, showcasing its real-world\napplicability. Additionally, we identified a critical challenge in the\ninvertible image steganography process: the transfer of non-essential, or\n`garbage', information from the secret to the host pipeline. To address this,\nwe introduced the decay weight to control the information transfer, filtering\nout irrelevant data and enhancing the performance of image steganography. Our\ncode is publicly accessible at https://github.com/yanghangAI/DKiS, and a\npractical demonstration is available at http://yanghang.site/hidekey.",
            "author": [
                "Hang Yang",
                "Yitian Xu",
                "Xuhua Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18243v1",
                "http://arxiv.org/pdf/2311.18243v1"
            ],
            "primary_category": "cs.MM",
            "category": [
                "cs.MM",
                "cs.CR",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18237v1",
            "title": "Label-efficient Training of Small Task-specific Models by Leveraging\n  Vision Foundation Models",
            "updated": "2023-11-30T04:07:44Z",
            "published": "2023-11-30T04:07:44Z",
            "summary": "Large Vision Foundation Models (VFMs) pretrained on massive datasets exhibit\nimpressive performance on various downstream tasks, especially with limited\nlabeled target data. However, due to their high memory and compute\nrequirements, these models cannot be deployed in resource constrained settings.\nThis raises an important question: How can we utilize the knowledge from a\nlarge VFM to train a small task-specific model for a new target task with\nlimited labeled training data? In this work, we answer this question by\nproposing a simple and highly effective task-oriented knowledge transfer\napproach to leverage pretrained VFMs for effective training of small\ntask-specific models. Our experimental results on four target tasks under\nlimited labeled data settings show that the proposed knowledge transfer\napproach outperforms task-agnostic VFM distillation, web-scale CLIP pretraining\nand supervised ImageNet pretraining by 1-10.5%, 2-22% and 2-14%, respectively.\nWe also show that the dataset used for transferring knowledge has a significant\neffect on the final target task performance, and propose an image\nretrieval-based approach for curating effective transfer sets.",
            "author": [
                "Raviteja Vemulapalli",
                "Hadi Pouransari",
                "Fartash Faghri",
                "Sachin Mehta",
                "Mehrdad Farajtabar",
                "Mohammad Rastegari",
                "Oncel Tuzel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18237v1",
                "http://arxiv.org/pdf/2311.18237v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18233v2",
            "title": "Semantic Bound and Multi Types, Revisited",
            "updated": "2023-12-04T08:58:22Z",
            "published": "2023-11-30T03:59:45Z",
            "summary": "Intersection types are a standard tool in operational and semantical studies\nof the lambda calculus. De Carvalho showed how multi types, a quantitative\nvariant of intersection types providing a handy presentation of the relational\ndenotational model, allows one to extract precise bounds on the number of\n$\\beta$-steps and the size of normal forms.\n  In the last few years, de Carvalho's work has been extended and adapted to a\nnumber of lambda calculi, evaluation strategies, and abstract machines. These\nworks, however, only adapt the first part of his work, that extracts bounds\nfrom multi type derivations, while never consider the second part, which deals\nwith extracting bounds from the multi types themselves. The reason is that this\nsecond part is more technical, and requires to reason up to type substitutions.\nIt is however also the most interesting, because it shows that the bounding\npower is inherent to the relational model (which is induced by the types,\nwithout the derivations), independently of its presentation as a type system.\n  Here we dissect and clarify the second part of de Carvalho's work,\nestablishing a link with principal multi types, and isolating a key property\nindependent of type substitutions.",
            "author": [
                "Beniamino Accattoli"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18233v2",
                "http://arxiv.org/pdf/2311.18233v2"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18232v1",
            "title": "LMRL Gym: Benchmarks for Multi-Turn Reinforcement Learning with Language\n  Models",
            "updated": "2023-11-30T03:59:31Z",
            "published": "2023-11-30T03:59:31Z",
            "summary": "Large language models (LLMs) provide excellent text-generation capabilities,\nbut standard prompting and generation methods generally do not lead to\nintentional or goal-directed agents and might necessitate considerable prompt\ntuning. This becomes particularly apparent in multi-turn conversations: even\nthe best current LLMs rarely ask clarifying questions, engage in explicit\ninformation gathering, or take actions now that lead to better decisions after\nmultiple turns. Reinforcement learning has the potential to leverage the\npowerful modeling capabilities of LLMs, as well as their internal\nrepresentation of textual interactions, to create capable goal-directed\nlanguage agents. This can enable intentional and temporally extended\ninteractions, such as with humans, through coordinated persuasion and carefully\ncrafted questions, or in goal-directed play through text games to bring about\ndesired final outcomes. However, enabling this requires the community to\ndevelop stable and reliable reinforcement learning algorithms that can\neffectively train LLMs. Developing such algorithms requires tasks that can\ngauge progress on algorithm design, provide accessible and reproducible\nevaluations for multi-turn interactions, and cover a range of task properties\nand challenges in improving reinforcement learning algorithms. Our paper\nintroduces the LMRL-Gym benchmark for evaluating multi-turn RL for LLMs,\ntogether with an open-source research framework containing a basic toolkit for\ngetting started on multi-turn RL with offline value-based and policy-based RL\nmethods. Our benchmark consists of 8 different language tasks, which require\nmultiple rounds of language interaction and cover a range of tasks in\nopen-ended dialogue and text games.",
            "author": [
                "Marwa Abdulhai",
                "Isadora White",
                "Charlie Snell",
                "Charles Sun",
                "Joey Hong",
                "Yuexiang Zhai",
                "Kelvin Xu",
                "Sergey Levine"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18232v1",
                "http://arxiv.org/pdf/2311.18232v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18224v1",
            "title": "Reasoning with the Theory of Mind for Pragmatic Semantic Communication",
            "updated": "2023-11-30T03:36:19Z",
            "published": "2023-11-30T03:36:19Z",
            "summary": "In this paper, a pragmatic semantic communication framework that enables\neffective goal-oriented information sharing between two-intelligent agents is\nproposed. In particular, semantics is defined as the causal state that\nencapsulates the fundamental causal relationships and dependencies among\ndifferent features extracted from data. The proposed framework leverages the\nemerging concept in machine learning (ML) called theory of mind (ToM). It\nemploys a dynamic two-level (wireless and semantic) feedback mechanism to\ncontinuously fine-tune neural network components at the transmitter. Thanks to\nthe ToM, the transmitter mimics the actual mental state of the receiver's\nreasoning neural network operating semantic interpretation. Then, the estimated\nmental state at the receiver is dynamically updated thanks to the proposed\ndynamic two-level feedback mechanism. At the lower level, conventional channel\nquality metrics are used to optimize the channel encoding process based on the\nwireless communication channel's quality, ensuring an efficient mapping of\nsemantic representations to a finite constellation. Additionally, a semantic\nfeedback level is introduced, providing information on the receiver's perceived\nsemantic effectiveness with minimal overhead. Numerical evaluations demonstrate\nthe framework's ability to achieve efficient communication with a reduced\namount of bits while maintaining the same semantics, outperforming conventional\nsystems that do not exploit the ToM-based reasoning.",
            "author": [
                "Christo Kurisummoottil Thomas",
                "Emilio Calvanese Strinati",
                "Walid Saad"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18224v1",
                "http://arxiv.org/pdf/2311.18224v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.AI",
                "cs.LG",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18222v1",
            "title": "AI-predicted protein deformation encodes energy landscape perturbation",
            "updated": "2023-11-30T03:33:05Z",
            "published": "2023-11-30T03:33:05Z",
            "summary": "AI algorithms proved excellent predictors of protein structure, but whether\ntheir exceptional accuracy is merely due to megascale regression or these\nalgorithms learn the underlying physics remains an open question. Here, we\nperform a stringent test for the existence of such learning in the Alphafold2\n(AF) algorithm: We use AF to predict the subtle structural deformation induced\nby single mutations, quantified by strain, and compare with experimental\ndatasets of corresponding perturbations in folding free energy $\\Delta\\Delta\nG$. Unexpectedly, we find that physical strain alone -- without any additional\ndata or computation -- correlates almost as well with $\\Delta \\Delta G$ as\nstate-of-the-art energy-based and machine-learning predictors.This indicates\nthat the AF-predicted structures alone encode fine details about the energy\nlandscape. In particular, the structures encode significant information on\nstability, enough to estimate (de-)stabilizing effects of mutations, thus\npaving the way for the development of novel, structure-based stability\npredictors for protein design and evolution.",
            "author": [
                "John M Mcbride",
                "Tsvi Tlusty"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18222v1",
                "http://arxiv.org/pdf/2311.18222v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM",
                "physics.bio-ph",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18221v1",
            "title": "Determining the core-collapse supernova explosion mechanism with current\n  and future gravitational-wave observatories",
            "updated": "2023-11-30T03:31:52Z",
            "published": "2023-11-30T03:31:52Z",
            "summary": "Gravitational waves are emitted from deep within a core-collapse supernova,\nwhich may enable us to determine the mechanism of the explosion from a\ngravitational-wave detection. Previous studies suggested that it is possible to\ndetermine if the explosion mechanism is neutrino-driven or magneto-rotationally\npowered from the gravitational-wave signal. However, long duration\nmagneto-rotational waveforms, that cover the full explosion phase, were not\navailable during the time of previous studies, and explosions were just assumed\nto be magneto-rotationally driven if the model was rapidly rotating. Therefore,\nwe perform an updated study using new 3D long-duration magneto-rotational\ncore-collapse supernova waveforms that cover the full explosion phase, injected\ninto noise for the Advanced LIGO, Einstein Telescope and NEMO\ngravitational-wave detectors. We also include a category for failed explosions\nin our signal classification results. We then determine the explosion mechanism\nof the signals using three different methods: Bayesian model selection,\ndictionary learning, and convolutional neural networks. The three different\nmethods are able to distinguish between neutrino-driven driven explosions and\nmagneto-rotational explosions, however they can only distinguish between the\nnon-exploding and neutrino-driven explosions for signals with a high signal to\nnoise ratio.",
            "author": [
                "Jade Powell",
                "Alberto Iess",
                "Miquel Llorens-Monteagudo",
                "Martin Obergaulinger",
                "Bernhard M\u00fcller",
                "Alejandro Torres-Forn\u00e9",
                "Elena Cuoco",
                "Jos\u00e9 A. Font"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18221v1",
                "http://arxiv.org/pdf/2311.18221v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE",
                "gr-qc"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18220v1",
            "title": "Lifting query complexity to time-space complexity for two-way finite\n  automata",
            "updated": "2023-11-30T03:31:01Z",
            "published": "2023-11-30T03:31:01Z",
            "summary": "Time-space tradeoff has been studied in a variety of models, such as Turing\nmachines, branching programs, and finite automata, etc. While communication\ncomplexity as a technique has been applied to study finite automata, it seems\nit has not been used to study time-space tradeoffs of finite automata. We\ndesign a new technique showing that separations of query complexity can be\nlifted, via communication complexity, to separations of time-space complexity\nof two-way finite automata. As an application, one of our main results exhibits\nthe first example of a language $L$ such that the time-space complexity of\ntwo-way probabilistic finite automata with a bounded error (2PFA) is\n$\\widetilde{\\Omega}(n^2)$, while of exact two-way quantum finite automata with\nclassical states (2QCFA) is $\\widetilde{O}(n^{5/3})$, that is, we demonstrate\nfor the first time that exact quantum computing has an advantage in time-space\ncomplexity comparing to classical computing.",
            "author": [
                "Shenggen Zheng",
                "Yaqiao Li",
                "Minghua Pan",
                "Jozef Gruska",
                "Lvzhou Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18220v1",
                "http://arxiv.org/pdf/2311.18220v1"
            ],
            "primary_category": "cs.CC",
            "category": [
                "cs.CC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18219v1",
            "title": "FoldExplorer: Fast and Accurate Protein Structure Search with\n  Sequence-Enhanced Graph Embedding",
            "updated": "2023-11-30T03:29:20Z",
            "published": "2023-11-30T03:29:20Z",
            "summary": "The advent of highly accurate protein structure prediction methods has fueled\nan exponential expansion of the protein structure database. Consequently, there\nis a rising demand for rapid and precise structural homolog search. Traditional\nalignment-based methods are dedicated to precise comparisons between pairs,\nexhibiting high accuracy. However, their sluggish processing speed is no longer\nadequate for managing the current massive volume of data. In response to this\nchallenge, we propose a novel deep-learning approach FoldExplorer. It harnesses\nthe powerful capabilities of graph attention neural networks and protein large\nlanguage models for protein structures and sequences data processing to\ngenerate embeddings for protein structures. The structural embeddings can be\nused for fast and accurate protein search. The embeddings also provide insights\ninto the protein space. FoldExplorer demonstrates a substantial performance\nimprovement of 5% to 8% over the current state-of-the-art algorithm on the\nbenchmark datasets. Meanwhile, FoldExplorer does not compromise on search speed\nand excels particularly in searching on a large-scale dataset.",
            "author": [
                "Yuan Liu",
                "Hong-Bin Shen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18219v1",
                "http://arxiv.org/pdf/2311.18219v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18213v1",
            "title": "Beyond Two-Tower Matching: Learning Sparse Retrievable\n  Cross-Interactions for Recommendation",
            "updated": "2023-11-30T03:13:36Z",
            "published": "2023-11-30T03:13:36Z",
            "summary": "Two-tower models are a prevalent matching framework for recommendation, which\nhave been widely deployed in industrial applications. The success of two-tower\nmatching attributes to its efficiency in retrieval among a large number of\nitems, since the item tower can be precomputed and used for fast Approximate\nNearest Neighbor (ANN) search. However, it suffers two main challenges,\nincluding limited feature interaction capability and reduced accuracy in online\nserving. Existing approaches attempt to design novel late interactions instead\nof dot products, but they still fail to support complex feature interactions or\nlose retrieval efficiency. To address these challenges, we propose a new\nmatching paradigm named SparCode, which supports not only sophisticated feature\ninteractions but also efficient retrieval. Specifically, SparCode introduces an\nall-to-all interaction module to model fine-grained query-item interactions.\nBesides, we design a discrete code-based sparse inverted index jointly trained\nwith the model to achieve effective and efficient model inference. Extensive\nexperiments have been conducted on open benchmark datasets to demonstrate the\nsuperiority of our framework. The results show that SparCode significantly\nimproves the accuracy of candidate item matching while retaining the same level\nof retrieval efficiency with two-tower models. Our source code will be\navailable at MindSpore/models.",
            "author": [
                "Liangcai Su",
                "Fan Yan",
                "Jieming Zhu",
                "Xi Xiao",
                "Haoyi Duan",
                "Zhou Zhao",
                "Zhenhua Dong",
                "Ruiming Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18213v1",
                "http://arxiv.org/pdf/2311.18213v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18208v1",
            "title": "SMaRt: Improving GANs with Score Matching Regularity",
            "updated": "2023-11-30T03:05:14Z",
            "published": "2023-11-30T03:05:14Z",
            "summary": "Generative adversarial networks (GANs) usually struggle in learning from\nhighly diverse data, whose underlying manifold is complex. In this work, we\nrevisit the mathematical foundations of GANs, and theoretically reveal that the\nnative adversarial loss for GAN training is insufficient to fix the problem of\nsubsets with positive Lebesgue measure of the generated data manifold lying out\nof the real data manifold. Instead, we find that score matching serves as a\nvalid solution to this issue thanks to its capability of persistently pushing\nthe generated data points towards the real data manifold. We thereby propose to\nimprove the optimization of GANs with score matching regularity (SMaRt).\nRegarding the empirical evidences, we first design a toy example to show that\ntraining GANs by the aid of a ground-truth score function can help reproduce\nthe real data distribution more accurately, and then confirm that our approach\ncan consistently boost the synthesis performance of various state-of-the-art\nGANs on real-world datasets with pre-trained diffusion models acting as the\napproximate score function. For instance, when training Aurora on the ImageNet\n64x64 dataset, we manage to improve FID from 8.87 to 7.11, on par with the\nperformance of one-step consistency model. The source code will be made public.",
            "author": [
                "Mengfei Xia",
                "Yujun Shen",
                "Ceyuan Yang",
                "Ran Yi",
                "Wenping Wang",
                "Yong-jin Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18208v1",
                "http://arxiv.org/pdf/2311.18208v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18207v2",
            "title": "Towards Assessing and Benchmarking Risk-Return Tradeoff of Off-Policy\n  Evaluation",
            "updated": "2023-12-04T18:37:30Z",
            "published": "2023-11-30T02:56:49Z",
            "summary": "Off-Policy Evaluation (OPE) aims to assess the effectiveness of\ncounterfactual policies using only offline logged data and is often used to\nidentify the top-k promising policies for deployment in online A/B tests.\nExisting evaluation metrics for OPE estimators primarily focus on the\n\"accuracy\" of OPE or that of downstream policy selection, neglecting\nrisk-return tradeoff in the subsequent online policy deployment. To address\nthis issue, we draw inspiration from portfolio evaluation in finance and\ndevelop a new metric, called SharpeRatio@k, which measures the risk-return\ntradeoff of policy portfolios formed by an OPE estimator under varying online\nevaluation budgets (k). We validate our metric in two example scenarios,\ndemonstrating its ability to effectively distinguish between low-risk and\nhigh-risk estimators and to accurately identify the most efficient estimator.\nThis efficient estimator is characterized by its capability to form the most\nadvantageous policy portfolios, maximizing returns while minimizing risks\nduring online deployment, a nuance that existing metrics typically overlook. To\nfacilitate a quick, accurate, and consistent evaluation of OPE via\nSharpeRatio@k, we have also integrated this metric into an open-source\nsoftware, SCOPE-RL. Employing SharpeRatio@k and SCOPE-RL, we conduct\ncomprehensive benchmarking experiments on various estimators and RL tasks,\nfocusing on their risk-return tradeoff. These experiments offer several\ninteresting directions and suggestions for future OPE research.",
            "author": [
                "Haruka Kiyohara",
                "Ren Kishimoto",
                "Kosuke Kawakami",
                "Ken Kobayashi",
                "Kazuhide Nakata",
                "Yuta Saito"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18207v2",
                "http://arxiv.org/pdf/2311.18207v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18206v2",
            "title": "SCOPE-RL: A Python Library for Offline Reinforcement Learning and\n  Off-Policy Evaluation",
            "updated": "2023-12-04T18:42:03Z",
            "published": "2023-11-30T02:56:43Z",
            "summary": "This paper introduces SCOPE-RL, a comprehensive open-source Python software\ndesigned for offline reinforcement learning (offline RL), off-policy evaluation\n(OPE), and selection (OPS). Unlike most existing libraries that focus solely on\neither policy learning or evaluation, SCOPE-RL seamlessly integrates these two\nkey aspects, facilitating flexible and complete implementations of both offline\nRL and OPE processes. SCOPE-RL put particular emphasis on its OPE modules,\noffering a range of OPE estimators and robust evaluation-of-OPE protocols. This\napproach enables more in-depth and reliable OPE compared to other packages. For\ninstance, SCOPE-RL enhances OPE by estimating the entire reward distribution\nunder a policy rather than its mere point-wise expected value. Additionally,\nSCOPE-RL provides a more thorough evaluation-of-OPE by presenting the\nrisk-return tradeoff in OPE results, extending beyond mere accuracy evaluations\nin existing OPE literature. SCOPE-RL is designed with user accessibility in\nmind. Its user-friendly APIs, comprehensive documentation, and a variety of\neasy-to-follow examples assist researchers and practitioners in efficiently\nimplementing and experimenting with various offline RL methods and OPE\nestimators, tailored to their specific problem contexts. The documentation of\nSCOPE-RL is available at https://scope-rl.readthedocs.io/en/latest/.",
            "author": [
                "Haruka Kiyohara",
                "Ren Kishimoto",
                "Kosuke Kawakami",
                "Ken Kobayashi",
                "Kazuhide Nakata",
                "Yuta Saito"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18206v2",
                "http://arxiv.org/pdf/2311.18206v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18203v1",
            "title": "A Novel Interface Database of Graphene Nanoribbon from Density\n  Functional Theory",
            "updated": "2023-11-30T02:43:10Z",
            "published": "2023-11-30T02:43:10Z",
            "summary": "Interfaces play a crucial role in determining the overall performance and\nfunctionality of electronic devices and systems. Driven by the data science,\nmachine learning (ML) reveals excellent guidance for material selection and\ndevice design, in which an advanced database is crucial for training models\nwith state-of-the-art (SOTA) precision. However, a systematic database of\ninterfaces is still in its infancy due to the difficulties in collecting raw\ndata in experiment and the expensive first-principles computational cost in\ndensity functional theory (DFT). In this paper, we construct ample interface\nstructures of graphene nanoribbons (GNR), whose interfacial morphology can be\nprecisely fabricated based on specific molecular precursors. The GNR interfaces\nserve as promising candidates since their bandgaps can be modulated. Their\nphysical properties including energy bands and density of states (DOS) maps are\nobtained under reasonable calculation parameters. This database can provide\ntheoretical guidance for the design of electronic devices and accelerate the ML\nstudy of various physical quantities.",
            "author": [
                "Ao Wu",
                "Jiangxue Huang",
                "Qijun Huang",
                "Jin He",
                "Hao Wang",
                "Sheng Chang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18203v1",
                "http://arxiv.org/pdf/2311.18203v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cond-mat.mes-hall"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02184v1",
            "title": "Channel-Feedback-Free Transmission for Downlink FD-RAN: A Radio Map\n  based Complex-valued Precoding Network Approach",
            "updated": "2023-11-30T02:41:04Z",
            "published": "2023-11-30T02:41:04Z",
            "summary": "As the demand for high-quality services proliferates, an innovative network\narchitecture, the fully-decoupled RAN (FD-RAN), has emerged for more flexible\nspectrum resource utilization and lower network costs. However, with the\ndecoupling of uplink base stations and downlink base stations in FD-RAN, the\ntraditional transmission mechanism, which relies on real-time channel feedback,\nis not suitable as the receiver is not able to feedback accurate and timely\nchannel state information to the transmitter. This paper proposes a novel\ntransmission scheme without relying on physical layer channel feedback.\nSpecifically, we design a radio map based complex-valued precoding\nnetwork~(RMCPNet) model, which outputs the base station precoding based on user\nlocation. RMCPNet comprises multiple subnets, with each subnet responsible for\nextracting unique modal features from diverse input modalities. Furthermore,\nthe multi-modal embeddings derived from these distinct subnets are integrated\nwithin the information fusion layer, culminating in a unified representation.\nWe also develop a specific RMCPNet training algorithm that employs the negative\nspectral efficiency as the loss function. We evaluate the performance of the\nproposed scheme on the public DeepMIMO dataset and show that RMCPNet can\nachieve 16\\% and 76\\% performance improvements over the conventional\nreal-valued neural network and statistical codebook approach, respectively.",
            "author": [
                "Jiwei Zhao",
                "Jiacheng Chen",
                "Zeyu Sun",
                "Yuhang Shi",
                "Haibo Zhou",
                "Xuemin",
                "Shen"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02184v1",
                "http://arxiv.org/pdf/2312.02184v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.LG",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18200v1",
            "title": "INarIG: Iterative Non-autoregressive Instruct Generation Model For\n  Word-Level Auto Completion",
            "updated": "2023-11-30T02:39:38Z",
            "published": "2023-11-30T02:39:38Z",
            "summary": "Computer-aided translation (CAT) aims to enhance human translation efficiency\nand is still important in scenarios where machine translation cannot meet\nquality requirements. One fundamental task within this field is Word-Level Auto\nCompletion (WLAC). WLAC predicts a target word given a source sentence,\ntranslation context, and a human typed character sequence. Previous works\neither employ word classification models to exploit contextual information from\nboth sides of the target word or directly disregarded the dependencies from the\nright-side context. Furthermore, the key information, i.e. human typed\nsequences, is only used as prefix constraints in the decoding module. In this\npaper, we propose the INarIG (Iterative Non-autoregressive Instruct Generation)\nmodel, which constructs the human typed sequence into Instruction Unit and\nemploys iterative decoding with subwords to fully utilize input information\ngiven in the task. Our model is more competent in dealing with low-frequency\nwords (core scenario of this task), and achieves state-of-the-art results on\nthe WMT22 and benchmark datasets, with a maximum increase of over 10%\nprediction accuracy.",
            "author": [
                "Hengchao Shang",
                "Zongyao Li",
                "Daimeng Wei",
                "Jiaxin Guo",
                "Minghan Wang",
                "Xiaoyu Chen",
                "Lizhi Lei",
                "Hao Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18200v1",
                "http://arxiv.org/pdf/2311.18200v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00080v1",
            "title": "PDB-Struct: A Comprehensive Benchmark for Structure-based Protein Design",
            "updated": "2023-11-30T02:37:55Z",
            "published": "2023-11-30T02:37:55Z",
            "summary": "Structure-based protein design has attracted increasing interest, with\nnumerous methods being introduced in recent years. However, a universally\naccepted method for evaluation has not been established, since the wet-lab\nvalidation can be overly time-consuming for the development of new algorithms,\nand the $\\textit{in silico}$ validation with recovery and perplexity metrics is\nefficient but may not precisely reflect true foldability. To address this gap,\nwe introduce two novel metrics: refoldability-based metric, which leverages\nhigh-accuracy protein structure prediction models as a proxy for wet lab\nexperiments, and stability-based metric, which assesses whether models can\nassign high likelihoods to experimentally stable proteins. We curate datasets\nfrom high-quality CATH protein data, high-throughput $\\textit{de novo}$\ndesigned proteins, and mega-scale experimental mutagenesis experiments, and in\ndoing so, present the $\\textbf{PDB-Struct}$ benchmark that evaluates both\nrecent and previously uncompared protein design methods. Experimental results\nindicate that ByProt, ProteinMPNN, and ESM-IF perform exceptionally well on our\nbenchmark, while ESM-Design and AF-Design fall short on the refoldability\nmetric. We also show that while some methods exhibit high sequence recovery,\nthey do not perform as well on our new benchmark. Our proposed benchmark paves\nthe way for a fair and comprehensive evaluation of protein design methods in\nthe future. Code is available at https://github.com/WANG-CR/PDB-Struct.",
            "author": [
                "Chuanrui Wang",
                "Bozitao Zhong",
                "Zuobai Zhang",
                "Narendra Chaudhary",
                "Sanchit Misra",
                "Jian Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00080v1",
                "http://arxiv.org/pdf/2312.00080v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00079v1",
            "title": "HiFi Tuner: High-Fidelity Subject-Driven Fine-Tuning for Diffusion\n  Models",
            "updated": "2023-11-30T02:33:29Z",
            "published": "2023-11-30T02:33:29Z",
            "summary": "This paper explores advancements in high-fidelity personalized image\ngeneration through the utilization of pre-trained text-to-image diffusion\nmodels. While previous approaches have made significant strides in generating\nversatile scenes based on text descriptions and a few input images, challenges\npersist in maintaining the subject fidelity within the generated images. In\nthis work, we introduce an innovative algorithm named HiFi Tuner to enhance the\nappearance preservation of objects during personalized image generation. Our\nproposed method employs a parameter-efficient fine-tuning framework, comprising\na denoising process and a pivotal inversion process. Key enhancements include\nthe utilization of mask guidance, a novel parameter regularization technique,\nand the incorporation of step-wise subject representations to elevate the\nsample fidelity. Additionally, we propose a reference-guided generation\napproach that leverages the pivotal inversion of a reference image to mitigate\nunwanted subject variations and artifacts. We further extend our method to a\nnovel image editing task: substituting the subject in an image through textual\nmanipulations. Experimental evaluations conducted on the DreamBooth dataset\nusing the Stable Diffusion model showcase promising results. Fine-tuning solely\non textual embeddings improves CLIP-T score by 3.6 points and improves DINO\nscore by 9.6 points over Textual Inversion. When fine-tuning all parameters,\nHiFi Tuner improves CLIP-T score by 1.2 points and improves DINO score by 1.2\npoints over DreamBooth, establishing a new state of the art.",
            "author": [
                "Zhonghao Wang",
                "Wei Wei",
                "Yang Zhao",
                "Zhisheng Xiao",
                "Mark Hasegawa-Johnson",
                "Humphrey Shi",
                "Tingbo Hou"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00079v1",
                "http://arxiv.org/pdf/2312.00079v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18198v1",
            "title": "S-T CRF: Spatial-Temporal Conditional Random Field for Human Trajectory\n  Prediction",
            "updated": "2023-11-30T02:33:01Z",
            "published": "2023-11-30T02:33:01Z",
            "summary": "Trajectory prediction is of significant importance in computer vision.\nAccurate pedestrian trajectory prediction benefits autonomous vehicles and\nrobots in planning their motion. Pedestrians' trajectories are greatly\ninfluenced by their intentions. Prior studies having introduced various deep\nlearning methods only pay attention to the spatial and temporal information of\ntrajectory, overlooking the explicit intention information. In this study, we\nintroduce a novel model, termed the \\textbf{S-T CRF}:\n\\textbf{S}patial-\\textbf{T}emporal \\textbf{C}onditional \\textbf{R}andom\n\\textbf{F}ield, which judiciously incorporates intention information besides\nspatial and temporal information of trajectory. This model uses a Conditional\nRandom Field (CRF) to generate a representation of future intentions, greatly\nimproving the prediction of subsequent trajectories when combined with\nspatial-temporal representation. Furthermore, the study innovatively devises a\nspace CRF loss and a time CRF loss, meticulously designed to enhance\ninteraction constraints and temporal dynamics, respectively. Extensive\nexperimental evaluations on dataset ETH/UCY and SDD demonstrate that the\nproposed method surpasses existing baseline approaches.",
            "author": [
                "Pengqian Han",
                "Jiamou Liu",
                "Jialing He",
                "Zeyu Zhang",
                "Song Yang",
                "Yanni Tang",
                "Partha Roop"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18198v1",
                "http://arxiv.org/pdf/2311.18198v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18194v1",
            "title": "Positional Information Matters for Invariant In-Context Learning: A Case\n  Study of Simple Function Classes",
            "updated": "2023-11-30T02:26:55Z",
            "published": "2023-11-30T02:26:55Z",
            "summary": "In-context learning (ICL) refers to the ability of a model to condition on a\nfew in-context demonstrations (input-output examples of the underlying task) to\ngenerate the answer for a new query input, without updating parameters. Despite\nthe impressive ICL ability of LLMs, it has also been found that ICL in LLMs is\nsensitive to input demonstrations and limited to short context lengths. To\nunderstand the limitations and principles for successful ICL, we conduct an\ninvestigation with ICL linear regression of transformers. We characterize\nseveral Out-of-Distribution (OOD) cases for ICL inspired by realistic LLM ICL\nfailures and compare transformers with DeepSet, a simple yet powerful\narchitecture for ICL. Surprisingly, DeepSet outperforms transformers across a\nvariety of distribution shifts, implying that preserving permutation invariance\nsymmetry to input demonstrations is crucial for OOD ICL. The phenomenon\nspecifies a fundamental requirement by ICL, which we termed as ICL invariance.\nNevertheless, the positional encodings in LLMs will break ICL invariance. To\nthis end, we further evaluate transformers with identical positional encodings\nand find preserving ICL invariance in transformers achieves state-of-the-art\nperformance across various ICL distribution shifts",
            "author": [
                "Yongqiang Chen",
                "Binghui Xie",
                "Kaiwen Zhou",
                "Bo Han",
                "Yatao Bian",
                "James Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18194v1",
                "http://arxiv.org/pdf/2311.18194v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18192v1",
            "title": "Powers of the Universe: Empowering primary school students with the\n  powers of ten notation",
            "updated": "2023-11-30T02:24:12Z",
            "published": "2023-11-30T02:24:12Z",
            "summary": "Numbers, both very large and very small, are crucially important for\nunderstanding the modern world. This paper assesses trials of a mathematics and\nphysics module called Powers of the Universe in which arithmetic with extreme\nnumbers (large and small) is developed through early learning of the powers of\nten notation. We trialled a 6-hour progression of lessons based on activities\nand group learning with students aged 7-13 years. We measured students' ability\nto estimate, compare, and calculate extreme numbers using pre and post-tests to\nevaluate the program. Results demonstrated students' strong enthusiasm and\npositive learning outcomes in areas normally assumed to be beyond the\ncapability of students in this age group. We discuss the age dependence of some\nresults and suggest an optimum strategy for enhancing primary school\nmathematics. The module has been delivered, as part of a broader five-module\nprogram called Maths for Einstein's Universe, that aims to reduce maths anxiety\nthrough programs with direct relevance to the modern world and reduced emphasis\non exactness.",
            "author": [
                "Anastasia Lonshakova",
                "David G. Blair",
                "David F. Treagust",
                "Marjan Zadnik"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18192v1",
                "http://arxiv.org/pdf/2311.18192v1"
            ],
            "primary_category": "physics.ed-ph",
            "category": [
                "physics.ed-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18190v1",
            "title": "Toward the Tradeoffs between Privacy, Fairness and Utility in Federated\n  Learning",
            "updated": "2023-11-30T02:19:35Z",
            "published": "2023-11-30T02:19:35Z",
            "summary": "Federated Learning (FL) is a novel privacy-protection distributed machine\nlearning paradigm that guarantees user privacy and prevents the risk of data\nleakage due to the advantage of the client's local training. Researchers have\nstruggled to design fair FL systems that ensure fairness of results. However,\nthe interplay between fairness and privacy has been less studied. Increasing\nthe fairness of FL systems can have an impact on user privacy, while an\nincrease in user privacy can affect fairness. In this work, on the client side,\nwe use fairness metrics, such as Demographic Parity (DemP), Equalized Odds\n(EOs), and Disparate Impact (DI), to construct the local fair model. To protect\nthe privacy of the client model, we propose a privacy-protection fairness FL\nmethod. The results show that the accuracy of the fair model with privacy\nincreases because privacy breaks the constraints of the fairness metrics. In\nour experiments, we conclude the relationship between privacy, fairness and\nutility, and there is a tradeoff between these.",
            "author": [
                "Kangkang Sun",
                "Xiaojin Zhang",
                "Xi Lin",
                "Gaolei Li",
                "Jing Wang",
                "Jianhua Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18190v1",
                "http://arxiv.org/pdf/2311.18190v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18188v1",
            "title": "Leveraging cache to enable SLU on tiny devices",
            "updated": "2023-11-30T02:15:07Z",
            "published": "2023-11-30T02:15:07Z",
            "summary": "This paper addresses spoken language understanding (SLU) on\nmicrocontroller-like embedded devices, integrating on-device execution with\ncloud offloading in a novel fashion. We exploit temporal locality in a device's\nspeech inputs and accordingly reuse recent SLU inferences. Our idea is simple:\nlet the device match new inputs against cached results, and only offload\nunmatched inputs to the cloud for full inference. Realization of this idea,\nhowever, is non-trivial: the device needs to compare acoustic features in a\nrobust, low-cost way. To this end, we present XYZ, a speech cache for tiny\ndevices. It matches speech inputs at two levels of representations: first by\nclustered sequences of raw sound units, then as sequences of phonemes. Working\nin tandem, the two representations offer complementary cost/accuracy tradeoffs.\nTo further boost accuracy, our cache is learning: with the mismatched and then\noffloaded inputs, it continuously finetunes the device's feature extractors\n(with the assistance of the cloud). We implement XYZ on an off-the-shelf STM32\nmicrocontroller. The resultant implementation has a small memory footprint of\n2MB. Evaluated on challenging speech benchmarks, our system resolves 45%--90%\nof inputs on device, reducing the average latency by up to 80% compared to\noffloading to popular cloud speech services. Our benefit is pronounced even in\nadversarial settings -- noisy environments, cold cache, or one device shared by\na number of users.",
            "author": [
                "Afsara Benazir",
                "Zhiming Xu",
                "Felix Xiaozhu Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18188v1",
                "http://arxiv.org/pdf/2311.18188v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18177v1",
            "title": "An Effective Universal Polynomial Basis for Spectral Graph Neural\n  Networks",
            "updated": "2023-11-30T01:48:42Z",
            "published": "2023-11-30T01:48:42Z",
            "summary": "Spectral Graph Neural Networks (GNNs), also referred to as graph filters have\ngained increasing prevalence for heterophily graphs. Optimal graph filters rely\non Laplacian eigendecomposition for Fourier transform. In an attempt to avert\nthe prohibitive computations, numerous polynomial filters by leveraging\ndistinct polynomials have been proposed to approximate the desired graph\nfilters. However, polynomials in the majority of polynomial filters are\npredefined and remain fixed across all graphs, failing to accommodate the\ndiverse heterophily degrees across different graphs. To tackle this issue, we\nfirst investigate the correlation between polynomial bases of desired graph\nfilters and the degrees of graph heterophily via a thorough theoretical\nanalysis. Afterward, we develop an adaptive heterophily basis by incorporating\ngraph heterophily degrees. Subsequently, we integrate this heterophily basis\nwith the homophily basis, creating a universal polynomial basis UniBasis. In\nconsequence, we devise a general polynomial filter UniFilter. Comprehensive\nexperiments on both real-world and synthetic datasets with varying heterophily\ndegrees significantly support the superiority of UniFilter, demonstrating the\neffectiveness and generality of UniBasis, as well as its promising capability\nas a new method for graph analysis.",
            "author": [
                "Keke Huang",
                "Pietro Li\u00f2"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18177v1",
                "http://arxiv.org/pdf/2311.18177v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00078v1",
            "title": "Enhancing Cross-domain Click-Through Rate Prediction via Explicit\n  Feature Augmentation",
            "updated": "2023-11-30T01:42:11Z",
            "published": "2023-11-30T01:42:11Z",
            "summary": "Cross-domain CTR (CDCTR) prediction is an important research topic that\nstudies how to leverage meaningful data from a related domain to help CTR\nprediction in target domain. Most existing CDCTR works design implicit ways to\ntransfer knowledge across domains such as parameter-sharing that regularizes\nthe model training in target domain. More effectively, recent researchers\npropose explicit techniques to extract user interest knowledge and transfer\nthis knowledge to target domain. However, the proposed method mainly faces two\nissues: 1) it usually requires a super domain, i.e. an extremely large source\ndomain, to cover most users or items of target domain, and 2) the extracted\nuser interest knowledge is static no matter what the context is in target\ndomain. These limitations motivate us to develop a more flexible and efficient\ntechnique to explicitly transfer knowledge. In this work, we propose a\ncross-domain augmentation network (CDAnet) being able to perform explicit\nknowledge transfer between two domains. Specifically, CDAnet contains a\ndesigned translation network and an augmentation network which are trained\nsequentially. The translation network computes latent features from two domains\nand learns meaningful cross-domain knowledge of each input in target domain by\nusing a designed cross-supervised feature translator. Later the augmentation\nnetwork employs the explicit cross-domain knowledge as augmented information to\nboost the target domain CTR prediction. Through extensive experiments on two\npublic benchmarks and one industrial production dataset, we show CDAnet can\nlearn meaningful translated features and largely improve the performance of CTR\nprediction. CDAnet has been conducted online A/B test in image2product\nretrieval at Taobao app, bringing an absolute 0.11 point CTR improvement, a\nrelative 0.64% deal growth and a relative 1.26% GMV increase.",
            "author": [
                "Xu Chen",
                "Zida Cheng",
                "Jiangchao Yao",
                "Chen Ju",
                "Weilin Huang",
                "Jinsong Lan",
                "Xiaoyi Zeng",
                "Shuai Xiao"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00078v1",
                "http://arxiv.org/pdf/2312.00078v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18174v1",
            "title": "Packrat: Automatic Reconfiguration for Latency Minimization in CPU-based\n  DNN Serving",
            "updated": "2023-11-30T01:36:46Z",
            "published": "2023-11-30T01:36:46Z",
            "summary": "In this paper, we investigate how to push the performance limits of serving\nDeep Neural Network (DNN) models on CPU-based servers. Specifically, we observe\nthat while intra-operator parallelism across multiple threads is an effective\nway to reduce inference latency, it provides diminishing returns. Our primary\ninsight is that instead of running a single instance of a model with all\navailable threads on a server, running multiple instances each with smaller\nbatch sizes and fewer threads for intra-op parallelism can provide lower\ninference latency. However, the right configuration is hard to determine\nmanually since it is workload- (DNN model and batch size used by the serving\nsystem) and deployment-dependent (number of CPU cores on server). We present\nPackrat, a new serving system for online inference that given a model and batch\nsize ($B$) algorithmically picks the optimal number of instances ($i$), the\nnumber of threads each should be allocated ($t$), and the batch sizes each\nshould operate on ($b$) that minimizes latency. Packrat is built as an\nextension to TorchServe and supports online reconfigurations to avoid serving\ndowntime. Averaged across a range of batch sizes, Packrat improves inference\nlatency by 1.43$\\times$ to 1.83$\\times$ on a range of commonly used DNNs.",
            "author": [
                "Ankit Bhardwaj",
                "Amar Phanishayee",
                "Deepak Narayanan",
                "Mihail Tarta",
                "Ryan Stutsman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18174v1",
                "http://arxiv.org/pdf/2311.18174v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18168v1",
            "title": "Probabilistic Speech-Driven 3D Facial Motion Synthesis: New Benchmarks,\n  Methods, and Applications",
            "updated": "2023-11-30T01:14:43Z",
            "published": "2023-11-30T01:14:43Z",
            "summary": "We consider the task of animating 3D facial geometry from speech signal.\nExisting works are primarily deterministic, focusing on learning a one-to-one\nmapping from speech signal to 3D face meshes on small datasets with limited\nspeakers. While these models can achieve high-quality lip articulation for\nspeakers in the training set, they are unable to capture the full and diverse\ndistribution of 3D facial motions that accompany speech in the real world.\nImportantly, the relationship between speech and facial motion is one-to-many,\ncontaining both inter-speaker and intra-speaker variations and necessitating a\nprobabilistic approach. In this paper, we identify and address key challenges\nthat have so far limited the development of probabilistic models: lack of\ndatasets and metrics that are suitable for training and evaluating them, as\nwell as the difficulty of designing a model that generates diverse results\nwhile remaining faithful to a strong conditioning signal as speech. We first\npropose large-scale benchmark datasets and metrics suitable for probabilistic\nmodeling. Then, we demonstrate a probabilistic model that achieves both\ndiversity and fidelity to speech, outperforming other methods across the\nproposed benchmarks. Finally, we showcase useful applications of probabilistic\nmodels trained on these large-scale datasets: we can generate diverse\nspeech-driven 3D facial motion that matches unseen speaker styles extracted\nfrom reference clips; and our synthetic meshes can be used to improve the\nperformance of downstream audio-visual models.",
            "author": [
                "Karren D. Yang",
                "Anurag Ranjan",
                "Jen-Hao Rick Chang",
                "Raviteja Vemulapalli",
                "Oncel Tuzel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18168v1",
                "http://arxiv.org/pdf/2311.18168v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18162v1",
            "title": "An Exponential Reduction in Training Data Sizes for Machine Learning\n  Derived Entanglement Witnesses",
            "updated": "2023-11-30T00:45:04Z",
            "published": "2023-11-30T00:45:04Z",
            "summary": "In this work, we propose an improved method of training linear support vector\nmachines (SVMs) to generate entanglement witnesses for systems of 3, 4, and 5\nqubits. SVMs generate hyperplanes represented by a weighted sum of expectation\nvalues of local observables, whose coefficients are optimized to provide a\npositive sum for all separable states and a negative sum for as many entangled\nstates as possible near a specific target state. We use the eigenstates of\ngeneralized Pauli matrices as training data, and correct the witnesses with a\ndifferential program. This method requires only $ O(6^n)$ training states,\nwhereas an existing method needs$ O(2^{4^n})$. We use this method to construct\nwitnesses of 4 and 5 qubit GHZ states with coefficients agreeing with\nstabilizer formalism witnesses to within 6.5 percent and 1 percent,\nrespectively. We also use the same training states to generate 4 and 5 qubit W\nstate witnesses. Finally, we propose methods for physical and computational\nverification of these witnesses.",
            "author": [
                "Aiden R. Rosebush",
                "Alexander C. B. Greenwood",
                "Brian T. Kirby",
                "Li Qian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18162v1",
                "http://arxiv.org/pdf/2311.18162v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00076v1",
            "title": "Towards A Foundation Model For Trajectory Intelligence",
            "updated": "2023-11-30T00:34:09Z",
            "published": "2023-11-30T00:34:09Z",
            "summary": "We present the results of training a large trajectory model using real-world\nuser check-in data. Our approach follows a pre-train and fine-tune paradigm,\nwhere a base model is pre-trained via masked trajectory modeling and then\nadapted through fine-tuning for various downstream tasks. To address challenges\nposed by noisy data and large spatial vocabularies, we propose a novel spatial\ntokenization block. Our empirical analysis utilizes a comprehensive dataset of\nover 2 billion check-ins generated by more than 6 million users. Through\nfine-tuning on 3 downstream tasks we demonstrate that our base model has\neffectively learned valuable underlying patterns in raw data, enabling its\napplication in meaningful trajectory intelligence tasks. Despite some\nlimitations, we believe this work represents an important step forward in the\nrealization of a foundation model for trajectory intelligence.",
            "author": [
                "Alameen Najjar"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00076v1",
                "http://arxiv.org/pdf/2312.00076v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18159v1",
            "title": "Compact3D: Compressing Gaussian Splat Radiance Field Models with Vector\n  Quantization",
            "updated": "2023-11-30T00:29:13Z",
            "published": "2023-11-30T00:29:13Z",
            "summary": "3D Gaussian Splatting is a new method for modeling and rendering 3D radiance\nfields that achieves much faster learning and rendering time compared to SOTA\nNeRF methods. However, it comes with a drawback in the much larger storage\ndemand compared to NeRF methods since it needs to store the parameters for\nseveral 3D Gaussians. We notice that many Gaussians may share similar\nparameters, so we introduce a simple vector quantization method based on\n\\kmeans algorithm to quantize the Gaussian parameters. Then, we store the small\ncodebook along with the index of the code for each Gaussian. Moreover, we\ncompress the indices further by sorting them and using a method similar to\nrun-length encoding. We do extensive experiments on standard benchmarks as well\nas a new benchmark which is an order of magnitude larger than the standard\nbenchmarks. We show that our simple yet effective method can reduce the storage\ncost for the original 3D Gaussian Splatting method by a factor of almost\n$20\\times$ with a very small drop in the quality of rendered images.",
            "author": [
                "KL Navaneet",
                "Kossar Pourahmadi Meibodi",
                "Soroush Abbasi Koohpayegani",
                "Hamed Pirsiavash"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18159v1",
                "http://arxiv.org/pdf/2311.18159v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18158v1",
            "title": "HiPA: Enabling One-Step Text-to-Image Diffusion Models via\n  High-Frequency-Promoting Adaptation",
            "updated": "2023-11-30T00:14:07Z",
            "published": "2023-11-30T00:14:07Z",
            "summary": "Diffusion models have revolutionized text-to-image generation, but their\nreal-world applications are hampered by the extensive time needed for hundreds\nof diffusion steps. Although progressive distillation has been proposed to\nspeed up diffusion sampling to 2-8 steps, it still falls short in one-step\ngeneration, and necessitates training multiple student models, which is highly\nparameter-extensive and time-consuming. To overcome these limitations, we\nintroduce High-frequency-Promoting Adaptation (HiPA), a parameter-efficient\napproach to enable one-step text-to-image diffusion. Grounded in the insight\nthat high-frequency information is essential but highly lacking in one-step\ndiffusion, HiPA focuses on training one-step, low-rank adaptors to specifically\nenhance the under-represented high-frequency abilities of advanced diffusion\nmodels. The learned adaptors empower these diffusion models to generate\nhigh-quality images in just a single step. Compared with progressive\ndistillation, HiPA achieves much better performance in one-step text-to-image\ngeneration (37.3 $\\rightarrow$ 23.8 in FID-5k on MS-COCO 2017) and 28.6x\ntraining speed-up (108.8 $\\rightarrow$ 3.8 A100 GPU days), requiring only 0.04%\ntraining parameters (7,740 million $\\rightarrow$ 3.3 million). We also\ndemonstrate HiPA's effectiveness in text-guided image editing, inpainting and\nsuper-resolution tasks, where our adapted models consistently deliver\nhigh-quality outputs in just one diffusion step. The source code will be\nreleased.",
            "author": [
                "Yifan Zhang",
                "Bryan Hooi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18158v1",
                "http://arxiv.org/pdf/2311.18158v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18154v1",
            "title": "Data-Driven Shape Sensing in Continuum Manipulators via Sliding\n  Resistive Flex Sensors",
            "updated": "2023-11-29T23:55:06Z",
            "published": "2023-11-29T23:55:06Z",
            "summary": "We introduce a novel shape-sensing method using Resistive Flex Sensors (RFS)\nembedded in cable-driven Continuum Dexterous Manipulators (CDMs). The RFS is\npredominantly sensitive to deformation rather than direct forces, making it a\ndistinctive tool for shape sensing. The RFS unit we designed is a considerably\nless expensive and robust alternative, offering comparable accuracy and\nreal-time performance to existing shape sensing methods used for the CDMs\nproposed for minimally-invasive surgery. Our design allows the RFS to move\nalong and inside the CDM conforming to its curvature, offering the ability to\ncapture resistance metrics from various bending positions without the need for\nelaborate sensor setups. The RFS unit is calibrated using an overhead camera\nand a ResNet machine learning framework. Experiments using a 3D printed\nprototype of the CDM achieved an average shape estimation error of 0.968 mm\nwith a standard error of 0.275 mm. The response time of the model was\napproximately 1.16 ms, making real-time shape sensing feasible. While this\npreliminary study successfully showed the feasibility of our approach for\nC-shape CDM deformations with non-constant curvatures, we are currently\nextending the results to show the feasibility for adapting to more complex CDM\nconfigurations such as S-shape created in obstructed environments or in\npresence of the external forces.",
            "author": [
                "Chenhan Zhang",
                "Shaopeng Jiang",
                "Heyun Wang",
                "Joshua Liu",
                "Amit Jain",
                "Mehran Armand"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18154v1",
                "http://arxiv.org/pdf/2311.18154v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18149v1",
            "title": "STF: Spatial Temporal Fusion for Trajectory Prediction",
            "updated": "2023-11-29T23:31:40Z",
            "published": "2023-11-29T23:31:40Z",
            "summary": "Trajectory prediction is a challenging task that aims to predict the future\ntrajectory of vehicles or pedestrians over a short time horizon based on their\nhistorical positions. The main reason is that the trajectory is a kind of\ncomplex data, including spatial and temporal information, which is crucial for\naccurate prediction. Intuitively, the more information the model can capture,\nthe more precise the future trajectory can be predicted. However, previous\nworks based on deep learning methods processed spatial and temporal information\nseparately, leading to inadequate spatial information capture, which means they\nfailed to capture the complete spatial information. Therefore, it is of\nsignificance to capture information more fully and effectively on vehicle\ninteractions. In this study, we introduced an integrated 3D graph that\nincorporates both spatial and temporal edges. Based on this, we proposed the\nintegrated 3D graph, which considers the cross-time interaction information. In\nspecific, we design a Spatial-Temporal Fusion (STF) model including Multi-layer\nperceptions (MLP) and Graph Attention (GAT) to capture the spatial and temporal\ninformation historical trajectories simultaneously on the 3D graph. Our\nexperiment on the ApolloScape Trajectory Datasets shows that the proposed STF\noutperforms several baseline methods, especially on the long-time-horizon\ntrajectory prediction.",
            "author": [
                "Pengqian Han",
                "Partha Roop",
                "Jiamou Liu",
                "Tianzhe Bao",
                "Yifei Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18149v1",
                "http://arxiv.org/pdf/2311.18149v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18144v1",
            "title": "Dynamical phase transition in quantum neural networks with large depth",
            "updated": "2023-11-29T23:14:33Z",
            "published": "2023-11-29T23:14:33Z",
            "summary": "Understanding the training dynamics of quantum neural networks is a\nfundamental task in quantum information science with wide impact in physics,\nchemistry and machine learning. In this work, we show that the late-time\ntraining dynamics of quantum neural networks can be described by the\ngeneralized Lotka-Volterra equations, which lead to a dynamical phase\ntransition. When the targeted value of cost function crosses the minimum\nachievable value from above to below, the dynamics evolve from a frozen-kernel\nphase to a frozen-error phase, showing a duality between the quantum neural\ntangent kernel and the total error. In both phases, the convergence towards the\nfixed point is exponential, while at the critical point becomes polynomial. Via\nmapping the Hessian of the training dynamics to a Hamiltonian in the imaginary\ntime, we reveal the nature of the phase transition to be second-order with the\nexponent $\\nu=1$, where scale invariance and closing gap are observed at\ncritical point. We also provide a non-perturbative analytical theory to explain\nthe phase transition via a restricted Haar ensemble at late time, when the\noutput state approaches the steady state. The theory findings are verified\nexperimentally on IBM quantum devices.",
            "author": [
                "Bingzhi Zhang",
                "Junyu Liu",
                "Xiao-Chuan Wu",
                "Liang Jiang",
                "Quntao Zhuang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18144v1",
                "http://arxiv.org/pdf/2311.18144v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.stat-mech",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18138v1",
            "title": "Algorithmic Persuasion Through Simulation: Information Design in the Age\n  of Generative AI",
            "updated": "2023-11-29T23:01:33Z",
            "published": "2023-11-29T23:01:33Z",
            "summary": "How can an informed sender persuade a receiver, having only limited\ninformation about the receiver's beliefs? Motivated by research showing\ngenerative AI can simulate economic agents, we initiate the study of\ninformation design with an oracle. We assume the sender can learn more about\nthe receiver by querying this oracle, e.g., by simulating the receiver's\nbehavior. Aside from AI motivations such as general-purpose Large Language\nModels (LLMs) and problem-specific machine learning models, alternate\nmotivations include customer surveys and querying a small pool of live users.\n  Specifically, we study Bayesian Persuasion where the sender has a\nsecond-order prior over the receiver's beliefs. After a fixed number of queries\nto an oracle to refine this prior, the sender commits to an information\nstructure. Upon receiving the message, the receiver takes a payoff-relevant\naction maximizing her expected utility given her posterior beliefs. We design\npolynomial-time querying algorithms that optimize the sender's expected utility\nin this Bayesian Persuasion game. As a technical contribution, we show that\nqueries form partitions of the space of receiver beliefs that can be used to\nquantify the sender's knowledge.",
            "author": [
                "Keegan Harris",
                "Nicole Immorlica",
                "Brendan Lucier",
                "Aleksandrs Slivkins"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18138v1",
                "http://arxiv.org/pdf/2311.18138v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.AI",
                "econ.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18134v1",
            "title": "A computational model of behavioral adaptation to solve the credit\n  assignment problem",
            "updated": "2023-11-29T22:53:28Z",
            "published": "2023-11-29T22:53:28Z",
            "summary": "The adaptive fitness of an organism in its ecological niche is highly reliant\nupon its ability to associate an environmental or internal stimulus with a\nbehavior response through reinforcement. This simple but powerful observation\nhas been successfully applied in a number of contexts within computational\nneuroscience and reinforcement learning to model both human and animal\nbehaviors. However, a critical challenge faced by these models is the credit\nassignment problem which asks how past behavior comes to be associated with a\ndelayed reinforcement signal. In this paper we reformulate the credit\nassignment problem to ask how past stimuli come to be linked to adaptive\nbehavioral responses in the context of a simple neuronal circuit. We propose a\nbiologically plausible variant of a spiking neural network which can model a\nwide variety of behavioral, learning, and evolutionary phenomena. Our model\nsuggests one fundamental mechanism, potentially in use in the brains of both\nsimple and complex organisms, that would allow it to associate a behavior with\nan adaptive response. We present results that showcase the model's versatility\nand biological plausibility in a number of tasks related to classical and\noperant conditioning including behavioral chaining. We then provide further\nsimulations to demonstrate how adaptive behaviors such as reflexes and simple\ncategory detection may have evolved using our model. Our results indicate the\npotential for further modifications and extensions of our model to replicate\nmore sophisticated and biologically plausible behavioral, learning, and\nintelligence phenomena found throughout the animal kingdom.",
            "author": [
                "Roy E. Clymer",
                "Sanjeev V. Namjoshi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18134v1",
                "http://arxiv.org/pdf/2311.18134v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18130v1",
            "title": "The Trifecta: Three simple techniques for training deeper\n  Forward-Forward networks",
            "updated": "2023-11-29T22:44:32Z",
            "published": "2023-11-29T22:44:32Z",
            "summary": "Modern machine learning models are able to outperform humans on a variety of\nnon-trivial tasks. However, as the complexity of the models increases, they\nconsume significant amounts of power and still struggle to generalize\neffectively to unseen data. Local learning, which focuses on updating subsets\nof a model's parameters at a time, has emerged as a promising technique to\naddress these issues. Recently, a novel local learning algorithm, called\nForward-Forward, has received widespread attention due to its innovative\napproach to learning. Unfortunately, its application has been limited to\nsmaller datasets due to scalability issues. To this end, we propose The\nTrifecta, a collection of three simple techniques that synergize exceptionally\nwell and drastically improve the Forward-Forward algorithm on deeper networks.\nOur experiments demonstrate that our models are on par with similarly\nstructured, backpropagation-based models in both training speed and test\naccuracy on simple datasets. This is achieved by the ability to learn\nrepresentations that are informative locally, on a layer-by-layer basis, and\nretain their informativeness when propagated to deeper layers in the\narchitecture. This leads to around 84\\% accuracy on CIFAR-10, a notable\nimprovement (25\\%) over the original FF algorithm. These results highlight the\npotential of Forward-Forward as a genuine competitor to backpropagation and as\na promising research avenue.",
            "author": [
                "Thomas Dooms",
                "Ing Jyh Tsang",
                "Jose Oramas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18130v1",
                "http://arxiv.org/pdf/2311.18130v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "68T07"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18129v1",
            "title": "Mixed-Precision Quantization for Federated Learning on\n  Resource-Constrained Heterogeneous Devices",
            "updated": "2023-11-29T22:43:40Z",
            "published": "2023-11-29T22:43:40Z",
            "summary": "While federated learning (FL) systems often utilize quantization to battle\ncommunication and computational bottlenecks, they have heretofore been limited\nto deploying fixed-precision quantization schemes. Meanwhile, the concept of\nmixed-precision quantization (MPQ), where different layers of a deep learning\nmodel are assigned varying bit-width, remains unexplored in the FL settings. We\npresent a novel FL algorithm, FedMPQ, which introduces mixed-precision\nquantization to resource-heterogeneous FL systems. Specifically, local models,\nquantized so as to satisfy bit-width constraint, are trained by optimizing an\nobjective function that includes a regularization term which promotes reduction\nof precision in some of the layers without significant performance degradation.\nThe server collects local model updates, de-quantizes them into full-precision\nmodels, and then aggregates them into a global model. To initialize the next\nround of local training, the server relies on the information learned in the\nprevious training round to customize bit-width assignments of the models\ndelivered to different clients. In extensive benchmarking experiments on\nseveral model architectures and different datasets in both iid and non-iid\nsettings, FedMPQ outperformed the baseline FL schemes that utilize\nfixed-precision quantization while incurring only a minor computational\noverhead on the participating devices.",
            "author": [
                "Huancheng Chen",
                "Haris Vikalo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18129v1",
                "http://arxiv.org/pdf/2311.18129v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18128v1",
            "title": "Dynamic Scheduling of a Multiclass Queue in the Halfin-Whitt Regime: A\n  Computational Approach for High-Dimensional Problems",
            "updated": "2023-11-29T22:38:33Z",
            "published": "2023-11-29T22:38:33Z",
            "summary": "We consider a multi-class queueing model of a telephone call center, in which\na system manager dynamically allocates available servers to customer calls.\nCalls can terminate through either service completion or customer abandonment,\nand the manager strives to minimize the expected total of holding costs plus\nabandonment costs over a finite horizon. Focusing on the Halfin-Whitt heavy\ntraffic regime, we derive an approximating diffusion control problem, and\nbuilding on earlier work by Han et al. (2018), develop a simulation-based\ncomputational method for solution of such problems, one that relies heavily on\ndeep neural network technology. Using this computational method, we propose a\npolicy for the original (pre-limit) call center scheduling problem. Finally,\nthe performance of this policy is assessed using test problems based on\npublicly available call center data. For the test problems considered so far,\nour policy does as well as the best benchmark we could find. Moreover, our\nmethod is computationally feasible at least up to dimension 100, that is, for\ncall centers with 100 or more distinct customer classes.",
            "author": [
                "Bar\u0131\u015f Ata",
                "Ebru Ka\u015f\u0131karalar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18128v1",
                "http://arxiv.org/pdf/2311.18128v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY",
                "math.AP",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00073v1",
            "title": "Binary perceptrons capacity via fully lifted random duality theory",
            "updated": "2023-11-29T22:22:32Z",
            "published": "2023-11-29T22:22:32Z",
            "summary": "We study the statistical capacity of the classical binary perceptrons with\ngeneral thresholds $\\kappa$. After recognizing the connection between the\ncapacity and the bilinearly indexed (bli) random processes, we utilize a recent\nprogress in studying such processes to characterize the capacity. In\nparticular, we rely on \\emph{fully lifted} random duality theory (fl RDT)\nestablished in \\cite{Stojnicflrdt23} to create a general framework for studying\nthe perceptrons' capacities. Successful underlying numerical evaluations are\nrequired for the framework (and ultimately the entire fl RDT machinery) to\nbecome fully practically operational. We present results obtained in that\ndirections and uncover that the capacity characterizations are achieved on the\nsecond (first non-trivial) level of \\emph{stationarized} full lifting. The\nobtained results \\emph{exactly} match the replica symmetry breaking predictions\nobtained through statistical physics replica methods in \\cite{KraMez89}. Most\nnotably, for the famous zero-threshold scenario, $\\kappa=0$, we uncover the\nwell known $\\alpha\\approx0.8330786$ scaled capacity.",
            "author": [
                "Mihailo Stojnic"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00073v1",
                "http://arxiv.org/pdf/2312.00073v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "cond-mat.dis-nn",
                "cs.IT",
                "math.IT",
                "math.ST",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00818v1",
            "title": "The perpetual motion machine of AI-generated data and the distraction of\n  ChatGPT-as-scientist",
            "updated": "2023-11-29T21:52:34Z",
            "published": "2023-11-29T21:52:34Z",
            "summary": "Since ChatGPT works so well, are we on the cusp of solving science with AI?\nIs not AlphaFold2 suggestive that the potential of LLMs in biology and the\nsciences more broadly is limitless? Can we use AI itself to bridge the lack of\ndata in the sciences in order to then train an AI? Herein we present a\ndiscussion of these topics.",
            "author": [
                "Jennifer Listgarten"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00818v1",
                "http://arxiv.org/pdf/2312.00818v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18103v1",
            "title": "Corner-to-Center Long-range Context Model for Efficient Learned Image\n  Compression",
            "updated": "2023-11-29T21:40:28Z",
            "published": "2023-11-29T21:40:28Z",
            "summary": "In the framework of learned image compression, the context model plays a\npivotal role in capturing the dependencies among latent representations. To\nreduce the decoding time resulting from the serial autoregressive context\nmodel, the parallel context model has been proposed as an alternative that\nnecessitates only two passes during the decoding phase, thus facilitating\nefficient image compression in real-world scenarios. However, performance\ndegradation occurs due to its incomplete casual context. To tackle this issue,\nwe conduct an in-depth analysis of the performance degradation observed in\nexisting parallel context models, focusing on two aspects: the Quantity and\nQuality of information utilized for context prediction and decoding. Based on\nsuch analysis, we propose the \\textbf{Corner-to-Center transformer-based\nContext Model (C$^3$M)} designed to enhance context and latent predictions and\nimprove rate-distortion performance. Specifically, we leverage the\nlogarithmic-based prediction order to predict more context features from corner\nto center progressively. In addition, to enlarge the receptive field in the\nanalysis and synthesis transformation, we use the Long-range Crossing Attention\nModule (LCAM) in the encoder/decoder to capture the long-range semantic\ninformation by assigning the different window shapes in different channels.\nExtensive experimental evaluations show that the proposed method is effective\nand outperforms the state-of-the-art parallel methods. Finally, according to\nthe subjective analysis, we suggest that improving the detailed representation\nin transformer-based image compression is a promising direction to be explored.",
            "author": [
                "Yang Sui",
                "Ding Ding",
                "Xiang Pan",
                "Xiaozhong Xu",
                "Shan Liu",
                "Bo Yuan",
                "Zhenzhong Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18103v1",
                "http://arxiv.org/pdf/2311.18103v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18102v1",
            "title": "PatchBMI-Net: Lightweight Facial Patch-based Ensemble for BMI Prediction",
            "updated": "2023-11-29T21:39:24Z",
            "published": "2023-11-29T21:39:24Z",
            "summary": "Due to an alarming trend related to obesity affecting 93.3 million adults in\nthe United States alone, body mass index (BMI) and body weight have drawn\nsignificant interest in various health monitoring applications. Consequently,\nseveral studies have proposed self-diagnostic facial image-based BMI prediction\nmethods for healthy weight monitoring. These methods have mostly used\nconvolutional neural network (CNN) based regression baselines, such as VGG19,\nResNet50, and Efficient-NetB0, for BMI prediction from facial images. However,\nthe high computational requirement of these heavy-weight CNN models limits\ntheir deployment to resource-constrained mobile devices, thus deterring weight\nmonitoring using smartphones. This paper aims to develop a lightweight facial\npatch-based ensemble (PatchBMI-Net) for BMI prediction to facilitate the\ndeployment and weight monitoring using smartphones. Extensive experiments on\nBMI-annotated facial image datasets suggest that our proposed PatchBMI-Net\nmodel can obtain Mean Absolute Error (MAE) in the range [3.58, 6.51] with a\nsize of about 3.3 million parameters. On cross-comparison with heavyweight\nmodels, such as ResNet-50 and Xception, trained for BMI prediction from facial\nimages, our proposed PatchBMI-Net obtains equivalent MAE along with the model\nsize reduction of about 5.4x and the average inference time reduction of about\n3x when deployed on Apple-14 smartphone. Thus, demonstrating performance\nefficiency as well as low latency for on-device deployment and weight\nmonitoring using smartphone applications.",
            "author": [
                "Parshuram N. Aarotale",
                "Twyla Hill",
                "Ajita Rattani"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18102v1",
                "http://arxiv.org/pdf/2311.18102v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18098v1",
            "title": "Adaptive Early Exiting for Collaborative Inference over Noisy Wireless\n  Channels",
            "updated": "2023-11-29T21:31:59Z",
            "published": "2023-11-29T21:31:59Z",
            "summary": "Collaborative inference systems are one of the emerging solutions for\ndeploying deep neural networks (DNNs) at the wireless network edge. Their main\nidea is to divide a DNN into two parts, where the first is shallow enough to be\nreliably executed at edge devices of limited computational power, while the\nsecond part is executed at an edge server with higher computational\ncapabilities. The main advantage of such systems is that the input of the DNN\ngets compressed as the subsequent layers of the shallow part extract only the\ninformation necessary for the task. As a result, significant communication\nsavings can be achieved compared to transmitting raw input samples. In this\nwork, we study early exiting in the context of collaborative inference, which\nallows obtaining inference results at the edge device for certain samples,\nwithout the need to transmit the partially processed data to the edge server at\nall, leading to further communication savings. The central part of our system\nis the transmission-decision (TD) mechanism, which, given the information from\nthe early exit, and the wireless channel conditions, decides whether to keep\nthe early exit prediction or transmit the data to the edge server for further\nprocessing. In this paper, we evaluate various TD mechanisms and show\nexperimentally, that for an image classification task over the wireless edge,\nproper utilization of early exits can provide both performance gains and\nsignificant communication savings.",
            "author": [
                "Mikolaj Jankowski",
                "Deniz Gunduz",
                "Krystian Mikolajczyk"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18098v1",
                "http://arxiv.org/pdf/2311.18098v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IT",
                "cs.NI",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18094v1",
            "title": "Self-Driving Telescopes: Autonomous Scheduling of Astronomical\n  Observation Campaigns with Offline Reinforcement Learning",
            "updated": "2023-11-29T21:23:30Z",
            "published": "2023-11-29T21:23:30Z",
            "summary": "Modern astronomical experiments are designed to achieve multiple scientific\ngoals, from studies of galaxy evolution to cosmic acceleration. These goals\nrequire data of many different classes of night-sky objects, each of which has\na particular set of observational needs. These observational needs are\ntypically in strong competition with one another. This poses a challenging\nmulti-objective optimization problem that remains unsolved. The effectiveness\nof Reinforcement Learning (RL) as a valuable paradigm for training autonomous\nsystems has been well-demonstrated, and it may provide the basis for\nself-driving telescopes capable of optimizing the scheduling for astronomy\ncampaigns. Simulated datasets containing examples of interactions between a\ntelescope and a discrete set of sky locations on the celestial sphere can be\nused to train an RL model to sequentially gather data from these several\nlocations to maximize a cumulative reward as a measure of the quality of the\ndata gathered. We use simulated data to test and compare multiple\nimplementations of a Deep Q-Network (DQN) for the task of optimizing the\nschedule of observations from the Stone Edge Observatory (SEO). We combine\nmultiple improvements on the DQN and adjustments to the dataset, showing that\nDQNs can achieve an average reward of 87%+-6% of the maximum achievable reward\nin each state on the test set. This is the first comparison of offline RL\nalgorithms for a particular astronomical challenge and the first open-source\nframework for performing such a comparison and assessment task.",
            "author": [
                "Franco Terranova",
                "M. Voetberg",
                "Brian Nord",
                "Amanda Pagul"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18094v1",
                "http://arxiv.org/pdf/2311.18094v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "astro-ph.CO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00069v1",
            "title": "SICKLE: A Multi-Sensor Satellite Imagery Dataset Annotated with Multiple\n  Key Cropping Parameters",
            "updated": "2023-11-29T21:20:58Z",
            "published": "2023-11-29T21:20:58Z",
            "summary": "The availability of well-curated datasets has driven the success of Machine\nLearning (ML) models. Despite greater access to earth observation data in\nagriculture, there is a scarcity of curated and labelled datasets, which limits\nthe potential of its use in training ML models for remote sensing (RS) in\nagriculture. To this end, we introduce a first-of-its-kind dataset called\nSICKLE, which constitutes a time-series of multi-resolution imagery from 3\ndistinct satellites: Landsat-8, Sentinel-1 and Sentinel-2. Our dataset\nconstitutes multi-spectral, thermal and microwave sensors during January 2018 -\nMarch 2021 period. We construct each temporal sequence by considering the\ncropping practices followed by farmers primarily engaged in paddy cultivation\nin the Cauvery Delta region of Tamil Nadu, India; and annotate the\ncorresponding imagery with key cropping parameters at multiple resolutions\n(i.e. 3m, 10m and 30m). Our dataset comprises 2,370 season-wise samples from\n388 unique plots, having an average size of 0.38 acres, for classifying 21 crop\ntypes across 4 districts in the Delta, which amounts to approximately 209,000\nsatellite images. Out of the 2,370 samples, 351 paddy samples from 145 plots\nare annotated with multiple crop parameters; such as the variety of paddy, its\ngrowing season and productivity in terms of per-acre yields. Ours is also one\namong the first studies that consider the growing season activities pertinent\nto crop phenology (spans sowing, transplanting and harvesting dates) as\nparameters of interest. We benchmark SICKLE on three tasks: crop type, crop\nphenology (sowing, transplanting, harvesting), and yield prediction",
            "author": [
                "Depanshu Sani",
                "Sandeep Mahato",
                "Sourabh Saini",
                "Harsh Kumar Agarwal",
                "Charu Chandra Devshali",
                "Saket Anand",
                "Gaurav Arora",
                "Thiagarajan Jayaraman"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00069v1",
                "http://arxiv.org/pdf/2312.00069v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18090v1",
            "title": "Fleming-Viot helps speed up variational quantum algorithms in the\n  presence of barren plateaus",
            "updated": "2023-11-29T21:18:23Z",
            "published": "2023-11-29T21:18:23Z",
            "summary": "Inspired by the Fleming-Viot stochastic process, we propose a variant of\nVariational Quantum Algorithms benefitting from a parallel implementation of\nthe classical step of learning parameters of a given variational form, with the\naim of avoiding regions of the parameter space known as barren plateaus. In the\nFleming-Viot tradition, parallel searches are called particles. In our proposed\napproach, the search by a Fleming-Viot particle is stopped when it encounters a\nregion where the gradient is too small or noisy. The stopped particle continues\nthe search after being regenerated at another potentially more interesting\nlocation of the parameter space, biasing the exploration away from barren\nplateaus. We analyze the behavior of the Fleming-Viot particles from a\ntheoretical standpoint, backed up with numerical experiments on synthetic\nproblems as well as on selected instances of the Max-Cut problem on graphs,\nwhich show that our method performs better than plain-vanilla variants when\nthere are large barren plateaus.",
            "author": [
                "Daniel Mastropietro",
                "Georgios Korpas",
                "Vyacheslav Kungurtsev",
                "Jakub Marecek"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18090v1",
                "http://arxiv.org/pdf/2311.18090v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18083v1",
            "title": "Meta Co-Training: Two Views are Better than One",
            "updated": "2023-11-29T21:11:58Z",
            "published": "2023-11-29T21:11:58Z",
            "summary": "In many practical computer vision scenarios unlabeled data is plentiful, but\nlabels are scarce and difficult to obtain. As a result, semi-supervised\nlearning which leverages unlabeled data to boost the performance of supervised\nclassifiers have received significant attention in recent literature. One major\nclass of semi-supervised algorithms is co-training. In co-training two\ndifferent models leverage different independent and sufficient \"views\" of the\ndata to jointly make better predictions. During co-training each model creates\npseudo labels on unlabeled points which are used to improve the other model. We\nshow that in the common case when independent views are not available we can\nconstruct such views inexpensively using pre-trained models. Co-training on the\nconstructed views yields a performance improvement over any of the individual\nviews we construct and performance comparable with recent approaches in\nsemi-supervised learning, but has some undesirable properties. To alleviate the\nissues present with co-training we present Meta Co-Training which is an\nextension of the successful Meta Pseudo Labels approach to multiple views. Our\nmethod achieves new state-of-the-art performance on ImageNet-10% with very few\ntraining resources, as well as outperforming prior semi-supervised work on\nseveral other fine-grained image classification datasets.",
            "author": [
                "Jay C. Rothenberger",
                "Dimitrios I. Diochnos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18083v1",
                "http://arxiv.org/pdf/2311.18083v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "I.2.6; I.4.10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18082v1",
            "title": "Zooming Out on Zooming In: Advancing Super-Resolution for Remote Sensing",
            "updated": "2023-11-29T21:06:45Z",
            "published": "2023-11-29T21:06:45Z",
            "summary": "Super-Resolution for remote sensing has the potential for huge impact on\nplanet monitoring by producing accurate and realistic high resolution imagery\non a frequent basis and a global scale. Despite a lot of attention, several\ninconsistencies and challenges have prevented it from being deployed in\npractice. These include the lack of effective metrics, fragmented and\nrelatively small-scale datasets for training, insufficient comparisons across a\nsuite of methods, and unclear evidence for the use of super-resolution outputs\nfor machine consumption. This work presents a new metric for super-resolution,\nCLIPScore, that corresponds far better with human judgments than previous\nmetrics on an extensive study. We use CLIPScore to evaluate four standard\nmethods on a new large-scale dataset, S2-NAIP, and three existing benchmark\ndatasets, and find that generative adversarial networks easily outperform more\ntraditional L2 loss-based models and are more semantically accurate than modern\ndiffusion models. We also find that using CLIPScore as an auxiliary loss can\nspeed up the training of GANs by 18x and lead to improved outputs, resulting in\nan effective model in diverse geographies across the world which we will\nrelease publicly. The dataset, pre-trained model weights, and code are\navailable at https://github.com/allenai/satlas-super-resolution/.",
            "author": [
                "Piper Wolters",
                "Favyen Bastani",
                "Aniruddha Kembhavi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18082v1",
                "http://arxiv.org/pdf/2311.18082v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18080v1",
            "title": "Variations on Keeler's Theorem",
            "updated": "2023-11-29T20:52:09Z",
            "published": "2023-11-29T20:52:09Z",
            "summary": "The 2010 Futurama episode The Prisoner of Benda features a mind swapping\nmachine that swaps the minds of two people at a time with the restriction that\nthe same pair of people cannot use the machine more than once. We show that if\na machine swaps $n$ people cyclically with the condition that the same group of\npeople cannot use the machine again, we can find a way to get everyone back. We\nprove our solution is optimal for when $n =3$. We also introduce an infinite\nvariant of the mind swapping machine.",
            "author": [
                "Alexandra Bartas",
                "Danny Lara",
                "Bruce Leavitt",
                "Ben Vessely"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18080v1",
                "http://arxiv.org/pdf/2311.18080v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18078v1",
            "title": "The Forecastability of Underlying Building Electricity Demand from Time\n  Series Data",
            "updated": "2023-11-29T20:47:47Z",
            "published": "2023-11-29T20:47:47Z",
            "summary": "Forecasting building energy consumption has become a promising solution in\nBuilding Energy Management Systems for energy saving and optimization.\nFurthermore, it can play an important role in the efficient management of the\noperation of a smart grid. Different data-driven approaches to forecast the\nfuture energy demand of buildings at different scale, and over various time\nhorizons, can be found in the scientific literature, including extensive\nMachine Learning and Deep Learning approaches. However, the identification of\nthe most accurate forecaster model which can be utilized to predict the energy\ndemand of such a building is still challenging.In this paper, the design and\nimplementation of a data-driven approach to predict how forecastable the future\nenergy demand of a building is, without first utilizing a data-driven\nforecasting model, is presented. The investigation utilizes a historical\nelectricity consumption time series data set with a half-hour interval that has\nbeen collected from a group of residential buildings located in the City of\nLondon, United Kingdom",
            "author": [
                "Mohamad Khalil",
                "A. Stephen McGough",
                "Hussain Kazmi",
                "Sara Walker"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18078v1",
                "http://arxiv.org/pdf/2311.18078v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18076v1",
            "title": "A Nystr\u00f6m method with missing distances",
            "updated": "2023-11-29T20:43:49Z",
            "published": "2023-11-29T20:43:49Z",
            "summary": "We study the problem of determining the configuration of $n$ points, referred\nto as mobile nodes, by utilizing pairwise distances to $m$ fixed points known\nas anchor nodes. In the standard setting, we have information about the\ndistances between anchors (anchor-anchor) and between anchors and mobile nodes\n(anchor-mobile), but the distances between mobile nodes (mobile-mobile) are not\nknown. For this setup, the Nystr\\\"om method is a viable technique for\nestimating the positions of the mobile nodes. This study focuses on the setting\nwhere the anchor-mobile block of the distance matrix contains only partial\ndistance information. First, we establish a relationship between the columns of\nthe anchor-mobile block in the distance matrix and the columns of the\ncorresponding block in the Gram matrix via a graph Laplacian. Exploiting this\nconnection, we introduce a novel sampling model that frames the position\nestimation problem as low-rank recovery of an inner product matrix, given a\nsubset of its expansion coefficients in a special non-orthogonal basis. This\nbasis and its dual basis--the central elements of our model--are explicitly\nderived. Our analysis is grounded in a specific centering of the points that is\nunique to the Nystr\\\"om method. With this in mind, we extend previous work in\nEuclidean distance geometry by providing a general dual basis approach for\npoints centered anywhere.",
            "author": [
                "Samuel Lichtenberg",
                "Abiy Tasissa"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18076v1",
                "http://arxiv.org/pdf/2311.18076v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.LG",
                "cs.RO",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18074v1",
            "title": "Game Projection and Robustness for Game-Theoretic Autonomous Driving",
            "updated": "2023-11-29T20:40:02Z",
            "published": "2023-11-29T20:40:02Z",
            "summary": "Game-theoretic approaches are envisioned to bring human-like reasoning skills\nand decision-making processes for autonomous vehicles (AVs). However,\nchallenges including game complexity and incomplete information still remain to\nbe addressed before they can be sufficiently practical for real-world use. Game\ncomplexity refers to the difficulties of solving a multi-player game, which\ninclude solution existence, algorithm convergence, and scalability. To address\nthese difficulties, a potential game based framework was developed in our\nrecent work. However, conditions on cost function design need to be enforced to\nmake the game a potential game. This paper relaxes the conditions and makes the\npotential game approach applicable to more general scenarios, even including\nthe ones that cannot be molded as a potential game. Incomplete information\nrefers to the ego vehicle's lack of knowledge of other traffic agents' cost\nfunctions. Cost function deviations between the ego vehicle estimated/learned\nother agents' cost functions and their actual ones are often inevitable. This\nmotivates us to study the robustness of a game-theoretic solution. This paper\ndefines the robustness margin of a game solution as the maximum magnitude of\ncost function deviations that can be accommodated in a game without changing\nthe optimality of the game solution. With this definition, closed-form\nrobustness margins are derived. Numerical studies using highway lane-changing\nscenarios are reported.",
            "author": [
                "Mushuang Liu",
                "H. Eric Tseng",
                "Dimitar Filev",
                "Anouck Girard",
                "Ilya Kolmanovsky"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18074v1",
                "http://arxiv.org/pdf/2311.18074v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18072v1",
            "title": "Self-Supervised Learning for Large-Scale Preventive Security Constrained\n  DC Optimal Power Flow",
            "updated": "2023-11-29T20:36:35Z",
            "published": "2023-11-29T20:36:35Z",
            "summary": "Security-Constrained Optimal Power Flow (SCOPF) plays a crucial role in power\ngrid stability but becomes increasingly complex as systems grow. This paper\nintroduces PDL-SCOPF, a self-supervised end-to-end primal-dual learning\nframework for producing near-optimal solutions to large-scale SCOPF problems in\nmilliseconds. Indeed, PDL-SCOPF remedies the limitations of supervised\ncounterparts that rely on training instances with their optimal solutions,\nwhich becomes impractical for large-scale SCOPF problems. PDL-SCOPF mimics an\nAugmented Lagrangian Method (ALM) for training primal and dual networks that\nlearn the primal solutions and the Lagrangian multipliers, respectively, to the\nunconstrained optimizations. In addition, PDL-SCOPF incorporates a repair layer\nto ensure the feasibility of the power balance in the nominal case, and a\nbinary search layer to compute, using the Automatic Primary Response (APR), the\ngenerator dispatches in the contingencies. The resulting differentiable program\ncan then be trained end-to-end using the objective function of the SCOPF and\nthe power balance constraints of the contingencies. Experimental results\ndemonstrate that the PDL-SCOPF delivers accurate feasible solutions with\nminimal optimality gaps. The framework underlying PDL-SCOPF aims at bridging\nthe gap between traditional optimization methods and machine learning,\nhighlighting the potential of self-supervised end-to-end primal-dual learning\nfor large-scale optimization tasks.",
            "author": [
                "Seonho Park",
                "Pascal Van Hentenryck"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18072v1",
                "http://arxiv.org/pdf/2311.18072v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18068v2",
            "title": "ALSTER: A Local Spatio-Temporal Expert for Online 3D Semantic\n  Reconstruction",
            "updated": "2023-12-03T08:33:52Z",
            "published": "2023-11-29T20:30:18Z",
            "summary": "We propose an online 3D semantic segmentation method that incrementally\nreconstructs a 3D semantic map from a stream of RGB-D frames. Unlike offline\nmethods, ours is directly applicable to scenarios with real-time constraints,\nsuch as robotics or mixed reality. To overcome the inherent challenges of\nonline methods, we make two main contributions. First, to effectively extract\ninformation from the input RGB-D video stream, we jointly estimate geometry and\nsemantic labels per frame in 3D. A key focus of our approach is to reason about\nsemantic entities both in the 2D input and the local 3D domain to leverage\ndifferences in spatial context and network architectures. Our method predicts\n2D features using an off-the-shelf segmentation network. The extracted 2D\nfeatures are refined by a lightweight 3D network to enable reasoning about the\nlocal 3D structure. Second, to efficiently deal with an infinite stream of\ninput RGB-D frames, a subsequent network serves as a temporal expert predicting\nthe incremental scene updates by leveraging 2D, 3D, and past information in a\nlearned manner. These updates are then integrated into a global scene\nrepresentation. Using these main contributions, our method can enable scenarios\nwith real-time constraints and can scale to arbitrary scene sizes by processing\nand updating the scene only in a local region defined by the new measurement.\nOur experiments demonstrate improved results compared to existing online\nmethods that purely operate in local regions and show that complementary\nsources of information can boost the performance. We provide a thorough\nablation study on the benefits of different architectural as well as\nalgorithmic design decisions. Our method yields competitive results on the\npopular ScanNet benchmark and SceneNN dataset.",
            "author": [
                "Silvan Weder",
                "Francis Engelmann",
                "Johannes L. Sch\u00f6nberger",
                "Akihito Seki",
                "Marc Pollefeys",
                "Martin R. Oswald"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18068v2",
                "http://arxiv.org/pdf/2311.18068v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18063v1",
            "title": "TurkishBERTweet: Fast and Reliable Large Language Model for Social Media\n  Analysis",
            "updated": "2023-11-29T20:22:44Z",
            "published": "2023-11-29T20:22:44Z",
            "summary": "Turkish is one of the most popular languages in the world. Wide us of this\nlanguage on social media platforms such as Twitter, Instagram, or Tiktok and\nstrategic position of the country in the world politics makes it appealing for\nthe social network researchers and industry. To address this need, we introduce\nTurkishBERTweet, the first large scale pre-trained language model for Turkish\nsocial media built using almost 900 million tweets. The model shares the same\narchitecture as base BERT model with smaller input length, making\nTurkishBERTweet lighter than BERTurk and can have significantly lower inference\ntime. We trained our model using the same approach for RoBERTa model and\nevaluated on two text classification tasks: Sentiment Classification and Hate\nSpeech Detection. We demonstrate that TurkishBERTweet outperforms the other\navailable alternatives on generalizability and its lower inference time gives\nsignificant advantage to process large-scale datasets. We also compared our\nmodels with the commercial OpenAI solutions in terms of cost and performance to\ndemonstrate TurkishBERTweet is scalable and cost-effective solution. As part of\nour research, we released TurkishBERTweet and fine-tuned LoRA adapters for the\nmentioned tasks under the MIT License to facilitate future research and\napplications on Turkish social media. Our TurkishBERTweet model is available\nat: https://github.com/ViralLab/TurkishBERTweet",
            "author": [
                "Ali Najafi",
                "Onur Varol"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18063v1",
                "http://arxiv.org/pdf/2311.18063v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18062v1",
            "title": "Understanding Your Agent: Leveraging Large Language Models for Behavior\n  Explanation",
            "updated": "2023-11-29T20:16:23Z",
            "published": "2023-11-29T20:16:23Z",
            "summary": "Intelligent agents such as robots are increasingly deployed in real-world,\nsafety-critical settings. It is vital that these agents are able to explain the\nreasoning behind their decisions to human counterparts; however, their behavior\nis often produced by uninterpretable models such as deep neural networks. We\npropose an approach to generate natural language explanations for an agent's\nbehavior based only on observations of states and actions, thus making our\nmethod independent from the underlying model's representation. For such models,\nwe first learn a behavior representation and subsequently use it to produce\nplausible explanations with minimal hallucination while affording user\ninteraction with a pre-trained large language model. We evaluate our method in\na multi-agent search-and-rescue environment and demonstrate the effectiveness\nof our explanations for agents executing various behaviors. Through user\nstudies and empirical experiments, we show that our approach generates\nexplanations as helpful as those produced by a human domain expert while\nenabling beneficial interactions such as clarification and counterfactual\nqueries.",
            "author": [
                "Xijia Zhang",
                "Yue Guo",
                "Simon Stepputtis",
                "Katia Sycara",
                "Joseph Campbell"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18062v1",
                "http://arxiv.org/pdf/2311.18062v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18061v2",
            "title": "TransNAS-TSAD: Harnessing Transformers for Multi-Objective Neural\n  Architecture Search in Time Series Anomaly Detection",
            "updated": "2023-12-03T00:41:46Z",
            "published": "2023-11-29T20:13:32Z",
            "summary": "The surge in real-time data collection across various industries has\nunderscored the need for advanced anomaly detection in both univariate and\nmultivariate time series data. Traditional methods, while comprehensive, often\nstruggle to capture the complex interdependencies in such data. This paper\nintroduces TransNAS-TSAD, a novel framework that synergizes transformer\narchitecture with neural architecture search (NAS), enhanced through NSGA-II\nalgorithm optimization. This innovative approach effectively tackles the\ncomplexities of both univariate and multivariate time series, balancing\ncomputational efficiency with detection accuracy. Our evaluation reveals that\nTransNAS-TSAD surpasses conventional anomaly detection models, demonstrating\nmarked improvements in diverse data scenarios. We also propose the\nEfficiency-Accuracy-Complexity Score (EACS) as a new metric for assessing model\nperformance, emphasizing the crucial balance between accuracy and computational\nresources. TransNAS-TSAD sets a new benchmark in time series anomaly detection,\noffering a versatile, efficient solution for complex real-world applications.\nThis research paves the way for future developments in the field, highlighting\nits potential in a wide range of industry applications.",
            "author": [
                "Ijaz Ul Haq",
                "Byung Suk Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18061v2",
                "http://arxiv.org/pdf/2311.18061v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18056v1",
            "title": "ReLU-QP: A GPU-Accelerated Quadratic Programming Solver for\n  Model-Predictive Control",
            "updated": "2023-11-29T20:06:29Z",
            "published": "2023-11-29T20:06:29Z",
            "summary": "We present ReLU-QP, a GPU-accelerated solver for quadratic programs (QPs)\nthat is capable of solving high-dimensional control problems at real-time\nrates. ReLU-QP is derived by exactly reformulating the Alternating Direction\nMethod of Multipliers (ADMM) algorithm for solving QPs as a deep, weight-tied\nneural network with rectified linear unit (ReLU) activations. This\nreformulation enables the deployment of ReLU-QP on GPUs using standard\nmachine-learning toolboxes. We evaluate the performance of ReLU-QP across three\nmodel-predictive control (MPC) benchmarks: stabilizing random linear dynamical\nsystems with control limits, balancing an Atlas humanoid robot on a single\nfoot, and tracking whole-body reference trajectories on a quadruped equipped\nwith a six-degree-of-freedom arm. These benchmarks indicate that ReLU-QP is\ncompetitive with state-of-the-art CPU-based solvers for small-to-medium-scale\nproblems and offers order-of-magnitude speed improvements for larger-scale\nproblems.",
            "author": [
                "Arun L. Bishop",
                "John Z. Zhang",
                "Swaminathan Gurumurthy",
                "Kevin Tracy",
                "Zachary Manchester"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18056v1",
                "http://arxiv.org/pdf/2311.18056v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18054v1",
            "title": "I Know You Did Not Write That! A Sampling Based Watermarking Method for\n  Identifying Machine Generated Text",
            "updated": "2023-11-29T20:04:57Z",
            "published": "2023-11-29T20:04:57Z",
            "summary": "Potential harms of Large Language Models such as mass misinformation and\nplagiarism can be partially mitigated if there exists a reliable way to detect\nmachine generated text. In this paper, we propose a new watermarking method to\ndetect machine-generated texts. Our method embeds a unique pattern within the\ngenerated text, ensuring that while the content remains coherent and natural to\nhuman readers, it carries distinct markers that can be identified\nalgorithmically. Specifically, we intervene with the token sampling process in\na way which enables us to trace back our token choices during the detection\nphase. We show how watermarking affects textual quality and compare our\nproposed method with a state-of-the-art watermarking method in terms of\nrobustness and detectability. Through extensive experiments, we demonstrate the\neffectiveness of our watermarking scheme in distinguishing between watermarked\nand non-watermarked text, achieving high detection rates while maintaining\ntextual quality.",
            "author": [
                "Kaan Efe Kele\u015f",
                "\u00d6mer Kaan G\u00fcrb\u00fcz",
                "Mucahid Kutlu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18054v1",
                "http://arxiv.org/pdf/2311.18054v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00067v1",
            "title": "Predicting breast cancer with AI for individual risk-adjusted MRI\n  screening and early detection",
            "updated": "2023-11-29T19:52:53Z",
            "published": "2023-11-29T19:52:53Z",
            "summary": "Women with an increased life-time risk of breast cancer undergo supplemental\nannual screening MRI. We propose to predict the risk of developing breast\ncancer within one year based on the current MRI, with the objective of reducing\nscreening burden and facilitating early detection. An AI algorithm was\ndeveloped on 53,858 breasts from 12,694 patients who underwent screening or\ndiagnostic MRI and accrued over 12 years, with 2,331 confirmed cancers. A first\nU-Net was trained to segment lesions and identify regions of concern. A second\nconvolutional network was trained to detect malignant cancer using features\nextracted by the U-Net. This network was then fine-tuned to estimate the risk\nof developing cancer within a year in cases that radiologists considered normal\nor likely benign. Risk predictions from this AI were evaluated with a\nretrospective analysis of 9,183 breasts from a high-risk screening cohort,\nwhich were not used for training. Statistical analysis focused on the tradeoff\nbetween number of omitted exams versus negative predictive value, and number of\npotential early detections versus positive predictive value. The AI algorithm\nidentified regions of concern that coincided with future tumors in 52% of\nscreen-detected cancers. Upon directed review, a radiologist found that 71.3%\nof cancers had a visible correlate on the MRI prior to diagnosis, 65% of these\ncorrelates were identified by the AI model. Reevaluating these regions in 10%\nof all cases with higher AI-predicted risk could have resulted in up to 33%\nearly detections by a radiologist. Additionally, screening burden could have\nbeen reduced in 16% of lower-risk cases by recommending a later follow-up\nwithout compromising current interval cancer rate. With increasing datasets and\nimproving image quality we expect this new AI-aided, adaptive screening to\nmeaningfully reduce screening burden and improve early detection.",
            "author": [
                "Lukas Hirsch",
                "Yu Huang",
                "Hernan A. Makse",
                "Danny F. Martinez",
                "Mary Hughes",
                "Sarah Eskreis-Winkler",
                "Katja Pinker",
                "Elizabeth Morris",
                "Lucas C. Parra",
                "Elizabeth J. Sutton"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00067v1",
                "http://arxiv.org/pdf/2312.00067v1"
            ],
            "primary_category": "physics.med-ph",
            "category": [
                "physics.med-ph",
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18048v1",
            "title": "An Interventional Perspective on Identifiability in Gaussian LTI Systems\n  with Independent Component Analysis",
            "updated": "2023-11-29T19:51:35Z",
            "published": "2023-11-29T19:51:35Z",
            "summary": "We investigate the relationship between system identification and\nintervention design in dynamical systems. While previous research demonstrated\nhow identifiable representation learning methods, such as Independent Component\nAnalysis (ICA), can reveal cause-effect relationships, it relied on a passive\nperspective without considering how to collect data. Our work shows that in\nGaussian Linear Time-Invariant (LTI) systems, the system parameters can be\nidentified by introducing diverse intervention signals in a multi-environment\nsetting. By harnessing appropriate diversity assumptions motivated by the ICA\nliterature, our findings connect experiment design and representational\nidentifiability in dynamical systems. We corroborate our findings on synthetic\nand (simulated) physical data. Additionally, we show that Hidden Markov Models,\nin general, and (Gaussian) LTI systems, in particular, fulfil a generalization\nof the Causal de Finetti theorem with continuous parameters.",
            "author": [
                "Goutham Rajendran",
                "Patrik Reizinger",
                "Wieland Brendel",
                "Pradeep Ravikumar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18048v1",
                "http://arxiv.org/pdf/2311.18048v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CE",
                "cs.SY",
                "eess.SY",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00066v1",
            "title": "Exploring Factors Affecting Pedestrian Crash Severity Using TabNet: A\n  Deep Learning Approach",
            "updated": "2023-11-29T19:44:52Z",
            "published": "2023-11-29T19:44:52Z",
            "summary": "This study presents the first investigation of pedestrian crash severity\nusing the TabNet model, a novel tabular deep learning method exceptionally\nsuited for analyzing the tabular data inherent in transportation safety\nresearch. Through the application of TabNet to a comprehensive dataset from\nUtah covering the years 2010 to 2022, we uncover intricate factors contributing\nto pedestrian crash severity. The TabNet model, capitalizing on its\ncompatibility with structured data, demonstrates remarkable predictive\naccuracy, eclipsing that of traditional models. It identifies critical\nvariables, such as pedestrian age, involvement in left or right turns, lighting\nconditions, and alcohol consumption, which significantly influence crash\noutcomes. The utilization of SHapley Additive exPlanations (SHAP) enhances our\nability to interpret the TabNet model's predictions, ensuring transparency and\nunderstandability in our deep learning approach. The insights derived from our\nanalysis provide a valuable compass for transportation safety engineers and\npolicymakers, enabling the identification of pivotal factors that affect\npedestrian crash severity. Such knowledge is instrumental in formulating\nprecise, data-driven interventions aimed at bolstering pedestrian safety across\ndiverse urban and rural settings.",
            "author": [
                "Amir Rafe",
                "Patrick A. Singleton"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00066v1",
                "http://arxiv.org/pdf/2312.00066v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00065v2",
            "title": "Unsupervised Keypoints from Pretrained Diffusion Models",
            "updated": "2023-12-05T19:36:01Z",
            "published": "2023-11-29T19:43:38Z",
            "summary": "Unsupervised learning of keypoints and landmarks has seen significant\nprogress with the help of modern neural network architectures, but performance\nis yet to match the supervised counterpart, making their practicability\nquestionable. We leverage the emergent knowledge within text-to-image diffusion\nmodels, towards more robust unsupervised keypoints. Our core idea is to find\ntext embeddings that would cause the generative model to consistently attend to\ncompact regions in images (i.e. keypoints). To do so, we simply optimize the\ntext embedding such that the cross-attention maps within the denoising network\nare localized as Gaussians with small standard deviations. We validate our\nperformance on multiple datasets: the CelebA, CUB-200-2011, Tai-Chi-HD,\nDeepFashion, and Human3.6m datasets. We achieve significantly improved\naccuracy, sometimes even outperforming supervised ones, particularly for data\nthat is non-aligned and less curated. Our code is publicly available and can be\nfound through our project page: https://ubc-vision.github.io/StableKeypoints/",
            "author": [
                "Eric Hedlin",
                "Gopal Sharma",
                "Shweta Mahajan",
                "Xingzhe He",
                "Hossam Isack",
                "Abhishek Kar Helge Rhodin",
                "Andrea Tagliasacchi",
                "Kwang Moo Yi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00065v2",
                "http://arxiv.org/pdf/2312.00065v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18044v1",
            "title": "Transfer Learning in Robotics: An Upcoming Breakthrough? A Review of\n  Promises and Challenges",
            "updated": "2023-11-29T19:40:10Z",
            "published": "2023-11-29T19:40:10Z",
            "summary": "Transfer learning is a conceptually-enticing paradigm in pursuit of truly\nintelligent embodied agents. The core concept -- reusing prior knowledge to\nlearn in and from novel situations -- is successfully leveraged by humans to\nhandle novel situations. In recent years, transfer learning has received\nrenewed interest from the community from different perspectives, including\nimitation learning, domain adaptation, and transfer of experience from\nsimulation to the real world, among others. In this paper, we unify the concept\nof transfer learning in robotics and provide the first taxonomy of its kind\nconsidering the key concepts of robot, task, and environment. Through a review\nof the promises and challenges in the field, we identify the need of\ntransferring at different abstraction levels, the need of quantifying the\ntransfer gap and the quality of transfer, as well as the dangers of negative\ntransfer. Via this position paper, we hope to channel the effort of the\ncommunity towards the most significant roadblocks to realize the full potential\nof transfer learning in robotics.",
            "author": [
                "No\u00e9mie Jaquier",
                "Michael C. Welle",
                "Andrej Gams",
                "Kunpeng Yao",
                "Bernardo Fichera",
                "Aude Billard",
                "Ale\u0161 Ude",
                "Tamim Asfour",
                "Danica Kragi\u0107"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18044v1",
                "http://arxiv.org/pdf/2311.18044v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18040v1",
            "title": "Evaluating Trustworthiness of AI-Enabled Decision Support Systems:\n  Validation of the Multisource AI Scorecard Table (MAST)",
            "updated": "2023-11-29T19:34:15Z",
            "published": "2023-11-29T19:34:15Z",
            "summary": "The Multisource AI Scorecard Table (MAST) is a checklist tool based on\nanalytic tradecraft standards to inform the design and evaluation of\ntrustworthy AI systems. In this study, we evaluate whether MAST is associated\nwith people's trust perceptions in AI-enabled decision support systems\n(AI-DSSs). Evaluating trust in AI-DSSs poses challenges to researchers and\npractitioners. These challenges include identifying the components,\ncapabilities, and potential of these systems, many of which are based on the\ncomplex deep learning algorithms that drive DSS performance and preclude\ncomplete manual inspection. We developed two interactive, AI-DSS test\nenvironments using the MAST criteria. One emulated an identity verification\ntask in security screening, and another emulated a text summarization system to\naid in an investigative reporting task. Each test environment had one version\ndesigned to match low-MAST ratings, and another designed to match high-MAST\nratings, with the hypothesis that MAST ratings would be positively related to\nthe trust ratings of these systems. A total of 177 subject matter experts were\nrecruited to interact with and evaluate these systems. Results generally show\nhigher MAST ratings for the high-MAST conditions compared to the low-MAST\ngroups, and that measures of trust perception are highly correlated with the\nMAST ratings. We conclude that MAST can be a useful tool for designing and\nevaluating systems that will engender high trust perceptions, including AI-DSS\nthat may be used to support visual screening and text summarization tasks.\nHowever, higher MAST ratings may not translate to higher joint performance.",
            "author": [
                "Pouria Salehi",
                "Yang Ba",
                "Nayoung Kim",
                "Ahmadreza Mosallanezhad",
                "Anna Pan",
                "Myke C. Cohen",
                "Yixuan Wang",
                "Jieqiong Zhao",
                "Shawaiz Bhatti",
                "James Sung",
                "Erik Blasch",
                "Michelle V. Mancenido",
                "Erin K. Chiou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18040v1",
                "http://arxiv.org/pdf/2311.18040v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18035v1",
            "title": "TransOpt: Transformer-based Representation Learning for Optimization\n  Problem Classification",
            "updated": "2023-11-29T19:20:47Z",
            "published": "2023-11-29T19:20:47Z",
            "summary": "We propose a representation of optimization problem instances using a\ntransformer-based neural network architecture trained for the task of problem\nclassification of the 24 problem classes from the Black-box Optimization\nBenchmarking (BBOB) benchmark. We show that transformer-based methods can be\ntrained to recognize problem classes with accuracies in the range of 70\\%-80\\%\nfor different problem dimensions, suggesting the possible application of\ntransformer architectures in acquiring representations for black-box\noptimization problems.",
            "author": [
                "Gjorgjina Cenikj",
                "Ga\u0161per Petelin",
                "Tome Eftimov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18035v1",
                "http://arxiv.org/pdf/2311.18035v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18034v1",
            "title": "Hyperpolyglot LLMs: Cross-Lingual Interpretability in Token Embeddings",
            "updated": "2023-11-29T19:20:14Z",
            "published": "2023-11-29T19:20:14Z",
            "summary": "Cross-lingual transfer learning is an important property of multilingual\nlarge language models (LLMs). But how do LLMs represent relationships between\nlanguages? Every language model has an input layer that maps tokens to vectors.\nThis ubiquitous layer of language models is often overlooked. We find that\nsimilarities between these input embeddings are highly interpretable and that\nthe geometry of these embeddings differs between model families. In one case\n(XLM-RoBERTa), embeddings encode language: tokens in different writing systems\ncan be linearly separated with an average of 99.2% accuracy. Another family\n(mT5) represents cross-lingual semantic similarity: the 50 nearest neighbors\nfor any token represent an average of 7.61 writing systems, and are frequently\ntranslations. This result is surprising given that there is no explicit\nparallel cross-lingual training corpora and no explicit incentive for\ntranslations in pre-training objectives. Our research opens the door for\ninvestigations in 1) The effect of pre-training and model architectures on\nrepresentations of languages and 2) The applications of cross-lingual\nrepresentations embedded in language models.",
            "author": [
                "Andrea W Wen-Yi",
                "David Mimno"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18034v1",
                "http://arxiv.org/pdf/2311.18034v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18029v1",
            "title": "A Bag of Receptive Fields for Time Series Extrinsic Predictions",
            "updated": "2023-11-29T19:13:10Z",
            "published": "2023-11-29T19:13:10Z",
            "summary": "High-dimensional time series data poses challenges due to its dynamic nature,\nvarying lengths, and presence of missing values. This kind of data requires\nextensive preprocessing, limiting the applicability of existing Time Series\nClassification and Time Series Extrinsic Regression techniques. For this\nreason, we propose BORF, a Bag-Of-Receptive-Fields model, which incorporates\nnotions from time series convolution and 1D-SAX to handle univariate and\nmultivariate time series with varying lengths and missing values. We evaluate\nBORF on Time Series Classification and Time Series Extrinsic Regression tasks\nusing the full UEA and UCR repositories, demonstrating its competitive\nperformance against state-of-the-art methods. Finally, we outline how this\nrepresentation can naturally provide saliency and feature-based explanations.",
            "author": [
                "Francesco Spinnato",
                "Riccardo Guidotti",
                "Anna Monreale",
                "Mirco Nanni"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18029v1",
                "http://arxiv.org/pdf/2311.18029v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18028v1",
            "title": "Filtered Semi-Markov CRF",
            "updated": "2023-11-29T19:11:55Z",
            "published": "2023-11-29T19:11:55Z",
            "summary": "Semi-Markov CRF has been proposed as an alternative to the traditional Linear\nChain CRF for text segmentation tasks such as Named Entity Recognition (NER).\nUnlike CRF, which treats text segmentation as token-level prediction, Semi-CRF\nconsiders segments as the basic unit, making it more expressive. However,\nSemi-CRF suffers from two major drawbacks: (1) quadratic complexity over\nsequence length, as it operates on every span of the input sequence, and (2)\ninferior performance compared to CRF for sequence labeling tasks like NER. In\nthis paper, we introduce Filtered Semi-Markov CRF, a variant of Semi-CRF that\naddresses these issues by incorporating a filtering step to eliminate\nirrelevant segments, reducing complexity and search space. Our approach is\nevaluated on several NER benchmarks, where it outperforms both CRF and Semi-CRF\nwhile being significantly faster. The implementation of our method is available\non \\href{https://github.com/urchade/Filtered-Semi-Markov-CRF}{Github}.",
            "author": [
                "Urchade Zaratiana",
                "Nadi Tomeh",
                "Niama El Khbir",
                "Pierre Holat",
                "Thierry Charnois"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18028v1",
                "http://arxiv.org/pdf/2311.18028v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18027v1",
            "title": "Enhancing Data-Assimilation in CFD using Graph Neural Networks",
            "updated": "2023-11-29T19:11:40Z",
            "published": "2023-11-29T19:11:40Z",
            "summary": "We present a novel machine learning approach for data assimilation applied in\nfluid mechanics, based on adjoint-optimization augmented by Graph Neural\nNetworks (GNNs) models. We consider as baseline the Reynolds-Averaged\nNavier-Stokes (RANS) equations, where the unknown is the meanflow and a closure\nmodel based on the Reynolds-stress tensor is required for correctly computing\nthe solution. An end-to-end process is cast; first, we train a GNN model for\nthe closure term. Second, the GNN model is introduced in the training process\nof data assimilation, where the RANS equations act as a physics constraint for\na consistent prediction. We obtain our results using direct numerical\nsimulations based on a Finite Element Method (FEM) solver; a two-fold interface\nbetween the GNN model and the solver allows the GNN's predictions to be\nincorporated into post-processing steps of the FEM analysis. The proposed\nscheme provides an excellent reconstruction of the meanflow without any\nfeatures selection; preliminary results show promising generalization\nproperties over unseen flow configurations.",
            "author": [
                "Michele Quattromini",
                "Michele Alessandro Bucci",
                "Stefania Cherubini",
                "Onofrio Semeraro"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18027v1",
                "http://arxiv.org/pdf/2311.18027v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18025v1",
            "title": "A Probabilistic Method to Predict Classifier Accuracy on Larger Datasets\n  given Small Pilot Data",
            "updated": "2023-11-29T19:10:15Z",
            "published": "2023-11-29T19:10:15Z",
            "summary": "Practitioners building classifiers often start with a smaller pilot dataset\nand plan to grow to larger data in the near future. Such projects need a\ntoolkit for extrapolating how much classifier accuracy may improve from a 2x,\n10x, or 50x increase in data size. While existing work has focused on finding a\nsingle \"best-fit\" curve using various functional forms like power laws, we\nargue that modeling and assessing the uncertainty of predictions is critical\nyet has seen less attention. In this paper, we propose a Gaussian process model\nto obtain probabilistic extrapolations of accuracy or similar performance\nmetrics as dataset size increases. We evaluate our approach in terms of error,\nlikelihood, and coverage across six datasets. Though we focus on medical tasks\nand image modalities, our open source approach generalizes to any kind of\nclassifier.",
            "author": [
                "Ethan Harvey",
                "Wansu Chen",
                "David M. Kent",
                "Michael C. Hughes"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18025v1",
                "http://arxiv.org/pdf/2311.18025v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18022v1",
            "title": "A trainable manifold for accurate approximation with ReLU Networks",
            "updated": "2023-11-29T19:09:48Z",
            "published": "2023-11-29T19:09:48Z",
            "summary": "We present a novel technique for exercising greater control of the weights of\nReLU activated neural networks to produce more accurate function\napproximations. Many theoretical works encode complex operations into ReLU\nnetworks using smaller base components. In these works, a common base component\nis a constant width approximation to x^2, which has exponentially decaying\nerror with respect to depth. We extend this block to represent a greater range\nof convex one-dimensional functions. We derive a manifold of weights such that\nthe output of these new networks utilizes exponentially many piecewise-linear\nsegments. This manifold guides their training process to overcome drawbacks\nassociated with random initialization and unassisted gradient descent. We train\nthese networks to approximate functions which do not necessarily lie on the\nmanifold, showing a significant reduction of error values over conventional\napproaches.",
            "author": [
                "Max Milkert",
                "Forrest Laine"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18022v1",
                "http://arxiv.org/pdf/2311.18022v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00817v1",
            "title": "TimelyGPT: Recurrent Convolutional Transformer for Long Time-series\n  Representation",
            "updated": "2023-11-29T19:09:28Z",
            "published": "2023-11-29T19:09:28Z",
            "summary": "Pre-trained models (PTMs) have gained prominence in Natural Language\nProcessing and Computer Vision domains. When it comes to time-series PTMs,\ntheir development has been limited. Previous research on time-series\ntransformers has mainly been devoted to small-scale tasks, yet these models\nhave not consistently outperformed traditional models. Additionally, the\nperformance of these transformers on large-scale data remains unexplored. These\nfindings raise doubts about Transformer's capabilities to scale up and capture\ntemporal dependencies. In this study, we re-examine time-series transformers\nand identify the shortcomings of prior studies. Drawing from these insights, we\nthen introduce a pioneering architecture called Timely Generative Pre-trained\nTransformer (\\model). This architecture integrates recurrent attention and\ntemporal convolution modules to effectively capture global-local temporal\ndependencies in long sequences. The relative position embedding with time decay\ncan effectively deal with trend and periodic patterns from time-series. Our\nexperiments show that \\model~excels in modeling continuously monitored\nbiosignal as well as irregularly-sampled time-series data commonly observed in\nlongitudinal electronic health records. This breakthrough suggests a priority\nshift in time-series deep learning research, moving from small-scale modeling\nfrom scratch to large-scale pre-training.",
            "author": [
                "Ziyang Song",
                "Qincheng Lu",
                "Hao Xu",
                "Yue Li"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00817v1",
                "http://arxiv.org/pdf/2312.00817v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18021v1",
            "title": "Understanding and Improving In-Context Learning on Vision-language\n  Models",
            "updated": "2023-11-29T19:08:11Z",
            "published": "2023-11-29T19:08:11Z",
            "summary": "Recently, in-context learning (ICL) on large language models (LLMs) has\nreceived great attention, and this technique can also be applied to\nvision-language models (VLMs) built upon LLMs. These VLMs can respond to\nqueries by conditioning responses on a series of multimodal demonstrations,\nwhich comprise images, queries, and answers. Though ICL has been extensively\nstudied on LLMs, its research on VLMs remains limited. The inclusion of\nadditional visual information in the demonstrations motivates the following\nresearch questions: which of the two modalities in the demonstration is more\nsignificant? How can we select effective multimodal demonstrations to enhance\nICL performance? This study investigates the significance of both visual and\nlanguage information. Our findings indicate that ICL in VLMs is predominantly\ndriven by the textual information in the demonstrations whereas the visual\ninformation in the demonstrations barely affects the ICL performance.\nSubsequently, we provide an understanding of the findings by analyzing the\nmodel information flow and comparing model inner states given different ICL\nsettings. Motivated by our analysis, we propose a simple yet effective\napproach, termed Mixed Modality In-Context Example Selection (MMICES), which\nconsiders both visual and language modalities when selecting demonstrations and\nshows better ICL performance. Extensive experiments are conducted to support\nour findings, understanding, and improvement of the ICL performance of VLMs.",
            "author": [
                "Shuo Chen",
                "Zhen Han",
                "Bailan He",
                "Mark Buckley",
                "Philip Torr",
                "Volker Tresp",
                "Jindong Gu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18021v1",
                "http://arxiv.org/pdf/2311.18021v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00063v1",
            "title": "MoMask: Generative Masked Modeling of 3D Human Motions",
            "updated": "2023-11-29T19:04:10Z",
            "published": "2023-11-29T19:04:10Z",
            "summary": "We introduce MoMask, a novel masked modeling framework for text-driven 3D\nhuman motion generation. In MoMask, a hierarchical quantization scheme is\nemployed to represent human motion as multi-layer discrete motion tokens with\nhigh-fidelity details. Starting at the base layer, with a sequence of motion\ntokens obtained by vector quantization, the residual tokens of increasing\norders are derived and stored at the subsequent layers of the hierarchy. This\nis consequently followed by two distinct bidirectional transformers. For the\nbase-layer motion tokens, a Masked Transformer is designated to predict\nrandomly masked motion tokens conditioned on text input at training stage.\nDuring generation (i.e. inference) stage, starting from an empty sequence, our\nMasked Transformer iteratively fills up the missing tokens; Subsequently, a\nResidual Transformer learns to progressively predict the next-layer tokens\nbased on the results from current layer. Extensive experiments demonstrate that\nMoMask outperforms the state-of-art methods on the text-to-motion generation\ntask, with an FID of 0.045 (vs e.g. 0.141 of T2M-GPT) on the HumanML3D dataset,\nand 0.228 (vs 0.514) on KIT-ML, respectively. MoMask can also be seamlessly\napplied in related tasks without further model fine-tuning, such as text-guided\ntemporal inpainting.",
            "author": [
                "Chuan Guo",
                "Yuxuan Mu",
                "Muhammad Gohar Javed",
                "Sen Wang",
                "Li Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00063v1",
                "http://arxiv.org/pdf/2312.00063v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18017v1",
            "title": "Learning an Effective Evolution Equation for Particle-Mesh Simulations\n  Across Cosmologies",
            "updated": "2023-11-29T19:03:37Z",
            "published": "2023-11-29T19:03:37Z",
            "summary": "Particle-mesh simulations trade small-scale accuracy for speed compared to\ntraditional, computationally expensive N-body codes in cosmological\nsimulations. In this work, we show how a data-driven model could be used to\nlearn an effective evolution equation for the particles, by correcting the\nerrors of the particle-mesh potential incurred on small scales during\nsimulations. We find that our learnt correction yields evolution equations that\ngeneralize well to new, unseen initial conditions and cosmologies. We further\ndemonstrate that the resulting corrected maps can be used in a simulation-based\ninference framework to yield an unbiased inference of cosmological parameters.\nThe model, a network implemented in Fourier space, is exclusively trained on\nthe particle positions and velocities.",
            "author": [
                "Nicolas Payot",
                "Pablo Lemos",
                "Laurence Perreault-Levasseur",
                "Carolina Cuesta-Lazaro",
                "Chirag Modi",
                "Yashar Hezaveh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18017v1",
                "http://arxiv.org/pdf/2311.18017v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18015v1",
            "title": "Predicting the Spectroscopic Features of Galaxies by Applying Manifold\n  Learning on Their Broad-Band Colors: Proof of Concept and Potential\n  Applications for Euclid, Roman, and Rubin LSST",
            "updated": "2023-11-29T19:01:34Z",
            "published": "2023-11-29T19:01:34Z",
            "summary": "Entering the era of large-scale galaxy surveys which will deliver\nunprecedented amounts of photometric and spectroscopic data, there is a growing\nneed for more efficient, data driven, and less model-dependent techniques to\nanalyze spectral energy distribution of galaxies. In this work, we demonstrate\nthat by taking advantage of manifold learning approaches, we can estimate\nspectroscopic features of large samples of galaxies from their broadband\nphotometry when spectroscopy is available only for a fraction of the sample.\nThis will be done by applying the Self Organizing Map (SOM) algorithm on\nbroadband colors of galaxies and mapping partially available spectroscopic\ninformation into the trained maps. In this pilot study, we focus on estimating\n4000A break in a magnitude-limited sample of galaxies in the COSMOS field. We\nuse observed galaxy colors (ugrizYJH) as well as spectroscopic measurements for\na fraction of the sample from LEGA-C and zCOSMOS spectroscopic surveys to\nestimate this feature for our parent photometric sample. We recover the D4000\nfeature for galaxies which only have broadband colors with uncertainties about\ntwice of the uncertainty of the employed spectroscopic surveys. Using these\nmeasurements we observe a positive correlation between D4000 and stellar mass\nof the galaxies in our sample with weaker D4000 features for higher redshift\ngalaxies at fixed stellar masses. These can be explained with downsizing\nscenario for the formation of galaxies and the decrease in their specific star\nformation rate as well as the aging of their stellar populations over this time\nperiod.",
            "author": [
                "Marziye Jafariyazani",
                "Daniel Masters",
                "Andreas Faisst",
                "Harry Teplitz",
                "Olivier Ilbert"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18015v1",
                "http://arxiv.org/pdf/2311.18015v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18014v1",
            "title": "Unraveling the Mysteries of Galaxy Clusters: Recurrent Inference\n  Deconvolution of X-ray Spectra",
            "updated": "2023-11-29T19:01:13Z",
            "published": "2023-11-29T19:01:13Z",
            "summary": "In the realm of X-ray spectral analysis, the true nature of spectra has\nremained elusive, as observed spectra have long been the outcome of convolution\nbetween instrumental response functions and intrinsic spectra. In this study,\nwe employ a recurrent neural network framework, the Recurrent Inference Machine\n(RIM), to achieve the high-precision deconvolution of intrinsic spectra from\ninstrumental response functions. Our RIM model is meticulously trained on\ncutting-edge thermodynamic models and authentic response matrices sourced from\nthe Chandra X-ray Observatory archive. Demonstrating remarkable accuracy, our\nmodel successfully reconstructs intrinsic spectra well below the 1-sigma error\nlevel. We showcase the practical application of this novel approach through\nreal Chandra observations of the galaxy cluster Abell 1550 - a vital\ncalibration target for the recently launched X-ray telescope, XRISM. This work\nmarks a significant stride in the domain of X-ray spectral analysis, offering a\npromising avenue for unlocking hitherto concealed insights into spectra.",
            "author": [
                "Carter Rhea",
                "Julie Hlavacek-Larrondo",
                "Ralph Kraft",
                "Akos Bogdan",
                "Alexandre Adam",
                "Laurence Perreault-Levasseur"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18014v1",
                "http://arxiv.org/pdf/2311.18014v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18012v1",
            "title": "Bayesian Imaging for Radio Interferometry with Score-Based Priors",
            "updated": "2023-11-29T19:01:05Z",
            "published": "2023-11-29T19:01:05Z",
            "summary": "The inverse imaging task in radio interferometry is a key limiting factor to\nretrieving Bayesian uncertainties in radio astronomy in a computationally\neffective manner. We use a score-based prior derived from optical images of\ngalaxies to recover images of protoplanetary disks from the DSHARP survey. We\ndemonstrate that our method produces plausible posterior samples despite the\nmisspecified galaxy prior. We show that our approach produces results which are\ncompetitive with existing radio interferometry imaging algorithms.",
            "author": [
                "Noe Dia",
                "M. J. Yantovski-Barth",
                "Alexandre Adam",
                "Micah Bowles",
                "Pablo Lemos",
                "Anna M. M. Scaife",
                "Yashar Hezaveh",
                "Laurence Perreault-Levasseur"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18012v1",
                "http://arxiv.org/pdf/2311.18012v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18010v1",
            "title": "Active learning meets fractal decision boundaries: a cautionary tale\n  from the Sitnikov three-body problem",
            "updated": "2023-11-29T19:00:35Z",
            "published": "2023-11-29T19:00:35Z",
            "summary": "Chaotic systems such as the gravitational N-body problem are ubiquitous in\nastronomy. Machine learning (ML) is increasingly deployed to predict the\nevolution of such systems, e.g. with the goal of speeding up simulations.\nStrategies such as active Learning (AL) are a natural choice to optimize ML\ntraining. Here we showcase an AL failure when predicting the stability of the\nSitnikov three-body problem, the simplest case of N-body problem displaying\nchaotic behavior. We link this failure to the fractal nature of our\nclassification problem's decision boundary. This is a potential pitfall in\noptimizing large sets of N-body simulations via AL in the context of star\ncluster physics, galactic dynamics, or cosmology.",
            "author": [
                "Nicolas Payot",
                "Mario Pasquato",
                "Alessandro Alberto Trani",
                "Yashar Hezaveh",
                "Laurence Perreault-Levasseur"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18010v1",
                "http://arxiv.org/pdf/2311.18010v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA",
                "astro-ph.IM",
                "nlin.CD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18007v1",
            "title": "Towards out-of-distribution generalization in large-scale astronomical\n  surveys: robust networks learn similar representations",
            "updated": "2023-11-29T19:00:05Z",
            "published": "2023-11-29T19:00:05Z",
            "summary": "The generalization of machine learning (ML) models to out-of-distribution\n(OOD) examples remains a key challenge in extracting information from upcoming\nastronomical surveys. Interpretability approaches are a natural way to gain\ninsights into the OOD generalization problem. We use Centered Kernel Alignment\n(CKA), a similarity measure metric of neural network representations, to\nexamine the relationship between representation similarity and performance of\npre-trained Convolutional Neural Networks (CNNs) on the CAMELS Multifield\nDataset. We find that when models are robust to a distribution shift, they\nproduce substantially different representations across their layers on OOD\ndata. However, when they fail to generalize, these representations change less\nfrom layer to layer on OOD data. We discuss the potential application of\nsimilarity representation in guiding model design, training strategy, and\nmitigating the OOD problem by incorporating CKA as an inductive bias during\ntraining.",
            "author": [
                "Yash Gondhalekar",
                "Sultan Hassan",
                "Naomi Saphra",
                "Sambatra Andrianomena"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18007v1",
                "http://arxiv.org/pdf/2311.18007v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "astro-ph.GA",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.18002v1",
            "title": "Echoes in the Noise: Posterior Samples of Faint Galaxy Surface\n  Brightness Profiles with Score-Based Likelihoods and Priors",
            "updated": "2023-11-29T19:00:03Z",
            "published": "2023-11-29T19:00:03Z",
            "summary": "Examining the detailed structure of galaxy populations provides valuable\ninsights into their formation and evolution mechanisms. Significant barriers to\nsuch analysis are the non-trivial noise properties of real astronomical images\nand the point spread function (PSF) which blurs structure. Here we present a\nframework which combines recent advances in score-based likelihood\ncharacterization and diffusion model priors to perform a Bayesian analysis of\nimage deconvolution. The method, when applied to minimally processed\n\\emph{Hubble Space Telescope} (\\emph{HST}) data, recovers structures which have\notherwise only become visible in next-generation \\emph{James Webb Space\nTelescope} (\\emph{JWST}) imaging.",
            "author": [
                "Alexandre Adam",
                "Connor Stone",
                "Connor Bottrell",
                "Ronan Legin",
                "Yashar Hezaveh",
                "Laurence Perreault-Levasseur"
            ],
            "link": [
                "http://arxiv.org/abs/2311.18002v1",
                "http://arxiv.org/pdf/2311.18002v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17994v1",
            "title": "Machine Learning the Operator Content of the Critical Self-Dual\n  Ising-Higgs Gauge Model",
            "updated": "2023-11-29T19:00:00Z",
            "published": "2023-11-29T19:00:00Z",
            "summary": "We study the critical properties of the Ising-Higgs gauge theory in $(2+1)D$\nalong the self-dual line which have recently been a subject of debate. For the\nfirst time, using machine learning techniques, we determine the low energy\noperator content of the associated field theory. Our approach enables us to\nlargely refute the existence of an emergent current operator and with it the\nstanding conjecture that this transition is of the $XY^*$ universality class.\nWe contrast these results with the ones obtained for the $(2+1)D$ Ashkin-Teller\ntransverse field Ising model where we find the expected current operator. Our\nnumerical technique extends the recently proposed Real-Space Mutual Information\nallowing us to extract sub-leading non-linear operators. This allows a\ncontrolled and computationally scalable approach to target CFT spectrum and\ndiscern universality classes beyond $(1+1)D$ from Monte Carlo data.",
            "author": [
                "Lior Oppenheim",
                "Maciej Koch-Janusz",
                "Snir Gazit",
                "Zohar Ringel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17994v1",
                "http://arxiv.org/pdf/2311.17994v1"
            ],
            "primary_category": "cond-mat.str-el",
            "category": [
                "cond-mat.str-el",
                "cond-mat.dis-nn",
                "cond-mat.stat-mech",
                "hep-lat",
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17921v2",
            "title": "Do text-free diffusion models learn discriminative visual\n  representations?",
            "updated": "2023-11-30T03:02:58Z",
            "published": "2023-11-29T18:59:59Z",
            "summary": "While many unsupervised learning models focus on one family of tasks, either\ngenerative or discriminative, we explore the possibility of a unified\nrepresentation learner: a model which addresses both families of tasks\nsimultaneously. We identify diffusion models, a state-of-the-art method for\ngenerative tasks, as a prime candidate. Such models involve training a U-Net to\niteratively predict and remove noise, and the resulting model can synthesize\nhigh-fidelity, diverse, novel images. We find that the intermediate feature\nmaps of the U-Net are diverse, discriminative feature representations. We\npropose a novel attention mechanism for pooling feature maps and further\nleverage this mechanism as DifFormer, a transformer feature fusion of features\nfrom different diffusion U-Net blocks and noise steps. We also develop DifFeed,\na novel feedback mechanism tailored to diffusion. We find that diffusion models\nare better than GANs, and, with our fusion and feedback mechanisms, can compete\nwith state-of-the-art unsupervised image representation learning methods for\ndiscriminative tasks - image classification with full and semi-supervision,\ntransfer for fine-grained classification, object detection and segmentation,\nand semantic segmentation. Our project website\n(https://mgwillia.github.io/diffssl/) and code\n(https://github.com/soumik-kanad/diffssl) are available publicly.",
            "author": [
                "Soumik Mukhopadhyay",
                "Matthew Gwilliam",
                "Yosuke Yamaguchi",
                "Vatsal Agarwal",
                "Namitha Padmanabhan",
                "Archana Swaminathan",
                "Tianyi Zhou",
                "Abhinav Shrivastava"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17921v2",
                "http://arxiv.org/pdf/2311.17921v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17922v1",
            "title": "A Simple Recipe for Language-guided Domain Generalized Segmentation",
            "updated": "2023-11-29T18:59:59Z",
            "published": "2023-11-29T18:59:59Z",
            "summary": "Generalization to new domains not seen during training is one of the\nlong-standing goals and challenges in deploying neural networks in real-world\napplications. Existing generalization techniques necessitate substantial data\naugmentation, potentially sourced from external datasets, and aim at learning\ninvariant representations by imposing various alignment constraints.\nLarge-scale pretraining has recently shown promising generalization\ncapabilities, along with the potential of bridging different modalities. For\ninstance, the recent advent of vision-language models like CLIP has opened the\ndoorway for vision models to exploit the textual modality. In this paper, we\nintroduce a simple framework for generalizing semantic segmentation networks by\nemploying language as the source of randomization. Our recipe comprises three\nkey ingredients: i) the preservation of the intrinsic CLIP robustness through\nminimal fine-tuning, ii) language-driven local style augmentation, and iii)\nrandomization by locally mixing the source and augmented styles during\ntraining. Extensive experiments report state-of-the-art results on various\ngeneralization benchmarks. The code will be made available.",
            "author": [
                "Mohammad Fahes",
                "Tuan-Hung Vu",
                "Andrei Bursuc",
                "Patrick P\u00e9rez",
                "Raoul de Charette"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17922v1",
                "http://arxiv.org/pdf/2311.17922v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17916v1",
            "title": "WyCryst: Wyckoff Inorganic Crystal Generator Framework",
            "updated": "2023-11-29T18:59:31Z",
            "published": "2023-11-29T18:59:31Z",
            "summary": "Generative design marks a significant data-driven advancement in the\nexploration of novel inorganic materials, which entails learning the symmetry\nequivalent to the crystal structure prediction (CSP) task and subsequent\nlearning of their target properties. Many generative models have been developed\nin the last few years. However, these models so far lack the capacity to\nproduce crystals that obey the fundamental rules of crystal symmetry. This is\nbecause an important step in these previous approaches involves energy\nrelaxation on the generated crystal structures to find the ground state crystal\nstructure, typically using Density Functional Theory (DFT). More often than\nnot, this changes the symmetry of the structure, thereby changing the desired\nproperty and hence invalidating the original CSP. To address this, we introduce\na generative design framework (WyCryst), composed of three pivotal components:\n1) a Wyckoff position based inorganic crystal representation, 2) a\nproperty-directed VAE model and 3) an automated DFT workflow for structure\nrefinement. By implementing loss functions that punish non-realistic crystal\nstructures, our model selectively generates materials that follow the ground\ntruth of crystal symmetry in the form of Wyckoff representation for each Space\nGroup. In leave-one-out validation experiments, we successfully reproduce a\nvariety of existing materials: CaTiO3 (space group, SG No. 62 and 221), CsPbI3\n(SG No. 221), BaTiO3 (SG No. 160), and CuInS2 (SG No.122) for both ground state\nas well as polymorphic crystal structure predictions for desired compositions.\nWe also generate several new ternary materials not found in the inorganic\nmaterials database (Materials Project), which are proved to be stable,\nretaining their symmetry, and we also check their phonon stability, using our\nautomated DFT workflow highlighting the validity of our approach.",
            "author": [
                "Ruiming Zhu",
                "Wei Nong",
                "Shuya Yamazaki",
                "Kedar Hippalgaonkar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17916v1",
                "http://arxiv.org/pdf/2311.17916v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17914v1",
            "title": "Reconstruction of electromagnetic showers in calorimeters using Deep\n  Learning",
            "updated": "2023-11-29T18:59:05Z",
            "published": "2023-11-29T18:59:05Z",
            "summary": "The precise reconstruction of properties of photons and electrons in modern\nhigh energy physics detectors, such as the CMS or Atlas experiments, plays a\ncrucial role in numerous physics results. Conventional geometrical algorithms\nare used to reconstruct the energy and position of these particles from the\nshowers they induce in the electromagnetic calorimeter. Despite their accuracy\nand efficiency, these methods still suffer from several limitations, such as\nlow-energy background and limited capacity to reconstruct close-by particles.\nThis paper introduces an innovative machine-learning technique to measure the\nenergy and position of photons and electrons based on convolutional and graph\nneural networks, taking the geometry of the CMS electromagnetic calorimeter as\nan example. The developed network demonstrates a significant improvement in\nresolution both for photon energy and position predictions compared to the\nalgorithm used in CMS. Notably, one of the main advantages of this new approach\nis its ability to better distinguish between multiple close-by electromagnetic\nshowers.",
            "author": [
                "Polina Simkina",
                "Fabrice Couderc",
                "Julie Malcl\u00e8s",
                "Mehmet \u00d6zg\u00fcr Sahin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17914v1",
                "http://arxiv.org/pdf/2311.17914v1"
            ],
            "primary_category": "hep-ex",
            "category": [
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17910v1",
            "title": "HUGS: Human Gaussian Splats",
            "updated": "2023-11-29T18:56:32Z",
            "published": "2023-11-29T18:56:32Z",
            "summary": "Recent advances in neural rendering have improved both training and rendering\ntimes by orders of magnitude. While these methods demonstrate state-of-the-art\nquality and speed, they are designed for photogrammetry of static scenes and do\nnot generalize well to freely moving humans in the environment. In this work,\nwe introduce Human Gaussian Splats (HUGS) that represents an animatable human\ntogether with the scene using 3D Gaussian Splatting (3DGS). Our method takes\nonly a monocular video with a small number of (50-100) frames, and it\nautomatically learns to disentangle the static scene and a fully animatable\nhuman avatar within 30 minutes. We utilize the SMPL body model to initialize\nthe human Gaussians. To capture details that are not modeled by SMPL (e.g.\ncloth, hairs), we allow the 3D Gaussians to deviate from the human body model.\nUtilizing 3D Gaussians for animated humans brings new challenges, including the\nartifacts created when articulating the Gaussians. We propose to jointly\noptimize the linear blend skinning weights to coordinate the movements of\nindividual Gaussians during animation. Our approach enables novel-pose\nsynthesis of human and novel view synthesis of both the human and the scene. We\nachieve state-of-the-art rendering quality with a rendering speed of 60 FPS\nwhile being ~100x faster to train over previous work. Our code will be\nannounced here: https://github.com/apple/ml-hugs",
            "author": [
                "Muhammed Kocabas",
                "Jen-Hao Rick Chang",
                "James Gabriel",
                "Oncel Tuzel",
                "Anurag Ranjan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17910v1",
                "http://arxiv.org/pdf/2311.17910v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17901v1",
            "title": "SODA: Bottleneck Diffusion Models for Representation Learning",
            "updated": "2023-11-29T18:53:34Z",
            "published": "2023-11-29T18:53:34Z",
            "summary": "We introduce SODA, a self-supervised diffusion model, designed for\nrepresentation learning. The model incorporates an image encoder, which\ndistills a source view into a compact representation, that, in turn, guides the\ngeneration of related novel views. We show that by imposing a tight bottleneck\nbetween the encoder and a denoising decoder, and leveraging novel view\nsynthesis as a self-supervised objective, we can turn diffusion models into\nstrong representation learners, capable of capturing visual semantics in an\nunsupervised manner. To the best of our knowledge, SODA is the first diffusion\nmodel to succeed at ImageNet linear-probe classification, and, at the same\ntime, it accomplishes reconstruction, editing and synthesis tasks across a wide\nrange of datasets. Further investigation reveals the disentangled nature of its\nemergent latent space, that serves as an effective interface to control and\nmanipulate the model's produced images. All in all, we aim to shed light on the\nexciting and promising potential of diffusion models, not only for image\ngeneration, but also for learning rich and robust representations.",
            "author": [
                "Drew A. Hudson",
                "Daniel Zoran",
                "Mateusz Malinowski",
                "Andrew K. Lampinen",
                "Andrew Jaegle",
                "James L. McClelland",
                "Loic Matthey",
                "Felix Hill",
                "Alexander Lerchner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17901v1",
                "http://arxiv.org/pdf/2311.17901v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17898v2",
            "title": "Knowledge Pursuit Prompting for Zero-Shot Multimodal Synthesis",
            "updated": "2023-11-30T18:59:01Z",
            "published": "2023-11-29T18:51:46Z",
            "summary": "Hallucinations and unfaithful synthesis due to inaccurate prompts with\ninsufficient semantic details are widely observed in multimodal generative\nmodels. A prevalent strategy to align multiple modalities is to fine-tune the\ngenerator with a large number of annotated text-image pairs. However, such a\nprocedure is labor-consuming and resource-draining. The key question we ask is:\ncan we enhance the quality and faithfulness of text-driven generative models\nbeyond extensive text-image pair annotations? To address this question, we\npropose Knowledge Pursuit Prompting (KPP), a zero-shot framework that\niteratively incorporates external knowledge to help generators produce reliable\nvisual content. Instead of training generators to handle generic prompts, KPP\nemploys a recursive knowledge query process to gather informative external\nfacts from the knowledge base, instructs a language model to compress the\nacquired knowledge for prompt refinement, and utilizes text-driven generators\nfor visual synthesis. The entire process is zero-shot, without accessing the\narchitectures and parameters of generative models. We evaluate the framework\nacross multiple text-driven generative tasks (image, 3D rendering, and video)\non datasets of different domains. We further demonstrate the extensibility and\nadaptability of KPP through varying foundation model bases and instructions.\nOur results show that KPP is capable of generating faithful and semantically\nrich content across diverse visual domains, offering a promising solution to\nimprove multimodal generative models.",
            "author": [
                "Jinqi Luo",
                "Kwan Ho Ryan Chan",
                "Dimitris Dimos",
                "Ren\u00e9 Vidal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17898v2",
                "http://arxiv.org/pdf/2311.17898v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17983v1",
            "title": "Improving Faithfulness for Vision Transformers",
            "updated": "2023-11-29T18:51:21Z",
            "published": "2023-11-29T18:51:21Z",
            "summary": "Vision Transformers (ViTs) have achieved state-of-the-art performance for\nvarious vision tasks. One reason behind the success lies in their ability to\nprovide plausible innate explanations for the behavior of neural architectures.\nHowever, ViTs suffer from issues with explanation faithfulness, as their focal\npoints are fragile to adversarial attacks and can be easily changed with even\nslight perturbations on the input image. In this paper, we propose a rigorous\napproach to mitigate these issues by introducing Faithful ViTs (FViTs). Briefly\nspeaking, an FViT should have the following two properties: (1) The top-$k$\nindices of its self-attention vector should remain mostly unchanged under input\nperturbation, indicating stable explanations; (2) The prediction distribution\nshould be robust to perturbations. To achieve this, we propose a new method\ncalled Denoised Diffusion Smoothing (DDS), which adopts randomized smoothing\nand diffusion-based denoising. We theoretically prove that processing ViTs\ndirectly with DDS can turn them into FViTs. We also show that Gaussian noise is\nnearly optimal for both $\\ell_2$ and $\\ell_\\infty$-norm cases. Finally, we\ndemonstrate the effectiveness of our approach through comprehensive experiments\nand evaluations. Specifically, we compare our FViTs with other baselines\nthrough visual interpretation and robustness accuracy under adversarial\nattacks. Results show that FViTs are more robust against adversarial attacks\nwhile maintaining the explainability of attention, indicating higher\nfaithfulness.",
            "author": [
                "Lijie Hu",
                "Yixin Liu",
                "Ninghao Liu",
                "Mengdi Huai",
                "Lichao Sun",
                "Di Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17983v1",
                "http://arxiv.org/pdf/2311.17983v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17895v1",
            "title": "Measurements of the Thermal and Ionization State of the Intergalactic\n  Medium during the Cosmic Afternoon",
            "updated": "2023-11-29T18:48:51Z",
            "published": "2023-11-29T18:48:51Z",
            "summary": "We perform the first measurement of the thermal and ionization state of the\nintergalactic medium (IGM) across 0.9 < z < 1.5 using 301 \\lya absorption lines\nfitted from 12 HST STIS quasar spectra, with a total pathlength of \\Delta\nz=2.1. We employ the machine-learning-based inference method that uses joint\nb-N distributions obtained from \\lyaf decomposition. Our results show that the\nHI photoionization rates, \\Gamma, are in good agreement with the recent UV\nbackground synthesis models, with \\log (\\Gamma/s^{-1})={-11.79}^{0.18}_{-0.15},\n-11.98}^{0.09}_{-0.09}, and {-12.32}^{0.10}_{-0.12} at z=1.4, 1.2, and 1\nrespectively. We obtain the IGM temperature at the mean density, T_0, and the\nadiabatic index, \\gamma, as [\\log (T_0/K), \\gamma]= [{4.13}^{+0.12}_{-0.10},\n{1.34}^{+0.10}_{-0.15}], [{3.79}^{+0.11}_{-0.11}, {1.70}^{+0.09}_{-0.09}] and\n[{4.12}^{+0.15}_{-0.25}, {1.34}^{+0.21}_{-0.26}] at z=1.4, 1.2 and 1\nrespectively. Our measurements of T_0 at z=1.4 and 1.2 are consistent with the\nexpected trend from z<3 temperature measurements as well as theoretical\nexpectations that, in the absence of any non-standard heating, the IGM should\ncool down after HeII reionization. Whereas, our T_0 measurements at z=1 show\nunexpectedly high IGM temperature. However, because of the relatively large\nuncertainty in these measurements of the order of \\Delta T_0~5000 K, mostly\nemanating from the limited redshift path length of available data in these\nbins, we can not definitively conclude whether the IGM cools down at z<1.5.\nLastly, we generate a mock dataset to test the constraining power of future\nmeasurement with larger datasets. The results demonstrate that, with redshift\npathlength \\Delta z \\sim 2 for each redshift bin, three times the current\ndataset, we can constrain the T_0 of IGM within 1500K. Such precision would be\nsufficient to conclusively constrain the history of IGM thermal evolution at z\n< 1.5.",
            "author": [
                "Teng Hu",
                "Vikram Khaire",
                "Joseph F. Hennawi",
                "Todd M. Tripp",
                "Jose O\u00f1orbe",
                "Michael Walther",
                "Zarija Lukic"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17895v1",
                "http://arxiv.org/pdf/2311.17895v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17892v1",
            "title": "A Pipeline For Discourse Circuits From CCG",
            "updated": "2023-11-29T18:46:29Z",
            "published": "2023-11-29T18:46:29Z",
            "summary": "There is a significant disconnect between linguistic theory and modern NLP\npractice, which relies heavily on inscrutable black-box architectures.\nDisCoCirc is a newly proposed model for meaning that aims to bridge this\ndivide, by providing neuro-symbolic models that incorporate linguistic\nstructure. DisCoCirc represents natural language text as a `circuit' that\ncaptures the core semantic information of the text. These circuits can then be\ninterpreted as modular machine learning models. Additionally, DisCoCirc fulfils\nanother major aim of providing an NLP model that can be implemented on\nnear-term quantum computers.\n  In this paper we describe a software pipeline that converts English text to\nits DisCoCirc representation. The pipeline achieves coverage over a large\nfragment of the English language. It relies on Combinatory Categorial Grammar\n(CCG) parses of the input text as well as coreference resolution information.\nThis semantic and syntactic information is used in several steps to convert the\ntext into a simply-typed $\\lambda$-calculus term, and then into a circuit\ndiagram. This pipeline will enable the application of the DisCoCirc framework\nto NLP tasks, using both classical and quantum approaches.",
            "author": [
                "Jonathon Liu",
                "Razin A. Shaikh",
                "Benjamin Rodatz",
                "Richie Yeung",
                "Bob Coecke"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17892v1",
                "http://arxiv.org/pdf/2311.17892v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17885v1",
            "title": "Are ensembles getting better all the time?",
            "updated": "2023-11-29T18:32:37Z",
            "published": "2023-11-29T18:32:37Z",
            "summary": "Ensemble methods combine the predictions of several base models. We study\nwhether or not including more models in an ensemble always improve its average\nperformance. Such a question depends on the kind of ensemble considered, as\nwell as the predictive metric chosen. We focus on situations where all members\nof the ensemble are a priori expected to perform as well, which is the case of\nseveral popular methods like random forests or deep ensembles. In this setting,\nwe essentially show that ensembles are getting better all the time if, and only\nif, the considered loss function is convex. More precisely, in that case, the\naverage loss of the ensemble is a decreasing function of the number of models.\nWhen the loss function is nonconvex, we show a series of results that can be\nsummarised by the insight that ensembles of good models keep getting better,\nand ensembles of bad models keep getting worse. To this end, we prove a new\nresult on the monotonicity of tail probabilities that may be of independent\ninterest. We illustrate our results on a simple machine learning problem\n(diagnosing melanomas using neural nets).",
            "author": [
                "Pierre-Alexandre Mattei",
                "Damien Garreau"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17885v1",
                "http://arxiv.org/pdf/2311.17885v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "math.ST",
                "stat.ME",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17869v1",
            "title": "SAIBench: A Structural Interpretation of AI for Science Through\n  Benchmarks",
            "updated": "2023-11-29T18:17:35Z",
            "published": "2023-11-29T18:17:35Z",
            "summary": "Artificial Intelligence for Science (AI4S) is an emerging research field that\nutilizes machine learning advancements to tackle complex scientific\ncomputational issues, aiming to enhance computational efficiency and accuracy.\nHowever, the data-driven nature of AI4S lacks the correctness or accuracy\nassurances of conventional scientific computing, posing challenges when\ndeploying AI4S models in real-world applications. To mitigate these, more\ncomprehensive benchmarking procedures are needed to better understand AI4S\nmodels. This paper introduces a novel benchmarking approach, known as\nstructural interpretation, which addresses two key requirements: identifying\nthe trusted operating range in the problem space and tracing errors back to\ntheir computational components. This method partitions both the problem and\nmetric spaces, facilitating a structural exploration of these spaces. The\npractical utility and effectiveness of structural interpretation are\nillustrated through its application to three distinct AI4S workloads:\nmachine-learning force fields (MLFF), jet tagging, and precipitation\nnowcasting. The benchmarks effectively model the trusted operating range, trace\nerrors, and reveal novel perspectives for refining the model, training process,\nand data sampling strategy. This work is part of the SAIBench project, an AI4S\nbenchmarking suite.",
            "author": [
                "Yatao Li",
                "Jianfeng Zhan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17869v1",
                "http://arxiv.org/pdf/2311.17869v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17858v1",
            "title": "On the Limits of Regression Adjustment",
            "updated": "2023-11-29T18:04:39Z",
            "published": "2023-11-29T18:04:39Z",
            "summary": "Regression adjustment, sometimes known as Controlled-experiment Using\nPre-Experiment Data (CUPED), is an important technique in internet\nexperimentation. It decreases the variance of effect size estimates, often\ncutting confidence interval widths in half or more while never making them\nworse. It does so by carefully regressing the goal metric against\npre-experiment features to reduce the variance. The tremendous gains of\nregression adjustment begs the question: How much better can we do by\nengineering better features from pre-experiment data, for example by using\nmachine learning techniques or synthetic controls? Could we even reduce the\nvariance in our effect sizes arbitrarily close to zero with the right\npredictors? Unfortunately, our answer is negative. A simple form of regression\nadjustment, which uses just the pre-experiment values of the goal metric,\ncaptures most of the benefit. Specifically, under a mild assumption that\nobservations closer in time are easier to predict that ones further away in\ntime, we upper bound the potential gains of more sophisticated feature\nengineering, with respect to the gains of this simple form of regression\nadjustment. The maximum reduction in variance is $50\\%$ in Theorem 1, or\nequivalently, the confidence interval width can be reduced by at most an\nadditional $29\\%$.",
            "author": [
                "Daniel Ting",
                "Kenneth Hung"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17858v1",
                "http://arxiv.org/pdf/2311.17858v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "econ.EM",
                "62P30",
                "G.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17856v1",
            "title": "Leveraging Graph Diffusion Models for Network Refinement Tasks",
            "updated": "2023-11-29T18:02:29Z",
            "published": "2023-11-29T18:02:29Z",
            "summary": "Most real-world networks are noisy and incomplete samples from an unknown\ntarget distribution. Refining them by correcting corruptions or inferring\nunobserved regions typically improves downstream performance. Inspired by the\nimpressive generative capabilities that have been used to correct corruptions\nin images, and the similarities between \"in-painting\" and filling in missing\nnodes and edges conditioned on the observed graph, we propose a novel graph\ngenerative framework, SGDM, which is based on subgraph diffusion. Our framework\nnot only improves the scalability and fidelity of graph diffusion models, but\nalso leverages the reverse process to perform novel, conditional generation\ntasks. In particular, through extensive empirical analysis and a set of novel\nmetrics, we demonstrate that our proposed model effectively supports the\nfollowing refinement tasks for partially observable networks: T1: denoising\nextraneous subgraphs, T2: expanding existing subgraphs and T3: performing\n\"style\" transfer by regenerating a particular subgraph to match the\ncharacteristics of a different node or subgraph.",
            "author": [
                "Puja Trivedi",
                "Ryan Rossi",
                "David Arbour",
                "Tong Yu",
                "Franck Dernoncourt",
                "Sungchul Kim",
                "Nedim Lipka",
                "Namyong Park",
                "Nesreen K. Ahmed",
                "Danai Koutra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17856v1",
                "http://arxiv.org/pdf/2311.17856v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17855v1",
            "title": "Maximum Entropy Model Correction in Reinforcement Learning",
            "updated": "2023-11-29T18:00:41Z",
            "published": "2023-11-29T18:00:41Z",
            "summary": "We propose and theoretically analyze an approach for planning with an\napproximate model in reinforcement learning that can reduce the adverse impact\nof model error. If the model is accurate enough, it accelerates the convergence\nto the true value function too. One of its key components is the MaxEnt Model\nCorrection (MoCo) procedure that corrects the model's next-state distributions\nbased on a Maximum Entropy density estimation formulation. Based on MoCo, we\nintroduce the Model Correcting Value Iteration (MoCoVI) algorithm, and its\nsampled-based variant MoCoDyna. We show that MoCoVI and MoCoDyna's convergence\ncan be much faster than the conventional model-free algorithms. Unlike\ntraditional model-based algorithms, MoCoVI and MoCoDyna effectively utilize an\napproximate model and still converge to the correct value function.",
            "author": [
                "Amin Rakhsha",
                "Mete Kemertas",
                "Mohammad Ghavamzadeh",
                "Amir-massoud Farahmand"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17855v1",
                "http://arxiv.org/pdf/2311.17855v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.SY",
                "eess.SY",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17853v2",
            "title": "On the Adversarial Robustness of Graph Contrastive Learning Methods",
            "updated": "2023-11-30T19:03:33Z",
            "published": "2023-11-29T17:59:18Z",
            "summary": "Contrastive learning (CL) has emerged as a powerful framework for learning\nrepresentations of images and text in a self-supervised manner while enhancing\nmodel robustness against adversarial attacks. More recently, researchers have\nextended the principles of contrastive learning to graph-structured data,\ngiving birth to the field of graph contrastive learning (GCL). However, whether\nGCL methods can deliver the same advantages in adversarial robustness as their\ncounterparts in the image and text domains remains an open question. In this\npaper, we introduce a comprehensive robustness evaluation protocol tailored to\nassess the robustness of GCL models. We subject these models to adaptive\nadversarial attacks targeting the graph structure, specifically in the evasion\nscenario. We evaluate node and graph classification tasks using diverse\nreal-world datasets and attack strategies. With our work, we aim to offer\ninsights into the robustness of GCL methods and hope to open avenues for\npotential future research directions.",
            "author": [
                "Filippo Guerranti",
                "Zinuo Yi",
                "Anna Starovoit",
                "Rafiq Kamel",
                "Simon Geisler",
                "Stephan G\u00fcnnemann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17853v2",
                "http://arxiv.org/pdf/2311.17853v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17852v1",
            "title": "A Computing-in-Memory-based One-Class Hyperdimensional Computing Model\n  for Outlier Detection",
            "updated": "2023-11-29T17:56:51Z",
            "published": "2023-11-29T17:56:51Z",
            "summary": "In this work, we present ODHD, an algorithm for outlier detection based on\nhyperdimensional computing (HDC), a non-classical learning paradigm. Along with\nthe HDC-based algorithm, we propose IM-ODHD, a computing-in-memory (CiM)\nimplementation based on hardware/software (HW/SW) codesign for improved latency\nand energy efficiency. The training and testing phases of ODHD may be performed\nwith conventional CPU/GPU hardware or our IM-ODHD, SRAM-based CiM architecture\nusing the proposed HW/SW codesign techniques. We evaluate the performance of\nODHD on six datasets from different application domains using three metrics,\nnamely accuracy, F1 score, and ROC-AUC, and compare it with multiple baseline\nmethods such as OCSVM, isolation forest, and autoencoder. The experimental\nresults indicate that ODHD outperforms all the baseline methods in terms of\nthese three metrics on every dataset for both CPU/GPU and CiM implementations.\nFurthermore, we perform an extensive design space exploration to demonstrate\nthe tradeoff between delay, energy efficiency, and performance of ODHD. We\ndemonstrate that the HW/SW codesign implementation of the outlier detection on\nIM-ODHD is able to outperform the GPU-based implementation of ODHD by at least\n293x/419x in terms of training/testing latency (and on average 16.0x/15.9x in\nterms of training/testing energy consumption).",
            "author": [
                "Ruixuan Wang",
                "Sabrina Hassan Moon",
                "Xiaobo Sharon Hu",
                "Xun Jiao",
                "Dayane Reis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17852v1",
                "http://arxiv.org/pdf/2311.17852v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17851v1",
            "title": "Evaluating VLMs for Score-Based, Multi-Probe Annotation of 3D Objects",
            "updated": "2023-11-29T17:54:22Z",
            "published": "2023-11-29T17:54:22Z",
            "summary": "Unlabeled 3D objects present an opportunity to leverage pretrained vision\nlanguage models (VLMs) on a range of annotation tasks -- from describing object\nsemantics to physical properties. An accurate response must take into account\nthe full appearance of the object in 3D, various ways of phrasing the\nquestion/prompt, and changes in other factors that affect the response. We\npresent a method to marginalize over any factors varied across VLM queries,\nutilizing the VLM's scores for sampled responses. We first show that this\nprobabilistic aggregation can outperform a language model (e.g., GPT4) for\nsummarization, for instance avoiding hallucinations when there are contrasting\ndetails between responses. Secondly, we show that aggregated annotations are\nuseful for prompt-chaining; they help improve downstream VLM predictions (e.g.,\nof object material when the object's type is specified as an auxiliary input in\nthe prompt). Such auxiliary inputs allow ablating and measuring the\ncontribution of visual reasoning over language-only reasoning. Using these\nevaluations, we show how VLMs can approach, without additional training or\nin-context learning, the quality of human-verified type and material\nannotations on the large-scale Objaverse dataset.",
            "author": [
                "Rishabh Kabra",
                "Loic Matthey",
                "Alexander Lerchner",
                "Niloy J. Mitra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17851v1",
                "http://arxiv.org/pdf/2311.17851v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17847v1",
            "title": "FastSample: Accelerating Distributed Graph Neural Network Training for\n  Billion-Scale Graphs",
            "updated": "2023-11-29T17:49:48Z",
            "published": "2023-11-29T17:49:48Z",
            "summary": "Training Graph Neural Networks(GNNs) on a large monolithic graph presents\nunique challenges as the graph cannot fit within a single machine and it cannot\nbe decomposed into smaller disconnected components. Distributed sampling-based\ntraining distributes the graph across multiple machines and trains the GNN on\nsmall parts of the graph that are randomly sampled every training iteration. We\nshow that in a distributed environment, the sampling overhead is a significant\ncomponent of the training time for large-scale graphs. We propose FastSample\nwhich is composed of two synergistic techniques that greatly reduce the\ndistributed sampling time: 1)a new graph partitioning method that eliminates\nmost of the communication rounds in distributed sampling , 2)a novel highly\noptimized sampling kernel that reduces memory movement during sampling. We test\nFastSample on large-scale graph benchmarks and show that FastSample speeds up\ndistributed sampling-based GNN training by up to 2x with no loss in accuracy.",
            "author": [
                "Hesham Mostafa",
                "Adam Grabowski",
                "Md Asadullah Turja",
                "Juan Cervino",
                "Alejandro Ribeiro",
                "Nageen Himayat"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17847v1",
                "http://arxiv.org/pdf/2311.17847v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17846v1",
            "title": "Towards Real-World Focus Stacking with Deep Learning",
            "updated": "2023-11-29T17:49:33Z",
            "published": "2023-11-29T17:49:33Z",
            "summary": "Focus stacking is widely used in micro, macro, and landscape photography to\nreconstruct all-in-focus images from multiple frames obtained with focus\nbracketing, that is, with shallow depth of field and different focus planes.\nExisting deep learning approaches to the underlying multi-focus image fusion\nproblem have limited applicability to real-world imagery since they are\ndesigned for very short image sequences (two to four images), and are typically\ntrained on small, low-resolution datasets either acquired by light-field\ncameras or generated synthetically. We introduce a new dataset consisting of 94\nhigh-resolution bursts of raw images with focus bracketing, with pseudo ground\ntruth computed from the data using state-of-the-art commercial software. This\ndataset is used to train the first deep learning algorithm for focus stacking\ncapable of handling bursts of sufficient length for real-world applications.\nQualitative experiments demonstrate that it is on par with existing commercial\nsolutions in the long-burst, realistic regime while being significantly more\ntolerant to noise. The code and dataset are available at\nhttps://github.com/araujoalexandre/FocusStackingDataset.",
            "author": [
                "Alexandre Araujo",
                "Jean Ponce",
                "Julien Mairal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17846v1",
                "http://arxiv.org/pdf/2311.17846v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17842v1",
            "title": "Look Before You Leap: Unveiling the Power of GPT-4V in Robotic\n  Vision-Language Planning",
            "updated": "2023-11-29T17:46:25Z",
            "published": "2023-11-29T17:46:25Z",
            "summary": "In this study, we are interested in imbuing robots with the capability of\nphysically-grounded task planning. Recent advancements have shown that large\nlanguage models (LLMs) possess extensive knowledge useful in robotic tasks,\nespecially in reasoning and planning. However, LLMs are constrained by their\nlack of world grounding and dependence on external affordance models to\nperceive environmental information, which cannot jointly reason with LLMs. We\nargue that a task planner should be an inherently grounded, unified multimodal\nsystem. To this end, we introduce Robotic Vision-Language Planning (ViLa), a\nnovel approach for long-horizon robotic planning that leverages vision-language\nmodels (VLMs) to generate a sequence of actionable steps. ViLa directly\nintegrates perceptual data into its reasoning and planning process, enabling a\nprofound understanding of commonsense knowledge in the visual world, including\nspatial layouts and object attributes. It also supports flexible multimodal\ngoal specification and naturally incorporates visual feedback. Our extensive\nevaluation, conducted in both real-robot and simulated environments,\ndemonstrates ViLa's superiority over existing LLM-based planners, highlighting\nits effectiveness in a wide array of open-world manipulation tasks.",
            "author": [
                "Yingdong Hu",
                "Fanqi Lin",
                "Tong Zhang",
                "Li Yi",
                "Yang Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17842v1",
                "http://arxiv.org/pdf/2311.17842v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CL",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17840v1",
            "title": "A quasi-polynomial time algorithm for Multi-Dimensional Scaling via LP\n  hierarchies",
            "updated": "2023-11-29T17:42:05Z",
            "published": "2023-11-29T17:42:05Z",
            "summary": "Multi-dimensional Scaling (MDS) is a family of methods for embedding\npair-wise dissimilarities between $n$ objects into low-dimensional space. MDS\nis widely used as a data visualization tool in the social and biological\nsciences, statistics, and machine learning. We study the Kamada-Kawai\nformulation of MDS: given a set of non-negative dissimilarities $\\{d_{i,j}\\}_{i\n, j \\in [n]}$ over $n$ points, the goal is to find an embedding\n$\\{x_1,\\dots,x_n\\} \\subset \\mathbb{R}^k$ that minimizes \\[ \\text{OPT} =\n\\min_{x} \\mathbb{E}_{i,j \\in [n]} \\left[ \\left(1-\\frac{\\|x_i -\nx_j\\|}{d_{i,j}}\\right)^2 \\right] \\]\n  Despite its popularity, our theoretical understanding of MDS is extremely\nlimited. Recently, Demaine, Hesterberg, Koehler, Lynch, and Urschel\n(arXiv:2109.11505) gave the first approximation algorithm with provable\nguarantees for Kamada-Kawai, which achieves an embedding with cost $\\text{OPT}\n+\\epsilon$ in $n^2 \\cdot 2^{\\tilde{\\mathcal{O}}(k \\Delta^4 / \\epsilon^2)}$\ntime, where $\\Delta$ is the aspect ratio of the input dissimilarities. In this\nwork, we give the first approximation algorithm for MDS with quasi-polynomial\ndependency on $\\Delta$: for target dimension $k$, we achieve a solution with\ncost $\\mathcal{O}(\\text{OPT}^{ \\hspace{0.04in}1/k } \\cdot \\log(\\Delta/\\epsilon)\n)+ \\epsilon$ in time $n^{ \\mathcal{O}(1)} \\cdot 2^{\\tilde{\\mathcal{O}}( k^2\n(\\log(\\Delta)/\\epsilon)^{k/2 + 1} ) }$.\n  Our approach is based on a novel analysis of a conditioning-based rounding\nscheme for the Sherali-Adams LP Hierarchy. Crucially, our analysis exploits the\ngeometry of low-dimensional Euclidean space, allowing us to avoid an\nexponential dependence on the aspect ratio $\\Delta$. We believe our\ngeometry-aware treatment of the Sherali-Adams Hierarchy is an important step\ntowards developing general-purpose techniques for efficient metric optimization\nalgorithms.",
            "author": [
                "Ainesh Bakshi",
                "Vincent Cohen-Addad",
                "Samuel B. Hopkins",
                "Rajesh Jayaram",
                "Silvio Lattanzi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17840v1",
                "http://arxiv.org/pdf/2311.17840v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17834v2",
            "title": "SPiC-E : Structural Priors in 3D Diffusion Models using Cross-Entity\n  Attention",
            "updated": "2023-11-30T12:59:21Z",
            "published": "2023-11-29T17:36:49Z",
            "summary": "We are witnessing rapid progress in automatically generating and manipulating\n3D assets due to the availability of pretrained text-image diffusion models.\nHowever, time-consuming optimization procedures are required for synthesizing\neach sample, hindering their potential for democratizing 3D content creation.\nConversely, 3D diffusion models now train on million-scale 3D datasets,\nyielding high-quality text-conditional 3D samples within seconds. In this work,\nwe present SPiC-E - a neural network that adds structural guidance to 3D\ndiffusion models, extending their usage beyond text-conditional generation. At\nits core, our framework introduces a cross-entity attention mechanism that\nallows for multiple entities (in particular, paired input and guidance 3D\nshapes) to interact via their internal representations within the denoising\nnetwork. We utilize this mechanism for learning task-specific structural priors\nin 3D diffusion models from auxiliary guidance shapes. We show that our\napproach supports a variety of applications, including 3D stylization, semantic\nshape editing and text-conditional abstraction-to-3D, which transforms\nprimitive-based abstractions into highly-expressive shapes. Extensive\nexperiments demonstrate that SPiC-E achieves SOTA performance over these tasks\nwhile often being considerably faster than alternative methods. Importantly,\nthis is accomplished without tailoring our approach for any specific task.",
            "author": [
                "Etai Sella",
                "Gal Fiebelman",
                "Noam Atia",
                "Hadar Averbuch-Elor"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17834v2",
                "http://arxiv.org/pdf/2311.17834v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17833v1",
            "title": "Analyzing and Explaining Image Classifiers via Diffusion Guidance",
            "updated": "2023-11-29T17:35:29Z",
            "published": "2023-11-29T17:35:29Z",
            "summary": "While deep learning has led to huge progress in complex image classification\ntasks like ImageNet, unexpected failure modes, e.g. via spurious features, call\ninto question how reliably these classifiers work in the wild. Furthermore, for\nsafety-critical tasks the black-box nature of their decisions is problematic,\nand explanations or at least methods which make decisions plausible are needed\nurgently. In this paper, we address these problems by generating images that\noptimize a classifier-derived objective using a framework for guided image\ngeneration. We analyze the behavior and decisions of image classifiers by\nvisual counterfactual explanations (VCEs), detection of systematic mistakes by\nanalyzing images where classifiers maximally disagree, and visualization of\nneurons to verify potential spurious features. In this way, we validate\nexisting observations, e.g. the shape bias of adversarially robust models, as\nwell as novel failure modes, e.g. systematic errors of zero-shot CLIP\nclassifiers, or identify harmful spurious features. Moreover, our VCEs\noutperform previous work while being more versatile.",
            "author": [
                "Maximilian Augustin",
                "Yannic Neuhaus",
                "Matthias Hein"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17833v1",
                "http://arxiv.org/pdf/2311.17833v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17978v1",
            "title": "AutArch: An AI-assisted workflow for object detection and automated\n  recording in archaeological catalogues",
            "updated": "2023-11-29T17:24:04Z",
            "published": "2023-11-29T17:24:04Z",
            "summary": "Compiling large datasets from published resources, such as archaeological\nfind catalogues presents fundamental challenges: identifying relevant content\nand manually recording it is a time-consuming, repetitive and error-prone task.\nFor the data to be useful, it must be of comparable quality and adhere to the\nsame recording standards, which is hardly ever the case in archaeology. Here,\nwe present a new data collection method exploiting recent advances in\nArtificial Intelligence. Our software uses an object detection neural network\ncombined with further classification networks to speed up, automate, and\nstandardise data collection from legacy resources, such as archaeological\ndrawings and photographs in large unsorted PDF files. The AI-assisted workflow\ndetects common objects found in archaeological catalogues, such as graves,\nskeletons, ceramics, ornaments, stone tools and maps, and spatially relates and\nanalyses these objects on the page to extract real-life attributes, such as the\nsize and orientation of a grave based on the north arrow and the scale. A\ngraphical interface allows for and assists with manual validation. We\ndemonstrate the benefits of this approach by collecting a range of shapes and\nnumerical attributes from richly-illustrated archaeological catalogues, and\nbenchmark it in a real-world experiment with ten users. Moreover, we record\ngeometric whole-outlines through contour detection, an alternative to\nlandmark-based geometric morphometrics not achievable by hand.",
            "author": [
                "Kevin Klein",
                "Alyssa Wohde",
                "Alexander V. Gorelik",
                "Volker Heyd",
                "Yoan Diekmann",
                "Maxime Brami"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17978v1",
                "http://arxiv.org/pdf/2311.17978v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17815v1",
            "title": "A Survey on Design Methodologies for Accelerating Deep Learning on\n  Heterogeneous Architectures",
            "updated": "2023-11-29T17:10:16Z",
            "published": "2023-11-29T17:10:16Z",
            "summary": "In recent years, the field of Deep Learning has seen many disruptive and\nimpactful advancements. Given the increasing complexity of deep neural\nnetworks, the need for efficient hardware accelerators has become more and more\npressing to design heterogeneous HPC platforms. The design of Deep Learning\naccelerators requires a multidisciplinary approach, combining expertise from\nseveral areas, spanning from computer architecture to approximate computing,\ncomputational models, and machine learning algorithms. Several methodologies\nand tools have been proposed to design accelerators for Deep Learning,\nincluding hardware-software co-design approaches, high-level synthesis methods,\nspecific customized compilers, and methodologies for design space exploration,\nmodeling, and simulation. These methodologies aim to maximize the exploitable\nparallelism and minimize data movement to achieve high performance and energy\nefficiency. This survey provides a holistic review of the most influential\ndesign methodologies and EDA tools proposed in recent years to implement Deep\nLearning accelerators, offering the reader a wide perspective in this rapidly\nevolving field. In particular, this work complements the previous survey\nproposed by the same authors in [203], which focuses on Deep Learning hardware\naccelerators for heterogeneous HPC platforms.",
            "author": [
                "Fabrizio Ferrandi",
                "Serena Curzel",
                "Leandro Fiorin",
                "Daniele Ielmini",
                "Cristina Silvano",
                "Francesco Conti",
                "Alessio Burrello",
                "Francesco Barchi",
                "Luca Benini",
                "Luciano Lavagno",
                "Teodoro Urso",
                "Enrico Calore",
                "Sebastiano Fabio Schifano",
                "Cristian Zambelli",
                "Maurizio Palesi",
                "Giuseppe Ascia",
                "Enrico Russo",
                "Nicola Petra",
                "Davide De Caro",
                "Gennaro Di Meo",
                "Valeria Cardellini",
                "Salvatore Filippone",
                "Francesco Lo Presti",
                "Francesco Silvestri",
                "Paolo Palazzari",
                "Stefania Perri"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17815v1",
                "http://arxiv.org/pdf/2311.17815v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17812v2",
            "title": "DAP: Domain-aware Prompt Learning for Vision-and-Language Navigation",
            "updated": "2023-11-30T11:28:59Z",
            "published": "2023-11-29T17:03:37Z",
            "summary": "Following language instructions to navigate in unseen environments is a\nchallenging task for autonomous embodied agents. With strong representation\ncapabilities, pretrained vision-and-language models are widely used in VLN.\nHowever, most of them are trained on web-crawled general-purpose datasets,\nwhich incurs a considerable domain gap when used for VLN tasks. To address the\nproblem, we propose a novel and model-agnostic domain-aware prompt learning\n(DAP) framework. For equipping the pretrained models with specific object-level\nand scene-level cross-modal alignment in VLN tasks, DAP applies a low-cost\nprompt tuning paradigm to learn soft visual prompts for extracting in-domain\nimage semantics. Specifically, we first generate a set of in-domain image-text\npairs with the help of the CLIP model. Then we introduce soft visual prompts in\nthe input space of the visual encoder in a pretrained model. DAP injects\nin-domain visual knowledge into the visual encoder of the pretrained model in\nan efficient way. Experimental results on both R2R and REVERIE show the\nsuperiority of DAP compared to existing state-of-the-art methods.",
            "author": [
                "Ting Liu",
                "Yue Hu",
                "Wansen Wu",
                "Youkai Wang",
                "Kai Xu",
                "Quanjun Yin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17812v2",
                "http://arxiv.org/pdf/2311.17812v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17804v1",
            "title": "Aggregation Model Hyperparameters Matter in Digital Pathology",
            "updated": "2023-11-29T16:54:25Z",
            "published": "2023-11-29T16:54:25Z",
            "summary": "Digital pathology has significantly advanced disease detection and\npathologist efficiency through the analysis of gigapixel whole-slide images\n(WSI). In this process, WSIs are first divided into patches, for which a\nfeature extractor model is applied to obtain feature vectors, which are\nsubsequently processed by an aggregation model to predict the respective WSI\nlabel. With the rapid evolution of representation learning, numerous new\nfeature extractor models, often termed foundational models, have emerged.\nTraditional evaluation methods, however, rely on fixed aggregation model\nhyperparameters, a framework we identify as potentially biasing the results.\nOur study uncovers a co-dependence between feature extractor models and\naggregation model hyperparameters, indicating that performance comparability\ncan be skewed based on the chosen hyperparameters. By accounting for this\nco-dependency, we find that the performance of many current feature extractor\nmodels is notably similar. We support this insight by evaluating seven feature\nextractor models across three different datasets with 162 different aggregation\nmodel configurations. This comprehensive approach provides a more nuanced\nunderstanding of the relationship between feature extractors and aggregation\nmodels, leading to a fairer and more accurate assessment of feature extractor\nmodels in digital pathology.",
            "author": [
                "Gustav Bredell",
                "Marcel Fischer",
                "Przemyslaw Szostak",
                "Samaneh Abbasi-Sureshjani",
                "Alvaro Gomariz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17804v1",
                "http://arxiv.org/pdf/2311.17804v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17801v1",
            "title": "Towards Efficient Hyperdimensional Computing Using Photonics",
            "updated": "2023-11-29T16:51:21Z",
            "published": "2023-11-29T16:51:21Z",
            "summary": "Over the past few years, silicon photonics-based computing has emerged as a\npromising alternative to CMOS-based computing for Deep Neural Networks (DNN).\nUnfortunately, the non-linear operations and the high-precision requirements of\nDNNs make it extremely challenging to design efficient silicon photonics-based\nsystems for DNN inference and training. Hyperdimensional Computing (HDC) is an\nemerging, brain-inspired machine learning technique that enjoys several\nadvantages over existing DNNs, including being lightweight, requiring\nlow-precision operands, and being robust to noise introduced by the\nnonidealities in the hardware. For HDC, computing in-memory (CiM) approaches\nhave been widely used, as CiM reduces the data transfer cost if the operands\ncan fit into the memory. However, inefficient multi-bit operations, high write\nlatency, and low endurance make CiM ill-suited for HDC. On the other hand, the\nexisting electro-photonic DNN accelerators are inefficient for HDC because they\nare specifically optimized for matrix multiplication in DNNs and consume a lot\nof power with high-precision data converters.\n  In this paper, we argue that photonic computing and HDC complement each other\nbetter than photonic computing and DNNs, or CiM and HDC. We propose PhotoHDC,\nthe first-ever electro-photonic accelerator for HDC training and inference,\nsupporting the basic, record-based, and graph encoding schemes. Evaluating with\npopular datasets, we show that our accelerator can achieve two to five orders\nof magnitude lower EDP than the state-of-the-art electro-photonic DNN\naccelerators for implementing HDC training and inference. PhotoHDC also\nachieves four orders of magnitude lower energy-delay product than CiM-based\naccelerators for both HDC training and inference.",
            "author": [
                "Farbin Fayza",
                "Cansu Demirkiran",
                "Hanning Chen",
                "Che-Kai Liu",
                "Avi Mohan",
                "Hamza Errahmouni",
                "Sanggeon Yun",
                "Mohsen Imani",
                "David Zhang",
                "Darius Bunandar",
                "Ajay Joshi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17801v1",
                "http://arxiv.org/pdf/2311.17801v1"
            ],
            "primary_category": "cs.ET",
            "category": [
                "cs.ET",
                "cs.AR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17798v1",
            "title": "Adaptive Circuit Learning of Born Machine: Towards Realization of\n  Amplitude Embedding and Data Loading",
            "updated": "2023-11-29T16:47:31Z",
            "published": "2023-11-29T16:47:31Z",
            "summary": "With the progress in the quantum algorithm in recent years, much of the\nexisting literature claims the exponential quantum advantage against their\nclassical counterpart. However, many of these successes hinge on the assumption\nthat arbitrary states can be efficiently prepared in quantum circuits. In\nreality, crafting a circuit to prepare a generic $n$-qubit quantum state\ndemands an operation count on the order of $\\mathcal{O}(2^n)$, which is\nprohibitively demanding for the quantum algorithm to demonstrate its advantage\nagainst the classical one. To tackle this data-loading problem, numerous\nstrategies have been put forward. Nonetheless, most of these approaches only\nconsider a very simple and easy-to-implement circuit structure, which has been\nshown to suffer from serious optimization issues.\n  In this study, we harness quantum circuits as Born machines to generate\nprobability distributions. Drawing inspiration from methods used to investigate\nelectronic structures in quantum chemistry and condensed matter physics, we\npresent a novel algorithm \"Adaptive Circuit Learning of Born Machine\" (ACLBM)\nthat dynamically expands the ansatz circuit. Our algorithm is tailored to\nselectively integrate two-qubit entangled gates that best capture the complex\nentanglement present within the target state. Empirical results underscore the\nproficiency of our approach in encoding real-world data through amplitude\nembedding, demonstrating not only compliance with but also enhancement over the\nperformance benchmarks set by previous research.",
            "author": [
                "Chun-Tse Li",
                "Hao-Chung Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17798v1",
                "http://arxiv.org/pdf/2311.17798v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17797v1",
            "title": "Learning to Simulate: Generative Metamodeling via Quantile Regression",
            "updated": "2023-11-29T16:46:24Z",
            "published": "2023-11-29T16:46:24Z",
            "summary": "Stochastic simulation models, while effective in capturing the dynamics of\ncomplex systems, are often too slow to run for real-time decision-making.\nMetamodeling techniques are widely used to learn the relationship between a\nsummary statistic of the outputs (e.g., the mean or quantile) and the inputs of\nthe simulator, so that it can be used in real time. However, this methodology\nrequires the knowledge of an appropriate summary statistic in advance, making\nit inflexible for many practical situations. In this paper, we propose a new\nmetamodeling concept, called generative metamodeling, which aims to construct a\n\"fast simulator of the simulator\". This technique can generate random outputs\nsubstantially faster than the original simulation model, while retaining an\napproximately equal conditional distribution given the same inputs. Once\nconstructed, a generative metamodel can instantaneously generate a large amount\nof random outputs as soon as the inputs are specified, thereby facilitating the\nimmediate computation of any summary statistic for real-time decision-making.\nFurthermore, we propose a new algorithm -- quantile-regression-based generative\nmetamodeling (QRGMM) -- and study its convergence and rate of convergence.\nExtensive numerical experiments are conducted to investigate the empirical\nperformance of QRGMM, compare it with other state-of-the-art generative\nalgorithms, and demonstrate its usefulness in practical real-time\ndecision-making.",
            "author": [
                "L. Jeff Hong",
                "Yanxi Hou",
                "Qingkai Zhang",
                "Xiaowei Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17797v1",
                "http://arxiv.org/pdf/2311.17797v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17795v1",
            "title": "Marginal Laplacian Score",
            "updated": "2023-11-29T16:45:43Z",
            "published": "2023-11-29T16:45:43Z",
            "summary": "High-dimensional imbalanced data poses a machine learning challenge. In the\nabsence of sufficient or high-quality labels, unsupervised feature selection\nmethods are crucial for the success of subsequent algorithms. Therefore, there\nis a growing need for unsupervised feature selection algorithms focused on\nimbalanced data. Thus, we propose a Marginal Laplacian Score (MLS) a\nmodification of the well-known Laplacian Score (LS) to be better suited for\nimbalance data. We introduce an assumption that the minority class or anomalous\nappear more frequently in the margin of the features. Consequently, MLS aims to\npreserve the local structure of the data set's margin. As MLS is better suited\nfor handling imbalanced data, we propose its integration into modern feature\nselection methods that utilize the Laplacian score. We integrate the MLS\nalgorithm into the Differentiable Unsupervised Feature Selection (DUFS),\nresulting in DUFS-MLS. The proposed methods demonstrate robust and improved\nperformance on synthetic and public data sets.",
            "author": [
                "Guy Hay",
                "Ohad Volk"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17795v1",
                "http://arxiv.org/pdf/2311.17795v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML",
                "I.5.0"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17790v1",
            "title": "FAT-HuBERT: Front-end Adaptive Training of Hidden-unit BERT for\n  Distortion-Invariant Robust Speech Recognition",
            "updated": "2023-11-29T16:35:13Z",
            "published": "2023-11-29T16:35:13Z",
            "summary": "Advancements in monaural speech enhancement (SE) techniques have greatly\nimproved the perceptual quality of speech. However, integrating these\ntechniques into automatic speech recognition (ASR) systems has not yielded the\nexpected performance gains, primarily due to the introduction of distortions\nduring the SE process. In this paper, we propose a novel approach called\nFAT-HuBERT, which leverages distortion-invariant self-supervised learning (SSL)\nto enhance the robustness of ASR. To address the distortions introduced by the\nSE frontends, we introduce layer-wise fusion modules that incorporate features\nextracted from both observed noisy signals and enhanced signals. During\ntraining, the SE frontend is randomly selected from a pool of models. We\nevaluate the performance of FAT-HuBERT on simulated noisy speech generated from\nLibriSpeech as well as real-world noisy speech from the CHiME-4 1-channel\ndataset. The experimental results demonstrate a significant relative reduction\nin word error rate (WER).",
            "author": [
                "Dongning Yang",
                "Wei Wang",
                "Yanmin Qian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17790v1",
                "http://arxiv.org/pdf/2311.17790v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17786v1",
            "title": "DSS: Synthesizing long Digital Ink using Data augmentation, Style\n  encoding and Split generation",
            "updated": "2023-11-29T16:33:19Z",
            "published": "2023-11-29T16:33:19Z",
            "summary": "As text generative models can give increasingly long answers, we tackle the\nproblem of synthesizing long text in digital ink. We show that the commonly\nused models for this task fail to generalize to long-form data and how this\nproblem can be solved by augmenting the training data, changing the model\narchitecture and the inference procedure. These methods use contrastive\nlearning technique and are tailored specifically for the handwriting domain.\nThey can be applied to any encoder-decoder model that works with digital ink.\nWe demonstrate that our method reduces the character error rate on long-form\nEnglish data by half compared to baseline RNN and by 16% compared to the\nprevious approach that aims at addressing the same problem. We show that all\nthree parts of the method improve recognizability of generated inks. In\naddition, we evaluate synthesized data in a human study and find that people\nperceive most of generated data as real.",
            "author": [
                "Aleksandr Timofeev",
                "Anastasiia Fadeeva",
                "Andrei Afonin",
                "Claudiu Musat",
                "Andrii Maksai"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-031-41685-9_14",
                "http://arxiv.org/abs/2311.17786v1",
                "http://arxiv.org/pdf/2311.17786v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17783v1",
            "title": "Identifying Dynamic Regulation with Adversarial Surrogates",
            "updated": "2023-11-29T16:27:27Z",
            "published": "2023-11-29T16:27:27Z",
            "summary": "Homeostasis, the ability to maintain a stable internal environment in the\nface of perturbations, is essential for the functioning of living systems.\nGiven observations of a system, or even a detailed model of one, it is both\nvaluable and extremely challenging to extract the control objectives of the\nhomeostatic mechanisms. Lacking a clear separation between plant and\ncontroller, frameworks such as inverse optimal control and inverse\nreinforcement learning are unable to identify the homeostatic mechanisms. A\nrecently developed data-driven algorithm, Identifying Regulation with\nAdversarial Surrogates (IRAS), detects highly regulated or conserved quantities\nas the solution of a min-max optimization scheme that automates classical\nsurrogate data methods. Yet, the definition of homeostasis as regulation within\nnarrow limits is too strict for biological systems which show sustained\noscillations such as circadian rhythms. In this work, we introduce Identifying\nDynamic Regulation with Adversarial Surrogates (IDRAS), a generalization of the\nIRAS algorithm, capable of identifying control objectives that are regulated\nwith respect to a dynamical reference value. We test the algorithm on\nsimulation data from realistic biological models and benchmark physical\nsystems, demonstrating excellent empirical results.",
            "author": [
                "Ron Teichner",
                "Naama Brenner",
                "Ron Meir"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17783v1",
                "http://arxiv.org/pdf/2311.17783v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17781v1",
            "title": "Propagate & Distill: Towards Effective Graph Learners Using\n  Propagation-Embracing MLPs",
            "updated": "2023-11-29T16:26:24Z",
            "published": "2023-11-29T16:26:24Z",
            "summary": "Recent studies attempted to utilize multilayer perceptrons (MLPs) to solve\nsemisupervised node classification on graphs, by training a student MLP by\nknowledge distillation from a teacher graph neural network (GNN). While\nprevious studies have focused mostly on training the student MLP by matching\nthe output probability distributions between the teacher and student models\nduring distillation, it has not been systematically studied how to inject the\nstructural information in an explicit and interpretable manner. Inspired by\nGNNs that separate feature transformation $T$ and propagation $\\Pi$, we\nre-frame the distillation process as making the student MLP learn both $T$ and\n$\\Pi$. Although this can be achieved by applying the inverse propagation\n$\\Pi^{-1}$ before distillation from the teacher, it still comes with a high\ncomputational cost from large matrix multiplications during training. To solve\nthis problem, we propose Propagate & Distill (P&D), which propagates the output\nof the teacher before distillation, which can be interpreted as an approximate\nprocess of the inverse propagation. We demonstrate that P&D can readily improve\nthe performance of the student MLP.",
            "author": [
                "Yong-Min Shin",
                "Won-Yong Shin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17781v1",
                "http://arxiv.org/pdf/2311.17781v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.IT",
                "cs.NE",
                "cs.SI",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17778v1",
            "title": "Unified Binary and Multiclass Margin-Based Classification",
            "updated": "2023-11-29T16:24:32Z",
            "published": "2023-11-29T16:24:32Z",
            "summary": "The notion of margin loss has been central to the development and analysis of\nalgorithms for binary classification. To date, however, there remains no\nconsensus as to the analogue of the margin loss for multiclass classification.\nIn this work, we show that a broad range of multiclass loss functions,\nincluding many popular ones, can be expressed in the relative margin form, a\ngeneralization of the margin form of binary losses. The relative margin form is\nbroadly useful for understanding and analyzing multiclass losses as shown by\nour prior work (Wang and Scott, 2020, 2021). To further demonstrate the utility\nof this way of expressing multiclass losses, we use it to extend the seminal\nresult of Bartlett et al. (2006) on classification-calibration of binary margin\nlosses to multiclass. We then analyze the class of Fenchel-Young losses, and\nexpand the set of these losses that are known to be classification-calibrated.",
            "author": [
                "Yutong Wang",
                "Clayton Scott"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17778v1",
                "http://arxiv.org/pdf/2311.17778v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17776v1",
            "title": "One-Shot Open Affordance Learning with Foundation Models",
            "updated": "2023-11-29T16:23:06Z",
            "published": "2023-11-29T16:23:06Z",
            "summary": "We introduce One-shot Open Affordance Learning (OOAL), where a model is\ntrained with just one example per base object category, but is expected to\nidentify novel objects and affordances. While vision-language models excel at\nrecognizing novel objects and scenes, they often struggle to understand finer\nlevels of granularity such as affordances. To handle this issue, we conduct a\ncomprehensive analysis of existing foundation models, to explore their inherent\nunderstanding of affordances and assess the potential for data-limited\naffordance learning. We then propose a vision-language framework with simple\nand effective designs that boost the alignment between visual features and\naffordance text embeddings. Experiments on two affordance segmentation\nbenchmarks show that the proposed method outperforms state-of-the-art models\nwith less than 1% of the full training data, and exhibits reasonable\ngeneralization capability on unseen objects and affordances.",
            "author": [
                "Gen Li",
                "Deqing Sun",
                "Laura Sevilla-Lara",
                "Varun Jampani"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17776v1",
                "http://arxiv.org/pdf/2311.17776v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17973v1",
            "title": "Homogeneous Artificial Neural Network",
            "updated": "2023-11-29T16:16:32Z",
            "published": "2023-11-29T16:16:32Z",
            "summary": "The paper proposes an artificial neural network (ANN) being a global\napproximator for a special class of functions, which are known as generalized\nhomogeneous. The homogeneity means a symmetry of a function with respect to a\ngroup of transformations having topological characterization of a dilation. In\nthis paper, a class of the so-called linear dilations is considered. A\nhomogeneous universal approximation theorem is proven. Procedures for an\nupgrade of an existing ANN to a homogeneous one are developed. Theoretical\nresults are supported by examples from the various domains (computer science,\nsystems theory and automatic control).",
            "author": [
                "Andrey Polyakov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17973v1",
                "http://arxiv.org/pdf/2311.17973v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.NA",
                "cs.NE",
                "cs.SY",
                "eess.SY",
                "math.NA",
                "math.OC",
                "68T07, 93C10, 93D15"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17972v1",
            "title": "Self-Infilling Code Generation",
            "updated": "2023-11-29T16:02:06Z",
            "published": "2023-11-29T16:02:06Z",
            "summary": "This work introduces a general code generation framework that incorporates\ninfilling operations into auto-regressive decoding. Our approach capitalizes on\nthe observation that recent code language models with infilling capabilities\ncan perform \\emph{self-infilling}: whereas infilling operations aim to fill in\nthe middle based on a predefined prefix and suffix, self-infilling sequentially\ngenerates both such surrounding context and the infilled content. We utilize\nthis feature to develop an infilling-augmented decoding process that\nfacilitates non-monotonic generation. This approach allows for postponing the\ngeneration of uncertain code snippets until a definitive suffix is established,\nleading to improved control over the generation sequence. In addition, it\nfacilitates a looping mechanism, which can iteratively update and synchronize\neach piece of generation in a cyclic manner. Extensive experiments are\nconducted to demonstrate that our proposed decoding process is effective in\nenhancing regularity and quality across several code generation benchmarks.",
            "author": [
                "Lin Zheng",
                "Jianbo Yuan",
                "Zhi Zhang",
                "Hongxia Yang",
                "Lingpeng Kong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17972v1",
                "http://arxiv.org/pdf/2311.17972v1"
            ],
            "primary_category": "cs.PL",
            "category": [
                "cs.PL",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17752v1",
            "title": "BAND-2k: Banding Artifact Noticeable Database for Banding Detection and\n  Quality Assessment",
            "updated": "2023-11-29T15:56:31Z",
            "published": "2023-11-29T15:56:31Z",
            "summary": "Banding, also known as staircase-like contours, frequently occurs in flat\nareas of images/videos processed by the compression or quantization algorithms.\nAs undesirable artifacts, banding destroys the original image structure, thus\ndegrading users' quality of experience (QoE). In this paper, we systematically\ninvestigate the banding image quality assessment (IQA) problem, aiming to\ndetect the image banding artifacts and evaluate their perceptual visual\nquality. Considering that the existing image banding databases only contain\nlimited content sources and banding generation methods, and lack perceptual\nquality labels (i.e. mean opinion scores), we first build the largest banding\nIQA database so far, named Banding Artifact Noticeable Database (BAND-2k),\nwhich consists of 2,000 banding images generated by 15 compression and\nquantization schemes. A total of 23 workers participated in the subjective IQA\nexperiment, yielding over 214,000 patch-level banding class labels and 44,371\nreliable image-level quality ratings. Subsequently, we develop an effective\nno-reference (NR) banding evaluator for banding detection and quality\nassessment by leveraging frequency characteristics of banding artifacts. A dual\nconvolutional neural network is employed to concurrently learn the feature\nrepresentation from the high-frequency and low-frequency maps, thereby\nenhancing the ability to discern banding artifacts. The quality score of a\nbanding image is generated by pooling the banding detection maps masked by the\nspatial frequency filters. Experiments demonstrate that our banding evaluator\nachieves a remarkably high accuracy in banding detection and also exhibits high\nSRCC and PLCC results with the perceptual quality labels. These findings unveil\nthe strong correlations between the intensity of banding artifacts and the\nperceptual visual quality, thus validating the necessity of banding quality\nassessment.",
            "author": [
                "Zijian Chen",
                "Wei Sun",
                "Jun Jia",
                "Fangfang Lu",
                "Zicheng Zhang",
                "Jing Liu",
                "Ru Huang",
                "Xiongkuo Min",
                "Guangtao Zhai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17752v1",
                "http://arxiv.org/pdf/2311.17752v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.DB",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17750v1",
            "title": "Addressing Membership Inference Attack in Federated Learning with Model\n  Compression",
            "updated": "2023-11-29T15:54:15Z",
            "published": "2023-11-29T15:54:15Z",
            "summary": "Federated Learning (FL) has been proposed as a privacy-preserving solution\nfor machine learning. However, recent works have shown that Federated Learning\ncan leak private client data through membership attacks. In this paper, we show\nthat the effectiveness of these attacks on the clients negatively correlates\nwith the size of the client datasets and model complexity. Based on this\nfinding, we propose model-agnostic Federated Learning as a privacy-enhancing\nsolution because it enables the use of models of varying complexity in the\nclients. To this end, we present $\\texttt{MaPP-FL}$, a novel privacy-aware FL\napproach that leverages model compression on the clients while keeping a full\nmodel on the server. We compare the performance of $\\texttt{MaPP-FL}$ against\nstate-of-the-art model-agnostic FL methods on the CIFAR-10, CIFAR-100, and\nFEMNIST vision datasets. Our experiments show the effectiveness of\n$\\texttt{MaPP-FL}$ in preserving the clients' and the server's privacy while\nachieving competitive classification accuracies.",
            "author": [
                "Gergely D\u00e1niel N\u00e9meth",
                "Miguel \u00c1ngel Lozano",
                "Novi Quadrianto",
                "Nuria Oliver"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17750v1",
                "http://arxiv.org/pdf/2311.17750v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17749v1",
            "title": "Learning Free Terminal Time Optimal Closed-loop Control of Manipulators",
            "updated": "2023-11-29T15:53:43Z",
            "published": "2023-11-29T15:53:43Z",
            "summary": "This paper presents a novel approach to learning free terminal time\nclosed-loop control for robotic manipulation tasks, enabling dynamic adjustment\nof task duration and control inputs to enhance performance. We extend the\nsupervised learning approach, namely solving selected optimal open-loop\nproblems and utilizing them as training data for a policy network, to the free\nterminal time scenario. Three main challenges are addressed in this extension.\nFirst, we introduce a marching scheme that enhances the solution quality and\nincreases the success rate of the open-loop solver by gradually refining time\ndiscretization. Second, we extend the QRnet in Nakamura-Zimmerer et al. (2021b)\nto the free terminal time setting to address discontinuity and improve\nstability at the terminal state. Third, we present a more automated version of\nthe initial value problem (IVP) enhanced sampling method from previous work\n(Zhang et al., 2022) to adaptively update the training dataset, significantly\nimproving its quality. By integrating these techniques, we develop a\nclosed-loop policy that operates effectively over a broad domain with varying\noptimal time durations, achieving near globally optimal total costs.",
            "author": [
                "Wei Hu",
                "Yue Zhao",
                "Weinan E",
                "Jiequn Han",
                "Jihao Long"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17749v1",
                "http://arxiv.org/pdf/2311.17749v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01520v1",
            "title": "Entropy and the Kullback-Leibler Divergence for Bayesian Networks:\n  Computational Complexity and Efficient Implementation",
            "updated": "2023-11-29T15:51:04Z",
            "published": "2023-11-29T15:51:04Z",
            "summary": "Bayesian networks (BNs) are a foundational model in machine learning and\ncausal inference. Their graphical structure can handle high-dimensional\nproblems, divide-and-conquering them into a sparse collection of smaller ones;\nunderlies Judea Pearl's causality; and determines their explainability and\ninterpretability. Despite their popularity, there are few resources in the\nliterature on how to compute Shannon's entropy and the Kullback-Leibler (KL)\ndivergence for BNs under their most common distributional assumptions. In this\npaper, we provide computationally efficient algorithms for both by leveraging\nBNs' graphical structure, and we illustrate them with a complete set of\nnumerical examples. In the process, we show it is possible to reduce the\ncomputational complexity of KL from cubic to quadratic for Gaussian BNs.",
            "author": [
                "Marco Scutari"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01520v1",
                "http://arxiv.org/pdf/2312.01520v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "stat.CO",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17744v1",
            "title": "Variational Bayes image restoration with compressive autoencoders",
            "updated": "2023-11-29T15:49:31Z",
            "published": "2023-11-29T15:49:31Z",
            "summary": "Regularization of inverse problems is of paramount importance in\ncomputational imaging. The ability of neural networks to learn efficient image\nrepresentations has been recently exploited to design powerful data-driven\nregularizers. While state-of-the-art plug-and-play methods rely on an implicit\nregularization provided by neural denoisers, alternative Bayesian approaches\nconsider Maximum A Posteriori (MAP) estimation in the latent space of a\ngenerative model, thus with an explicit regularization. However,\nstate-of-the-art deep generative models require a huge amount of training data\ncompared to denoisers. Besides, their complexity hampers the optimization of\nthe latent MAP. In this work, we propose to use compressive autoencoders for\nlatent estimation. These networks, which can be seen as variational\nautoencoders with a flexible latent prior, are smaller and easier to train than\nstate-of-the-art generative models. We then introduce the Variational Bayes\nLatent Estimation (VBLE) algorithm, which performs this estimation within the\nframework of variational inference. This allows for fast and easy (approximate)\nposterior sampling. Experimental results on image datasets BSD and FFHQ\ndemonstrate that VBLE reaches similar performance than state-of-the-art\nplug-and-play methods, while being able to quantify uncertainties faster than\nother existing posterior sampling techniques.",
            "author": [
                "Maud Biquard",
                "Marie Chabert",
                "Thomas Oberlin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17744v1",
                "http://arxiv.org/pdf/2311.17744v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17740v1",
            "title": "A transductive few-shot learning approach for classification of digital\n  histopathological slides from liver cancer",
            "updated": "2023-11-29T15:44:00Z",
            "published": "2023-11-29T15:44:00Z",
            "summary": "This paper presents a new approach for classifying 2D histopathology patches\nusing few-shot learning. The method is designed to tackle a significant\nchallenge in histopathology, which is the limited availability of labeled data.\nBy applying a sliding window technique to histopathology slides, we illustrate\nthe practical benefits of transductive learning (i.e., making joint predictions\non patches) to achieve consistent and accurate classification. Our approach\ninvolves an optimization-based strategy that actively penalizes the prediction\nof a large number of distinct classes within each window. We conducted\nexperiments on histopathological data to classify tissue classes in digital\nslides of liver cancer, specifically hepatocellular carcinoma. The initial\nresults show the effectiveness of our method and its potential to enhance the\nprocess of automated cancer diagnosis and treatment, all while reducing the\ntime and effort required for expert annotation.",
            "author": [
                "Aymen Sadraoui",
                "S\u00e9gol\u00e8ne Martin",
                "Eliott Barbot",
                "Astrid Laurent-Bellue",
                "Jean-Christophe Pesquet",
                "Catherine Guettier",
                "Ismail Ben Ayed"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17740v1",
                "http://arxiv.org/pdf/2311.17740v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.LG",
                "q-bio.TO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17970v1",
            "title": "Description Generation using Variational Auto-Encoders for precursor\n  microRNA",
            "updated": "2023-11-29T15:41:45Z",
            "published": "2023-11-29T15:41:45Z",
            "summary": "Micro RNAs (miRNA) are a type of non-coding RNA, which are involved in gene\nregulation and can be associated with diseases such as cancer, cardiovascular\nand neurological diseases. As such, identifying the entire genome of miRNA can\nbe of great relevance. Since experimental methods for novel precursor miRNA\n(pre-miRNA) detection are complex and expensive, computational detection using\nML could be useful. Existing ML methods are often complex black boxes, which do\nnot create an interpretable structural description of pre-miRNA. In this paper,\nwe propose a novel framework, which makes use of generative modeling through\nVariational Auto-Encoders to uncover the generative factors of pre-miRNA. After\ntraining the VAE, the pre-miRNA description is developed using a decision tree\non the lower dimensional latent space. Applying the framework to miRNA\nclassification, we obtain a high reconstruction and classification performance,\nwhile also developing an accurate miRNA description.",
            "author": [
                "Marko Petkovi\u0107",
                "Vlado Menkovski"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17970v1",
                "http://arxiv.org/pdf/2311.17970v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17737v1",
            "title": "GenZI: Zero-Shot 3D Human-Scene Interaction Generation",
            "updated": "2023-11-29T15:40:11Z",
            "published": "2023-11-29T15:40:11Z",
            "summary": "Can we synthesize 3D humans interacting with scenes without learning from any\n3D human-scene interaction data? We propose GenZI, the first zero-shot approach\nto generating 3D human-scene interactions. Key to GenZI is our distillation of\ninteraction priors from large vision-language models (VLMs), which have learned\na rich semantic space of 2D human-scene compositions. Given a natural language\ndescription and a coarse point location of the desired interaction in a 3D\nscene, we first leverage VLMs to imagine plausible 2D human interactions\ninpainted into multiple rendered views of the scene. We then formulate a robust\niterative optimization to synthesize the pose and shape of a 3D human model in\nthe scene, guided by consistency with the 2D interaction hypotheses. In\ncontrast to existing learning-based approaches, GenZI circumvents the\nconventional need for captured 3D interaction data, and allows for flexible\ncontrol of the 3D interaction synthesis with easy-to-use text prompts.\nExtensive experiments show that our zero-shot approach has high flexibility and\ngenerality, making it applicable to diverse scene types, including both indoor\nand outdoor environments.",
            "author": [
                "Lei Li",
                "Angela Dai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17737v1",
                "http://arxiv.org/pdf/2311.17737v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17969v1",
            "title": "Generation of a Compendium of Transcription Factor Cascades and\n  Identification of Potential Therapeutic Targets using Graph Machine Learning",
            "updated": "2023-11-29T15:31:58Z",
            "published": "2023-11-29T15:31:58Z",
            "summary": "Transcription factors (TFs) play a vital role in the regulation of gene\nexpression thereby making them critical to many cellular processes. In this\nstudy, we used graph machine learning methods to create a compendium of TF\ncascades using data extracted from the STRING database. A TF cascade is a\nsequence of TFs that regulate each other, forming a directed path in the TF\nnetwork. We constructed a knowledge graph of 81,488 unique TF cascades, with\nthe longest cascade consisting of 62 TFs. Our results highlight the complex and\nintricate nature of TF interactions, where multiple TFs work together to\nregulate gene expression. We also identified 10 TFs with the highest regulatory\ninfluence based on centrality measurements, providing valuable information for\nresearchers interested in studying specific TFs. Furthermore, our pathway\nenrichment analysis revealed significant enrichment of various pathways and\nfunctional categories, including those involved in cancer and other diseases,\nas well as those involved in development, differentiation, and cell signaling.\nThe enriched pathways identified in this study may have potential as targets\nfor therapeutic intervention in diseases associated with dysregulation of\ntranscription factors. We have released the dataset, knowledge graph, and\ngraphML methods for the TF cascades, and created a website to display the\nresults, which can be accessed by researchers interested in using this dataset.\nOur study provides a valuable resource for understanding the complex network of\ninteractions between TFs and their regulatory roles in cellular processes.",
            "author": [
                "Sonish Sivarajkumar",
                "Pratyush Tandale",
                "Ankit Bhardwaj",
                "Kipp W. Johnson",
                "Anoop Titus",
                "Benjamin S. Glicksberg",
                "Shameer Khader",
                "Kamlesh K. Yadav",
                "Lakshminarayanan Subramanian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17969v1",
                "http://arxiv.org/pdf/2311.17969v1"
            ],
            "primary_category": "q-bio.MN",
            "category": [
                "q-bio.MN",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17722v1",
            "title": "SenTest: Evaluating Robustness of Sentence Encoders",
            "updated": "2023-11-29T15:21:35Z",
            "published": "2023-11-29T15:21:35Z",
            "summary": "Contrastive learning has proven to be an effective method for pre-training\nmodels using weakly labeled data in the vision domain. Sentence transformers\nare the NLP counterparts to this architecture, and have been growing in\npopularity due to their rich and effective sentence representations. Having\neffective sentence representations is paramount in multiple tasks, such as\ninformation retrieval, retrieval augmented generation (RAG), and sentence\ncomparison. Keeping in mind the deployability factor of transformers,\nevaluating the robustness of sentence transformers is of utmost importance.\nThis work focuses on evaluating the robustness of the sentence encoders. We\nemploy several adversarial attacks to evaluate its robustness. This system uses\ncharacter-level attacks in the form of random character substitution,\nword-level attacks in the form of synonym replacement, and sentence-level\nattacks in the form of intra-sentence word order shuffling. The results of the\nexperiments strongly undermine the robustness of sentence encoders. The models\nproduce significantly different predictions as well as embeddings on perturbed\ndatasets. The accuracy of the models can fall up to 15 percent on perturbed\ndatasets as compared to unperturbed datasets. Furthermore, the experiments\ndemonstrate that these embeddings does capture the semantic and syntactic\nstructure (sentence order) of sentences. However, existing supervised\nclassification strategies fail to leverage this information, and merely\nfunction as n-gram detectors.",
            "author": [
                "Tanmay Chavan",
                "Shantanu Patankar",
                "Aditya Kane",
                "Omkar Gokhale",
                "Geetanjali Kale",
                "Raviraj Joshi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17722v1",
                "http://arxiv.org/pdf/2311.17722v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17721v1",
            "title": "Beyond FRiM, ASAP: a family of sparse approximation for covariance\n  matrices and preconditioners",
            "updated": "2023-11-29T15:21:33Z",
            "published": "2023-11-29T15:21:33Z",
            "summary": "The FRiM fractal operator belongs to a family of operators, called ASAP,\ndefined by an ordered selection of nearest neighbors. This generalization\nprovides means to improve upon the good properties of FRiM. We propose a fast\nalgorithm to build an ASAP operator mimicking the fractal structure of FRiM for\npupils of any size and geometry and to learn the sparse coefficients from\nempirical data. We empirically show the good approximation by ASAP of\ncorrelated statistics and the benefits of ASAP for solving phase restoration\nproblems.",
            "author": [
                "\u00c9ric Thi\u00e9baut",
                "Michel Tallon",
                "Samuel Th\u00e9",
                "Lo\u00efc Denis"
            ],
            "link": [
                "http://dx.doi.org/10.1117/12.2630192",
                "http://arxiv.org/abs/2311.17721v1",
                "http://arxiv.org/pdf/2311.17721v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17717v1",
            "title": "Receler: Reliable Concept Erasing of Text-to-Image Diffusion Models via\n  Lightweight Erasers",
            "updated": "2023-11-29T15:19:49Z",
            "published": "2023-11-29T15:19:49Z",
            "summary": "Concept erasure in text-to-image diffusion models aims to disable pre-trained\ndiffusion models from generating images related to a target concept. To perform\nreliable concept erasure, the properties of robustness and locality are\ndesirable. The former refrains the model from producing images associated with\nthe target concept for any paraphrased or learned prompts, while the latter\npreserves the model ability in generating images for non-target concepts. In\nthis paper, we propose Reliable Concept Erasing via Lightweight Erasers\n(Receler), which learns a lightweight Eraser to perform concept erasing and\nenhances locality and robustness with the proposed concept-localized\nregularization and adversarial prompt learning, respectively. Comprehensive\nquantitative and qualitative experiments with various concept prompts verify\nthe superiority of Receler over the previous erasing methods on the above two\ndesirable properties.",
            "author": [
                "Chi-Pin Huang",
                "Kai-Po Chang",
                "Chung-Ting Tsai",
                "Yung-Hsuan Lai",
                "Yu-Chiang Frank Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17717v1",
                "http://arxiv.org/pdf/2311.17717v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17705v1",
            "title": "Q-PAC: Automated Detection of Quantum Bug-Fix Patterns",
            "updated": "2023-11-29T15:09:32Z",
            "published": "2023-11-29T15:09:32Z",
            "summary": "Context: Bug-fix pattern detection has been investigated in the past in the\ncontext of classical software. However, while quantum software is developing\nrapidly, the literature still lacks automated methods and tools to identify,\nanalyze, and detect bug-fix patterns. To the best of our knowledge, our work\npreviously published in SEKE'23 was the first to leverage classical techniques\nto detect bug-fix patterns in quantum code.\n  Objective: To extend our previous effort, we present a research agenda\n(Q-Repair), including a series of testing and debugging methodologies, to\nimprove the quality of quantum software. The ultimate goal is to utilize\nmachine learning techniques to automatically predict fix patterns for existing\nquantum bugs.\n  Method: As part of the first stage of the agenda, we extend our initial study\nand propose a more comprehensive automated framework, called Q-PAC, for\ndetecting bug-fix patterns in IBM Qiskit quantum code. In the framework, we\ndevelop seven bug-fix pattern detectors using abstract syntax trees, syntactic\nfilters, and semantic checks.\n  Results: To demonstrate our method, we run Q-PAC on a variety of quantum\nbug-fix patterns using both real-world and handcrafted examples of bugs and\nfixes. The experimental results show that Q-PAC can effectively identify\nbug-fix patterns in IBM Qiskit.\n  Conclusion: We hope our initial study on quantum bug-fix detection can bring\nawareness of quantum software engineering to both researchers and\npractitioners. Thus, we also publish Q-PAC as an open-source software on\nGitHub. We would like to encourage other researchers to work on research\ndirections (such as Q-Repair) to improve the quality of the quantum\nprogramming.",
            "author": [
                "Pranav K. Nayak",
                "Krishn V. Kher",
                "M. Bharat Chandra",
                "M. V. Panduranga Rao",
                "Lei Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17705v1",
                "http://arxiv.org/pdf/2311.17705v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17704v1",
            "title": "An Efficient Algorithm for Unbalanced 1D Transportation",
            "updated": "2023-11-29T15:09:24Z",
            "published": "2023-11-29T15:09:24Z",
            "summary": "Optimal transport (OT) and unbalanced optimal transport (UOT) are central in\nmany machine learning, statistics and engineering applications. 1D OT is easily\nsolved, with complexity O(n log n), but no efficient algorithm was known for 1D\nUOT. We present a new approach that leverages the successive shortest path\nalgorithm for the corresponding network flow problem. By employing a suitable\nrepresentation, we bundle together multiple steps that do not change the cost\nof the shortest path. We prove that our algorithm solves 1D UOT in O(n log n),\nclosing the gap.",
            "author": [
                "Gabriel Gouvine"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17704v1",
                "http://arxiv.org/pdf/2311.17704v1"
            ],
            "primary_category": "cs.PF",
            "category": [
                "cs.PF",
                "cs.CC",
                "cs.DS",
                "68",
                "E.1; F.2.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17696v2",
            "title": "How to Build an AI Tutor that Can Adapt to Any Course and Provide\n  Accurate Answers Using Large Language Model and Retrieval-Augmented\n  Generation",
            "updated": "2023-11-30T06:28:22Z",
            "published": "2023-11-29T15:02:46Z",
            "summary": "Artificial intelligence is transforming education through data-driven,\npersonalized learning solutions. This paper introduces AI Tutor, an innovative\nweb application that provides personalized tutoring in any subject using\nstate-of-the-art Large Language Model (LLM). AI Tutor ingests course materials\nto construct an adaptive knowledge base tailored to the course. When students\npose questions, it retrieves the most relevant information and generates\ndetailed, conversational responses citing supporting evidence. The system is\npowered by advanced large language models and Retrieval-Augmented Generation\n(RAG) techniques for accurate, natural question answering. We present a\nfully-functional web interface and video demonstration that showcase AI Tutor's\nversatility across diverse subjects and its ability to produce pedagogically\ncogent responses. While an initial prototype, this work represents a pioneering\nstep toward AI-enabled tutoring systems that can democratize access to\nhigh-quality, customized educational support.",
            "author": [
                "Chenxi Dong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17696v2",
                "http://arxiv.org/pdf/2311.17696v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17695v1",
            "title": "Fair Text-to-Image Diffusion via Fair Mapping",
            "updated": "2023-11-29T15:02:01Z",
            "published": "2023-11-29T15:02:01Z",
            "summary": "In this paper, we address the limitations of existing text-to-image diffusion\nmodels in generating demographically fair results when given human-related\ndescriptions. These models often struggle to disentangle the target language\ncontext from sociocultural biases, resulting in biased image generation. To\novercome this challenge, we propose Fair Mapping, a general, model-agnostic,\nand lightweight approach that modifies a pre-trained text-to-image model by\ncontrolling the prompt to achieve fair image generation. One key advantage of\nour approach is its high efficiency. The training process only requires\nupdating a small number of parameters in an additional linear mapping network.\nThis not only reduces the computational cost but also accelerates the\noptimization process. We first demonstrate the issue of bias in generated\nresults caused by language biases in text-guided diffusion models. By\ndeveloping a mapping network that projects language embeddings into an unbiased\nspace, we enable the generation of relatively balanced demographic results\nbased on a keyword specified in the prompt. With comprehensive experiments on\nface image generation, we show that our method significantly improves image\ngeneration performance when prompted with descriptions related to human faces.\nBy effectively addressing the issue of bias, we produce more fair and diverse\nimage outputs. This work contributes to the field of text-to-image generation\nby enhancing the ability to generate images that accurately reflect the\nintended demographic characteristics specified in the text.",
            "author": [
                "Jia Li",
                "Lijie Hu",
                "Jingfeng Zhang",
                "Tianhang Zheng",
                "Hua Zhang",
                "Di Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17695v1",
                "http://arxiv.org/pdf/2311.17695v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CY",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17693v1",
            "title": "Toward a Surgeon-in-the-Loop Ophthalmic Robotic Apprentice using\n  Reinforcement and Imitation Learning",
            "updated": "2023-11-29T15:00:06Z",
            "published": "2023-11-29T15:00:06Z",
            "summary": "Robotic-assisted surgical systems have demonstrated significant potential in\nenhancing surgical precision and minimizing human errors. However, existing\nsystems lack the ability to accommodate the unique preferences and requirements\nof individual surgeons. Additionally, they primarily focus on general surgeries\n(e.g., laparoscopy) and are not suitable for highly precise microsurgeries,\nsuch as ophthalmic procedures. Thus, we propose a simulation-based image-guided\napproach for surgeon-centered autonomous agents that can adapt to the\nindividual surgeon's skill level and preferred surgical techniques during\nophthalmic cataract surgery. Our approach utilizes a simulated environment to\ntrain reinforcement and imitation learning agents guided by image data to\nperform all tasks of the incision phase of cataract surgery. By integrating the\nsurgeon's actions and preferences into the training process with the\nsurgeon-in-the-loop, our approach enables the robot to implicitly learn and\nadapt to the individual surgeon's unique approach through demonstrations. This\nresults in a more intuitive and personalized surgical experience for the\nsurgeon. Simultaneously, it ensures consistent performance for the autonomous\nrobotic apprentice. We define and evaluate the effectiveness of our approach\nusing our proposed metrics; and highlight the trade-off between a generic agent\nand a surgeon-centered adapted agent. Moreover, our approach has the potential\nto extend to other ophthalmic surgical procedures, opening the door to a new\ngeneration of surgeon-in-the-loop autonomous surgical robots. We provide an\nopen-source simulation framework for future development and reproducibility.",
            "author": [
                "Amr Gomaa",
                "Bilal Mahdy",
                "Niko Kleer",
                "Antonio Kr\u00fcger"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17693v1",
                "http://arxiv.org/pdf/2311.17693v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV",
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17685v1",
            "title": "Enhancing efficiency and robustness in high-dimensional linear\n  regression with additional unlabeled data",
            "updated": "2023-11-29T14:47:16Z",
            "published": "2023-11-29T14:47:16Z",
            "summary": "In semi-supervised learning, the prevailing understanding suggests that\nobserving additional unlabeled samples improves estimation accuracy for linear\nparameters only in the case of model misspecification. This paper challenges\nthis notion, demonstrating its inaccuracy in high dimensions. Initially\nfocusing on a dense scenario, we introduce robust semi-supervised estimators\nfor the regression coefficient without relying on sparse structures in the\npopulation slope. Even when the true underlying model is linear, we show that\nleveraging information from large-scale unlabeled data improves both estimation\naccuracy and inference robustness. Moreover, we propose semi-supervised methods\nwith further enhanced efficiency in scenarios with a sparse linear slope.\nDiverging from the standard semi-supervised literature, we also allow for\ncovariate shift. The performance of the proposed methods is illustrated through\nextensive numerical studies, including simulations and a real-data application\nto the AIDS Clinical Trials Group Protocol 175 (ACTG175).",
            "author": [
                "Kai Chen",
                "Yuqian Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17685v1",
                "http://arxiv.org/pdf/2311.17685v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17677v1",
            "title": "COVIDx CXR-4: An Expanded Multi-Institutional Open-Source Benchmark\n  Dataset for Chest X-ray Image-Based Computer-Aided COVID-19 Diagnostics",
            "updated": "2023-11-29T14:40:31Z",
            "published": "2023-11-29T14:40:31Z",
            "summary": "The global ramifications of the COVID-19 pandemic remain significant,\nexerting persistent pressure on nations even three years after its initial\noutbreak. Deep learning models have shown promise in improving COVID-19\ndiagnostics but require diverse and larger-scale datasets to improve\nperformance. In this paper, we introduce COVIDx CXR-4, an expanded\nmulti-institutional open-source benchmark dataset for chest X-ray image-based\ncomputer-aided COVID-19 diagnostics. COVIDx CXR-4 expands significantly on the\nprevious COVIDx CXR-3 dataset by increasing the total patient cohort size by\ngreater than 2.66 times, resulting in 84,818 images from 45,342 patients across\nmultiple institutions. We provide extensive analysis on the diversity of the\npatient demographic, imaging metadata, and disease distributions to highlight\npotential dataset biases. To the best of the authors' knowledge, COVIDx CXR-4\nis the largest and most diverse open-source COVID-19 CXR dataset and is made\npublicly available as part of an open initiative to advance research to aid\nclinicians against the COVID-19 disease.",
            "author": [
                "Yifan Wu",
                "Hayden Gunraj",
                "Chi-en Amy Tai",
                "Alexander Wong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17677v1",
                "http://arxiv.org/pdf/2311.17677v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02182v1",
            "title": "Adam-like Algorithm with Smooth Clipping Attains Global Minima: Analysis\n  Based on Ergodicity of Functional SDEs",
            "updated": "2023-11-29T14:38:59Z",
            "published": "2023-11-29T14:38:59Z",
            "summary": "In this paper, we prove that an Adam-type algorithm with smooth clipping\napproaches the global minimizer of the regularized non-convex loss function.\nAdding smooth clipping and taking the state space as the set of all\ntrajectories, we can apply the ergodic theory of Markov semigroups for this\nalgorithm and investigate its asymptotic behavior. The ergodic theory we\nestablish in this paper reduces the problem of evaluating the convergence,\ngeneralization error and discretization error of this algorithm to the problem\nof evaluating the difference between two functional stochastic differential\nequations (SDEs) with different drift coefficients. As a result of our\nanalysis, we have shown that this algorithm minimizes the the regularized\nnon-convex loss function with errors of the form $n^{-1/2}$, $\\eta^{1/4}$,\n$\\beta^{-1} \\log (\\beta + 1)$ and $e^{- c t}$. Here, $c$ is a constant and $n$,\n$\\eta$, $\\beta$ and $t$ denote the size of the training dataset, learning rate,\ninverse temperature and time, respectively.",
            "author": [
                "Keisuke Suzuki"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02182v1",
                "http://arxiv.org/pdf/2312.02182v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC",
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17673v1",
            "title": "Using Ornstein-Uhlenbeck Process to understand Denoising Diffusion\n  Probabilistic Model and its Noise Schedules",
            "updated": "2023-11-29T14:36:33Z",
            "published": "2023-11-29T14:36:33Z",
            "summary": "The aim of this short note is to show that Denoising Diffusion Probabilistic\nModel DDPM, a non-homogeneous discrete-time Markov process, can be represented\nby a time-homogeneous continuous-time Markov process observed at non-uniformly\nsampled discrete times. Surprisingly, this continuous-time Markov process is\nthe well-known and well-studied Ornstein-Ohlenbeck (OU) process, which was\ndeveloped in 1930's for studying Brownian particles in Harmonic potentials. We\nestablish the formal equivalence between DDPM and the OU process using its\nanalytical solution. We further demonstrate that the design problem of the\nnoise scheduler for non-homogeneous DDPM is equivalent to designing observation\ntimes for the OU process. We present several heuristic designs for observation\ntimes based on principled quantities such as auto-variance and Fisher\nInformation and connect them to ad hoc noise schedules for DDPM. Interestingly,\nwe show that the Fisher-Information-motivated schedule corresponds exactly the\ncosine schedule, which was developed without any theoretical foundation but is\nthe current state-of-the-art noise schedule.",
            "author": [
                "Javier E. Santos",
                "Yen Ting Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17673v1",
                "http://arxiv.org/pdf/2311.17673v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cond-mat.stat-mech",
                "cs.AI",
                "cs.LG",
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17662v1",
            "title": "Issue Report Validation in an Industrial Context",
            "updated": "2023-11-29T14:24:13Z",
            "published": "2023-11-29T14:24:13Z",
            "summary": "Effective issue triaging is crucial for software development teams to improve\nsoftware quality, and thus customer satisfaction. Validating issue reports\nmanually can be time-consuming, hindering the overall efficiency of the\ntriaging process. This paper presents an approach on automating the validation\nof issue reports to accelerate the issue triaging process in an industrial\nset-up. We work on 1,200 randomly selected issue reports in banking domain,\nwritten in Turkish, an agglutinative language, meaning that new words can be\nformed with linear concatenation of suffixes to express entire sentences. We\nmanually label these reports for validity, and extract the relevant patterns\nindicating that they are invalid. Since the issue reports we work on are\nwritten in an agglutinative language, we use morphological analysis to extract\nthe features. Using the proposed feature extractors, we utilize a machine\nlearning based approach to predict the issue reports' validity, performing a\n0.77 F1-score.",
            "author": [
                "Ethem Utku Aktas",
                "Ebru Cakmak",
                "Mete Cihad Inan",
                "Cemal Yilmaz"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3611643.3613887",
                "http://arxiv.org/abs/2311.17662v1",
                "http://arxiv.org/pdf/2311.17662v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17657v1",
            "title": "Volumetric Cloud Field Reconstruction",
            "updated": "2023-11-29T14:19:40Z",
            "published": "2023-11-29T14:19:40Z",
            "summary": "Volumetric phenomena, such as clouds and fog, present a significant challenge\nfor 3D reconstruction systems due to their translucent nature and their complex\ninteractions with light. Conventional techniques for reconstructing scattering\nvolumes rely on controlled setups, limiting practical applications. This paper\nintroduces an approach to reconstructing volumes from a few input stereo pairs.\nWe propose a novel deep learning framework that integrates a deep stereo model\nwith a 3D Convolutional Neural Network (3D CNN) and an advection module,\ncapable of capturing the shape and dynamics of volumes. The stereo depths are\nused to carve empty space around volumes, providing the 3D CNN with a prior for\ncoping with the lack of input views. Refining our output, the advection module\nleverages the temporal evolution of the medium, providing a mechanism to infer\nmotion and improve temporal consistency. The efficacy of our system is\ndemonstrated through its ability to estimate density and velocity fields of\nlarge-scale volumes, in this case, clouds, from a sparse set of stereo image\npairs.",
            "author": [
                "Jacob Lin",
                "Miguel Farinha",
                "Edward Gryspeerdt",
                "Ronald Clark"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17657v1",
                "http://arxiv.org/pdf/2311.17657v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17647v1",
            "title": "VIM: Probing Multimodal Large Language Models for Visual Embedded\n  Instruction Following",
            "updated": "2023-11-29T14:08:53Z",
            "published": "2023-11-29T14:08:53Z",
            "summary": "We introduce VISUAL EMBEDDED INSTRUCTION (VIM), a new framework designed to\nevaluate the visual instruction following capability of Multimodal Large\nLanguage Models (MLLMs). As illustrated in Figure 2, VIM challenges the MLLMs\nby embedding the instructions into the visual scenes, demanding strong visual\ninterpretative skills for instruction following. We adapt VIM to various\nbenchmarks, including VQAv2, MME, MM-Vet, and RefCOCO series, compose a VIM\nbench, and probe diverse MLLMs across three distinct in-context learning\nsettings: Zero Shot, One Shot, and Pair Shot. We observe that there is a\nsignificant performance disparity between the open-source MLLMs and GPT-4V,\nimplying that their proficiency in visual instruction comprehension is not up\nto par. Our results highlight a promising direction for the enhancement of\nMLLMs capabilities on instruction following. We aim VIM to serve as a useful\nnorm for advancing the state of the art and driving further progress in the\nfield.",
            "author": [
                "Yujie Lu",
                "Xiujun Li",
                "William Yang Wang",
                "Yejin Choi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17647v1",
                "http://arxiv.org/pdf/2311.17647v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17646v1",
            "title": "A novel feature selection method based on quantum support vector machine",
            "updated": "2023-11-29T14:08:26Z",
            "published": "2023-11-29T14:08:26Z",
            "summary": "Feature selection is critical in machine learning to reduce dimensionality\nand improve model accuracy and efficiency. The exponential growth in feature\nspace dimensionality for modern datasets directly results in ambiguous samples\nand redundant features, which can severely degrade classification accuracy.\nQuantum machine learning offers potential advantages for addressing this\nchallenge. In this paper, we propose a novel method, quantum support vector\nmachine feature selection (QSVMF), integrating quantum support vector machines\nwith multi-objective genetic algorithm. QSVMF optimizes multiple simultaneous\nobjectives: maximizing classification accuracy, minimizing selected features\nand quantum circuit costs, and reducing feature covariance. We apply QSVMF for\nfeature selection on a breast cancer dataset, comparing the performance of\nQSVMF against classical approaches with the selected features. Experimental\nresults show that QSVMF achieves superior performance. Furthermore, The Pareto\nfront solutions of QSVMF enable analysis of accuracy versus feature set size\ntrade-offs, identifying extremely sparse yet accurate feature subsets. We\ncontextualize the biological relevance of the selected features in terms of\nknown breast cancer biomarkers. This work highlights the potential of\nquantum-based feature selection to enhance machine learning efficiency and\nperformance on complex real-world data.",
            "author": [
                "Haiyan Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17646v1",
                "http://arxiv.org/pdf/2311.17646v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17633v1",
            "title": "Introduction to Transformers: an NLP Perspective",
            "updated": "2023-11-29T13:51:04Z",
            "published": "2023-11-29T13:51:04Z",
            "summary": "Transformers have dominated empirical machine learning models of natural\nlanguage processing. In this paper, we introduce basic concepts of Transformers\nand present key techniques that form the recent advances of these models. This\nincludes a description of the standard Transformer architecture, a series of\nmodel refinements, and common applications. Given that Transformers and related\ndeep learning techniques might be evolving in ways we have never seen, we\ncannot dive into all the model details or cover all the technical areas.\nInstead, we focus on just those concepts that are helpful for gaining a good\nunderstanding of Transformers and their variants. We also summarize the key\nideas that impact this field, thereby yielding some insights into the strengths\nand limitations of these models.",
            "author": [
                "Tong Xiao",
                "Jingbo Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17633v1",
                "http://arxiv.org/pdf/2311.17633v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17631v1",
            "title": "Q-learning Based Optimal False Data Injection Attack on Probabilistic\n  Boolean Control Networks",
            "updated": "2023-11-29T13:45:07Z",
            "published": "2023-11-29T13:45:07Z",
            "summary": "In this paper, we present a reinforcement learning (RL) method for solving\noptimal false data injection attack problems in probabilistic Boolean control\nnetworks (PBCNs) where the attacker lacks knowledge of the system model.\nSpecifically, we employ a Q-learning (QL) algorithm to address this problem. We\nthen propose an improved QL algorithm that not only enhances learning\nefficiency but also obtains optimal attack strategies for large-scale PBCNs\nthat the standard QL algorithm cannot handle. Finally, we verify the\neffectiveness of our proposed approach by considering two attacked PBCNs,\nincluding a 10-node network and a 28-node network.",
            "author": [
                "Xianlun Peng",
                "Yang Tang",
                "Fangfei Li",
                "Yang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17631v1",
                "http://arxiv.org/pdf/2311.17631v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.CR",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17621v1",
            "title": "The AutoSPADA Platform: User-Friendly Edge Computing for Distributed\n  Learning and Data Analytics in Connected Vehicles",
            "updated": "2023-11-29T13:30:26Z",
            "published": "2023-11-29T13:30:26Z",
            "summary": "Contemporary connected vehicles host numerous applications, such as\ndiagnostics and navigation, and new software is continuously being developed.\nHowever, the development process typically requires offline batch processing of\nlarge data volumes. In an edge computing approach, data analysts and developers\ncan instead process sensor data directly on computational resources inside\nvehicles. This enables rapid prototyping to shorten development cycles and\nreduce the time to create new business values or insights. This paper presents\nthe design, implementation, and operation of the AutoSPADA edge computing\nplatform for distributed data analytics. The platform's design follows\nscalability, reliability, resource efficiency, privacy, and security principles\npromoted through mature and industrially proven technologies. In AutoSPADA,\ncomputational tasks are general Python scripts, and we provide a library to,\nfor example, read signals from the vehicle and publish results to the cloud.\nHence, users only need Python knowledge to use the platform. Moreover, the\nplatform is designed to be extended to support additional programming\nlanguages.",
            "author": [
                "Adrian Nilsson",
                "Simon Smith",
                "Jonas Hagmar",
                "Magnus \u00d6nnheim",
                "Mats Jirstrand"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17621v1",
                "http://arxiv.org/pdf/2311.17621v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17618v3",
            "title": "ShapeGPT: 3D Shape Generation with A Unified Multi-modal Language Model",
            "updated": "2023-12-01T12:46:13Z",
            "published": "2023-11-29T13:26:29Z",
            "summary": "The advent of large language models, enabling flexibility through\ninstruction-driven approaches, has revolutionized many traditional generative\ntasks, but large models for 3D data, particularly in comprehensively handling\n3D shapes with other modalities, are still under-explored. By achieving\ninstruction-based shape generations, versatile multimodal generative shape\nmodels can significantly benefit various fields like 3D virtual construction\nand network-aided design. In this work, we present ShapeGPT, a shape-included\nmulti-modal framework to leverage strong pre-trained language models to address\nmultiple shape-relevant tasks. Specifically, ShapeGPT employs a\nword-sentence-paragraph framework to discretize continuous shapes into shape\nwords, further assembles these words for shape sentences, as well as integrates\nshape with instructional text for multi-modal paragraphs. To learn this\nshape-language model, we use a three-stage training scheme, including shape\nrepresentation, multimodal alignment, and instruction-based generation, to\nalign shape-language codebooks and learn the intricate correlations among these\nmodalities. Extensive experiments demonstrate that ShapeGPT achieves comparable\nperformance across shape-relevant tasks, including text-to-shape,\nshape-to-text, shape completion, and shape editing.",
            "author": [
                "Fukun Yin",
                "Xin Chen",
                "Chi Zhang",
                "Biao Jiang",
                "Zibo Zhao",
                "Jiayuan Fan",
                "Gang Yu",
                "Taihao Li",
                "Tao Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17618v3",
                "http://arxiv.org/pdf/2311.17618v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17609v1",
            "title": "AnyLens: A Generative Diffusion Model with Any Rendering Lens",
            "updated": "2023-11-29T13:06:48Z",
            "published": "2023-11-29T13:06:48Z",
            "summary": "State-of-the-art diffusion models can generate highly realistic images based\non various conditioning like text, segmentation, and depth. However, an\nessential aspect often overlooked is the specific camera geometry used during\nimage capture. The influence of different optical systems on the final scene\nappearance is frequently overlooked. This study introduces a framework that\nintimately integrates a text-to-image diffusion model with the particular lens\ngeometry used in image rendering. Our method is based on a per-pixel coordinate\nconditioning method, enabling the control over the rendering geometry. Notably,\nwe demonstrate the manipulation of curvature properties, achieving diverse\nvisual effects, such as fish-eye, panoramic views, and spherical texturing\nusing a single diffusion model.",
            "author": [
                "Andrey Voynov",
                "Amir Hertz",
                "Moab Arar",
                "Shlomi Fruchter",
                "Daniel Cohen-Or"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17609v1",
                "http://arxiv.org/pdf/2311.17609v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17608v1",
            "title": "Adversarial Robust Memory-Based Continual Learner",
            "updated": "2023-11-29T13:05:20Z",
            "published": "2023-11-29T13:05:20Z",
            "summary": "Despite the remarkable advances that have been made in continual learning,\nthe adversarial vulnerability of such methods has not been fully discussed. We\ndelve into the adversarial robustness of memory-based continual learning\nalgorithms and observe limited robustness improvement by directly applying\nadversarial training techniques. Preliminary studies reveal the twin challenges\nfor building adversarial robust continual learners: accelerated forgetting in\ncontinual learning and gradient obfuscation in adversarial robustness. In this\nstudy, we put forward a novel adversarial robust memory-based continual learner\nthat adjusts data logits to mitigate the forgetting of pasts caused by\nadversarial samples. Furthermore, we devise a gradient-based data selection\nmechanism to overcome the gradient obfuscation caused by limited stored data.\nThe proposed approach can widely integrate with existing memory-based continual\nlearning as well as adversarial training algorithms in a plug-and-play way.\nExtensive experiments on Split-CIFAR10/100 and Split-Tiny-ImageNet demonstrate\nthe effectiveness of our approach, achieving up to 8.13% higher accuracy for\nadversarial data.",
            "author": [
                "Xiaoyue Mi",
                "Fan Tang",
                "Zonghan Yang",
                "Danding Wang",
                "Juan Cao",
                "Peng Li",
                "Yang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17608v1",
                "http://arxiv.org/pdf/2311.17608v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17607v1",
            "title": "Topology-Preserving Adversarial Training",
            "updated": "2023-11-29T13:05:06Z",
            "published": "2023-11-29T13:05:06Z",
            "summary": "Despite the effectiveness in improving the robustness of neural networks,\nadversarial training has suffered from the natural accuracy degradation\nproblem, i.e., accuracy on natural samples has reduced significantly. In this\nstudy, we reveal that natural accuracy degradation is highly related to the\ndisruption of the natural sample topology in the representation space by\nquantitative and qualitative experiments. Based on this observation, we propose\nTopology-pReserving Adversarial traINing (TRAIN) to alleviate the problem by\npreserving the topology structure of natural samples from a standard model\ntrained only on natural samples during adversarial training. As an additional\nregularization, our method can easily be combined with various popular\nadversarial training algorithms in a plug-and-play manner, taking advantage of\nboth sides. Extensive experiments on CIFAR-10, CIFAR-100, and Tiny ImageNet\nshow that our proposed method achieves consistent and significant improvements\nover various strong baselines in most cases. Specifically, without additional\ndata, our proposed method achieves up to 8.78% improvement in natural accuracy\nand 4.50% improvement in robust accuracy.",
            "author": [
                "Xiaoyue Mi",
                "Fan Tang",
                "Yepeng Weng",
                "Danding Wang",
                "Juan Cao",
                "Sheng Tang",
                "Peng Li",
                "Yang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17607v1",
                "http://arxiv.org/pdf/2311.17607v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17603v1",
            "title": "sec-certs: Examining the security certification practice for better\n  vulnerability mitigation",
            "updated": "2023-11-29T12:55:16Z",
            "published": "2023-11-29T12:55:16Z",
            "summary": "Products certified under security certification frameworks such as Common\nCriteria undergo significant scrutiny during the costly certification process.\nYet, critical vulnerabilities, including private key recovery (ROCA, Minerva,\nTPM-Fail...), get discovered in certified products with high assurance levels.\nFurthermore, assessing which certified products are impacted by such\nvulnerabilities is complicated due to the large amount of unstructured\ncertification-related data and unclear relationships between the certificates.\nTo address these problems, we conducted a large-scale automated analysis of\nCommon Criteria and FIPS 140 certificates. We trained unsupervised models to\nlearn which vulnerabilities from NIST's National Vulnerability Database impact\nexisting certified products and how certified products reference each other.\nOur tooling automates the analysis of tens of thousands of\ncertification-related documents, extracting machine-readable features where\nmanual analysis is unattainable. Further, we identify the security requirements\nthat are associated with products being affected by fewer and less severe\nvulnerabilities (on average). This indicates which aspects of certification\ncorrelate with higher security. We demonstrate how our tool can be used for\nbetter vulnerability mitigation on four case studies of known, high-profile\nvulnerabilities. All tools and continuously updated results are available at\nhttps://seccerts.org.",
            "author": [
                "Adam Janovsky",
                "Jan Jancar",
                "Petr Svenda",
                "\u0141ukasz Chmielewski",
                "Jiri Michalik",
                "Vashek Matyas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17603v1",
                "http://arxiv.org/pdf/2311.17603v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17601v1",
            "title": "Continual Learning with Low Rank Adaptation",
            "updated": "2023-11-29T12:53:32Z",
            "published": "2023-11-29T12:53:32Z",
            "summary": "Recent work using pretrained transformers has shown impressive performance\nwhen fine-tuned with data from the downstream problem of interest. However,\nthey struggle to retain that performance when the data characteristics changes.\nIn this paper, we focus on continual learning, where a pre-trained transformer\nis updated to perform well on new data, while retaining its performance on data\nit was previously trained on. Earlier works have tackled this primarily through\nmethods inspired from prompt tuning. We question this choice, and investigate\nthe applicability of Low Rank Adaptation (LoRA) to continual learning. On a\nrange of domain-incremental learning benchmarks, our LoRA-based solution,\nCoLoR, yields state-of-the-art performance, while still being as parameter\nefficient as the prompt tuning based methods.",
            "author": [
                "Martin Wistuba",
                "Prabhu Teja Sivaprasad",
                "Lukas Balles",
                "Giovanni Zappella"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17601v1",
                "http://arxiv.org/pdf/2311.17601v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17598v1",
            "title": "Improving embedding of graphs with missing data by soft manifolds",
            "updated": "2023-11-29T12:48:33Z",
            "published": "2023-11-29T12:48:33Z",
            "summary": "Embedding graphs in continous spaces is a key factor in designing and\ndeveloping algorithms for automatic information extraction to be applied in\ndiverse tasks (e.g., learning, inferring, predicting). The reliability of graph\nembeddings directly depends on how much the geometry of the continuous space\nmatches the graph structure. Manifolds are mathematical structure that can\nenable to incorporate in their topological spaces the graph characteristics,\nand in particular nodes distances. State-of-the-art of manifold-based graph\nembedding algorithms take advantage of the assumption that the projection on a\ntangential space of each point in the manifold (corresponding to a node in the\ngraph) would locally resemble a Euclidean space. Although this condition helps\nin achieving efficient analytical solutions to the embedding problem, it does\nnot represent an adequate set-up to work with modern real life graphs, that are\ncharacterized by weighted connections across nodes often computed over sparse\ndatasets with missing records. In this work, we introduce a new class of\nmanifold, named soft manifold, that can solve this situation. In particular,\nsoft manifolds are mathematical structures with spherical symmetry where the\ntangent spaces to each point are hypocycloids whose shape is defined according\nto the velocity of information propagation across the data points. Using soft\nmanifolds for graph embedding, we can provide continuous spaces to pursue any\ntask in data analysis over complex datasets. Experimental results on\nreconstruction tasks on synthetic and real datasets show how the proposed\napproach enable more accurate and reliable characterization of graphs in\ncontinuous spaces with respect to the state-of-the-art.",
            "author": [
                "Andrea Marinoni",
                "Pietro Lio'",
                "Alessandro Barp",
                "Christian Jutten",
                "Mark Girolami"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17598v1",
                "http://arxiv.org/pdf/2311.17598v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17597v2",
            "title": "Continual Self-supervised Learning: Towards Universal Multi-modal\n  Medical Data Representation Learning",
            "updated": "2023-11-30T02:06:13Z",
            "published": "2023-11-29T12:47:42Z",
            "summary": "Self-supervised learning is an efficient pre-training method for medical\nimage analysis. However, current research is mostly confined to\nspecific-modality data pre-training, consuming considerable time and resources\nwithout achieving universality across different modalities. A straightforward\nsolution is combining all modality data for joint self-supervised pre-training,\nwhich poses practical challenges. Firstly, our experiments reveal conflicts in\nrepresentation learning as the number of modalities increases. Secondly,\nmulti-modal data collected in advance cannot cover all real-world scenarios. In\nthis paper, we reconsider versatile self-supervised learning from the\nperspective of continual learning and propose MedCoSS, a continuous\nself-supervised learning approach for multi-modal medical data. Unlike joint\nself-supervised learning, MedCoSS assigns different modality data to different\ntraining stages, forming a multi-stage pre-training process. To balance modal\nconflicts and prevent catastrophic forgetting, we propose a rehearsal-based\ncontinual learning method. We introduce the k-means sampling strategy to retain\ndata from previous modalities and rehearse it when learning new modalities.\nInstead of executing the pretext task on buffer data, a feature distillation\nstrategy and an intra-modal mixup strategy are applied to these data for\nknowledge retention. We conduct continuous self-supervised pre-training on a\nlarge-scale multi-modal unlabeled dataset, including clinical reports, X-rays,\nCT scans, MRI scans, and pathological images. Experimental results demonstrate\nMedCoSS's exceptional generalization ability across nine downstream datasets\nand its significant scalability in integrating new modality data. Code and\npre-trained weight are available at https://github.com/yeerwen/MedCoSS.",
            "author": [
                "Yiwen Ye",
                "Yutong Xie",
                "Jianpeng Zhang",
                "Ziyang Chen",
                "Qi Wu",
                "Yong Xia"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17597v2",
                "http://arxiv.org/pdf/2311.17597v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17593v1",
            "title": "LanGWM: Language Grounded World Model",
            "updated": "2023-11-29T12:41:55Z",
            "published": "2023-11-29T12:41:55Z",
            "summary": "Recent advances in deep reinforcement learning have showcased its potential\nin tackling complex tasks. However, experiments on visual control tasks have\nrevealed that state-of-the-art reinforcement learning models struggle with\nout-of-distribution generalization. Conversely, expressing higher-level\nconcepts and global contexts is relatively easy using language.\n  Building upon recent success of the large language models, our main objective\nis to improve the state abstraction technique in reinforcement learning by\nleveraging language for robust action selection. Specifically, we focus on\nlearning language-grounded visual features to enhance the world model learning,\na model-based reinforcement learning technique.\n  To enforce our hypothesis explicitly, we mask out the bounding boxes of a few\nobjects in the image observation and provide the text prompt as descriptions\nfor these masked objects. Subsequently, we predict the masked objects along\nwith the surrounding regions as pixel reconstruction, similar to the\ntransformer-based masked autoencoder approach.\n  Our proposed LanGWM: Language Grounded World Model achieves state-of-the-art\nperformance in out-of-distribution test at the 100K interaction steps\nbenchmarks of iGibson point navigation tasks. Furthermore, our proposed\ntechnique of explicit language-grounded visual representation learning has the\npotential to improve models for human-robot interaction because our extracted\nvisual features are language grounded.",
            "author": [
                "Rudra P. K. Poudel",
                "Harit Pandya",
                "Chao Zhang",
                "Roberto Cipolla"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17593v1",
                "http://arxiv.org/pdf/2311.17593v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL",
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17592v1",
            "title": "Robust Correlated Equilibrium: Definition and Computation",
            "updated": "2023-11-29T12:41:17Z",
            "published": "2023-11-29T12:41:17Z",
            "summary": "We study N-player finite games with costs perturbed due to time-varying\ndisturbances in the underlying system and to that end we propose the concept of\nRobust Correlated Equilibrium that generalizes the definition of Correlated\nEquilibrium. Conditions under which the Robust Correlated Equilibrium exists\nare specified and a decentralized algorithm for learning strategies that are\noptimal in the sense of Robust Correlated Equilibrium is proposed. The primary\ncontribution of the paper is the convergence analysis of the algorithm and to\nthat end, we propose an extension of the celebrated Blackwell's Approachability\ntheorem to games with costs that are not just time-average as in the original\nBlackwell's Approachability Theorem but also include time-average of previous\nalgorithm iterates. The designed algorithm is applied to a practical water\ndistribution network with pumps being the controllers and their costs being\nperturbed by uncertain consumption by consumers. Simulation results show that\neach controller achieves no regret and empirical distributions converge to the\nRobust Correlated Equilibrium.",
            "author": [
                "Rahul Misra",
                "Rafa\u0142 Wisniewski",
                "Carsten Skovmose Kalles\u00f8e",
                "Manuela L. Bujorianu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17592v1",
                "http://arxiv.org/pdf/2311.17592v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.MA",
                "cs.SY",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17968v1",
            "title": "Latent Alignment with Deep Set EEG Decoders",
            "updated": "2023-11-29T12:40:45Z",
            "published": "2023-11-29T12:40:45Z",
            "summary": "The variability in EEG signals between different individuals poses a\nsignificant challenge when implementing brain-computer interfaces (BCI).\nCommonly proposed solutions to this problem include deep learning models, due\nto their increased capacity and generalization, as well as explicit domain\nadaptation techniques. Here, we introduce the Latent Alignment method that won\nthe Benchmarks for EEG Transfer Learning (BEETL) competition and present its\nformulation as a deep set applied on the set of trials from a given subject.\nIts performance is compared to recent statistical domain adaptation techniques\nunder various conditions. The experimental paradigms include motor imagery\n(MI), oddball event-related potentials (ERP) and sleep stage classification,\nwhere different well-established deep learning models are applied on each task.\nOur experimental results show that performing statistical distribution\nalignment at later stages in a deep learning model is beneficial to the\nclassification accuracy, yielding the highest performance for our proposed\nmethod. We further investigate practical considerations that arise in the\ncontext of using deep learning and statistical alignment for EEG decoding. In\nthis regard, we study class-discriminative artifacts that can spuriously\nimprove results for deep learning models, as well as the impact of\nclass-imbalance on alignment. We delineate a trade-off relationship between\nincreased classification accuracy when alignment is performed at later modeling\nstages, and susceptibility to class-imbalance in the set of trials that the\nstatistics are computed on.",
            "author": [
                "Stylianos Bakas",
                "Siegfried Ludwig",
                "Dimitrios A. Adamos",
                "Nikolaos Laskaris",
                "Yannis Panagakis",
                "Stefanos Zafeiriou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17968v1",
                "http://arxiv.org/pdf/2311.17968v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.AI",
                "cs.HC",
                "cs.LG",
                "I.2.6"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17967v1",
            "title": "Discovering Galaxy Features via Dataset Distillation",
            "updated": "2023-11-29T12:39:31Z",
            "published": "2023-11-29T12:39:31Z",
            "summary": "In many applications, Neural Nets (NNs) have classification performance on\npar or even exceeding human capacity. Moreover, it is likely that NNs leverage\nunderlying features that might differ from those humans perceive to classify.\nCan we \"reverse-engineer\" pertinent features to enhance our scientific\nunderstanding? Here, we apply this idea to the notoriously difficult task of\ngalaxy classification: NNs have reached high performance for this task, but\nwhat does a neural net (NN) \"see\" when it classifies galaxies? Are there\nmorphological features that the human eye might overlook that could help with\nthe task and provide new insights? Can we visualize tracers of early evolution,\nor additionally incorporated spectral data? We present a novel way to summarize\nand visualize galaxy morphology through the lens of neural networks, leveraging\nDataset Distillation, a recent deep-learning methodology with the primary\nobjective to distill knowledge from a large dataset and condense it into a\ncompact synthetic dataset, such that a model trained on this synthetic dataset\nachieves performance comparable to a model trained on the full dataset. We\ncurate a class-balanced, medium-size high-confidence version of the Galaxy Zoo\n2 dataset, and proceed with dataset distillation from our accurate\nNN-classifier to create synthesized prototypical images of galaxy morphological\nfeatures, demonstrating its effectiveness. Of independent interest, we\nintroduce a self-adaptive version of the state-of-the-art Matching Trajectory\nalgorithm to automate the distillation process, and show enhanced performance\non computer vision benchmarks.",
            "author": [
                "Haowen Guan",
                "Xuan Zhao",
                "Zishi Wang",
                "Zhiyang Li",
                "Julia Kempe"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17967v1",
                "http://arxiv.org/pdf/2311.17967v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "astro-ph.IM",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17587v1",
            "title": "Deep Reinforcement Learning Graphs: Feedback Motion Planning via Neural\n  Lyapunov Verification",
            "updated": "2023-11-29T12:31:06Z",
            "published": "2023-11-29T12:31:06Z",
            "summary": "Recent advancements in model-free deep reinforcement learning have enabled\nefficient agent training. However, challenges arise when determining the region\nof attraction for these controllers, especially if the region does not fully\ncover the desired area. This paper addresses this issue by introducing a\nfeedback motion control algorithm that utilizes data-driven techniques and\nneural networks. The algorithm constructs a graph of connected\nreinforcement-learning based controllers, each with its own defined region of\nattraction. This incremental approach effectively covers a bounded region of\ninterest, creating a trajectory of interconnected nodes that guide the system\nfrom an initial state to the goal. Two approaches are presented for connecting\nnodes within the algorithm. The first is a tree-structured method, facilitating\n\"point-to-point\" control by constructing a tree connecting the initial state to\nthe goal state. The second is a graph-structured method, enabling\n\"space-to-space\" control by building a graph within a bounded region. This\napproach allows for control from arbitrary initial and goal states. The\nproposed method's performance is evaluated on a first-order dynamic system,\nconsidering scenarios both with and without obstacles. The results demonstrate\nthe effectiveness of the proposed algorithm in achieving the desired control\nobjectives.",
            "author": [
                "Armin Ghanbarzadeh",
                "Esmaeil Najafi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17587v1",
                "http://arxiv.org/pdf/2311.17587v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.RO",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17586v1",
            "title": "Federated Online and Bandit Convex Optimization",
            "updated": "2023-11-29T12:29:54Z",
            "published": "2023-11-29T12:29:54Z",
            "summary": "We study the problems of distributed online and bandit convex optimization\nagainst an adaptive adversary. We aim to minimize the average regret on $M$\nmachines working in parallel over $T$ rounds with $R$ intermittent\ncommunications. Assuming the underlying cost functions are convex and can be\ngenerated adaptively, our results show that collaboration is not beneficial\nwhen the machines have access to the first-order gradient information at the\nqueried points. This is in contrast to the case for stochastic functions, where\neach machine samples the cost functions from a fixed distribution. Furthermore,\nwe delve into the more challenging setting of federated online optimization\nwith bandit (zeroth-order) feedback, where the machines can only access values\nof the cost functions at the queried points. The key finding here is\nidentifying the high-dimensional regime where collaboration is beneficial and\nmay even lead to a linear speedup in the number of machines. We further\nillustrate our findings through federated adversarial linear bandits by\ndeveloping novel distributed single and two-point feedback algorithms. Our work\nis the first attempt towards a systematic understanding of federated online\noptimization with limited feedback, and it attains tight regret bounds in the\nintermittent communication setting for both first and zeroth-order feedback.\nOur results thus bridge the gap between stochastic and adaptive settings in\nfederated online optimization.",
            "author": [
                "Kumar Kshitij Patel",
                "Lingxiao Wang",
                "Aadirupa Saha",
                "Nati Sebro"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17586v1",
                "http://arxiv.org/pdf/2311.17586v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17583v1",
            "title": "CLIPC8: Face liveness detection algorithm based on image-text pairs and\n  contrastive learning",
            "updated": "2023-11-29T12:21:42Z",
            "published": "2023-11-29T12:21:42Z",
            "summary": "Face recognition technology is widely used in the financial field, and\nvarious types of liveness attack behaviors need to be addressed. Existing\nliveness detection algorithms are trained on specific training datasets and\ntested on testing datasets, but their performance and robustness in\ntransferring to unseen datasets are relatively poor. To tackle this issue, we\npropose a face liveness detection method based on image-text pairs and\ncontrastive learning, dividing liveness attack problems in the financial field\ninto eight categories and using text information to describe the images of\nthese eight types of attacks. The text encoder and image encoder are used to\nextract feature vector representations for the classification description text\nand face images, respectively. By maximizing the similarity of positive samples\nand minimizing the similarity of negative samples, the model learns shared\nrepresentations between images and texts. The proposed method is capable of\neffectively detecting specific liveness attack behaviors in certain scenarios,\nsuch as those occurring in dark environments or involving the tampering of ID\ncard photos. Additionally, it is also effective in detecting traditional\nliveness attack methods, such as printing photo attacks and screen remake\nattacks. The zero-shot capabilities of face liveness detection on five public\ndatasets, including NUAA, CASIA-FASD, Replay-Attack, OULU-NPU and MSU-MFSD also\nreaches the level of commercial algorithms. The detection capability of\nproposed algorithm was verified on 5 types of testing datasets, and the results\nshow that the method outperformed commercial algorithms, and the detection\nrates reached 100% on multiple datasets. Demonstrating the effectiveness and\nrobustness of introducing image-text pairs and contrastive learning into\nliveness detection tasks as proposed in this paper.",
            "author": [
                "Xu Liu",
                "Shu Zhou",
                "Yurong Song",
                "Wenzhe Luo",
                "Xin Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17583v1",
                "http://arxiv.org/pdf/2311.17583v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17582v1",
            "title": "LoCoMotif: Discovering time-warped motifs in time series",
            "updated": "2023-11-29T12:18:46Z",
            "published": "2023-11-29T12:18:46Z",
            "summary": "Time Series Motif Discovery (TSMD) refers to the task of identifying patterns\nthat occur multiple times (possibly with minor variations) in a time series.\nAll existing methods for TSMD have one or more of the following limitations:\nthey only look for the two most similar occurrences of a pattern; they only\nlook for patterns of a pre-specified, fixed length; they cannot handle\nvariability along the time axis; and they only handle univariate time series.\nIn this paper, we present a new method, LoCoMotif, that has none of these\nlimitations. The method is motivated by a concrete use case from physiotherapy.\nWe demonstrate the value of the proposed method on this use case. We also\nintroduce a new quantitative evaluation metric for motif discovery, and\nbenchmark data for comparing TSMD methods. LoCoMotif substantially outperforms\nthe existing methods, on top of being more broadly applicable.",
            "author": [
                "Daan Van Wesenbeeck",
                "Aras Yurtman",
                "Wannes Meert",
                "Hendrik Blockeel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17582v1",
                "http://arxiv.org/pdf/2311.17582v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17575v1",
            "title": "Identifying Causal Effects of Nonbinary, Ordered Treatments using\n  Multiple Instrumental Variables",
            "updated": "2023-11-29T12:11:44Z",
            "published": "2023-11-29T12:11:44Z",
            "summary": "This paper addresses the challenge of identifying causal effects of\nnonbinary, ordered treatments with multiple binary instruments. Next to\npresenting novel insights into the widely-applied two-stage least squares\nestimand, I show that a weighted average of local average treatment effects for\ncombined complier populations is identified under the limited monotonicity\nassumption. This novel causal parameter has an intuitive interpretation,\noffering an appealing alternative to two-stage least squares. I employ recent\nadvances in causal machine learning for estimation. I further demonstrate how\ncausal forests can be used to detect local violations of the underlying limited\nmonotonicity assumption. The methodology is applied to study the impact of\ncommunity nurseries on child health outcomes.",
            "author": [
                "Nadja van 't Hoff"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17575v1",
                "http://arxiv.org/pdf/2311.17575v1"
            ],
            "primary_category": "econ.EM",
            "category": [
                "econ.EM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17965v1",
            "title": "Defining Reference Sequences for Nocardia Species by Similarity and\n  Clustering Analyses of 16S rRNA Gene Sequence Data",
            "updated": "2023-11-29T12:09:02Z",
            "published": "2023-11-29T12:09:02Z",
            "summary": "The intra- and inter-species genetic diversity of bacteria and the absence of\n'reference', or the most representative, sequences of individual species\npresent a significant challenge for sequence-based identification. The aims of\nthis study were to determine the utility, and compare the performance of\nseveral clustering and classification algorithms to identify the species of 364\nsequences of 16S rRNA gene with a defined species in GenBank, and 110 sequences\nof 16S rRNA gene with no defined species, all within the genus Nocardia. A\ntotal of 364 16S rRNA gene sequences of Nocardia species were studied. In\naddition, 110 16S rRNA gene sequences assigned only to the Nocardia genus level\nat the time of submission to GenBank were used for machine learning\nclassification experiments. Different clustering algorithms were compared with\na novel algorithm or the linear mapping (LM) of the distance matrix. Principal\nComponents Analysis was used for the dimensionality reduction and\nvisualization. Results: The LM algorithm achieved the highest performance and\nclassified the set of 364 16S rRNA sequences into 80 clusters, the majority of\nwhich (83.52%) corresponded with the original species. The most representative\n16S rRNA sequences for individual Nocardia species have been identified as\n'centroids' in respective clusters from which the distances to all other\nsequences were minimized; 110 16S rRNA gene sequences with identifications\nrecorded only at the genus level were classified using machine learning\nmethods. Simple kNN machine learning demonstrated the highest performance and\nclassified Nocardia species sequences with an accuracy of 92.7% and a mean\nfrequency of 0.578.",
            "author": [
                "Manal Helal",
                "Fanrong Kong",
                "Sharon C. A. Chen",
                "Michael Bain",
                "Richard Christen",
                "Vitali Sintchenko"
            ],
            "link": [
                "http://dx.doi.org/10.1371/journal.pone.0019517",
                "http://arxiv.org/abs/2311.17965v1",
                "http://arxiv.org/pdf/2311.17965v1"
            ],
            "primary_category": "q-bio.GN",
            "category": [
                "q-bio.GN",
                "cs.LG",
                "I.2.6"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17565v1",
            "title": "Bias Resilient Multi-Step Off-Policy Goal-Conditioned Reinforcement\n  Learning",
            "updated": "2023-11-29T11:59:03Z",
            "published": "2023-11-29T11:59:03Z",
            "summary": "In goal-conditioned reinforcement learning (GCRL), sparse rewards present\nsignificant challenges, often obstructing efficient learning. Although\nmulti-step GCRL can boost this efficiency, it can also lead to off-policy\nbiases in target values. This paper dives deep into these biases, categorizing\nthem into two distinct categories: \"shooting\" and \"shifting\". Recognizing that\ncertain behavior policies can hasten policy refinement, we present solutions\ndesigned to capitalize on the positive aspects of these biases while minimizing\ntheir drawbacks, enabling the use of larger step sizes to speed up GCRL. An\nempirical study demonstrates that our approach ensures a resilient and robust\nimprovement, even in ten-step learning scenarios, leading to superior learning\nefficiency and performance that generally surpass the baseline and several\nstate-of-the-art multi-step GCRL benchmarks.",
            "author": [
                "Lisheng Wu",
                "Ke Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17565v1",
                "http://arxiv.org/pdf/2311.17565v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17563v1",
            "title": "Efficient Computation of Sparse and Robust Maximum Association\n  Estimators",
            "updated": "2023-11-29T11:57:50Z",
            "published": "2023-11-29T11:57:50Z",
            "summary": "Although robust statistical estimators are less affected by outlying\nobservations, their computation is usually more challenging. This is\nparticularly the case in high-dimensional sparse settings. The availability of\nnew optimization procedures, mainly developed in the computer science domain,\noffers new possibilities for the field of robust statistics. This paper\ninvestigates how such procedures can be used for robust sparse association\nestimators. The problem can be split into a robust estimation step followed by\nan optimization for the remaining decoupled, (bi-)convex problem. A combination\nof the augmented Lagrangian algorithm and adaptive gradient descent is\nimplemented to also include suitable constraints for inducing sparsity. We\nprovide results concerning the precision of the algorithm and show the\nadvantages over existing algorithms in this context. High-dimensional empirical\nexamples underline the usefulness of this procedure. Extensions to other robust\nsparse estimators are possible.",
            "author": [
                "Pia Pfeiffer",
                "Andreas Alfons",
                "Peter Filzmoser"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17563v1",
                "http://arxiv.org/pdf/2311.17563v1"
            ],
            "primary_category": "stat.CO",
            "category": [
                "stat.CO",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17964v1",
            "title": "Linear normalised hash function for clustering gene sequences and\n  identifying reference sequences from multiple sequence alignments",
            "updated": "2023-11-29T11:51:05Z",
            "published": "2023-11-29T11:51:05Z",
            "summary": "The aim of this study was to develop a method that would identify the cluster\ncentroids and the optimal number of clusters for a given sensitivity level and\ncould work equally well for the different sequence datasets. A novel method\nthat combines the linear mapping hash function and multiple sequence alignment\n(MSA) was developed. This method takes advantage of the already sorted by\nsimilarity sequences from the MSA output, and identifies the optimal number of\nclusters, clusters cut-offs, and clusters centroids that can represent\nreference gene vouchers for the different species. The linear mapping hash\nfunction can map an already ordered by similarity distance matrix to indices to\nreveal gaps in the values around which the optimal cut-offs of the different\nclusters can be identified. The method was evaluated using sets of closely\nrelated (16S rRNA gene sequences of Nocardia species) and highly variable (VP1\ngenomic region of Enterovirus 71) sequences and outperformed existing\nunsupervised machine learning clustering methods and dimensionality reduction\nmethods. This method does not require prior knowledge of the number of clusters\nor the distance between clusters, handles clusters of different sizes and\nshapes, and scales linearly with the dataset. The combination of MSA with the\nlinear mapping hash function is a computationally efficient way of gene\nsequence clustering and can be a valuable tool for the assessment of\nsimilarity, clustering of different microbial genomes, identifying reference\nsequences, and for the study of evolution of bacteria and viruses.",
            "author": [
                "Manal Helal",
                "Fanrong Kong",
                "Sharon C-A Chen",
                "Fei Zhou",
                "Dominic E Dwyer",
                "John Potter",
                "Vitali Sintchenko"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17964v1",
                "http://arxiv.org/pdf/2311.17964v1"
            ],
            "primary_category": "q-bio.GN",
            "category": [
                "q-bio.GN",
                "cs.LG",
                "I.2.6"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17560v1",
            "title": "Interpreting Differentiable Latent States for Healthcare Time-series\n  Data",
            "updated": "2023-11-29T11:48:16Z",
            "published": "2023-11-29T11:48:16Z",
            "summary": "Machine learning enables extracting clinical insights from large temporal\ndatasets. The applications of such machine learning models include identifying\ndisease patterns and predicting patient outcomes. However, limited\ninterpretability poses challenges for deploying advanced machine learning in\ndigital healthcare. Understanding the meaning of latent states is crucial for\ninterpreting machine learning models, assuming they capture underlying\npatterns. In this paper, we present a concise algorithm that allows for i)\ninterpreting latent states using highly related input features; ii)\ninterpreting predictions using subsets of input features via latent states; and\niii) interpreting changes in latent states over time. The proposed algorithm is\nfeasible for any model that is differentiable. We demonstrate that this\napproach enables the identification of a daytime behavioral pattern for\npredicting nocturnal behavior in a real-world healthcare dataset.",
            "author": [
                "Yu Chen",
                "Nivedita Bijlani",
                "Samaneh Kouchaki",
                "Payam Barnaghi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17560v1",
                "http://arxiv.org/pdf/2311.17560v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17553v1",
            "title": "Deep Learning 21cm Lightcones in 3D",
            "updated": "2023-11-29T11:36:15Z",
            "published": "2023-11-29T11:36:15Z",
            "summary": "Interferometric measurements of the 21cm signal are a prime example of the\ndata-driven era in astrophysics we are entering with current and upcoming\nexperiments. We showcase the use of deep networks that are tailored for the\nstructure of 3D tomographic 21cm light-cones to firstly detect and characterise\nHI sources and to secondly directly infer global astrophysical and cosmological\nmodel parameters. We compare different architectures and highlight how 3D CNN\narchitectures that mirror the data structure are the best-performing model.",
            "author": [
                "Caroline Heneka"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-031-34167-0_34",
                "http://arxiv.org/abs/2311.17553v1",
                "http://arxiv.org/pdf/2311.17553v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17552v1",
            "title": "An Efficient Illumination Invariant Tiger Detection Framework for\n  Wildlife Surveillance",
            "updated": "2023-11-29T11:35:54Z",
            "published": "2023-11-29T11:35:54Z",
            "summary": "Tiger conservation necessitates the strategic deployment of multifaceted\ninitiatives encompassing the preservation of ecological habitats, anti-poaching\nmeasures, and community involvement for sustainable growth in the tiger\npopulation. With the advent of artificial intelligence, tiger surveillance can\nbe automated using object detection. In this paper, an accurate illumination\ninvariant framework is proposed based on EnlightenGAN and YOLOv8 for tiger\ndetection. The fine-tuned YOLOv8 model achieves a mAP score of 61% without\nillumination enhancement. The illumination enhancement improves the mAP by\n0.7%. The approaches elevate the state-of-the-art performance on the ATRW\ndataset by approximately 6% to 7%.",
            "author": [
                "Gaurav Pendharkar",
                "A. Ancy Micheal",
                "Jason Misquitta",
                "Ranjeesh Kaippada"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17552v1",
                "http://arxiv.org/pdf/2311.17552v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00258v1",
            "title": "Precipitation Nowcasting With Spatial And Temporal Transfer Learning\n  Using Swin-UNETR",
            "updated": "2023-11-29T11:35:50Z",
            "published": "2023-11-29T11:35:50Z",
            "summary": "Climate change has led to an increase in frequency of extreme weather events.\nEarly warning systems can prevent disasters and loss of life. Managing such\nevents remain a challenge for both public and private institutions.\nPrecipitation nowcasting can help relevant institutions to better prepare for\nsuch events. Numerical weather prediction (NWP) has traditionally been used to\nmake physics based forecasting, and recently deep learning based approaches\nhave been used to reduce turn-around time for nowcasting. In this work,\nrecently proposed Swin-UNETR (Swin UNEt TRansformer) is used for precipitation\nnowcasting for ten different regions of Europe. Swin-UNETR utilizes a U-shaped\nnetwork within which a swin transformer-based encoder extracts multi-scale\nfeatures from multiple input channels of satellite image, while CNN-based\ndecoder makes the prediction. Trained model is capable of nowcasting not only\nfor the regions for which data is available, but can also be used for new\nregions for which data is not available.",
            "author": [
                "Ajitabh Kumar"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00258v1",
                "http://arxiv.org/pdf/2312.00258v1"
            ],
            "primary_category": "physics.ao-ph",
            "category": [
                "physics.ao-ph",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17548v1",
            "title": "Detecting genuine multipartite entanglement via machine learning",
            "updated": "2023-11-29T11:31:22Z",
            "published": "2023-11-29T11:31:22Z",
            "summary": "In recent years, supervised and semi-supervised machine learning methods such\nas neural networks, support vector machines (SVM), and semi-supervised support\nvector machines (S4VM) have been widely used in quantum entanglement and\nquantum steering verification problems. However, few studies have focused on\ndetecting genuine multipartite entanglement based on machine learning. Here, we\ninvestigate supervised and semi-supervised machine learning for detecting\ngenuine multipartite entanglement of three-qubit states. We randomly generate\nthree-qubit density matrices, and train an SVM for the detection of genuine\nmultipartite entangled states. Moreover, we improve the training method of\nS4VM, which optimizes the grouping of prediction samples and then performs\niterative predictions. Through numerical simulation, it is confirmed that this\nmethod can significantly improve the prediction accuracy.",
            "author": [
                "Yi-Jun Luo",
                "Jin-Ming Liu",
                "Chengjie Zhang"
            ],
            "link": [
                "http://dx.doi.org/10.1103/PhysRevA.108.052424",
                "http://arxiv.org/abs/2311.17548v1",
                "http://arxiv.org/pdf/2311.17548v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17963v1",
            "title": "ChatIllusion: Efficient-Aligning Interleaved Generation ability with\n  Visual Instruction Model",
            "updated": "2023-11-29T11:30:33Z",
            "published": "2023-11-29T11:30:33Z",
            "summary": "As the capabilities of Large-Language Models (LLMs) become widely recognized,\nthere is an increasing demand for human-machine chat applications. Human\ninteraction with text often inherently invokes mental imagery, an aspect that\nexisting LLM-based chatbots like GPT-4 do not currently emulate, as they are\nconfined to generating text-only content. To bridge this gap, we introduce\nChatIllusion, an advanced Generative multimodal large language model (MLLM)\nthat combines the capabilities of LLM with not only visual comprehension but\nalso creativity. Specifically, ChatIllusion integrates Stable Diffusion XL and\nLlama, which have been fine-tuned on modest image-caption data, to facilitate\nmultiple rounds of illustrated chats. The central component of ChatIllusion is\nthe \"GenAdapter,\" an efficient approach that equips the multimodal language\nmodel with capabilities for visual representation, without necessitating\nmodifications to the foundational model. Extensive experiments validate the\nefficacy of our approach, showcasing its ability to produce diverse and\nsuperior-quality image outputs Simultaneously, it preserves semantic\nconsistency and control over the dialogue, significantly enhancing the overall\nuser's quality of experience (QoE). The code is available at\nhttps://github.com/litwellchi/ChatIllusion.",
            "author": [
                "Xiaowei Chi",
                "Yijiang Liu",
                "Zhengkai Jiang",
                "Rongyu Zhang",
                "Ziyi Lin",
                "Renrui Zhang",
                "Peng Gao",
                "Chaoyou Fu",
                "Shanghang Zhang",
                "Qifeng Liu",
                "Yike Guo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17963v1",
                "http://arxiv.org/pdf/2311.17963v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17546v1",
            "title": "VINNA for Neonates -- Orientation Independence through Latent\n  Augmentations",
            "updated": "2023-11-29T11:28:26Z",
            "published": "2023-11-29T11:28:26Z",
            "summary": "Fast and accurate segmentation of neonatal brain images is highly desired to\nbetter understand and detect changes during development and disease. Yet, the\nlimited availability of ground truth datasets, lack of standardized acquisition\nprotocols, and wide variations of head positioning pose challenges for method\ndevelopment. A few automated image analysis pipelines exist for newborn brain\nMRI segmentation, but they often rely on time-consuming procedures and require\nresampling to a common resolution, subject to loss of information due to\ninterpolation and down-sampling. Without registration and image resampling,\nvariations with respect to head positions and voxel resolutions have to be\naddressed differently. In deep-learning, external augmentations are\ntraditionally used to artificially expand the representation of spatial\nvariability, increasing the training dataset size and robustness. However,\nthese transformations in the image space still require resampling, reducing\naccuracy specifically in the context of label interpolation. We recently\nintroduced the concept of resolution-independence with the Voxel-size\nIndependent Neural Network framework, VINN. Here, we extend this concept by\nadditionally shifting all rigid-transforms into the network architecture with a\nfour degree of freedom (4-DOF) transform module, enabling resolution-aware\ninternal augmentations (VINNA). In this work we show that VINNA (i)\nsignificantly outperforms state-of-the-art external augmentation approaches,\n(ii) effectively addresses the head variations present specifically in newborn\ndatasets, and (iii) retains high segmentation accuracy across a range of\nresolutions (0.5-1.0 mm). The 4-DOF transform module is a powerful, general\napproach to implement spatial augmentation without requiring image or label\ninterpolation. The specific network application to newborns will be made\npublicly available as VINNA4neonates.",
            "author": [
                "Leonie Henschel",
                "David K\u00fcgler",
                "Lilla Z\u00f6llei",
                "Martin Reuter"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17546v1",
                "http://arxiv.org/pdf/2311.17546v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17961v1",
            "title": "Skilful Precipitation Nowcasting Using NowcastNet",
            "updated": "2023-11-29T11:24:52Z",
            "published": "2023-11-29T11:24:52Z",
            "summary": "Designing early warning system for precipitation requires accurate short-term\nforecasting system. Climate change has led to an increase in frequency of\nextreme weather events, and hence such systems can prevent disasters and loss\nof life. Managing such events remain a challenge for both public and private\ninstitutions. Precipitation nowcasting can help relevant institutions to better\nprepare for such events as they impact agriculture, transport, public health\nand safety, etc. Physics-based numerical weather prediction (NWP) is unable to\nperform well for nowcasting because of large computational turn-around time.\nDeep-learning based models on the other hand are able to give predictions\nwithin seconds. We use recently proposed NowcastNet, a physics-conditioned deep\ngenerative network, to forecast precipitation for different regions of Europe\nusing satellite images. Both spatial and temporal transfer learning is done by\nforecasting for the unseen regions and year. Model makes realistic predictions\nand is able to outperform baseline for such a prediction task.",
            "author": [
                "Ajitabh Kumar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17961v1",
                "http://arxiv.org/pdf/2311.17961v1"
            ],
            "primary_category": "physics.ao-ph",
            "category": [
                "physics.ao-ph",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17539v1",
            "title": "The Effects of Overparameterization on Sharpness-aware Minimization: An\n  Empirical and Theoretical Analysis",
            "updated": "2023-11-29T11:19:50Z",
            "published": "2023-11-29T11:19:50Z",
            "summary": "Training an overparameterized neural network can yield minimizers of the same\nlevel of training loss and yet different generalization capabilities. With\nevidence that indicates a correlation between sharpness of minima and their\ngeneralization errors, increasing efforts have been made to develop an\noptimization method to explicitly find flat minima as more generalizable\nsolutions. This sharpness-aware minimization (SAM) strategy, however, has not\nbeen studied much yet as to how overparameterization can actually affect its\nbehavior. In this work, we analyze SAM under varying degrees of\noverparameterization and present both empirical and theoretical results that\nsuggest a critical influence of overparameterization on SAM. Specifically, we\nfirst use standard techniques in optimization to prove that SAM can achieve a\nlinear convergence rate under overparameterization in a stochastic setting. We\nalso show that the linearly stable minima found by SAM are indeed flatter and\nhave more uniformly distributed Hessian moments compared to those of SGD. These\nresults are corroborated with our experiments that reveal a consistent trend\nthat the generalization improvement made by SAM continues to increase as the\nmodel becomes more overparameterized. We further present that sparsity can open\nup an avenue for effective overparameterization in practice.",
            "author": [
                "Sungbin Shin",
                "Dongyeop Lee",
                "Maksym Andriushchenko",
                "Namhoon Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17539v1",
                "http://arxiv.org/pdf/2311.17539v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17532v1",
            "title": "Weakly-Supervised Emotion Transition Learning for Diverse 3D Co-speech\n  Gesture Generation",
            "updated": "2023-11-29T11:10:40Z",
            "published": "2023-11-29T11:10:40Z",
            "summary": "Generating vivid and emotional 3D co-speech gestures is crucial for virtual\navatar animation in human-machine interaction applications. While the existing\nmethods enable generating the gestures to follow a single emotion label, they\noverlook that long gesture sequence modeling with emotion transition is more\npractical in real scenes. In addition, the lack of large-scale available\ndatasets with emotional transition speech and corresponding 3D human gestures\nalso limits the addressing of this task. To fulfill this goal, we first\nincorporate the ChatGPT-4 and an audio inpainting approach to construct the\nhigh-fidelity emotion transition human speeches. Considering obtaining the\nrealistic 3D pose annotations corresponding to the dynamically inpainted\nemotion transition audio is extremely difficult, we propose a novel weakly\nsupervised training strategy to encourage authority gesture transitions.\nSpecifically, to enhance the coordination of transition gestures w.r.t\ndifferent emotional ones, we model the temporal association representation\nbetween two different emotional gesture sequences as style guidance and infuse\nit into the transition generation. We further devise an emotion mixture\nmechanism that provides weak supervision based on a learnable mixed emotion\nlabel for transition gestures. Last, we present a keyframe sampler to supply\neffective initial posture cues in long sequences, enabling us to generate\ndiverse gestures. Extensive experiments demonstrate that our method outperforms\nthe state-of-the-art models constructed by adapting single emotion-conditioned\ncounterparts on our newly defined emotion transition task and datasets.",
            "author": [
                "Xingqun Qi",
                "Jiahao Pan",
                "Peng Li",
                "Ruibin Yuan",
                "Xiaowei Chi",
                "Mengfei Li",
                "Wenhan Luo",
                "Wei Xue",
                "Shanghang Zhang",
                "Qifeng Liu",
                "Yike Guo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17532v1",
                "http://arxiv.org/pdf/2311.17532v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17959v1",
            "title": "Transformer Based Model for Predicting Rapid Impact Compaction Outcomes:\n  A Case Study of Utapao International Airport",
            "updated": "2023-11-29T10:56:02Z",
            "published": "2023-11-29T10:56:02Z",
            "summary": "This paper introduces a novel deep learning approach to predict the\nengineering properties of the ground improved by Rapid Impact Compaction (RIC),\nwhich is a ground improvement technique that uses a drop hammer to compact the\nsoil and fill layers. The proposed approach uses transformer-based neural\nnetworks to capture the complex nonlinear relationships between the input\nfeatures, such as the hammer energy, drop height, and number of blows, and the\noutput variables, such as the cone resistance. The approach is applied to a\nreal-world dataset from a trial test section for the new apron construction of\nthe Utapao International Airport in Thailand. The results show that the\nproposed approach outperforms the existing methods in terms of prediction\naccuracy and efficiency and provides interpretable attention maps that reveal\nthe importance of different features for RIC prediction. The paper also\ndiscusses the limitations and future directions of applying deep learning\nmethods to RIC prediction.",
            "author": [
                "Sompote Youwai",
                "Sirasak Detcheewa"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17959v1",
                "http://arxiv.org/pdf/2311.17959v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17519v1",
            "title": "Reinforcement Learning with thermal fluctuations at the nano-scale",
            "updated": "2023-11-29T10:41:11Z",
            "published": "2023-11-29T10:41:11Z",
            "summary": "Reinforcement Learning offers a framework to learn to choose actions in order\nto achieve some goal. However, at the nano-scale, thermal fluctuations hamper\nthe learning process. We show that in this regime, while optimal actions should\nbring an improvement proportional to the small ratio of the applied force times\na length-scale over the temperature, the learned improvement is smaller and\nproportional to the square of this small ratio. Consequently, the efficiency of\nlearning, which compares the learning improvement to the theoretical optimal\nimprovement, drops to zero. Nevertheless, we show how to circumvent these\nlimitations by using actions learned at a lower temperature. Our results are\nillustrated with simulations of the control of small particle clusters, and\nshould apply to a wide class of other problems that can also be formulated as a\nMarkov Decision Processes such as nano-navigation and nano-machine actuation.",
            "author": [
                "Francesco Boccardo",
                "Olivier Pierre-Louis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17519v1",
                "http://arxiv.org/pdf/2311.17519v1"
            ],
            "primary_category": "cond-mat.stat-mech",
            "category": [
                "cond-mat.stat-mech",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17518v1",
            "title": "The devil is in the fine-grained details: Evaluating open-vocabulary\n  object detectors for fine-grained understanding",
            "updated": "2023-11-29T10:40:52Z",
            "published": "2023-11-29T10:40:52Z",
            "summary": "Recent advancements in large vision-language models enabled visual object\ndetection in open-vocabulary scenarios, where object classes are defined in\nfree-text formats during inference. In this paper, we aim to probe the\nstate-of-the-art methods for open-vocabulary object detection to determine to\nwhat extent they understand fine-grained properties of objects and their parts.\nTo this end, we introduce an evaluation protocol based on dynamic vocabulary\ngeneration to test whether models detect, discern, and assign the correct\nfine-grained description to objects in the presence of hard-negative classes.\nWe contribute with a benchmark suite of increasing difficulty and probing\ndifferent properties like color, pattern, and material. We further enhance our\ninvestigation by evaluating several state-of-the-art open-vocabulary object\ndetectors using the proposed protocol and find that most existing solutions,\nwhich shine in standard open-vocabulary benchmarks, struggle to accurately\ncapture and distinguish finer object details. We conclude the paper by\nhighlighting the limitations of current methodologies and exploring promising\nresearch directions to overcome the discovered drawbacks. Data and code are\navailable at https://github.com/lorebianchi98/FG-OVD.",
            "author": [
                "Lorenzo Bianchi",
                "Fabio Carrara",
                "Nicola Messina",
                "Claudio Gennaro",
                "Fabrizio Falchi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17518v1",
                "http://arxiv.org/pdf/2311.17518v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17515v1",
            "title": "Fusion of Single and Integral Multispectral Aerial Images",
            "updated": "2023-11-29T10:38:42Z",
            "published": "2023-11-29T10:38:42Z",
            "summary": "We present a novel hybrid (model- and learning-based) architecture for fusing\nthe most significant features from conventional aerial images and integral\naerial images that result from synthetic aperture sensing for removing\nocclusion caused by dense vegetation. It combines the environment's spatial\nreferences with features of unoccluded targets. Our method out-beats the\nstate-of-the-art, does not require manually tuned parameters, can be extended\nto an arbitrary number and combinations of spectral channels, and is\nreconfigurable to address different use-cases.",
            "author": [
                "Mohamed Youssef",
                "Oliver Bimber"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17515v1",
                "http://arxiv.org/pdf/2311.17515v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17514v1",
            "title": "Reinforcement Replaces Supervision: Query focused Summarization using\n  Deep Reinforcement Learning",
            "updated": "2023-11-29T10:38:16Z",
            "published": "2023-11-29T10:38:16Z",
            "summary": "Query-focused Summarization (QfS) deals with systems that generate summaries\nfrom document(s) based on a query. Motivated by the insight that Reinforcement\nLearning (RL) provides a generalization to Supervised Learning (SL) for Natural\nLanguage Generation, and thereby performs better (empirically) than SL, we use\nan RL-based approach for this task of QfS. Additionally, we also resolve the\nconflict of employing RL in Transformers with Teacher Forcing. We develop\nmultiple Policy Gradient networks, trained on various reward signals: ROUGE,\nBLEU, and Semantic Similarity, which lead to a 10-point improvement over the\nState-of-the-Art approach on the ROUGE-L metric for a benchmark dataset (ELI5).\nWe also show performance of our approach in zero-shot setting for another\nbenchmark dataset (DebatePedia) -- our approach leads to results comparable to\nbaselines, which were specifically trained on DebatePedia. To aid the RL\ntraining, we propose a better semantic similarity reward, enabled by a novel\nPassage Embedding scheme developed using Cluster Hypothesis. Lastly, we\ncontribute a gold-standard test dataset to further research in QfS and\nLong-form Question Answering (LfQA).",
            "author": [
                "Swaroop Nath",
                "Harshad Khadilkar",
                "Pushpak Bhattacharyya"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17514v1",
                "http://arxiv.org/pdf/2311.17514v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17508v1",
            "title": "Model Performance Prediction for Hyperparameter Optimization of Deep\n  Learning Models Using High Performance Computing and Quantum Annealing",
            "updated": "2023-11-29T10:32:40Z",
            "published": "2023-11-29T10:32:40Z",
            "summary": "Hyperparameter Optimization (HPO) of Deep Learning-based models tends to be a\ncompute resource intensive process as it usually requires to train the target\nmodel with many different hyperparameter configurations. We show that\nintegrating model performance prediction with early stopping methods holds\ngreat potential to speed up the HPO process of deep learning models. Moreover,\nwe propose a novel algorithm called Swift-Hyperband that can use either\nclassical or quantum support vector regression for performance prediction and\nbenefit from distributed High Performance Computing environments. This\nalgorithm is tested not only for the Machine-Learned Particle Flow model used\nin High Energy Physics, but also for a wider range of target models from\ndomains such as computer vision and natural language processing.\nSwift-Hyperband is shown to find comparable (or better) hyperparameters as well\nas using less computational resources in all test cases.",
            "author": [
                "Juan Pablo Garc\u00eda Amboage",
                "Eric Wulff",
                "Maria Girone",
                "Tom\u00e1s F. Pena"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17508v1",
                "http://arxiv.org/pdf/2311.17508v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.data-an"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03743v1",
            "title": "Easy Data Augmentation in Sentiment Analysis of Cyberbullying",
            "updated": "2023-11-29T10:05:58Z",
            "published": "2023-11-29T10:05:58Z",
            "summary": "Instagram, a social media platform, has in the vicinity of 2 billion active\nusers in 2023. The platform allows users to post photos and videos with one\nanother. However, cyberbullying remains a significant problem for about 50% of\nyoung Indonesians. To address this issue, sentiment analysis for comment\nfiltering uses a Support Vector Machine (SVM) and Easy Data Augmentation (EDA).\nEDA will augment the dataset, enabling robust prediction and analysis of\ncyberbullying by introducing more variation. Based on the tests, SVM\ncombination with EDA results in a 2.52% increase in the k-Fold Cross Validation\nscore. Our proposed approach shows an improved accuracy of 92.5%, 2.5% higher\nthan that of the existing state-of-the-art method. To maintain the\nreproducibility and replicability of this research, the source code can be\naccessed at uns.id/eda_svm.",
            "author": [
                "Alwan Wirawan",
                "Hasan Dwi Cahyono",
                "Winarno"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03743v1",
                "http://arxiv.org/pdf/2312.03743v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17492v1",
            "title": "Mergen: The First Manchu-Korean Machine Translation Model Trained on\n  Augmented Data",
            "updated": "2023-11-29T10:01:48Z",
            "published": "2023-11-29T10:01:48Z",
            "summary": "The Manchu language, with its roots in the historical Manchurian region of\nNortheast China, is now facing a critical threat of extinction, as there are\nvery few speakers left. In our efforts to safeguard the Manchu language, we\nintroduce Mergen, the first-ever attempt at a Manchu-Korean Machine Translation\n(MT) model. To develop this model, we utilize valuable resources such as the\nManwen Laodang(a historical book) and a Manchu-Korean dictionary. Due to the\nscarcity of a Manchu-Korean parallel dataset, we expand our data by employing\nword replacement guided by GloVe embeddings, trained on both monolingual and\nparallel texts. Our approach is built around an encoder-decoder neural machine\ntranslation model, incorporating a bi-directional Gated Recurrent Unit (GRU)\nlayer. The experiments have yielded promising results, showcasing a significant\nenhancement in Manchu-Korean translation, with a remarkable 20-30 point\nincrease in the BLEU score.",
            "author": [
                "Jean Seo",
                "Sungjoo Byun",
                "Minha Kang",
                "Sangah Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17492v1",
                "http://arxiv.org/pdf/2311.17492v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    }
]