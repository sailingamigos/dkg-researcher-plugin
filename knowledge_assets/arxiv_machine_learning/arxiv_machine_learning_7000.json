[
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18935v1",
            "title": "Implicit Bias of Gradient Descent for Two-layer ReLU and Leaky ReLU\n  Networks on Nearly-orthogonal Data",
            "updated": "2023-10-29T08:47:48Z",
            "published": "2023-10-29T08:47:48Z",
            "summary": "The implicit bias towards solutions with favorable properties is believed to\nbe a key reason why neural networks trained by gradient-based optimization can\ngeneralize well. While the implicit bias of gradient flow has been widely\nstudied for homogeneous neural networks (including ReLU and leaky ReLU\nnetworks), the implicit bias of gradient descent is currently only understood\nfor smooth neural networks. Therefore, implicit bias in non-smooth neural\nnetworks trained by gradient descent remains an open question. In this paper,\nwe aim to answer this question by studying the implicit bias of gradient\ndescent for training two-layer fully connected (leaky) ReLU neural networks. We\nshowed that when the training data are nearly-orthogonal, for leaky ReLU\nactivation function, gradient descent will find a network with a stable rank\nthat converges to $1$, whereas for ReLU activation function, gradient descent\nwill find a neural network with a stable rank that is upper bounded by a\nconstant. Additionally, we show that gradient descent will find a neural\nnetwork such that all the training data points have the same normalized margin\nasymptotically. Experiments on both synthetic and real data backup our\ntheoretical findings.",
            "author": [
                "Yiwen Kou",
                "Zixiang Chen",
                "Quanquan Gu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18935v1",
                "http://arxiv.org/pdf/2310.18935v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18933v1",
            "title": "Label Poisoning is All You Need",
            "updated": "2023-10-29T08:03:45Z",
            "published": "2023-10-29T08:03:45Z",
            "summary": "In a backdoor attack, an adversary injects corrupted data into a model's\ntraining dataset in order to gain control over its predictions on images with a\nspecific attacker-defined trigger. A typical corrupted training example\nrequires altering both the image, by applying the trigger, and the label.\nModels trained on clean images, therefore, were considered safe from backdoor\nattacks. However, in some common machine learning scenarios, the training\nlabels are provided by potentially malicious third-parties. This includes\ncrowd-sourced annotation and knowledge distillation. We, hence, investigate a\nfundamental question: can we launch a successful backdoor attack by only\ncorrupting labels? We introduce a novel approach to design label-only backdoor\nattacks, which we call FLIP, and demonstrate its strengths on three datasets\n(CIFAR-10, CIFAR-100, and Tiny-ImageNet) and four architectures (ResNet-32,\nResNet-18, VGG-19, and Vision Transformer). With only 2% of CIFAR-10 labels\ncorrupted, FLIP achieves a near-perfect attack success rate of 99.4% while\nsuffering only a 1.8% drop in the clean test accuracy. Our approach builds upon\nthe recent advances in trajectory matching, originally introduced for dataset\ndistillation.",
            "author": [
                "Rishi D. Jha",
                "Jonathan Hayase",
                "Sewoong Oh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18933v1",
                "http://arxiv.org/pdf/2310.18933v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18932v1",
            "title": "Self Attention with Temporal Prior: Can We Learn More from Arrow of\n  Time?",
            "updated": "2023-10-29T08:00:13Z",
            "published": "2023-10-29T08:00:13Z",
            "summary": "Many of diverse phenomena in nature often inherently encode both short and\nlong term temporal dependencies, short term dependencies especially resulting\nfrom the direction of flow of time. In this respect, we discovered experimental\nevidences suggesting that {\\it interrelations} of these events are higher for\ncloser time stamps. However, to be able for attention based models to learn\nthese regularities in short term dependencies, it requires large amounts of\ndata which are often infeasible. This is due to the reason that, while they are\ngood at learning piece wised temporal dependencies, attention based models lack\nstructures that encode biases in time series. As a resolution, we propose a\nsimple and efficient method that enables attention layers to better encode\nshort term temporal bias of these data sets by applying learnable, adaptive\nkernels directly to the attention matrices. For the experiments, we chose\nvarious prediction tasks using Electronic Health Records (EHR) data sets since\nthey are great examples that have underlying long and short term temporal\ndependencies. The results of our experiments show exceptional classification\nresults compared to best performing models on most of the task and data sets.",
            "author": [
                "Kyung Geun Kim",
                "Byeong Tak Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18932v1",
                "http://arxiv.org/pdf/2310.18932v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18930v1",
            "title": "Retrofitting Light-weight Language Models for Emotions using Supervised\n  Contrastive Learning",
            "updated": "2023-10-29T07:43:34Z",
            "published": "2023-10-29T07:43:34Z",
            "summary": "We present a novel retrofitting method to induce emotion aspects into\npre-trained language models (PLMs) such as BERT and RoBERTa. Our method updates\npre-trained network weights using contrastive learning so that the text\nfragments exhibiting similar emotions are encoded nearby in the representation\nspace, and the fragments with different emotion content are pushed apart. While\ndoing so, it also ensures that the linguistic knowledge already present in PLMs\nis not inadvertently perturbed. The language models retrofitted by our method,\ni.e., BERTEmo and RoBERTaEmo, produce emotion-aware text representations, as\nevaluated through different clustering and retrieval metrics. For the\ndownstream tasks on sentiment analysis and sarcasm detection, they perform\nbetter than their pre-trained counterparts (about 1% improvement in F1-score)\nand other existing approaches. Additionally, a more significant boost in\nperformance is observed for the retrofitted models over pre-trained ones in\nfew-shot learning setting.",
            "author": [
                "Sapan Shah",
                "Sreedhar Reddy",
                "Pushpak Bhattacharyya"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18930v1",
                "http://arxiv.org/pdf/2310.18930v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18928v1",
            "title": "A transfer learning approach with convolutional neural network for Face\n  Mask Detection",
            "updated": "2023-10-29T07:38:33Z",
            "published": "2023-10-29T07:38:33Z",
            "summary": "Due to the epidemic of the coronavirus (Covid-19) and its rapid spread around\nthe world, the world has faced an enormous crisis. To prevent the spread of the\ncoronavirus, the World Health Organization (WHO) has introduced the use of\nmasks and keeping social distance as the best preventive method. So, developing\nan automatic monitoring system for detecting facemasks in some crowded places\nis essential. To do this, we propose a mask recognition system based on\ntransfer learning and Inception v3 architecture. In the proposed method, two\ndatasets are used simultaneously for training including the Simulated Mask Face\nDataset (SMFD) and MaskedFace-Net (MFN) This paper tries to increase the\naccuracy of the proposed system by optimally setting hyper-parameters and\naccurately designing the fully connected layers. The main advantage of the\nproposed method is that in addition to masked and unmasked faces, it can also\ndetect cases of incorrect use of mask. Therefore, the proposed method\nclassifies the input face images into three categories. Experimental results\nshow the high accuracy and efficiency of the proposed method; so, this method\nhas achieved an accuracy of 99.47% and 99.33% in training and test data\nrespectively",
            "author": [
                "Abolfazl Younesi",
                "Reza Afrouzian",
                "Yousef Seyfari"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18928v1",
                "http://arxiv.org/pdf/2310.18928v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18926v1",
            "title": "CHAIN: Exploring Global-Local Spatio-Temporal Information for Improved\n  Self-Supervised Video Hashing",
            "updated": "2023-10-29T07:36:11Z",
            "published": "2023-10-29T07:36:11Z",
            "summary": "Compressing videos into binary codes can improve retrieval speed and reduce\nstorage overhead. However, learning accurate hash codes for video retrieval can\nbe challenging due to high local redundancy and complex global dependencies\nbetween video frames, especially in the absence of labels. Existing\nself-supervised video hashing methods have been effective in designing\nexpressive temporal encoders, but have not fully utilized the temporal dynamics\nand spatial appearance of videos due to less challenging and unreliable\nlearning tasks. To address these challenges, we begin by utilizing the\ncontrastive learning task to capture global spatio-temporal information of\nvideos for hashing. With the aid of our designed augmentation strategies, which\nfocus on spatial and temporal variations to create positive pairs, the learning\nframework can generate hash codes that are invariant to motion, scale, and\nviewpoint. Furthermore, we incorporate two collaborative learning tasks, i.e.,\nframe order verification and scene change regularization, to capture local\nspatio-temporal details within video frames, thereby enhancing the perception\nof temporal structure and the modeling of spatio-temporal relationships. Our\nproposed Contrastive Hashing with Global-Local Spatio-temporal Information\n(CHAIN) outperforms state-of-the-art self-supervised video hashing methods on\nfour video benchmark datasets. Our codes will be released.",
            "author": [
                "Rukai Wei",
                "Yu Liu",
                "Jingkuan Song",
                "Heng Cui",
                "Yanzhao Xie",
                "Ke Zhou"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3581783.3613440",
                "http://arxiv.org/abs/2310.18926v1",
                "http://arxiv.org/pdf/2310.18926v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18924v1",
            "title": "Remaining Useful Life Prediction of Lithium-ion Batteries using\n  Spatio-temporal Multimodal Attention Networks",
            "updated": "2023-10-29T07:32:32Z",
            "published": "2023-10-29T07:32:32Z",
            "summary": "Lithium-ion batteries are widely used in various applications, including\nelectric vehicles and renewable energy storage. The prediction of the remaining\nuseful life (RUL) of batteries is crucial for ensuring reliable and efficient\noperation, as well as reducing maintenance costs. However, determining the life\ncycle of batteries in real-world scenarios is challenging, and existing methods\nhave limitations in predicting the number of cycles iteratively. In addition,\nexisting works often oversimplify the datasets, neglecting important features\nof the batteries such as temperature, internal resistance, and material type.\nTo address these limitations, this paper proposes a two-stage remaining useful\nlife prediction scheme for Lithium-ion batteries using a spatio-temporal\nmultimodal attention network (ST-MAN). The proposed model is designed to\niteratively predict the number of cycles required for the battery to reach the\nend of its useful life, based on available data. The proposed ST-MAN is to\ncapture the complex spatio-temporal dependencies in the battery data, including\nthe features that are often neglected in existing works. Experimental results\ndemonstrate that the proposed ST-MAN model outperforms existing CNN and\nLSTM-based methods, achieving state-of-the-art performance in predicting the\nremaining useful life of Li-ion batteries. The proposed method has the\npotential to improve the reliability and efficiency of battery operations and\nis applicable in various industries, including automotive and renewable energy.",
            "author": [
                "Sungho Suh",
                "Dhruv Aditya Mittal",
                "Hymalai Bello",
                "Bo Zhou",
                "Mayank Shekhar Jha",
                "Paul Lukowicz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18924v1",
                "http://arxiv.org/pdf/2310.18924v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18921v1",
            "title": "QWID: Quantized Weed Identification Deep neural network",
            "updated": "2023-10-29T06:43:01Z",
            "published": "2023-10-29T06:43:01Z",
            "summary": "In this paper, we present an efficient solution for weed classification in\nagriculture. We focus on optimizing model performance at inference while\nrespecting the constraints of the agricultural domain. We propose a Quantized\nDeep Neural Network model that classifies a dataset of 9 weed classes using\n8-bit integer (int8) quantization, a departure from standard 32-bit floating\npoint (fp32) models. Recognizing the hardware resource limitations in\nagriculture, our model balances model size, inference time, and accuracy,\naligning with practical requirements. We evaluate the approach on ResNet-50 and\nInceptionV3 architectures, comparing their performance against their int8\nquantized versions. Transfer learning and fine-tuning are applied using the\nDeepWeeds dataset. The results show staggering model size and inference time\nreductions while maintaining accuracy in real-world production scenarios like\nDesktop, Mobile and Raspberry Pi. Our work sheds light on a promising direction\nfor efficient AI in agriculture, holding potential for broader applications.\n  Code: https://github.com/parikshit14/QNN-for-weed",
            "author": [
                "Parikshit Singh Rathore"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18921v1",
                "http://arxiv.org/pdf/2310.18921v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18919v2",
            "title": "Posterior Sampling with Delayed Feedback for Reinforcement Learning with\n  Linear Function Approximation",
            "updated": "2023-11-04T01:38:40Z",
            "published": "2023-10-29T06:12:43Z",
            "summary": "Recent studies in reinforcement learning (RL) have made significant progress\nby leveraging function approximation to alleviate the sample complexity hurdle\nfor better performance. Despite the success, existing provably efficient\nalgorithms typically rely on the accessibility of immediate feedback upon\ntaking actions. The failure to account for the impact of delay in observations\ncan significantly degrade the performance of real-world systems due to the\nregret blow-up. In this work, we tackle the challenge of delayed feedback in RL\nwith linear function approximation by employing posterior sampling, which has\nbeen shown to empirically outperform the popular UCB algorithms in a wide range\nof regimes. We first introduce Delayed-PSVI, an optimistic value-based\nalgorithm that effectively explores the value function space via noise\nperturbation with posterior sampling. We provide the first analysis for\nposterior sampling algorithms with delayed feedback in RL and show our\nalgorithm achieves $\\widetilde{O}(\\sqrt{d^3H^3 T} + d^2H^2 E[\\tau])$ worst-case\nregret in the presence of unknown stochastic delays. Here $E[\\tau]$ is the\nexpected delay. To further improve its computational efficiency and to expand\nits applicability in high-dimensional RL problems, we incorporate a\ngradient-based approximate sampling scheme via Langevin dynamics for\nDelayed-LPSVI, which maintains the same order-optimal regret guarantee with\n$\\widetilde{O}(dHK)$ computational cost. Empirical evaluations are performed to\ndemonstrate the statistical and computational efficacy of our algorithms.",
            "author": [
                "Nikki Lijing Kuang",
                "Ming Yin",
                "Mengdi Wang",
                "Yu-Xiang Wang",
                "Yi-An Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18919v2",
                "http://arxiv.org/pdf/2310.18919v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18918v1",
            "title": "Hyperbolic Graph Neural Networks at Scale: A Meta Learning Approach",
            "updated": "2023-10-29T06:11:49Z",
            "published": "2023-10-29T06:11:49Z",
            "summary": "The progress in hyperbolic neural networks (HNNs) research is hindered by\ntheir absence of inductive bias mechanisms, which are essential for\ngeneralizing to new tasks and facilitating scalable learning over large\ndatasets. In this paper, we aim to alleviate these issues by learning\ngeneralizable inductive biases from the nodes' local subgraph and transfer them\nfor faster learning over new subgraphs with a disjoint set of nodes, edges, and\nlabels in a few-shot setting. We introduce a novel method, Hyperbolic GRAph\nMeta Learner (H-GRAM), that, for the tasks of node classification and link\nprediction, learns transferable information from a set of support local\nsubgraphs in the form of hyperbolic meta gradients and label hyperbolic\nprotonets to enable faster learning over a query set of new tasks dealing with\ndisjoint subgraphs. Furthermore, we show that an extension of our meta-learning\nframework also mitigates the scalability challenges seen in HNNs faced by\nexisting approaches. Our comparative analysis shows that H-GRAM effectively\nlearns and transfers information in multiple challenging few-shot settings\ncompared to other state-of-the-art baselines. Additionally, we demonstrate\nthat, unlike standard HNNs, our approach is able to scale over large graph\ndatasets and improve performance over its Euclidean counterparts.",
            "author": [
                "Nurendra Choudhary",
                "Nikhil Rao",
                "Chandan K. Reddy"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18918v1",
                "http://arxiv.org/pdf/2310.18918v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18913v1",
            "title": "Debiasing Algorithm through Model Adaptation",
            "updated": "2023-10-29T05:50:03Z",
            "published": "2023-10-29T05:50:03Z",
            "summary": "Large language models are becoming the go-to solution for various language\ntasks. However, with growing capacity, models are prone to rely on spurious\ncorrelations stemming from biases and stereotypes present in the training data.\nThis work proposes a novel method for detecting and mitigating gender bias in\nlanguage models. We perform causal analysis to identify problematic model\ncomponents and discover that mid-upper feed-forward layers are most prone to\nconvey biases. Based on the analysis results, we adapt the model by multiplying\nthese layers by a linear projection. Our titular method, DAMA, significantly\ndecreases bias as measured by diverse metrics while maintaining the model's\nperformance on downstream tasks. We release code for our method and models,\nwhich retrain LLaMA's state-of-the-art performance while being significantly\nless biased.",
            "author": [
                "Tomasz Limisiewicz",
                "David Mare\u010dek",
                "Tom\u00e1\u0161 Musil"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18913v1",
                "http://arxiv.org/pdf/2310.18913v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18912v1",
            "title": "Sentence Bag Graph Formulation for Biomedical Distant Supervision\n  Relation Extraction",
            "updated": "2023-10-29T05:48:04Z",
            "published": "2023-10-29T05:48:04Z",
            "summary": "We introduce a novel graph-based framework for alleviating key challenges in\ndistantly-supervised relation extraction and demonstrate its effectiveness in\nthe challenging and important domain of biomedical data. Specifically, we\npropose a graph view of sentence bags referring to an entity pair, which\nenables message-passing based aggregation of information related to the entity\npair over the sentence bag. The proposed framework alleviates the common\nproblem of noisy labeling in distantly supervised relation extraction and also\neffectively incorporates inter-dependencies between sentences within a bag.\nExtensive experiments on two large-scale biomedical relation datasets and the\nwidely utilized NYT dataset demonstrate that our proposed framework\nsignificantly outperforms the state-of-the-art methods for biomedical distant\nsupervision relation extraction while also providing excellent performance for\nrelation extraction in the general text mining domain.",
            "author": [
                "Hao Zhang",
                "Yang Liu",
                "Xiaoyan Liu",
                "Tianming Liang",
                "Gaurav Sharma",
                "Liang Xue",
                "Maozu Guo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18912v1",
                "http://arxiv.org/pdf/2310.18912v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18910v1",
            "title": "InstanT: Semi-supervised Learning with Instance-dependent Thresholds",
            "updated": "2023-10-29T05:31:43Z",
            "published": "2023-10-29T05:31:43Z",
            "summary": "Semi-supervised learning (SSL) has been a fundamental challenge in machine\nlearning for decades. The primary family of SSL algorithms, known as\npseudo-labeling, involves assigning pseudo-labels to confident unlabeled\ninstances and incorporating them into the training set. Therefore, the\nselection criteria of confident instances are crucial to the success of SSL.\nRecently, there has been growing interest in the development of SSL methods\nthat use dynamic or adaptive thresholds. Yet, these methods typically apply the\nsame threshold to all samples, or use class-dependent thresholds for instances\nbelonging to a certain class, while neglecting instance-level information. In\nthis paper, we propose the study of instance-dependent thresholds, which has\nthe highest degree of freedom compared with existing methods. Specifically, we\ndevise a novel instance-dependent threshold function for all unlabeled\ninstances by utilizing their instance-level ambiguity and the\ninstance-dependent error rates of pseudo-labels, so instances that are more\nlikely to have incorrect pseudo-labels will have higher thresholds.\nFurthermore, we demonstrate that our instance-dependent threshold function\nprovides a bounded probabilistic guarantee for the correctness of the\npseudo-labels it assigns.",
            "author": [
                "Muyang Li",
                "Runze Wu",
                "Haoyu Liu",
                "Jun Yu",
                "Xun Yang",
                "Bo Han",
                "Tongliang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18910v1",
                "http://arxiv.org/pdf/2310.18910v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18908v1",
            "title": "Estimating the Rate-Distortion Function by Wasserstein Gradient Descent",
            "updated": "2023-10-29T05:29:59Z",
            "published": "2023-10-29T05:29:59Z",
            "summary": "In the theory of lossy compression, the rate-distortion (R-D) function $R(D)$\ndescribes how much a data source can be compressed (in bit-rate) at any given\nlevel of fidelity (distortion). Obtaining $R(D)$ for a given data source\nestablishes the fundamental performance limit for all compression algorithms.\nWe propose a new method to estimate $R(D)$ from the perspective of optimal\ntransport. Unlike the classic Blahut--Arimoto algorithm which fixes the support\nof the reproduction distribution in advance, our Wasserstein gradient descent\nalgorithm learns the support of the optimal reproduction distribution by moving\nparticles. We prove its local convergence and analyze the sample complexity of\nour R-D estimator based on a connection to entropic optimal transport.\nExperimentally, we obtain comparable or tighter bounds than state-of-the-art\nneural network methods on low-rate sources while requiring considerably less\ntuning and computation effort. We also highlight a connection to\nmaximum-likelihood deconvolution and introduce a new class of sources that can\nbe used as test cases with known solutions to the R-D problem.",
            "author": [
                "Yibo Yang",
                "Stephan Eckstein",
                "Marcel Nutz",
                "Stephan Mandt"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18908v1",
                "http://arxiv.org/pdf/2310.18908v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.LG",
                "math.IT",
                "stat.AP",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18907v1",
            "title": "Topological, or Non-topological? A Deep Learning Based Prediction",
            "updated": "2023-10-29T05:29:49Z",
            "published": "2023-10-29T05:29:49Z",
            "summary": "Prediction and discovery of new materials with desired properties are at the\nforefront of quantum science and technology research. A major bottleneck in\nthis field is the computational resources and time complexity related to\nfinding new materials from ab initio calculations. In this work, an effective\nand robust deep learning-based model is proposed by incorporating persistent\nhomology and graph neural network which offers an accuracy of 91.4% and an F1\nscore of 88.5% in classifying topological vs. non-topological materials,\noutperforming the other state-of-the-art classifier models. The incorporation\nof the graph neural network encodes the underlying relation between the atoms\ninto the model based on their own crystalline structures and thus proved to be\nan effective method to represent and process non-euclidean data like molecules\nwith a relatively shallow network. The persistent homology pipeline in the\nsuggested neural network is capable of integrating the atom-specific\ntopological information into the deep learning model, increasing robustness,\nand gain in performance. It is believed that the presented work will be an\nefficacious tool for predicting the topological class and therefore enable the\nhigh-throughput search for novel materials in this field.",
            "author": [
                "Ashiqur Rasul",
                "Md Shafayat Hossain",
                "Ankan Ghosh Dastider",
                "Himaddri Roy",
                "M. Zahid Hasan",
                "Quazi D. M. Khosru"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18907v1",
                "http://arxiv.org/pdf/2310.18907v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18904v1",
            "title": "Identifiable Contrastive Learning with Automatic Feature Importance\n  Discovery",
            "updated": "2023-10-29T05:20:54Z",
            "published": "2023-10-29T05:20:54Z",
            "summary": "Existing contrastive learning methods rely on pairwise sample contrast\n$z_x^\\top z_{x'}$ to learn data representations, but the learned features often\nlack clear interpretability from a human perspective. Theoretically, it lacks\nfeature identifiability and different initialization may lead to totally\ndifferent features. In this paper, we study a new method named tri-factor\ncontrastive learning (triCL) that involves a 3-factor contrast in the form of\n$z_x^\\top S z_{x'}$, where $S=\\text{diag}(s_1,\\dots,s_k)$ is a learnable\ndiagonal matrix that automatically captures the importance of each feature. We\nshow that by this simple extension, triCL can not only obtain identifiable\nfeatures that eliminate randomness but also obtain more interpretable features\nthat are ordered according to the importance matrix $S$. We show that features\nwith high importance have nice interpretability by capturing common classwise\nfeatures, and obtain superior performance when evaluated for image retrieval\nusing a few features. The proposed triCL objective is general and can be\napplied to different contrastive learning methods like SimCLR and CLIP. We\nbelieve that it is a better alternative to existing 2-factor contrastive\nlearning by improving its identifiability and interpretability with minimal\noverhead. Code is available at\nhttps://github.com/PKU-ML/Tri-factor-Contrastive-Learning.",
            "author": [
                "Qi Zhang",
                "Yifei Wang",
                "Yisen Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18904v1",
                "http://arxiv.org/pdf/2310.18904v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18899v1",
            "title": "Multi-task deep learning for large-scale building detail extraction from\n  high-resolution satellite imagery",
            "updated": "2023-10-29T04:43:30Z",
            "published": "2023-10-29T04:43:30Z",
            "summary": "Understanding urban dynamics and promoting sustainable development requires\ncomprehensive insights about buildings. While geospatial artificial\nintelligence has advanced the extraction of such details from Earth\nobservational data, existing methods often suffer from computational\ninefficiencies and inconsistencies when compiling unified building-related\ndatasets for practical applications. To bridge this gap, we introduce the\nMulti-task Building Refiner (MT-BR), an adaptable neural network tailored for\nsimultaneous extraction of spatial and attributional building details from\nhigh-resolution satellite imagery, exemplified by building rooftops, urban\nfunctional types, and roof architectural types. Notably, MT-BR can be\nfine-tuned to incorporate additional building details, extending its\napplicability. For large-scale applications, we devise a novel spatial sampling\nscheme that strategically selects limited but representative image samples.\nThis process optimizes both the spatial distribution of samples and the urban\nenvironmental characteristics they contain, thus enhancing extraction\neffectiveness while curtailing data preparation expenditures. We further\nenhance MT-BR's predictive performance and generalization capabilities through\nthe integration of advanced augmentation techniques. Our quantitative results\nhighlight the efficacy of the proposed methods. Specifically, networks trained\nwith datasets curated via our sampling method demonstrate improved predictive\naccuracy relative to those using alternative sampling approaches, with no\nalterations to network architecture. Moreover, MT-BR consistently outperforms\nother state-of-the-art methods in extracting building details across various\nmetrics. The real-world practicality is also demonstrated in an application\nacross Shanghai, generating a unified dataset that encompasses both the spatial\nand attributional details of buildings.",
            "author": [
                "Zhen Qian",
                "Min Chen",
                "Zhuo Sun",
                "Fan Zhang",
                "Qingsong Xu",
                "Jinzhao Guo",
                "Zhiwei Xie",
                "Zhixin Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18899v1",
                "http://arxiv.org/pdf/2310.18899v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18897v1",
            "title": "Learning Subgrid-Scale Models in Discontinuous Galerkin Methods with\n  Neural Ordinary Differential Equations for Compressible Navier--Stokes\n  Equations",
            "updated": "2023-10-29T04:26:23Z",
            "published": "2023-10-29T04:26:23Z",
            "summary": "The growing computing power over the years has enabled simulations to become\nmore complex and accurate. However, high-fidelity simulations, while immensely\nvaluable for scientific discovery and problem solving, come with significant\ncomputational demands. As a result, it is common to run a low-fidelity model\nwith a subgrid-scale model to reduce the computational cost, but selecting the\nappropriate subgrid-scale models and tuning them are challenging. We propose a\nnovel method for learning the subgrid-scale model effects when simulating\npartial differential equations using neural ordinary differential equations in\nthe context of discontinuous Galerkin (DG) spatial discretization. Our approach\nlearns the missing scales of the low-order DG solver at a continuous level and\nhence improves the accuracy of the low-order DG approximations as well as\naccelerates the filtered high-order DG simulations with a certain degree of\nprecision. We demonstrate the performance of our approach through\nmultidimensional Taylor--Green vortex examples at different Reynolds numbers\nand times, which cover laminar, transitional, and turbulent regimes. The\nproposed method not only reconstructs the subgrid-scale from the low-order\n(1st-order) approximation but also speeds up the filtered high-order DG\n(6th-order) simulation by two orders of magnitude.",
            "author": [
                "Shinhoo Kang",
                "Emil M. Constantinescu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18897v1",
                "http://arxiv.org/pdf/2310.18897v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn",
                "cs.LG",
                "cs.NA",
                "math.NA",
                "68T07, 76M10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18894v1",
            "title": "Emergence of Shape Bias in Convolutional Neural Networks through\n  Activation Sparsity",
            "updated": "2023-10-29T04:07:52Z",
            "published": "2023-10-29T04:07:52Z",
            "summary": "Current deep-learning models for object recognition are known to be heavily\nbiased toward texture. In contrast, human visual systems are known to be biased\ntoward shape and structure. What could be the design principles in human visual\nsystems that led to this difference? How could we introduce more shape bias\ninto the deep learning models? In this paper, we report that sparse coding, a\nubiquitous principle in the brain, can in itself introduce shape bias into the\nnetwork. We found that enforcing the sparse coding constraint using a\nnon-differential Top-K operation can lead to the emergence of structural\nencoding in neurons in convolutional neural networks, resulting in a smooth\ndecomposition of objects into parts and subparts and endowing the networks with\nshape bias. We demonstrated this emergence of shape bias and its functional\nbenefits for different network structures with various datasets. For object\nrecognition convolutional neural networks, the shape bias leads to greater\nrobustness against style and pattern change distraction. For the image\nsynthesis generative adversary networks, the emerged shape bias leads to more\ncoherent and decomposable structures in the synthesized images. Ablation\nstudies suggest that sparse codes tend to encode structures, whereas the more\ndistributed codes tend to favor texture. Our code is host at the github\nrepository: \\url{https://github.com/Crazy-Jack/nips2023_shape_vs_texture}",
            "author": [
                "Tianqin Li",
                "Ziqi Wen",
                "Yangfan Li",
                "Tai Sing Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18894v1",
                "http://arxiv.org/pdf/2310.18894v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18893v1",
            "title": "Ever Evolving Evaluator (EV3): Towards Flexible and Reliable\n  Meta-Optimization for Knowledge Distillation",
            "updated": "2023-10-29T04:00:33Z",
            "published": "2023-10-29T04:00:33Z",
            "summary": "We introduce EV3, a novel meta-optimization framework designed to efficiently\ntrain scalable machine learning models through an intuitive\nexplore-assess-adapt protocol. In each iteration of EV3, we explore various\nmodel parameter updates, assess them using pertinent evaluation methods, and\nadapt the model based on the optimal updates and previous progress history. EV3\noffers substantial flexibility without imposing stringent constraints like\ndifferentiability on the key objectives relevant to the tasks of interest.\nMoreover, this protocol welcomes updates with biased gradients and allows for\nthe use of a diversity of losses and optimizers. Additionally, in scenarios\nwith multiple objectives, it can be used to dynamically prioritize tasks. With\ninspiration drawn from evolutionary algorithms, meta-learning, and neural\narchitecture search, we investigate an application of EV3 to knowledge\ndistillation. Our experimental results illustrate EV3's capability to safely\nexplore model spaces, while hinting at its potential applicability across\nnumerous domains due to its inherent flexibility and adaptability.",
            "author": [
                "Li Ding",
                "Masrour Zoghi",
                "Guy Tennenholtz",
                "Maryam Karimzadehgan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18893v1",
                "http://arxiv.org/pdf/2310.18893v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18891v2",
            "title": "Social Interaction-Aware Dynamical Models and Decision Making for\n  Autonomous Vehicles",
            "updated": "2023-10-31T03:57:56Z",
            "published": "2023-10-29T03:43:50Z",
            "summary": "Interaction-aware Autonomous Driving (IAAD) is a rapidly growing field of\nresearch that focuses on the development of autonomous vehicles (AVs) that are\ncapable of interacting safely and efficiently with human road users. This is a\nchallenging task, as it requires the autonomous vehicle to be able to\nunderstand and predict the behaviour of human road users. In this literature\nreview, the current state of IAAD research is surveyed in this work. Commencing\nwith an examination of terminology, attention is drawn to challenges and\nexisting models employed for modelling the behaviour of drivers and\npedestrians. Next, a comprehensive review is conducted on various techniques\nproposed for interaction modelling, encompassing cognitive methods, machine\nlearning approaches, and game-theoretic methods. The conclusion is reached\nthrough a discussion of potential advantages and risks associated with IAAD,\nalong with the illumination of pivotal research inquiries necessitating future\nexploration.",
            "author": [
                "Luca Crosato",
                "Kai Tian",
                "Hubert P. H Shum",
                "Edmond S. L. Ho",
                "Yafei Wang",
                "Chongfeng Wei"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18891v2",
                "http://arxiv.org/pdf/2310.18891v2"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.CY",
                "cs.RO",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18890v1",
            "title": "Towards Generalized Multi-stage Clustering: Multi-view Self-distillation",
            "updated": "2023-10-29T03:35:34Z",
            "published": "2023-10-29T03:35:34Z",
            "summary": "Existing multi-stage clustering methods independently learn the salient\nfeatures from multiple views and then perform the clustering task.\nParticularly, multi-view clustering (MVC) has attracted a lot of attention in\nmulti-view or multi-modal scenarios. MVC aims at exploring common semantics and\npseudo-labels from multiple views and clustering in a self-supervised manner.\nHowever, limited by noisy data and inadequate feature learning, such a\nclustering paradigm generates overconfident pseudo-labels that mis-guide the\nmodel to produce inaccurate predictions. Therefore, it is desirable to have a\nmethod that can correct this pseudo-label mistraction in multi-stage clustering\nto avoid the bias accumulation. To alleviate the effect of overconfident\npseudo-labels and improve the generalization ability of the model, this paper\nproposes a novel multi-stage deep MVC framework where multi-view\nself-distillation (DistilMVC) is introduced to distill dark knowledge of label\ndistribution. Specifically, in the feature subspace at different hierarchies,\nwe explore the common semantics of multiple views through contrastive learning\nand obtain pseudo-labels by maximizing the mutual information between views.\nAdditionally, a teacher network is responsible for distilling pseudo-labels\ninto dark knowledge, supervising the student network and improving its\npredictive capabilities to enhance the robustness. Extensive experiments on\nreal-world multi-view datasets show that our method has better clustering\nperformance than state-of-the-art methods.",
            "author": [
                "Jiatai Wang",
                "Zhiwei Xu",
                "Xin Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18890v1",
                "http://arxiv.org/pdf/2310.18890v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18888v1",
            "title": "D2NO: Efficient Handling of Heterogeneous Input Function Spaces with\n  Distributed Deep Neural Operators",
            "updated": "2023-10-29T03:29:59Z",
            "published": "2023-10-29T03:29:59Z",
            "summary": "Neural operators have been applied in various scientific fields, such as\nsolving parametric partial differential equations, dynamical systems with\ncontrol, and inverse problems. However, challenges arise when dealing with\ninput functions that exhibit heterogeneous properties, requiring multiple\nsensors to handle functions with minimal regularity. To address this issue,\ndiscretization-invariant neural operators have been used, allowing the sampling\nof diverse input functions with different sensor locations. However, existing\nframeworks still require an equal number of sensors for all functions. In our\nstudy, we propose a novel distributed approach to further relax the\ndiscretization requirements and solve the heterogeneous dataset challenges. Our\nmethod involves partitioning the input function space and processing individual\ninput functions using independent and separate neural networks. A centralized\nneural network is used to handle shared information across all output\nfunctions. This distributed methodology reduces the number of gradient descent\nback-propagation steps, improving efficiency while maintaining accuracy. We\ndemonstrate that the corresponding neural network is a universal approximator\nof continuous nonlinear operators and present four numerical examples to\nvalidate its performance.",
            "author": [
                "Zecheng Zhang",
                "Christian Moya",
                "Lu Lu",
                "Guang Lin",
                "Hayden Schaeffer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18888v1",
                "http://arxiv.org/pdf/2310.18888v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.LG",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18887v1",
            "title": "Dynamo-Depth: Fixing Unsupervised Depth Estimation for Dynamical Scenes",
            "updated": "2023-10-29T03:24:16Z",
            "published": "2023-10-29T03:24:16Z",
            "summary": "Unsupervised monocular depth estimation techniques have demonstrated\nencouraging results but typically assume that the scene is static. These\ntechniques suffer when trained on dynamical scenes, where apparent object\nmotion can equally be explained by hypothesizing the object's independent\nmotion, or by altering its depth. This ambiguity causes depth estimators to\npredict erroneous depth for moving objects. To resolve this issue, we introduce\nDynamo-Depth, an unifying approach that disambiguates dynamical motion by\njointly learning monocular depth, 3D independent flow field, and motion\nsegmentation from unlabeled monocular videos. Specifically, we offer our key\ninsight that a good initial estimation of motion segmentation is sufficient for\njointly learning depth and independent motion despite the fundamental\nunderlying ambiguity. Our proposed method achieves state-of-the-art performance\non monocular depth estimation on Waymo Open and nuScenes Dataset with\nsignificant improvement in the depth of moving objects. Code and additional\nresults are available at https://dynamo-depth.github.io.",
            "author": [
                "Yihong Sun",
                "Bharath Hariharan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18887v1",
                "http://arxiv.org/pdf/2310.18887v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18885v1",
            "title": "A foundational neural operator that continuously learns without\n  forgetting",
            "updated": "2023-10-29T03:20:10Z",
            "published": "2023-10-29T03:20:10Z",
            "summary": "Machine learning has witnessed substantial growth, leading to the development\nof advanced artificial intelligence models crafted to address a wide range of\nreal-world challenges spanning various domains, such as computer vision,\nnatural language processing, and scientific computing. Nevertheless, the\ncreation of custom models for each new task remains a resource-intensive\nundertaking, demanding considerable computational time and memory resources. In\nthis study, we introduce the concept of the Neural Combinatorial Wavelet Neural\nOperator (NCWNO) as a foundational model for scientific computing. This model\nis specifically designed to excel in learning from a diverse spectrum of\nphysics and continuously adapt to the solution operators associated with\nparametric partial differential equations (PDEs). The NCWNO leverages a gated\nstructure that employs local wavelet experts to acquire shared features across\nmultiple physical systems, complemented by a memory-based ensembling approach\namong these local wavelet experts. This combination enables rapid adaptation to\nnew challenges. The proposed foundational model offers two key advantages: (i)\nit can simultaneously learn solution operators for multiple parametric PDEs,\nand (ii) it can swiftly generalize to new parametric PDEs with minimal\nfine-tuning. The proposed NCWNO is the first foundational operator learning\nalgorithm distinguished by its (i) robustness against catastrophic forgetting,\n(ii) the maintenance of positive transfer for new parametric PDEs, and (iii)\nthe facilitation of knowledge transfer across dissimilar tasks. Through an\nextensive set of benchmark examples, we demonstrate that the NCWNO can\noutperform task-specific baseline operator learning frameworks with minimal\nhyperparameter tuning at the prediction stage. We also show that with minimal\nfine-tuning, the NCWNO performs accurate combinatorial learning of new\nparametric PDEs.",
            "author": [
                "Tapas Tripura",
                "Souvik Chakraborty"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18885v1",
                "http://arxiv.org/pdf/2310.18885v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18884v1",
            "title": "Simple and Asymmetric Graph Contrastive Learning without Augmentations",
            "updated": "2023-10-29T03:14:20Z",
            "published": "2023-10-29T03:14:20Z",
            "summary": "Graph Contrastive Learning (GCL) has shown superior performance in\nrepresentation learning in graph-structured data. Despite their success, most\nexisting GCL methods rely on prefabricated graph augmentation and homophily\nassumptions. Thus, they fail to generalize well to heterophilic graphs where\nconnected nodes may have different class labels and dissimilar features. In\nthis paper, we study the problem of conducting contrastive learning on\nhomophilic and heterophilic graphs. We find that we can achieve promising\nperformance simply by considering an asymmetric view of the neighboring nodes.\nThe resulting simple algorithm, Asymmetric Contrastive Learning for Graphs\n(GraphACL), is easy to implement and does not rely on graph augmentations and\nhomophily assumptions. We provide theoretical and empirical evidence that\nGraphACL can capture one-hop local neighborhood information and two-hop\nmonophily similarity, which are both important for modeling heterophilic\ngraphs. Experimental results show that the simple GraphACL significantly\noutperforms state-of-the-art graph contrastive learning and self-supervised\nlearning methods on homophilic and heterophilic graphs. The code of GraphACL is\navailable at https://github.com/tengxiao1/GraphACL.",
            "author": [
                "Teng Xiao",
                "Huaisheng Zhu",
                "Zhengyu Chen",
                "Suhang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18884v1",
                "http://arxiv.org/pdf/2310.18884v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18882v1",
            "title": "Differentiable Learning of Generalized Structured Matrices for Efficient\n  Deep Neural Networks",
            "updated": "2023-10-29T03:07:30Z",
            "published": "2023-10-29T03:07:30Z",
            "summary": "This paper investigates efficient deep neural networks (DNNs) to replace\ndense unstructured weight matrices with structured ones that possess desired\nproperties. The challenge arises because the optimal weight matrix structure in\npopular neural network models is obscure in most cases and may vary from layer\nto layer even in the same network. Prior structured matrices proposed for\nefficient DNNs were mostly hand-crafted without a generalized framework to\nsystematically learn them. To address this issue, we propose a generalized and\ndifferentiable framework to learn efficient structures of weight matrices by\ngradient descent. We first define a new class of structured matrices that\ncovers a wide range of structured matrices in the literature by adjusting the\nstructural parameters. Then, the frequency-domain differentiable\nparameterization scheme based on the Gaussian-Dirichlet kernel is adopted to\nlearn the structural parameters by proximal gradient descent. Finally, we\nintroduce an effective initialization method for the proposed scheme. Our\nmethod learns efficient DNNs with structured matrices, achieving lower\ncomplexity and/or higher performance than prior approaches that employ\nlow-rank, block-sparse, or block-low-rank matrices.",
            "author": [
                "Changwoo Lee",
                "Hun-Seok Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18882v1",
                "http://arxiv.org/pdf/2310.18882v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "eess.IV",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18877v1",
            "title": "Pre-trained Speech Processing Models Contain Human-Like Biases that\n  Propagate to Speech Emotion Recognition",
            "updated": "2023-10-29T02:27:56Z",
            "published": "2023-10-29T02:27:56Z",
            "summary": "Previous work has established that a person's demographics and speech style\naffect how well speech processing models perform for them. But where does this\nbias come from? In this work, we present the Speech Embedding Association Test\n(SpEAT), a method for detecting bias in one type of model used for many speech\ntasks: pre-trained models. The SpEAT is inspired by word embedding association\ntests in natural language processing, which quantify intrinsic bias in a\nmodel's representations of different concepts, such as race or valence\n(something's pleasantness or unpleasantness) and capture the extent to which a\nmodel trained on large-scale socio-cultural data has learned human-like biases.\nUsing the SpEAT, we test for six types of bias in 16 English speech models\n(including 4 models also trained on multilingual data), which come from the\nwav2vec 2.0, HuBERT, WavLM, and Whisper model families. We find that 14 or more\nmodels reveal positive valence (pleasantness) associations with abled people\nover disabled people, with European-Americans over African-Americans, with\nfemales over males, with U.S. accented speakers over non-U.S. accented\nspeakers, and with younger people over older people. Beyond establishing that\npre-trained speech models contain these biases, we also show that they can have\nreal world effects. We compare biases found in pre-trained models to biases in\ndownstream models adapted to the task of Speech Emotion Recognition (SER) and\nfind that in 66 of the 96 tests performed (69%), the group that is more\nassociated with positive valence as indicated by the SpEAT also tends to be\npredicted as speaking with higher valence by the downstream model. Our work\nprovides evidence that, like text and image-based models, pre-trained speech\nbased-models frequently learn human-like biases. Our work also shows that bias\nfound in pre-trained models can propagate to the downstream task of SER.",
            "author": [
                "Isaac Slaughter",
                "Craig Greenberg",
                "Reva Schwartz",
                "Aylin Caliskan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18877v1",
                "http://arxiv.org/pdf/2310.18877v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18875v1",
            "title": "Feature calibration for computer models",
            "updated": "2023-10-29T02:23:17Z",
            "published": "2023-10-29T02:23:17Z",
            "summary": "Computer model calibration involves using partial and imperfect observations\nof the real world to learn which values of a model's input parameters lead to\noutputs that are consistent with real-world observations. When calibrating\nmodels with high-dimensional output (e.g. a spatial field), it is common to\nrepresent the output as a linear combination of a small set of basis vectors.\nOften, when trying to calibrate to such output, what is important to the\ncredibility of the model is that key emergent physical phenomena are\nrepresented, even if not faithfully or in the right place. In these cases,\ncomparison of model output and data in a linear subspace is inappropriate and\nwill usually lead to poor model calibration. To overcome this, we present\nkernel-based history matching (KHM), generalising the meaning of the technique\nsufficiently to be able to project model outputs and observations into a\nhigher-dimensional feature space, where patterns can be compared without their\nlocation necessarily being fixed. We develop the technical methodology, present\nan expert-driven kernel selection algorithm, and then apply the techniques to\nthe calibration of boundary layer clouds for the French climate model IPSL-CM.",
            "author": [
                "Wenzhe Xu",
                "Daniel B. Williamson",
                "Frederic Hourdin",
                "Romain Roehrig"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18875v1",
                "http://arxiv.org/pdf/2310.18875v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18868v1",
            "title": "Correlation Aware Sparsified Mean Estimation Using Random Projection",
            "updated": "2023-10-29T01:45:52Z",
            "published": "2023-10-29T01:45:52Z",
            "summary": "We study the problem of communication-efficient distributed vector mean\nestimation, a commonly used subroutine in distributed optimization and\nFederated Learning (FL). Rand-$k$ sparsification is a commonly used technique\nto reduce communication cost, where each client sends $k < d$ of its\ncoordinates to the server. However, Rand-$k$ is agnostic to any correlations,\nthat might exist between clients in practical scenarios. The recently proposed\nRand-$k$-Spatial estimator leverages the cross-client correlation information\nat the server to improve Rand-$k$'s performance. Yet, the performance of\nRand-$k$-Spatial is suboptimal. We propose the Rand-Proj-Spatial estimator with\na more flexible encoding-decoding procedure, which generalizes the encoding of\nRand-$k$ by projecting the client vectors to a random $k$-dimensional subspace.\nWe utilize Subsampled Randomized Hadamard Transform (SRHT) as the projection\nmatrix and show that Rand-Proj-Spatial with SRHT outperforms Rand-$k$-Spatial,\nusing the correlation information more efficiently. Furthermore, we propose an\napproach to incorporate varying degrees of correlation and suggest a practical\nvariant of Rand-Proj-Spatial when the correlation information is not available\nto the server. Experiments on real-world distributed optimization tasks\nshowcase the superior performance of Rand-Proj-Spatial compared to\nRand-$k$-Spatial and other more sophisticated sparsification techniques.",
            "author": [
                "Shuli Jiang",
                "Pranay Sharma",
                "Gauri Joshi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18868v1",
                "http://arxiv.org/pdf/2310.18868v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18865v1",
            "title": "MUST: A Multilingual Student-Teacher Learning approach for low-resource\n  speech recognition",
            "updated": "2023-10-29T01:38:36Z",
            "published": "2023-10-29T01:38:36Z",
            "summary": "Student-teacher learning or knowledge distillation (KD) has been previously\nused to address data scarcity issue for training of speech recognition (ASR)\nsystems. However, a limitation of KD training is that the student model classes\nmust be a proper or improper subset of the teacher model classes. It prevents\ndistillation from even acoustically similar languages if the character sets are\nnot same. In this work, the aforementioned limitation is addressed by proposing\na MUltilingual Student-Teacher (MUST) learning which exploits a posteriors\nmapping approach. A pre-trained mapping model is used to map posteriors from a\nteacher language to the student language ASR. These mapped posteriors are used\nas soft labels for KD learning. Various teacher ensemble schemes are\nexperimented to train an ASR model for low-resource languages. A model trained\nwith MUST learning reduces relative character error rate (CER) up to 9.5% in\ncomparison with a baseline monolingual ASR.",
            "author": [
                "Muhammad Umar Farooq",
                "Rehan Ahmad",
                "Thomas Hain"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18865v1",
                "http://arxiv.org/pdf/2310.18865v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18861v1",
            "title": "Peer-to-Peer Deep Learning for Beyond-5G IoT",
            "updated": "2023-10-29T01:18:45Z",
            "published": "2023-10-29T01:18:45Z",
            "summary": "We present P2PL, a practical multi-device peer-to-peer deep learning\nalgorithm that, unlike the federated learning paradigm, does not require\ncoordination from edge servers or the cloud. This makes P2PL well-suited for\nthe sheer scale of beyond-5G computing environments like smart cities that\notherwise create range, latency, bandwidth, and single point of failure issues\nfor federated approaches.\n  P2PL introduces max norm synchronization to catalyze training, retains\non-device deep model training to preserve privacy, and leverages local\ninter-device communication to implement distributed consensus. Each device\niteratively alternates between two phases: 1) on-device learning and 2)\ndistributed cooperation where they combine model parameters with nearby\ndevices. We empirically show that all participating devices achieve the same\ntest performance attained by federated and centralized training -- even with\n100 devices and relaxed singly stochastic consensus weights. We extend these\nexperimental results to settings with diverse network topologies, sparse and\nintermittent communication, and non-IID data distributions.",
            "author": [
                "Srinivasa Pranav",
                "Jos\u00e9 M. F. Moura"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18861v1",
                "http://arxiv.org/pdf/2310.18861v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18860v2",
            "title": "Bayes beats Cross Validation: Efficient and Accurate Ridge Regression\n  via Expectation Maximization",
            "updated": "2023-11-03T02:00:03Z",
            "published": "2023-10-29T01:13:55Z",
            "summary": "We present a novel method for tuning the regularization hyper-parameter,\n$\\lambda$, of a ridge regression that is faster to compute than leave-one-out\ncross-validation (LOOCV) while yielding estimates of the regression parameters\nof equal, or particularly in the setting of sparse covariates, superior quality\nto those obtained by minimising the LOOCV risk. The LOOCV risk can suffer from\nmultiple and bad local minima for finite $n$ and thus requires the\nspecification of a set of candidate $\\lambda$, which can fail to provide good\nsolutions. In contrast, we show that the proposed method is guaranteed to find\na unique optimal solution for large enough $n$, under relatively mild\nconditions, without requiring the specification of any difficult to determine\nhyper-parameters. This is based on a Bayesian formulation of ridge regression\nthat we prove to have a unimodal posterior for large enough $n$, allowing for\nboth the optimal $\\lambda$ and the regression coefficients to be jointly\nlearned within an iterative expectation maximization (EM) procedure.\nImportantly, we show that by utilizing an appropriate preprocessing step, a\nsingle iteration of the main EM loop can be implemented in $O(\\min(n, p))$\noperations, for input data with $n$ rows and $p$ columns. In contrast,\nevaluating a single value of $\\lambda$ using fast LOOCV costs $O(n \\min(n, p))$\noperations when using the same preprocessing. This advantage amounts to an\nasymptotic improvement of a factor of $l$ for $l$ candidate values for\n$\\lambda$ (in the regime $q, p \\in O(\\sqrt{n})$ where $q$ is the number of\nregression targets).",
            "author": [
                "Shu Yu Tew",
                "Mario Boley",
                "Daniel F. Schmidt"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18860v2",
                "http://arxiv.org/pdf/2310.18860v2"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18859v1",
            "title": "SiDA: Sparsity-Inspired Data-Aware Serving for Efficient and Scalable\n  Large Mixture-of-Experts Models",
            "updated": "2023-10-29T01:08:55Z",
            "published": "2023-10-29T01:08:55Z",
            "summary": "Mixture-of-Experts (MoE) has emerged as a favorable architecture in the era\nof large models due to its inherent advantage, i.e., enlarging model capacity\nwithout incurring notable computational overhead. Yet, the realization of such\nbenefits often results in ineffective GPU memory utilization, as large portions\nof the model parameters remain dormant during inference. Moreover, the memory\ndemands of large models consistently outpace the memory capacity of\ncontemporary GPUs. Addressing this, we introduce SiDA (Sparsity-inspired\nData-Aware), an efficient inference approach tailored for large MoE models.\nSiDA judiciously exploits both the system's main memory, which is now abundant\nand readily scalable, and GPU memory by capitalizing on the inherent sparsity\non expert activation in MoE models. By adopting a data-aware perspective, SiDA\nachieves enhanced model efficiency with a neglectable performance drop.\nSpecifically, SiDA attains a remarkable speedup in MoE inference with up to\n3.93X throughput increasing, up to 75% latency reduction, and up to 80% GPU\nmemory saving with down to 1% performance drop. This work paves the way for\nscalable and efficient deployment of large MoE models, even in\nmemory-constrained systems.",
            "author": [
                "Zhixu Du",
                "Shiyu Li",
                "Yuhao Wu",
                "Xiangyu Jiang",
                "Jingwei Sun",
                "Qilin Zheng",
                "Yongkai Wu",
                "Ang Li",
                "Hai \"Helen\" Li",
                "Yiran Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18859v1",
                "http://arxiv.org/pdf/2310.18859v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18850v1",
            "title": "Exploring Data Augmentations on Self-/Semi-/Fully- Supervised\n  Pre-trained Models",
            "updated": "2023-10-28T23:46:31Z",
            "published": "2023-10-28T23:46:31Z",
            "summary": "Data augmentation has become a standard component of vision pre-trained\nmodels to capture the invariance between augmented views. In practice,\naugmentation techniques that mask regions of a sample with zero/mean values or\npatches from other samples are commonly employed in pre-trained models with\nself-/semi-/fully-supervised contrastive losses. However, the underlying\nmechanism behind the effectiveness of these augmentation techniques remains\npoorly explored. To investigate the problems, we conduct an empirical study to\nquantify how data augmentation affects performance. Concretely, we apply 4\ntypes of data augmentations termed with Random Erasing, CutOut, CutMix and\nMixUp to a series of self-/semi-/fully- supervised pre-trained models. We\nreport their performance on vision tasks such as image classification, object\ndetection, instance segmentation, and semantic segmentation. We then explicitly\nevaluate the invariance and diversity of the feature embedding. We observe\nthat: 1) Masking regions of the images decreases the invariance of the learned\nfeature embedding while providing a more considerable diversity. 2) Manual\nannotations do not change the invariance or diversity of the learned feature\nembedding. 3) The MixUp approach improves the diversity significantly, with\nonly a marginal decrease in terms of the invariance.",
            "author": [
                "Shentong Mo",
                "Zhun Sun",
                "Chao Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18850v1",
                "http://arxiv.org/pdf/2310.18850v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18849v2",
            "title": "Deep Learning-based Compressed Domain Multimedia for Man and Machine: A\n  Taxonomy and Application to Point Cloud Classification",
            "updated": "2023-11-17T15:53:50Z",
            "published": "2023-10-28T23:38:30Z",
            "summary": "In the current golden age of multimedia, human visualization is no longer the\nsingle main target, with the final consumer often being a machine which\nperforms some processing or computer vision tasks. In both cases, deep learning\nplays a undamental role in extracting features from the multimedia\nrepresentation data, usually producing a compressed representation referred to\nas latent representation. The increasing development and adoption of deep\nlearning-based solutions in a wide area of multimedia applications have opened\nan exciting new vision where a common compressed multimedia representation is\nused for both man and machine. The main benefits of this vision are two-fold:\ni) improved performance for the computer vision tasks, since the effects of\ncoding artifacts are mitigated; and ii) reduced computational complexity, since\nprior decoding is not required. This paper proposes the first taxonomy for\ndesigning compressed domain computer vision solutions driven by the\narchitecture and weights compatibility with an available spatio-temporal\ncomputer vision processor. The potential of the proposed taxonomy is\ndemonstrated for the specific case of point cloud classification by designing\nnovel compressed domain processors using the JPEG Pleno Point Cloud Coding\nstandard under development and adaptations of the PointGrid classifier.\nExperimental results show that the designed compressed domain point cloud\nclassification solutions can significantly outperform the spatial-temporal\ndomain classification benchmarks when applied to the decompressed data,\ncontaining coding artifacts, and even surpass their performance when applied to\nthe original uncompressed data.",
            "author": [
                "Abdelrahman Seleem",
                "Andr\u00e9 F. R. Guarda",
                "Nuno M. M. Rodrigues",
                "Fernando Pereira"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18849v2",
                "http://arxiv.org/pdf/2310.18849v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.16125v1",
            "title": "Vision-Based Incoming Traffic Estimator Using Deep Neural Network on\n  General Purpose Embedded Hardware",
            "updated": "2023-10-28T23:33:00Z",
            "published": "2023-10-28T23:33:00Z",
            "summary": "Traffic management is a serious problem in many cities around the world. Even\nthe suburban areas are now experiencing regular traffic congestion.\nInappropriate traffic control wastes fuel, time, and the productivity of\nnations. Though traffic signals are used to improve traffic flow, they often\ncause problems due to inappropriate or obsolete timing that does not tally with\nthe actual traffic intensity at the intersection. Traffic intensity\ndetermination based on statistical methods only gives the average intensity\nexpected at any given time. However, to control traffic accurately, it is\nrequired to know the real-time traffic intensity. In this research, image\nprocessing and machine learning have been used to estimate actual traffic\nintensity in real time. General-purpose electronic hardware has been used for\nin-situ image processing based on the edge-detection method. A deep neural\nnetwork (DNN) was trained to infer traffic intensity in each image in real\ntime. The trained DNN estimated traffic intensity accurately in 90% of the\nreal-time images during road tests. The electronic system was implemented on a\nRaspberry Pi single-board computer; hence, it is cost-effective for large-scale\ndeployment.",
            "author": [
                "K. G. Zoysa",
                "S. R. Munasinghe"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16125v1",
                "http://arxiv.org/pdf/2311.16125v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18847v1",
            "title": "World Model Based Sim2Real Transfer for Visual Navigation",
            "updated": "2023-10-28T23:25:19Z",
            "published": "2023-10-28T23:25:19Z",
            "summary": "Sim2Real transfer has gained popularity because it helps transfer from\ninexpensive simulators to real world. This paper presents a novel system that\nfuses components in a traditional \\textit{World Model} into a robust system,\ntrained entirely within a simulator, that \\textit{Zero-Shot} transfers to the\nreal world. To facilitate transfer, we use an intermediary representation that\nare based on \\textit{Bird's Eye View (BEV)} images. Thus, our robot learns to\nnavigate in a simulator by first learning to translate from complex\n\\textit{First-Person View (FPV)} based RGB images to BEV representations, then\nlearning to navigate using those representations. Later, when tested in the\nreal world, the robot uses the perception model that translates FPV-based RGB\nimages to embeddings that are used by the downstream policy. The incorporation\nof state-checking modules using \\textit{Anchor images} and \\textit{Mixture\nDensity LSTM} not only interpolates uncertain and missing observations but also\nenhances the robustness of the model when exposed to the real-world\nenvironment. We trained the model using data collected using a\n\\textit{Differential drive} robot in the CARLA simulator. Our methodology's\neffectiveness is shown through the deployment of trained models onto a\n\\textit{Real world Differential drive} robot. Lastly we release a comprehensive\ncodebase, dataset and models for training and deployment that are available to\nthe public.",
            "author": [
                "Chen Liu",
                "Kiran Lekkala",
                "Laurent Itti"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18847v1",
                "http://arxiv.org/pdf/2310.18847v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18845v1",
            "title": "Application of Collaborative Learning Paradigms within Software\n  Engineering Education: A Systematic Mapping Study",
            "updated": "2023-10-28T23:16:38Z",
            "published": "2023-10-28T23:16:38Z",
            "summary": "Collaboration is used in Software Engineering (SE) to develop software.\nIndustry seeks SE graduates with collaboration skills to contribute to\nproductive software development. SE educators can use Collaborative Learning\n(CL) to help students develop collaboration skills. This paper uses a\nSystematic Mapping Study (SMS) to examine the application of the CL educational\ntheory in SE Education. The SMS identified 14 papers published between 2011 and\n2022. We used qualitative analysis to classify the papers into four CL\nparadigms: Conditions, Effect, Interactions, and Computer-Supported\nCollaborative Learning (CSCL). We found a high interest in CSCL, with a shift\nin student interaction research to computer-mediated technologies. We discussed\nthe 14 papers in depth, describing their goals and further analysing the CSCL\nresearch. Almost half the papers did not achieve the appropriate level of\nsupporting evidence; however, calibrating the instruments presented could\nstrengthen findings and support multiple CL paradigms, especially opportunities\nto learn at the social and community levels, where research was lacking. Though\nour results demonstrate limited CL educational theory applied in SE Education,\nwe discuss future work to layer the theory on existing study designs for more\neffective teaching strategies.",
            "author": [
                "Rita Garcia",
                "Christoph Treude",
                "Andrew Valentine"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3626252.3630780",
                "http://arxiv.org/abs/2310.18845v1",
                "http://arxiv.org/pdf/2310.18845v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18844v1",
            "title": "BanditPAM++: Faster $k$-medoids Clustering",
            "updated": "2023-10-28T23:11:16Z",
            "published": "2023-10-28T23:11:16Z",
            "summary": "Clustering is a fundamental task in data science with wide-ranging\napplications. In $k$-medoids clustering, cluster centers must be actual\ndatapoints and arbitrary distance metrics may be used; these features allow for\ngreater interpretability of the cluster centers and the clustering of exotic\nobjects in $k$-medoids clustering, respectively. $k$-medoids clustering has\nrecently grown in popularity due to the discovery of more efficient $k$-medoids\nalgorithms. In particular, recent research has proposed BanditPAM, a randomized\n$k$-medoids algorithm with state-of-the-art complexity and clustering accuracy.\nIn this paper, we present BanditPAM++, which accelerates BanditPAM via two\nalgorithmic improvements, and is $O(k)$ faster than BanditPAM in complexity and\nsubstantially faster than BanditPAM in wall-clock runtime. First, we\ndemonstrate that BanditPAM has a special structure that allows the reuse of\nclustering information $\\textit{within}$ each iteration. Second, we demonstrate\nthat BanditPAM has additional structure that permits the reuse of information\n$\\textit{across}$ different iterations. These observations inspire our proposed\nalgorithm, BanditPAM++, which returns the same clustering solutions as\nBanditPAM but often several times faster. For example, on the CIFAR10 dataset,\nBanditPAM++ returns the same results as BanditPAM but runs over 10$\\times$\nfaster. Finally, we provide a high-performance C++ implementation of\nBanditPAM++, callable from Python and R, that may be of interest to\npractitioners at https://github.com/motiwari/BanditPAM. Auxiliary code to\nreproduce all of our experiments via a one-line script is available at\nhttps://github.com/ThrunGroup/BanditPAM_plusplus_experiments.",
            "author": [
                "Mo Tiwari",
                "Ryan Kang",
                "Donghyun Lee",
                "Sebastian Thrun",
                "Chris Piech",
                "Ilan Shomorony",
                "Martin Jinye Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18844v1",
                "http://arxiv.org/pdf/2310.18844v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "68",
                "I.m; I.2.0; I.2.6; K.3.2; I.2.m"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18841v1",
            "title": "A randomized algorithm for nonconvex minimization with inexact\n  evaluations and complexity guarantees",
            "updated": "2023-10-28T22:57:56Z",
            "published": "2023-10-28T22:57:56Z",
            "summary": "We consider minimization of a smooth nonconvex function with inexact oracle\naccess to gradient and Hessian (but not the function value) to achieve\n$(\\epsilon_{g}, \\epsilon_{H})$-approximate second-order optimality. A novel\nfeature of our method is that if an approximate direction of negative curvature\nis chosen as the step, we choose its sense to be positive or negative with\nequal probability. We also use relative inexactness measures on gradient and\nHessian and relax the coupling between the first- and second-order tolerances\n$\\epsilon_{g}$ and $\\epsilon_{H}$. Our convergence analysis includes both an\nexpectation bound based on martingale analysis and a high-probability bound\nbased on concentration inequalities. We apply our algorithm to empirical risk\nminimization problems and obtain gradient sample complexity.",
            "author": [
                "Shuyao Li",
                "Stephen J. Wright"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18841v1",
                "http://arxiv.org/pdf/2310.18841v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18836v2",
            "title": "Design of Cluster-Randomized Trials with Cross-Cluster Interference",
            "updated": "2023-11-20T04:02:24Z",
            "published": "2023-10-28T22:36:37Z",
            "summary": "Cluster-randomized trials often involve units that are irregularly\ndistributed in space without well-separated communities. In these settings,\ncluster construction is a critical aspect of the design due to the potential\nfor cross-cluster interference. The existing literature relies on partial\ninterference models, which take clusters as given and assume no cross-cluster\ninterference. We relax this assumption by allowing interference to decay with\ngeographic distance between units. This induces a bias-variance trade-off:\nconstructing fewer, larger clusters reduces bias due to interference but\nincreases variance. We propose new estimators that exclude units most\npotentially impacted by cross-cluster interference and show that this\nsubstantially reduces asymptotic bias relative to conventional\ndifference-in-means estimators. We provide formal justification for a new\ndesign that chooses the number of clusters to balance the asymptotic bias and\nvariance of our estimators and uses unsupervised learning to automate cluster\nconstruction.",
            "author": [
                "Michael P. Leung"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18836v2",
                "http://arxiv.org/pdf/2310.18836v2"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "econ.EM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18835v1",
            "title": "Experience-weighted attraction learning in network coordination games",
            "updated": "2023-10-28T22:35:05Z",
            "published": "2023-10-28T22:35:05Z",
            "summary": "This paper studies the action dynamics of network coordination games with\nbounded-rational agents. I apply the experience-weighted attraction (EWA) model\nto the analysis as the EWA model has several free parameters that can capture\ndifferent aspects of agents' behavioural features. I show that the set of\npossible long-term action patterns can be largely different when the\nbehavioural parameters vary, ranging from a unique possibility in which all\nagents favour the risk-dominant option to some set of outcomes richer than the\ncollection of Nash equilibria. Monotonicity and non-monotonicity in the\nrelationship between the number of possible long-term action profiles and the\nbehavioural parameters are explored. I also study the question of influential\nagents in terms of whose initial predispositions are important to the actions\nof the whole network. The importance of agents can be represented by a left\neigenvector of a Jacobian matrix provided that agents' initial attractions are\nclose to some neutral level. Numerical calculations examine the predictive\npower of the eigenvector for the long-run action profile and how agents'\ninfluences are impacted by their behavioural features and network positions.",
            "author": [
                "Fulin Guo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18835v1",
                "http://arxiv.org/pdf/2310.18835v1"
            ],
            "primary_category": "econ.GN",
            "category": [
                "econ.GN",
                "q-fin.EC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18832v1",
            "title": "Responsible AI (RAI) Games and Ensembles",
            "updated": "2023-10-28T22:17:30Z",
            "published": "2023-10-28T22:17:30Z",
            "summary": "Several recent works have studied the societal effects of AI; these include\nissues such as fairness, robustness, and safety. In many of these objectives, a\nlearner seeks to minimize its worst-case loss over a set of predefined\ndistributions (known as uncertainty sets), with usual examples being perturbed\nversions of the empirical distribution. In other words, aforementioned problems\ncan be written as min-max problems over these uncertainty sets. In this work,\nwe provide a general framework for studying these problems, which we refer to\nas Responsible AI (RAI) games. We provide two classes of algorithms for solving\nthese games: (a) game-play based algorithms, and (b) greedy stagewise\nestimation algorithms. The former class is motivated by online learning and\ngame theory, whereas the latter class is motivated by the classical statistical\nliterature on boosting, and regression. We empirically demonstrate the\napplicability and competitive performance of our techniques for solving several\nRAI problems, particularly around subpopulation shift.",
            "author": [
                "Yash Gupta",
                "Runtian Zhai",
                "Arun Suggala",
                "Pradeep Ravikumar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18832v1",
                "http://arxiv.org/pdf/2310.18832v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18830v1",
            "title": "Translating away Translationese without Parallel Data",
            "updated": "2023-10-28T22:11:25Z",
            "published": "2023-10-28T22:11:25Z",
            "summary": "Translated texts exhibit systematic linguistic differences compared to\noriginal texts in the same language, and these differences are referred to as\ntranslationese. Translationese has effects on various cross-lingual natural\nlanguage processing tasks, potentially leading to biased results. In this\npaper, we explore a novel approach to reduce translationese in translated\ntexts: translation-based style transfer. As there are no parallel\nhuman-translated and original data in the same language, we use a\nself-supervised approach that can learn from comparable (rather than parallel)\nmono-lingual original and translated data. However, even this self-supervised\napproach requires some parallel data for validation. We show how we can\neliminate the need for parallel validation data by combining the\nself-supervised loss with an unsupervised loss. This unsupervised loss\nleverages the original language model loss over the style-transferred output\nand a semantic similarity loss between the input and style-transferred output.\nWe evaluate our approach in terms of original vs. translationese binary\nclassification in addition to measuring content preservation and target-style\nfluency. The results show that our approach is able to reduce translationese\nclassifier accuracy to a level of a random classifier after style transfer\nwhile adequately preserving the content and fluency in the target original\nstyle.",
            "author": [
                "Rricha Jalota",
                "Koel Dutta Chowdhury",
                "Cristina Espa\u00f1a-Bonet",
                "Josef van Genabith"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18830v1",
                "http://arxiv.org/pdf/2310.18830v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18824v1",
            "title": "Intrinsic Gaussian Vector Fields on Manifolds",
            "updated": "2023-10-28T21:17:36Z",
            "published": "2023-10-28T21:17:36Z",
            "summary": "Various applications ranging from robotics to climate science require\nmodeling signals on non-Euclidean domains, such as the sphere. Gaussian process\nmodels on manifolds have recently been proposed for such tasks, in particular\nwhen uncertainty quantification is needed. In the manifold setting,\nvector-valued signals can behave very differently from scalar-valued ones, with\nmuch of the progress so far focused on modeling the latter. The former,\nhowever, are crucial for many applications, such as modeling wind speeds or\nforce fields of unknown dynamical systems. In this paper, we propose novel\nGaussian process models for vector-valued signals on manifolds that are\nintrinsically defined and account for the geometry of the space in\nconsideration. We provide computational primitives needed to deploy the\nresulting Hodge-Mat\\'ern Gaussian vector fields on the two-dimensional sphere\nand the hypertori. Further, we highlight two generalization directions:\ndiscrete two-dimensional meshes and \"ideal\" manifolds like hyperspheres, Lie\ngroups, and homogeneous spaces. Finally, we show that our Gaussian vector\nfields constitute considerably more refined inductive biases than the extrinsic\nfields proposed before.",
            "author": [
                "Daniel Robert-Nicoud",
                "Andreas Krause",
                "Viacheslav Borovitskiy"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18824v1",
                "http://arxiv.org/pdf/2310.18824v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18823v1",
            "title": "Successfully Applying Lottery Ticket Hypothesis to Diffusion Model",
            "updated": "2023-10-28T21:09:50Z",
            "published": "2023-10-28T21:09:50Z",
            "summary": "Despite the success of diffusion models, the training and inference of\ndiffusion models are notoriously expensive due to the long chain of the reverse\nprocess. In parallel, the Lottery Ticket Hypothesis (LTH) claims that there\nexists winning tickets (i.e., aproperly pruned sub-network together with\noriginal weight initialization) that can achieve performance competitive to the\noriginal dense neural network when trained in isolation. In this work, we for\nthe first time apply LTH to diffusion models. We empirically find subnetworks\nat sparsity 90%-99% without compromising performance for denoising diffusion\nprobabilistic models on benchmarks (CIFAR-10, CIFAR-100, MNIST). Moreover,\nexisting LTH works identify the subnetworks with a unified sparsity along\ndifferent layers. We observe that the similarity between two winning tickets of\na model varies from block to block. Specifically, the upstream layers from two\nwinning tickets for a model tend to be more similar than the downstream layers.\nTherefore, we propose to find the winning ticket with varying sparsity along\ndifferent layers in the model. Experimental results demonstrate that our method\ncan find sparser sub-models that require less memory for storage and reduce the\nnecessary number of FLOPs. Codes are available at\nhttps://github.com/osier0524/Lottery-Ticket-to-DDPM.",
            "author": [
                "Chao Jiang",
                "Bo Hui",
                "Bohan Liu",
                "Da Yan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18823v1",
                "http://arxiv.org/pdf/2310.18823v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18816v1",
            "title": "Adaptive Test-Time Personalization for Federated Learning",
            "updated": "2023-10-28T20:42:47Z",
            "published": "2023-10-28T20:42:47Z",
            "summary": "Personalized federated learning algorithms have shown promising results in\nadapting models to various distribution shifts. However, most of these methods\nrequire labeled data on testing clients for personalization, which is usually\nunavailable in real-world scenarios. In this paper, we introduce a novel\nsetting called test-time personalized federated learning (TTPFL), where clients\nlocally adapt a global model in an unsupervised way without relying on any\nlabeled data during test-time. While traditional test-time adaptation (TTA) can\nbe used in this scenario, most of them inherently assume training data come\nfrom a single domain, while they come from multiple clients (source domains)\nwith different distributions. Overlooking these domain interrelationships can\nresult in suboptimal generalization. Moreover, most TTA algorithms are designed\nfor a specific kind of distribution shift and lack the flexibility to handle\nmultiple kinds of distribution shifts in FL. In this paper, we find that this\nlack of flexibility partially results from their pre-defining which modules to\nadapt in the model. To tackle this challenge, we propose a novel algorithm\ncalled ATP to adaptively learns the adaptation rates for each module in the\nmodel from distribution shifts among source domains. Theoretical analysis\nproves the strong generalization of ATP. Extensive experiments demonstrate its\nsuperiority in handling various distribution shifts including label shift,\nimage corruptions, and domain shift, outperforming existing TTA methods across\nmultiple datasets and model architectures. Our code is available at\nhttps://github.com/baowenxuan/ATP .",
            "author": [
                "Wenxuan Bao",
                "Tianxin Wei",
                "Haohan Wang",
                "Jingrui He"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18816v1",
                "http://arxiv.org/pdf/2310.18816v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18815v1",
            "title": "Rethinking Semi-Supervised Federated Learning: How to co-train\n  fully-labeled and fully-unlabeled client imaging data",
            "updated": "2023-10-28T20:41:41Z",
            "published": "2023-10-28T20:41:41Z",
            "summary": "The most challenging, yet practical, setting of semi-supervised federated\nlearning (SSFL) is where a few clients have fully labeled data whereas the\nother clients have fully unlabeled data. This is particularly common in\nhealthcare settings where collaborating partners (typically hospitals) may have\nimages but not annotations. The bottleneck in this setting is the joint\ntraining of labeled and unlabeled clients as the objective function for each\nclient varies based on the availability of labels. This paper investigates an\nalternative way for effective training with labeled and unlabeled clients in a\nfederated setting. We propose a novel learning scheme specifically designed for\nSSFL which we call Isolated Federated Learning (IsoFed) that circumvents the\nproblem by avoiding simple averaging of supervised and semi-supervised models\ntogether. In particular, our training approach consists of two parts - (a)\nisolated aggregation of labeled and unlabeled client models, and (b) local\nself-supervised pretraining of isolated global models in all clients. We\nevaluate our model performance on medical image datasets of four different\nmodalities publicly available within the biomedical image classification\nbenchmark MedMNIST. We further vary the proportion of labeled clients and the\ndegree of heterogeneity to demonstrate the effectiveness of the proposed method\nunder varied experimental settings.",
            "author": [
                "Pramit Saha",
                "Divyanshu Mishra",
                "J. Alison Noble"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18815v1",
                "http://arxiv.org/pdf/2310.18815v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18814v1",
            "title": "Stability of Random Forests and Coverage of Random-Forest Prediction\n  Intervals",
            "updated": "2023-10-28T20:38:53Z",
            "published": "2023-10-28T20:38:53Z",
            "summary": "We establish stability of random forests under the mild condition that the\nsquared response ($Y^2$) does not have a heavy tail. In particular, our\nanalysis holds for the practical version of random forests that is implemented\nin popular packages like \\texttt{randomForest} in \\texttt{R}. Empirical results\nshow that stability may persist even beyond our assumption and hold for\nheavy-tailed $Y^2$. Using the stability property, we prove a non-asymptotic\nlower bound for the coverage probability of prediction intervals constructed\nfrom the out-of-bag error of random forests. With another mild condition that\nis typically satisfied when $Y$ is continuous, we also establish a\ncomplementary upper bound, which can be similarly established for the jackknife\nprediction interval constructed from an arbitrary stable algorithm. We also\ndiscuss the asymptotic coverage probability under assumptions weaker than those\nconsidered in previous literature. Our work implies that random forests, with\nits stability property, is an effective machine learning method that can\nprovide not only satisfactory point prediction but also justified interval\nprediction at almost no extra computational cost.",
            "author": [
                "Yan Wang",
                "Huaiqing Wu",
                "Dan Nettleton"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18814v1",
                "http://arxiv.org/pdf/2310.18814v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18813v1",
            "title": "The Synergy of Speculative Decoding and Batching in Serving Large\n  Language Models",
            "updated": "2023-10-28T20:36:36Z",
            "published": "2023-10-28T20:36:36Z",
            "summary": "Large Language Models (LLMs) like GPT are state-of-the-art text generation\nmodels that provide significant assistance in daily routines. However, LLM\nexecution is inherently sequential, since they only produce one token at a\ntime, thus incurring low hardware utilization on modern GPUs. Batching and\nspeculative decoding are two techniques to improve GPU hardware utilization in\nLLM inference. To study their synergy, we implement a prototype implementation\nand perform an extensive characterization analysis on various LLM models and\nGPU architectures. We observe that the optimal speculation length depends on\nthe batch size used. We analyze the key observation and build a quantitative\nmodel to explain it. Based on our analysis, we propose a new adaptive\nspeculative decoding strategy that chooses the optimal speculation length for\ndifferent batch sizes. Our evaluations show that our proposed method can\nachieve equal or better performance than the state-of-the-art speculation\ndecoding schemes with fixed speculation length.",
            "author": [
                "Qidong Su",
                "Christina Giannoula",
                "Gennady Pekhimenko"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18813v1",
                "http://arxiv.org/pdf/2310.18813v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18811v1",
            "title": "Hierarchical Framework for Interpretable and Probabilistic Model-Based\n  Safe Reinforcement Learning",
            "updated": "2023-10-28T20:30:57Z",
            "published": "2023-10-28T20:30:57Z",
            "summary": "The difficulty of identifying the physical model of complex systems has led\nto exploring methods that do not rely on such complex modeling of the systems.\nDeep reinforcement learning has been the pioneer for solving this problem\nwithout the need for relying on the physical model of complex systems by just\ninteracting with it. However, it uses a black-box learning approach that makes\nit difficult to be applied within real-world and safety-critical systems\nwithout providing explanations of the actions derived by the model.\nFurthermore, an open research question in deep reinforcement learning is how to\nfocus the policy learning of critical decisions within a sparse domain. This\npaper proposes a novel approach for the use of deep reinforcement learning in\nsafety-critical systems. It combines the advantages of probabilistic modeling\nand reinforcement learning with the added benefits of interpretability and\nworks in collaboration and synchronization with conventional decision-making\nstrategies. The BC-SRLA is activated in specific situations which are\nidentified autonomously through the fused information of probabilistic model\nand reinforcement learning, such as abnormal conditions or when the system is\nnear-to-failure. Further, it is initialized with a baseline policy using policy\ncloning to allow minimum interactions with the environment to address the\nchallenges associated with using RL in safety-critical industries. The\neffectiveness of the BC-SRLA is demonstrated through a case study in\nmaintenance applied to turbofan engines, where it shows superior performance to\nthe prior art and other baselines.",
            "author": [
                "Ammar N. Abbas",
                "Georgios C. Chasparis",
                "John D. Kelleher"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18811v1",
                "http://arxiv.org/pdf/2310.18811v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18807v1",
            "title": "OC-NMN: Object-centric Compositional Neural Module Network for\n  Generative Visual Analogical Reasoning",
            "updated": "2023-10-28T20:12:58Z",
            "published": "2023-10-28T20:12:58Z",
            "summary": "A key aspect of human intelligence is the ability to imagine -- composing\nlearned concepts in novel ways -- to make sense of new scenarios. Such capacity\nis not yet attained for machine learning systems. In this work, in the context\nof visual reasoning, we show how modularity can be leveraged to derive a\ncompositional data augmentation framework inspired by imagination. Our method,\ndenoted Object-centric Compositional Neural Module Network (OC-NMN), decomposes\nvisual generative reasoning tasks into a series of primitives applied to\nobjects without using a domain-specific language. We show that our modular\narchitectural choices can be used to generate new training tasks that lead to\nbetter out-of-distribution generalization. We compare our model to existing and\nnew baselines in proposed visual reasoning benchmark that consists of applying\narithmetic operations to MNIST digits.",
            "author": [
                "Rim Assouel",
                "Pau Rodriguez",
                "Perouz Taslakian",
                "David Vazquez",
                "Yoshua Bengio"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18807v1",
                "http://arxiv.org/pdf/2310.18807v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18805v2",
            "title": "Inverse distance weighting attention",
            "updated": "2023-12-06T21:06:07Z",
            "published": "2023-10-28T20:11:01Z",
            "summary": "We report the effects of replacing the scaled dot-product (within softmax)\nattention with the negative-log of Euclidean distance. This form of attention\nsimplifies to inverse distance weighting interpolation. Used in simple one\nhidden layer networks and trained with vanilla cross-entropy loss on\nclassification problems, it tends to produce a key matrix containing prototypes\nand a value matrix with corresponding logits. We also show that the resulting\ninterpretable networks can be augmented with manually-constructed prototypes to\nperform low-impact handling of special cases.",
            "author": [
                "Calvin McCarter"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18805v2",
                "http://arxiv.org/pdf/2310.18805v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18804v1",
            "title": "Open Visual Knowledge Extraction via Relation-Oriented Multimodality\n  Model Prompting",
            "updated": "2023-10-28T20:09:29Z",
            "published": "2023-10-28T20:09:29Z",
            "summary": "Images contain rich relational knowledge that can help machines understand\nthe world. Existing methods on visual knowledge extraction often rely on the\npre-defined format (e.g., sub-verb-obj tuples) or vocabulary (e.g., relation\ntypes), restricting the expressiveness of the extracted knowledge. In this\nwork, we take a first exploration to a new paradigm of open visual knowledge\nextraction. To achieve this, we present OpenVik which consists of an open\nrelational region detector to detect regions potentially containing relational\nknowledge and a visual knowledge generator that generates format-free knowledge\nby prompting the large multimodality model with the detected region of\ninterest. We also explore two data enhancement techniques for diversifying the\ngenerated format-free visual knowledge. Extensive knowledge quality evaluations\nhighlight the correctness and uniqueness of the extracted open visual knowledge\nby OpenVik. Moreover, integrating our extracted knowledge across various visual\nreasoning applications shows consistent improvements, indicating the real-world\napplicability of OpenVik.",
            "author": [
                "Hejie Cui",
                "Xinyu Fang",
                "Zihan Zhang",
                "Ran Xu",
                "Xuan Kan",
                "Xin Liu",
                "Yue Yu",
                "Manling Li",
                "Yangqiu Song",
                "Carl Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18804v1",
                "http://arxiv.org/pdf/2310.18804v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18803v1",
            "title": "Weakly Coupled Deep Q-Networks",
            "updated": "2023-10-28T20:07:57Z",
            "published": "2023-10-28T20:07:57Z",
            "summary": "We propose weakly coupled deep Q-networks (WCDQN), a novel deep reinforcement\nlearning algorithm that enhances performance in a class of structured problems\ncalled weakly coupled Markov decision processes (WCMDP). WCMDPs consist of\nmultiple independent subproblems connected by an action space constraint, which\nis a structural property that frequently emerges in practice. Despite this\nappealing structure, WCMDPs quickly become intractable as the number of\nsubproblems grows. WCDQN employs a single network to train multiple DQN\n\"subagents\", one for each subproblem, and then combine their solutions to\nestablish an upper bound on the optimal action value. This guides the main DQN\nagent towards optimality. We show that the tabular version, weakly coupled\nQ-learning (WCQL), converges almost surely to the optimal action value.\nNumerical experiments show faster convergence compared to DQN and related\ntechniques in settings with as many as 10 subproblems, $3^{10}$ total actions,\nand a continuous state space.",
            "author": [
                "Ibrahim El Shar",
                "Daniel R. Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18803v1",
                "http://arxiv.org/pdf/2310.18803v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18795v1",
            "title": "A Review on the Applications of Machine Learning for Tinnitus Diagnosis\n  Using EEG Signals",
            "updated": "2023-10-28T19:49:43Z",
            "published": "2023-10-28T19:49:43Z",
            "summary": "Tinnitus is a prevalent hearing disorder that can be caused by various\nfactors such as age, hearing loss, exposure to loud noises, ear infections or\ntumors, certain medications, head or neck injuries, and psychological\nconditions like anxiety and depression. While not every patient requires\nmedical attention, about 20% of sufferers seek clinical intervention. Early\ndiagnosis is crucial for effective treatment. New developments have been made\nin tinnitus detection to aid in early detection of this illness. Over the past\nfew years, there has been a notable growth in the usage of\nelectroencephalography (EEG) to study variations in oscillatory brain activity\nrelated to tinnitus. However, the results obtained from numerous studies vary\ngreatly, leading to conflicting conclusions. Currently, clinicians rely solely\non their expertise to identify individuals with tinnitus. Researchers in this\nfield have incorporated various data modalities and machine-learning techniques\nto aid clinicians in identifying tinnitus characteristics and classifying\npeople with tinnitus. The purpose of writing this article is to review articles\nthat focus on using machine learning (ML) to identify or predict tinnitus\npatients using EEG signals as input data. We have evaluated 11 articles\npublished between 2016 and 2023 using a systematic literature review (SLR)\nmethod. This article arranges perfect summaries of all the research reviewed\nand compares the significant aspects of each. Additionally, we performed\nstatistical analyses to gain a deeper comprehension of the most recent research\nin this area. Almost all of the reviewed articles followed a five-step\nprocedure to achieve the goal of tinnitus. Disclosure. Finally, we discuss the\nopen affairs and challenges in this method of tinnitus recognition or\nprediction and suggest future directions for research.",
            "author": [
                "Farzaneh Ramezani",
                "Hamidreza Bolhasani"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18795v1",
                "http://arxiv.org/pdf/2310.18795v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18788v1",
            "title": "PrObeD: Proactive Object Detection Wrapper",
            "updated": "2023-10-28T19:25:01Z",
            "published": "2023-10-28T19:25:01Z",
            "summary": "Previous research in $2D$ object detection focuses on various tasks,\nincluding detecting objects in generic and camouflaged images. These works are\nregarded as passive works for object detection as they take the input image as\nis. However, convergence to global minima is not guaranteed to be optimal in\nneural networks; therefore, we argue that the trained weights in the object\ndetector are not optimal. To rectify this problem, we propose a wrapper based\non proactive schemes, PrObeD, which enhances the performance of these object\ndetectors by learning a signal. PrObeD consists of an encoder-decoder\narchitecture, where the encoder network generates an image-dependent signal\ntermed templates to encrypt the input images, and the decoder recovers this\ntemplate from the encrypted images. We propose that learning the optimum\ntemplate results in an object detector with an improved detection performance.\nThe template acts as a mask to the input images to highlight semantics useful\nfor the object detector. Finetuning the object detector with these encrypted\nimages enhances the detection performance for both generic and camouflaged. Our\nexperiments on MS-COCO, CAMO, COD$10$K, and NC$4$K datasets show improvement\nover different detectors after applying PrObeD. Our models/codes are available\nat https://github.com/vishal3477/Proactive-Object-Detection.",
            "author": [
                "Vishal Asnani",
                "Abhinav Kumar",
                "Suya You",
                "Xiaoming Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18788v1",
                "http://arxiv.org/pdf/2310.18788v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18786v1",
            "title": "A Competitive Algorithm for Agnostic Active Learning",
            "updated": "2023-10-28T19:01:16Z",
            "published": "2023-10-28T19:01:16Z",
            "summary": "For some hypothesis classes and input distributions, active agnostic learning\nneeds exponentially fewer samples than passive learning; for other classes and\ndistributions, it offers little to no improvement. The most popular algorithms\nfor agnostic active learning express their performance in terms of a parameter\ncalled the disagreement coefficient, but it is known that these algorithms are\ninefficient on some inputs.\n  We take a different approach to agnostic active learning, getting an\nalgorithm that is competitive with the optimal algorithm for any binary\nhypothesis class $H$ and distribution $D_X$ over $X$. In particular, if any\nalgorithm can use $m^*$ queries to get $O(\\eta)$ error, then our algorithm uses\n$O(m^* \\log |H|)$ queries to get $O(\\eta)$ error. Our algorithm lies in the\nvein of the splitting-based approach of Dasgupta [2004], which gets a similar\nresult for the realizable ($\\eta = 0$) setting.\n  We also show that it is NP-hard to do better than our algorithm's $O(\\log\n|H|)$ overhead in general.",
            "author": [
                "Eric Price",
                "Yihan Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18786v1",
                "http://arxiv.org/pdf/2310.18786v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18784v3",
            "title": "High-probability Convergence Bounds for Nonlinear Stochastic Gradient\n  Descent Under Heavy-tailed Noise",
            "updated": "2023-12-04T20:45:39Z",
            "published": "2023-10-28T18:53:41Z",
            "summary": "Several recent works have studied the convergence \\textit{in high\nprobability} of stochastic gradient descent (SGD) and its clipped variant.\nCompared to vanilla SGD, clipped SGD is practically more stable and has the\nadditional theoretical benefit of logarithmic dependence on the failure\nprobability. However, the convergence of other practical nonlinear variants of\nSGD, e.g., sign SGD, quantized SGD and normalized SGD, that achieve improved\ncommunication efficiency or accelerated convergence is much less understood. In\nthis work, we study the convergence bounds \\textit{in high probability} of a\nbroad class of nonlinear SGD methods. For strongly convex loss functions with\nLipschitz continuous gradients, we prove a logarithmic dependence on the\nfailure probability, even when the noise is heavy-tailed. Strictly more general\nthan the results for clipped SGD, our results hold for any nonlinearity with\nbounded (component-wise or joint) outputs, such as clipping, normalization, and\nquantization. Further, existing results with heavy-tailed noise assume bounded\n$\\eta$-th central moments, with $\\eta \\in (1,2]$. In contrast, our refined\nanalysis works even for $\\eta=1$, strictly relaxing the noise moment\nassumptions in the literature.",
            "author": [
                "Aleksandar Armacki",
                "Pranay Sharma",
                "Gauri Joshi",
                "Dragana Bajovic",
                "Dusan Jakovetic",
                "Soummya Kar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18784v3",
                "http://arxiv.org/pdf/2310.18784v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC",
                "math.ST",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18780v1",
            "title": "Laughing Hyena Distillery: Extracting Compact Recurrences From\n  Convolutions",
            "updated": "2023-10-28T18:40:03Z",
            "published": "2023-10-28T18:40:03Z",
            "summary": "Recent advances in attention-free sequence models rely on convolutions as\nalternatives to the attention operator at the core of Transformers. In\nparticular, long convolution sequence models have achieved state-of-the-art\nperformance in many domains, but incur a significant cost during\nauto-regressive inference workloads -- naively requiring a full pass (or\ncaching of activations) over the input sequence for each generated token --\nsimilarly to attention-based models. In this paper, we seek to enable $\\mathcal\nO(1)$ compute and memory cost per token in any pre-trained long convolution\narchitecture to reduce memory footprint and increase throughput during\ngeneration. Concretely, our methods consist in extracting low-dimensional\nlinear state-space models from each convolution layer, building upon rational\ninterpolation and model-order reduction techniques. We further introduce\narchitectural improvements to convolution-based layers such as Hyena: by\nweight-tying the filters across channels into heads, we achieve higher\npre-training quality and reduce the number of filters to be distilled. The\nresulting model achieves 10x higher throughput than Transformers and 1.5x\nhigher than Hyena at 1.3B parameters, without any loss in quality after\ndistillation.",
            "author": [
                "Stefano Massaroli",
                "Michael Poli",
                "Daniel Y. Fu",
                "Hermann Kumbong",
                "Rom N. Parnichkun",
                "Aman Timalsina",
                "David W. Romero",
                "Quinn McIntyre",
                "Beidi Chen",
                "Atri Rudra",
                "Ce Zhang",
                "Christopher Re",
                "Stefano Ermon",
                "Yoshua Bengio"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18780v1",
                "http://arxiv.org/pdf/2310.18780v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18777v1",
            "title": "Improving Compositional Generalization Using Iterated Learning and\n  Simplicial Embeddings",
            "updated": "2023-10-28T18:30:30Z",
            "published": "2023-10-28T18:30:30Z",
            "summary": "Compositional generalization, the ability of an agent to generalize to unseen\ncombinations of latent factors, is easy for humans but hard for deep neural\nnetworks. A line of research in cognitive science has hypothesized a process,\n``iterated learning,'' to help explain how human language developed this\nability; the theory rests on simultaneous pressures towards compressibility\n(when an ignorant agent learns from an informed one) and expressivity (when it\nuses the representation for downstream tasks). Inspired by this process, we\npropose to improve the compositional generalization of deep networks by using\niterated learning on models with simplicial embeddings, which can approximately\ndiscretize representations. This approach is further motivated by an analysis\nof compositionality based on Kolmogorov complexity. We show that this\ncombination of changes improves compositional generalization over other\napproaches, demonstrating these improvements both on vision tasks with\nwell-understood latent factors and on real molecular graph prediction tasks\nwhere the latent structure is unknown.",
            "author": [
                "Yi Ren",
                "Samuel Lavoie",
                "Mikhail Galkin",
                "Danica J. Sutherland",
                "Aaron Courville"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18777v1",
                "http://arxiv.org/pdf/2310.18777v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18774v1",
            "title": "Reflection coupling for unadjusted generalized Hamiltonian Monte Carlo\n  in the nonconvex stochastic gradient case",
            "updated": "2023-10-28T18:25:59Z",
            "published": "2023-10-28T18:25:59Z",
            "summary": "Contraction in Wasserstein 1-distance with explicit rates is established for\ngeneralized Hamiltonian Monte Carlo with stochastic gradients under possibly\nnonconvex conditions. The algorithms considered include splitting schemes of\nkinetic Langevin diffusion. As consequence, quantitative Gaussian concentration\nbounds are provided for empirical averages. Convergence in Wasserstein\n2-distance, total variation and relative entropy are also given, together with\nnumerical bias estimates.",
            "author": [
                "Martin Chak",
                "Pierre Monmarch\u00e9"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18774v1",
                "http://arxiv.org/pdf/2310.18774v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "stat.CO",
                "stat.ML",
                "60J05, 65P10, 65C05"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18773v1",
            "title": "CityRefer: Geography-aware 3D Visual Grounding Dataset on City-scale\n  Point Cloud Data",
            "updated": "2023-10-28T18:05:32Z",
            "published": "2023-10-28T18:05:32Z",
            "summary": "City-scale 3D point cloud is a promising way to express detailed and\ncomplicated outdoor structures. It encompasses both the appearance and geometry\nfeatures of segmented city components, including cars, streets, and buildings,\nthat can be utilized for attractive applications such as user-interactive\nnavigation of autonomous vehicles and drones. However, compared to the\nextensive text annotations available for images and indoor scenes, the scarcity\nof text annotations for outdoor scenes poses a significant challenge for\nachieving these applications. To tackle this problem, we introduce the\nCityRefer dataset for city-level visual grounding. The dataset consists of 35k\nnatural language descriptions of 3D objects appearing in SensatUrban city\nscenes and 5k landmarks labels synchronizing with OpenStreetMap. To ensure the\nquality and accuracy of the dataset, all descriptions and labels in the\nCityRefer dataset are manually verified. We also have developed a baseline\nsystem that can learn encoded language descriptions, 3D object instances, and\ngeographical information about the city's landmarks to perform visual grounding\non the CityRefer dataset. To the best of our knowledge, the CityRefer dataset\nis the largest city-level visual grounding dataset for localizing specific 3D\nobjects.",
            "author": [
                "Taiki Miyanishi",
                "Fumiya Kitamori",
                "Shuhei Kurita",
                "Jungdae Lee",
                "Motoaki Kawanabe",
                "Nakamasa Inoue"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18773v1",
                "http://arxiv.org/pdf/2310.18773v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18772v1",
            "title": "A Data-driven Recommendation Framework for Optimal Walker Designs",
            "updated": "2023-10-28T18:04:38Z",
            "published": "2023-10-28T18:04:38Z",
            "summary": "The rapidly advancing fields of statistical modeling and machine learning\nhave significantly enhanced data-driven design and optimization. This paper\nfocuses on leveraging these design algorithms to optimize a medical walker, an\nintegral part of gait rehabilitation and physiological therapy of the lower\nextremities. To achieve the desirable qualities of a walker, we train a\npredictive machine-learning model to identify trade-offs between performance\nobjectives, thus enabling the use of efficient optimization algorithms. To do\nthis, we use an Automated Machine Learning model utilizing a stacked-ensemble\napproach shown to outperform traditional ML models. However, training a\npredictive model requires vast amounts of data for accuracy. Due to limited\npublicly available walker designs, this paper presents a dataset of more than\n5,000 parametric walker designs with performance values to assess mass,\nstructural integrity, and stability. These performance values include\ndisplacement vectors for the given load case, stress coefficients, mass, and\nother physical properties. We also introduce a novel method of systematically\ncalculating the stability index of a walker. We use MultiObjective\nCounterfactuals for Design (MCD), a novel genetic-based optimization algorithm,\nto explore the diverse 16-dimensional design space and search for\nhigh-performing designs based on numerous objectives. This paper presents\npotential walker designs that demonstrate up to a 30% mass reduction while\nincreasing structural stability and integrity. This work takes a step toward\nthe improved development of assistive mobility devices.",
            "author": [
                "Advaith Narayanan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18772v1",
                "http://arxiv.org/pdf/2310.18772v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18770v1",
            "title": "Leveraging Multimodal Features and Item-level User Feedback for Bundle\n  Construction",
            "updated": "2023-10-28T17:54:26Z",
            "published": "2023-10-28T17:54:26Z",
            "summary": "Automatic bundle construction is a crucial prerequisite step in various\nbundle-aware online services. Previous approaches are mostly designed to model\nthe bundling strategy of existing bundles. However, it is hard to acquire\nlarge-scale well-curated bundle dataset, especially for those platforms that\nhave not offered bundle services before. Even for platforms with mature bundle\nservices, there are still many items that are included in few or even zero\nbundles, which give rise to sparsity and cold-start challenges in the bundle\nconstruction models. To tackle these issues, we target at leveraging multimodal\nfeatures, item-level user feedback signals, and the bundle composition\ninformation, to achieve a comprehensive formulation of bundle construction.\nNevertheless, such formulation poses two new technical challenges: 1) how to\nlearn effective representations by optimally unifying multiple features, and 2)\nhow to address the problems of modality missing, noise, and sparsity problems\ninduced by the incomplete query bundles. In this work, to address these\ntechnical challenges, we propose a Contrastive Learning-enhanced Hierarchical\nEncoder method (CLHE). Specifically, we use self-attention modules to combine\nthe multimodal and multi-item features, and then leverage both item- and\nbundle-level contrastive learning to enhance the representation learning, thus\nto counter the modality missing, noise, and sparsity problems. Extensive\nexperiments on four datasets in two application domains demonstrate that our\nmethod outperforms a list of SOTA methods. The code and dataset are available\nat https://github.com/Xiaohao-Liu/CLHE.",
            "author": [
                "Yunshan Ma",
                "Xiaohao Liu",
                "Yinwei Wei",
                "Zhulin Tao",
                "Xiang Wang",
                "Tat-Seng Chua"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18770v1",
                "http://arxiv.org/pdf/2310.18770v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.MM",
                "H.3.0"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18769v1",
            "title": "Linear Mode Connectivity in Sparse Neural Networks",
            "updated": "2023-10-28T17:51:39Z",
            "published": "2023-10-28T17:51:39Z",
            "summary": "With the rise in interest of sparse neural networks, we study how neural\nnetwork pruning with synthetic data leads to sparse networks with unique\ntraining properties. We find that distilled data, a synthetic summarization of\nthe real data, paired with Iterative Magnitude Pruning (IMP) unveils a new\nclass of sparse networks that are more stable to SGD noise on the real data,\nthan either the dense model, or subnetworks found with real data in IMP. That\nis, synthetically chosen subnetworks often train to the same minima, or exhibit\nlinear mode connectivity. We study this through linear interpolation, loss\nlandscape visualizations, and measuring the diagonal of the hessian. While\ndataset distillation as a field is still young, we find that these properties\nlead to synthetic subnetworks matching the performance of traditional IMP with\nup to 150x less training points in settings where distilled data applies.",
            "author": [
                "Luke McDermott",
                "Daniel Cummings"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18769v1",
                "http://arxiv.org/pdf/2310.18769v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18767v1",
            "title": "Enhancing Epileptic Seizure Detection with EEG Feature Embeddings",
            "updated": "2023-10-28T17:46:21Z",
            "published": "2023-10-28T17:46:21Z",
            "summary": "Epilepsy is one of the most prevalent brain disorders that disrupts the lives\nof millions worldwide. For patients with drug-resistant seizures, there exist\nimplantable devices capable of monitoring neural activity, promptly triggering\nneurostimulation to regulate seizures, or alerting patients of potential\nepisodes. Next-generation seizure detection systems heavily rely on\nhigh-accuracy machine learning-based classifiers to detect the seizure onset.\nHere, we propose to enhance the seizure detection performance by learning\ninformative embeddings of the EEG signal. We empirically demonstrate, for the\nfirst time, that converting raw EEG signals to appropriate embeddings can\nsignificantly boost the performance of seizure detection algorithms.\nImportantly, we show that embedding features, which converts the raw EEG into\nan alternative representation, is beneficial for various machine learning\nmodels such as Logistic Regression, Multi-Layer Perceptron, Support Vector\nMachines, and Gradient Boosted Trees. The experiments were conducted on the\nCHB-MIT scalp EEG dataset. With the proposed EEG feature embeddings, we achieve\nsignificant improvements in sensitivity, specificity, and AUC score across\nmultiple models. By employing this approach alongside an SVM classifier, we\nwere able to attain state-of-the-art classification performance with a\nsensitivity of 100% and specificity of 99%, setting a new benchmark in the\nfield.",
            "author": [
                "Arman Zarei",
                "Bingzhao Zhu",
                "Mahsa Shoaran"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18767v1",
                "http://arxiv.org/pdf/2310.18767v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18765v2",
            "title": "Rethinking Semi-Supervised Imbalanced Node Classification from\n  Bias-Variance Decomposition",
            "updated": "2023-11-10T13:23:07Z",
            "published": "2023-10-28T17:28:07Z",
            "summary": "This paper introduces a new approach to address the issue of class imbalance\nin graph neural networks (GNNs) for learning on graph-structured data. Our\napproach integrates imbalanced node classification and Bias-Variance\nDecomposition, establishing a theoretical framework that closely relates data\nimbalance to model variance. We also leverage graph augmentation technique to\nestimate the variance, and design a regularization term to alleviate the impact\nof imbalance. Exhaustive tests are conducted on multiple benchmarks, including\nnaturally imbalanced datasets and public-split class-imbalanced datasets,\ndemonstrating that our approach outperforms state-of-the-art methods in various\nimbalanced scenarios. This work provides a novel theoretical perspective for\naddressing the problem of imbalanced node classification in GNNs.",
            "author": [
                "Divin Yan",
                "Gengchen Wei",
                "Chen Yang",
                "Shengzhong Zhang",
                "Zengfeng Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18765v2",
                "http://arxiv.org/pdf/2310.18765v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.14674v1",
            "title": "Emotion-Oriented Behavior Model Using Deep Learning",
            "updated": "2023-10-28T17:27:59Z",
            "published": "2023-10-28T17:27:59Z",
            "summary": "Emotions, as a fundamental ingredient of any social interaction, lead to\nbehaviors that represent the effectiveness of the interaction through facial\nexpressions and gestures in humans. Hence an agent must possess the social and\ncognitive abilities to understand human social parameters and behave\naccordingly. However, no such emotion-oriented behavior model is presented yet\nin the existing research. The emotion prediction may generate appropriate\nagents' behaviors for effective interaction using conversation modality.\nConsidering the importance of emotions, and behaviors, for an agent's social\ninteraction, an Emotion-based Behavior model is presented in this paper for\nSocio-cognitive artificial agents. The proposed model is implemented using\ntweets data trained on multiple models like Long Short-Term Memory (LSTM),\nConvolution Neural Network (CNN) and Bidirectional Encoder Representations from\nTransformers (BERT) for emotion prediction with an average accuracy of 92%, and\n55% respectively. Further, using emotion predictions from CNN-LSTM, the\nbehavior module responds using facial expressions and gestures using Behavioral\nMarkup Language (BML). The accuracy of emotion-based behavior predictions is\nstatistically validated using the 2-tailed Pearson correlation on the data\ncollected from human users through questionnaires. Analysis shows that all\nemotion-based behaviors accurately depict human-like gestures and facial\nexpressions based on the significant correlation at the 0.01 and 0.05 levels.\nThis study is a steppingstone to a multi-faceted artificial agent interaction\nbased on emotion-oriented behaviors. Cognition has significance regarding\nsocial interaction among humans.",
            "author": [
                "Muhammad Arslan Raza",
                "Muhammad Shoaib Farooq",
                "Adel Khelifi",
                "Atif Alvi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14674v1",
                "http://arxiv.org/pdf/2311.14674v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18762v1",
            "title": "Purify++: Improving Diffusion-Purification with Advanced Diffusion\n  Models and Control of Randomness",
            "updated": "2023-10-28T17:18:38Z",
            "published": "2023-10-28T17:18:38Z",
            "summary": "Adversarial attacks can mislead neural network classifiers. The defense\nagainst adversarial attacks is important for AI safety. Adversarial\npurification is a family of approaches that defend adversarial attacks with\nsuitable pre-processing. Diffusion models have been shown to be effective for\nadversarial purification. Despite their success, many aspects of diffusion\npurification still remain unexplored. In this paper, we investigate and improve\nupon three limiting designs of diffusion purification: the use of an improved\ndiffusion model, advanced numerical simulation techniques, and optimal control\nof randomness. Based on our findings, we propose Purify++, a new diffusion\npurification algorithm that is now the state-of-the-art purification method\nagainst several adversarial attacks. Our work presents a systematic exploration\nof the limits of diffusion purification methods.",
            "author": [
                "Boya Zhang",
                "Weijian Luo",
                "Zhihua Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18762v1",
                "http://arxiv.org/pdf/2310.18762v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18760v2",
            "title": "Integration of persistent Laplacian and pre-trained transformer for\n  protein solubility changes upon mutation",
            "updated": "2023-11-02T20:19:28Z",
            "published": "2023-10-28T17:13:47Z",
            "summary": "Protein mutations can significantly influence protein solubility, which\nresults in altered protein functions and leads to various diseases. Despite of\ntremendous effort, machine learning prediction of protein solubility changes\nupon mutation remains a challenging task as indicated by the poor scores of\nnormalized Correct Prediction Ratio (CPR). Part of the challenge stems from the\nfact that there is no three-dimensional (3D) structures for the wild-type and\nmutant proteins. This work integrates persistent Laplacians and pre-trained\nTransformer for the task. The Transformer, pretrained with hunderds of millions\nof protein sequences, embeds wild-type and mutant sequences, while persistent\nLaplacians track the topological invariant change and homotopic shape evolution\ninduced by mutations in 3D protein structures, which are rendered from\nAlphaFold2. The resulting machine learning model was trained on an extensive\ndata set labeled with three solubility types. Our model outperforms all\nexisting predictive methods and improves the state-of-the-art up to 15%.",
            "author": [
                "JunJie Wee",
                "Jiahui Chen",
                "Kelin Xia",
                "Guo-Wei Wei"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18760v2",
                "http://arxiv.org/pdf/2310.18760v2"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM",
                "math.AT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18743v1",
            "title": "Optimization of utility-based shortfall risk: A non-asymptotic viewpoint",
            "updated": "2023-10-28T15:57:58Z",
            "published": "2023-10-28T15:57:58Z",
            "summary": "We consider the problems of estimation and optimization of utility-based\nshortfall risk (UBSR), which is a popular risk measure in finance. In the\ncontext of UBSR estimation, we derive a non-asymptotic bound on the\nmean-squared error of the classical sample average approximation (SAA) of UBSR.\nNext, in the context of UBSR optimization, we derive an expression for the UBSR\ngradient under a smooth parameterization. This expression is a ratio of\nexpectations, both of which involve the UBSR. We use SAA for the numerator as\nwell as denominator in the UBSR gradient expression to arrive at a biased\ngradient estimator. We derive non-asymptotic bounds on the estimation error,\nwhich show that our gradient estimator is asymptotically unbiased. We\nincorporate the aforementioned gradient estimator into a stochastic gradient\n(SG) algorithm for UBSR optimization. Finally, we derive non-asymptotic bounds\nthat quantify the rate of convergence of our SG algorithm for UBSR\noptimization.",
            "author": [
                "Sumedh Gupte",
                "Prashanth L. A.",
                "Sanjay P. Bhat"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18743v1",
                "http://arxiv.org/pdf/2310.18743v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18741v1",
            "title": "On Training Implicit Meta-Learning With Applications to Inductive\n  Weighing in Consistency Regularization",
            "updated": "2023-10-28T15:50:03Z",
            "published": "2023-10-28T15:50:03Z",
            "summary": "Meta-learning that uses implicit gradient have provided an exciting\nalternative to standard techniques which depend on the trajectory of the inner\nloop training. Implicit meta-learning (IML), however, require computing\n$2^{nd}$ order gradients, particularly the Hessian which is impractical to\ncompute for modern deep learning models. Various approximations for the Hessian\nwere proposed but a systematic comparison of their compute cost, stability,\ngeneralization of solution found and estimation accuracy were largely\noverlooked. In this study, we start by conducting a systematic comparative\nanalysis of the various approximation methods and their effect when\nincorporated into IML training routines. We establish situations where\ncatastrophic forgetting is exhibited in IML and explain their cause in terms of\nthe inability of the approximations to estimate the curvature at convergence\npoints. Sources of IML training instability are demonstrated and remedied. A\ndetailed analysis of the effeciency of various inverse Hessian-vector product\napproximation methods is also provided. Subsequently, we use the insights\ngained to propose and evaluate a novel semi-supervised learning algorithm that\nlearns to inductively weigh consistency regularization losses. We show how\ntraining a \"Confidence Network\" to extract domain specific features can learn\nto up-weigh useful images and down-weigh out-of-distribution samples. Results\noutperform the baseline FixMatch performance.",
            "author": [
                "Fady Rezk"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18741v1",
                "http://arxiv.org/pdf/2310.18741v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18740v1",
            "title": "TraceDiag: Adaptive, Interpretable, and Efficient Root Cause Analysis on\n  Large-Scale Microservice Systems",
            "updated": "2023-10-28T15:49:00Z",
            "published": "2023-10-28T15:49:00Z",
            "summary": "Root Cause Analysis (RCA) is becoming increasingly crucial for ensuring the\nreliability of microservice systems. However, performing RCA on modern\nmicroservice systems can be challenging due to their large scale, as they\nusually comprise hundreds of components, leading significant human effort. This\npaper proposes TraceDiag, an end-to-end RCA framework that addresses the\nchallenges for large-scale microservice systems. It leverages reinforcement\nlearning to learn a pruning policy for the service dependency graph to\nautomatically eliminates redundant components, thereby significantly improving\nthe RCA efficiency. The learned pruning policy is interpretable and fully\nadaptive to new RCA instances. With the pruned graph, a causal-based method can\nbe executed with high accuracy and efficiency. The proposed TraceDiag framework\nis evaluated on real data traces collected from the Microsoft Exchange system,\nand demonstrates superior performance compared to state-of-the-art RCA\napproaches. Notably, TraceDiag has been integrated as a critical component in\nthe Microsoft M365 Exchange, resulting in a significant improvement in the\nsystem's reliability and a considerable reduction in the human effort required\nfor RCA.",
            "author": [
                "Ruomeng Ding",
                "Chaoyun Zhang",
                "Lu Wang",
                "Yong Xu",
                "Minghua Ma",
                "Xiaomin Wu",
                "Meng Zhang",
                "Qingjun Chen",
                "Xin Gao",
                "Xuedong Gao",
                "Hao Fan",
                "Saravan Rajmohan",
                "Qingwei Lin",
                "Dongmei Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18740v1",
                "http://arxiv.org/pdf/2310.18740v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18738v1",
            "title": "TLM: Token-Level Masking for Transformers",
            "updated": "2023-10-28T15:42:47Z",
            "published": "2023-10-28T15:42:47Z",
            "summary": "Structured dropout approaches, such as attention dropout and DropHead, have\nbeen investigated to regularize the multi-head attention mechanism in\nTransformers. In this paper, we propose a new regularization scheme based on\ntoken-level rather than structure-level to reduce overfitting. Specifically, we\ndevise a novel Token-Level Masking (TLM) training strategy for Transformers to\nregularize the connections of self-attention, which consists of two masking\ntechniques that are effective and easy to implement. The underlying idea is to\nmanipulate the connections between tokens in the multi-head attention via\nmasking, where the networks are forced to exploit partial neighbors'\ninformation to produce a meaningful representation. The generality and\neffectiveness of TLM are thoroughly evaluated via extensive experiments on 4\ndiversified NLP tasks across 18 datasets, including natural language\nunderstanding benchmark GLUE, ChineseGLUE, Chinese Grammatical Error\nCorrection, and data-to-text generation. The results indicate that TLM can\nconsistently outperform attention dropout and DropHead, e.g., it increases by\n0.5 points relative to DropHead with BERT-large on GLUE. Moreover, TLM can\nestablish a new record on the data-to-text benchmark Rotowire (18.93 BLEU). Our\ncode will be publicly available at https://github.com/Young1993/tlm.",
            "author": [
                "Yangjun Wu",
                "Kebin Fang",
                "Dongxiang Zhang",
                "Han Wang",
                "Hao Zhang",
                "Gang Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18738v1",
                "http://arxiv.org/pdf/2310.18738v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18737v1",
            "title": "Pre-training with Random Orthogonal Projection Image Modeling",
            "updated": "2023-10-28T15:42:07Z",
            "published": "2023-10-28T15:42:07Z",
            "summary": "Masked Image Modeling (MIM) is a powerful self-supervised strategy for visual\npre-training without the use of labels. MIM applies random crops to input\nimages, processes them with an encoder, and then recovers the masked inputs\nwith a decoder, which encourages the network to capture and learn structural\ninformation about objects and scenes. The intermediate feature representations\nobtained from MIM are suitable for fine-tuning on downstream tasks. In this\npaper, we propose an Image Modeling framework based on random orthogonal\nprojection instead of binary masking as in MIM. Our proposed Random Orthogonal\nProjection Image Modeling (ROPIM) reduces spatially-wise token information\nunder guaranteed bound on the noise variance and can be considered as masking\nentire spatial image area under locally varying masking degrees. Since ROPIM\nuses a random subspace for the projection that realizes the masking step, the\nreadily available complement of the subspace can be used during unmasking to\npromote recovery of removed information. In this paper, we show that using\nrandom orthogonal projection leads to superior performance compared to\ncrop-based masking. We demonstrate state-of-the-art results on several popular\nbenchmarks.",
            "author": [
                "Maryam Haghighat",
                "Peyman Moghadam",
                "Shaheer Mohamed",
                "Piotr Koniusz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18737v1",
                "http://arxiv.org/pdf/2310.18737v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18735v1",
            "title": "Curriculum Learning for Graph Neural Networks: Which Edges Should We\n  Learn First",
            "updated": "2023-10-28T15:35:34Z",
            "published": "2023-10-28T15:35:34Z",
            "summary": "Graph Neural Networks (GNNs) have achieved great success in representing data\nwith dependencies by recursively propagating and aggregating messages along the\nedges. However, edges in real-world graphs often have varying degrees of\ndifficulty, and some edges may even be noisy to the downstream tasks.\nTherefore, existing GNNs may lead to suboptimal learned representations because\nthey usually treat every edge in the graph equally. On the other hand,\nCurriculum Learning (CL), which mimics the human learning principle of learning\ndata samples in a meaningful order, has been shown to be effective in improving\nthe generalization ability and robustness of representation learners by\ngradually proceeding from easy to more difficult samples during training.\nUnfortunately, existing CL strategies are designed for independent data samples\nand cannot trivially generalize to handle data dependencies. To address these\nissues, we propose a novel CL strategy to gradually incorporate more edges into\ntraining according to their difficulty from easy to hard, where the degree of\ndifficulty is measured by how well the edges are expected given the model\ntraining status. We demonstrate the strength of our proposed method in\nimproving the generalization ability and robustness of learned representations\nthrough extensive experiments on nine synthetic datasets and nine real-world\ndatasets. The code for our proposed method is available at\nhttps://github.com/rollingstonezz/Curriculum_learning_for_GNNs.",
            "author": [
                "Zheng Zhang",
                "Junxiang Wang",
                "Liang Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18735v1",
                "http://arxiv.org/pdf/2310.18735v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18728v2",
            "title": "Debunking Free Fusion Myth: Online Multi-view Anomaly Detection with\n  Disentangled Product-of-Experts Modeling",
            "updated": "2023-10-31T22:52:08Z",
            "published": "2023-10-28T15:14:43Z",
            "summary": "Multi-view or even multi-modal data is appealing yet challenging for\nreal-world applications. Detecting anomalies in multi-view data is a prominent\nrecent research topic. However, most of the existing methods 1) are only\nsuitable for two views or type-specific anomalies, 2) suffer from the issue of\nfusion disentanglement, and 3) do not support online detection after model\ndeployment. To address these challenges, our main ideas in this paper are\nthree-fold: multi-view learning, disentangled representation learning, and\ngenerative model. To this end, we propose dPoE, a novel multi-view variational\nautoencoder model that involves (1) a Product-of-Experts (PoE) layer in\ntackling multi-view data, (2) a Total Correction (TC) discriminator in\ndisentangling view-common and view-specific representations, and (3) a joint\nloss function in wrapping up all components. In addition, we devise theoretical\ninformation bounds to control both view-common and view-specific\nrepresentations. Extensive experiments on six real-world datasets markedly\ndemonstrate that the proposed dPoE outperforms baselines.",
            "author": [
                "Hao Wang",
                "Zhi-Qi Cheng",
                "Jingdong Sun",
                "Xin Yang",
                "Xiao Wu",
                "Hongyang Chen",
                "Yan Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18728v2",
                "http://arxiv.org/pdf/2310.18728v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18727v1",
            "title": "Latent class analysis by regularized spectral clustering",
            "updated": "2023-10-28T15:09:08Z",
            "published": "2023-10-28T15:09:08Z",
            "summary": "The latent class model is a powerful tool for identifying latent classes\nwithin populations that share common characteristics for categorical data in\nsocial, psychological, and behavioral sciences. In this article, we propose two\nnew algorithms to estimate a latent class model for categorical data. Our\nalgorithms are developed by using a newly defined regularized Laplacian matrix\ncalculated from the response matrix. We provide theoretical convergence rates\nof our algorithms by considering a sparsity parameter and show that our\nalgorithms stably yield consistent latent class analysis under mild conditions.\nAdditionally, we propose a metric to capture the strength of latent class\nanalysis and several procedures designed based on this metric to infer how many\nlatent classes one should use for real-world categorical data. The efficiency\nand accuracy of our algorithms are verified by extensive simulated experiments,\nand we further apply our algorithms to real-world categorical data with\npromising results.",
            "author": [
                "Huan Qing"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18727v1",
                "http://arxiv.org/pdf/2310.18727v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18725v2",
            "title": "The Evolution of the Interplay Between Input Distributions and Linear\n  Regions in Networks",
            "updated": "2023-11-07T04:44:14Z",
            "published": "2023-10-28T15:04:53Z",
            "summary": "It is commonly recognized that the expressiveness of deep neural networks is\ncontingent upon a range of factors, encompassing their depth, width, and other\nrelevant considerations. Currently, the practical performance of the majority\nof deep neural networks remains uncertain. For ReLU (Rectified Linear Unit)\nnetworks with piecewise linear activations, the number of linear convex regions\nserves as a natural metric to gauge the network's expressivity. In this paper,\nwe count the number of linear convex regions in deep neural networks based on\nReLU. In particular, we prove that for any one-dimensional input, there exists\na minimum threshold for the number of neurons required to express it. We also\nempirically observe that for the same network, intricate inputs hinder its\ncapacity to express linear regions. Furthermore, we unveil the iterative\nrefinement process of decision boundaries in ReLU networks during training. We\naspire for our research to serve as an inspiration for network optimization\nendeavors and aids in the exploration and analysis of the behaviors exhibited\nby deep networks.",
            "author": [
                "Xuan Qi",
                "Yi Wei"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18725v2",
                "http://arxiv.org/pdf/2310.18725v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18724v1",
            "title": "WCLD: Curated Large Dataset of Criminal Cases from Wisconsin Circuit\n  Courts",
            "updated": "2023-10-28T15:04:29Z",
            "published": "2023-10-28T15:04:29Z",
            "summary": "Machine learning based decision-support tools in criminal justice systems are\nsubjects of intense discussions and academic research. There are important open\nquestions about the utility and fairness of such tools. Academic researchers\noften rely on a few small datasets that are not sufficient to empirically study\nvarious real-world aspects of these questions. In this paper, we contribute\nWCLD, a curated large dataset of 1.5 million criminal cases from circuit courts\nin the U.S. state of Wisconsin. We used reliable public data from 1970 to 2020\nto curate attributes like prior criminal counts and recidivism outcomes. The\ndataset contains large number of samples from five racial groups, in addition\nto information like sex and age (at judgment and first offense). Other\nattributes in this dataset include neighborhood characteristics obtained from\ncensus data, detailed types of offense, charge severity, case decisions,\nsentence lengths, year of filing etc. We also provide pseudo-identifiers for\njudge, county and zipcode. The dataset will not only enable researchers to more\nrigorously study algorithmic fairness in the context of criminal justice, but\nalso relate algorithmic challenges with various systemic issues. We also\ndiscuss in detail the process of constructing the dataset and provide a\ndatasheet. The WCLD dataset is available at\n\\url{https://clezdata.github.io/wcld/}.",
            "author": [
                "Elliott Ash",
                "Naman Goel",
                "Nianyun Li",
                "Claudia Marangon",
                "Peiyao Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18724v1",
                "http://arxiv.org/pdf/2310.18724v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18717v1",
            "title": "On the Accuracy of Hotelling-Type Asymmetric Tensor Deflation: A Random\n  Tensor Analysis",
            "updated": "2023-10-28T14:40:10Z",
            "published": "2023-10-28T14:40:10Z",
            "summary": "This work introduces an asymptotic study of Hotelling-type tensor deflation\nin the presence of noise, in the regime of large tensor dimensions.\nSpecifically, we consider a low-rank asymmetric tensor model of the form\n$\\sum_{i=1}^r \\beta_i{\\mathcal{A}}_i + {\\mathcal{W}}$ where $\\beta_i\\geq 0$ and\nthe ${\\mathcal{A}}_i$'s are unit-norm rank-one tensors such that $\\left|\n\\langle {\\mathcal{A}}_i, {\\mathcal{A}}_j \\rangle \\right| \\in [0, 1]$ for $i\\neq\nj$ and ${\\mathcal{W}}$ is an additive noise term. Assuming that the dominant\ncomponents are successively estimated from the noisy observation and\nsubsequently subtracted, we leverage recent advances in random tensor theory in\nthe regime of asymptotically large tensor dimensions to analytically\ncharacterize the estimated singular values and the alignment of estimated and\ntrue singular vectors at each step of the deflation procedure. Furthermore,\nthis result can be used to construct estimators of the signal-to-noise ratios\n$\\beta_i$ and the alignments between the estimated and true rank-1 signal\ncomponents.",
            "author": [
                "Mohamed El Amine Seddik",
                "Maxime Guillaud",
                "Alexis Decurninge",
                "Jos\u00e9 Henrique de Morais Goulart"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18717v1",
                "http://arxiv.org/pdf/2310.18717v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18716v1",
            "title": "Laplacian Canonization: A Minimalist Approach to Sign and Basis\n  Invariant Spectral Embedding",
            "updated": "2023-10-28T14:35:10Z",
            "published": "2023-10-28T14:35:10Z",
            "summary": "Spectral embedding is a powerful graph embedding technique that has received\na lot of attention recently due to its effectiveness on Graph Transformers.\nHowever, from a theoretical perspective, the universal expressive power of\nspectral embedding comes at the price of losing two important invariance\nproperties of graphs, sign and basis invariance, which also limits its\neffectiveness on graph data. To remedy this issue, many previous methods\ndeveloped costly approaches to learn new invariants and suffer from high\ncomputation complexity. In this work, we explore a minimal approach that\nresolves the ambiguity issues by directly finding canonical directions for the\neigenvectors, named Laplacian Canonization (LC). As a pure pre-processing\nmethod, LC is light-weighted and can be applied to any existing GNNs. We\nprovide a thorough investigation, from theory to algorithm, on this approach,\nand discover an efficient algorithm named Maximal Axis Projection (MAP) that\nworks for both sign and basis invariance and successfully canonizes more than\n90% of all eigenvectors. Experiments on real-world benchmark datasets like\nZINC, MOLTOX21, and MOLPCBA show that MAP consistently outperforms existing\nmethods while bringing minimal computation overhead. Code is available at\nhttps://github.com/PKU-ML/LaplacianCanonization.",
            "author": [
                "Jiangyan Ma",
                "Yifei Wang",
                "Yisen Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18716v1",
                "http://arxiv.org/pdf/2310.18716v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18715v1",
            "title": "Robust Offline Policy Evaluation and Optimization with Heavy-Tailed\n  Rewards",
            "updated": "2023-10-28T14:24:26Z",
            "published": "2023-10-28T14:24:26Z",
            "summary": "This paper endeavors to augment the robustness of offline reinforcement\nlearning (RL) in scenarios laden with heavy-tailed rewards, a prevalent\ncircumstance in real-world applications. We propose two algorithmic frameworks,\nROAM and ROOM, for robust off-policy evaluation (OPE) and offline policy\noptimization (OPO), respectively. Central to our frameworks is the strategic\nincorporation of the median-of-means method with offline RL, enabling\nstraightforward uncertainty estimation for the value function estimator. This\nnot only adheres to the principle of pessimism in OPO but also adeptly manages\nheavy-tailed rewards. Theoretical results and extensive experiments demonstrate\nthat our two frameworks outperform existing methods on the logged dataset\nexhibits heavy-tailed reward distributions.",
            "author": [
                "Jin Zhu",
                "Runzhe Wan",
                "Zhengling Qi",
                "Shikai Luo",
                "Chengchun Shi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18715v1",
                "http://arxiv.org/pdf/2310.18715v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18713v1",
            "title": "Episodic Multi-Task Learning with Heterogeneous Neural Processes",
            "updated": "2023-10-28T14:12:40Z",
            "published": "2023-10-28T14:12:40Z",
            "summary": "This paper focuses on the data-insufficiency problem in multi-task learning\nwithin an episodic training setup. Specifically, we explore the potential of\nheterogeneous information across tasks and meta-knowledge among episodes to\neffectively tackle each task with limited data. Existing meta-learning methods\noften fail to take advantage of crucial heterogeneous information in a single\nepisode, while multi-task learning models neglect reusing experience from\nearlier episodes. To address the problem of insufficient data, we develop\nHeterogeneous Neural Processes (HNPs) for the episodic multi-task setup. Within\nthe framework of hierarchical Bayes, HNPs effectively capitalize on prior\nexperiences as meta-knowledge and capture task-relatedness among heterogeneous\ntasks, mitigating data-insufficiency. Meanwhile, transformer-structured\ninference modules are designed to enable efficient inferences toward\nmeta-knowledge and task-relatedness. In this way, HNPs can learn more powerful\nfunctional priors for adapting to novel heterogeneous tasks in each meta-test\nepisode. Experimental results show the superior performance of the proposed\nHNPs over typical baselines, and ablation studies verify the effectiveness of\nthe designed inference modules.",
            "author": [
                "Jiayi Shen",
                "Xiantong Zhen",
                "Qi",
                "Wang",
                "Marcel Worring"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18713v1",
                "http://arxiv.org/pdf/2310.18713v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18709v1",
            "title": "Audio-Visual Instance Segmentation",
            "updated": "2023-10-28T13:37:52Z",
            "published": "2023-10-28T13:37:52Z",
            "summary": "In this paper, we propose a new multi-modal task, namely audio-visual\ninstance segmentation (AVIS), in which the goal is to identify, segment, and\ntrack individual sounding object instances in audible videos, simultaneously.\nTo our knowledge, it is the first time that instance segmentation has been\nextended into the audio-visual domain. To better facilitate this research, we\nconstruct the first audio-visual instance segmentation benchmark (AVISeg).\nSpecifically, AVISeg consists of 1,258 videos with an average duration of 62.6\nseconds from YouTube and public audio-visual datasets, where 117 videos have\nbeen annotated by using an interactive semi-automatic labeling tool based on\nthe Segment Anything Model (SAM). In addition, we present a simple baseline\nmodel for the AVIS task. Our new model introduces an audio branch and a\ncross-modal fusion module to Mask2Former to locate all sounding objects.\nFinally, we evaluate the proposed method using two backbones on AVISeg. We\nbelieve that AVIS will inspire the community towards a more comprehensive\nmulti-modal understanding.",
            "author": [
                "Ruohao Guo",
                "Yaru Chen",
                "Yanyu Qi",
                "Wenzhen Yue",
                "Dantong Niu",
                "Xianghua Ying"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18709v1",
                "http://arxiv.org/pdf/2310.18709v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "cs.MM",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18706v1",
            "title": "ALERTA-Net: A Temporal Distance-Aware Recurrent Networks for Stock\n  Movement and Volatility Prediction",
            "updated": "2023-10-28T13:31:39Z",
            "published": "2023-10-28T13:31:39Z",
            "summary": "For both investors and policymakers, forecasting the stock market is\nessential as it serves as an indicator of economic well-being. To this end, we\nharness the power of social media data, a rich source of public sentiment, to\nenhance the accuracy of stock market predictions. Diverging from conventional\nmethods, we pioneer an approach that integrates sentiment analysis,\nmacroeconomic indicators, search engine data, and historical prices within a\nmulti-attention deep learning model, masterfully decoding the complex patterns\ninherent in the data. We showcase the state-of-the-art performance of our\nproposed model using a dataset, specifically curated by us, for predicting\nstock market movements and volatility.",
            "author": [
                "Shengkun Wang",
                "YangXiao Bai",
                "Kaiqun Fu",
                "Linhan Wang",
                "Chang-Tien Lu",
                "Taoran Ji"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3625007.3627488",
                "http://arxiv.org/abs/2310.18706v1",
                "http://arxiv.org/pdf/2310.18706v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19831v1",
            "title": "Explaining by Imitating: Understanding Decisions by Interpretable Policy\n  Learning",
            "updated": "2023-10-28T13:06:14Z",
            "published": "2023-10-28T13:06:14Z",
            "summary": "Understanding human behavior from observed data is critical for transparency\nand accountability in decision-making. Consider real-world settings such as\nhealthcare, in which modeling a decision-maker's policy is challenging -- with\nno access to underlying states, no knowledge of environment dynamics, and no\nallowance for live experimentation. We desire learning a data-driven\nrepresentation of decision-making behavior that (1) inheres transparency by\ndesign, (2) accommodates partial observability, and (3) operates completely\noffline. To satisfy these key criteria, we propose a novel model-based Bayesian\nmethod for interpretable policy learning (\"Interpole\") that jointly estimates\nan agent's (possibly biased) belief-update process together with their\n(possibly suboptimal) belief-action mapping. Through experiments on both\nsimulated and real-world data for the problem of Alzheimer's disease diagnosis,\nwe illustrate the potential of our approach as an investigative device for\nauditing, quantifying, and understanding human decision-making behavior.",
            "author": [
                "Alihan H\u00fcy\u00fck",
                "Daniel Jarrett",
                "Mihaela van der Schaar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19831v1",
                "http://arxiv.org/pdf/2310.19831v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18703v1",
            "title": "Detangling the role of climate in vegetation productivity with an\n  explainable convolutional neural network",
            "updated": "2023-10-28T13:04:30Z",
            "published": "2023-10-28T13:04:30Z",
            "summary": "Forests of the Earth are a vital carbon sink while providing an essential\nhabitat for biodiversity. Vegetation productivity (VP) is a critical indicator\nof carbon uptake in the atmosphere. The leaf area index is a crucial vegetation\nindex used in VP estimation. This work proposes to predict the leaf area index\n(LAI) using climate variables to better understand future productivity\ndynamics; our approach leverages the capacities of the V-Net architecture for\nspatiotemporal LAI prediction. Preliminary results are well-aligned with\nestablished quality standards of LAI products estimated from Earth observation\ndata. We hope that this work serves as a robust foundation for subsequent\nresearch endeavours, particularly for the incorporation of prediction\nattribution methodologies, which hold promise for elucidating the underlying\nclimate change drivers of global vegetation productivity.",
            "author": [
                "Ricardo Barros Louren\u00e7o",
                "Michael J. Smith",
                "Sylvia Smullin",
                "Umangi Jain",
                "Alemu Gonsamo",
                "Arthur Ouaknine"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18703v1",
                "http://arxiv.org/pdf/2310.18703v1"
            ],
            "primary_category": "physics.ao-ph",
            "category": [
                "physics.ao-ph",
                "physics.geo-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18702v1",
            "title": "Towards Combinatorial Generalization for Catalysts: A Kohn-Sham\n  Charge-Density Approach",
            "updated": "2023-10-28T13:04:05Z",
            "published": "2023-10-28T13:04:05Z",
            "summary": "The Kohn-Sham equations underlie many important applications such as the\ndiscovery of new catalysts. Recent machine learning work on catalyst modeling\nhas focused on prediction of the energy, but has so far not yet demonstrated\nsignificant out-of-distribution generalization. Here we investigate another\napproach based on the pointwise learning of the Kohn-Sham charge-density. On a\nnew dataset of bulk catalysts with charge densities, we show density models can\ngeneralize to new structures with combinations of elements not seen at train\ntime, a form of combinatorial generalization. We show that over 80% of binary\nand ternary test cases achieve faster convergence than standard baselines in\nDensity Functional Theory, amounting to an average reduction of 13% in the\nnumber of iterations required to reach convergence, which may be of independent\ninterest. Our results suggest that density learning is a viable alternative,\ntrading greater inference costs for a step towards combinatorial\ngeneralization, a key property for applications.",
            "author": [
                "Phillip Pope",
                "David Jacobs"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18702v1",
                "http://arxiv.org/pdf/2310.18702v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18701v1",
            "title": "Efficient Algorithms for Generalized Linear Bandits with Heavy-tailed\n  Rewards",
            "updated": "2023-10-28T13:01:10Z",
            "published": "2023-10-28T13:01:10Z",
            "summary": "This paper investigates the problem of generalized linear bandits with\nheavy-tailed rewards, whose $(1+\\epsilon)$-th moment is bounded for some\n$\\epsilon\\in (0,1]$. Although there exist methods for generalized linear\nbandits, most of them focus on bounded or sub-Gaussian rewards and are not\nwell-suited for many real-world scenarios, such as financial markets and\nweb-advertising. To address this issue, we propose two novel algorithms based\non truncation and mean of medians. These algorithms achieve an almost optimal\nregret bound of $\\widetilde{O}(dT^{\\frac{1}{1+\\epsilon}})$, where $d$ is the\ndimension of contextual information and $T$ is the time horizon. Our\ntruncation-based algorithm supports online learning, distinguishing it from\nexisting truncation-based approaches. Additionally, our mean-of-medians-based\nalgorithm requires only $O(\\log T)$ rewards and one estimator per epoch, making\nit more practical. Moreover, our algorithms improve the regret bounds by a\nlogarithmic factor compared to existing algorithms when $\\epsilon=1$. Numerical\nexperimental results confirm the merits of our algorithms.",
            "author": [
                "Bo Xue",
                "Yimu Wang",
                "Yuanyu Wan",
                "Jinfeng Yi",
                "Lijun Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18701v1",
                "http://arxiv.org/pdf/2310.18701v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18700v1",
            "title": "Empowering Collaborative Filtering with Principled Adversarial\n  Contrastive Loss",
            "updated": "2023-10-28T12:57:39Z",
            "published": "2023-10-28T12:57:39Z",
            "summary": "Contrastive Learning (CL) has achieved impressive performance in\nself-supervised learning tasks, showing superior generalization ability.\nInspired by the success, adopting CL into collaborative filtering (CF) is\nprevailing in semi-supervised top-K recommendations. The basic idea is to\nroutinely conduct heuristic-based data augmentation and apply contrastive\nlosses (e.g., InfoNCE) on the augmented views. Yet, some CF-tailored challenges\nmake this adoption suboptimal, such as the issue of out-of-distribution, the\nrisk of false negatives, and the nature of top-K evaluation. They necessitate\nthe CL-based CF scheme to focus more on mining hard negatives and\ndistinguishing false negatives from the vast unlabeled user-item interactions,\nfor informative contrast signals. Worse still, there is limited understanding\nof contrastive loss in CF methods, especially w.r.t. its generalization\nability. To bridge the gap, we delve into the reasons underpinning the success\nof contrastive loss in CF, and propose a principled Adversarial InfoNCE loss\n(AdvInfoNCE), which is a variant of InfoNCE, specially tailored for CF methods.\nAdvInfoNCE adaptively explores and assigns hardness to each negative instance\nin an adversarial fashion and further utilizes a fine-grained hardness-aware\nranking criterion to empower the recommender's generalization ability. Training\nCF models with AdvInfoNCE, we validate the effectiveness of AdvInfoNCE on both\nsynthetic and real-world benchmark datasets, thus showing its generalization\nability to mitigate out-of-distribution problems. Given the theoretical\nguarantees and empirical superiority of AdvInfoNCE over most contrastive loss\nfunctions, we advocate its adoption as a standard loss in recommender systems,\nparticularly for the out-of-distribution tasks. Codes are available at\nhttps://github.com/LehengTHU/AdvInfoNCE.",
            "author": [
                "An Zhang",
                "Leheng Sheng",
                "Zhibo Cai",
                "Xiang Wang",
                "Tat-Seng Chua"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18700v1",
                "http://arxiv.org/pdf/2310.18700v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18698v1",
            "title": "Triplet Attention Transformer for Spatiotemporal Predictive Learning",
            "updated": "2023-10-28T12:49:33Z",
            "published": "2023-10-28T12:49:33Z",
            "summary": "Spatiotemporal predictive learning offers a self-supervised learning paradigm\nthat enables models to learn both spatial and temporal patterns by predicting\nfuture sequences based on historical sequences. Mainstream methods are\ndominated by recurrent units, yet they are limited by their lack of\nparallelization and often underperform in real-world scenarios. To improve\nprediction quality while maintaining computational efficiency, we propose an\ninnovative triplet attention transformer designed to capture both inter-frame\ndynamics and intra-frame static features. Specifically, the model incorporates\nthe Triplet Attention Module (TAM), which replaces traditional recurrent units\nby exploring self-attention mechanisms in temporal, spatial, and channel\ndimensions. In this configuration: (i) temporal tokens contain abstract\nrepresentations of inter-frame, facilitating the capture of inherent temporal\ndependencies; (ii) spatial and channel attention combine to refine the\nintra-frame representation by performing fine-grained interactions across\nspatial and channel dimensions. Alternating temporal, spatial, and\nchannel-level attention allows our approach to learn more complex short- and\nlong-range spatiotemporal dependencies. Extensive experiments demonstrate\nperformance surpassing existing recurrent-based and recurrent-free methods,\nachieving state-of-the-art under multi-scenario examination including moving\nobject trajectory prediction, traffic flow prediction, driving scene\nprediction, and human motion capture.",
            "author": [
                "Xuesong Nie",
                "Xi Chen",
                "Haoyuan Jin",
                "Zhihang Zhu",
                "Yunfeng Yan",
                "Donglian Qi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18698v1",
                "http://arxiv.org/pdf/2310.18698v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18696v1",
            "title": "Probing LLMs for Joint Encoding of Linguistic Categories",
            "updated": "2023-10-28T12:46:40Z",
            "published": "2023-10-28T12:46:40Z",
            "summary": "Large Language Models (LLMs) exhibit impressive performance on a range of NLP\ntasks, due to the general-purpose linguistic knowledge acquired during\npretraining. Existing model interpretability research (Tenney et al., 2019)\nsuggests that a linguistic hierarchy emerges in the LLM layers, with lower\nlayers better suited to solving syntactic tasks and higher layers employed for\nsemantic processing. Yet, little is known about how encodings of different\nlinguistic phenomena interact within the models and to what extent processing\nof linguistically-related categories relies on the same, shared model\nrepresentations. In this paper, we propose a framework for testing the joint\nencoding of linguistic categories in LLMs. Focusing on syntax, we find evidence\nof joint encoding both at the same (related part-of-speech (POS) classes) and\ndifferent (POS classes and related syntactic dependency relations) levels of\nlinguistic hierarchy. Our cross-lingual experiments show that the same patterns\nhold across languages in multilingual LLMs.",
            "author": [
                "Giulio Starace",
                "Konstantinos Papakostas",
                "Rochelle Choenni",
                "Apostolos Panagiotopoulos",
                "Matteo Rosati",
                "Alina Leidinger",
                "Ekaterina Shutova"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18696v1",
                "http://arxiv.org/pdf/2310.18696v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18689v1",
            "title": "Foundational Models in Medical Imaging: A Comprehensive Survey and\n  Future Vision",
            "updated": "2023-10-28T12:08:12Z",
            "published": "2023-10-28T12:08:12Z",
            "summary": "Foundation models, large-scale, pre-trained deep-learning models adapted to a\nwide range of downstream tasks have gained significant interest lately in\nvarious deep-learning problems undergoing a paradigm shift with the rise of\nthese models. Trained on large-scale dataset to bridge the gap between\ndifferent modalities, foundation models facilitate contextual reasoning,\ngeneralization, and prompt capabilities at test time. The predictions of these\nmodels can be adjusted for new tasks by augmenting the model input with\ntask-specific hints called prompts without requiring extensive labeled data and\nretraining. Capitalizing on the advances in computer vision, medical imaging\nhas also marked a growing interest in these models. To assist researchers in\nnavigating this direction, this survey intends to provide a comprehensive\noverview of foundation models in the domain of medical imaging. Specifically,\nwe initiate our exploration by providing an exposition of the fundamental\nconcepts forming the basis of foundation models. Subsequently, we offer a\nmethodical taxonomy of foundation models within the medical domain, proposing a\nclassification system primarily structured around training strategies, while\nalso incorporating additional facets such as application domains, imaging\nmodalities, specific organs of interest, and the algorithms integral to these\nmodels. Furthermore, we emphasize the practical use case of some selected\napproaches and then discuss the opportunities, applications, and future\ndirections of these large-scale pre-trained models, for analyzing medical\nimages. In the same vein, we address the prevailing challenges and research\npathways associated with foundational models in medical imaging. These\nencompass the areas of interpretability, data management, computational\nrequirements, and the nuanced issue of contextual comprehension.",
            "author": [
                "Bobby Azad",
                "Reza Azad",
                "Sania Eskandari",
                "Afshin Bozorgpour",
                "Amirhossein Kazerouni",
                "Islem Rekik",
                "Dorit Merhof"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18689v1",
                "http://arxiv.org/pdf/2310.18689v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18688v1",
            "title": "Clairvoyance: A Pipeline Toolkit for Medical Time Series",
            "updated": "2023-10-28T12:08:03Z",
            "published": "2023-10-28T12:08:03Z",
            "summary": "Time-series learning is the bread and butter of data-driven *clinical\ndecision support*, and the recent explosion in ML research has demonstrated\ngreat potential in various healthcare settings. At the same time, medical\ntime-series problems in the wild are challenging due to their highly\n*composite* nature: They entail design choices and interactions among\ncomponents that preprocess data, impute missing values, select features, issue\npredictions, estimate uncertainty, and interpret models. Despite exponential\ngrowth in electronic patient data, there is a remarkable gap between the\npotential and realized utilization of ML for clinical research and decision\nsupport. In particular, orchestrating a real-world project lifecycle poses\nchallenges in engineering (i.e. hard to build), evaluation (i.e. hard to\nassess), and efficiency (i.e. hard to optimize). Designed to address these\nissues simultaneously, Clairvoyance proposes a unified, end-to-end,\nautoML-friendly pipeline that serves as a (i) software toolkit, (ii) empirical\nstandard, and (iii) interface for optimization. Our ultimate goal lies in\nfacilitating transparent and reproducible experimentation with complex\ninference workflows, providing integrated pathways for (1) personalized\nprediction, (2) treatment-effect estimation, and (3) information acquisition.\nThrough illustrative examples on real-world data in outpatient, general wards,\nand intensive-care settings, we illustrate the applicability of the pipeline\nparadigm on core tasks in the healthcare journey. To the best of our knowledge,\nClairvoyance is the first to demonstrate viability of a comprehensive and\nautomatable pipeline for clinical time-series ML.",
            "author": [
                "Daniel Jarrett",
                "Jinsung Yoon",
                "Ioana Bica",
                "Zhaozhi Qian",
                "Ari Ercole",
                "Mihaela van der Schaar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18688v1",
                "http://arxiv.org/pdf/2310.18688v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18687v1",
            "title": "Unsupervised Behavior Extraction via Random Intent Priors",
            "updated": "2023-10-28T12:03:34Z",
            "published": "2023-10-28T12:03:34Z",
            "summary": "Reward-free data is abundant and contains rich prior knowledge of human\nbehaviors, but it is not well exploited by offline reinforcement learning (RL)\nalgorithms. In this paper, we propose UBER, an unsupervised approach to extract\nuseful behaviors from offline reward-free datasets via diversified rewards.\nUBER assigns different pseudo-rewards sampled from a given prior distribution\nto different agents to extract a diverse set of behaviors, and reuse them as\ncandidate policies to facilitate the learning of new tasks. Perhaps\nsurprisingly, we show that rewards generated from random neural networks are\nsufficient to extract diverse and useful behaviors, some even close to expert\nones. We provide both empirical and theoretical evidence to justify the use of\nrandom priors for the reward function. Experiments on multiple benchmarks\nshowcase UBER's ability to learn effective and diverse behavior sets that\nenhance sample efficiency for online RL, outperforming existing baselines. By\nreducing reliance on human supervision, UBER broadens the applicability of RL\nto real-world scenarios with abundant reward-free data.",
            "author": [
                "Hao Hu",
                "Yiqin Yang",
                "Jianing Ye",
                "Ziqing Mai",
                "Chongjie Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18687v1",
                "http://arxiv.org/pdf/2310.18687v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18681v1",
            "title": "DySurv: Dynamic Deep Learning Model for Survival Prediction in the ICU",
            "updated": "2023-10-28T11:29:09Z",
            "published": "2023-10-28T11:29:09Z",
            "summary": "Survival analysis helps approximate underlying distributions of\ntime-to-events which in the case of critical care like in the ICU can be a\npowerful tool for dynamic mortality risk prediction. Extending beyond the\nclassical Cox model, deep learning techniques have been leveraged over the last\nyears relaxing the many constraints of their counterparts from statistical\nmethods. In this work, we propose a novel conditional variational\nautoencoder-based method called DySurv which uses a combination of static and\ntime-series measurements from patient electronic health records in estimating\nrisk of death dynamically in the ICU. DySurv has been tested on standard\nbenchmarks where it outperforms most existing methods including other deep\nlearning methods and we evaluate it on a real-world patient database from\nMIMIC-IV. The predictive capacity of DySurv is consistent and the survival\nestimates remain disentangled across different datasets supporting the idea\nthat dynamic deep learning models based on conditional variational inference in\nmulti-task cases can be robust models for survival analysis.",
            "author": [
                "Munib Mesinovic",
                "Peter Watkinson",
                "Tingting Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18681v1",
                "http://arxiv.org/pdf/2310.18681v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18679v2",
            "title": "N-Critics: Self-Refinement of Large Language Models with Ensemble of\n  Critics",
            "updated": "2023-11-08T13:23:20Z",
            "published": "2023-10-28T11:22:22Z",
            "summary": "We propose a self-correction mechanism for Large Language Models (LLMs) to\nmitigate issues such as toxicity and fact hallucination. This method involves\nrefining model outputs through an ensemble of critics and the model's own\nfeedback. Drawing inspiration from human behavior, we explore whether LLMs can\nemulate the self-correction process observed in humans who often engage in\nself-reflection and seek input from others to refine their understanding of\ncomplex topics. Our approach is model-agnostic and can be applied across\nvarious domains to enhance trustworthiness by addressing fairness, bias, and\nrobustness concerns. We consistently observe performance improvements in LLMs\nfor reducing toxicity and correcting factual errors.",
            "author": [
                "Sajad Mousavi",
                "Ricardo Luna Guti\u00e9rrez",
                "Desik Rengarajan",
                "Vineet Gundecha",
                "Ashwin Ramesh Babu",
                "Avisek Naug",
                "Antonio Guillen",
                "Soumyendu Sarkar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18679v2",
                "http://arxiv.org/pdf/2310.18679v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18677v1",
            "title": "Energy-Based Models for Anomaly Detection: A Manifold Diffusion Recovery\n  Approach",
            "updated": "2023-10-28T11:18:39Z",
            "published": "2023-10-28T11:18:39Z",
            "summary": "We present a new method of training energy-based models (EBMs) for anomaly\ndetection that leverages low-dimensional structures within data. The proposed\nalgorithm, Manifold Projection-Diffusion Recovery (MPDR), first perturbs a data\npoint along a low-dimensional manifold that approximates the training dataset.\nThen, EBM is trained to maximize the probability of recovering the original\ndata. The training involves the generation of negative samples via MCMC, as in\nconventional EBM training, but from a different distribution concentrated near\nthe manifold. The resulting near-manifold negative samples are highly\ninformative, reflecting relevant modes of variation in data. An energy function\nof MPDR effectively learns accurate boundaries of the training data\ndistribution and excels at detecting out-of-distribution samples. Experimental\nresults show that MPDR exhibits strong performance across various anomaly\ndetection tasks involving diverse data types, such as images, vectors, and\nacoustic signals.",
            "author": [
                "Sangwoong Yoon",
                "Young-Uk Jin",
                "Yung-Kyun Noh",
                "Frank C. Park"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18677v1",
                "http://arxiv.org/pdf/2310.18677v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18672v1",
            "title": "Maximum Independent Set: Self-Training through Dynamic Programming",
            "updated": "2023-10-28T10:58:25Z",
            "published": "2023-10-28T10:58:25Z",
            "summary": "This work presents a graph neural network (GNN) framework for solving the\nmaximum independent set (MIS) problem, inspired by dynamic programming (DP).\nSpecifically, given a graph, we propose a DP-like recursive algorithm based on\nGNNs that firstly constructs two smaller sub-graphs, predicts the one with the\nlarger MIS, and then uses it in the next recursive call. To train our\nalgorithm, we require annotated comparisons of different graphs concerning\ntheir MIS size. Annotating the comparisons with the output of our algorithm\nleads to a self-training process that results in more accurate self-annotation\nof the comparisons and vice versa. We provide numerical evidence showing the\nsuperiority of our method vs prior methods in multiple synthetic and real-world\ndatasets.",
            "author": [
                "Lorenzo Brusca",
                "Lars C. P. M. Quaedvlieg",
                "Stratis Skoulakis",
                "Grigorios G Chrysos",
                "Volkan Cevher"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18672v1",
                "http://arxiv.org/pdf/2310.18672v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18660v2",
            "title": "Foundation Models for Generalist Geospatial Artificial Intelligence",
            "updated": "2023-11-08T18:25:24Z",
            "published": "2023-10-28T10:19:55Z",
            "summary": "Significant progress in the development of highly adaptable and reusable\nArtificial Intelligence (AI) models is expected to have a significant impact on\nEarth science and remote sensing. Foundation models are pre-trained on large\nunlabeled datasets through self-supervision, and then fine-tuned for various\ndownstream tasks with small labeled datasets. This paper introduces a\nfirst-of-a-kind framework for the efficient pre-training and fine-tuning of\nfoundational models on extensive geospatial data. We have utilized this\nframework to create Prithvi, a transformer-based geospatial foundational model\npre-trained on more than 1TB of multispectral satellite imagery from the\nHarmonized Landsat-Sentinel 2 (HLS) dataset. Our study demonstrates the\nefficacy of our framework in successfully fine-tuning Prithvi to a range of\nEarth observation tasks that have not been tackled by previous work on\nfoundation models involving multi-temporal cloud gap imputation, flood mapping,\nwildfire scar segmentation, and multi-temporal crop segmentation. Our\nexperiments show that the pre-trained model accelerates the fine-tuning process\ncompared to leveraging randomly initialized weights. In addition, pre-trained\nPrithvi compares well against the state-of-the-art, e.g., outperforming a\nconditional GAN model in multi-temporal cloud imputation by up to 5pp (or 5.7%)\nin the structural similarity index. Finally, due to the limited availability of\nlabeled data in the field of Earth observation, we gradually reduce the\nquantity of available labeled data for refining the model to evaluate data\nefficiency and demonstrate that data can be decreased significantly without\naffecting the model's accuracy. The pre-trained 100 million parameter model and\ncorresponding fine-tuning workflows have been released publicly as open source\ncontributions to the global Earth sciences community through Hugging Face.",
            "author": [
                "Johannes Jakubik",
                "Sujit Roy",
                "C. E. Phillips",
                "Paolo Fraccaro",
                "Denys Godwin",
                "Bianca Zadrozny",
                "Daniela Szwarcman",
                "Carlos Gomes",
                "Gabby Nyirjesy",
                "Blair Edwards",
                "Daiki Kimura",
                "Naomi Simumba",
                "Linsong Chu",
                "S. Karthik Mukkavilli",
                "Devyani Lambhate",
                "Kamal Das",
                "Ranjini Bangalore",
                "Dario Oliveira",
                "Michal Muszynski",
                "Kumar Ankur",
                "Muthukumaran Ramasubramanian",
                "Iksha Gurung",
                "Sam Khallaghi",
                "Hanxi",
                "Li",
                "Michael Cecil",
                "Maryam Ahmadi",
                "Fatemeh Kordi",
                "Hamed Alemohammad",
                "Manil Maskey",
                "Raghu Ganti",
                "Kommy Weldemariam",
                "Rahul Ramachandran"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18660v2",
                "http://arxiv.org/pdf/2310.18660v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18655v1",
            "title": "Systematic Improvement of Empirical Energy Functions in the Era of\n  Machine Learning",
            "updated": "2023-10-28T09:50:49Z",
            "published": "2023-10-28T09:50:49Z",
            "summary": "The impact of targeted replacement of individual terms in empirical force\nfields is quantitatively assessed for pure water, dichloromethane (DCM), and\nsolvated K$^+$ and Cl$^-$ ions. For the electrostatics, point charges (PCs) and\nmachine learning (ML)based minimally distributed charges (MDCM) fitted to the\nmolecular electrostatic potential are evaluated together with electrostatics\nbased on the Coulomb integral. The impact of explicitly including second-order\nterms is investigated by adding a fragment molecular orbital (FMO)-derived\npolarization energy to an existing force field, in this case CHARMM. It is\ndemonstrated that anisotropic electrostatics reduce the RMSE for water (by 1.6\nkcal/mol), DCM (by 0.8 kcal/mol) and for solvated Cl$^-$ clusters (by 0.4\nkcal/mol). An additional polarization term can be neglected for DCM but notably\nimproves errors in pure water (by 1.1 kcal/mol) and in Cl$^-$ clusters (by 0.4\nkcal/mol) and is key to describing solvated K$^+$, reducing the RMSE by 2.3\nkcal/mol. A 12-6 Lennard-Jones functional form is found to perform\nsatisfactorily with PC and MDCM electrostatics, but is not appropriate for\ndescriptions that account for the electrostatic penetration energy. The\nimportance of many-body contributions is assessed by comparing a strictly\n2-body approach with self-consistent reference data. DCM can be approximated\nwell with a 2-body potential while water and solvated K$^+$ and Cl$^-$ ions\nrequire explicit many-body corrections. The present work systematically\nquantifies which terms improve the performance of an existing force field and\nwhat reference data to use for parametrizing these terms in a tractable fashion\nfor ML fitting of pure and heterogeneous systems.",
            "author": [
                "Mike Devereux",
                "Eric D. Boittier",
                "Markus Meuwly"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18655v1",
                "http://arxiv.org/pdf/2310.18655v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "physics.atm-clus"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18654v1",
            "title": "Causal discovery in a complex industrial system: A time series benchmark",
            "updated": "2023-10-28T09:47:02Z",
            "published": "2023-10-28T09:47:02Z",
            "summary": "Causal discovery outputs a causal structure, represented by a graph, from\nobserved data. For time series data, there is a variety of methods, however, it\nis difficult to evaluate these on real data as realistic use cases very rarely\ncome with a known causal graph to which output can be compared. In this paper,\nwe present a dataset from an industrial subsystem at the European Spallation\nSource along with its causal graph which has been constructed from expert\nknowledge. This provides a testbed for causal discovery from time series\nobservations of complex systems, and we believe this can help inform the\ndevelopment of causal discovery methodology.",
            "author": [
                "S\u00f8ren Wengel Mogensen",
                "Karin Rathsman",
                "Per Nilsson"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18654v1",
                "http://arxiv.org/pdf/2310.18654v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18653v1",
            "title": "Feature Guided Masked Autoencoder for Self-supervised Learning in Remote\n  Sensing",
            "updated": "2023-10-28T09:43:13Z",
            "published": "2023-10-28T09:43:13Z",
            "summary": "Self-supervised learning guided by masked image modelling, such as Masked\nAutoEncoder (MAE), has attracted wide attention for pretraining vision\ntransformers in remote sensing. However, MAE tends to excessively focus on\npixel details, thereby limiting the model's capacity for semantic\nunderstanding, in particular for noisy SAR images. In this paper, we explore\nspectral and spatial remote sensing image features as improved\nMAE-reconstruction targets. We first conduct a study on reconstructing various\nimage features, all performing comparably well or better than raw pixels. Based\non such observations, we propose Feature Guided Masked Autoencoder (FG-MAE):\nreconstructing a combination of Histograms of Oriented Graidents (HOG) and\nNormalized Difference Indices (NDI) for multispectral images, and\nreconstructing HOG for SAR images. Experimental results on three downstream\ntasks illustrate the effectiveness of FG-MAE with a particular boost for SAR\nimagery. Furthermore, we demonstrate the well-inherited scalability of FG-MAE\nand release a first series of pretrained vision transformers for medium\nresolution SAR and multispectral images.",
            "author": [
                "Yi Wang",
                "Hugo Hern\u00e1ndez Hern\u00e1ndez",
                "Conrad M Albrecht",
                "Xiao Xiang Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18653v1",
                "http://arxiv.org/pdf/2310.18653v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18651v3",
            "title": "LG-Self: Local-Global Self-Supervised Visual Representation Learning",
            "updated": "2023-11-07T07:02:59Z",
            "published": "2023-10-28T09:35:30Z",
            "summary": "Self-supervised representation learning methods mainly focus on image-level\ninstance discrimination. This study explores the potential benefits of\nincorporating patch-level discrimination into existing methods to enhance the\nquality of learned representations by simultaneously looking at local and\nglobal visual features. Towards this idea, we present a straightforward yet\neffective patch-matching algorithm that can find the corresponding patches\nacross the augmented views of an image. The augmented views are subsequently\nfed into a self-supervised learning framework employing Vision Transformer\n(ViT) as its backbone. The result is the generation of both image-level and\npatch-level representations. Leveraging the proposed patch-matching algorithm,\nthe model minimizes the representation distance between not only the CLS tokens\nbut also the corresponding patches. As a result, the model gains a more\ncomprehensive understanding of both the entirety of the image as well as its\nfiner details. We pretrain the proposed method on small, medium, and\nlarge-scale datasets. It is shown that our approach could outperform\nstate-of-the-art image-level representation learning methods on both image\nclassification and downstream tasks. Keywords: Self-Supervised Learning; Visual\nRepresentations; Local-Global Representation Learning; Patch-Wise\nRepresentation Learning; Vision Transformer (ViT)",
            "author": [
                "Ali Javidani",
                "Mohammad Amin Sadeghi",
                "Babak Nadjar Araabi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18651v3",
                "http://arxiv.org/pdf/2310.18651v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18647v1",
            "title": "Sleep Deprivation in the Forward-Forward Algorithm",
            "updated": "2023-10-28T09:09:44Z",
            "published": "2023-10-28T09:09:44Z",
            "summary": "This paper aims to explore the separation of the two forward passes in the\nForward-Forward algorithm from a biological perspective in the context of\nsleep. We show the size of the gap between the sleep and awake phase influences\nthe learning capabilities of the algorithm and highlight the importance of\nnegative data in diminishing the devastating effects of sleep deprivation.",
            "author": [
                "Mircea-Tudor Lic\u0103",
                "David Dinucu-Jianu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18647v1",
                "http://arxiv.org/pdf/2310.18647v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18646v1",
            "title": "Predicting Agricultural Commodities Prices with Machine Learning: A\n  Review of Current Research",
            "updated": "2023-10-28T09:09:29Z",
            "published": "2023-10-28T09:09:29Z",
            "summary": "Agricultural price prediction is crucial for farmers, policymakers, and other\nstakeholders in the agricultural sector. However, it is a challenging task due\nto the complex and dynamic nature of agricultural markets. Machine learning\nalgorithms have the potential to revolutionize agricultural price prediction by\nimproving accuracy, real-time prediction, customization, and integration. This\npaper reviews recent research on machine learning algorithms for agricultural\nprice prediction. We discuss the importance of agriculture in developing\ncountries and the problems associated with crop price falls. We then identify\nthe challenges of predicting agricultural prices and highlight how machine\nlearning algorithms can support better prediction. Next, we present a\ncomprehensive analysis of recent research, discussing the strengths and\nweaknesses of various machine learning techniques. We conclude that machine\nlearning has the potential to revolutionize agricultural price prediction, but\nfurther research is essential to address the limitations and challenges\nassociated with this approach.",
            "author": [
                "Nhat-Quang Tran",
                "Anna Felipe",
                "Thanh Nguyen Ngoc",
                "Tom Huynh",
                "Quang Tran",
                "Arthur Tang",
                "Thuy Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18646v1",
                "http://arxiv.org/pdf/2310.18646v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18640v1",
            "title": "Switching Temporary Teachers for Semi-Supervised Semantic Segmentation",
            "updated": "2023-10-28T08:49:16Z",
            "published": "2023-10-28T08:49:16Z",
            "summary": "The teacher-student framework, prevalent in semi-supervised semantic\nsegmentation, mainly employs the exponential moving average (EMA) to update a\nsingle teacher's weights based on the student's. However, EMA updates raise a\nproblem in that the weights of the teacher and student are getting coupled,\ncausing a potential performance bottleneck. Furthermore, this problem may\nbecome more severe when training with more complicated labels such as\nsegmentation masks but with few annotated data. This paper introduces Dual\nTeacher, a simple yet effective approach that employs dual temporary teachers\naiming to alleviate the coupling problem for the student. The temporary\nteachers work in shifts and are progressively improved, so consistently prevent\nthe teacher and student from becoming excessively close. Specifically, the\ntemporary teachers periodically take turns generating pseudo-labels to train a\nstudent model and maintain the distinct characteristics of the student model\nfor each epoch. Consequently, Dual Teacher achieves competitive performance on\nthe PASCAL VOC, Cityscapes, and ADE20K benchmarks with remarkably shorter\ntraining times than state-of-the-art methods. Moreover, we demonstrate that our\napproach is model-agnostic and compatible with both CNN- and Transformer-based\nmodels. Code is available at \\url{https://github.com/naver-ai/dual-teacher}.",
            "author": [
                "Jaemin Na",
                "Jung-Woo Ha",
                "Hyung Jin Chang",
                "Dongyoon Han",
                "Wonjun Hwang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18640v1",
                "http://arxiv.org/pdf/2310.18640v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18639v2",
            "title": "Towards Plastic and Stable Exemplar-Free Incremental Learning: A\n  Dual-Learner Framework with Cumulative Parameter Averaging",
            "updated": "2023-11-21T03:23:39Z",
            "published": "2023-10-28T08:48:44Z",
            "summary": "The dilemma between plasticity and stability presents a significant challenge\nin Incremental Learning (IL), especially in the exemplar-free scenario where\naccessing old-task samples is strictly prohibited during the learning of a new\ntask. A straightforward solution to this issue is learning and storing an\nindependent model for each task, known as Single Task Learning (STL). Despite\nthe linear growth in model storage with the number of tasks in STL, we\nempirically discover that averaging these model parameters can potentially\npreserve knowledge across all tasks. Inspired by this observation, we propose a\nDual-Learner framework with Cumulative Parameter Averaging (DLCPA). DLCPA\nemploys a dual-learner design: a plastic learner focused on acquiring new-task\nknowledge and a stable learner responsible for accumulating all learned\nknowledge. The knowledge from the plastic learner is transferred to the stable\nlearner via cumulative parameter averaging. Additionally, several task-specific\nclassifiers work in cooperation with the stable learner to yield the final\nprediction. Specifically, when learning a new task, these modules are updated\nin a cyclic manner: i) the plastic learner is initially optimized using a\nself-supervised loss besides the supervised loss to enhance the feature\nextraction robustness; ii) the stable learner is then updated with respect to\nthe plastic learner in a cumulative parameter averaging manner to maintain its\ntask-wise generalization; iii) the task-specific classifier is accordingly\noptimized to align with the stable learner. Experimental results on CIFAR-100\nand Tiny-ImageNet show that DLCPA outperforms several state-of-the-art\nexemplar-free baselines in both Task-IL and Class-IL settings.",
            "author": [
                "Wenju Sun",
                "Qingyong Li",
                "Wen Wang",
                "Yangli-ao Geng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18639v2",
                "http://arxiv.org/pdf/2310.18639v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18636v1",
            "title": "Electrical Impedance Tomography: A Fair Comparative Study on Deep\n  Learning and Analytic-based Approaches",
            "updated": "2023-10-28T08:45:51Z",
            "published": "2023-10-28T08:45:51Z",
            "summary": "Electrical Impedance Tomography (EIT) is a powerful imaging technique with\ndiverse applications, e.g., medical diagnosis, industrial monitoring, and\nenvironmental studies. The EIT inverse problem is about inferring the internal\nconductivity distribution of an object from measurements taken on its boundary.\nIt is severely ill-posed, necessitating advanced computational methods for\naccurate image reconstructions. Recent years have witnessed significant\nprogress, driven by innovations in analytic-based approaches and deep learning.\nThis review explores techniques for solving the EIT inverse problem, focusing\non the interplay between contemporary deep learning-based strategies and\nclassical analytic-based methods. Four state-of-the-art deep learning\nalgorithms are rigorously examined, harnessing the representational\ncapabilities of deep neural networks to reconstruct intricate conductivity\ndistributions. In parallel, two analytic-based methods, rooted in mathematical\nformulations and regularisation techniques, are dissected for their strengths\nand limitations. These methodologies are evaluated through various numerical\nexperiments, encompassing diverse scenarios that reflect real-world\ncomplexities. A suite of performance metrics is employed to assess the efficacy\nof these methods. These metrics collectively provide a nuanced understanding of\nthe methods' ability to capture essential features and delineate complex\nconductivity patterns. One novel feature of the study is the incorporation of\nvariable conductivity scenarios, introducing a level of heterogeneity that\nmimics textured inclusions. This departure from uniform conductivity\nassumptions mimics realistic scenarios where tissues or materials exhibit\nspatially varying electrical properties. Exploring how each method responds to\nsuch variable conductivity scenarios opens avenues for understanding their\nrobustness and adaptability.",
            "author": [
                "Derick Nganyu Tanyu",
                "Jianfeng Ning",
                "Andreas Hauptmann",
                "Bangti Jin",
                "Peter Maass"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18636v1",
                "http://arxiv.org/pdf/2310.18636v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CE",
                "cs.CV",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18634v1",
            "title": "SSL Framework for Causal Inconsistency between Structures and\n  Representations",
            "updated": "2023-10-28T08:29:49Z",
            "published": "2023-10-28T08:29:49Z",
            "summary": "The cross-pollination of deep learning and causal discovery has catalyzed a\nburgeoning field of research seeking to elucidate causal relationships within\nnon-statistical data forms like images, videos, and text. Such data, often\nbeing named `indefinite data', exhibit unique challenges-inconsistency between\ncausal structure and representation, which are not common in conventional data\nforms. To tackle this issue, we theoretically develop intervention strategies\nsuitable for indefinite data and derive causal consistency condition (CCC).\nMoreover, we design a self-supervised learning (SSL) framework that considers\ninterventions as `views' and CCC as a `philosophy' with two implement examples\non Supervised Specialized Models (SSMs) and Large Language Models (LLMs),\nrespectively. To evaluate pure inconsistency manifestations, we have prepared\nthe first high-quality causal dialogue dataset-Causalogue. Evaluations are also\nperformed on three other downstream tasks. Extensive experimentation has\nsubstantiated the efficacy of our methodology, illuminating how CCC could\npotentially play an influential role in various fields.",
            "author": [
                "Hang Chen",
                "Xinyu Yang",
                "Keqing Du"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18634v1",
                "http://arxiv.org/pdf/2310.18634v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18633v1",
            "title": "Setting the Trap: Capturing and Defeating Backdoors in Pretrained\n  Language Models through Honeypots",
            "updated": "2023-10-28T08:21:16Z",
            "published": "2023-10-28T08:21:16Z",
            "summary": "In the field of natural language processing, the prevalent approach involves\nfine-tuning pretrained language models (PLMs) using local samples. Recent\nresearch has exposed the susceptibility of PLMs to backdoor attacks, wherein\nthe adversaries can embed malicious prediction behaviors by manipulating a few\ntraining samples. In this study, our objective is to develop a\nbackdoor-resistant tuning procedure that yields a backdoor-free model, no\nmatter whether the fine-tuning dataset contains poisoned samples. To this end,\nwe propose and integrate a honeypot module into the original PLM, specifically\ndesigned to absorb backdoor information exclusively. Our design is motivated by\nthe observation that lower-layer representations in PLMs carry sufficient\nbackdoor features while carrying minimal information about the original tasks.\nConsequently, we can impose penalties on the information acquired by the\nhoneypot module to inhibit backdoor creation during the fine-tuning process of\nthe stem network. Comprehensive experiments conducted on benchmark datasets\nsubstantiate the effectiveness and robustness of our defensive strategy.\nNotably, these results indicate a substantial reduction in the attack success\nrate ranging from 10\\% to 40\\% when compared to prior state-of-the-art methods.",
            "author": [
                "Ruixiang Tang",
                "Jiayi Yuan",
                "Yiming Li",
                "Zirui Liu",
                "Rui Chen",
                "Xia Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18633v1",
                "http://arxiv.org/pdf/2310.18633v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18629v1",
            "title": "Explainable Modeling for Wind Power Forecasting: A Glass-Box Approach\n  with Exceptional Accuracy",
            "updated": "2023-10-28T07:56:42Z",
            "published": "2023-10-28T07:56:42Z",
            "summary": "Machine learning models (e.g., neural networks) achieve high accuracy in wind\npower forecasting, but they are usually regarded as black boxes that lack\ninterpretability. To address this issue, the paper proposes a glass-box\napproach that combines exceptional accuracy with transparency for wind power\nforecasting. Specifically, advanced artificial intelligence methods (e.g.,\ngradient boosting) are innovatively employed to create shape functions within\nthe forecasting model. These functions effectively map the intricate non-linear\nrelationships between wind power output and input features. Furthermore, the\nforecasting model is enriched by incorporating interaction terms that adeptly\ncapture interdependencies and synergies among the input features. Simulation\nresults show that the proposed glass-box approach effectively interprets the\nresults of wind power forecasting from both global and instance perspectives.\nBesides, it outperforms most benchmark models and exhibits comparable\nperformance to the best-performing neural networks. This dual strength of\ntransparency and high accuracy positions the proposed glass-box approach as a\ncompelling choice for reliable wind power forecasting.",
            "author": [
                "Wenlong Liao",
                "Fernando Port\u00e9-Agel",
                "Jiannong Fang",
                "Birgitte Bak-Jensen",
                "Guangchun Ruan",
                "Zhe Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18629v1",
                "http://arxiv.org/pdf/2310.18629v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18628v1",
            "title": "Personalised Distillation: Empowering Open-Sourced LLMs with Adaptive\n  Learning for Code Generation",
            "updated": "2023-10-28T07:54:39Z",
            "published": "2023-10-28T07:54:39Z",
            "summary": "With the rise of powerful closed-sourced LLMs (ChatGPT, GPT-4), there are\nincreasing interests in distilling the capabilies of close-sourced LLMs to\nsmaller open-sourced LLMs. Previous distillation methods usually prompt ChatGPT\nto generate a set of instructions and answers, for the student model to learn.\nHowever, such standard distillation approach neglects the merits and conditions\nof the student model. Inspired by modern teaching principles, we design a\npersonalised distillation process, in which the student attempts to solve a\ntask first, then the teacher provides an adaptive refinement for the student to\nimprove. Instead of feeding the student with teacher's prior, personalised\ndistillation enables personalised learning for the student model, as it only\nlearns on examples it makes mistakes upon and learns to improve its own\nsolution. On code generation, personalised distillation consistently\noutperforms standard distillation with only one third of the data. With only\n2.5-3K personalised examples that incur a data-collection cost of 4-6$, we\nboost CodeGen-mono-16B by 7% to achieve 36.4% pass@1 and StarCoder by 12.2% to\nachieve 45.8% pass@1 on HumanEval.",
            "author": [
                "Hailin Chen",
                "Amrita Saha",
                "Steven Hoi",
                "Shafiq Joty"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18628v1",
                "http://arxiv.org/pdf/2310.18628v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18626v2",
            "title": "Benchmark Generation Framework with Customizable Distortions for Image\n  Classifier Robustness",
            "updated": "2023-11-08T13:44:53Z",
            "published": "2023-10-28T07:40:42Z",
            "summary": "We present a novel framework for generating adversarial benchmarks to\nevaluate the robustness of image classification models. Our framework allows\nusers to customize the types of distortions to be optimally applied to images,\nwhich helps address the specific distortions relevant to their deployment. The\nbenchmark can generate datasets at various distortion levels to assess the\nrobustness of different image classifiers. Our results show that the\nadversarial samples generated by our framework with any of the image\nclassification models, like ResNet-50, Inception-V3, and VGG-16, are effective\nand transferable to other models causing them to fail. These failures happen\neven when these models are adversarially retrained using state-of-the-art\ntechniques, demonstrating the generalizability of our adversarial samples. We\nachieve competitive performance in terms of net $L_2$ distortion compared to\nstate-of-the-art benchmark techniques on CIFAR-10 and ImageNet; however, we\ndemonstrate our framework achieves such results with simple distortions like\nGaussian noise without introducing unnatural artifacts or color bleeds. This is\nmade possible by a model-based reinforcement learning (RL) agent and a\ntechnique that reduces a deep tree search of the image for model sensitivity to\nperturbations, to a one-level analysis and action. The flexibility of choosing\ndistortions and setting classification probability thresholds for multiple\nclasses makes our framework suitable for algorithmic audits.",
            "author": [
                "Soumyendu Sarkar",
                "Ashwin Ramesh Babu",
                "Sajad Mousavi",
                "Zachariah Carmichael",
                "Vineet Gundecha",
                "Sahand Ghorbanpour",
                "Ricardo Luna",
                "Gutierrez Antonio Guillen",
                "Avisek Naug"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18626v2",
                "http://arxiv.org/pdf/2310.18626v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18622v1",
            "title": "Arbitrarily Scalable Environment Generators via Neural Cellular Automata",
            "updated": "2023-10-28T07:30:09Z",
            "published": "2023-10-28T07:30:09Z",
            "summary": "We study the problem of generating arbitrarily large environments to improve\nthe throughput of multi-robot systems. Prior work proposes Quality Diversity\n(QD) algorithms as an effective method for optimizing the environments of\nautomated warehouses. However, these approaches optimize only relatively small\nenvironments, falling short when it comes to replicating real-world warehouse\nsizes. The challenge arises from the exponential increase in the search space\nas the environment size increases. Additionally, the previous methods have only\nbeen tested with up to 350 robots in simulations, while practical warehouses\ncould host thousands of robots. In this paper, instead of optimizing\nenvironments, we propose to optimize Neural Cellular Automata (NCA) environment\ngenerators via QD algorithms. We train a collection of NCA generators with QD\nalgorithms in small environments and then generate arbitrarily large\nenvironments from the generators at test time. We show that NCA environment\ngenerators maintain consistent, regularized patterns regardless of environment\nsize, significantly enhancing the scalability of multi-robot systems in two\ndifferent domains with up to 2,350 robots. Additionally, we demonstrate that\nour method scales a single-agent reinforcement learning policy to arbitrarily\nlarge environments with similar patterns. We include the source code at\n\\url{https://github.com/lunjohnzhang/warehouse_env_gen_nca_public}.",
            "author": [
                "Yulun Zhang",
                "Matthew C. Fontaine",
                "Varun Bhatt",
                "Stefanos Nikolaidis",
                "Jiaoyang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18622v1",
                "http://arxiv.org/pdf/2310.18622v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.MA",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18620v2",
            "title": "ODM3D: Alleviating Foreground Sparsity for Semi-Supervised Monocular 3D\n  Object Detection",
            "updated": "2023-11-07T02:55:02Z",
            "published": "2023-10-28T07:12:09Z",
            "summary": "Monocular 3D object detection (M3OD) is a significant yet inherently\nchallenging task in autonomous driving due to absence of explicit depth cues in\na single RGB image. In this paper, we strive to boost currently underperforming\nmonocular 3D object detectors by leveraging an abundance of unlabelled data via\nsemi-supervised learning. Our proposed ODM3D framework entails cross-modal\nknowledge distillation at various levels to inject LiDAR-domain knowledge into\na monocular detector during training. By identifying foreground sparsity as the\nmain culprit behind existing methods' suboptimal training, we exploit the\nprecise localisation information embedded in LiDAR points to enable more\nforeground-attentive and efficient distillation via the proposed BEV occupancy\nguidance mask, leading to notably improved knowledge transfer and M3OD\nperformance. Besides, motivated by insights into why existing cross-modal\nGT-sampling techniques fail on our task at hand, we further design a novel\ncross-modal object-wise data augmentation strategy for effective RGB-LiDAR\njoint learning. Our method ranks 1st in both KITTI validation and test\nbenchmarks, significantly surpassing all existing monocular methods, supervised\nor semi-supervised, on both BEV and 3D detection metrics.",
            "author": [
                "Weijia Zhang",
                "Dongnan Liu",
                "Chao Ma",
                "Weidong Cai"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18620v2",
                "http://arxiv.org/pdf/2310.18620v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18619v1",
            "title": "Dense Retrieval as Indirect Supervision for Large-space Decision Making",
            "updated": "2023-10-28T07:00:28Z",
            "published": "2023-10-28T07:00:28Z",
            "summary": "Many discriminative natural language understanding (NLU) tasks have large\nlabel spaces. Learning such a process of large-space decision making is\nparticularly challenging due to the lack of training instances per label and\nthe difficulty of selection among many fine-grained labels. Inspired by dense\nretrieval methods for passage finding in open-domain QA, we propose a\nreformulation of large-space discriminative NLU tasks as a learning-to-retrieve\ntask, leading to a novel solution named Dense Decision Retrieval (DDR ).\nInstead of predicting fine-grained decisions as logits, DDR adopts a\ndual-encoder architecture that learns to predict by retrieving from a decision\nthesaurus. This approach not only leverages rich indirect supervision signals\nfrom easy-to-consume learning resources for dense retrieval, it also leads to\nenhanced prediction generalizability with a semantically meaningful\nrepresentation of the large decision space. When evaluated on tasks with\ndecision spaces ranging from hundreds to hundred-thousand scales, DDR\noutperforms strong baselines greatly by 27.54% in P@1 on two extreme\nmulti-label classification tasks, 1.17% in F1 score ultra-fine entity typing,\nand 1.26% in accuracy on three few-shot intent classification tasks on average.\nCode and resources are available at https://github.com/luka-group/DDR",
            "author": [
                "Nan Xu",
                "Fei Wang",
                "Mingtao Dong",
                "Muhao Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18619v1",
                "http://arxiv.org/pdf/2310.18619v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18617v1",
            "title": "Pessimistic Off-Policy Multi-Objective Optimization",
            "updated": "2023-10-28T06:50:15Z",
            "published": "2023-10-28T06:50:15Z",
            "summary": "Multi-objective optimization is a type of decision making problems where\nmultiple conflicting objectives are optimized. We study offline optimization of\nmulti-objective policies from data collected by an existing policy. We propose\na pessimistic estimator for the multi-objective policy values that can be\neasily plugged into existing formulas for hypervolume computation and\noptimized. The estimator is based on inverse propensity scores (IPS), and\nimproves upon a naive IPS estimator in both theory and experiments. Our\nanalysis is general, and applies beyond our IPS estimators and methods for\noptimizing them. The pessimistic estimator can be optimized by policy gradients\nand performs well in all of our experiments.",
            "author": [
                "Shima Alizadeh",
                "Aniruddha Bhargava",
                "Karthick Gopalswamy",
                "Lalit Jain",
                "Branislav Kveton",
                "Ge Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18617v1",
                "http://arxiv.org/pdf/2310.18617v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18615v1",
            "title": "Temporally Disentangled Representation Learning under Unknown\n  Nonstationarity",
            "updated": "2023-10-28T06:46:03Z",
            "published": "2023-10-28T06:46:03Z",
            "summary": "In unsupervised causal representation learning for sequential data with\ntime-delayed latent causal influences, strong identifiability results for the\ndisentanglement of causally-related latent variables have been established in\nstationary settings by leveraging temporal structure. However, in nonstationary\nsetting, existing work only partially addressed the problem by either utilizing\nobserved auxiliary variables (e.g., class labels and/or domain indexes) as side\ninformation or assuming simplified latent causal dynamics. Both constrain the\nmethod to a limited range of scenarios. In this study, we further explored the\nMarkov Assumption under time-delayed causally related process in nonstationary\nsetting and showed that under mild conditions, the independent latent\ncomponents can be recovered from their nonlinear mixture up to a permutation\nand a component-wise transformation, without the observation of auxiliary\nvariables. We then introduce NCTRL, a principled estimation framework, to\nreconstruct time-delayed latent causal variables and identify their relations\nfrom measured sequential data only. Empirical evaluations demonstrated the\nreliable identification of time-delayed latent causal influences, with our\nmethodology substantially outperforming existing baselines that fail to exploit\nthe nonstationarity adequately and then, consequently, cannot distinguish\ndistribution shifts.",
            "author": [
                "Xiangchen Song",
                "Weiran Yao",
                "Yewen Fan",
                "Xinshuai Dong",
                "Guangyi Chen",
                "Juan Carlos Niebles",
                "Eric Xing",
                "Kun Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18615v1",
                "http://arxiv.org/pdf/2310.18615v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18614v1",
            "title": "Hierarchical Mutual Information Analysis: Towards Multi-view Clustering\n  in The Wild",
            "updated": "2023-10-28T06:43:57Z",
            "published": "2023-10-28T06:43:57Z",
            "summary": "Multi-view clustering (MVC) can explore common semantics from unsupervised\nviews generated by different sources, and thus has been extensively used in\napplications of practical computer vision. Due to the spatio-temporal\nasynchronism, multi-view data often suffer from view missing and are unaligned\nin real-world applications, which makes it difficult to learn consistent\nrepresentations. To address the above issues, this work proposes a deep MVC\nframework where data recovery and alignment are fused in a hierarchically\nconsistent way to maximize the mutual information among different views and\nensure the consistency of their latent spaces. More specifically, we first\nleverage dual prediction to fill in missing views while achieving the\ninstance-level alignment, and then take the contrastive reconstruction to\nachieve the class-level alignment. To the best of our knowledge, this could be\nthe first successful attempt to handle the missing and unaligned data problem\nseparately with different learning paradigms. Extensive experiments on public\ndatasets demonstrate that our method significantly outperforms state-of-the-art\nmethods on multi-view clustering even in the cases of view missing and\nunalignment.",
            "author": [
                "Jiatai Wang",
                "Zhiwei Xu",
                "Xuewen Yang",
                "Xin Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18614v1",
                "http://arxiv.org/pdf/2310.18614v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18612v1",
            "title": "Efficient kernel surrogates for neural network-based regression",
            "updated": "2023-10-28T06:41:47Z",
            "published": "2023-10-28T06:41:47Z",
            "summary": "Despite their immense promise in performing a variety of learning tasks, a\ntheoretical understanding of the effectiveness and limitations of Deep Neural\nNetworks (DNNs) has so far eluded practitioners. This is partly due to the\ninability to determine the closed forms of the learned functions, making it\nharder to assess their precise dependence on the training data and to study\ntheir generalization properties on unseen datasets. Recent work has shown that\nrandomly initialized DNNs in the infinite width limit converge to kernel\nmachines relying on a Neural Tangent Kernel (NTK) with known closed form. These\nresults suggest, and experimental evidence corroborates, that empirical kernel\nmachines can also act as surrogates for finite width DNNs. The high\ncomputational cost of assembling the full NTK, however, makes this approach\ninfeasible in practice, motivating the need for low-cost approximations. In the\ncurrent work, we study the performance of the Conjugate Kernel (CK), an\nefficient approximation to the NTK that has been observed to yield fairly\nsimilar results. For the regression problem of smooth functions and\nclassification using logistic regression, we show that the CK performance is\nonly marginally worse than that of the NTK and, in certain cases, is shown to\nbe superior. In particular, we establish bounds for the relative test losses,\nverify them with numerical tests, and identify the regularity of the kernel as\nthe key determinant of performance. In addition to providing a theoretical\ngrounding for using CKs instead of NTKs, our framework provides insights into\nunderstanding the robustness of the various approximants and suggests a recipe\nfor improving DNN accuracy inexpensively. We present a demonstration of this on\nthe foundation model GPT-2 by comparing its performance on a classification\ntask using a conventional approach and our prescription.",
            "author": [
                "Saad Qadeer",
                "Andrew Engel",
                "Adam Tsou",
                "Max Vargas",
                "Panos Stinis",
                "Tony Chiang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18612v1",
                "http://arxiv.org/pdf/2310.18612v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "68T07"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18609v1",
            "title": "Deep3DSketch+: Obtaining Customized 3D Model by Single Free-Hand Sketch\n  through Deep Learning",
            "updated": "2023-10-28T06:36:53Z",
            "published": "2023-10-28T06:36:53Z",
            "summary": "As 3D models become critical in today's manufacturing and product design,\nconventional 3D modeling approaches based on Computer-Aided Design (CAD) are\nlabor-intensive, time-consuming, and have high demands on the creators. This\nwork aims to introduce an alternative approach to 3D modeling by utilizing\nfree-hand sketches to obtain desired 3D models. We introduce Deep3DSketch+,\nwhich is a deep-learning algorithm that takes the input of a single free-hand\nsketch and produces a complete and high-fidelity model that matches the sketch\ninput. The neural network has view- and structural-awareness enabled by a Shape\nDiscriminator (SD) and a Stroke Enhancement Module (SEM), which overcomes the\nlimitations of sparsity and ambiguity of the sketches. The network design also\nbrings high robustness to partial sketch input in industrial applications.Our\napproach has undergone extensive experiments, demonstrating its\nstate-of-the-art (SOTA) performance on both synthetic and real-world datasets.\nThese results validate the effectiveness and superiority of our method compared\nto existing techniques. We have demonstrated the conversion of free-hand\nsketches into physical 3D objects using additive manufacturing. We believe that\nour approach has the potential to accelerate product design and democratize\ncustomized manufacturing.",
            "author": [
                "Ying Zang",
                "Chenglong Fu",
                "Tianrun Chen",
                "Yuanqi Hu",
                "Qingshan Liu",
                "Wenjun Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18609v1",
                "http://arxiv.org/pdf/2310.18609v1"
            ],
            "primary_category": "cs.MM",
            "category": [
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18608v1",
            "title": "Embedding in Recommender Systems: A Survey",
            "updated": "2023-10-28T06:31:06Z",
            "published": "2023-10-28T06:31:06Z",
            "summary": "Recommender systems have become an essential component of many online\nplatforms, providing personalized recommendations to users. A crucial aspect is\nembedding techniques that coverts the high-dimensional discrete features, such\nas user and item IDs, into low-dimensional continuous vectors and can enhance\nthe recommendation performance. Applying embedding techniques captures complex\nentity relationships and has spurred substantial research. In this survey, we\nprovide an overview of the recent literature on embedding techniques in\nrecommender systems. This survey covers embedding methods like collaborative\nfiltering, self-supervised learning, and graph-based techniques. Collaborative\nfiltering generates embeddings capturing user-item preferences, excelling in\nsparse data. Self-supervised methods leverage contrastive or generative\nlearning for various tasks. Graph-based techniques like node2vec exploit\ncomplex relationships in network-rich environments. Addressing the scalability\nchallenges inherent to embedding methods, our survey delves into innovative\ndirections within the field of recommendation systems. These directions aim to\nenhance performance and reduce computational complexity, paving the way for\nimproved recommender systems. Among these innovative approaches, we will\nintroduce Auto Machine Learning (AutoML), hash techniques, and quantization\ntechniques in this survey. We discuss various architectures and techniques and\nhighlight the challenges and future directions in these aspects. This survey\naims to provide a comprehensive overview of the state-of-the-art in this\nrapidly evolving field and serve as a useful resource for researchers and\npractitioners working in the area of recommender systems.",
            "author": [
                "Xiangyu Zhao",
                "Maolin Wang",
                "Xinjian Zhao",
                "Jiansheng Li",
                "Shucheng Zhou",
                "Dawei Yin",
                "Qing Li",
                "Jiliang Tang",
                "Ruocheng Guo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18608v1",
                "http://arxiv.org/pdf/2310.18608v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18606v1",
            "title": "Where have you been? A Study of Privacy Risk for Point-of-Interest\n  Recommendation",
            "updated": "2023-10-28T06:17:52Z",
            "published": "2023-10-28T06:17:52Z",
            "summary": "As location-based services (LBS) have grown in popularity, the collection of\nhuman mobility data has become increasingly extensive to build machine learning\n(ML) models offering enhanced convenience to LBS users. However, the\nconvenience comes with the risk of privacy leakage since this type of data\nmight contain sensitive information related to user identities, such as\nhome/work locations. Prior work focuses on protecting mobility data privacy\nduring transmission or prior to release, lacking the privacy risk evaluation of\nmobility data-based ML models. To better understand and quantify the privacy\nleakage in mobility data-based ML models, we design a privacy attack suite\ncontaining data extraction and membership inference attacks tailored for\npoint-of-interest (POI) recommendation models, one of the most widely used\nmobility data-based ML models. These attacks in our attack suite assume\ndifferent adversary knowledge and aim to extract different types of sensitive\ninformation from mobility data, providing a holistic privacy risk assessment\nfor POI recommendation models. Our experimental evaluation using two real-world\nmobility datasets demonstrates that current POI recommendation models are\nvulnerable to our attacks. We also present unique findings to understand what\ntypes of mobility data are more susceptible to privacy attacks. Finally, we\nevaluate defenses against these attacks and highlight future directions and\nchallenges.",
            "author": [
                "Kunlin Cai",
                "Jinghuai Zhang",
                "Will Shand",
                "Zhiqing Hong",
                "Guang Wang",
                "Desheng Zhang",
                "Jianfeng Chi",
                "Yuan Tian"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18606v1",
                "http://arxiv.org/pdf/2310.18606v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18605v1",
            "title": "TorchDEQ: A Library for Deep Equilibrium Models",
            "updated": "2023-10-28T06:16:10Z",
            "published": "2023-10-28T06:16:10Z",
            "summary": "Deep Equilibrium (DEQ) Models, an emerging class of implicit models that maps\ninputs to fixed points of neural networks, are of growing interest in the deep\nlearning community. However, training and applying DEQ models is currently done\nin an ad-hoc fashion, with various techniques spread across the literature. In\nthis work, we systematically revisit DEQs and present TorchDEQ, an\nout-of-the-box PyTorch-based library that allows users to define, train, and\ninfer using DEQs over multiple domains with minimal code and best practices.\nUsing TorchDEQ, we build a ``DEQ Zoo'' that supports six published implicit\nmodels across different domains. By developing a joint framework that\nincorporates the best practices across all models, we have substantially\nimproved the performance, training stability, and efficiency of DEQs on ten\ndatasets across all six projects in the DEQ Zoo. TorchDEQ and DEQ Zoo are\nreleased as \\href{https://github.com/locuslab/torchdeq}{open source}.",
            "author": [
                "Zhengyang Geng",
                "J. Zico Kolter"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18605v1",
                "http://arxiv.org/pdf/2310.18605v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18604v1",
            "title": "Anaphor Assisted Document-Level Relation Extraction",
            "updated": "2023-10-28T06:11:18Z",
            "published": "2023-10-28T06:11:18Z",
            "summary": "Document-level relation extraction (DocRE) involves identifying relations\nbetween entities distributed in multiple sentences within a document. Existing\nmethods focus on building a heterogeneous document graph to model the internal\nstructure of an entity and the external interaction between entities. However,\nthere are two drawbacks in existing methods. On one hand, anaphor plays an\nimportant role in reasoning to identify relations between entities but is\nignored by these methods. On the other hand, these methods achieve\ncross-sentence entity interactions implicitly by utilizing a document or\nsentences as intermediate nodes. Such an approach has difficulties in learning\nfine-grained interactions between entities across different sentences,\nresulting in sub-optimal performance. To address these issues, we propose an\nAnaphor-Assisted (AA) framework for DocRE tasks. Experimental results on the\nwidely-used datasets demonstrate that our model achieves a new state-of-the-art\nperformance.",
            "author": [
                "Chonggang Lu",
                "Richong Zhang",
                "Kai Sun",
                "Jaein Kim",
                "Cunwang Zhang",
                "Yongyi Mao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18604v1",
                "http://arxiv.org/pdf/2310.18604v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18603v1",
            "title": "Large Language Models Are Better Adversaries: Exploring Generative\n  Clean-Label Backdoor Attacks Against Text Classifiers",
            "updated": "2023-10-28T06:11:07Z",
            "published": "2023-10-28T06:11:07Z",
            "summary": "Backdoor attacks manipulate model predictions by inserting innocuous triggers\ninto training and test data. We focus on more realistic and more challenging\nclean-label attacks where the adversarial training examples are correctly\nlabeled. Our attack, LLMBkd, leverages language models to automatically insert\ndiverse style-based triggers into texts. We also propose a poison selection\ntechnique to improve the effectiveness of both LLMBkd as well as existing\ntextual backdoor attacks. Lastly, we describe REACT, a baseline defense to\nmitigate backdoor attacks via antidote training examples. Our evaluations\ndemonstrate LLMBkd's effectiveness and efficiency, where we consistently\nachieve high attack success rates across a wide range of styles with little\neffort and no model training.",
            "author": [
                "Wencong You",
                "Zayd Hammoudeh",
                "Daniel Lowd"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18603v1",
                "http://arxiv.org/pdf/2310.18603v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18601v1",
            "title": "Online Decision Mediation",
            "updated": "2023-10-28T05:59:43Z",
            "published": "2023-10-28T05:59:43Z",
            "summary": "Consider learning a decision support assistant to serve as an intermediary\nbetween (oracle) expert behavior and (imperfect) human behavior: At each time,\nthe algorithm observes an action chosen by a fallible agent, and decides\nwhether to *accept* that agent's decision, *intervene* with an alternative, or\n*request* the expert's opinion. For instance, in clinical diagnosis,\nfully-autonomous machine behavior is often beyond ethical affordances, thus\nreal-world decision support is often limited to monitoring and forecasting.\nInstead, such an intermediary would strike a prudent balance between the former\n(purely prescriptive) and latter (purely descriptive) approaches, while\nproviding an efficient interface between human mistakes and expert feedback. In\nthis work, we first formalize the sequential problem of *online decision\nmediation* -- that is, of simultaneously learning and evaluating mediator\npolicies from scratch with *abstentive feedback*: In each round, deferring to\nthe oracle obviates the risk of error, but incurs an upfront penalty, and\nreveals the otherwise hidden expert action as a new training data point.\nSecond, we motivate and propose a solution that seeks to trade off (immediate)\nloss terms against (future) improvements in generalization error; in doing so,\nwe identify why conventional bandit algorithms may fail. Finally, through\nexperiments and sensitivities on a variety of datasets, we illustrate\nconsistent gains over applicable benchmarks on performance measures with\nrespect to the mediator policy, the learned model, and the decision-making\nsystem as a whole.",
            "author": [
                "Daniel Jarrett",
                "Alihan H\u00fcy\u00fck",
                "Mihaela van der Schaar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18601v1",
                "http://arxiv.org/pdf/2310.18601v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18598v1",
            "title": "Domain Generalisation via Risk Distribution Matching",
            "updated": "2023-10-28T05:23:55Z",
            "published": "2023-10-28T05:23:55Z",
            "summary": "We propose a novel approach for domain generalisation (DG) leveraging risk\ndistributions to characterise domains, thereby achieving domain invariance. In\nour findings, risk distributions effectively highlight differences between\ntraining domains and reveal their inherent complexities. In testing, we may\nobserve similar, or potentially intensifying in magnitude, divergences between\nrisk distributions. Hence, we propose a compelling proposition: Minimising the\ndivergences between risk distributions across training domains leads to robust\ninvariance for DG. The key rationale behind this concept is that a model,\ntrained on domain-invariant or stable features, may consistently produce\nsimilar risk distributions across various domains. Building upon this idea, we\npropose Risk Distribution Matching (RDM). Using the maximum mean discrepancy\n(MMD) distance, RDM aims to minimise the variance of risk distributions across\ntraining domains. However, when the number of domains increases, the direct\noptimisation of variance leads to linear growth in MMD computations, resulting\nin inefficiency. Instead, we propose an approximation that requires only one\nMMD computation, by aligning just two distributions: that of the worst-case\ndomain and the aggregated distribution from all domains. Notably, this method\nempirically outperforms optimising distributional variance while being\ncomputationally more efficient. Unlike conventional DG matching algorithms, RDM\nstands out for its enhanced efficacy by concentrating on scalar risk\ndistributions, sidestepping the pitfalls of high-dimensional challenges seen in\nfeature or gradient matching. Our extensive experiments on standard benchmark\ndatasets demonstrate that RDM shows superior generalisation capability over\nstate-of-the-art DG methods.",
            "author": [
                "Toan Nguyen",
                "Kien Do",
                "Bao Duong",
                "Thin Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18598v1",
                "http://arxiv.org/pdf/2310.18598v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18593v1",
            "title": "Fair Streaming Principal Component Analysis: Statistical and Algorithmic\n  Viewpoint",
            "updated": "2023-10-28T05:09:30Z",
            "published": "2023-10-28T05:09:30Z",
            "summary": "Fair Principal Component Analysis (PCA) is a problem setting where we aim to\nperform PCA while making the resulting representation fair in that the\nprojected distributions, conditional on the sensitive attributes, match one\nanother. However, existing approaches to fair PCA have two main problems:\ntheoretically, there has been no statistical foundation of fair PCA in terms of\nlearnability; practically, limited memory prevents us from using existing\napproaches, as they explicitly rely on full access to the entire data. On the\ntheoretical side, we rigorously formulate fair PCA using a new notion called\n\\emph{probably approximately fair and optimal} (PAFO) learnability. On the\npractical side, motivated by recent advances in streaming algorithms for\naddressing memory limitation, we propose a new setting called \\emph{fair\nstreaming PCA} along with a memory-efficient algorithm, fair noisy power method\n(FNPM). We then provide its {\\it statistical} guarantee in terms of\nPAFO-learnability, which is the first of its kind in fair PCA literature.\nLastly, we verify the efficacy and memory efficiency of our algorithm on\nreal-world datasets.",
            "author": [
                "Junghyun Lee",
                "Hanseul Cho",
                "Se-Young Yun",
                "Chulhee Yun"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18593v1",
                "http://arxiv.org/pdf/2310.18593v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.CY",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18591v1",
            "title": "Inverse Decision Modeling: Learning Interpretable Representations of\n  Behavior",
            "updated": "2023-10-28T05:05:01Z",
            "published": "2023-10-28T05:05:01Z",
            "summary": "Decision analysis deals with modeling and enhancing decision processes. A\nprincipal challenge in improving behavior is in obtaining a transparent\ndescription of existing behavior in the first place. In this paper, we develop\nan expressive, unifying perspective on inverse decision modeling: a framework\nfor learning parameterized representations of sequential decision behavior.\nFirst, we formalize the forward problem (as a normative standard), subsuming\ncommon classes of control behavior. Second, we use this to formalize the\ninverse problem (as a descriptive model), generalizing existing work on\nimitation/reward learning -- while opening up a much broader class of research\nproblems in behavior representation. Finally, we instantiate this approach with\nan example (inverse bounded rational control), illustrating how this structure\nenables learning (interpretable) representations of (bounded) rationality --\nwhile naturally capturing intuitive notions of suboptimal actions, biased\nbeliefs, and imperfect knowledge of environments.",
            "author": [
                "Daniel Jarrett",
                "Alihan H\u00fcy\u00fck",
                "Mihaela van der Schaar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18591v1",
                "http://arxiv.org/pdf/2310.18591v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18590v2",
            "title": "Using Early Readouts to Mediate Featural Bias in Distillation",
            "updated": "2023-11-08T13:13:13Z",
            "published": "2023-10-28T04:58:15Z",
            "summary": "Deep networks tend to learn spurious feature-label correlations in real-world\nsupervised learning tasks. This vulnerability is aggravated in distillation,\nwhere a student model may have lesser representational capacity than the\ncorresponding teacher model. Often, knowledge of specific spurious correlations\nis used to reweight instances & rebalance the learning process. We propose a\nnovel early readout mechanism whereby we attempt to predict the label using\nrepresentations from earlier network layers. We show that these early readouts\nautomatically identify problem instances or groups in the form of confident,\nincorrect predictions. Leveraging these signals to modulate the distillation\nloss on an instance level allows us to substantially improve not only group\nfairness measures across benchmark datasets, but also overall accuracy of the\nstudent model. We also provide secondary analyses that bring insight into the\nrole of feature learning in supervision and distillation.",
            "author": [
                "Rishabh Tiwari",
                "Durga Sivasubramanian",
                "Anmol Mekala",
                "Ganesh Ramakrishnan",
                "Pradeep Shenoy"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18590v2",
                "http://arxiv.org/pdf/2310.18590v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18589v1",
            "title": "This Looks Like Those: Illuminating Prototypical Concepts Using Multiple\n  Visualizations",
            "updated": "2023-10-28T04:54:48Z",
            "published": "2023-10-28T04:54:48Z",
            "summary": "We present ProtoConcepts, a method for interpretable image classification\ncombining deep learning and case-based reasoning using prototypical parts.\nExisting work in prototype-based image classification uses a ``this looks like\nthat'' reasoning process, which dissects a test image by finding prototypical\nparts and combining evidence from these prototypes to make a final\nclassification. However, all of the existing prototypical part-based image\nclassifiers provide only one-to-one comparisons, where a single training image\npatch serves as a prototype to compare with a part of our test image. With\nthese single-image comparisons, it can often be difficult to identify the\nunderlying concept being compared (e.g., ``is it comparing the color or the\nshape?''). Our proposed method modifies the architecture of prototype-based\nnetworks to instead learn prototypical concepts which are visualized using\nmultiple image patches. Having multiple visualizations of the same prototype\nallows us to more easily identify the concept captured by that prototype (e.g.,\n``the test image and the related training patches are all the same shade of\nblue''), and allows our model to create richer, more interpretable visual\nexplanations. Our experiments show that our ``this looks like those'' reasoning\nprocess can be applied as a modification to a wide range of existing\nprototypical image classification networks while achieving comparable accuracy\non benchmark datasets.",
            "author": [
                "Chiyu Ma",
                "Brandon Zhao",
                "Chaofan Chen",
                "Cynthia Rudin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18589v1",
                "http://arxiv.org/pdf/2310.18589v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18586v1",
            "title": "Optimal Transport for Kernel Gaussian Mixture Models",
            "updated": "2023-10-28T04:31:49Z",
            "published": "2023-10-28T04:31:49Z",
            "summary": "The Wasserstein distance from optimal mass transport (OMT) is a powerful\nmathematical tool with numerous applications that provides a natural measure of\nthe distance between two probability distributions. Several methods to\nincorporate OMT into widely used probabilistic models, such as Gaussian or\nGaussian mixture, have been developed to enhance the capability of modeling\ncomplex multimodal densities of real datasets. However, very few studies have\nexplored the OMT problems in a reproducing kernel Hilbert space (RKHS), wherein\nthe kernel trick is utilized to avoid the need to explicitly map input data\ninto a high-dimensional feature space. In the current study, we propose a\nWasserstein-type metric to compute the distance between two Gaussian mixtures\nin a RKHS via the kernel trick, i.e., kernel Gaussian mixture models.",
            "author": [
                "Jung Hun Oh",
                "Rena Elkin",
                "Anish Kumar Simhal",
                "Jiening Zhu",
                "Joseph O Deasy",
                "Allen Tannenbaum"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18586v1",
                "http://arxiv.org/pdf/2310.18586v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18583v2",
            "title": "Self-Supervised Multi-Modality Learning for Multi-Label Skin Lesion\n  Classification",
            "updated": "2023-11-16T05:02:34Z",
            "published": "2023-10-28T04:16:08Z",
            "summary": "The clinical diagnosis of skin lesion involves the analysis of dermoscopic\nand clinical modalities. Dermoscopic images provide a detailed view of the\nsurface structures whereas clinical images offer a complementary macroscopic\ninformation. The visual diagnosis of melanoma is also based on seven-point\nchecklist which involves identifying different visual attributes. Recently,\nsupervised learning approaches such as convolutional neural networks (CNNs)\nhave shown great performances using both dermoscopic and clinical modalities\n(Multi-modality). The seven different visual attributes in the checklist are\nalso used to further improve the the diagnosis. The performances of these\napproaches, however, are still reliant on the availability of large-scaled\nlabeled data. The acquisition of annotated dataset is an expensive and\ntime-consuming task, more so with annotating multi-attributes. To overcome this\nlimitation, we propose a self-supervised learning (SSL) algorithm for\nmulti-modality skin lesion classification. Our algorithm enables the\nmulti-modality learning by maximizing the similarities between paired\ndermoscopic and clinical images from different views. In addition, we generate\nsurrogate pseudo-multi-labels that represent seven attributes via clustering\nanalysis. We also propose a label-relation-aware module to refine each\npseudo-label embedding and capture the interrelationships between\npseudo-multi-labels. We validated the effectiveness of our algorithm using\nwell-benchmarked seven-point skin lesion dataset. Our results show that our\nalgorithm achieved better performances than other state-of-the-art SSL\ncounterparts.",
            "author": [
                "Hao Wang",
                "Euijoon Ahn",
                "Lei Bi",
                "Jinman Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18583v2",
                "http://arxiv.org/pdf/2310.18583v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18582v1",
            "title": "Data-driven learning of the generalized Langevin equation with\n  state-dependent memory",
            "updated": "2023-10-28T04:10:39Z",
            "published": "2023-10-28T04:10:39Z",
            "summary": "We present a data-driven method to learn stochastic reduced models of complex\nsystems that retain a state-dependent memory beyond the standard generalized\nLangevin equation (GLE) with a homogeneous kernel. The constructed model\nnaturally encodes the heterogeneous energy dissipation by jointly learning a\nset of state features and the non-Markovian coupling among the features.\nNumerical results demonstrate the limitation of the standard GLE and the\nessential role of the broadly overlooked state-dependency nature in predicting\nmolecule kinetics related to conformation relaxation and transition.",
            "author": [
                "Pei Ge",
                "Zhongqiang Zhang",
                "Huan Lei"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18582v1",
                "http://arxiv.org/pdf/2310.18582v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph",
                "physics.data-an"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18574v1",
            "title": "Breaking the Trilemma of Privacy, Utility, Efficiency via Controllable\n  Machine Unlearning",
            "updated": "2023-10-28T03:24:54Z",
            "published": "2023-10-28T03:24:54Z",
            "summary": "Machine Unlearning (MU) algorithms have become increasingly critical due to\nthe imperative adherence to data privacy regulations. The primary objective of\nMU is to erase the influence of specific data samples on a given model without\nthe need to retrain it from scratch. Accordingly, existing methods focus on\nmaximizing user privacy protection. However, there are different degrees of\nprivacy regulations for each real-world web-based application. Exploring the\nfull spectrum of trade-offs between privacy, model utility, and runtime\nefficiency is critical for practical unlearning scenarios. Furthermore,\ndesigning the MU algorithm with simple control of the aforementioned trade-off\nis desirable but challenging due to the inherent complex interaction. To\naddress the challenges, we present Controllable Machine Unlearning (ConMU), a\nnovel framework designed to facilitate the calibration of MU. The ConMU\nframework contains three integral modules: an important data selection module\nthat reconciles the runtime efficiency and model generalization, a progressive\nGaussian mechanism module that balances privacy and model generalization, and\nan unlearning proxy that controls the trade-offs between privacy and runtime\nefficiency. Comprehensive experiments on various benchmark datasets have\ndemonstrated the robust adaptability of our control mechanism and its\nsuperiority over established unlearning methods. ConMU explores the full\nspectrum of the Privacy-Utility-Efficiency trade-off and allows practitioners\nto account for different real-world regulations. Source code available at:\nhttps://github.com/guangyaodou/ConMU.",
            "author": [
                "Zheyuan Liu",
                "Guangyao Dou",
                "Yijun Tian",
                "Chunhui Zhang",
                "Eli Chien",
                "Ziwei Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18574v1",
                "http://arxiv.org/pdf/2310.18574v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18569v1",
            "title": "Enhancing Grasping Performance of Novel Objects through an Improved\n  Fine-Tuning Process",
            "updated": "2023-10-28T02:34:35Z",
            "published": "2023-10-28T02:34:35Z",
            "summary": "Grasping algorithms have evolved from planar depth grasping to utilizing\npoint cloud information, allowing for application in a wider range of\nscenarios. However, data-driven grasps based on models trained on basic\nopen-source datasets may not perform well on novel objects, which are often\nrequired in different scenarios, necessitating fine-tuning using new objects.\nThe data driving these algorithms essentially corresponds to the closing region\nof the hand in 6D pose, and due to the uniqueness of 6D pose, synthetic\nannotation or real-machine annotation methods are typically employed. Acquiring\nlarge amounts of data with real-machine annotation is challenging, making\nsynthetic annotation a common practice. However, obtaining annotated 6D pose\ndata using conventional methods is extremely time-consuming. Therefore, we\npropose a method to quickly acquire data for novel objects, enabling more\nefficient fine-tuning. Our method primarily samples grasp orientations to\ngenerate and annotate grasps. Experimental results demonstrate that our\nfine-tuning process for a new object is 400 \\% faster than other methods.\nFurthermore, we propose an optimized grasp annotation framework that accounts\nfor the effects of the gripper closing, making the annotations more reasonable.\nUpon acceptance of this paper, we will release our algorithm as open-source.",
            "author": [
                "Xiao Hu",
                "Xiangsheng Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18569v1",
                "http://arxiv.org/pdf/2310.18569v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18564v1",
            "title": "A General Framework for Robust G-Invariance in G-Equivariant Networks",
            "updated": "2023-10-28T02:27:34Z",
            "published": "2023-10-28T02:27:34Z",
            "summary": "We introduce a general method for achieving robust group-invariance in\ngroup-equivariant convolutional neural networks ($G$-CNNs), which we call the\n$G$-triple-correlation ($G$-TC) layer. The approach leverages the theory of the\ntriple-correlation on groups, which is the unique, lowest-degree polynomial\ninvariant map that is also complete. Many commonly used invariant maps - such\nas the max - are incomplete: they remove both group and signal structure. A\ncomplete invariant, by contrast, removes only the variation due to the actions\nof the group, while preserving all information about the structure of the\nsignal. The completeness of the triple correlation endows the $G$-TC layer with\nstrong robustness, which can be observed in its resistance to invariance-based\nadversarial attacks. In addition, we observe that it yields measurable\nimprovements in classification accuracy over standard Max $G$-Pooling in\n$G$-CNN architectures. We provide a general and efficient implementation of the\nmethod for any discretized group, which requires only a table defining the\ngroup's product structure. We demonstrate the benefits of this method for\n$G$-CNNs defined on both commutative and non-commutative groups - $SO(2)$,\n$O(2)$, $SO(3)$, and $O(3)$ (discretized as the cyclic $C8$, dihedral $D16$,\nchiral octahedral $O$ and full octahedral $O_h$ groups) - acting on\n$\\mathbb{R}^2$ and $\\mathbb{R}^3$ on both $G$-MNIST and $G$-ModelNet10\ndatasets.",
            "author": [
                "Sophia Sanborn",
                "Nina Miolane"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18564v1",
                "http://arxiv.org/pdf/2310.18564v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18562v1",
            "title": "Optimization-Free Test-Time Adaptation for Cross-Person Activity\n  Recognition",
            "updated": "2023-10-28T02:20:33Z",
            "published": "2023-10-28T02:20:33Z",
            "summary": "Human Activity Recognition (HAR) models often suffer from performance\ndegradation in real-world applications due to distribution shifts in activity\npatterns across individuals. Test-Time Adaptation (TTA) is an emerging learning\nparadigm that aims to utilize the test stream to adjust predictions in\nreal-time inference, which has not been explored in HAR before. However, the\nhigh computational cost of optimization-based TTA algorithms makes it\nintractable to run on resource-constrained edge devices. In this paper, we\npropose an Optimization-Free Test-Time Adaptation (OFTTA) framework for\nsensor-based HAR. OFTTA adjusts the feature extractor and linear classifier\nsimultaneously in an optimization-free manner. For the feature extractor, we\npropose Exponential DecayTest-time Normalization (EDTN) to replace the\nconventional batch normalization (CBN) layers. EDTN combines CBN and Test-time\nbatch Normalization (TBN) to extract reliable features against domain shifts\nwith TBN's influence decreasing exponentially in deeper layers. For the\nclassifier, we adjust the prediction by computing the distance between the\nfeature and the prototype, which is calculated by a maintained support set. In\naddition, the update of the support set is based on the pseudo label, which can\nbenefit from reliable features extracted by EDTN. Extensive experiments on\nthree public cross-person HAR datasets and two different TTA settings\ndemonstrate that OFTTA outperforms the state-of-the-art TTA approaches in both\nclassification performance and computational efficiency. Finally, we verify the\nsuperiority of our proposed OFTTA on edge devices, indicating possible\ndeployment in real applications. Our code is available at\n\\href{https://github.com/Claydon-Wang/OFTTA}{this https URL}.",
            "author": [
                "Shuoyuan Wang",
                "Jindong Wang",
                "HuaJun Xi",
                "Bob Zhang",
                "Lei Zhang",
                "Hongxin Wei"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18562v1",
                "http://arxiv.org/pdf/2310.18562v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18560v1",
            "title": "Interpretable machine learning for finding intermediate-mass black holes",
            "updated": "2023-10-28T02:15:09Z",
            "published": "2023-10-28T02:15:09Z",
            "summary": "Definitive evidence that globular clusters (GCs) host intermediate-mass black\nholes (IMBHs) is elusive. Machine learning (ML) models trained on GC\nsimulations can in principle predict IMBH host candidates based on observable\nfeatures. This approach has two limitations: first, an accurate ML model is\nexpected to be a black box due to complexity; second, despite our efforts to\nrealistically simulate GCs, the simulation physics or initial conditions may\nfail to fully reflect reality. Therefore our training data may be biased,\nleading to a failure in generalization on observational data. Both the first\nissue -- explainability/interpretability -- and the second -- out of\ndistribution generalization and fairness -- are active areas of research in ML.\nHere we employ techniques from these fields to address them: we use the anchors\nmethod to explain an XGBoost classifier; we also independently train a natively\ninterpretable model using Certifiably Optimal RulE ListS (CORELS). The\nresulting model has a clear physical meaning, but loses some performance with\nrespect to XGBoost. We evaluate potential candidates in real data based not\nonly on classifier predictions but also on their similarity to the training\ndata, measured by the likelihood of a kernel density estimation model. This\nmeasures the realism of our simulated data and mitigates the risk that our\nmodels may produce biased predictions by working in extrapolation. We apply our\nclassifiers to real GCs, obtaining a predicted classification, a measure of the\nconfidence of the prediction, an out-of-distribution flag, a local rule\nexplaining the prediction of XGBoost and a global rule from CORELS.",
            "author": [
                "Mario Pasquato",
                "Piero Trevisan",
                "Abbas Askar",
                "Pablo Lemos",
                "Gaia Carenini",
                "Michela Mapelli",
                "Yashar Hezaveh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18560v1",
                "http://arxiv.org/pdf/2310.18560v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA",
                "astro-ph.HE",
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18555v1",
            "title": "Group Robust Classification Without Any Group Information",
            "updated": "2023-10-28T01:29:18Z",
            "published": "2023-10-28T01:29:18Z",
            "summary": "Empirical risk minimization (ERM) is sensitive to spurious correlations in\nthe training data, which poses a significant risk when deploying systems\ntrained under this paradigm in high-stake applications. While the existing\nliterature focuses on maximizing group-balanced or worst-group accuracy,\nestimating these accuracies is hindered by costly bias annotations. This study\ncontends that current bias-unsupervised approaches to group robustness continue\nto rely on group information to achieve optimal performance. Firstly, these\nmethods implicitly assume that all group combinations are represented during\ntraining. To illustrate this, we introduce a systematic generalization task on\nthe MPI3D dataset and discover that current algorithms fail to improve the ERM\nbaseline when combinations of observed attribute values are missing. Secondly,\nbias labels are still crucial for effective model selection, restricting the\npracticality of these methods in real-world scenarios. To address these\nlimitations, we propose a revised methodology for training and validating\ndebiased models in an entirely bias-unsupervised manner. We achieve this by\nemploying pretrained self-supervised models to reliably extract bias\ninformation, which enables the integration of a logit adjustment training loss\nwith our validation criterion. Our empirical analysis on synthetic and\nreal-world tasks provides evidence that our approach overcomes the identified\nchallenges and consistently enhances robust accuracy, attaining performance\nwhich is competitive with or outperforms that of state-of-the-art methods,\nwhich, conversely, rely on bias labels for validation.",
            "author": [
                "Christos Tsirigotis",
                "Joao Monteiro",
                "Pau Rodriguez",
                "David Vazquez",
                "Aaron Courville"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18555v1",
                "http://arxiv.org/pdf/2310.18555v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18554v1",
            "title": "Improved Regret Bounds of (Multinomial) Logistic Bandits via\n  Regret-to-Confidence-Set Conversion",
            "updated": "2023-10-28T01:27:52Z",
            "published": "2023-10-28T01:27:52Z",
            "summary": "Logistic bandit is a ubiquitous framework of modeling users' choices, e.g.,\nclick vs. no click for advertisement recommender system. We observe that the\nprior works overlook or neglect dependencies in $S \\geq \\lVert \\theta_\\star\n\\rVert_2$, where $\\theta_\\star \\in \\mathbb{R}^d$ is the unknown parameter\nvector, which is particularly problematic when $S$ is large, e.g., $S \\geq d$.\nIn this work, we improve the dependency on $S$ via a novel approach called {\\it\nregret-to-confidence set conversion (R2CS)}, which allows us to construct a\nconvex confidence set based on only the \\textit{existence} of an online\nlearning algorithm with a regret guarantee. Using R2CS, we obtain a strict\nimprovement in the regret bound w.r.t. $S$ in logistic bandits while retaining\ncomputational feasibility and the dependence on other factors such as $d$ and\n$T$. We apply our new confidence set to the regret analyses of logistic bandits\nwith a new martingale concentration step that circumvents an additional factor\nof $S$. We then extend this analysis to multinomial logistic bandits and obtain\nsimilar improvements in the regret, showing the efficacy of R2CS. While we\napplied R2CS to the (multinomial) logistic model, R2CS is a generic approach\nfor developing confidence sets that can be used for various models, which can\nbe of independent interest.",
            "author": [
                "Junghyun Lee",
                "Se-Young Yun",
                "Kwang-Sung Jun"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18554v1",
                "http://arxiv.org/pdf/2310.18554v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18552v1",
            "title": "The Role of Reference Points in Machine-Learned Atomistic Simulation\n  Models",
            "updated": "2023-10-28T01:02:14Z",
            "published": "2023-10-28T01:02:14Z",
            "summary": "This paper introduces the Chemical Environment Modeling Theory (CEMT), a\nnovel, generalized framework designed to overcome the limitations inherent in\ntraditional atom-centered Machine Learning Force Field (MLFF) models, widely\nused in atomistic simulations of chemical systems. CEMT demonstrated enhanced\nflexibility and adaptability by allowing reference points to exist anywhere\nwithin the modeled domain and thus, enabling the study of various model\narchitectures. Utilizing Gaussian Multipole (GMP) featurization functions,\nseveral models with different reference point sets, including finite difference\ngrid-centered and bond-centered models, were tested to analyze the variance in\ncapabilities intrinsic to models built on distinct reference points. The\nresults underscore the potential of non-atom-centered reference points in force\ntraining, revealing variations in prediction accuracy, inference speed and\nlearning efficiency. Finally, a unique connection between CEMT and real-space\norbital-free finite element Density Functional Theory (FE-DFT) is established,\nand the implications include the enhancement of data efficiency and robustness.\nIt allows the leveraging of spatially-resolved energy densities and charge\ndensities from FE-DFT calculations, as well as serving as a pivotal step\ntowards integrating known quantum-mechanical laws into the architecture of ML\nmodels.",
            "author": [
                "Xiangyun Lei",
                "Weike Ye",
                "Joseph Montoya",
                "Tim Mueller",
                "Linda Hung",
                "Jens Hummelshoej"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18552v1",
                "http://arxiv.org/pdf/2310.18552v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "cs.CE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18549v1",
            "title": "Deep Intrinsic Decomposition with Adversarial Learning for Hyperspectral\n  Image Classification",
            "updated": "2023-10-28T00:41:25Z",
            "published": "2023-10-28T00:41:25Z",
            "summary": "Convolutional neural networks (CNNs) have been demonstrated their powerful\nability to extract discriminative features for hyperspectral image\nclassification. However, general deep learning methods for CNNs ignore the\ninfluence of complex environmental factor which enlarges the intra-class\nvariance and decreases the inter-class variance. This multiplies the difficulty\nto extract discriminative features. To overcome this problem, this work\ndevelops a novel deep intrinsic decomposition with adversarial learning, namely\nAdverDecom, for hyperspectral image classification to mitigate the negative\nimpact of environmental factors on classification performance. First, we\ndevelop a generative network for hyperspectral image (HyperNet) to extract the\nenvironmental-related feature and category-related feature from the image.\nThen, a discriminative network is constructed to distinguish different\nenvironmental categories. Finally, a environmental and category joint learning\nloss is developed for adversarial learning to make the deep model learn\ndiscriminative features. Experiments are conducted over three commonly used\nreal-world datasets and the comparison results show the superiority of the\nproposed method. The implementation of the proposed method and other compared\nmethods could be accessed at https://github.com/shendu-sw/Adversarial Learning\nIntrinsic Decomposition for the sake of reproducibility.",
            "author": [
                "Zhiqiang Gong",
                "Xian Zhou",
                "Wen Yao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18549v1",
                "http://arxiv.org/pdf/2310.18549v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18547v1",
            "title": "Punica: Multi-Tenant LoRA Serving",
            "updated": "2023-10-28T00:33:37Z",
            "published": "2023-10-28T00:33:37Z",
            "summary": "Low-rank adaptation (LoRA) has become an important and popular method to\nadapt pre-trained models to specific domains. We present Punica, a system to\nserve multiple LoRA models in a shared GPU cluster. Punica contains a new CUDA\nkernel design that allows batching of GPU operations for different LoRA models.\nThis allows a GPU to hold only a single copy of the underlying pre-trained\nmodel when serving multiple, different LoRA models, significantly enhancing GPU\nefficiency in terms of both memory and computation. Our scheduler consolidates\nmulti-tenant LoRA serving workloads in a shared GPU cluster. With a fixed-sized\nGPU cluster, our evaluations show that Punica achieves 12x higher throughput in\nserving multiple LoRA models compared to state-of-the-art LLM serving systems\nwhile only adding 2ms latency per token. Punica is open source at\nhttps://github.com/punica-ai/punica .",
            "author": [
                "Lequn Chen",
                "Zihao Ye",
                "Yongji Wu",
                "Danyang Zhuo",
                "Luis Ceze",
                "Arvind Krishnamurthy"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18547v1",
                "http://arxiv.org/pdf/2310.18547v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18542v1",
            "title": "End-to-end Feature Selection Approach for Learning Skinny Trees",
            "updated": "2023-10-28T00:15:10Z",
            "published": "2023-10-28T00:15:10Z",
            "summary": "Joint feature selection and tree ensemble learning is a challenging task.\nPopular tree ensemble toolkits e.g., Gradient Boosted Trees and Random Forests\nsupport feature selection post-training based on feature importances, which are\nknown to be misleading, and can significantly hurt performance. We propose\nSkinny Trees: a toolkit for feature selection in tree ensembles, such that\nfeature selection and tree ensemble learning occurs simultaneously. It is based\non an end-to-end optimization approach that considers feature selection in\ndifferentiable trees with Group $\\ell_0 - \\ell_2$ regularization. We optimize\nwith a first-order proximal method and present convergence guarantees for a\nnon-convex and non-smooth objective. Interestingly, dense-to-sparse\nregularization scheduling can lead to more expressive and sparser tree\nensembles than vanilla proximal method. On 15 synthetic and real-world\ndatasets, Skinny Trees can achieve $1.5\\times$ - $620\\times$ feature\ncompression rates, leading up to $10\\times$ faster inference over dense trees,\nwithout any loss in performance. Skinny Trees lead to superior feature\nselection than many existing toolkits e.g., in terms of AUC performance for\n$25\\%$ feature budget, Skinny Trees outperforms LightGBM by $10.2\\%$ (up to\n$37.7\\%$), and Random Forests by $3\\%$ (up to $12.5\\%$).",
            "author": [
                "Shibal Ibrahim",
                "Kayhan Behdin",
                "Rahul Mazumder"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18542v1",
                "http://arxiv.org/pdf/2310.18542v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18541v1",
            "title": "ReConTab: Regularized Contrastive Representation Learning for Tabular\n  Data",
            "updated": "2023-10-28T00:05:28Z",
            "published": "2023-10-28T00:05:28Z",
            "summary": "Representation learning stands as one of the critical machine learning\ntechniques across various domains. Through the acquisition of high-quality\nfeatures, pre-trained embeddings significantly reduce input space redundancy,\nbenefiting downstream pattern recognition tasks such as classification,\nregression, or detection. Nonetheless, in the domain of tabular data, feature\nengineering and selection still heavily rely on manual intervention, leading to\ntime-consuming processes and necessitating domain expertise. In response to\nthis challenge, we introduce ReConTab, a deep automatic representation learning\nframework with regularized contrastive learning. Agnostic to any type of\nmodeling task, ReConTab constructs an asymmetric autoencoder based on the same\nraw features from model inputs, producing low-dimensional representative\nembeddings. Specifically, regularization techniques are applied for raw feature\nselection. Meanwhile, ReConTab leverages contrastive learning to distill the\nmost pertinent information for downstream tasks. Experiments conducted on\nextensive real-world datasets substantiate the framework's capacity to yield\nsubstantial and robust performance improvements. Furthermore, we empirically\ndemonstrate that pre-trained embeddings can seamlessly integrate as easily\nadaptable features, enhancing the performance of various traditional methods\nsuch as XGBoost and Random Forest.",
            "author": [
                "Suiyao Chen",
                "Jing Wu",
                "Naira Hovakimyan",
                "Handong Yao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18541v1",
                "http://arxiv.org/pdf/2310.18541v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18539v1",
            "title": "Prediction of Yield Surface of Single Crystal Copper from Discrete\n  Dislocation Dynamics and Geometric Learning",
            "updated": "2023-10-27T23:38:49Z",
            "published": "2023-10-27T23:38:49Z",
            "summary": "A yield surface of a material is a set of critical stress conditions beyond\nwhich macroscopic plastic deformation begins. For crystalline solids, plastic\ndeformation occurs by the motion of dislocations, which can be captured by\ndiscrete dislocation dynamics (DDD) simulations. In this paper, we predict the\nyield surfaces and strain-hardening behaviors using DDD simulations and a\ngeometric manifold learning approach. The yield surfaces in the\nthree-dimensional space of plane stress are constructed for single-crystal\ncopper subjected to uniaxial loading along the $[100]$ and $[110]$ directions,\nrespectively. With increasing plastic deformation under $[100]$ loading, the\nyield surface expands nearly uniformly in all directions, corresponding to\nisotropic hardening. In contrast, under $[110]$ loading, latent hardening is\nobserved, where the yield surface remains nearly unchanged in the orientations\nin the vicinity of the loading direction itself, but expands in other\ndirections, resulting in an asymmetric shape. This difference in hardening\nbehaviors is attributed to the different dislocation multiplication behaviors\non various slip systems under the two loading conditions.",
            "author": [
                "Wu-Rong Jian",
                "Mian Xiao",
                "WaiChing Sun",
                "Wei Cai"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18539v1",
                "http://arxiv.org/pdf/2310.18539v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18538v1",
            "title": "Evaluating Cross-Domain Text-to-SQL Models and Benchmarks",
            "updated": "2023-10-27T23:36:14Z",
            "published": "2023-10-27T23:36:14Z",
            "summary": "Text-to-SQL benchmarks play a crucial role in evaluating the progress made in\nthe field and the ranking of different models. However, accurately matching a\nmodel-generated SQL query to a reference SQL query in a benchmark fails for\nvarious reasons, such as underspecified natural language queries, inherent\nassumptions in both model-generated and reference queries, and the\nnon-deterministic nature of SQL output under certain conditions. In this paper,\nwe conduct an extensive study of several prominent cross-domain text-to-SQL\nbenchmarks and re-evaluate some of the top-performing models within these\nbenchmarks, by both manually evaluating the SQL queries and rewriting them in\nequivalent expressions. Our evaluation reveals that attaining a perfect\nperformance on these benchmarks is unfeasible due to the multiple\ninterpretations that can be derived from the provided samples. Furthermore, we\nfind that the true performance of the models is underestimated and their\nrelative performance changes after a re-evaluation. Most notably, our\nevaluation reveals a surprising discovery: a recent GPT4-based model surpasses\nthe gold standard reference queries in the Spider benchmark in our human\nevaluation. This finding highlights the importance of interpreting benchmark\nevaluations cautiously, while also acknowledging the critical role of\nadditional independent evaluations in driving advancements in the field.",
            "author": [
                "Mohammadreza Pourreza",
                "Davood Rafiei"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18538v1",
                "http://arxiv.org/pdf/2310.18538v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.DB",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18535v1",
            "title": "Contextual Stochastic Bilevel Optimization",
            "updated": "2023-10-27T23:24:37Z",
            "published": "2023-10-27T23:24:37Z",
            "summary": "We introduce contextual stochastic bilevel optimization (CSBO) -- a\nstochastic bilevel optimization framework with the lower-level problem\nminimizing an expectation conditioned on some contextual information and the\nupper-level decision variable. This framework extends classical stochastic\nbilevel optimization when the lower-level decision maker responds optimally not\nonly to the decision of the upper-level decision maker but also to some side\ninformation and when there are multiple or even infinite many followers. It\ncaptures important applications such as meta-learning, personalized federated\nlearning, end-to-end learning, and Wasserstein distributionally robust\noptimization with side information (WDRO-SI). Due to the presence of contextual\ninformation, existing single-loop methods for classical stochastic bilevel\noptimization are unable to converge. To overcome this challenge, we introduce\nan efficient double-loop gradient method based on the Multilevel Monte-Carlo\n(MLMC) technique and establish its sample and computational complexities. When\nspecialized to stochastic nonconvex optimization, our method matches existing\nlower bounds. For meta-learning, the complexity of our method does not depend\non the number of tasks. Numerical experiments further validate our theoretical\nresults.",
            "author": [
                "Yifan Hu",
                "Jie Wang",
                "Yao Xie",
                "Andreas Krause",
                "Daniel Kuhn"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18535v1",
                "http://arxiv.org/pdf/2310.18535v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18534v3",
            "title": "Multi Time Scale World Models",
            "updated": "2023-12-04T10:20:40Z",
            "published": "2023-10-27T23:18:44Z",
            "summary": "Intelligent agents use internal world models to reason and make predictions\nabout different courses of their actions at many scales. Devising learning\nparadigms and architectures that allow machines to learn world models that\noperate at multiple levels of temporal abstractions while dealing with complex\nuncertainty predictions is a major technical hurdle. In this work, we propose a\nprobabilistic formalism to learn multi-time scale world models which we call\nthe Multi Time Scale State Space (MTS3) model. Our model uses a computationally\nefficient inference scheme on multiple time scales for highly accurate\nlong-horizon predictions and uncertainty estimates over several seconds into\nthe future. Our experiments, which focus on action conditional long horizon\nfuture predictions, show that MTS3 outperforms recent methods on several system\nidentification benchmarks including complex simulated and real-world dynamical\nsystems. Code is available at this repository: https://github.com/ALRhub/MTS3.",
            "author": [
                "Vaisakh Shaj",
                "Saleh Gholam Zadeh",
                "Ozan Demir",
                "Luiz Ricardo Douat",
                "Gerhard Neumann"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18534v3",
                "http://arxiv.org/pdf/2310.18534v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18531v1",
            "title": "Feature Selection in the Contrastive Analysis Setting",
            "updated": "2023-10-27T23:16:03Z",
            "published": "2023-10-27T23:16:03Z",
            "summary": "Contrastive analysis (CA) refers to the exploration of variations uniquely\nenriched in a target dataset as compared to a corresponding background dataset\ngenerated from sources of variation that are irrelevant to a given task. For\nexample, a biomedical data analyst may wish to find a small set of genes to use\nas a proxy for variations in genomic data only present among patients with a\ngiven disease (target) as opposed to healthy control subjects (background).\nHowever, as of yet the problem of feature selection in the CA setting has\nreceived little attention from the machine learning community. In this work we\npresent contrastive feature selection (CFS), a method for performing feature\nselection in the CA setting. We motivate our approach with a novel\ninformation-theoretic analysis of representation learning in the CA setting,\nand we empirically validate CFS on a semi-synthetic dataset and four real-world\nbiomedical datasets. We find that our method consistently outperforms\npreviously proposed state-of-the-art supervised and fully unsupervised feature\nselection methods not designed for the CA setting. An open-source\nimplementation of our method is available at https://github.com/suinleelab/CFS.",
            "author": [
                "Ethan Weinberger",
                "Ian Covert",
                "Su-In Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18531v1",
                "http://arxiv.org/pdf/2310.18531v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18529v2",
            "title": "FPM-INR: Fourier ptychographic microscopy image stack reconstruction\n  using implicit neural representations",
            "updated": "2023-10-31T20:22:28Z",
            "published": "2023-10-27T23:13:49Z",
            "summary": "Image stacks provide invaluable 3D information in various biological and\npathological imaging applications. Fourier ptychographic microscopy (FPM)\nenables reconstructing high-resolution, wide field-of-view image stacks without\nz-stack scanning, thus significantly accelerating image acquisition. However,\nexisting FPM methods take tens of minutes to reconstruct and gigabytes of\nmemory to store a high-resolution volumetric scene, impeding fast\ngigapixel-scale remote digital pathology. While deep learning approaches have\nbeen explored to address this challenge, existing methods poorly generalize to\nnovel datasets and can produce unreliable hallucinations. This work presents\nFPM-INR, a compact and efficient framework that integrates physics-based\noptical models with implicit neural representations (INR) to represent and\nreconstruct FPM image stacks. FPM-INR is agnostic to system design or sample\ntypes and does not require external training data. In our demonstrated\nexperiments, FPM-INR substantially outperforms traditional FPM algorithms with\nup to a 25-fold increase in speed and an 80-fold reduction in memory usage for\ncontinuous image stack representations.",
            "author": [
                "Haowen Zhou",
                "Brandon Y. Feng",
                "Haiyun Guo",
                "Siyu Lin",
                "Mingshu Liang",
                "Christopher A. Metzler",
                "Changhuei Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18529v2",
                "http://arxiv.org/pdf/2310.18529v2"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18526v1",
            "title": "Sample based Explanations via Generalized Representers",
            "updated": "2023-10-27T22:54:47Z",
            "published": "2023-10-27T22:54:47Z",
            "summary": "We propose a general class of sample based explanations of machine learning\nmodels, which we term generalized representers. To measure the effect of a\ntraining sample on a model's test prediction, generalized representers use two\ncomponents: a global sample importance that quantifies the importance of the\ntraining point to the model and is invariant to test samples, and a local\nsample importance that measures similarity between the training sample and the\ntest point with a kernel. A key contribution of the paper is to show that\ngeneralized representers are the only class of sample based explanations\nsatisfying a natural set of axiomatic properties. We discuss approaches to\nextract global importances given a kernel, and also natural choices of kernels\ngiven modern non-linear models. As we show, many popular existing sample based\nexplanations could be cast as generalized representers with particular choices\nof kernels and approaches to extract global importances. Additionally, we\nconduct empirical comparisons of different generalized representers on two\nimage and two text classification datasets.",
            "author": [
                "Che-Ping Tsai",
                "Chih-Kuan Yeh",
                "Pradeep Ravikumar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18526v1",
                "http://arxiv.org/pdf/2310.18526v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18523v1",
            "title": "Using convolutional neural networks for stereological characterization\n  of 3D hetero-aggregates based on synthetic STEM data",
            "updated": "2023-10-27T22:49:08Z",
            "published": "2023-10-27T22:49:08Z",
            "summary": "The structural characterization of hetero-aggregates in 3D is of great\ninterest, e.g., for deriving process-structure or structure-property\nrelationships. However, since 3D imaging techniques are often difficult to\nperform as well as time and cost intensive, a characterization of\nhetero-aggregates based on 2D image data is desirable, but often non-trivial.\nTo overcome the issues of characterizing 3D structures from 2D measurements, a\nmethod is presented that relies on machine learning combined with methods of\nspatial stochastic modeling, where the latter are utilized for the generation\nof synthetic training data. This kind of training data has the advantage that\ntime-consuming experiments for the synthesis of differently structured\nmaterials followed by their 3D imaging can be avoided. More precisely, a\nparametric stochastic 3D model is presented, from which a wide spectrum of\nvirtual hetero-aggregates can be generated. Additionally, the virtual\nstructures are passed to a physics-based simulation tool in order to generate\nvirtual scanning transmission electron microscopy (STEM) images. The preset\nparameters of the 3D model together with the simulated STEM images serve as a\ndatabase for the training of convolutional neural networks, which can be used\nto determine the parameters of the underlying 3D model and, consequently, to\npredict 3D structures of hetero-aggregates from 2D STEM images. Furthermore, an\nerror analysis is performed to evaluate the prediction power of the trained\nneural networks with respect to structural descriptors, e.g. the\nhetero-coordination number.",
            "author": [
                "Lukas Fuchs",
                "Tom Kirstein",
                "Christoph Mahr",
                "Orkun Furat",
                "Valentin Baric",
                "Andreas Rosenauer",
                "Lutz Maedler",
                "Volker Schmidt"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18523v1",
                "http://arxiv.org/pdf/2310.18523v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18519v1",
            "title": "Practical trainable temporal post-processor for multi-state quantum\n  measurement",
            "updated": "2023-10-27T22:36:59Z",
            "published": "2023-10-27T22:36:59Z",
            "summary": "We develop and demonstrate a trainable temporal post-processor (TPP),\nharnessing a simple but versatile machine learning algorithm to provide optimal\nprocessing of quantum measurement data subject to arbitrary noise processes,\nfor the readout of an arbitrary number of quantum states. We demonstrate the\nTPP on the essential task of qubit state readout, which has historically relied\non temporal processing via matched filters in spite of their applicability only\nfor specific noise conditions. Our results show that the TPP can reliably\noutperform standard filtering approaches under complex readout conditions, such\nas high power readout. Using simulations of quantum measurement noise sources,\nwe show that this advantage relies on the TPP's ability to learn optimal linear\nfilters that account for general quantum noise correlations in data, such as\nthose due to quantum jumps, or correlated noise added by a phase-preserving\nquantum amplifier. Furthermore, for signals subject to Gaussian white noise\nprocesses, the TPP provides a linearly-scaling semi-analytic generalization of\nmatched filtering to an arbitrary number of states. The TPP can be efficiently,\nautonomously, and reliably trained on measurement data, and requires only\nlinear operations, making it ideal for FPGA implementations in cQED for\nreal-time processing of measurement data from general quantum systems.",
            "author": [
                "Saeed A. Khan",
                "Ryan Kaufman",
                "Boris Mesits",
                "Michael Hatridge",
                "Hakan E. T\u00fcreci"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18519v1",
                "http://arxiv.org/pdf/2310.18519v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18517v1",
            "title": "Learning to recognize occluded and small objects with partial inputs",
            "updated": "2023-10-27T22:29:27Z",
            "published": "2023-10-27T22:29:27Z",
            "summary": "Recognizing multiple objects in an image is challenging due to occlusions,\nand becomes even more so when the objects are small. While promising, existing\nmulti-label image recognition models do not explicitly learn context-based\nrepresentations, and hence struggle to correctly recognize small and occluded\nobjects. Intuitively, recognizing occluded objects requires knowledge of\npartial input, and hence context. Motivated by this intuition, we propose\nMasked Supervised Learning (MSL), a single-stage, model-agnostic learning\nparadigm for multi-label image recognition. The key idea is to learn\ncontext-based representations using a masked branch and to model label\nco-occurrence using label consistency. Experimental results demonstrate the\nsimplicity, applicability and more importantly the competitive performance of\nMSL against previous state-of-the-art methods on standard multi-label image\nrecognition benchmarks. In addition, we show that MSL is robust to random\nmasking and demonstrate its effectiveness in recognizing non-masked objects.\nCode and pretrained models are available on GitHub.",
            "author": [
                "Hasib Zunair",
                "A. Ben Hamza"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18517v1",
                "http://arxiv.org/pdf/2310.18517v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18516v1",
            "title": "Operator is the Model",
            "updated": "2023-10-27T22:29:23Z",
            "published": "2023-10-27T22:29:23Z",
            "summary": "Koopman operator based models emerged as the leading methodology for machine\nlearning of dynamical systems. But their scope is much larger. In fact they\npresent a new take on modeling of physical systems, and even language. In this\narticle I present some of the underlying mathematical structures, applications,\nconnections to other methodologies such as transformer architectures",
            "author": [
                "Igor Mezi\u0107"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18516v1",
                "http://arxiv.org/pdf/2310.18516v1"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18515v2",
            "title": "Learning to design protein-protein interactions with enhanced\n  generalization",
            "updated": "2023-11-27T21:21:48Z",
            "published": "2023-10-27T22:22:44Z",
            "summary": "Discovering mutations enhancing protein-protein interactions (PPIs) is\ncritical for advancing biomedical research and developing improved\ntherapeutics. While machine learning approaches have substantially advanced the\nfield, they often struggle to generalize beyond training data in practical\nscenarios. The contributions of this work are three-fold. First, we construct\nPPIRef, the largest and non-redundant dataset of 3D protein-protein\ninteractions, enabling effective large-scale learning. Second, we leverage the\nPPIRef dataset to pre-train PPIformer, a new SE(3)-equivariant model\ngeneralizing across diverse protein-binder variants. We fine-tune PPIformer to\npredict effects of mutations on protein-protein interactions via a\nthermodynamically motivated adjustment of the pre-training loss function.\nFinally, we demonstrate the enhanced generalization of our new PPIformer\napproach by outperforming other state-of-the-art methods on new, non-leaking\nsplits of standard labeled PPI mutational data and independent case studies\noptimizing a human antibody against SARS-CoV-2 and increasing the thrombolytic\nactivity of staphylokinase.",
            "author": [
                "Anton Bushuiev",
                "Roman Bushuiev",
                "Petr Kouba",
                "Anatolii Filkin",
                "Marketa Gabrielova",
                "Michal Gabriel",
                "Jiri Sedlar",
                "Tomas Pluskal",
                "Jiri Damborsky",
                "Stanislav Mazurenko",
                "Josef Sivic"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18515v2",
                "http://arxiv.org/pdf/2310.18515v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18512v2",
            "title": "Preventing Language Models From Hiding Their Reasoning",
            "updated": "2023-10-31T19:13:43Z",
            "published": "2023-10-27T22:02:29Z",
            "summary": "Large language models (LLMs) often benefit from intermediate steps of\nreasoning to generate answers to complex problems. When these intermediate\nsteps of reasoning are used to monitor the activity of the model, it is\nessential that this explicit reasoning is faithful, i.e. that it reflects what\nthe model is actually reasoning about. In this work, we focus on one potential\nway intermediate steps of reasoning could be unfaithful: encoded reasoning,\nwhere an LLM could encode intermediate steps of reasoning in the generated text\nin a way that is not understandable to human readers. We show that language\nmodels can be trained to make use of encoded reasoning to get higher\nperformance without the user understanding the intermediate steps of reasoning.\nWe argue that, as language models get stronger, this behavior becomes more\nlikely to appear naturally. Finally, we describe a methodology that enables the\nevaluation of defenses against encoded reasoning, and show that, under the\nright conditions, paraphrasing successfully prevents even the best encoding\nschemes we built from encoding more than 3 bits of information per KB of text.",
            "author": [
                "Fabien Roger",
                "Ryan Greenblatt"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18512v2",
                "http://arxiv.org/pdf/2310.18512v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06281v2",
            "title": "Efficient Parallelization of an Ubiquitous Sequential Computation",
            "updated": "2023-11-15T14:53:19Z",
            "published": "2023-10-27T21:58:55Z",
            "summary": "We find a succinct expression for computing the sequence $x_t = a_t x_{t-1} +\nb_t$ in parallel with two prefix sums, given $t = (1, 2, \\dots, n)$, $a_t \\in\n\\mathbb{R}^n$, $b_t \\in \\mathbb{R}^n$, and initial value $x_0 \\in \\mathbb{R}$.\nOn $n$ parallel processors, the computation of $n$ elements incurs\n$\\mathcal{O}(\\log n)$ time and $\\mathcal{O}(n)$ space. Sequences of this form\nare ubiquitous in science and engineering, making efficient parallelization\nuseful for a vast number of applications. We implement our expression in\nsoftware, test it on parallel hardware, and verify that it executes faster than\nsequential computation by a factor of $\\frac{n}{\\log n}$.",
            "author": [
                "Franz A. Heinsen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06281v2",
                "http://arxiv.org/pdf/2311.06281v2"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18509v1",
            "title": "Deep Reinforcement Learning for Weapons to Targets Assignment in a\n  Hypersonic strike",
            "updated": "2023-10-27T21:58:05Z",
            "published": "2023-10-27T21:58:05Z",
            "summary": "We use deep reinforcement learning (RL) to optimize a weapons to target\nassignment (WTA) policy for multi-vehicle hypersonic strike against multiple\ntargets. The objective is to maximize the total value of destroyed targets in\neach episode. Each randomly generated episode varies the number and initial\nconditions of the hypersonic strike weapons (HSW) and targets, the value\ndistribution of the targets, and the probability of a HSW being intercepted. We\ncompare the performance of this WTA policy to that of a benchmark WTA policy\nderived using non-linear integer programming (NLIP), and find that the RL WTA\npolicy gives near optimal performance with a 1000X speedup in computation time,\nallowing real time operation that facilitates autonomous decision making in the\nmission end game.",
            "author": [
                "Brian Gaudet",
                "Kris Drozd",
                "Roberto Furfaro"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18509v1",
                "http://arxiv.org/pdf/2310.18509v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18505v1",
            "title": "Multi-fidelity Design of Porous Microstructures for Thermofluidic\n  Applications",
            "updated": "2023-10-27T21:51:11Z",
            "published": "2023-10-27T21:51:11Z",
            "summary": "As modern electronic devices are increasingly miniaturized and integrated,\ntheir performance relies more heavily on effective thermal management.\nTwo-phase cooling methods enhanced by porous surfaces, which capitalize on\nthin-film evaporation atop structured porous surfaces, are emerging as\npotential solutions. In such porous structures, the optimum heat dissipation\ncapacity relies on two competing objectives that depend on mass and heat\ntransfer. The computational costs of evaluating these objectives, the high\ndimensionality of the design space which a voxelated microstructure\nrepresentation, and the manufacturability constraints hinder the optimization\nprocess for thermal management. We address these challenges by developing a\ndata-driven framework for designing optimal porous microstructures for cooling\napplications. In our framework we leverage spectral density functions (SDFs) to\nencode the design space via a handful of interpretable variables and, in turn,\nefficiently search it. We develop physics-based formulas to quantify the\nthermofluidic properties and feasibility of candidate designs via offline\nsimulations. To decrease the reliance on expensive simulations, we generate\nmulti-fidelity data and build emulators to find Pareto-optimal designs. We\napply our approach to a canonical problem on evaporator wick design and obtain\nfin-like topologies in the optimal microstructures which are also\ncharacteristics often observed in industrial applications.",
            "author": [
                "Jonathan Tammer Eweis-LaBolle",
                "Chuanning Zhao",
                "Yoonjin Won",
                "Ramin Bostanabad"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18505v1",
                "http://arxiv.org/pdf/2310.18505v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18498v1",
            "title": "GPT-4 Vision on Medical Image Classification -- A Case Study on COVID-19\n  Dataset",
            "updated": "2023-10-27T21:28:36Z",
            "published": "2023-10-27T21:28:36Z",
            "summary": "This technical report delves into the application of GPT-4 Vision (GPT-4V) in\nthe nuanced realm of COVID-19 image classification, leveraging the\ntransformative potential of in-context learning to enhance diagnostic\nprocesses.",
            "author": [
                "Ruibo Chen",
                "Tianyi Xiong",
                "Yihan Wu",
                "Guodong Liu",
                "Zhengmian Hu",
                "Lichang Chen",
                "Yanshuo Chen",
                "Chenxi Liu",
                "Heng Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18498v1",
                "http://arxiv.org/pdf/2310.18498v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18496v1",
            "title": "How Well Do Feature-Additive Explainers Explain Feature-Additive\n  Predictors?",
            "updated": "2023-10-27T21:16:28Z",
            "published": "2023-10-27T21:16:28Z",
            "summary": "Surging interest in deep learning from high-stakes domains has precipitated\nconcern over the inscrutable nature of black box neural networks. Explainable\nAI (XAI) research has led to an abundance of explanation algorithms for these\nblack boxes. Such post hoc explainers produce human-comprehensible\nexplanations, however, their fidelity with respect to the model is not well\nunderstood - explanation evaluation remains one of the most challenging issues\nin XAI. In this paper, we ask a targeted but important question: can popular\nfeature-additive explainers (e.g., LIME, SHAP, SHAPR, MAPLE, and PDP) explain\nfeature-additive predictors? Herein, we evaluate such explainers on ground\ntruth that is analytically derived from the additive structure of a model. We\ndemonstrate the efficacy of our approach in understanding these explainers\napplied to symbolic expressions, neural networks, and generalized additive\nmodels on thousands of synthetic and several real-world tasks. Our results\nsuggest that all explainers eventually fail to correctly attribute the\nimportance of features, especially when a decision-making process involves\nfeature interactions.",
            "author": [
                "Zachariah Carmichael",
                "Walter J. Scheirer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18496v1",
                "http://arxiv.org/pdf/2310.18496v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18491v1",
            "title": "Publicly Detectable Watermarking for Language Models",
            "updated": "2023-10-27T21:08:51Z",
            "published": "2023-10-27T21:08:51Z",
            "summary": "We construct the first provable watermarking scheme for language models with\npublic detectability or verifiability: we use a private key for watermarking\nand a public key for watermark detection. Our protocol is the first\nwatermarking scheme that does not embed a statistical signal in generated text.\nRather, we directly embed a publicly-verifiable cryptographic signature using a\nform of rejection sampling. We show that our construction meets strong formal\nsecurity guarantees and preserves many desirable properties found in schemes in\nthe private-key watermarking setting. In particular, our watermarking scheme\nretains distortion-freeness and model agnosticity. We implement our scheme and\nmake empirical measurements over open models in the 7B parameter range. Our\nexperiments suggest that our watermarking scheme meets our formal claims while\npreserving text quality.",
            "author": [
                "Jaiden Fairoze",
                "Sanjam Garg",
                "Somesh Jha",
                "Saeed Mahloujifar",
                "Mohammad Mahmoody",
                "Mingyuan Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18491v1",
                "http://arxiv.org/pdf/2310.18491v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18481v1",
            "title": "MOSEL: Inference Serving Using Dynamic Modality Selection",
            "updated": "2023-10-27T20:50:56Z",
            "published": "2023-10-27T20:50:56Z",
            "summary": "Rapid advancements over the years have helped machine learning models reach\npreviously hard-to-achieve goals, sometimes even exceeding human capabilities.\nHowever, to attain the desired accuracy, the model sizes and in turn their\ncomputational requirements have increased drastically. Thus, serving\npredictions from these models to meet any target latency and cost requirements\nof applications remains a key challenge, despite recent work in building\ninference-serving systems as well as algorithmic approaches that dynamically\nadapt models based on inputs. In this paper, we introduce a form of dynamism,\nmodality selection, where we adaptively choose modalities from inference inputs\nwhile maintaining the model quality. We introduce MOSEL, an automated inference\nserving system for multi-modal ML models that carefully picks input modalities\nper request based on user-defined performance and accuracy requirements. MOSEL\nexploits modality configurations extensively, improving system throughput by\n3.6$\\times$ with an accuracy guarantee and shortening job completion times by\n11$\\times$.",
            "author": [
                "Bodun Hu",
                "Le Xu",
                "Jeongyoon Moon",
                "Neeraja J. Yadwadkar",
                "Aditya Akella"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18481v1",
                "http://arxiv.org/pdf/2310.18481v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.OS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18479v1",
            "title": "Weighted Sampled Split Learning (WSSL): Balancing Privacy, Robustness,\n  and Fairness in Distributed Learning Environments",
            "updated": "2023-10-27T20:50:21Z",
            "published": "2023-10-27T20:50:21Z",
            "summary": "This study presents Weighted Sampled Split Learning (WSSL), an innovative\nframework tailored to bolster privacy, robustness, and fairness in distributed\nmachine learning systems. Unlike traditional approaches, WSSL disperses the\nlearning process among multiple clients, thereby safeguarding data\nconfidentiality. Central to WSSL's efficacy is its utilization of weighted\nsampling. This approach ensures equitable learning by tactically selecting\ninfluential clients based on their contributions. Our evaluation of WSSL\nspanned various client configurations and employed two distinct datasets: Human\nGait Sensor and CIFAR-10. We observed three primary benefits: heightened model\naccuracy, enhanced robustness, and maintained fairness across diverse client\ncompositions. Notably, our distributed frameworks consistently surpassed\ncentralized counterparts, registering accuracy peaks of 82.63% and 75.51% for\nthe Human Gait Sensor and CIFAR-10 datasets, respectively. These figures\ncontrast with the top accuracies of 81.12% and 58.60% achieved by centralized\nsystems. Collectively, our findings champion WSSL as a potent and scalable\nsuccessor to conventional centralized learning, marking it as a pivotal stride\nforward in privacy-focused, resilient, and impartial distributed machine\nlearning.",
            "author": [
                "Manish Osti",
                "Aashray Thakuri",
                "Basheer Qolomany",
                "Aos Mulahuwaish"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18479v1",
                "http://arxiv.org/pdf/2310.18479v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18477v2",
            "title": "Understanding and Improving Ensemble Adversarial Defense",
            "updated": "2023-11-02T11:57:18Z",
            "published": "2023-10-27T20:43:29Z",
            "summary": "The strategy of ensemble has become popular in adversarial defense, which\ntrains multiple base classifiers to defend against adversarial attacks in a\ncooperative manner. Despite the empirical success, theoretical explanations on\nwhy an ensemble of adversarially trained classifiers is more robust than single\nones remain unclear. To fill in this gap, we develop a new error theory\ndedicated to understanding ensemble adversarial defense, demonstrating a\nprovable 0-1 loss reduction on challenging sample sets in an adversarial\ndefense scenario. Guided by this theory, we propose an effective approach to\nimprove ensemble adversarial defense, named interactive global adversarial\ntraining (iGAT). The proposal includes (1) a probabilistic distributing rule\nthat selectively allocates to different base classifiers adversarial examples\nthat are globally challenging to the ensemble, and (2) a regularization term to\nrescue the severest weaknesses of the base classifiers. Being tested over\nvarious existing ensemble adversarial defense techniques, iGAT is capable of\nboosting their performance by increases up to 17% evaluated using CIFAR10 and\nCIFAR100 datasets under both white-box and black-box attacks.",
            "author": [
                "Yian Deng",
                "Tingting Mu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18477v2",
                "http://arxiv.org/pdf/2310.18477v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18472v1",
            "title": "Parameter-Efficient Methods for Metastases Detection from Clinical Notes",
            "updated": "2023-10-27T20:30:59Z",
            "published": "2023-10-27T20:30:59Z",
            "summary": "Understanding the progression of cancer is crucial for defining treatments\nfor patients. The objective of this study is to automate the detection of\nmetastatic liver disease from free-style computed tomography (CT) radiology\nreports. Our research demonstrates that transferring knowledge using three\napproaches can improve model performance. First, we utilize generic language\nmodels (LMs), pretrained in a self-supervised manner. Second, we use a\nsemi-supervised approach to train our model by automatically annotating a large\nunlabeled dataset; this approach substantially enhances the model's\nperformance. Finally, we transfer knowledge from related tasks by designing a\nmulti-task transfer learning methodology. We leverage the recent advancement of\nparameter-efficient LM adaptation strategies to improve performance and\ntraining efficiency. Our dataset consists of CT reports collected at Memorial\nSloan Kettering Cancer Center (MSKCC) over the course of 12 years. 2,641\nreports were manually annotated by domain experts; among them, 841 reports have\nbeen annotated for the presence of liver metastases. Our best model achieved an\nF1-score of 73.8%, a precision of 84%, and a recall of 65.8%.",
            "author": [
                "Maede Ashofteh Barabadi",
                "Xiaodan Zhu",
                "Wai Yip Chan",
                "Amber L. Simpson",
                "Richard K. G. Do"
            ],
            "link": [
                "http://dx.doi.org/10.21428/594757db.8bee12fd",
                "http://arxiv.org/abs/2310.18472v1",
                "http://arxiv.org/pdf/2310.18472v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18471v2",
            "title": "Causal disentanglement of multimodal data",
            "updated": "2023-11-08T18:54:52Z",
            "published": "2023-10-27T20:30:11Z",
            "summary": "Causal representation learning algorithms discover lower-dimensional\nrepresentations of data that admit a decipherable interpretation of cause and\neffect; as achieving such interpretable representations is challenging, many\ncausal learning algorithms utilize elements indicating prior information, such\nas (linear) structural causal models, interventional data, or weak supervision.\nUnfortunately, in exploratory causal representation learning, such elements and\nprior information may not be available or warranted. Alternatively, scientific\ndatasets often have multiple modalities or physics-based constraints, and the\nuse of such scientific, multimodal data has been shown to improve\ndisentanglement in fully unsupervised settings. Consequently, we introduce a\ncausal representation learning algorithm (causalPIMA) that can use multimodal\ndata and known physics to discover important features with causal\nrelationships. Our innovative algorithm utilizes a new differentiable\nparametrization to learn a directed acyclic graph (DAG) together with a latent\nspace of a variational autoencoder in an end-to-end differentiable framework\nvia a single, tractable evidence lower bound loss function. We place a Gaussian\nmixture prior on the latent space and identify each of the mixtures with an\noutcome of the DAG nodes; this novel identification enables feature discovery\nwith causal relationships. Tested against a synthetic and a scientific dataset,\nour results demonstrate the capability of learning an interpretable causal\nstructure while simultaneously discovering key features in a fully unsupervised\nsetting.",
            "author": [
                "Elise Walker",
                "Jonas A. Actor",
                "Carianne Martinez",
                "Nathaniel Trask"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18471v2",
                "http://arxiv.org/pdf/2310.18471v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML",
                "68T07"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18469v1",
            "title": "Semi-Synthetic Dataset Augmentation for Application-Specific Gaze\n  Estimation",
            "updated": "2023-10-27T20:27:22Z",
            "published": "2023-10-27T20:27:22Z",
            "summary": "Although the number of gaze estimation datasets is growing, the application\nof appearance-based gaze estimation methods is mostly limited to estimating the\npoint of gaze on a screen. This is in part because most datasets are generated\nin a similar fashion, where the gaze target is on a screen close to camera's\norigin. In other applications such as assistive robotics or marketing research,\nthe 3D point of gaze might not be close to the camera's origin, meaning models\ntrained on current datasets do not generalize well to these tasks. We therefore\nsuggest generating a textured tridimensional mesh of the face and rendering the\ntraining images from a virtual camera at a specific position and orientation\nrelated to the application as a mean of augmenting the existing datasets. In\nour tests, this lead to an average 47% decrease in gaze estimation angular\nerror.",
            "author": [
                "Cedric Leblond-Menard",
                "Gabriel Picard-Krashevski",
                "Sofiane Achiche"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18469v1",
                "http://arxiv.org/pdf/2310.18469v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18465v1",
            "title": "Minimax Optimal Submodular Optimization with Bandit Feedback",
            "updated": "2023-10-27T20:19:03Z",
            "published": "2023-10-27T20:19:03Z",
            "summary": "We consider maximizing a monotonic, submodular set function $f: 2^{[n]}\n\\rightarrow [0,1]$ under stochastic bandit feedback. Specifically, $f$ is\nunknown to the learner but at each time $t=1,\\dots,T$ the learner chooses a set\n$S_t \\subset [n]$ with $|S_t| \\leq k$ and receives reward $f(S_t) + \\eta_t$\nwhere $\\eta_t$ is mean-zero sub-Gaussian noise. The objective is to minimize\nthe learner's regret over $T$ times with respect to ($1-e^{-1}$)-approximation\nof maximum $f(S_*)$ with $|S_*| = k$, obtained through greedy maximization of\n$f$. To date, the best regret bound in the literature scales as $k n^{1/3}\nT^{2/3}$. And by trivially treating every set as a unique arm one deduces that\n$\\sqrt{ {n \\choose k} T }$ is also achievable. In this work, we establish the\nfirst minimax lower bound for this setting that scales like\n$\\mathcal{O}(\\min_{i \\le k}(in^{1/3}T^{2/3} + \\sqrt{n^{k-i}T}))$. Moreover, we\npropose an algorithm that is capable of matching the lower bound regret.",
            "author": [
                "Artin Tajdini",
                "Lalit Jain",
                "Kevin Jamieson"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18465v1",
                "http://arxiv.org/pdf/2310.18465v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18459v1",
            "title": "VFAS-Grasp: Closed Loop Grasping with Visual Feedback and Adaptive\n  Sampling",
            "updated": "2023-10-27T20:12:30Z",
            "published": "2023-10-27T20:12:30Z",
            "summary": "We consider the problem of closed-loop robotic grasping and present a novel\nplanner which uses Visual Feedback and an uncertainty-aware Adaptive Sampling\nstrategy (VFAS) to close the loop. At each iteration, our method VFAS-Grasp\nbuilds a set of candidate grasps by generating random perturbations of a seed\ngrasp. The candidates are then scored using a novel metric which combines a\nlearned grasp-quality estimator, the uncertainty in the estimate and the\ndistance from the seed proposal to promote temporal consistency. Additionally,\nwe present two mechanisms to improve the efficiency of our sampling strategy:\nWe dynamically scale the sampling region size and number of samples in it based\non past grasp scores. We also leverage a motion vector field estimator to shift\nthe center of our sampling region. We demonstrate that our algorithm can run in\nreal time (20 Hz) and is capable of improving grasp performance for static\nscenes by refining the initial grasp proposal. We also show that it can enable\ngrasping of slow moving objects, such as those encountered during human to\nrobot handover.",
            "author": [
                "Pedro Piacenza",
                "Jiacheng Yuan",
                "Jinwook Huh",
                "Volkan Isler"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18459v1",
                "http://arxiv.org/pdf/2310.18459v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18457v1",
            "title": "LLMSTEP: LLM proofstep suggestions in Lean",
            "updated": "2023-10-27T20:10:56Z",
            "published": "2023-10-27T20:10:56Z",
            "summary": "We present LLMSTEP, a tool for integrating a language model into the Lean\nproof assistant. LLMSTEP is a Lean 4 tactic that sends a user's proof state to\na server hosting a language model. The language model generates suggestions,\nwhich are checked in Lean and displayed to a user in their development\nenvironment. We provide a baseline language model, along with code for\nfine-tuning and evaluation to support further development. We provide server\nimplementations that run on CPU, a CUDA GPU, or a Google Colab notebook, as a\nstep towards fast, effective language model suggestions for any user.",
            "author": [
                "Sean Welleck",
                "Rahul Saha"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18457v1",
                "http://arxiv.org/pdf/2310.18457v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "I.2.2; I.2.5; I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18455v1",
            "title": "Approximate Heavy Tails in Offline (Multi-Pass) Stochastic Gradient\n  Descent",
            "updated": "2023-10-27T20:06:03Z",
            "published": "2023-10-27T20:06:03Z",
            "summary": "A recent line of empirical studies has demonstrated that SGD might exhibit a\nheavy-tailed behavior in practical settings, and the heaviness of the tails\nmight correlate with the overall performance. In this paper, we investigate the\nemergence of such heavy tails. Previous works on this problem only considered,\nup to our knowledge, online (also called single-pass) SGD, in which the\nemergence of heavy tails in theoretical findings is contingent upon access to\nan infinite amount of data. Hence, the underlying mechanism generating the\nreported heavy-tailed behavior in practical settings, where the amount of\ntraining data is finite, is still not well-understood. Our contribution aims to\nfill this gap. In particular, we show that the stationary distribution of\noffline (also called multi-pass) SGD exhibits 'approximate' power-law tails and\nthe approximation error is controlled by how fast the empirical distribution of\nthe training data converges to the true underlying data distribution in the\nWasserstein metric. Our main takeaway is that, as the number of data points\nincreases, offline SGD will behave increasingly 'power-law-like'. To achieve\nthis result, we first prove nonasymptotic Wasserstein convergence bounds for\noffline SGD to online SGD as the number of data points increases, which can be\ninteresting on their own. Finally, we illustrate our theory on various\nexperiments conducted on synthetic data and neural networks.",
            "author": [
                "Krunoslav Lehman Pavasovic",
                "Alain Durmus",
                "Umut Simsekli"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18455v1",
                "http://arxiv.org/pdf/2310.18455v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18454v1",
            "title": "T5 meets Tybalt: Author Attribution in Early Modern English Drama Using\n  Large Language Models",
            "updated": "2023-10-27T20:04:57Z",
            "published": "2023-10-27T20:04:57Z",
            "summary": "Large language models have shown breakthrough potential in many NLP domains.\nHere we consider their use for stylometry, specifically authorship\nidentification in Early Modern English drama. We find both promising and\nconcerning results; LLMs are able to accurately predict the author of\nsurprisingly short passages but are also prone to confidently misattribute\ntexts to specific authors. A fine-tuned t5-large model outperforms all tested\nbaselines, including logistic regression, SVM with a linear kernel, and cosine\ndelta, at attributing small passages. However, we see indications that the\npresence of certain authors in the model's pre-training data affects predictive\nresults in ways that are difficult to assess.",
            "author": [
                "Rebecca M. M. Hicke",
                "David Mimno"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18454v1",
                "http://arxiv.org/pdf/2310.18454v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18449v1",
            "title": "Bayesian Optimization with Hidden Constraints via Latent Decision Models",
            "updated": "2023-10-27T19:47:26Z",
            "published": "2023-10-27T19:47:26Z",
            "summary": "Bayesian optimization (BO) has emerged as a potent tool for addressing\nintricate decision-making challenges, especially in public policy domains such\nas police districting. However, its broader application in public policymaking\nis hindered by the complexity of defining feasible regions and the\nhigh-dimensionality of decisions. This paper introduces the Hidden-Constrained\nLatent Space Bayesian Optimization (HC-LSBO), a novel BO method integrated with\na latent decision model. This approach leverages a variational autoencoder to\nlearn the distribution of feasible decisions, enabling a two-way mapping\nbetween the original decision space and a lower-dimensional latent space. By\ndoing so, HC-LSBO captures the nuances of hidden constraints inherent in public\npolicymaking, allowing for optimization in the latent space while evaluating\nobjectives in the original space. We validate our method through numerical\nexperiments on both synthetic and real data sets, with a specific focus on\nlarge-scale police districting problems in Atlanta, Georgia. Our results reveal\nthat HC-LSBO offers notable improvements in performance and efficiency compared\nto the baselines.",
            "author": [
                "Wenqian Xing",
                "Jungho Lee",
                "Chong Liu",
                "Shixiang Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18449v1",
                "http://arxiv.org/pdf/2310.18449v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.CE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18446v2",
            "title": "A Novel Skip Orthogonal List for Dynamic Optimal Transport Problem",
            "updated": "2023-11-25T19:05:40Z",
            "published": "2023-10-27T19:42:23Z",
            "summary": "Optimal transportation is a fundamental topic that has attracted a great\namount of attention from machine learning community in the past decades. In\nthis paper, we consider an interesting discrete dynamic optimal transport\nproblem: can we efficiently update the optimal transport plan when the weights\nor the locations of the data points change? This problem is naturally motivated\nby several applications in machine learning. For example, we often need to\ncompute the optimal transportation cost between two different data sets; if\nsome change happens to a few data points, should we re-compute the high\ncomplexity cost function or update the cost by some efficient dynamic data\nstructure? We are aware that several dynamic maximum flow algorithms have been\nproposed before, however, the research on dynamic minimum cost flow problem is\nstill quite limited, to the best of our knowledge. We propose a novel 2D Skip\nOrthogonal List together with some dynamic tree techniques. Although our\nalgorithm is based on the conventional simplex method, it can efficiently\ncomplete each pivoting operation within $O(|V|)$ time with high probability\nwhere $V$ is the set of all supply and demand nodes. Since dynamic\nmodifications typically do not introduce significant changes, our algorithm\nrequires only a few simplex iterations in practice. So our algorithm is more\nefficient than re-computing the optimal transportation cost that needs at least\none traversal over all the $O(|E|) = O(|V|^2)$ variables in general cases. Our\nexperiments demonstrate that our algorithm significantly outperforms existing\nalgorithms in the dynamic scenarios.",
            "author": [
                "Xiaoyang Xu",
                "Hu Ding"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18446v2",
                "http://arxiv.org/pdf/2310.18446v2"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.AI",
                "cs.CG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18444v1",
            "title": "M3C: A Framework towards Convergent, Flexible, and Unsupervised Learning\n  of Mixture Graph Matching and Clustering",
            "updated": "2023-10-27T19:40:34Z",
            "published": "2023-10-27T19:40:34Z",
            "summary": "Existing graph matching methods typically assume that there are similar\nstructures between graphs and they are matchable. However, these assumptions do\nnot align with real-world applications. This work addresses a more realistic\nscenario where graphs exhibit diverse modes, requiring graph grouping before or\nalong with matching, a task termed mixture graph matching and clustering. We\nintroduce Minorize-Maximization Matching and Clustering (M3C), a learning-free\nalgorithm that guarantees theoretical convergence through the\nMinorize-Maximization framework and offers enhanced flexibility via relaxed\nclustering. Building on M3C, we develop UM3C, an unsupervised model that\nincorporates novel edge-wise affinity learning and pseudo label selection.\nExtensive experimental results on public benchmarks demonstrate that our method\noutperforms state-of-the-art graph matching and mixture graph matching and\nclustering approaches in both accuracy and efficiency. Source code will be made\npublicly available.",
            "author": [
                "Jiaxin Lu",
                "Zetian Jiang",
                "Tianzhe Wang",
                "Junchi Yan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18444v1",
                "http://arxiv.org/pdf/2310.18444v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18443v1",
            "title": "Towards a fuller understanding of neurons with Clustered Compositional\n  Explanations",
            "updated": "2023-10-27T19:39:50Z",
            "published": "2023-10-27T19:39:50Z",
            "summary": "Compositional Explanations is a method for identifying logical formulas of\nconcepts that approximate the neurons' behavior. However, these explanations\nare linked to the small spectrum of neuron activations (i.e., the highest ones)\nused to check the alignment, thus lacking completeness. In this paper, we\npropose a generalization, called Clustered Compositional Explanations, that\ncombines Compositional Explanations with clustering and a novel search\nheuristic to approximate a broader spectrum of the neurons' behavior. We define\nand address the problems connected to the application of these methods to\nmultiple ranges of activations, analyze the insights retrievable by using our\nalgorithm, and propose desiderata qualities that can be used to study the\nexplanations returned by different algorithms.",
            "author": [
                "Biagio La Rosa",
                "Leilani H. Gilpin",
                "Roberto Capobianco"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18443v1",
                "http://arxiv.org/pdf/2310.18443v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18439v1",
            "title": "Machine learning detecting Majorana Zero Mode from Zero Bias Peak\n  measurements",
            "updated": "2023-10-27T19:26:55Z",
            "published": "2023-10-27T19:26:55Z",
            "summary": "Majorana zero modes (MZMs), emerging as exotic quasiparticles that carry\nnon-Abelian statistics, hold great promise for achieving fault-tolerant\ntopological quantum computation. A key signature of the presence of MZMs is the\nzero-bias peaks (ZBPs) from tunneling differential conductance. However, the\nidentification of MZMs from ZBPs has faced tremendous challenges, due to the\npresence of topological trivial states that generate spurious ZBP signals. In\nthis work, we introduce a machine-learning framework that can discern MZM from\nother signals using ZBP data. Quantum transport simulation from tight-binding\nmodels is used to generate the training data, while persistent cohomology\nanalysis confirms the feasibility of classification via machine learning. In\nparticular, even with added data noise, XGBoost classifier reaches $85\\%$\naccuracy for 1D tunneling conductance data and $94\\%$ for 2D data incorporating\nZeeman splitting. Tests on prior ZBP experiments show that some data are more\nlikely to originate from MZM than others. Our model offers a quantitative\napproach to assess MZMs using ZBP data. Furthermore, our results shed light on\nthe use of machine learning on exotic quantum systems with\nexperimental-computational integration.",
            "author": [
                "Mouyang Cheng",
                "Ryotaro Okabe",
                "Abhijatmedhi Chotrattanapituk",
                "Mingda Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18439v1",
                "http://arxiv.org/pdf/2310.18439v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall",
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18438v1",
            "title": "Exploring Shape Embedding for Cloth-Changing Person Re-Identification\n  via 2D-3D Correspondences",
            "updated": "2023-10-27T19:26:30Z",
            "published": "2023-10-27T19:26:30Z",
            "summary": "Cloth-Changing Person Re-Identification (CC-ReID) is a common and realistic\nproblem since fashion constantly changes over time and people's aesthetic\npreferences are not set in stone. While most existing cloth-changing ReID\nmethods focus on learning cloth-agnostic identity representations from coarse\nsemantic cues (e.g. silhouettes and part segmentation maps), they neglect the\ncontinuous shape distributions at the pixel level. In this paper, we propose\nContinuous Surface Correspondence Learning (CSCL), a new shape embedding\nparadigm for cloth-changing ReID. CSCL establishes continuous correspondences\nbetween a 2D image plane and a canonical 3D body surface via pixel-to-vertex\nclassification, which naturally aligns a person image to the surface of a 3D\nhuman model and simultaneously obtains pixel-wise surface embeddings. We\nfurther extract fine-grained shape features from the learned surface embeddings\nand then integrate them with global RGB features via a carefully designed\ncross-modality fusion module. The shape embedding paradigm based on 2D-3D\ncorrespondences remarkably enhances the model's global understanding of human\nbody shape. To promote the study of ReID under clothing change, we construct 3D\nDense Persons (DP3D), which is the first large-scale cloth-changing ReID\ndataset that provides densely annotated 2D-3D correspondences and a precise 3D\nmesh for each person image, while containing diverse cloth-changing cases over\nall four seasons. Experiments on both cloth-changing and cloth-consistent ReID\nbenchmarks validate the effectiveness of our method.",
            "author": [
                "Yubin Wang",
                "Huimin Yu",
                "Yuming Yan",
                "Shuyi Song",
                "Biyang Liu",
                "Yichong Lu"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3581783.3611715",
                "http://arxiv.org/abs/2310.18438v1",
                "http://arxiv.org/pdf/2310.18438v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18437v1",
            "title": "Inclination Angles for Be Stars Determined Using Machine Learning",
            "updated": "2023-10-27T19:23:55Z",
            "published": "2023-10-27T19:23:55Z",
            "summary": "We test the viability of training machine learning algorithms with synthetic\nH alpha line profiles to determine the inclination angles of Be stars (the\nangle between the central B star's rotation axis and the observer's line of\nsight) from a single observed medium-resolution, moderate S/N, spectrum. The\nperformance of three different machine learning algorithms were compared:\nneural networks tasked with regression, neural networks tasked with\nclassification, and support vector regression. Of these three algorithms,\nneural networks tasked with regression consistently outperformed the other\nmethods with a RMSE error of 7.6 degrees on an observational sample of 92\ngalactic Be stars with inclination angles known from direct H alpha profile\nfitting, from the spectroscopic signature of gravitational darkening, and, in a\nfew cases, from interferometric observations that resolved the disk. The\ntrained neural networks enable a quick and useful determination of the\ninclination angles of observed Be stars which can be used to search for\ncorrelated spin axes in young open clusters or to extract an equatorial\nrotation velocity from a measurement of v sin(i).",
            "author": [
                "B. D. Lailey",
                "T. A. A. Sigut"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18437v1",
                "http://arxiv.org/pdf/2310.18437v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18434v1",
            "title": "Bridging Distributionally Robust Learning and Offline RL: An Approach to\n  Mitigate Distribution Shift and Partial Data Coverage",
            "updated": "2023-10-27T19:19:30Z",
            "published": "2023-10-27T19:19:30Z",
            "summary": "The goal of an offline reinforcement learning (RL) algorithm is to learn\noptimal polices using historical (offline) data, without access to the\nenvironment for online exploration. One of the main challenges in offline RL is\nthe distribution shift which refers to the difference between the state-action\nvisitation distribution of the data generating policy and the learning policy.\nMany recent works have used the idea of pessimism for developing offline RL\nalgorithms and characterizing their sample complexity under a relatively weak\nassumption of single policy concentrability. Different from the offline RL\nliterature, the area of distributionally robust learning (DRL) offers a\nprincipled framework that uses a minimax formulation to tackle model mismatch\nbetween training and testing environments. In this work, we aim to bridge these\ntwo areas by showing that the DRL approach can be used to tackle the\ndistributional shift problem in offline RL. In particular, we propose two\noffline RL algorithms using the DRL framework, for the tabular and linear\nfunction approximation settings, and characterize their sample complexity under\nthe single policy concentrability assumption. We also demonstrate the superior\nperformance our proposed algorithm through simulation experiments.",
            "author": [
                "Kishan Panaganti",
                "Zaiyan Xu",
                "Dileep Kalathil",
                "Mohammad Ghavamzadeh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18434v1",
                "http://arxiv.org/pdf/2310.18434v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18430v1",
            "title": "MCRAGE: Synthetic Healthcare Data for Fairness",
            "updated": "2023-10-27T19:02:22Z",
            "published": "2023-10-27T19:02:22Z",
            "summary": "In the field of healthcare, electronic health records (EHR) serve as crucial\ntraining data for developing machine learning models for diagnosis, treatment,\nand the management of healthcare resources. However, medical datasets are often\nimbalanced in terms of sensitive attributes such as race/ethnicity, gender, and\nage. Machine learning models trained on class-imbalanced EHR datasets perform\nsignificantly worse in deployment for individuals of the minority classes\ncompared to samples from majority classes, which may lead to inequitable\nhealthcare outcomes for minority groups. To address this challenge, we propose\nMinority Class Rebalancing through Augmentation by Generative modeling\n(MCRAGE), a novel approach to augment imbalanced datasets using samples\ngenerated by a deep generative model. The MCRAGE process involves training a\nConditional Denoising Diffusion Probabilistic Model (CDDPM) capable of\ngenerating high-quality synthetic EHR samples from underrepresented classes. We\nuse this synthetic data to augment the existing imbalanced dataset, thereby\nachieving a more balanced distribution across all classes, which can be used to\ntrain an unbiased machine learning model. We measure the performance of MCRAGE\nversus alternative approaches using Accuracy, F1 score and AUROC. We provide\ntheoretical justification for our method in terms of recent convergence results\nfor DDPMs with minimal assumptions.",
            "author": [
                "Keira Behal",
                "Jiayi Chen",
                "Caleb Fikes",
                "Sophia Xiao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18430v1",
                "http://arxiv.org/pdf/2310.18430v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18428v2",
            "title": "The Bayesian Stability Zoo",
            "updated": "2023-12-05T09:50:00Z",
            "published": "2023-10-27T18:59:31Z",
            "summary": "We show that many definitions of stability found in the learning theory\nliterature are equivalent to one another. We distinguish between two families\nof definitions of stability: distribution-dependent and\ndistribution-independent Bayesian stability. Within each family, we establish\nequivalences between various definitions, encompassing approximate differential\nprivacy, pure differential privacy, replicability, global stability, perfect\ngeneralization, TV stability, mutual information stability, KL-divergence\nstability, and R\\'enyi-divergence stability. Along the way, we prove boosting\nresults that enable the amplification of the stability of a learning rule. This\nwork is a step towards a more systematic taxonomy of stability notions in\nlearning theory, which can promote clarity and an improved understanding of an\narray of stability concepts that have emerged in recent years.",
            "author": [
                "Shay Moran",
                "Hilla Schefler",
                "Jonathan Shafer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18428v2",
                "http://arxiv.org/pdf/2310.18428v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18427v1",
            "title": "Maximizing Equitable Reach and Accessibility of ETDs",
            "updated": "2023-10-27T18:57:27Z",
            "published": "2023-10-27T18:57:27Z",
            "summary": "This poster addresses accessibility issues of electronic theses and\ndissertations (ETDs) in digital libraries (DLs). ETDs are available primarily\nas PDF files, which present barriers to equitable access, especially for users\nwith visual impairments, cognitive or learning disabilities, or for anyone\nneeding more efficient and effective ways of finding relevant information\nwithin these long documents. We propose using AI techniques, including natural\nlanguage processing (NLP), computer vision, and text analysis, to convert PDFs\ninto machine-readable HTML documents with semantic tags and structure,\nextracting figures and tables, and generating summaries and keywords. Our goal\nis to increase the accessibility of ETDs and to make this important scholarship\navailable to a wider audience.",
            "author": [
                "William A. Ingram",
                "Jian Wu",
                "Edward A. Fox"
            ],
            "link": [
                "http://dx.doi.org/10.1109/JCDL57899.2023.00049",
                "http://arxiv.org/abs/2310.18427v1",
                "http://arxiv.org/pdf/2310.18427v1"
            ],
            "primary_category": "cs.DL",
            "category": [
                "cs.DL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18424v2",
            "title": "Fast Machine Learning Method with Vector Embedding on Orthonormal Basis\n  and Spectral Transform",
            "updated": "2023-11-13T16:48:01Z",
            "published": "2023-10-27T18:48:54Z",
            "summary": "This paper presents a novel fast machine learning method that leverages two\ntechniques: Vector Embedding on Orthonormal Basis (VEOB) and Spectral Transform\n(ST). The VEOB converts the original data encoding into a vector embedding with\ncoordinates projected onto orthonormal bases. The Singular Value Decomposition\n(SVD) technique is used to calculate the vector basis and projection\ncoordinates, leading to an enhanced distance measurement in the embedding space\nand facilitating data compression by preserving the projection vectors\nassociated with the largest singular values. On the other hand, ST transforms\nsequence of vector data into spectral space. By applying the Discrete Cosine\nTransform (DCT) and selecting the most significant components, it streamlines\nthe handling of lengthy vector sequences. The paper provides examples of word\nembedding, text chunk embedding, and image embedding, implemented in Julia\nlanguage with a vector database. It also investigates unsupervised learning and\nsupervised learning using this method, along with strategies for handling large\ndata volumes.",
            "author": [
                "Louis Yu Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18424v2",
                "http://arxiv.org/pdf/2310.18424v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18417v1",
            "title": "Teacher Perception of Automatically Extracted Grammar Concepts for L2\n  Language Learning",
            "updated": "2023-10-27T18:17:29Z",
            "published": "2023-10-27T18:17:29Z",
            "summary": "One of the challenges in language teaching is how best to organize rules\nregarding syntax, semantics, or phonology in a meaningful manner. This not only\nrequires content creators to have pedagogical skills, but also have that\nlanguage's deep understanding. While comprehensive materials to develop such\ncurricula are available in English and some broadly spoken languages, for many\nother languages, teachers need to manually create them in response to their\nstudents' needs. This is challenging because i) it requires that such experts\nbe accessible and have the necessary resources, and ii) describing all the\nintricacies of a language is time-consuming and prone to omission. In this\nwork, we aim to facilitate this process by automatically discovering and\nvisualizing grammar descriptions. We extract descriptions from a natural text\ncorpus that answer questions about morphosyntax (learning of word order,\nagreement, case marking, or word formation) and semantics (learning of\nvocabulary). We apply this method for teaching two Indian languages, Kannada\nand Marathi, which, unlike English, do not have well-developed resources for\nsecond language learning. To assess the perceived utility of the extracted\nmaterial, we enlist the help of language educators from schools in North\nAmerica to perform a manual evaluation, who find the materials have potential\nto be used for their lesson preparation and learner evaluation.",
            "author": [
                "Aditi Chaudhary",
                "Arun Sampath",
                "Ashwin Sheshadri",
                "Antonios Anastasopoulos",
                "Graham Neubig"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18417v1",
                "http://arxiv.org/pdf/2310.18417v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18413v1",
            "title": "On the Fairness ROAD: Robust Optimization for Adversarial Debiasing",
            "updated": "2023-10-27T18:08:42Z",
            "published": "2023-10-27T18:08:42Z",
            "summary": "In the field of algorithmic fairness, significant attention has been put on\ngroup fairness criteria, such as Demographic Parity and Equalized Odds.\nNevertheless, these objectives, measured as global averages, have raised\nconcerns about persistent local disparities between sensitive groups. In this\nwork, we address the problem of local fairness, which ensures that the\npredictor is unbiased not only in terms of expectations over the whole\npopulation, but also within any subregion of the feature space, unknown at\ntraining time. To enforce this objective, we introduce ROAD, a novel approach\nthat leverages the Distributionally Robust Optimization (DRO) framework within\na fair adversarial learning objective, where an adversary tries to infer the\nsensitive attribute from the predictions. Using an instance-level re-weighting\nstrategy, ROAD is designed to prioritize inputs that are likely to be locally\nunfair, i.e. where the adversary faces the least difficulty in reconstructing\nthe sensitive attribute. Numerical experiments demonstrate the effectiveness of\nour method: it achieves Pareto dominance with respect to local fairness and\naccuracy for a given global fairness level across three standard datasets, and\nalso enhances fairness generalization under distribution shift.",
            "author": [
                "Vincent Grari",
                "Thibault Laugel",
                "Tatsunori Hashimoto",
                "Sylvain Lamprier",
                "Marcin Detyniecki"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18413v1",
                "http://arxiv.org/pdf/2310.18413v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18411v1",
            "title": "A general learning scheme for classical and quantum Ising machines",
            "updated": "2023-10-27T18:07:02Z",
            "published": "2023-10-27T18:07:02Z",
            "summary": "An Ising machine is any hardware specifically designed for finding the ground\nstate of the Ising model. Relevant examples are coherent Ising machines and\nquantum annealers. In this paper, we propose a new machine learning model that\nis based on the Ising structure and can be efficiently trained using gradient\ndescent. We provide a mathematical characterization of the training process,\nwhich is based upon optimizing a loss function whose partial derivatives are\nnot explicitly calculated but estimated by the Ising machine itself. Moreover,\nwe present some experimental results on the training and execution of the\nproposed learning model. These results point out new possibilities offered by\nIsing machines for different learning tasks. In particular, in the quantum\nrealm, the quantum resources are used for both the execution and the training\nof the model, providing a promising perspective in quantum machine learning.",
            "author": [
                "Ludwig Schmid",
                "Enrico Zardini",
                "Davide Pastorello"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18411v1",
                "http://arxiv.org/pdf/2310.18411v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18409v1",
            "title": "State-Action Similarity-Based Representations for Off-Policy Evaluation",
            "updated": "2023-10-27T18:00:57Z",
            "published": "2023-10-27T18:00:57Z",
            "summary": "In reinforcement learning, off-policy evaluation (OPE) is the problem of\nestimating the expected return of an evaluation policy given a fixed dataset\nthat was collected by running one or more different policies. One of the more\nempirically successful algorithms for OPE has been the fitted q-evaluation\n(FQE) algorithm that uses temporal difference updates to learn an action-value\nfunction, which is then used to estimate the expected return of the evaluation\npolicy. Typically, the original fixed dataset is fed directly into FQE to learn\nthe action-value function of the evaluation policy. Instead, in this paper, we\nseek to enhance the data-efficiency of FQE by first transforming the fixed\ndataset using a learned encoder, and then feeding the transformed dataset into\nFQE. To learn such an encoder, we introduce an OPE-tailored state-action\nbehavioral similarity metric, and use this metric and the fixed dataset to\nlearn an encoder that models this metric. Theoretically, we show that this\nmetric allows us to bound the error in the resulting OPE estimate. Empirically,\nwe show that other state-action similarity metrics lead to representations that\ncannot represent the action-value function of the evaluation policy, and that\nour state-action representation method boosts the data-efficiency of FQE and\nlowers OPE error relative to other OPE-based representation learning methods on\nchallenging OPE tasks. We also empirically show that the learned\nrepresentations significantly mitigate divergence of FQE under varying\ndistribution shifts. Our code is available here:\nhttps://github.com/Badger-RL/ROPE.",
            "author": [
                "Brahma S. Pavse",
                "Josiah P. Hanna"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18409v1",
                "http://arxiv.org/pdf/2310.18409v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18313v1",
            "title": "FP8-LM: Training FP8 Large Language Models",
            "updated": "2023-10-27T17:59:51Z",
            "published": "2023-10-27T17:59:51Z",
            "summary": "In this paper, we explore FP8 low-bit data formats for efficient training of\nlarge language models (LLMs). Our key insight is that most variables, such as\ngradients and optimizer states, in LLM training can employ low-precision data\nformats without compromising model accuracy and requiring no changes to\nhyper-parameters. Specifically, we propose a new FP8 automatic mixed-precision\nframework for training LLMs. This framework offers three levels of FP8\nutilization to streamline mixed-precision and distributed parallel training for\nLLMs. It gradually incorporates 8-bit gradients, optimizer states, and\ndistributed learning in an incremental manner. Experiment results show that,\nduring the training of GPT-175B model on H100 GPU platform, our FP8\nmixed-precision training framework not only achieved a remarkable 42% reduction\nin real memory usage but also ran 64% faster than the widely adopted BF16\nframework (i.e., Megatron-LM), surpassing the speed of Nvidia Transformer\nEngine by 17%. This largely reduces the training costs for large foundation\nmodels. Furthermore, our FP8 mixed-precision training methodology is generic.\nIt can be seamlessly applied to other tasks such as LLM instruction tuning and\nreinforcement learning with human feedback, offering savings in fine-tuning\nexpenses. Our FP8 low-precision training framework is open-sourced at\n{https://github.com/Azure/MS-AMP}{aka.ms/MS.AMP}.",
            "author": [
                "Houwen Peng",
                "Kan Wu",
                "Yixuan Wei",
                "Guoshuai Zhao",
                "Yuxiang Yang",
                "Ze Liu",
                "Yifan Xiong",
                "Ziyue Yang",
                "Bolin Ni",
                "Jingcheng Hu",
                "Ruihang Li",
                "Miaosen Zhang",
                "Chen Li",
                "Jia Ning",
                "Ruizhe Wang",
                "Zheng Zhang",
                "Shuguang Liu",
                "Joe Chau",
                "Han Hu",
                "Peng Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18313v1",
                "http://arxiv.org/pdf/2310.18313v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18308v1",
            "title": "Gen2Sim: Scaling up Robot Learning in Simulation with Generative Models",
            "updated": "2023-10-27T17:55:32Z",
            "published": "2023-10-27T17:55:32Z",
            "summary": "Generalist robot manipulators need to learn a wide variety of manipulation\nskills across diverse environments. Current robot training pipelines rely on\nhumans to provide kinesthetic demonstrations or to program simulation\nenvironments and to code up reward functions for reinforcement learning. Such\nhuman involvement is an important bottleneck towards scaling up robot learning\nacross diverse tasks and environments. We propose Generation to Simulation\n(Gen2Sim), a method for scaling up robot skill learning in simulation by\nautomating generation of 3D assets, task descriptions, task decompositions and\nreward functions using large pre-trained generative models of language and\nvision. We generate 3D assets for simulation by lifting open-world 2D\nobject-centric images to 3D using image diffusion models and querying LLMs to\ndetermine plausible physics parameters. Given URDF files of generated and\nhuman-developed assets, we chain-of-thought prompt LLMs to map these to\nrelevant task descriptions, temporal decompositions, and corresponding python\nreward functions for reinforcement learning. We show Gen2Sim succeeds in\nlearning policies for diverse long horizon tasks, where reinforcement learning\nwith non temporally decomposed reward functions fails. Gen2Sim provides a\nviable path for scaling up reinforcement learning for robot manipulators in\nsimulation, both by diversifying and expanding task and environment\ndevelopment, and by facilitating the discovery of reinforcement-learned\nbehaviors through temporal task decomposition in RL. Our work contributes\nhundreds of simulated assets, tasks and demonstrations, taking a step towards\nfully autonomous robotic manipulation skill acquisition in simulation.",
            "author": [
                "Pushkal Katara",
                "Zhou Xian",
                "Katerina Fragkiadaki"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18308v1",
                "http://arxiv.org/pdf/2310.18308v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18306v2",
            "title": "Supervised and Penalized Baseline Correction",
            "updated": "2023-11-14T22:36:17Z",
            "published": "2023-10-27T17:55:17Z",
            "summary": "Spectroscopic measurements can show distorted spectral shapes arising from a\nmixture of absorbing and scattering contributions. These distortions (or\nbaselines) often manifest themselves as non-constant offsets or low-frequency\noscillations. As a result, these baselines can adversely affect analytical and\nquantitative results. Baseline correction is an umbrella term where one applies\npre-processing methods to obtain baseline spectra (the unwanted distortions)\nand then remove the distortions by differencing. However, current state-of-the\nart baseline correction methods do not utilize analyte concentrations even if\nthey are available, or even if they contribute significantly to the observed\nspectral variability. We examine a class of state-of-the-art methods (penalized\nbaseline correction) and modify them such that they can accommodate a priori\nanalyte concentrations such that prediction can be enhanced. Performance will\nbe assessed on two near infra-red data sets across both classical penalized\nbaseline correction methods (without analyte information) and modified\npenalized baseline correction methods (leveraging analyte information).",
            "author": [
                "Erik Andries",
                "Ramin Nikzad-Langerodi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18306v2",
                "http://arxiv.org/pdf/2310.18306v2"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "eess.SP",
                "15, 62"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18304v1",
            "title": "A Stability Principle for Learning under Non-Stationarity",
            "updated": "2023-10-27T17:53:53Z",
            "published": "2023-10-27T17:53:53Z",
            "summary": "We develop a versatile framework for statistical learning in non-stationary\nenvironments. In each time period, our approach applies a stability principle\nto select a look-back window that maximizes the utilization of historical data\nwhile keeping the cumulative bias within an acceptable range relative to the\nstochastic error. Our theory showcases the adaptability of this approach to\nunknown non-stationarity. The regret bound is minimax optimal up to logarithmic\nfactors when the population losses are strongly convex, or Lipschitz only. At\nthe heart of our analysis lie two novel components: a measure of similarity\nbetween functions and a segmentation technique for dividing the non-stationary\ndata sequence into quasi-stationary pieces.",
            "author": [
                "Chengpiao Huang",
                "Kaizheng Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18304v1",
                "http://arxiv.org/pdf/2310.18304v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "math.OC",
                "stat.ML",
                "68T05, 90C15"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18301v4",
            "title": "Interactive Joint Planning for Autonomous Vehicles",
            "updated": "2023-11-22T22:25:54Z",
            "published": "2023-10-27T17:48:25Z",
            "summary": "In highly interactive driving scenarios, the actions of one agent greatly\ninfluences those of its neighbors. Planning safe motions for autonomous\nvehicles in such interactive environments, therefore, requires reasoning about\nthe impact of the ego's intended motion plan on nearby agents' behavior.\nDeep-learning-based models have recently achieved great success in trajectory\nprediction and many models in the literature allow for ego-conditioned\nprediction. However, leveraging ego-conditioned prediction remains challenging\nin downstream planning due to the complex nature of neural networks, limiting\nthe planner structure to simple ones, e.g., sampling-based planner. Despite\ntheir ability to generate fine-grained high-quality motion plans, it is\ndifficult for gradient-based planning algorithms, such as model predictive\ncontrol (MPC), to leverage ego-conditioned prediction due to their iterative\nnature and need for gradient. We present Interactive Joint Planning (IJP) that\nbridges MPC with learned prediction models in a computationally scalable manner\nto provide us the best of both the worlds. In particular, IJP jointly optimizes\nover the behavior of the ego and the surrounding agents and leverages\ndeep-learned prediction models as prediction priors that the join trajectory\noptimization tries to stay close to. Furthermore, by leveraging homotopy\nclasses, our joint optimizer searches over diverse motion plans to avoid\ngetting stuck at local minima. Closed-loop simulation result shows that IJP\nsignificantly outperforms the baselines that are either without joint\noptimization or running sampling-based planning.",
            "author": [
                "Yuxiao Chen",
                "Sushant Veer",
                "Peter Karkus",
                "Marco Pavone"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18301v4",
                "http://arxiv.org/pdf/2310.18301v4"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18291v1",
            "title": "Addressing GAN Training Instabilities via Tunable Classification Losses",
            "updated": "2023-10-27T17:29:07Z",
            "published": "2023-10-27T17:29:07Z",
            "summary": "Generative adversarial networks (GANs), modeled as a zero-sum game between a\ngenerator (G) and a discriminator (D), allow generating synthetic data with\nformal guarantees. Noting that D is a classifier, we begin by reformulating the\nGAN value function using class probability estimation (CPE) losses. We prove a\ntwo-way correspondence between CPE loss GANs and $f$-GANs which minimize\n$f$-divergences. We also show that all symmetric $f$-divergences are equivalent\nin convergence. In the finite sample and model capacity setting, we define and\nobtain bounds on estimation and generalization errors. We specialize these\nresults to $\\alpha$-GANs, defined using $\\alpha$-loss, a tunable CPE loss\nfamily parametrized by $\\alpha\\in(0,\\infty]$. We next introduce a class of\ndual-objective GANs to address training instabilities of GANs by modeling each\nplayer's objective using $\\alpha$-loss to obtain $(\\alpha_D,\\alpha_G)$-GANs. We\nshow that the resulting non-zero sum game simplifies to minimizing an\n$f$-divergence under appropriate conditions on $(\\alpha_D,\\alpha_G)$.\nGeneralizing this dual-objective formulation using CPE losses, we define and\nobtain upper bounds on an appropriately defined estimation error. Finally, we\nhighlight the value of tuning $(\\alpha_D,\\alpha_G)$ in alleviating training\ninstabilities for the synthetic 2D Gaussian mixture ring as well as the large\npublicly available Celeb-A and LSUN Classroom image datasets.",
            "author": [
                "Monica Welfert",
                "Gowtham R. Kurri",
                "Kyle Otstot",
                "Lalitha Sankar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18291v1",
                "http://arxiv.org/pdf/2310.18291v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IT",
                "math.IT",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18290v1",
            "title": "An Approach to Automatically generating Riddles aiding Concept\n  Attainment",
            "updated": "2023-10-27T17:28:23Z",
            "published": "2023-10-27T17:28:23Z",
            "summary": "One of the primary challenges in online learning environments, is to retain\nlearner engagement. Several different instructional strategies are proposed\nboth in online and offline environments to enhance learner engagement. The\nConcept Attainment Model is one such instructional strategy that focuses on\nlearners acquiring a deeper understanding of a concept rather than just its\ndictionary definition. This is done by searching and listing the properties\nused to distinguish examples from non-examples of various concepts. Our work\nattempts to apply the Concept Attainment Model to build conceptual riddles, to\ndeploy over online learning environments. The approach involves creating\nfactual triples from learning resources, classifying them based on their\nuniqueness to a concept into `Topic Markers' and `Common', followed by\ngenerating riddles based on the Concept Attainment Model's format and capturing\nall possible solutions to those riddles. The results obtained from the human\nevaluation of riddles prove encouraging.",
            "author": [
                "Niharika Sri Parasa",
                "Chaitali Diwan",
                "Srinath Srinivasa"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18290v1",
                "http://arxiv.org/pdf/2310.18290v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18288v3",
            "title": "Sustainable Concrete via Bayesian Optimization",
            "updated": "2023-11-20T16:17:38Z",
            "published": "2023-10-27T17:25:12Z",
            "summary": "Eight percent of global carbon dioxide emissions can be attributed to the\nproduction of cement, the main component of concrete, which is also the\ndominant source of CO2 emissions in the construction of data centers. The\ndiscovery of lower-carbon concrete formulae is therefore of high significance\nfor sustainability. However, experimenting with new concrete formulae is time\nconsuming and labor intensive, as one usually has to wait to record the\nconcrete's 28-day compressive strength, a quantity whose measurement can by its\ndefinition not be accelerated. This provides an opportunity for experimental\ndesign methodology like Bayesian Optimization (BO) to accelerate the search for\nstrong and sustainable concrete formulae. Herein, we 1) propose modeling steps\nthat make concrete strength amenable to be predicted accurately by a Gaussian\nprocess model with relatively few measurements, 2) formulate the search for\nsustainable concrete as a multi-objective optimization problem, and 3) leverage\nthe proposed model to carry out multi-objective BO with real-world strength\nmeasurements of the algorithmically proposed mixes. Our experimental results\nshow improved trade-offs between the mixtures' global warming potential (GWP)\nand their associated compressive strengths, compared to mixes based on current\nindustry practices. Our methods are open-sourced at\ngithub.com/facebookresearch/SustainableConcrete.",
            "author": [
                "Sebastian Ament",
                "Andrew Witte",
                "Nishant Garg",
                "Julius Kusuma"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18288v3",
                "http://arxiv.org/pdf/2310.18288v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18286v1",
            "title": "Optimal Transport for Treatment Effect Estimation",
            "updated": "2023-10-27T17:22:45Z",
            "published": "2023-10-27T17:22:45Z",
            "summary": "Estimating conditional average treatment effect from observational data is\nhighly challenging due to the existence of treatment selection bias. Prevalent\nmethods mitigate this issue by aligning distributions of different treatment\ngroups in the latent space. However, there are two critical problems that these\nmethods fail to address: (1) mini-batch sampling effects (MSE), which causes\nmisalignment in non-ideal mini-batches with outcome imbalance and outliers; (2)\nunobserved confounder effects (UCE), which results in inaccurate discrepancy\ncalculation due to the neglect of unobserved confounders. To tackle these\nproblems, we propose a principled approach named Entire Space CounterFactual\nRegression (ESCFR), which is a new take on optimal transport in the context of\ncausality. Specifically, based on the framework of stochastic optimal\ntransport, we propose a relaxed mass-preserving regularizer to address the MSE\nissue and design a proximal factual outcome regularizer to handle the UCE\nissue. Extensive experiments demonstrate that our proposed ESCFR can\nsuccessfully tackle the treatment selection bias and achieve significantly\nbetter performance than state-of-the-art methods.",
            "author": [
                "Hao Wang",
                "Zhichao Chen",
                "Jiajun Fan",
                "Haoxuan Li",
                "Tianqiao Liu",
                "Weiming Liu",
                "Quanyu Dai",
                "Yichao Wang",
                "Zhenhua Dong",
                "Ruiming Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18286v1",
                "http://arxiv.org/pdf/2310.18286v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.AP",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18285v2",
            "title": "Unlocking the Potential of Prompt-Tuning in Bridging Generalized and\n  Personalized Federated Learning",
            "updated": "2023-11-24T06:49:25Z",
            "published": "2023-10-27T17:22:09Z",
            "summary": "Vision Transformers (ViT) and Visual Prompt Tuning (VPT) achieve\nstate-of-the-art performance with improved efficiency in various computer\nvision tasks. This suggests a promising paradigm shift of adapting pre-trained\nViT models to Federated Learning (FL) settings. However, the challenge of data\nheterogeneity among FL clients presents a significant hurdle in effectively\ndeploying ViT models. Existing Generalized FL (GFL) and Personalized FL (PFL)\nmethods have limitations in balancing performance across both global and local\ndata distributions. In this paper, we present a novel algorithm, SGPT, that\nintegrates GFL and PFL approaches by employing a unique combination of both\nshared and group-specific prompts. This design enables SGPT to capture both\ncommon and group-specific features. A key feature of SGPT is its prompt\nselection module, which facilitates the training of a single global model\ncapable of automatically adapting to diverse local client data distributions\nwithout the need for local fine-tuning. To effectively train the prompts, we\nutilize block coordinate descent (BCD), learning from common feature\ninformation (shared prompts), and then more specialized knowledge (group\nprompts) iteratively. Theoretically, we justify that learning the proposed\nprompts can reduce the gap between global and local performance. Empirically,\nwe conduct experiments on both label and feature heterogeneity settings in\ncomparison with state-of-the-art baselines, along with extensive ablation\nstudies, to substantiate the superior performance of SGPT.",
            "author": [
                "Wenlong Deng",
                "Christos Thrampoulidis",
                "Xiaoxiao Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18285v2",
                "http://arxiv.org/pdf/2310.18285v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18281v1",
            "title": "Exploring Non-Linear Programming Formulations in QuantumCircuitOpt for\n  Optimal Circuit Design",
            "updated": "2023-10-27T17:16:58Z",
            "published": "2023-10-27T17:16:58Z",
            "summary": "Given the limitations of current hardware, the theoretical gains promised by\nquantum computing remain unrealized across practical applications. But the gap\nbetween theory and hardware is closing, assisted by developments in quantum\nalgorithmic modeling. One such recent development is QuantumCircuitOpt (QCOpt),\nan open-source software framework that leverages state-of-the-art\noptimization-based solvers to find provably optimal compact circuit\ndecompositions, which are exact up to global phase and machine precision. The\nquantum circuit design problem can be modeled using non-linear, non-convex\nconstraints. However, QCOpt reformulates these non-linear constraints using\nwell-known linearization techniques such that the resulting design problem is\nsolved as a Mixed-Integer Linear Programming (MILP) model. In this work, we\ninstead explore whether the QCOpt could also be effective with a continuous\nNon-Linear Programming (NLP) model obtained via relaxation of the integer\nvariables in the non-linear constraints. We are able to present not only\nmultiple significant enhancements to QCOpt, with up to 11.3x speed-up in run\ntimes on average, but also opportunities for more generally exploring the\nbehavior of gradient-based NLP solvers.",
            "author": [
                "Elena R. Henderson",
                "Harsha Nagarajan",
                "Carleton Coffrin"
            ],
            "link": [
                "http://dx.doi.org/10.1109/QCS56647.2022.00009",
                "http://arxiv.org/abs/2310.18281v1",
                "http://arxiv.org/pdf/2310.18281v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18280v1",
            "title": "Universality for the global spectrum of random inner-product kernel\n  matrices in the polynomial regime",
            "updated": "2023-10-27T17:15:55Z",
            "published": "2023-10-27T17:15:55Z",
            "summary": "We consider certain large random matrices, called random inner-product kernel\nmatrices, which are essentially given by a nonlinear function $f$ applied\nentrywise to a sample-covariance matrix, $f(X^TX)$, where $X \\in \\mathbb{R}^{d\n\\times N}$ is random and normalized in such a way that $f$ typically has\norder-one arguments. We work in the polynomial regime, where $N \\asymp d^\\ell$\nfor some $\\ell > 0$, not just the linear regime where $\\ell = 1$. Earlier work\nby various authors showed that, when the columns of $X$ are either uniform on\nthe sphere or standard Gaussian vectors, and when $\\ell$ is an integer (the\nlinear regime $\\ell = 1$ is particularly well-studied), the bulk eigenvalues of\nsuch matrices behave in a simple way: They are asymptotically given by the free\nconvolution of the semicircular and Mar\\v{c}enko-Pastur distributions, with\nrelative weights given by expanding $f$ in the Hermite basis. In this paper, we\nshow that this phenomenon is universal, holding as soon as $X$ has i.i.d.\nentries with all finite moments. In the case of non-integer $\\ell$, the\nMar\\v{c}enko-Pastur term disappears (its weight in the free convolution\nvanishes), and the spectrum is just semicircular.",
            "author": [
                "Sofiia Dubova",
                "Yue M. Lu",
                "Benjamin McKenna",
                "Horng-Tzer Yau"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18280v1",
                "http://arxiv.org/pdf/2310.18280v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "stat.ML",
                "60B20, 15B52"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18278v1",
            "title": "Navigating protein landscapes with a machine-learned transferable\n  coarse-grained model",
            "updated": "2023-10-27T17:10:23Z",
            "published": "2023-10-27T17:10:23Z",
            "summary": "The most popular and universally predictive protein simulation models employ\nall-atom molecular dynamics (MD), but they come at extreme computational cost.\nThe development of a universal, computationally efficient coarse-grained (CG)\nmodel with similar prediction performance has been a long-standing challenge.\nBy combining recent deep learning methods with a large and diverse training set\nof all-atom protein simulations, we here develop a bottom-up CG force field\nwith chemical transferability, which can be used for extrapolative molecular\ndynamics on new sequences not used during model parametrization. We demonstrate\nthat the model successfully predicts folded structures, intermediates,\nmetastable folded and unfolded basins, and the fluctuations of intrinsically\ndisordered proteins while it is several orders of magnitude faster than an\nall-atom model. This showcases the feasibility of a universal and\ncomputationally efficient machine-learned CG model for proteins.",
            "author": [
                "Nicholas E. Charron",
                "Felix Musil",
                "Andrea Guljas",
                "Yaoyi Chen",
                "Klara Bonneau",
                "Aldo S. Pasos-Trejo",
                "Jacopo Venturin",
                "Daria Gusew",
                "Iryna Zaporozhets",
                "Andreas Kr\u00e4mer",
                "Clark Templeton",
                "Atharva Kelkar",
                "Aleksander E. P. Durumeric",
                "Simon Olsson",
                "Adri\u00e0 P\u00e9rez",
                "Maciej Majewski",
                "Brooke E. Husic",
                "Ankit Patel",
                "Gianni De Fabritiis",
                "Frank No\u00e9",
                "Cecilia Clementi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18278v1",
                "http://arxiv.org/pdf/2310.18278v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM",
                "physics.bio-ph",
                "physics.chem-ph",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18390v1",
            "title": "Entity Embeddings : Perspectives Towards an Omni-Modality Era for Large\n  Language Models",
            "updated": "2023-10-27T17:04:10Z",
            "published": "2023-10-27T17:04:10Z",
            "summary": "Large Language Models (LLMs) are evolving to integrate multiple modalities,\nsuch as text, image, and audio into a unified linguistic space. We envision a\nfuture direction based on this framework where conceptual entities defined in\nsequences of text can also be imagined as modalities. Such a formulation has\nthe potential to overcome the cognitive and computational limitations of\ncurrent models. Several illustrative examples of such potential implicit\nmodalities are given. Along with vast promises of the hypothesized structure,\nexpected challenges are discussed as well.",
            "author": [
                "Eren Unlu",
                "Unver Ciftci"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18390v1",
                "http://arxiv.org/pdf/2310.18390v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18274v1",
            "title": "LipSim: A Provably Robust Perceptual Similarity Metric",
            "updated": "2023-10-27T16:59:51Z",
            "published": "2023-10-27T16:59:51Z",
            "summary": "Recent years have seen growing interest in developing and applying perceptual\nsimilarity metrics. Research has shown the superiority of perceptual metrics\nover pixel-wise metrics in aligning with human perception and serving as a\nproxy for the human visual system. On the other hand, as perceptual metrics\nrely on neural networks, there is a growing concern regarding their resilience,\ngiven the established vulnerability of neural networks to adversarial attacks.\nIt is indeed logical to infer that perceptual metrics may inherit both the\nstrengths and shortcomings of neural networks. In this work, we demonstrate the\nvulnerability of state-of-the-art perceptual similarity metrics based on an\nensemble of ViT-based feature extractors to adversarial attacks. We then\npropose a framework to train a robust perceptual similarity metric called\nLipSim (Lipschitz Similarity Metric) with provable guarantees. By leveraging\n1-Lipschitz neural networks as the backbone, LipSim provides guarded areas\naround each data point and certificates for all perturbations within an\n$\\ell_2$ ball. Finally, a comprehensive set of experiments shows the\nperformance of LipSim in terms of natural and certified scores and on the image\nretrieval application. The code is available at\nhttps://github.com/SaraGhazanfari/LipSim.",
            "author": [
                "Sara Ghazanfari",
                "Alexandre Araujo",
                "Prashanth Krishnamurthy",
                "Farshad Khorrami",
                "Siddharth Garg"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18274v1",
                "http://arxiv.org/pdf/2310.18274v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18268v1",
            "title": "PlantPlotGAN: A Physics-Informed Generative Adversarial Network for\n  Plant Disease Prediction",
            "updated": "2023-10-27T16:56:28Z",
            "published": "2023-10-27T16:56:28Z",
            "summary": "Monitoring plantations is crucial for crop management and producing healthy\nharvests. Unmanned Aerial Vehicles (UAVs) have been used to collect\nmultispectral images that aid in this monitoring. However, given the number of\nhectares to be monitored and the limitations of flight, plant disease signals\nbecome visually clear only in the later stages of plant growth and only if the\ndisease has spread throughout a significant portion of the plantation. This\nlimited amount of relevant data hampers the prediction models, as the\nalgorithms struggle to generalize patterns with unbalanced or unrealistic\naugmented datasets effectively. To address this issue, we propose PlantPlotGAN,\na physics-informed generative model capable of creating synthetic multispectral\nplot images with realistic vegetation indices. These indices served as a proxy\nfor disease detection and were used to evaluate if our model could help\nincrease the accuracy of prediction models. The results demonstrate that the\nsynthetic imagery generated from PlantPlotGAN outperforms state-of-the-art\nmethods regarding the Fr\\'echet inception distance. Moreover, prediction models\nachieve higher accuracy metrics when trained with synthetic and original\nimagery for earlier plant disease detection compared to the training processes\nbased solely on real imagery.",
            "author": [
                "Felipe A. Lopes",
                "Vasit Sagan",
                "Flavio Esposito"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18268v1",
                "http://arxiv.org/pdf/2310.18268v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18265v1",
            "title": "Structured Semidefinite Programming for Recovering Structured\n  Preconditioners",
            "updated": "2023-10-27T16:54:29Z",
            "published": "2023-10-27T16:54:29Z",
            "summary": "We develop a general framework for finding approximately-optimal\npreconditioners for solving linear systems. Leveraging this framework we obtain\nimproved runtimes for fundamental preconditioning and linear system solving\nproblems including the following. We give an algorithm which, given positive\ndefinite $\\mathbf{K} \\in \\mathbb{R}^{d \\times d}$ with\n$\\mathrm{nnz}(\\mathbf{K})$ nonzero entries, computes an $\\epsilon$-optimal\ndiagonal preconditioner in time $\\widetilde{O}(\\mathrm{nnz}(\\mathbf{K}) \\cdot\n\\mathrm{poly}(\\kappa^\\star,\\epsilon^{-1}))$, where $\\kappa^\\star$ is the\noptimal condition number of the rescaled matrix. We give an algorithm which,\ngiven $\\mathbf{M} \\in \\mathbb{R}^{d \\times d}$ that is either the pseudoinverse\nof a graph Laplacian matrix or a constant spectral approximation of one, solves\nlinear systems in $\\mathbf{M}$ in $\\widetilde{O}(d^2)$ time. Our diagonal\npreconditioning results improve state-of-the-art runtimes of $\\Omega(d^{3.5})$\nattained by general-purpose semidefinite programming, and our solvers improve\nstate-of-the-art runtimes of $\\Omega(d^{\\omega})$ where $\\omega > 2.3$ is the\ncurrent matrix multiplication constant. We attain our results via new\nalgorithms for a class of semidefinite programs (SDPs) we call\nmatrix-dictionary approximation SDPs, which we leverage to solve an associated\nproblem we call matrix-dictionary recovery.",
            "author": [
                "Arun Jambulapati",
                "Jerry Li",
                "Christopher Musco",
                "Kirankumar Shiragur",
                "Aaron Sidford",
                "Kevin Tian"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18265v1",
                "http://arxiv.org/pdf/2310.18265v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.LG",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18264v1",
            "title": "Learning to Search Feasible and Infeasible Regions of Routing Problems\n  with Flexible Neural k-Opt",
            "updated": "2023-10-27T16:51:41Z",
            "published": "2023-10-27T16:51:41Z",
            "summary": "In this paper, we present Neural k-Opt (NeuOpt), a novel learning-to-search\n(L2S) solver for routing problems. It learns to perform flexible k-opt\nexchanges based on a tailored action factorization method and a customized\nrecurrent dual-stream decoder. As a pioneering work to circumvent the pure\nfeasibility masking scheme and enable the autonomous exploration of both\nfeasible and infeasible regions, we then propose the Guided Infeasible Region\nExploration (GIRE) scheme, which supplements the NeuOpt policy network with\nfeasibility-related features and leverages reward shaping to steer\nreinforcement learning more effectively. Additionally, we equip NeuOpt with\nDynamic Data Augmentation (D2A) for more diverse searches during inference.\nExtensive experiments on the Traveling Salesman Problem (TSP) and Capacitated\nVehicle Routing Problem (CVRP) demonstrate that our NeuOpt not only\nsignificantly outstrips existing (masking-based) L2S solvers, but also\nshowcases superiority over the learning-to-construct (L2C) and\nlearning-to-predict (L2P) solvers. Notably, we offer fresh perspectives on how\nneural solvers can handle VRP constraints. Our code is available:\nhttps://github.com/yining043/NeuOpt.",
            "author": [
                "Yining Ma",
                "Zhiguang Cao",
                "Yeow Meng Chee"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18264v1",
                "http://arxiv.org/pdf/2310.18264v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18263v1",
            "title": "MalFake: A Multimodal Fake News Identification for Malayalam using\n  Recurrent Neural Networks and VGG-16",
            "updated": "2023-10-27T16:51:29Z",
            "published": "2023-10-27T16:51:29Z",
            "summary": "The amount of news being consumed online has substantially expanded in recent\nyears. Fake news has become increasingly common, especially in regional\nlanguages like Malayalam, due to the rapid publication and lack of editorial\nstandards on some online sites. Fake news may have a terrible effect on\nsociety, causing people to make bad judgments, lose faith in authorities, and\neven engage in violent behavior. When we take into the context of India, there\nare many regional languages, and fake news is spreading in every language.\nTherefore, providing efficient techniques for identifying false information in\nregional tongues is crucial. Until now, little to no work has been done in\nMalayalam, extracting features from multiple modalities to classify fake news.\nMultimodal approaches are more accurate in detecting fake news, as features\nfrom multiple modalities are extracted to build the deep learning\nclassification model. As far as we know, this is the first piece of work in\nMalayalam that uses multimodal deep learning to tackle false information.\nModels trained with more than one modality typically outperform models taught\nwith only one modality. Our study in the Malayalam language utilizing\nmultimodal deep learning is a significant step toward more effective\nmisinformation detection and mitigation.",
            "author": [
                "Adhish S. Sujan",
                "Ajitha. V",
                "Aleena Benny",
                "Amiya M. P.",
                "V. S. Anoop"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18263v1",
                "http://arxiv.org/pdf/2310.18263v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18261v1",
            "title": "Label Shift Estimators for Non-Ignorable Missing Data",
            "updated": "2023-10-27T16:50:13Z",
            "published": "2023-10-27T16:50:13Z",
            "summary": "We consider the problem of estimating the mean of a random variable Y subject\nto non-ignorable missingness, i.e., where the missingness mechanism depends on\nY . We connect the auxiliary proxy variable framework for non-ignorable\nmissingness (West and Little, 2013) to the label shift setting (Saerens et al.,\n2002). Exploiting this connection, we construct an estimator for non-ignorable\nmissing data that uses high-dimensional covariates (or proxies) without the\nneed for a generative model. In synthetic and semi-synthetic experiments, we\nstudy the behavior of the proposed estimator, comparing it to commonly used\nignorable estimators in both well-specified and misspecified settings.\nAdditionally, we develop a score to assess how consistent the data are with the\nlabel shift assumption. We use our approach to estimate disease prevalence\nusing a large health survey, comparing ignorable and non-ignorable approaches.\nWe show that failing to account for non-ignorable missingness can have profound\nconsequences on conclusions drawn from non-representative samples.",
            "author": [
                "Andrew C. Miller",
                "Joseph Futoma"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18261v1",
                "http://arxiv.org/pdf/2310.18261v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18260v1",
            "title": "Concepts and Paradigms for Neuromorphic Programming",
            "updated": "2023-10-27T16:48:11Z",
            "published": "2023-10-27T16:48:11Z",
            "summary": "The value of neuromorphic computers depends crucially on our ability to\nprogram them for relevant tasks. Currently, neuromorphic computers are mostly\nlimited to machine learning methods adapted from deep learning. However,\nneuromorphic computers have potential far beyond deep learning if we can only\nmake use of their computational properties to harness their full power.\nNeuromorphic programming will necessarily be different from conventional\nprogramming, requiring a paradigm shift in how we think about programming in\ngeneral. The contributions of this paper are 1) a conceptual analysis of what\n\"programming\" means in the context of neuromorphic computers and 2) an\nexploration of existing programming paradigms that are promising yet overlooked\nin neuromorphic computing. The goal is to expand the horizon of neuromorphic\nprogramming methods, thereby allowing researchers to move beyond the shackles\nof current methods and explore novel directions.",
            "author": [
                "Steven Abreu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18260v1",
                "http://arxiv.org/pdf/2310.18260v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.ET"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18251v1",
            "title": "A Self-Supervised Approach to Land Cover Segmentation",
            "updated": "2023-10-27T16:37:36Z",
            "published": "2023-10-27T16:37:36Z",
            "summary": "Land use/land cover change (LULC) maps are integral resources in earth\nscience and agricultural research. Due to the nature of such maps, the creation\nof LULC maps is often constrained by the time and human resources necessary to\naccurately annotate satellite imagery and remote sensing data. While computer\nvision models that perform semantic segmentation to create detailed labels from\nsuch data are not uncommon, litle research has been done on self-supervised and\nunsupervised approaches to labelling LULC maps without the use of ground-truth\nmasks. Here, we demonstrate a self-supervised method of land cover segmentation\nthat has no need for high-quality ground truth labels. The proposed deep\nlearning employs a frozen pre-trained ViT backbone transferred from DINO in a\nSTEGO architecture and is fine-tuned using a custom dataset consisting of very\nhigh resolution (VHR) sattelite imagery. After only 10 epochs of fine-tuning,\nan accuracy of roughly 52% was observed across 5 samples, signifying the\nfeasibility of self-supervised models for the automated labelling of VHR LULC\nmaps.",
            "author": [
                "Charles Moore",
                "Dakota Hester"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18251v1",
                "http://arxiv.org/pdf/2310.18251v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18249v1",
            "title": "Leveraging Machine Learning Models for Peptide-Protein Interaction\n  Prediction",
            "updated": "2023-10-27T16:36:06Z",
            "published": "2023-10-27T16:36:06Z",
            "summary": "Peptides play a pivotal role in a wide range of biological activities through\nparticipating in up to 40% protein-protein interactions in cellular processes.\nThey also demonstrate remarkable specificity and efficacy, making them\npromising candidates for drug development. However, predicting peptide-protein\ncomplexes by traditional computational approaches, such as Docking and\nMolecular Dynamics simulations, still remains a challenge due to high\ncomputational cost, flexible nature of peptides, and limited structural\ninformation of peptide-protein complexes. In recent years, the surge of\navailable biological data has given rise to the development of an increasing\nnumber of machine learning models for predicting peptide-protein interactions.\nThese models offer efficient solutions to address the challenges associated\nwith traditional computational approaches. Furthermore, they offer enhanced\naccuracy, robustness, and interpretability in their predictive outcomes. This\nreview presents a comprehensive overview of machine learning and deep learning\nmodels that have emerged in recent years for the prediction of peptide-protein\ninteractions.",
            "author": [
                "Song Yin",
                "Xuenan Mi",
                "Diwakar Shukla"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18249v1",
                "http://arxiv.org/pdf/2310.18249v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18247v1",
            "title": "Guided Data Augmentation for Offline Reinforcement Learning and\n  Imitation Learning",
            "updated": "2023-10-27T16:34:00Z",
            "published": "2023-10-27T16:34:00Z",
            "summary": "Learning from demonstration (LfD) is a popular technique that uses expert\ndemonstrations to learn robot control policies. However, the difficulty in\nacquiring expert-quality demonstrations limits the applicability of LfD\nmethods: real-world data collection is often costly, and the quality of the\ndemonstrations depends greatly on the demonstrator's abilities and safety\nconcerns. A number of works have leveraged data augmentation (DA) to\ninexpensively generate additional demonstration data, but most DA works\ngenerate augmented data in a random fashion and ultimately produce highly\nsuboptimal data. In this work, we propose Guided Data Augmentation (GuDA), a\nhuman-guided DA framework that generates expert-quality augmented data. The key\ninsight of GuDA is that while it may be difficult to demonstrate the sequence\nof actions required to produce expert data, a user can often easily identify\nwhen an augmented trajectory segment represents task progress. Thus, the user\ncan impose a series of simple rules on the DA process to automatically generate\naugmented samples that approximate expert behavior. To extract a policy from\nGuDA, we use off-the-shelf offline reinforcement learning and behavior cloning\nalgorithms. We evaluate GuDA on a physical robot soccer task as well as\nsimulated D4RL navigation tasks, a simulated autonomous driving task, and a\nsimulated soccer task. Empirically, we find that GuDA enables learning from a\nsmall set of potentially suboptimal demonstrations and substantially\noutperforms a DA strategy that samples augmented data randomly.",
            "author": [
                "Nicholas E. Corrado",
                "Yuxiao Qu",
                "John U. Balis",
                "Adam Labiosa",
                "Josiah P. Hanna"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18247v1",
                "http://arxiv.org/pdf/2310.18247v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18241v1",
            "title": "$\u03b1$-Mutual Information: A Tunable Privacy Measure for Privacy\n  Protection in Data Sharing",
            "updated": "2023-10-27T16:26:14Z",
            "published": "2023-10-27T16:26:14Z",
            "summary": "This paper adopts Arimoto's $\\alpha$-Mutual Information as a tunable privacy\nmeasure, in a privacy-preserving data release setting that aims to prevent\ndisclosing private data to adversaries. By fine-tuning the privacy metric, we\ndemonstrate that our approach yields superior models that effectively thwart\nattackers across various performance dimensions. We formulate a general\ndistortion-based mechanism that manipulates the original data to offer privacy\nprotection. The distortion metrics are determined according to the data\nstructure of a specific experiment. We confront the problem expressed in the\nformulation by employing a general adversarial deep learning framework that\nconsists of a releaser and an adversary, trained with opposite goals. This\nstudy conducts empirical experiments on images and time-series data to verify\nthe functionality of $\\alpha$-Mutual Information. We evaluate the\nprivacy-utility trade-off of customized models and compare them to mutual\ninformation as the baseline measure. Finally, we analyze the consequence of an\nattacker's access to side information about private data and witness that\nadapting the privacy measure results in a more refined model than the\nstate-of-the-art in terms of resiliency against side information.",
            "author": [
                "MirHamed Jafarzadeh Asl",
                "Mohammadhadi Shateri",
                "Fabrice Labeau"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18241v1",
                "http://arxiv.org/pdf/2310.18241v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18237v2",
            "title": "Generative AI Model for Artistic Style Transfer Using Convolutional\n  Neural Networks",
            "updated": "2023-10-30T16:55:43Z",
            "published": "2023-10-27T16:21:17Z",
            "summary": "Artistic style transfer, a captivating application of generative artificial\nintelligence, involves fusing the content of one image with the artistic style\nof another to create unique visual compositions. This paper presents a\ncomprehensive overview of a novel technique for style transfer using\nConvolutional Neural Networks (CNNs). By leveraging deep image representations\nlearned by CNNs, we demonstrate how to separate and manipulate image content\nand style, enabling the synthesis of high-quality images that combine content\nand style in a harmonious manner. We describe the methodology, including\ncontent and style representations, loss computation, and optimization, and\nshowcase experimental results highlighting the effectiveness and versatility of\nthe approach across different styles and content",
            "author": [
                "Jonayet Miah",
                "Duc M Cao",
                "Md Abu Sayed",
                "Md. Sabbirul Haque"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18237v2",
                "http://arxiv.org/pdf/2310.18237v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18236v1",
            "title": "How Re-sampling Helps for Long-Tail Learning?",
            "updated": "2023-10-27T16:20:34Z",
            "published": "2023-10-27T16:20:34Z",
            "summary": "Long-tail learning has received significant attention in recent years due to\nthe challenge it poses with extremely imbalanced datasets. In these datasets,\nonly a few classes (known as the head classes) have an adequate number of\ntraining samples, while the rest of the classes (known as the tail classes) are\ninfrequent in the training data. Re-sampling is a classical and widely used\napproach for addressing class imbalance issues. Unfortunately, recent studies\nclaim that re-sampling brings negligible performance improvements in modern\nlong-tail learning tasks. This paper aims to investigate this phenomenon\nsystematically. Our research shows that re-sampling can considerably improve\ngeneralization when the training images do not contain semantically irrelevant\ncontexts. In other scenarios, however, it can learn unexpected spurious\ncorrelations between irrelevant contexts and target labels. We design\nexperiments on two homogeneous datasets, one containing irrelevant context and\nthe other not, to confirm our findings. To prevent the learning of spurious\ncorrelations, we propose a new context shift augmentation module that generates\ndiverse training images for the tail class by maintaining a context bank\nextracted from the head-class images. Experiments demonstrate that our proposed\nmodule can boost the generalization and outperform other approaches, including\nclass-balanced re-sampling, decoupled classifier re-training, and data\naugmentation methods. The source code is available at\nhttps://www.lamda.nju.edu.cn/code_CSA.ashx.",
            "author": [
                "Jiang-Xin Shi",
                "Tong Wei",
                "Yuke Xiang",
                "Yu-Feng Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18236v1",
                "http://arxiv.org/pdf/2310.18236v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18235v2",
            "title": "Davidsonian Scene Graph: Improving Reliability in Fine-grained\n  Evaluation for Text-to-Image Generation",
            "updated": "2023-10-30T16:00:49Z",
            "published": "2023-10-27T16:20:10Z",
            "summary": "Evaluating text-to-image models is notoriously difficult. A strong recent\napproach for assessing text-image faithfulness is based on QG/A (question\ngeneration and answering), which uses pre-trained foundational models to\nautomatically generate a set of questions and answers from the prompt, and\noutput images are scored based on whether these answers extracted with a visual\nquestion answering model are consistent with the prompt-based answers. This\nkind of evaluation is naturally dependent on the quality of the underlying QG\nand QA models. We identify and address several reliability challenges in\nexisting QG/A work: (a) QG questions should respect the prompt (avoiding\nhallucinations, duplications, and omissions) and (b) VQA answers should be\nconsistent (not asserting that there is no motorcycle in an image while also\nclaiming the motorcycle is blue). We address these issues with Davidsonian\nScene Graph (DSG), an empirically grounded evaluation framework inspired by\nformal semantics. DSG is an automatic, graph-based QG/A that is modularly\nimplemented to be adaptable to any QG/A module. DSG produces atomic and unique\nquestions organized in dependency graphs, which (i) ensure appropriate semantic\ncoverage and (ii) sidestep inconsistent answers. With extensive experimentation\nand human evaluation on a range of model configurations (LLM, VQA, and T2I), we\nempirically demonstrate that DSG addresses the challenges noted above. Finally,\nwe present DSG-1k, an open-sourced evaluation benchmark that includes 1,060\nprompts, covering a wide range of fine-grained semantic categories with a\nbalanced distribution. We release the DSG-1k prompts and the corresponding DSG\nquestions.",
            "author": [
                "Jaemin Cho",
                "Yushi Hu",
                "Roopal Garg",
                "Peter Anderson",
                "Ranjay Krishna",
                "Jason Baldridge",
                "Mohit Bansal",
                "Jordi Pont-Tuset",
                "Su Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18235v2",
                "http://arxiv.org/pdf/2310.18235v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18234v1",
            "title": "Edge AI-Based Vein Detector for Efficient Venipuncture in the\n  Antecubital Fossa",
            "updated": "2023-10-27T16:19:26Z",
            "published": "2023-10-27T16:19:26Z",
            "summary": "Assessing the condition and visibility of veins is a crucial step before\nobtaining intravenous access in the antecubital fossa, which is a common\nprocedure to draw blood or administer intravenous therapies (IV therapies).\nEven though medical practitioners are highly skilled at intravenous\ncannulation, they usually struggle to perform the procedure in patients with\nlow visible veins due to fluid retention, age, overweight, dark skin tone, or\ndiabetes. Recently, several investigations proposed combining Near Infrared\n(NIR) imaging and deep learning (DL) techniques for forearm vein segmentation.\nAlthough they have demonstrated compelling results, their use has been rather\nlimited owing to the portability and precision requirements to perform\nvenipuncture. In this paper, we aim to contribute to bridging this gap using\nthree strategies. First, we introduce a new NIR-based forearm vein segmentation\ndataset of 2,016 labelled images collected from 1,008 subjects with low visible\nveins. Second, we propose a modified U-Net architecture that locates veins\nspecifically in the antecubital fossa region of the examined patient. Finally,\na compressed version of the proposed architecture was deployed inside a\nbespoke, portable vein finder device after testing four common embedded\nmicrocomputers and four common quantization modalities. Experimental results\nshowed that the model compressed with Dynamic Range Quantization and deployed\non a Raspberry Pi 4B card produced the best execution time and precision\nbalance, with 5.14 FPS and 0.957 of latency and Intersection over Union (IoU),\nrespectively. These results show promising performance inside a\nresource-restricted low-cost device.",
            "author": [
                "Edwin Salcedo",
                "Patricia Pe\u00f1aloza"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-031-47640-2_24",
                "http://arxiv.org/abs/2310.18234v1",
                "http://arxiv.org/pdf/2310.18234v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18230v2",
            "title": "Deep Transformed Gaussian Processes",
            "updated": "2023-11-02T10:25:56Z",
            "published": "2023-10-27T16:09:39Z",
            "summary": "Transformed Gaussian Processes (TGPs) are stochastic processes specified by\ntransforming samples from the joint distribution from a prior process\n(typically a GP) using an invertible transformation; increasing the flexibility\nof the base process.\n  Furthermore, they achieve competitive results compared with Deep Gaussian\nProcesses (DGPs), which are another generalization constructed by a\nhierarchical concatenation of GPs. In this work, we propose a generalization of\nTGPs named Deep Transformed Gaussian Processes (DTGPs), which follows the trend\nof concatenating layers of stochastic processes. More precisely, we obtain a\nmulti-layer model in which each layer is a TGP. This generalization implies an\nincrement of flexibility with respect to both TGPs and DGPs. Exact inference in\nsuch a model is intractable. However, we show that one can use variational\ninference to approximate the required computations yielding a straightforward\nextension of the popular DSVI inference algorithm Salimbeni et al (2017). The\nexperiments conducted evaluate the proposed novel DTGPs in multiple regression\ndatasets, achieving good scalability and performance.",
            "author": [
                "Francisco Javier S\u00e1ez-Maldonado",
                "Juan Maro\u00f1as",
                "Daniel Hern\u00e1ndez-Lobato"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18230v2",
                "http://arxiv.org/pdf/2310.18230v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18222v1",
            "title": "TBDLNet: a network for classifying multidrug-resistant and\n  drug-sensitive tuberculosis",
            "updated": "2023-10-27T15:51:33Z",
            "published": "2023-10-27T15:51:33Z",
            "summary": "This paper proposes applying a novel deep-learning model, TBDLNet, to\nrecognize CT images to classify multidrug-resistant and drug-sensitive\ntuberculosis automatically. The pre-trained ResNet50 is selected to extract\nfeatures. Three randomized neural networks are used to alleviate the\noverfitting problem. The ensemble of three RNNs is applied to boost the\nrobustness via majority voting. The proposed model is evaluated by five-fold\ncross-validation. Five indexes are selected in this paper, which are accuracy,\nsensitivity, precision, F1-score, and specificity. The TBDLNet achieves 0.9822\naccuracy, 0.9815 specificity, 0.9823 precision, 0.9829 sensitivity, and 0.9826\nF1-score, respectively. The TBDLNet is suitable for classifying\nmultidrug-resistant tuberculosis and drug-sensitive tuberculosis. It can detect\nmultidrug-resistant pulmonary tuberculosis as early as possible, which helps to\nadjust the treatment plan in time and improve the treatment effect.",
            "author": [
                "Ziquan Zhu",
                "Jing Tao",
                "Shuihua Wang",
                "Xin Zhang",
                "Yudong Zhang"
            ],
            "link": [
                "http://dx.doi.org/10.1002/ENG2.12815",
                "http://arxiv.org/abs/2310.18222v1",
                "http://arxiv.org/pdf/2310.18222v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18215v1",
            "title": "One Model Fits All: Cross-Region Taxi-Demand Forecasting",
            "updated": "2023-10-27T15:42:04Z",
            "published": "2023-10-27T15:42:04Z",
            "summary": "The growing demand for ride-hailing services has led to an increasing need\nfor accurate taxi demand prediction. Existing systems are limited to specific\nregions, lacking generalizability to unseen areas. This paper presents a novel\ntaxi demand forecasting system that leverages a graph neural network to capture\nspatial dependencies and patterns in urban environments. Additionally, the\nproposed system employs a region-neutral approach, enabling it to train a model\nthat can be applied to any region, including unseen regions. To achieve this,\nthe framework incorporates the power of Variational Autoencoder to disentangle\nthe input features into region-specific and region-neutral components. The\nregion-neutral features facilitate cross-region taxi demand predictions,\nallowing the model to generalize well across different urban areas.\nExperimental results demonstrate the effectiveness of the proposed system in\naccurately forecasting taxi demand, even in previously unobserved regions, thus\nshowcasing its potential for optimizing taxi services and improving\ntransportation efficiency on a broader scale.",
            "author": [
                "Ren Ozeki",
                "Haruki Yonekura",
                "Aidana Baimbetova",
                "Hamada Rizk",
                "Hirozumi Yamaguchi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18215v1",
                "http://arxiv.org/pdf/2310.18215v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18212v1",
            "title": "Robustness of Algorithms for Causal Structure Learning to Hyperparameter\n  Choice",
            "updated": "2023-10-27T15:34:08Z",
            "published": "2023-10-27T15:34:08Z",
            "summary": "Hyperparameters play a critical role in machine learning. Hyperparameter\ntuning can make the difference between state-of-the-art and poor prediction\nperformance for any algorithm, but it is particularly challenging for structure\nlearning due to its unsupervised nature. As a result, hyperparameter tuning is\noften neglected in favour of using the default values provided by a particular\nimplementation of an algorithm. While there have been numerous studies on\nperformance evaluation of causal discovery algorithms, how hyperparameters\naffect individual algorithms, as well as the choice of the best algorithm for a\nspecific problem, has not been studied in depth before. This work addresses\nthis gap by investigating the influence of hyperparameters on causal structure\nlearning tasks. Specifically, we perform an empirical evaluation of\nhyperparameter selection for some seminal learning algorithms on datasets of\nvarying levels of complexity. We find that, while the choice of algorithm\nremains crucial to obtaining state-of-the-art performance, hyperparameter\nselection in ensemble settings strongly influences the choice of algorithm, in\nthat a poor choice of hyperparameters can lead to analysts using algorithms\nwhich do not give state-of-the-art performance for their data.",
            "author": [
                "Damian Machlanski",
                "Spyridon Samothrakis",
                "Paul Clarke"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18212v1",
                "http://arxiv.org/pdf/2310.18212v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18209v1",
            "title": "Alignment and Outer Shell Isotropy for Hyperbolic Graph Contrastive\n  Learning",
            "updated": "2023-10-27T15:31:42Z",
            "published": "2023-10-27T15:31:42Z",
            "summary": "Learning good self-supervised graph representations that are beneficial to\ndownstream tasks is challenging. Among a variety of methods, contrastive\nlearning enjoys competitive performance. The embeddings of contrastive learning\nare arranged on a hypersphere that enables the Cosine distance measurement in\nthe Euclidean space. However, the underlying structure of many domains such as\ngraphs exhibits highly non-Euclidean latent geometry. To this end, we propose a\nnovel contrastive learning framework to learn high-quality graph embedding.\nSpecifically, we design the alignment metric that effectively captures the\nhierarchical data-invariant information, as well as we propose a substitute of\nuniformity metric to prevent the so-called dimensional collapse. We show that\nin the hyperbolic space one has to address the leaf- and height-level\nuniformity which are related to properties of trees, whereas in the ambient\nspace of the hyperbolic manifold, these notions translate into imposing an\nisotropic ring density towards boundaries of Poincar\\'e ball. This ring density\ncan be easily imposed by promoting the isotropic feature distribution on the\ntangent space of manifold. In the experiments, we demonstrate the efficacy of\nour proposed method across different hyperbolic graph embedding techniques in\nboth supervised and self-supervised learning settings.",
            "author": [
                "Yifei Zhang",
                "Hao Zhu",
                "Jiahong Liu",
                "Piotr Koniusz",
                "Irwin King"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18209v1",
                "http://arxiv.org/pdf/2310.18209v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18208v2",
            "title": "ArcheType: A Novel Framework for Open-Source Column Type Annotation\n  using Large Language Models",
            "updated": "2023-11-06T13:16:27Z",
            "published": "2023-10-27T15:31:22Z",
            "summary": "Existing deep-learning approaches to semantic column type annotation (CTA)\nhave important shortcomings: they rely on semantic types which are fixed at\ntraining time; require a large number of training samples per type and incur\nlarge run-time inference costs; and their performance can degrade when\nevaluated on novel datasets, even when types remain constant. Large language\nmodels have exhibited strong zero-shot classification performance on a wide\nrange of tasks and in this paper we explore their use for CTA. We introduce\nArcheType, a simple, practical method for context sampling, prompt\nserialization, model querying, and label remapping, which enables large\nlanguage models to solve CTA problems in a fully zero-shot manner. We ablate\neach component of our method separately, and establish that improvements to\ncontext sampling and label remapping provide the most consistent gains.\nArcheType establishes a new state-of-the-art performance on zero-shot CTA\nbenchmarks (including three new domain-specific benchmarks which we release\nalong with this paper), and when used in conjunction with classical CTA\ntechniques, it outperforms a SOTA DoDuo model on the fine-tuned SOTAB\nbenchmark. Our code is available at https://github.com/penfever/ArcheType.",
            "author": [
                "Benjamin Feuer",
                "Yurong Liu",
                "Chinmay Hegde",
                "Juliana Freire"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18208v2",
                "http://arxiv.org/pdf/2310.18208v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18207v1",
            "title": "INA: An Integrative Approach for Enhancing Negotiation Strategies with\n  Reward-Based Dialogue System",
            "updated": "2023-10-27T15:31:16Z",
            "published": "2023-10-27T15:31:16Z",
            "summary": "In this paper, we propose a novel negotiation dialogue agent designed for the\nonline marketplace. Our agent is integrative in nature i.e, it possesses the\ncapability to negotiate on price as well as other factors, such as the addition\nor removal of items from a deal bundle, thereby offering a more flexible and\ncomprehensive negotiation experience. We create a new dataset called\nIntegrative Negotiation Dataset (IND) to enable this functionality. For this\ndataset creation, we introduce a new semi-automated data creation method, which\ncombines defining negotiation intents, actions, and intent-action simulation\nbetween users and the agent to generate potential dialogue flows. Finally, the\nprompting of GPT-J, a state-of-the-art language model, is done to generate\ndialogues for a given intent, with a human-in-the-loop process for post-editing\nand refining minor errors to ensure high data quality. We employ a set of novel\nrewards, specifically tailored for the negotiation task to train our\nNegotiation Agent, termed as the Integrative Negotiation Agent (INA). These\nrewards incentivize the chatbot to learn effective negotiation strategies that\ncan adapt to various contextual requirements and price proposals. By leveraging\nthe IND, we train our model and conduct experiments to evaluate the\neffectiveness of our reward-based dialogue system for negotiation. Our results\ndemonstrate that the proposed approach and reward system significantly enhance\nthe agent's negotiation capabilities. The INA successfully engages in\nintegrative negotiations, displaying the ability to dynamically adjust prices\nand negotiate the inclusion or exclusion of items in a bundle deal",
            "author": [
                "Zishan Ahmad",
                "Suman Saurabh",
                "Vaishakh Sreekanth Menon",
                "Asif Ekbal",
                "Roshni Ramnani",
                "Anutosh Maitra"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18207v1",
                "http://arxiv.org/pdf/2310.18207v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.16123v1",
            "title": "Exploring Multiple Neighborhood Neural Cellular Automata (MNNCA) for\n  Enhanced Texture Learning",
            "updated": "2023-10-27T15:16:19Z",
            "published": "2023-10-27T15:16:19Z",
            "summary": "Cellular Automata (CA) have long been foundational in simulating dynamical\nsystems computationally. With recent innovations, this model class has been\nbrought into the realm of deep learning by parameterizing the CA's update rule\nusing an artificial neural network, termed Neural Cellular Automata (NCA). This\nallows NCAs to be trained via gradient descent, enabling them to evolve into\nspecific shapes, generate textures, and mimic behaviors such as swarming.\nHowever, a limitation of traditional NCAs is their inability to exhibit\nsufficiently complex behaviors, restricting their potential in creative and\nmodeling tasks. Our research explores enhancing the NCA framework by\nincorporating multiple neighborhoods and introducing structured noise for seed\nstates. This approach is inspired by techniques that have historically\namplified the expressiveness of classical continuous CA. All code and example\nvideos are publicly available on https://github.com/MagnusPetersen/MNNCA.",
            "author": [
                "Magnus Petersen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16123v1",
                "http://arxiv.org/pdf/2311.16123v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "nlin.CG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18192v1",
            "title": "Artifact-Robust Graph-Based Learning in Digital Pathology",
            "updated": "2023-10-27T15:06:01Z",
            "published": "2023-10-27T15:06:01Z",
            "summary": "Whole slide images~(WSIs) are digitized images of tissues placed in glass\nslides using advanced scanners. The digital processing of WSIs is challenging\nas they are gigapixel images and stored in multi-resolution format. A common\nchallenge with WSIs is that perturbations/artifacts are inevitable during\nstoring the glass slides and digitizing them. These perturbations include\nmotion, which often arises from slide movement during placement, and changes in\nhue and brightness due to variations in staining chemicals and the quality of\ndigitizing scanners. In this work, a novel robust learning approach to account\nfor these artifacts is presented. Due to the size and resolution of WSIs and to\naccount for neighborhood information, graph-based methods are called for. We\nuse graph convolutional network~(GCN) to extract features from the graph\nrepresenting WSI. Through a denoiser {and pooling layer}, the effects of\nperturbations in WSIs are controlled and the output is followed by a\ntransformer for the classification of different grades of prostate cancer. To\ncompare the efficacy of the proposed approach, the model without denoiser is\ntrained and tested with WSIs without any perturbation and then different\nperturbations are introduced in WSIs and passed through the network with the\ndenoiser. The accuracy and kappa scores of the proposed model with prostate\ncancer dataset compared with non-robust algorithms show significant improvement\nin cancer diagnosis.",
            "author": [
                "Saba Heidari Gheshlaghi",
                "Milan Aryal",
                "Nasim Yahyasoltani",
                "Masoud Ganji"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18192v1",
                "http://arxiv.org/pdf/2310.18192v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18191v1",
            "title": "Is Scaling Learned Optimizers Worth It? Evaluating The Value of VeLO's\n  4000 TPU Months",
            "updated": "2023-10-27T15:04:00Z",
            "published": "2023-10-27T15:04:00Z",
            "summary": "We analyze VeLO (versatile learned optimizer), the largest scale attempt to\ntrain a general purpose \"foundational\" optimizer to date. VeLO was trained on\nthousands of machine learning tasks using over 4000 TPU months with the goal of\nproducing an optimizer capable of generalizing to new problems while being\nhyperparameter free, and outperforming industry standards such as Adam. We\nindependently evaluate VeLO on the MLCommons optimizer benchmark suite. We find\nthat, contrary to initial claims: (1) VeLO has a critical hyperparameter that\nneeds problem-specific tuning, (2) VeLO does not necessarily outperform\ncompetitors in quality of solution found, and (3) VeLO is not faster than\ncompeting optimizers at reducing the training loss. These observations call\ninto question VeLO's generality and the value of the investment in training it.",
            "author": [
                "Fady Rezk",
                "Antreas Antoniou",
                "Henry Gouk",
                "Timothy Hospedales"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18191v1",
                "http://arxiv.org/pdf/2310.18191v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18186v1",
            "title": "Model-free Posterior Sampling via Learning Rate Randomization",
            "updated": "2023-10-27T14:59:44Z",
            "published": "2023-10-27T14:59:44Z",
            "summary": "In this paper, we introduce Randomized Q-learning (RandQL), a novel\nrandomized model-free algorithm for regret minimization in episodic Markov\nDecision Processes (MDPs). To the best of our knowledge, RandQL is the first\ntractable model-free posterior sampling-based algorithm. We analyze the\nperformance of RandQL in both tabular and non-tabular metric space settings. In\ntabular MDPs, RandQL achieves a regret bound of order\n$\\widetilde{\\mathcal{O}}(\\sqrt{H^{5}SAT})$, where $H$ is the planning horizon,\n$S$ is the number of states, $A$ is the number of actions, and $T$ is the\nnumber of episodes. For a metric state-action space, RandQL enjoys a regret\nbound of order $\\widetilde{\\mathcal{O}}(H^{5/2} T^{(d_z+1)/(d_z+2)})$, where\n$d_z$ denotes the zooming dimension. Notably, RandQL achieves optimistic\nexploration without using bonuses, relying instead on a novel idea of learning\nrate randomization. Our empirical study shows that RandQL outperforms existing\napproaches on baseline exploration environments.",
            "author": [
                "Daniil Tiapkin",
                "Denis Belomestny",
                "Daniele Calandriello",
                "Eric Moulines",
                "Remi Munos",
                "Alexey Naumov",
                "Pierre Perrault",
                "Michal Valko",
                "Pierre Menard"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18186v1",
                "http://arxiv.org/pdf/2310.18186v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04224v1",
            "title": "MELEP: A Novel Predictive Measure of Transferability in Multi-Label ECG\n  Analysis",
            "updated": "2023-10-27T14:57:10Z",
            "published": "2023-10-27T14:57:10Z",
            "summary": "We introduce MELEP, which stands for Muti-label Expected Log of Empirical\nPredictions, a novel measure to estimate how effective it is to transfer\nknowledge from a pre-trained model to a downstream task in a multi-label\nsettings. The measure is generic to work with new target data having a\ndifferent label set from source data. It is also computationally efficient,\nonly requires forward passing the downstream dataset through the pre-trained\nmodel once. To the best of our knowledge, we are the first to develop such a\ntransferability metric for multi-label ECG classification problems. Our\nexperiments show that MELEP can predict the performance of pre-trained\nconvolutional and recurrent deep neural networks, on small and imbalanced ECG\ndata. Specifically, strong correlation coefficients, with absolute values\nexceeding 0.6 in most cases, were observed between MELEP and the actual average\nF1 scores of the fine-tuned models.",
            "author": [
                "Cuong V. Nguyen",
                "Hieu Minh Duong",
                "Cuong D. Do"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04224v1",
                "http://arxiv.org/pdf/2311.04224v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18177v1",
            "title": "Reinterpreting Fundamental Plane Correlations with Machine Learning",
            "updated": "2023-10-27T14:44:06Z",
            "published": "2023-10-27T14:44:06Z",
            "summary": "This work explores the relationships between galaxy sizes and related\nobservable galaxy properties in a large volume cosmological hydrodynamical\nsimulation. The objectives of this work are to both develop a better\nunderstanding of the correlations between galaxy properties and the influence\nof environment on galaxy physics in order to build an improved model for the\ngalaxy sizes, building off of the {\\it fundamental plane}. With an accurate\nintrinsic galaxy size predictor, the residuals in the observed galaxy sizes can\npotentially be used for multiple cosmological applications, including making\nmeasurements of galaxy velocities in spectroscopic samples, estimating the rate\nof cosmic expansion, and constraining the uncertainties in the photometric\nredshifts of galaxies. Using projection pursuit regression, the model\naccurately predicts intrinsic galaxy sizes and have residuals which have\nlimited correlation with galaxy properties. The model decreases the spatial\ncorrelation of galaxy size residuals by a factor of $\\sim$ 5 at small scales\ncompared to the baseline correlation when the mean size is used as a predictor.",
            "author": [
                "Chad Schafer",
                "Sukhdeep Singh",
                "Yesukhei Jagvaral"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18177v1",
                "http://arxiv.org/pdf/2310.18177v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA",
                "astro-ph.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00718v1",
            "title": "Chat GPT Integrated with Voice Assistant as Learning Oral Chat-based\n  Constructive Communication to Improve Communicative Competence for EFL\n  earners",
            "updated": "2023-10-27T14:29:36Z",
            "published": "2023-10-27T14:29:36Z",
            "summary": "Chat GPT belongs to the category of Generative Pre-trained Transformer (GPT)\nlanguage models, which have received specialized training to produce text based\non natural language inputs. Its purpose is to imitate human-like conversation\nand can be implemented in multiple applications, such as chatbots, virtual\nassistants, and language translation systems, starting with an introduction to\nthe new trends and differences between artificial intelligence, machine\nlearning, and artificial neural networks, and highlighting the rigorous\nlanguage logic and powerful text generation capabilities of Chat GPT. This\npaper delves into how advances in artificial intelligence will shape e-learning\nin the coming decades, particularly in terms of Chat- GPT's ability to improve\nlearners' Communicative Competence when English is a second language. The\ncombination of new trends in artificial intelligence, mainly in the particular\ncase of English as a second language, and, at the academic level, chatbot\ntechnology, will be the next step in the replacement of the human academic\ncommunity by virtual assistants, apparently until a certain point. Despite the\ncontroversy, this very innovative solution will be able to bridge the gap\nbetween technology and education. Moreover, such innovative practices\nfacilitate communication by enabling its inclusion in various applications,\nincluding virtual assistants, chatbots, and language education. Keyword: Chat\nGPT, artificial intelligence, Communicative Competence, Communicative Language\nTeaching (CLT)",
            "author": [
                "Wei Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00718v1",
                "http://arxiv.org/pdf/2311.00718v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18168v3",
            "title": "Personas as a Way to Model Truthfulness in Language Models",
            "updated": "2023-11-21T09:19:03Z",
            "published": "2023-10-27T14:27:43Z",
            "summary": "Large Language Models (LLMs) are trained on vast amounts of text from the\ninternet, which contains both factual and misleading information about the\nworld. Can language models discern truth from falsehood in this contradicting\ndata? Expanding on the view that LLMs can model different communicative agents,\nwe present the persona hypothesis: LLMs can cluster agents into personas using\ncommon features of their generations. For instance, a truthful persona is a\ngroup of agents that are likely to produce truthful text and that share similar\nfeatures like formal writing styles and scientific references. By modeling this\npersona, LLMs can generalize truthfulness beyond the specific contexts in which\neach agent generated the training text. For example, the model can infer that\nthe agent ``Wikipedia'' will behave truthfully on topics that were only\ngenerated by ``Science'' because they both belong to the truthful persona. We\nshow evidence for the persona hypothesis via two observations: (1) we can probe\nwhether a model's answer will be truthful before it is generated; (2)\nfinetuning a model on a set of facts improves its truthfulness on unseen\ntopics. Next, using arithmetics as a synthetic environment, we show that\nlanguage models can separate true and false statements, and generalize\ntruthfulness across agents; but only if agents in the training data share a\ntruthful generative process that enables the creation of a truthful persona.\nOverall, our findings suggest that models can exploit hierarchical structures\nin the data to learn abstract concepts like truthfulness.",
            "author": [
                "Nitish Joshi",
                "Javier Rando",
                "Abulhair Saparov",
                "Najoung Kim",
                "He He"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18168v3",
                "http://arxiv.org/pdf/2310.18168v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18167v1",
            "title": "MPrompt: Exploring Multi-level Prompt Tuning for Machine Reading\n  Comprehension",
            "updated": "2023-10-27T14:24:06Z",
            "published": "2023-10-27T14:24:06Z",
            "summary": "The large language models have achieved superior performance on various\nnatural language tasks. One major drawback of such approaches is they are\nresource-intensive in fine-tuning new datasets. Soft-prompt tuning presents a\nresource-efficient solution to fine-tune the pre-trained language models (PLMs)\nwhile keeping their weight frozen. Existing soft prompt methods mainly focus on\ndesigning the input-independent prompts that steer the model to fit the domain\nof the new dataset. Those methods often ignore the fine-grained information\nabout the task and context of the text. In this paper, we propose a multi-level\nprompt tuning (MPrompt) method for machine reading comprehension. It utilizes\nprompts at task-specific, domain-specific, and context-specific levels to\nenhance the comprehension of input semantics at different granularities. We\nalso propose an independence constraint to steer each domain-specific prompt to\nfocus on information within its domain to avoid redundancy. Moreover, we\npresent a prompt generator that incorporates context-related knowledge in the\nprompt generation to enhance contextual relevancy. We conducted extensive\nexperiments on 12 benchmarks of various QA formats and achieved an average\nimprovement of 1.94\\% over the state-of-the-art methods.",
            "author": [
                "Guoxin Chen",
                "Yiming Qian",
                "Bowen Wang",
                "Liangzhi Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18167v1",
                "http://arxiv.org/pdf/2310.18167v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18165v1",
            "title": "Enhancing Enterprise Network Security: Comparing Machine-Level and\n  Process-Level Analysis for Dynamic Malware Detection",
            "updated": "2023-10-27T14:17:35Z",
            "published": "2023-10-27T14:17:35Z",
            "summary": "Analysing malware is important to understand how malicious software works and\nto develop appropriate detection and prevention methods. Dynamic analysis can\novercome evasion techniques commonly used to bypass static analysis and provide\ninsights into malware runtime activities. Much research on dynamic analysis\nfocused on investigating machine-level information (e.g., CPU, memory, network\nusage) to identify whether a machine is running malicious activities. A\nmalicious machine does not necessarily mean all running processes on the\nmachine are also malicious. If we can isolate the malicious process instead of\nisolating the whole machine, we could kill the malicious process, and the\nmachine can keep doing its job. Another challenge dynamic malware detection\nresearch faces is that the samples are executed in one machine without any\nbackground applications running. It is unrealistic as a computer typically runs\nmany benign (background) applications when a malware incident happens. Our\nexperiment with machine-level data shows that the existence of background\napplications decreases previous state-of-the-art accuracy by about 20.12% on\naverage. We also proposed a process-level Recurrent Neural Network (RNN)-based\ndetection model. Our proposed model performs better than the machine-level\ndetection model; 0.049 increase in detection rate and a false-positive rate\nbelow 0.1.",
            "author": [
                "Baskoro Adi Pratomo",
                "Toby Jackson",
                "Pete Burnap",
                "Andrew Hood",
                "Eirini Anthi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18165v1",
                "http://arxiv.org/pdf/2310.18165v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03374v1",
            "title": "Generative AI for Software Metadata: Overview of the Information\n  Retrieval in Software Engineering Track at FIRE 2023",
            "updated": "2023-10-27T14:13:23Z",
            "published": "2023-10-27T14:13:23Z",
            "summary": "The Information Retrieval in Software Engineering (IRSE) track aims to\ndevelop solutions for automated evaluation of code comments in a machine\nlearning framework based on human and large language model generated labels. In\nthis track, there is a binary classification task to classify comments as\nuseful and not useful. The dataset consists of 9048 code comments and\nsurrounding code snippet pairs extracted from open source github C based\nprojects and an additional dataset generated individually by teams using large\nlanguage models. Overall 56 experiments have been submitted by 17 teams from\nvarious universities and software companies. The submissions have been\nevaluated quantitatively using the F1-Score and qualitatively based on the type\nof features developed, the supervised learning model used and their\ncorresponding hyper-parameters. The labels generated from large language models\nincrease the bias in the prediction model but lead to less over-fitted results.",
            "author": [
                "Srijoni Majumdar",
                "Soumen Paul",
                "Debjyoti Paul",
                "Ayan Bandyopadhyay",
                "Samiran Chattopadhyay",
                "Partha Pratim Das",
                "Paul D Clough",
                "Prasenjit Majumder"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03374v1",
                "http://arxiv.org/pdf/2311.03374v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.AI",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18162v1",
            "title": "Proportional Fairness in Clustering: A Social Choice Perspective",
            "updated": "2023-10-27T14:12:56Z",
            "published": "2023-10-27T14:12:56Z",
            "summary": "We study the proportional clustering problem of Chen et al. [ICML'19] and\nrelate it to the area of multiwinner voting in computational social choice. We\nshow that any clustering satisfying a weak proportionality notion of Brill and\nPeters [EC'23] simultaneously obtains the best known approximations to the\nproportional fairness notion of Chen et al. [ICML'19], but also to individual\nfairness [Jung et al., FORC'20] and the \"core\" [Li et al. ICML'21]. In fact, we\nshow that any approximation to proportional fairness is also an approximation\nto individual fairness and vice versa. Finally, we also study stronger notions\nof proportional representation, in which deviations do not only happen to\nsingle, but multiple candidate centers, and show that stronger proportionality\nnotions of Brill and Peters [EC'23] imply approximations to these stronger\nguarantees.",
            "author": [
                "Leon Kellerhals",
                "Jannik Peters"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18162v1",
                "http://arxiv.org/pdf/2310.18162v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY",
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18159v1",
            "title": "DESiRED -- Dynamic, Enhanced, and Smart iRED: A P4-AQM with Deep\n  Reinforcement Learning and In-band Network Telemetry",
            "updated": "2023-10-27T14:06:57Z",
            "published": "2023-10-27T14:06:57Z",
            "summary": "Active Queue Management (AQM) is a mechanism employed to alleviate transient\ncongestion in network device buffers, such as routers and switches. Traditional\nAQM algorithms use fixed thresholds, like target delay or queue occupancy, to\ncompute random packet drop probabilities. A very small target delay can\nincrease packet losses and reduce link utilization, while a large target delay\nmay increase queueing delays while lowering drop probability. Due to dynamic\nnetwork traffic characteristics, where traffic fluctuations can lead to\nsignificant queue variations, maintaining a fixed threshold AQM may not suit\nall applications. Consequently, we explore the question: \\textit{What is the\nideal threshold (target delay) for AQMs?} In this work, we introduce DESiRED\n(Dynamic, Enhanced, and Smart iRED), a P4-based AQM that leverages precise\nnetwork feedback from In-band Network Telemetry (INT) to feed a Deep\nReinforcement Learning (DRL) model. This model dynamically adjusts the target\ndelay based on rewards that maximize application Quality of Service (QoS). We\nevaluate DESiRED in a realistic P4-based test environment running an MPEG-DASH\nservice. Our findings demonstrate up to a 90x reduction in video stall and a\n42x increase in high-resolution video playback quality when the target delay is\nadjusted dynamically by DESiRED.",
            "author": [
                "Leandro C. de Almeida",
                "Washington Rodrigo Dias da Silva",
                "Thiago C. Tavares",
                "Rafael Pasquini",
                "Chrysa Papagianni",
                "F\u00e1bio L. Verdi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18159v1",
                "http://arxiv.org/pdf/2310.18159v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18152v2",
            "title": "Disentangled Representation Learning with Large Language Models for\n  Text-Attributed Graphs",
            "updated": "2023-11-06T12:54:14Z",
            "published": "2023-10-27T14:00:04Z",
            "summary": "Text-attributed graphs (TAGs) are prevalent on the web and research over TAGs\nsuch as citation networks, e-commerce networks and social networks has\nattracted considerable attention in the web community. Recently, large language\nmodels (LLMs) have demonstrated exceptional capabilities across a wide range of\ntasks. However, the existing works focus on harnessing the potential of LLMs\nsolely relying on prompts to convey graph structure information to LLMs, thus\nsuffering from insufficient understanding of the complex structural\nrelationships within TAGs. To address this problem, in this paper we present\nthe Disentangled Graph-Text Learner (DGTL) model, which is able to enhance the\nreasoning and predicting capabilities of LLMs for TAGs. Our proposed DGTL model\nincorporates graph structure information through tailored disentangled graph\nneural network (GNN) layers, enabling LLMs to capture the intricate\nrelationships hidden in text-attributed graphs from multiple structural\nfactors. Furthermore, DGTL operates with frozen pre-trained LLMs, reducing\ncomputational costs and allowing much more flexibility in combining with\ndifferent LLM models. Experimental evaluations demonstrate the effectiveness of\nthe proposed DGTL model on achieving superior or comparable performance over\nstate-of-the-art baselines. Additionally, we also demonstrate that our DGTL\nmodel can offer natural language explanations for predictions, thereby\nsignificantly enhancing model interpretability.",
            "author": [
                "Yijian Qin",
                "Xin Wang",
                "Ziwei Zhang",
                "Wenwu Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18152v2",
                "http://arxiv.org/pdf/2310.18152v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18144v3",
            "title": "Improving Intrinsic Exploration by Creating Stationary Objectives",
            "updated": "2023-12-04T17:32:31Z",
            "published": "2023-10-27T13:51:18Z",
            "summary": "Exploration bonuses in reinforcement learning guide long-horizon exploration\nby defining custom intrinsic objectives. Several exploration objectives like\ncount-based bonuses, pseudo-counts, and state-entropy maximization are\nnon-stationary and hence are difficult to optimize for the agent. While this\nissue is generally known, it is usually omitted and solutions remain\nunder-explored. The key contribution of our work lies in transforming the\noriginal non-stationary rewards into stationary rewards through an augmented\nstate representation. For this purpose, we introduce the Stationary Objectives\nFor Exploration (SOFE) framework. SOFE requires identifying sufficient\nstatistics for different exploration bonuses and finding an efficient encoding\nof these statistics to use as input to a deep network. SOFE is based on\nproposing state augmentations that expand the state space but hold the promise\nof simplifying the optimization of the agent's objective. We show that SOFE\nimproves the performance of several exploration objectives, including\ncount-based bonuses, pseudo-counts, and state-entropy maximization. Moreover,\nSOFE outperforms prior methods that attempt to stabilize the optimization of\nintrinsic objectives. We demonstrate the efficacy of SOFE in hard-exploration\nproblems, including sparse-reward tasks, pixel-based observations, 3D\nnavigation, and procedurally generated environments.",
            "author": [
                "Roger Creus Castanyer",
                "Joshua Romoff",
                "Glen Berseth"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18144v3",
                "http://arxiv.org/pdf/2310.18144v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18142v1",
            "title": "Semi-Supervised Panoptic Narrative Grounding",
            "updated": "2023-10-27T13:47:09Z",
            "published": "2023-10-27T13:47:09Z",
            "summary": "Despite considerable progress, the advancement of Panoptic Narrative\nGrounding (PNG) remains hindered by costly annotations. In this paper, we\nintroduce a novel Semi-Supervised Panoptic Narrative Grounding (SS-PNG)\nlearning scheme, capitalizing on a smaller set of labeled image-text pairs and\na larger set of unlabeled pairs to achieve competitive performance. Unlike\nvisual segmentation tasks, PNG involves one pixel belonging to multiple\nopen-ended nouns. As a result, existing multi-class based semi-supervised\nsegmentation frameworks cannot be directly applied to this task. To address\nthis challenge, we first develop a novel SS-PNG Network (SS-PNG-NW) tailored to\nthe SS-PNG setting. We thoroughly investigate strategies such as Burn-In and\ndata augmentation to determine the optimal generic configuration for the\nSS-PNG-NW. Additionally, to tackle the issue of imbalanced pseudo-label\nquality, we propose a Quality-Based Loss Adjustment (QLA) approach to adjust\nthe semi-supervised objective, resulting in an enhanced SS-PNG-NW+. Employing\nour proposed QLA, we improve BCE Loss and Dice loss at pixel and mask levels,\nrespectively. We conduct extensive experiments on PNG datasets, with our\nSS-PNG-NW+ demonstrating promising results comparable to fully-supervised\nmodels across all data ratios. Remarkably, our SS-PNG-NW+ outperforms\nfully-supervised models with only 30% and 50% supervision data, exceeding their\nperformance by 0.8% and 1.1% respectively. This highlights the effectiveness of\nour proposed SS-PNG-NW+ in overcoming the challenges posed by limited\nannotations and enhancing the applicability of PNG tasks. The source code is\navailable at https://github.com/nini0919/SSPNG.",
            "author": [
                "Danni Yang",
                "Jiayi Ji",
                "Xiaoshuai Sun",
                "Haowei Wang",
                "Yinan Li",
                "Yiwei Ma",
                "Rongrong Ji"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3581783.3612259",
                "http://arxiv.org/abs/2310.18142v1",
                "http://arxiv.org/pdf/2310.18142v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18141v1",
            "title": "Unsupervised Representation Learning for Diverse Deformable Shape\n  Collections",
            "updated": "2023-10-27T13:45:30Z",
            "published": "2023-10-27T13:45:30Z",
            "summary": "We introduce a novel learning-based method for encoding and manipulating 3D\nsurface meshes. Our method is specifically designed to create an interpretable\nembedding space for deformable shape collections. Unlike previous 3D mesh\nautoencoders that require meshes to be in a 1-to-1 correspondence, our approach\nis trained on diverse meshes in an unsupervised manner. Central to our method\nis a spectral pooling technique that establishes a universal latent space,\nbreaking free from traditional constraints of mesh connectivity and shape\ncategories. The entire process consists of two stages. In the first stage, we\nemploy the functional map paradigm to extract point-to-point (p2p) maps between\na collection of shapes in an unsupervised manner. These p2p maps are then\nutilized to construct a common latent space, which ensures straightforward\ninterpretation and independence from mesh connectivity and shape category.\nThrough extensive experiments, we demonstrate that our method achieves\nexcellent reconstructions and produces more realistic and smoother\ninterpolations than baseline approaches.",
            "author": [
                "Sara Hahner",
                "Souhaib Attaiki",
                "Jochen Garcke",
                "Maks Ovsjanikov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18141v1",
                "http://arxiv.org/pdf/2310.18141v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19903v1",
            "title": "A Multi-agent Reinforcement Learning Study of Emergence of Social\n  Classes out of Arbitrary Governance: The Role of Environment",
            "updated": "2023-10-27T13:31:53Z",
            "published": "2023-10-27T13:31:53Z",
            "summary": "There are several theories in economics regarding the roots or causes of\nprosperity in a society. One of these theories or hypotheses -- named geography\nhypothesis -- mentions that the reason why some countries are prosperous and\nsome others are poor is the geographical location of the countries in the world\nas makes their climate and environment favorable or unfavorable regarding\nnatural resources. Another competing hypothesis states that man-made\ninstitutions particularly inclusive political institutions are the reasons why\nsome countries are prosperous and some others are poor. On the other hand,\nthere is a specific political theory developed for the long-term social\ndevelopment in Iran -- named Arbitrary Rule and Aridisolatic Society which\nparticularly emphasizes on the role of aridity to shape arbitrary political and\neconomical institutions in Iran, without any functional social classes in the\nsociety. In this paper, by extending the AI-Economist -- a recently developed\ntwo-level multi-agent reinforcement learning environment -- I show that when\nthe central planner is ruling the environment by arbitrary rules, the society\nevolves through different paths in different environments. In the environment\nhaving band-like vertical isolated patches of natural resources, all mobile\nagents are equally exploited by the central planner and the central planner is\nalso not gaining any income, while in the society having more uniformly\ndistributed natural resources, the productivity and Maximin are higher and the\nsociety generates a heterogeneous stratified social structure. All these\nfindings provide a partial answer to the above debate and reconcile the role of\ngeography and political institutions on the long-term development in a region.",
            "author": [
                "Aslan S. Dizaji"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19903v1",
                "http://arxiv.org/pdf/2310.19903v1"
            ],
            "primary_category": "cs.MA",
            "category": [
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18131v2",
            "title": "End-to-end Video Gaze Estimation via Capturing Head-face-eye\n  Spatial-temporal Interaction Context",
            "updated": "2023-11-01T09:13:29Z",
            "published": "2023-10-27T13:23:38Z",
            "summary": "In this letter, we propose a new method, Multi-Clue Gaze (MCGaze), to\nfacilitate video gaze estimation via capturing spatial-temporal interaction\ncontext among head, face, and eye in an end-to-end learning way, which has not\nbeen well concerned yet. The main advantage of MCGaze is that the tasks of clue\nlocalization of head, face, and eye can be solved jointly for gaze estimation\nin a one-step way, with joint optimization to seek optimal performance. During\nthis, spatial-temporal context exchange happens among the clues on the head,\nface, and eye. Accordingly, the final gazes obtained by fusing features from\nvarious queries can be aware of global clues from heads and faces, and local\nclues from eyes simultaneously, which essentially leverages performance.\nMeanwhile, the one-step running way also ensures high running efficiency.\nExperiments on the challenging Gaze360 dataset verify the superiority of our\nproposition. The source code will be released at\nhttps://github.com/zgchen33/MCGaze.",
            "author": [
                "Yiran Guan",
                "Zhuoguang Chen",
                "Wenzheng Zeng",
                "Zhiguo Cao",
                "Yang Xiao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18131v2",
                "http://arxiv.org/pdf/2310.18131v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18129v1",
            "title": "TabAttention: Learning Attention Conditionally on Tabular Data",
            "updated": "2023-10-27T13:21:37Z",
            "published": "2023-10-27T13:21:37Z",
            "summary": "Medical data analysis often combines both imaging and tabular data processing\nusing machine learning algorithms. While previous studies have investigated the\nimpact of attention mechanisms on deep learning models, few have explored\nintegrating attention modules and tabular data. In this paper, we introduce\nTabAttention, a novel module that enhances the performance of Convolutional\nNeural Networks (CNNs) with an attention mechanism that is trained\nconditionally on tabular data. Specifically, we extend the Convolutional Block\nAttention Module to 3D by adding a Temporal Attention Module that uses\nmulti-head self-attention to learn attention maps. Furthermore, we enhance all\nattention modules by integrating tabular data embeddings. Our approach is\ndemonstrated on the fetal birth weight (FBW) estimation task, using 92 fetal\nabdominal ultrasound video scans and fetal biometry measurements. Our results\nindicate that TabAttention outperforms clinicians and existing methods that\nrely on tabular and/or imaging data for FBW prediction. This novel approach has\nthe potential to improve computer-aided diagnosis in various clinical workflows\nwhere imaging and tabular data are combined. We provide a source code for\nintegrating TabAttention in CNNs at\nhttps://github.com/SanoScience/Tab-Attention.",
            "author": [
                "Michal K. Grzeszczyk",
                "Szymon P\u0142otka",
                "Beata Rebizant",
                "Katarzyna Kosi\u0144ska-Kaczy\u0144ska",
                "Micha\u0142 Lipa",
                "Robert Brawura-Biskupski-Samaha",
                "Przemys\u0142aw Korzeniowski",
                "Tomasz Trzci\u0144ski",
                "Arkadiusz Sitek"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-031-43990-2_33",
                "http://arxiv.org/abs/2310.18129v1",
                "http://arxiv.org/pdf/2310.18129v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18127v1",
            "title": "Ask more, know better: Reinforce-Learned Prompt Questions for Decision\n  Making with Large Language Models",
            "updated": "2023-10-27T13:19:19Z",
            "published": "2023-10-27T13:19:19Z",
            "summary": "Large language models (LLMs) demonstrate their promise in tackling\ncomplicated practical challenges by combining action-based policies with chain\nof thought (CoT) reasoning. Having high-quality prompts on hand, however, is\nvital to the framework's effectiveness. Currently, these prompts are\nhandcrafted utilizing extensive human labor, resulting in CoT policies that\nfrequently fail to generalize. Human intervention is also required in order to\ndevelop grounding functions that ensure low-level controllers appropriately\nprocess CoT reasoning. In this paper, we take the first step towards a fully\nintegrated end-to-end framework for task-solving in real settings employing\ncomplicated reasoning. To that purpose, we offer a new leader-follower bilevel\nframework capable of learning to ask relevant questions (prompts) and\nsubsequently undertaking reasoning to guide the learning of actions to be\nperformed in an environment. A good prompt should make introspective revisions\nbased on historical findings, leading the CoT to consider the anticipated\ngoals. A prompt-generator policy has its own aim in our system, allowing it to\nadapt to the action policy and automatically root the CoT process towards\noutputs that lead to decisive, high-performing actions. Meanwhile, the action\npolicy is learning how to use the CoT outputs to take specific actions. Our\nempirical data reveal that our system outperforms leading methods in agent\nlearning benchmarks such as Overcooked and FourRoom.",
            "author": [
                "Xue Yan",
                "Yan Song",
                "Xinyu Cui",
                "Filippos Christianos",
                "Haifeng Zhang",
                "David Henry Mguni",
                "Jun Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18127v1",
                "http://arxiv.org/pdf/2310.18127v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18123v1",
            "title": "Sample Complexity Bounds for Score-Matching: Causal Discovery and\n  Generative Modeling",
            "updated": "2023-10-27T13:09:56Z",
            "published": "2023-10-27T13:09:56Z",
            "summary": "This paper provides statistical sample complexity bounds for score-matching\nand its applications in causal discovery. We demonstrate that accurate\nestimation of the score function is achievable by training a standard deep ReLU\nneural network using stochastic gradient descent. We establish bounds on the\nerror rate of recovering causal relationships using the score-matching-based\ncausal discovery method of Rolland et al. [2022], assuming a sufficiently good\nestimation of the score function. Finally, we analyze the upper bound of\nscore-matching estimation within the score-based generative modeling, which has\nbeen applied for causal discovery but is also of independent interest within\nthe domain of generative models.",
            "author": [
                "Zhenyu Zhu",
                "Francesco Locatello",
                "Volkan Cevher"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18123v1",
                "http://arxiv.org/pdf/2310.18123v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18119v1",
            "title": "Towards a Unified Conversational Recommendation System: Multi-task\n  Learning via Contextualized Knowledge Distillation",
            "updated": "2023-10-27T13:06:24Z",
            "published": "2023-10-27T13:06:24Z",
            "summary": "In Conversational Recommendation System (CRS), an agent is asked to recommend\na set of items to users within natural language conversations. To address the\nneed for both conversational capability and personalized recommendations, prior\nworks have utilized separate recommendation and dialogue modules. However, such\napproach inevitably results in a discrepancy between recommendation results and\ngenerated responses. To bridge the gap, we propose a multi-task learning for a\nunified CRS, where a single model jointly learns both tasks via Contextualized\nKnowledge Distillation (ConKD). We introduce two versions of ConKD: hard gate\nand soft gate. The former selectively gates between two task-specific teachers,\nwhile the latter integrates knowledge from both teachers. Our gates are\ncomputed on-the-fly in a context-specific manner, facilitating flexible\nintegration of relevant knowledge. Extensive experiments demonstrate that our\nsingle model significantly improves recommendation performance while enhancing\nfluency, and achieves comparable results in terms of diversity.",
            "author": [
                "Yeongseo Jung",
                "Eunseo Jung",
                "Lei Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18119v1",
                "http://arxiv.org/pdf/2310.18119v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18118v1",
            "title": "A Global Multi-Unit Calibration as a Method for Large Scale IoT\n  Particulate Matter Monitoring Systems Deployments",
            "updated": "2023-10-27T13:04:53Z",
            "published": "2023-10-27T13:04:53Z",
            "summary": "Scalable and effective calibration is a fundamental requirement for Low Cost\nAir Quality Monitoring Systems and will enable accurate and pervasive\nmonitoring in cities. Suffering from environmental interferences and\nfabrication variance, these devices need to encompass sensors specific and\ncomplex calibration processes for reaching a sufficient accuracy to be deployed\nas indicative measurement devices in Air Quality (AQ) monitoring networks.\nConcept and sensor drift often force calibration process to be frequently\nrepeated. These issues lead to unbearable calibration costs which denies their\nmassive deployment when accuracy is a concern. In this work, We propose a zero\ntransfer samples, global calibration methodology as a technological enabler for\nIoT AQ multisensory devices which relies on low cost Particulate Matter (PM)\nsensors. This methodology is based on field recorded responses from a limited\nnumber of IoT AQ multisensors units and machine learning concepts and can be\nuniversally applied to all units of the same type. A multi season test campaign\nshown that, when applied to different sensors, this methodology performances\nmatch those of state of the art methodology which requires to derive different\ncalibration parameters for each different unit. If confirmed, these results\nshow that, when properly derived, a global calibration law can be exploited for\na large number of networked devices with dramatic cost reduction eventually\nallowing massive deployment of accurate IoT AQ monitoring devices. Furthermore,\nthis calibration model could be easily embedded on board of the device or\nimplemented on the edge allowing immediate access to accurate readings for\npersonal exposure monitor applications as well as reducing long range data\ntransfer needs.",
            "author": [
                "Saverio De Vito",
                "Gerardo D Elia",
                "Sergio Ferlito",
                "Girolamo Di Francia",
                "Milos Davidovic",
                "Duska Kleut",
                "Danka Stojanovic",
                "Milena Jovasevic Stojanovic"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TIM.2023.3331428",
                "http://arxiv.org/abs/2310.18118v1",
                "http://arxiv.org/pdf/2310.18118v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18116v2",
            "title": "Direct Unsupervised Denoising",
            "updated": "2023-12-04T17:38:31Z",
            "published": "2023-10-27T13:02:12Z",
            "summary": "Traditional supervised denoisers are trained using pairs of noisy input and\nclean target images. They learn to predict a central tendency of the posterior\ndistribution over possible clean images. When, e.g., trained with the popular\nquadratic loss function, the network's output will correspond to the minimum\nmean square error (MMSE) estimate. Unsupervised denoisers based on Variational\nAutoEncoders (VAEs) have succeeded in achieving state-of-the-art results while\nrequiring only unpaired noisy data as training input. In contrast to the\ntraditional supervised approach, unsupervised denoisers do not directly produce\na single prediction, such as the MMSE estimate, but allow us to draw samples\nfrom the posterior distribution of clean solutions corresponding to the noisy\ninput. To approximate the MMSE estimate during inference, unsupervised methods\nhave to create and draw a large number of samples - a computationally expensive\nprocess - rendering the approach inapplicable in many situations. Here, we\npresent an alternative approach that trains a deterministic network alongside\nthe VAE to directly predict a central tendency. Our method achieves results\nthat surpass the results achieved by the unsupervised method at a fraction of\nthe computational cost.",
            "author": [
                "Benjamin Salmon",
                "Alexander Krull"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18116v2",
                "http://arxiv.org/pdf/2310.18116v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18113v1",
            "title": "Gaussian boson sampling validation via detector binning",
            "updated": "2023-10-27T12:55:52Z",
            "published": "2023-10-27T12:55:52Z",
            "summary": "Gaussian boson sampling (GBS), a computational problem conjectured to be hard\nto simulate on a classical machine, has been at the forefront of recent years'\nexperimental and theoretical efforts to demonstrate quantum advantage. The\nclassical intractability of the sampling task makes validating these\nexperiments a challenging and essential undertaking. In this paper, we propose\nbinned-detector probability distributions as a suitable quantity to\nstatistically validate GBS experiments employing photon-number-resolving\ndetectors. We show how to compute such distributions by leveraging their\nconnection with their respective characteristic function. The latter may be\nefficiently and analytically computed for squeezed input states as well as for\nrelevant classical hypothesis like squashed states. Our scheme encompasses\nother validation methods based on marginal distributions and correlation\nfunctions. Additionally, it can accommodate various sources of noise, such as\nlosses and partial distinguishability, a feature that have received limited\nattention within the GBS framework so far. We also illustrate how\nbinned-detector probability distributions behave when Haar-averaged over all\npossible interferometric networks, extending known results for Fock boson\nsampling.",
            "author": [
                "Gabriele Bressanini",
                "Benoit Seron",
                "Leonardo Novo",
                "Nicolas J. Cerf",
                "M. S. Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18113v1",
                "http://arxiv.org/pdf/2310.18113v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18112v1",
            "title": "er.autopilot 1.0: The Full Autonomous Stack for Oval Racing at High\n  Speeds",
            "updated": "2023-10-27T12:52:34Z",
            "published": "2023-10-27T12:52:34Z",
            "summary": "The Indy Autonomous Challenge (IAC) brought together for the first time in\nhistory nine autonomous racing teams competing at unprecedented speed and in\nhead-to-head scenario, using independently developed software on open-wheel\nracecars. This paper presents the complete software architecture used by team\nTII EuroRacing (TII-ER), covering all the modules needed to avoid static\nobstacles, perform active overtakes and reach speeds above 75 m/s (270 km/h).\nIn addition to the most common modules related to perception, planning, and\ncontrol, we discuss the approaches used for vehicle dynamics modelling,\nsimulation, telemetry, and safety. Overall results and the performance of each\nmodule are described, as well as the lessons learned during the first two\nevents of the competition on oval tracks, where the team placed respectively\nsecond and third.",
            "author": [
                "Ayoub Raji",
                "Danilo Caporale",
                "Francesco Gatti",
                "Andrea Giove",
                "Micaela Verucchi",
                "Davide Malatesta",
                "Nicola Musiu",
                "Alessandro Toschi",
                "Silviu Roberto Popitanu",
                "Fabio Bagni",
                "Massimiliano Bosi",
                "Alexander Liniger",
                "Marko Bertogna",
                "Daniele Morra",
                "Francesco Amerotti",
                "Luca Bartoli",
                "Federico Martello",
                "Riccardo Porta"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18112v1",
                "http://arxiv.org/pdf/2310.18112v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CV",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18108v1",
            "title": "Transductive conformal inference with adaptive scores",
            "updated": "2023-10-27T12:48:30Z",
            "published": "2023-10-27T12:48:30Z",
            "summary": "Conformal inference is a fundamental and versatile tool that provides\ndistribution-free guarantees for many machine learning tasks. We consider the\ntransductive setting, where decisions are made on a test sample of $m$ new\npoints, giving rise to $m$ conformal $p$-values. {While classical results only\nconcern their marginal distribution, we show that their joint distribution\nfollows a P\\'olya urn model, and establish a concentration inequality for their\nempirical distribution function.} The results hold for arbitrary exchangeable\nscores, including {\\it adaptive} ones that can use the covariates of the\ntest+calibration samples at training stage for increased accuracy. We\ndemonstrate the usefulness of these theoretical results through uniform,\nin-probability guarantees for two machine learning tasks of current interest:\ninterval prediction for transductive transfer learning and novelty detection\nbased on two-class classification.",
            "author": [
                "Ulysse Gazin",
                "Gilles Blanchard",
                "Etienne Roquain"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18108v1",
                "http://arxiv.org/pdf/2310.18108v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18103v1",
            "title": "A Novel Application of Polynomial Solvers in mmWave Analog Radio\n  Beamforming",
            "updated": "2023-10-27T12:41:41Z",
            "published": "2023-10-27T12:41:41Z",
            "summary": "Beamforming is a signal processing technique where an array of antenna\nelements can be steered to transmit and receive radio signals in a specific\ndirection. The usage of millimeter wave (mmWave) frequencies and multiple input\nmultiple output (MIMO) beamforming are considered as the key innovations of 5th\nGeneration (5G) and beyond communication systems. The technique initially\nperforms a beam alignment procedure, followed by data transfer in the aligned\ndirections between the transmitter and the receiver. Traditionally, beam\nalignment involves periodical and exhaustive beam sweeping at both transmitter\nand the receiver, which is a slow process causing extra communication overhead\nwith MIMO and massive MIMO radio units. In applications such as beam tracking,\nangular velocity, beam steering etc., the beam alignment procedure is optimized\nby estimating the beam directions using first order polynomial approximations.\nRecent learning-based SOTA strategies for fast mmWave beam alignment also\nrequire exploration over exhaustive beam pairs during the training procedure,\ncausing overhead to learning strategies for higher antenna configurations. In\nthis work, we first optimize the beam alignment cost functions e.g. the data\nrate, to reduce the beam sweeping overhead by applying polynomial\napproximations of its partial derivatives which can then be solved as a system\nof polynomial equations using well-known tools from algebraic geometry. At this\npoint, a question arises: 'what is a good polynomial approximation?' In this\nwork, we attempt to obtain a 'good polynomial approximation'. Preliminary\nexperiments indicate that our estimated polynomial approximations attain a\nso-called sweet-spot in terms of the solver speed and accuracy, when evaluated\non test beamforming problems.",
            "author": [
                "Snehal Bhayani",
                "Praneeth Susarla",
                "S. S. Krishna Chaitanya Bulusu",
                "Olli Silven",
                "Markku Juntti",
                "Janne Heikkila"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18103v1",
                "http://arxiv.org/pdf/2310.18103v1"
            ],
            "primary_category": "cs.SC",
            "category": [
                "cs.SC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18100v1",
            "title": "Analysis of the Generalization Error of deep learning based on\n  Randomized Quasi-Monte Carlo for Solving Linear Kolmogorov PDEs",
            "updated": "2023-10-27T12:36:55Z",
            "published": "2023-10-27T12:36:55Z",
            "summary": "Deep learning algorithms have been widely used to solve linear Kolmogorov\npartial differential equations~(PDEs) in high dimensions, where the loss\nfunction is defined as a mathematical expectation. We propose to use the\nrandomized quasi-Monte Carlo (RQMC) method instead of the Monte Carlo (MC)\nmethod for computing the loss function. In theory, we decompose the error from\nempirical risk minimization~(ERM) into the generalization error and the\napproximation error. Notably, the approximation error is independent of the\nsampling methods. We prove that the convergence order of the mean\ngeneralization error for the RQMC method is $O(n^{-1+\\epsilon})$ for\narbitrarily small $\\epsilon>0$, while for the MC method it is\n$O(n^{-1/2+\\epsilon})$ for arbitrarily small $\\epsilon>0$. Consequently, we\nfind that the overall error for the RQMC method is asymptotically smaller than\nthat for the MC method as $n$ increases. Our numerical experiments show that\nthe algorithm based on the RQMC method consistently achieves smaller relative\n$L^{2}$ error than that based on the MC method.",
            "author": [
                "Jichang Xiao",
                "Fengjiang Fu",
                "Xiaoqun Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18100v1",
                "http://arxiv.org/pdf/2310.18100v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "65C30, 65D30, 65N15, 68T07"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18091v1",
            "title": "Adversarial Anomaly Detection using Gaussian Priors and Nonlinear\n  Anomaly Scores",
            "updated": "2023-10-27T12:24:08Z",
            "published": "2023-10-27T12:24:08Z",
            "summary": "Anomaly detection in imbalanced datasets is a frequent and crucial problem,\nespecially in the medical domain where retrieving and labeling irregularities\nis often expensive. By combining the generative stability of a\n$\\beta$-variational autoencoder (VAE) with the discriminative strengths of\ngenerative adversarial networks (GANs), we propose a novel model,\n$\\beta$-VAEGAN. We investigate methods for composing anomaly scores based on\nthe discriminative and reconstructive capabilities of our model. Existing work\nfocuses on linear combinations of these components to determine if data is\nanomalous. We advance existing work by training a kernelized support vector\nmachine (SVM) on the respective error components to also consider nonlinear\nrelationships. This improves anomaly detection performance, while allowing\nfaster optimization. Lastly, we use the deviations from the Gaussian prior of\n$\\beta$-VAEGAN to form a novel anomaly score component. In comparison to\nstate-of-the-art work, we improve the $F_1$ score during anomaly detection from\n0.85 to 0.92 on the widely used MITBIH Arrhythmia Database.",
            "author": [
                "Fiete L\u00fcer",
                "Tobias Weber",
                "Maxim Dolgich",
                "Christian B\u00f6hm"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18091v1",
                "http://arxiv.org/pdf/2310.18091v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18080v1",
            "title": "Unveiling the Potential of Probabilistic Embeddings in Self-Supervised\n  Learning",
            "updated": "2023-10-27T12:01:16Z",
            "published": "2023-10-27T12:01:16Z",
            "summary": "In recent years, self-supervised learning has played a pivotal role in\nadvancing machine learning by allowing models to acquire meaningful\nrepresentations from unlabeled data. An intriguing research avenue involves\ndeveloping self-supervised models within an information-theoretic framework,\nbut many studies often deviate from the stochasticity assumptions made when\nderiving their objectives. To gain deeper insights into this issue, we propose\nto explicitly model the representation with stochastic embeddings and assess\ntheir effects on performance, information compression and potential for\nout-of-distribution detection. From an information-theoretic perspective, we\nseek to investigate the impact of probabilistic modeling on the information\nbottleneck, shedding light on a trade-off between compression and preservation\nof information in both representation and loss space. Emphasizing the\nimportance of distinguishing between these two spaces, we demonstrate how\nconstraining one can affect the other, potentially leading to performance\ndegradation. Moreover, our findings suggest that introducing an additional\nbottleneck in the loss space can significantly enhance the ability to detect\nout-of-distribution examples, only leveraging either representation features or\nthe variance of their underlying distribution.",
            "author": [
                "Denis Janiak",
                "Jakub Binkowski",
                "Piotr Bielak",
                "Tomasz Kajdanowicz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18080v1",
                "http://arxiv.org/pdf/2310.18080v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18079v1",
            "title": "Supporting Better Insights of Data Science Pipelines with Fine-grained\n  Provenance",
            "updated": "2023-10-27T12:00:22Z",
            "published": "2023-10-27T12:00:22Z",
            "summary": "Successful data-driven science requires complex data engineering pipelines to\nclean, transform, and alter data in preparation for machine learning, and\nrobust results can only be achieved when each step in the pipeline can be\njustified, and its effect on the data explained. In this framework, our aim is\nto provide data scientists with facilities to gain an in-depth understanding of\nhow each step in the pipeline affects the data, from the raw input to training\nsets ready to be used for learning. Starting from an extensible set of data\npreparation operators commonly used within a data science setting, in this work\nwe present a provenance management infrastructure for generating, storing, and\nquerying very granular accounts of data transformations, at the level of\nindividual elements within datasets whenever possible. Then, from the formal\ndefinition of a core set of data science preprocessing operators, we derive a\nprovenance semantics embodied by a collection of templates expressed in PROV, a\nstandard model for data provenance. Using those templates as a reference, our\nprovenance generation algorithm generalises to any operator with observable\ninput/output pairs. We provide a prototype implementation of an\napplication-level provenance capture library to produce, in a semi-automatic\nway, complete provenance documents that account for the entire pipeline. We\nreport on the ability of our implementations to capture provenance in real ML\nbenchmark pipelines and over TCP-DI synthetic data. We finally show how the\ncollected provenance can be used to answer a suite of provenance benchmark\nqueries that underpin some common pipeline inspection questions, as expressed\non the Data Science Stack Exchange.",
            "author": [
                "Adriane Chapman",
                "Luca Lauro",
                "Paolo Missier",
                "Riccardo Torlone"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18079v1",
                "http://arxiv.org/pdf/2310.18079v1"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB",
                "68",
                "H.1; H.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18078v1",
            "title": "Lipschitz and H\u00f6lder Continuity in Reproducing Kernel Hilbert Spaces",
            "updated": "2023-10-27T11:56:43Z",
            "published": "2023-10-27T11:56:43Z",
            "summary": "Reproducing kernel Hilbert spaces (RKHSs) are very important function spaces,\nplaying an important role in machine learning, statistics, numerical analysis\nand pure mathematics. Since Lipschitz and H\\\"older continuity are important\nregularity properties, with many applications in interpolation, approximation\nand optimization problems, in this work we investigate these continuity notion\nin RKHSs. We provide several sufficient conditions as well as an in depth\ninvestigation of reproducing kernels inducing prescribed Lipschitz or H\\\"older\ncontinuity. Apart from new results, we also collect related known results from\nthe literature, making the present work also a convenient reference on this\ntopic.",
            "author": [
                "Christian Fiedler"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18078v1",
                "http://arxiv.org/pdf/2310.18078v1"
            ],
            "primary_category": "math.FA",
            "category": [
                "math.FA",
                "cs.LG",
                "46E22 (Primary), 51F30, 47B34, 47G10 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18074v1",
            "title": "On kernel-based statistical learning in the mean field limit",
            "updated": "2023-10-27T11:42:56Z",
            "published": "2023-10-27T11:42:56Z",
            "summary": "In many applications of machine learning, a large number of variables are\nconsidered. Motivated by machine learning of interacting particle systems, we\nconsider the situation when the number of input variables goes to infinity.\nFirst, we continue the recent investigation of the mean field limit of kernels\nand their reproducing kernel Hilbert spaces, completing the existing theory.\nNext, we provide results relevant for approximation with such kernels in the\nmean field limit, including a representer theorem. Finally, we use these\nkernels in the context of statistical learning in the mean field limit,\nfocusing on Support Vector Machines. In particular, we show mean field\nconvergence of empirical and infinite-sample solutions as well as the\nconvergence of the corresponding risks. On the one hand, our results establish\nrigorous mean field limits in the context of kernel methods, providing new\ntheoretical tools and insights for large-scale problems. On the other hand, our\nsetting corresponds to a new form of limit of learning problems, which seems to\nhave not been investigated yet in the statistical learning theory literature.",
            "author": [
                "Christian Fiedler",
                "Michael Herty",
                "Sebastian Trimpe"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18074v1",
                "http://arxiv.org/pdf/2310.18074v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.ST",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18070v1",
            "title": "Multi-grained Evidence Inference for Multi-choice Reading Comprehension",
            "updated": "2023-10-27T11:36:18Z",
            "published": "2023-10-27T11:36:18Z",
            "summary": "Multi-choice Machine Reading Comprehension (MRC) is a major and challenging\ntask for machines to answer questions according to provided options. Answers in\nmulti-choice MRC cannot be directly extracted in the given passages, and\nessentially require machines capable of reasoning from accurate extracted\nevidence. However, the critical evidence may be as simple as just one word or\nphrase, while it is hidden in the given redundant, noisy passage with multiple\nlinguistic hierarchies from phrase, fragment, sentence until the entire\npassage. We thus propose a novel general-purpose model enhancement which\nintegrates multi-grained evidence comprehensively, named Multi-grained evidence\ninferencer (Mugen), to make up for the inability. Mugen extracts three\ndifferent granularities of evidence: coarse-, middle- and fine-grained\nevidence, and integrates evidence with the original passages, achieving\nsignificant and consistent performance improvement on four multi-choice MRC\nbenchmarks.",
            "author": [
                "Yilin Zhao",
                "Hai Zhao",
                "Sufeng Duan"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TASLP.2023.3313885",
                "http://arxiv.org/abs/2310.18070v1",
                "http://arxiv.org/pdf/2310.18070v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18063v1",
            "title": "\"Honey, Tell Me What's Wrong\", Global Explanation of Textual\n  Discriminative Models through Cooperative Generation",
            "updated": "2023-10-27T11:26:27Z",
            "published": "2023-10-27T11:26:27Z",
            "summary": "The ubiquity of complex machine learning has raised the importance of\nmodel-agnostic explanation algorithms. These methods create artificial\ninstances by slightly perturbing real instances, capturing shifts in model\ndecisions. However, such methods rely on initial data and only provide\nexplanations of the decision for these. To tackle these problems, we propose\nTherapy, the first global and model-agnostic explanation method adapted to text\nwhich requires no input dataset. Therapy generates texts following the\ndistribution learned by a classifier through cooperative generation. Because it\ndoes not rely on initial samples, it allows to generate explanations even when\ndata is absent (e.g., for confidentiality reasons). Moreover, conversely to\nexisting methods that combine multiple local explanations into a global one,\nTherapy offers a global overview of the model behavior on the input space. Our\nexperiments show that although using no input data to generate samples, Therapy\nprovides insightful information about features used by the classifier that is\ncompetitive with the ones from methods relying on input samples and outperforms\nthem when input samples are not specific to the studied model.",
            "author": [
                "Antoine Chaffin",
                "Julien Delaunay"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18063v1",
                "http://arxiv.org/pdf/2310.18063v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06280v1",
            "title": "A Data-driven Deep Learning Approach for Bitcoin Price Forecasting",
            "updated": "2023-10-27T10:35:47Z",
            "published": "2023-10-27T10:35:47Z",
            "summary": "Bitcoin as a cryptocurrency has been one of the most important digital coins\nand the first decentralized digital currency. Deep neural networks, on the\nother hand, has shown promising results recently; however, we require huge\namount of high-quality data to leverage their power. There are some techniques\nsuch as augmentation that can help us with increasing the dataset size, but we\ncannot exploit them on historical bitcoin data. As a result, we propose a\nshallow Bidirectional-LSTM (Bi-LSTM) model, fed with feature engineered data\nusing our proposed method to forecast bitcoin closing prices in a daily time\nframe. We compare the performance with that of other forecasting methods, and\nshow that with the help of the proposed feature engineering method, a shallow\ndeep neural network outperforms other popular price forecasting models.",
            "author": [
                "Parth Daxesh Modi",
                "Kamyar Arshi",
                "Pertami J. Kunz",
                "Abdelhak M. Zoubir"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06280v1",
                "http://arxiv.org/pdf/2311.06280v1"
            ],
            "primary_category": "q-fin.ST",
            "category": [
                "q-fin.ST",
                "cs.AI",
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18035v1",
            "title": "High Throughput Screening of Ternary Nitrides with Convolutional Neural\n  Networks",
            "updated": "2023-10-27T10:27:57Z",
            "published": "2023-10-27T10:27:57Z",
            "summary": "The development of new materials is a core aspect of advancement in synthesis\nand application for industry. There is a vast number of possible chemical\npermutations of the basic elements that can be explored to synthesize materials\nthat possess attractive catalytic, mechanical and electrical properties that\nmay not be easily accessible to traditional experimental methods for various\nreasons, including cost and time considerations. Nitrides, as examples, require\nvery stringent and precise conditions to successfully synthesize making their\nexperimental exploration very slow. In this paper, we employ the use of machine\nlearning algorithms to predict the bulk properties of Ternary Metal Nitrides\n(TMN), specifically their bulk modulus which is correlated with the hardness of\nthe material. We were able to develop a consistent model with encouraging\naccuracy, that was able to predict the bulk moduli of materials that previously\ndid not have computed values. The model was trained on $10^3$ ternary materials\nwith known elastic properties and defined structures, and was able to predict\nthe bulk modulus of $\\thickapprox 1,000$ Ternary Metal Nitrides (TMNs) to\n$\\thickapprox 80\\%$ accuracy. This approach is orders of magnitude faster than\nthe traditional computational approaches like density functional theory\n(DFT)\\cite{dft-paper} which makes exploratory identification of materials with\npromising properties fast. We propose that such models be used to select\ninteresting candidates for high throughput computation from first principles.",
            "author": [
                "Antony A. Ayieko",
                "Michael O. Atambo",
                "George O. Amolo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18035v1",
                "http://arxiv.org/pdf/2310.18035v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18027v3",
            "title": "Bayesian Prognostic Covariate Adjustment With Additive Mixture Priors",
            "updated": "2023-11-23T00:57:01Z",
            "published": "2023-10-27T10:05:06Z",
            "summary": "Effective and rapid decision-making from randomized controlled trials (RCTs)\nrequires unbiased and precise treatment effect inferences. Two strategies to\naddress this requirement are to adjust for covariates that are highly\ncorrelated with the outcome, and to leverage historical control information via\nBayes' theorem. We propose a new Bayesian prognostic covariate adjustment\nmethodology, referred to as Bayesian PROCOVA, that combines these two\nstrategies. Covariate adjustment in Bayesian PROCOVA is based on generative\nartificial intelligence (AI) algorithms that construct a digital twin generator\n(DTG) for RCT participants. The DTG is trained on historical control data and\nyields a digital twin (DT) probability distribution for each RCT participant's\noutcome under the control treatment. The expectation of the DT distribution,\nreferred to as the prognostic score, defines the covariate for adjustment.\nHistorical control information is leveraged via an additive mixture prior with\ntwo components: an informative prior probability distribution specified based\non historical control data, and a weakly informative prior distribution. The\nmixture weight determines the extent to which posterior inferences are drawn\nfrom the informative component, versus the weakly informative component. This\nweight has a prior distribution as well, and so the entire additive mixture\nprior is completely pre-specifiable without involving any RCT information. We\nestablish an efficient Gibbs algorithm for sampling from the posterior\ndistribution, and derive closed-form expressions for the posterior mean and\nvariance of the treatment effect parameter conditional on the weight, in\nBayesian PROCOVA. We evaluate efficiency gains of Bayesian PROCOVA via its bias\ncontrol and variance reduction compared to frequentist PROCOVA in simulation\nstudies that encompass different discrepancies. These gains translate to\nsmaller RCTs.",
            "author": [
                "Alyssa M. Vanderbeek",
                "Arman Sabbaghi",
                "Jon R. Walsh",
                "Charles K. Fisher"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18027v3",
                "http://arxiv.org/pdf/2310.18027v3"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.AP",
                "stat.ML",
                "62F15"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18021v3",
            "title": "FormalGeo: The First Step Toward Human-like IMO-level Geometric\n  Automated Reasoning",
            "updated": "2023-11-28T07:00:35Z",
            "published": "2023-10-27T09:55:12Z",
            "summary": "This is the first paper in a series of work we have accomplished over the\npast three years. In this paper, we have constructed a complete and compatible\nformal plane geometry system. This will serve as a crucial bridge between\nIMO-level plane geometry challenges and readable AI automated reasoning. Within\nthis formal framework, we have been able to seamlessly integrate modern AI\nmodels with our formal system. AI is now capable of providing deductive\nreasoning solutions to IMO-level plane geometry problems, just like handling\nother natural languages, and these proofs are readable, traceable, and\nverifiable. We propose the geometry formalization theory (GFT) to guide the\ndevelopment of the geometry formal system. Based on the GFT, we have\nestablished the FormalGeo, which consists of 88 geometric predicates and 196\ntheorems. It can represent, validate, and solve IMO-level geometry problems. we\nalso have crafted the FGPS (formal geometry problem solver) in Python. It\nserves as both an interactive assistant for verifying problem-solving processes\nand an automated problem solver. We've annotated the formalgeo7k and\nformalgeo-imo datasets. The former contains 6,891 (expand to 133,818 through\ndata augmentation) geometry problems, while the latter includes 18 (expand to\n2,627 and continuously increasing) IMO-level challenging geometry problems. All\nannotated problems include detailed formal language descriptions and solutions.\nImplementation of the formal system and experiments validate the correctness\nand utility of the GFT. The backward depth-first search method only yields a\n2.42% problem-solving failure rate, and we can incorporate deep learning\ntechniques to achieve lower one. The source code of FGPS and datasets are\navailable at https://github.com/BitSecret/FGPS.",
            "author": [
                "Xiaokai Zhang",
                "Na Zhu",
                "Yiming He",
                "Jia Zou",
                "Qike Huang",
                "Xiaoxiao Jin",
                "Yanjun Guo",
                "Chenyang Mao",
                "Zhe Zhu",
                "Dengfeng Yue",
                "Fangzhen Zhu",
                "Yang Li",
                "Yifan Wang",
                "Yiwen Huang",
                "Runan Wang",
                "Cheng Qin",
                "Zhenbing Zeng",
                "Shaorong Xie",
                "Xiangfeng Luo",
                "Tuo Leng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18021v3",
                "http://arxiv.org/pdf/2310.18021v3"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18019v1",
            "title": "Temperature Monitoring of Agricultural Areas in a Secure Data Room",
            "updated": "2023-10-27T09:49:52Z",
            "published": "2023-10-27T09:49:52Z",
            "summary": "Agricultural production is highly dependent on naturally occurring\nenvironmental conditions like change of seasons and the weather. Especially in\nfruit and wine growing, late frosts occurring shortly after the crops have\nsprouted have the potential to cause massive damage to plants [L1,L2] [1]. In\nthis article we present a cost-efficient temperature monitoring system for\ndetecting and reacting to late frosts to prevent crop failures. The proposed\nsolution includes a data space where Internet of Things (IoT) devices can form\na cyber-physical system (CPS) to interact with their nearby environment and\nsecurely exchange data. Based on this data, more accurate predictions can be\nmade in the future using machine learning (ML), which will further contribute\nto minimising economic damage caused by crop failures.",
            "author": [
                "Thomas Ederer",
                "Martin Ivancsits",
                "Igor Ivki\u0107"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18019v1",
                "http://arxiv.org/pdf/2310.18019v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18004v1",
            "title": "Text2Bundle: Towards Personalized Query-based Bundle Generation",
            "updated": "2023-10-27T09:24:38Z",
            "published": "2023-10-27T09:24:38Z",
            "summary": "Bundle generation aims to provide a bundle of items for the user, and has\nbeen widely studied and applied on online service platforms. Existing bundle\ngeneration methods mainly utilized user's preference from historical\ninteractions in common recommendation paradigm, and ignored the potential\ntextual query which is user's current explicit intention. There can be a\nscenario in which a user proactively queries a bundle with some natural\nlanguage description, the system should be able to generate a bundle that\nexactly matches the user's intention through the user's query and preferences.\nIn this work, we define this user-friendly scenario as Query-based Bundle\nGeneration task and propose a novel framework Text2Bundle that leverages both\nthe user's short-term interests from the query and the user's long-term\npreferences from the historical interactions. Our framework consists of three\nmodules: (1) a query interest extractor that mines the user's fine-grained\ninterests from the query; (2) a unified state encoder that learns the current\nbundle context state and the user's preferences based on historical interaction\nand current query; and (3) a bundle generator that generates personalized and\ncomplementary bundles using a reinforcement learning with specifically designed\nrewards. We conduct extensive experiments on three real-world datasets and\ndemonstrate the effectiveness of our framework compared with several\nstate-of-the-art methods.",
            "author": [
                "Shixuan Zhu",
                "Chuan Cui",
                "JunTong Hu",
                "Qi Shen",
                "Yu Ji",
                "Zhihua Wei"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18004v1",
                "http://arxiv.org/pdf/2310.18004v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18001v1",
            "title": "DP-SGD with weight clipping",
            "updated": "2023-10-27T09:17:15Z",
            "published": "2023-10-27T09:17:15Z",
            "summary": "Recently, due to the popularity of deep neural networks and other methods\nwhose training typically relies on the optimization of an objective function,\nand due to concerns for data privacy, there is a lot of interest in\ndifferentially private gradient descent methods. To achieve differential\nprivacy guarantees with a minimum amount of noise, it is important to be able\nto bound precisely the sensitivity of the information which the participants\nwill observe. In this study, we present a novel approach that mitigates the\nbias arising from traditional gradient clipping. By leveraging public\ninformation concerning the current global model and its location within the\nsearch domain, we can achieve improved gradient bounds, leading to enhanced\nsensitivity determinations and refined noise level adjustments. We extend the\nstate of the art algorithms, present improved differential privacy guarantees\nrequiring less noise and present an empirical evaluation.",
            "author": [
                "Antoine Barczewski",
                "Jan Ramon"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18001v1",
                "http://arxiv.org/pdf/2310.18001v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17998v1",
            "title": "Closing the Gap Between the Upper Bound and the Lower Bound of Adam's\n  Iteration Complexity",
            "updated": "2023-10-27T09:16:58Z",
            "published": "2023-10-27T09:16:58Z",
            "summary": "Recently, Arjevani et al. [1] established a lower bound of iteration\ncomplexity for the first-order optimization under an $L$-smooth condition and a\nbounded noise variance assumption. However, a thorough review of existing\nliterature on Adam's convergence reveals a noticeable gap: none of them meet\nthe above lower bound. In this paper, we close the gap by deriving a new\nconvergence guarantee of Adam, with only an $L$-smooth condition and a bounded\nnoise variance assumption. Our results remain valid across a broad spectrum of\nhyperparameters. Especially with properly chosen hyperparameters, we derive an\nupper bound of the iteration complexity of Adam and show that it meets the\nlower bound for first-order optimizers. To the best of our knowledge, this is\nthe first to establish such a tight upper bound for Adam's convergence. Our\nproof utilizes novel techniques to handle the entanglement between momentum and\nadaptive learning rate and to convert the first-order term in the Descent Lemma\nto the gradient norm, which may be of independent interest.",
            "author": [
                "Bohan Wang",
                "Jingwen Fu",
                "Huishuai Zhang",
                "Nanning Zheng",
                "Wei Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17998v1",
                "http://arxiv.org/pdf/2310.17998v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17997v1",
            "title": "Deep Learning Enables Large Depth-of-Field Images for\n  Sub-Diffraction-Limit Scanning Superlens Microscopy",
            "updated": "2023-10-27T09:16:56Z",
            "published": "2023-10-27T09:16:56Z",
            "summary": "Scanning electron microscopy (SEM) is indispensable in diverse applications\nranging from microelectronics to food processing because it provides large\ndepth-of-field images with a resolution beyond the optical diffraction limit.\nHowever, the technology requires coating conductive films on insulator samples\nand a vacuum environment. We use deep learning to obtain the mapping\nrelationship between optical super-resolution (OSR) images and SEM domain\nimages, which enables the transformation of OSR images into SEM-like large\ndepth-of-field images. Our custom-built scanning superlens microscopy (SSUM)\nsystem, which requires neither coating samples by conductive films nor a vacuum\nenvironment, is used to acquire the OSR images with features down to ~80 nm.\nThe peak signal-to-noise ratio (PSNR) and structural similarity index measure\nvalues indicate that the deep learning method performs excellently in\nimage-to-image translation, with a PSNR improvement of about 0.74 dB over the\noptical super-resolution images. The proposed method provides a high level of\ndetail in the reconstructed results, indicating that it has broad applicability\nto chip-level defect detection, biological sample analysis, forensics, and\nvarious other fields.",
            "author": [
                "Hui Sun",
                "Hao Luo",
                "Feifei Wang",
                "Qingjiu Chen",
                "Meng Chen",
                "Xiaoduo Wang",
                "Haibo Yu",
                "Guanglie Zhang",
                "Lianqing Liu",
                "Jianping Wang",
                "Dapeng Wu",
                "Wen Jung Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17997v1",
                "http://arxiv.org/pdf/2310.17997v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics",
                "cs.AI",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17974v1",
            "title": "FaultSeg Swin-UNETR: Transformer-Based Self-Supervised Pretraining Model\n  for Fault Recognition",
            "updated": "2023-10-27T08:38:59Z",
            "published": "2023-10-27T08:38:59Z",
            "summary": "This paper introduces an approach to enhance seismic fault recognition\nthrough self-supervised pretraining. Seismic fault interpretation holds great\nsignificance in the fields of geophysics and geology. However, conventional\nmethods for seismic fault recognition encounter various issues, including\ndependence on data quality and quantity, as well as susceptibility to\ninterpreter subjectivity. Currently, automated fault recognition methods\nproposed based on small synthetic datasets experience performance degradation\nwhen applied to actual seismic data. To address these challenges, we have\nintroduced the concept of self-supervised learning, utilizing a substantial\namount of relatively easily obtainable unlabeled seismic data for pretraining.\nSpecifically, we have employed the Swin Transformer model as the core network\nand employed the SimMIM pretraining task to capture unique features related to\ndiscontinuities in seismic data. During the fine-tuning phase, inspired by edge\ndetection techniques, we have also refined the structure of the Swin-UNETR\nmodel, enabling multiscale decoding and fusion for more effective fault\ndetection. Experimental results demonstrate that our proposed method attains\nstate-of-the-art performance on the Thebe dataset, as measured by the OIS and\nODS metrics.",
            "author": [
                "Zeren Zhang",
                "Ran Chen",
                "Jinwen Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17974v1",
                "http://arxiv.org/pdf/2310.17974v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17972v1",
            "title": "CEFL: Carbon-Efficient Federated Learning",
            "updated": "2023-10-27T08:37:10Z",
            "published": "2023-10-27T08:37:10Z",
            "summary": "Federated Learning (FL) distributes machine learning (ML) training across\nmany edge devices to reduce data transfer overhead and protect data privacy.\nSince FL model training may span millions of devices and is thus\nresource-intensive, prior work has focused on improving its resource efficiency\nto optimize time-to-accuracy. However, prior work generally treats all\nresources the same, while, in practice, they may incur widely different costs,\nwhich instead motivates optimizing cost-to-accuracy. To address the problem, we\ndesign CEFL, which uses adaptive cost-aware client selection policies to\noptimize an arbitrary cost metric when training FL models. Our policies extend\nand combine prior work on utility-based client selection and critical learning\nperiods by making them cost-aware. We demonstrate CEFL by designing\ncarbon-efficient FL, where energy's carbon-intensity is the cost, and show that\nit i) reduces carbon emissions by 93\\% and reduces training time by 50%\ncompared to random client selection and ii) reduces carbon emissions by 80%,\nwhile only increasing training time by 38%, compared to a state-of-the-art\napproach that optimizes training time.",
            "author": [
                "Talha Mehboob",
                "Noman Bashir",
                "Jesus Omana Iglesias",
                "Michael Zink",
                "David Irwin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17972v1",
                "http://arxiv.org/pdf/2310.17972v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17966v2",
            "title": "Train Once, Get a Family: State-Adaptive Balances for Offline-to-Online\n  Reinforcement Learning",
            "updated": "2023-10-30T05:22:23Z",
            "published": "2023-10-27T08:30:54Z",
            "summary": "Offline-to-online reinforcement learning (RL) is a training paradigm that\ncombines pre-training on a pre-collected dataset with fine-tuning in an online\nenvironment. However, the incorporation of online fine-tuning can intensify the\nwell-known distributional shift problem. Existing solutions tackle this problem\nby imposing a policy constraint on the policy improvement objective in both\noffline and online learning. They typically advocate a single balance between\npolicy improvement and constraints across diverse data collections. This\none-size-fits-all manner may not optimally leverage each collected sample due\nto the significant variation in data quality across different states. To this\nend, we introduce Family Offline-to-Online RL (FamO2O), a simple yet effective\nframework that empowers existing algorithms to determine state-adaptive\nimprovement-constraint balances. FamO2O utilizes a universal model to train a\nfamily of policies with different improvement/constraint intensities, and a\nbalance model to select a suitable policy for each state. Theoretically, we\nprove that state-adaptive balances are necessary for achieving a higher policy\nperformance upper bound. Empirically, extensive experiments show that FamO2O\noffers a statistically significant improvement over various existing methods,\nachieving state-of-the-art performance on the D4RL benchmark. Codes are\navailable at https://github.com/LeapLabTHU/FamO2O.",
            "author": [
                "Shenzhi Wang",
                "Qisen Yang",
                "Jiawei Gao",
                "Matthieu Gaetan Lin",
                "Hao Chen",
                "Liwei Wu",
                "Ning Jia",
                "Shiji Song",
                "Gao Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17966v2",
                "http://arxiv.org/pdf/2310.17966v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17954v1",
            "title": "Multivessel Coronary Artery Segmentation and Stenosis Localisation using\n  Ensemble Learning",
            "updated": "2023-10-27T08:03:12Z",
            "published": "2023-10-27T08:03:12Z",
            "summary": "Coronary angiography analysis is a common clinical task performed by\ncardiologists to diagnose coronary artery disease (CAD) through an assessment\nof atherosclerotic plaque's accumulation. This study introduces an end-to-end\nmachine learning solution developed as part of our solution for the MICCAI 2023\nAutomatic Region-based Coronary Artery Disease diagnostics using x-ray\nangiography imagEs (ARCADE) challenge, which aims to benchmark solutions for\nmultivessel coronary artery segmentation and potential stenotic lesion\nlocalisation from X-ray coronary angiograms. We adopted a robust baseline model\ntraining strategy to progressively improve performance, comprising five\nsuccessive stages of binary class pretraining, multivessel segmentation,\nfine-tuning using class frequency weighted dataloaders, fine-tuning using\nF1-based curriculum learning strategy (F1-CLS), and finally multi-target\nangiogram view classifier-based collective adaptation. Unlike many other\nmedical imaging procedures, this task exhibits a notable degree of\ninterobserver variability. %, making it particularly amenable to automated\nanalysis. Our ensemble model combines the outputs from six baseline models\nusing the weighted ensembling approach, which our analysis shows is found to\ndouble the predictive accuracy of the proposed solution. The final prediction\nwas further refined, targeting the correction of misclassified blobs. Our\nsolution achieved a mean F1 score of $37.69\\%$ for coronary artery\nsegmentation, and $39.41\\%$ for stenosis localisation, positioning our team in\nthe 5th position on both leaderboards. This work demonstrates the potential of\nautomated tools to aid CAD diagnosis, guide interventions, and improve the\naccuracy of stent injections in clinical settings.",
            "author": [
                "Muhammad Bilal",
                "Dinis Martinho",
                "Reiner Sim",
                "Adnan Qayyum",
                "Hunaid Vohra",
                "Massimo Caputo",
                "Taofeek Akinosho",
                "Sofiat Abioye",
                "Zaheer Khan",
                "Waleed Niaz",
                "Junaid Qadir"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17954v1",
                "http://arxiv.org/pdf/2310.17954v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17952v2",
            "title": "Shape-centered Representation Learning for Visible-Infrared Person\n  Re-identification",
            "updated": "2023-10-30T01:37:18Z",
            "published": "2023-10-27T07:57:24Z",
            "summary": "Current Visible-Infrared Person Re-Identification (VI-ReID) methods\nprioritize extracting distinguishing appearance features, ignoring the natural\nresistance of body shape against modality changes. Initially, we gauged the\ndiscriminative potential of shapes by a straightforward concatenation of shape\nand appearance features. However, two unresolved issues persist in the\nutilization of shape features. One pertains to the dependence on auxiliary\nmodels for shape feature extraction in the inference phase, along with the\nerrors in generated infrared shapes due to the intrinsic modality disparity.\nThe other issue involves the inadequately explored correlation between shape\nand appearance features. To tackle the aforementioned challenges, we propose\nthe Shape-centered Representation Learning framework (ScRL), which focuses on\nlearning shape features and appearance features associated with shapes.\nSpecifically, we devise the Shape Feature Propagation (SFP), facilitating\ndirect extraction of shape features from original images with minimal\ncomplexity costs during inference. To restitute inaccuracies in infrared body\nshapes at the feature level, we present the Infrared Shape Restitution (ISR).\nFurthermore, to acquire appearance features related to shape, we design the\nAppearance Feature Enhancement (AFE), which accentuates identity-related\nfeatures while suppressing identity-unrelated features guided by shape\nfeatures. Extensive experiments are conducted to validate the effectiveness of\nthe proposed ScRL. Achieving remarkable results, the Rank-1 (mAP) accuracy\nattains 76.1%, 71.2%, 92.4% (72.6%, 52.9%, 86.7%) on the SYSU-MM01, HITSZ-VCM,\nRegDB datasets respectively, outperforming existing state-of-the-art methods.",
            "author": [
                "Shuang Li",
                "Jiaxu Leng",
                "Ji Gan",
                "Mengjingcheng Mo",
                "Xinbo Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17952v2",
                "http://arxiv.org/pdf/2310.17952v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17949v2",
            "title": "Instance Segmentation under Occlusions via Location-aware Copy-Paste\n  Data Augmentation",
            "updated": "2023-11-21T05:55:10Z",
            "published": "2023-10-27T07:44:25Z",
            "summary": "Occlusion is a long-standing problem in computer vision, particularly in\ninstance segmentation. ACM MMSports 2023 DeepSportRadar has introduced a\ndataset that focuses on segmenting human subjects within a basketball context\nand a specialized evaluation metric for occlusion scenarios. Given the modest\nsize of the dataset and the highly deformable nature of the objects to be\nsegmented, this challenge demands the application of robust data augmentation\ntechniques and wisely-chosen deep learning architectures. Our work (ranked 1st\nin the competition) first proposes a novel data augmentation technique, capable\nof generating more training samples with wider distribution. Then, we adopt a\nnew architecture - Hybrid Task Cascade (HTC) framework with CBNetV2 as backbone\nand MaskIoU head to improve segmentation performance. Furthermore, we employ a\nStochastic Weight Averaging (SWA) training strategy to improve the model's\ngeneralization. As a result, we achieve a remarkable occlusion score (OM) of\n0.533 on the challenge dataset, securing the top-1 position on the leaderboard.\nSource code is available at this\nhttps://github.com/nguyendinhson-kaist/MMSports23-Seg-AutoID.",
            "author": [
                "Son Nguyen",
                "Mikel Lainsa",
                "Hung Dao",
                "Daeyoung Kim",
                "Giang Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17949v2",
                "http://arxiv.org/pdf/2310.17949v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17945v1",
            "title": "A Comprehensive and Reliable Feature Attribution Method: Double-sided\n  Remove and Reconstruct (DoRaR)",
            "updated": "2023-10-27T07:40:45Z",
            "published": "2023-10-27T07:40:45Z",
            "summary": "The limited transparency of the inner decision-making mechanism in deep\nneural networks (DNN) and other machine learning (ML) models has hindered their\napplication in several domains. In order to tackle this issue, feature\nattribution methods have been developed to identify the crucial features that\nheavily influence decisions made by these black box models. However, many\nfeature attribution methods have inherent downsides. For example, one category\nof feature attribution methods suffers from the artifacts problem, which feeds\nout-of-distribution masked inputs directly through the classifier that was\noriginally trained on natural data points. Another category of feature\nattribution method finds explanations by using jointly trained feature\nselectors and predictors. While avoiding the artifacts problem, this new\ncategory suffers from the Encoding Prediction in the Explanation (EPITE)\nproblem, in which the predictor's decisions rely not on the features, but on\nthe masks that selects those features. As a result, the credibility of\nattribution results is undermined by these downsides. In this research, we\nintroduce the Double-sided Remove and Reconstruct (DoRaR) feature attribution\nmethod based on several improvement methods that addresses these issues. By\nconducting thorough testing on MNIST, CIFAR10 and our own synthetic dataset, we\ndemonstrate that the DoRaR feature attribution method can effectively bypass\nthe above issues and can aid in training a feature selector that outperforms\nother state-of-the-art feature attribution methods. Our code is available at\nhttps://github.com/dxq21/DoRaR.",
            "author": [
                "Dong Qin",
                "George Amariucai",
                "Daji Qiao",
                "Yong Guan",
                "Shen Fu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17945v1",
                "http://arxiv.org/pdf/2310.17945v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17944v1",
            "title": "Trustworthy Edge Machine Learning: A Survey",
            "updated": "2023-10-27T07:39:54Z",
            "published": "2023-10-27T07:39:54Z",
            "summary": "The convergence of Edge Computing (EC) and Machine Learning (ML), known as\nEdge Machine Learning (EML), has become a highly regarded research area by\nutilizing distributed network resources to perform joint training and inference\nin a cooperative manner. However, EML faces various challenges due to resource\nconstraints, heterogeneous network environments, and diverse service\nrequirements of different applications, which together affect the\ntrustworthiness of EML in the eyes of its stakeholders. This survey provides a\ncomprehensive summary of definitions, attributes, frameworks, techniques, and\nsolutions for trustworthy EML. Specifically, we first emphasize the importance\nof trustworthy EML within the context of Sixth-Generation (6G) networks. We\nthen discuss the necessity of trustworthiness from the perspective of\nchallenges encountered during deployment and real-world application scenarios.\nSubsequently, we provide a preliminary definition of trustworthy EML and\nexplore its key attributes. Following this, we introduce fundamental frameworks\nand enabling technologies for trustworthy EML systems, and provide an in-depth\nliterature review of the latest solutions to enhance trustworthiness of EML.\nFinally, we discuss corresponding research challenges and open issues.",
            "author": [
                "Xiaojie Wang",
                "Beibei Wang",
                "Yu Wu",
                "Zhaolong Ning",
                "Song Guo",
                "Fei Richard Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17944v1",
                "http://arxiv.org/pdf/2310.17944v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17942v1",
            "title": "Diversifying Spatial-Temporal Perception for Video Domain Generalization",
            "updated": "2023-10-27T07:36:36Z",
            "published": "2023-10-27T07:36:36Z",
            "summary": "Video domain generalization aims to learn generalizable video classification\nmodels for unseen target domains by training in a source domain. A critical\nchallenge of video domain generalization is to defend against the heavy\nreliance on domain-specific cues extracted from the source domain when\nrecognizing target videos. To this end, we propose to perceive diverse\nspatial-temporal cues in videos, aiming to discover potential domain-invariant\ncues in addition to domain-specific cues. We contribute a novel model named\nSpatial-Temporal Diversification Network (STDN), which improves the diversity\nfrom both space and time dimensions of video data. First, our STDN proposes to\ndiscover various types of spatial cues within individual frames by spatial\ngrouping. Then, our STDN proposes to explicitly model spatial-temporal\ndependencies between video contents at multiple space-time scales by\nspatial-temporal relation modeling. Extensive experiments on three benchmarks\nof different types demonstrate the effectiveness and versatility of our\napproach.",
            "author": [
                "Kun-Yu Lin",
                "Jia-Run Du",
                "Yipeng Gao",
                "Jiaming Zhou",
                "Wei-Shi Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17942v1",
                "http://arxiv.org/pdf/2310.17942v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17940v4",
            "title": "Unified Segment-to-Segment Framework for Simultaneous Sequence\n  Generation",
            "updated": "2023-11-30T08:26:16Z",
            "published": "2023-10-27T07:34:51Z",
            "summary": "Simultaneous sequence generation is a pivotal task for real-time scenarios,\nsuch as streaming speech recognition, simultaneous machine translation and\nsimultaneous speech translation, where the target sequence is generated while\nreceiving the source sequence. The crux of achieving high-quality generation\nwith low latency lies in identifying the optimal moments for generating,\naccomplished by learning a mapping between the source and target sequences.\nHowever, existing methods often rely on task-specific heuristics for different\nsequence types, limiting the model's capacity to adaptively learn the\nsource-target mapping and hindering the exploration of multi-task learning for\nvarious simultaneous tasks. In this paper, we propose a unified\nsegment-to-segment framework (Seg2Seg) for simultaneous sequence generation,\nwhich learns the mapping in an adaptive and unified manner. During the process\nof simultaneous generation, the model alternates between waiting for a source\nsegment and generating a target segment, making the segment serve as the\nnatural bridge between the source and target. To accomplish this, Seg2Seg\nintroduces a latent segment as the pivot between source to target and explores\nall potential source-target mappings via the proposed expectation training,\nthereby learning the optimal moments for generating. Experiments on multiple\nsimultaneous generation tasks demonstrate that Seg2Seg achieves\nstate-of-the-art performance and exhibits better generality across various\ntasks.",
            "author": [
                "Shaolei Zhang",
                "Yang Feng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17940v4",
                "http://arxiv.org/pdf/2310.17940v4"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17936v1",
            "title": "Transformers as Graph-to-Graph Models",
            "updated": "2023-10-27T07:21:37Z",
            "published": "2023-10-27T07:21:37Z",
            "summary": "We argue that Transformers are essentially graph-to-graph models, with\nsequences just being a special case. Attention weights are functionally\nequivalent to graph edges. Our Graph-to-Graph Transformer architecture makes\nthis ability explicit, by inputting graph edges into the attention weight\ncomputations and predicting graph edges with attention-like functions, thereby\nintegrating explicit graphs into the latent graphs learned by pretrained\nTransformers. Adding iterative graph refinement provides a joint embedding of\ninput, output, and latent graphs, allowing non-autoregressive graph prediction\nto optimise the complete graph without any bespoke pipeline or decoding\nstrategy. Empirical results show that this architecture achieves\nstate-of-the-art accuracies for modelling a variety of linguistic structures,\nintegrating very effectively with the latent linguistic representations learned\nby pretraining.",
            "author": [
                "James Henderson",
                "Alireza Mohammadshahi",
                "Andrei C. Coman",
                "Lesly Miculicich"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17936v1",
                "http://arxiv.org/pdf/2310.17936v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18384v1",
            "title": "MicroNAS: Memory and Latency Constrained Hardware-Aware Neural\n  Architecture Search for Time Series Classification on Microcontrollers",
            "updated": "2023-10-27T06:55:15Z",
            "published": "2023-10-27T06:55:15Z",
            "summary": "This paper presents MicroNAS, a system designed to automatically search and\ngenerate neural network architectures capable of classifying time series data\non resource-constrained microcontrollers (MCUs) and generating standard tf-lite\nML models. MicroNAS takes into account user-defined constraints on execution\nlatency and peak memory consumption on a target MCU. This approach ensures that\nthe resulting neural network architectures are optimised for the specific\nconstraints and requirements of the MCU on which they are implemented. To\nachieve this, MicroNAS uses a look-up table estimation approach for accurate\nexecution latency calculations, with a minimum error of only 1.02ms. This\naccurate latency estimation on MCUs sets it apart from other hardware-aware\nneural architecture search (HW-NAS) methods that use less accurate estimation\ntechniques. Finally, MicroNAS delivers performance close to that of\nstate-of-the-art models running on desktop computers, achieving high\nclassification accuracies on recognised datasets (93.93% on UCI-HAR and 96.33%\non SkodaR) while running on a Cortex-M4 MCU.",
            "author": [
                "Tobias King",
                "Yexu Zhou",
                "Tobias R\u00f6ddiger",
                "Michael Beigl"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18384v1",
                "http://arxiv.org/pdf/2310.18384v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17923v1",
            "title": "Dynamic Grasping of Unknown Objects with a Multi-Fingered Hand",
            "updated": "2023-10-27T06:37:33Z",
            "published": "2023-10-27T06:37:33Z",
            "summary": "An important prerequisite for autonomous robots is their ability to reliably\ngrasp a wide variety of objects. Most state-of-the-art systems employ\nspecialized or simple end-effectors, such as two-jaw grippers, which severely\nlimit the range of objects to manipulate. Additionally, they conventionally\nrequire a structured and fully predictable environment while the vast majority\nof our world is complex, unstructured, and dynamic. This paper presents an\nimplementation to overcome both issues. Firstly, the integration of a\nfive-finger hand enhances the variety of possible grasps and manipulable\nobjects. This kinematically complex end-effector is controlled by a deep\nlearning based generative grasping network. The required virtual model of the\nunknown target object is iteratively completed by processing visual sensor\ndata. Secondly, this visual feedback is employed to realize closed-loop servo\ncontrol which compensates for external disturbances. Our experiments on real\nhardware confirm the system's capability to reliably grasp unknown dynamic\ntarget objects without a priori knowledge of their trajectories. To the best of\nour knowledge, this is the first method to achieve dynamic multi-fingered\ngrasping for unknown objects. A video of the experiments is available at\nhttps://youtu.be/Ut28yM1gnvI.",
            "author": [
                "Yannick Burkhardt",
                "Qian Feng",
                "Karan Sharma",
                "Zhaopeng Chen",
                "Alois Knoll"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17923v1",
                "http://arxiv.org/pdf/2310.17923v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17922v1",
            "title": "Chain-of-Choice Hierarchical Policy Learning for Conversational\n  Recommendation",
            "updated": "2023-10-27T06:36:31Z",
            "published": "2023-10-27T06:36:31Z",
            "summary": "Conversational Recommender Systems (CRS) illuminate user preferences via\nmulti-round interactive dialogues, ultimately navigating towards precise and\nsatisfactory recommendations. However, contemporary CRS are limited to\ninquiring binary or multi-choice questions based on a single attribute type\n(e.g., color) per round, which causes excessive rounds of interaction and\ndiminishes the user's experience. To address this, we propose a more realistic\nand efficient conversational recommendation problem setting, called\nMulti-Type-Attribute Multi-round Conversational Recommendation (MTAMCR), which\nenables CRS to inquire about multi-choice questions covering multiple types of\nattributes in each round, thereby improving interactive efficiency. Moreover,\nby formulating MTAMCR as a hierarchical reinforcement learning task, we propose\na Chain-of-Choice Hierarchical Policy Learning (CoCHPL) framework to enhance\nboth the questioning efficiency and recommendation effectiveness in MTAMCR.\nSpecifically, a long-term policy over options (i.e., ask or recommend)\ndetermines the action type, while two short-term intra-option policies\nsequentially generate the chain of attributes or items through multi-step\nreasoning and selection, optimizing the diversity and interdependence of\nquestioning attributes. Finally, extensive experiments on four benchmarks\ndemonstrate the superior performance of CoCHPL over prevailing state-of-the-art\nmethods.",
            "author": [
                "Wei Fan",
                "Weijia Zhang",
                "Weiqi Wang",
                "Yangqiu Song",
                "Hao Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17922v1",
                "http://arxiv.org/pdf/2310.17922v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17915v1",
            "title": "Lifting the Veil: Unlocking the Power of Depth in Q-learning",
            "updated": "2023-10-27T06:15:33Z",
            "published": "2023-10-27T06:15:33Z",
            "summary": "With the help of massive data and rich computational resources, deep\nQ-learning has been widely used in operations research and management science\nand has contributed to great success in numerous applications, including\nrecommender systems, supply chains, games, and robotic manipulation. However,\nthe success of deep Q-learning lacks solid theoretical verification and\ninterpretability. The aim of this paper is to theoretically verify the power of\ndepth in deep Q-learning. Within the framework of statistical learning theory,\nwe rigorously prove that deep Q-learning outperforms its traditional version by\ndemonstrating its good generalization error bound. Our results reveal that the\nmain reason for the success of deep Q-learning is the excellent performance of\ndeep neural networks (deep nets) in capturing the special properties of rewards\nnamely, spatial sparseness and piecewise constancy, rather than their large\ncapacities. In this paper, we make fundamental contributions to the field of\nreinforcement learning by answering to the following three questions: Why does\ndeep Q-learning perform so well? When does deep Q-learning perform better than\ntraditional Q-learning? How many samples are required to achieve a specific\nprediction accuracy for deep Q-learning? Our theoretical assertions are\nverified by applying deep Q-learning in the well-known beer game in supply\nchain management and a simulated recommender system.",
            "author": [
                "Shao-Bo Lin",
                "Tao Li",
                "Shaojie Tang",
                "Yao Wang",
                "Ding-Xuan Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17915v1",
                "http://arxiv.org/pdf/2310.17915v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17912v1",
            "title": "Restoring the Broken Covenant Between Compilers and Deep Learning\n  Accelerators",
            "updated": "2023-10-27T06:14:45Z",
            "published": "2023-10-27T06:14:45Z",
            "summary": "Deep learning accelerators address the computational demands of Deep Neural\nNetworks (DNNs), departing from the traditional Von Neumann execution model.\nThey leverage specialized hardware to align with the application domain's\nstructure. Compilers for these accelerators face distinct challenges compared\nto those for general-purpose processors. These challenges include exposing and\nmanaging more micro-architectural features, handling software-managed scratch\npads for on-chip storage, explicitly managing data movement, and matching DNN\nlayers with varying hardware capabilities. These complexities necessitate a new\napproach to compiler design, as traditional compilers mainly focused on\ngenerating fine-grained instruction sequences while abstracting\nmicro-architecture details. This paper introduces the Architecture Covenant\nGraph (ACG), an abstract representation of an architectural structure's\ncomponents and their programmable capabilities. By enabling the compiler to\nwork with the ACG, it allows for adaptable compilation workflows when making\nchanges to accelerator design, reducing the need for a complete compiler\nredevelopment. Codelets, which express DNN operation functionality and evolve\ninto execution mappings on the ACG, are key to this process. The Covenant\ncompiler efficiently targets diverse deep learning accelerators, achieving\n93.8% performance compared to state-of-the-art, hand-tuned DNN layer\nimplementations when compiling 14 DNN layers from various models on two\ndifferent architectures.",
            "author": [
                "Sean Kinzer",
                "Soroush Ghodrati",
                "Rohan Mahapatra",
                "Byung Hoon Ahn",
                "Edwin Mascarenhas",
                "Xiaolong Li",
                "Janarbek Matai",
                "Liang Zhang",
                "Hadi Esmaeilzadeh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17912v1",
                "http://arxiv.org/pdf/2310.17912v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17903v1",
            "title": "Pitfalls in Language Models for Code Intelligence: A Taxonomy and Survey",
            "updated": "2023-10-27T05:32:57Z",
            "published": "2023-10-27T05:32:57Z",
            "summary": "Modern language models (LMs) have been successfully employed in source code\ngeneration and understanding, leading to a significant increase in research\nfocused on learning-based code intelligence, such as automated bug repair, and\ntest case generation. Despite their great potential, language models for code\nintelligence (LM4Code) are susceptible to potential pitfalls, which hinder\nrealistic performance and further impact their reliability and applicability in\nreal-world deployment. Such challenges drive the need for a comprehensive\nunderstanding - not just identifying these issues but delving into their\npossible implications and existing solutions to build more reliable language\nmodels tailored to code intelligence. Based on a well-defined systematic\nresearch approach, we conducted an extensive literature review to uncover the\npitfalls inherent in LM4Code. Finally, 67 primary studies from top-tier venues\nhave been identified. After carefully examining these studies, we designed a\ntaxonomy of pitfalls in LM4Code research and conducted a systematic study to\nsummarize the issues, implications, current solutions, and challenges of\ndifferent pitfalls for LM4Code systems. We developed a comprehensive\nclassification scheme that dissects pitfalls across four crucial aspects: data\ncollection and labeling, system design and learning, performance evaluation,\nand deployment and maintenance. Through this study, we aim to provide a roadmap\nfor researchers and practitioners, facilitating their understanding and\nutilization of LM4Code in reliable and trustworthy ways.",
            "author": [
                "Xinyu She",
                "Yue Liu",
                "Yanjie Zhao",
                "Yiling He",
                "Li Li",
                "Chakkrit Tantithamthavorn",
                "Zhan Qin",
                "Haoyu Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17903v1",
                "http://arxiv.org/pdf/2310.17903v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17902v1",
            "title": "CPIA Dataset: A Comprehensive Pathological Image Analysis Dataset for\n  Self-supervised Learning Pre-training",
            "updated": "2023-10-27T05:32:16Z",
            "published": "2023-10-27T05:32:16Z",
            "summary": "Pathological image analysis is a crucial field in computer-aided diagnosis,\nwhere deep learning is widely applied. Transfer learning using pre-trained\nmodels initialized on natural images has effectively improved the downstream\npathological performance. However, the lack of sophisticated domain-specific\npathological initialization hinders their potential. Self-supervised learning\n(SSL) enables pre-training without sample-level labels, which has great\npotential to overcome the challenge of expensive annotations. Thus, studies\nfocusing on pathological SSL pre-training call for a comprehensive and\nstandardized dataset, similar to the ImageNet in computer vision. This paper\npresents the comprehensive pathological image analysis (CPIA) dataset, a\nlarge-scale SSL pre-training dataset combining 103 open-source datasets with\nextensive standardization. The CPIA dataset contains 21,427,877 standardized\nimages, covering over 48 organs/tissues and about 100 kinds of diseases, which\nincludes two main data types: whole slide images (WSIs) and characteristic\nregions of interest (ROIs). A four-scale WSI standardization process is\nproposed based on the uniform resolution in microns per pixel (MPP), while the\nROIs are divided into three scales artificially. This multi-scale dataset is\nbuilt with the diagnosis habits under the supervision of experienced senior\npathologists. The CPIA dataset facilitates a comprehensive pathological\nunderstanding and enables pattern discovery explorations. Additionally, to\nlaunch the CPIA dataset, several state-of-the-art (SOTA) baselines of SSL\npre-training and downstream evaluation are specially conducted. The CPIA\ndataset along with baselines is available at\nhttps://github.com/zhanglab2021/CPIA_Dataset.",
            "author": [
                "Nan Ying",
                "Yanli Lei",
                "Tianyi Zhang",
                "Shangqing Lyu",
                "Chunhui Li",
                "Sicheng Chen",
                "Zeyu Liu",
                "Yu Zhao",
                "Guanglei Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17902v1",
                "http://arxiv.org/pdf/2310.17902v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17901v1",
            "title": "Improving the Knowledge Gradient Algorithm",
            "updated": "2023-10-27T05:25:02Z",
            "published": "2023-10-27T05:25:02Z",
            "summary": "The knowledge gradient (KG) algorithm is a popular policy for the best arm\nidentification (BAI) problem. It is built on the simple idea of always choosing\nthe measurement that yields the greatest expected one-step improvement in the\nestimate of the best mean of the arms. In this research, we show that this\npolicy has limitations, causing the algorithm not asymptotically optimal. We\nnext provide a remedy for it, by following the manner of one-step look ahead of\nKG, but instead choosing the measurement that yields the greatest one-step\nimprovement in the probability of selecting the best arm. The new policy is\ncalled improved knowledge gradient (iKG). iKG can be shown to be asymptotically\noptimal. In addition, we show that compared to KG, it is easier to extend iKG\nto variant problems of BAI, with the $\\epsilon$-good arm identification and\nfeasible arm identification as two examples. The superior performances of iKG\non these problems are further demonstrated using numerical examples.",
            "author": [
                "Yang Le",
                "Gao Siyang",
                "Ho Chin Pang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17901v1",
                "http://arxiv.org/pdf/2310.17901v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17897v1",
            "title": "Event Generation and Consistence Test for Physics with Sliced\n  Wasserstein Distance",
            "updated": "2023-10-27T05:08:25Z",
            "published": "2023-10-27T05:08:25Z",
            "summary": "In the field of modern high-energy physics research, there is a growing\nemphasis on utilizing deep learning techniques to optimize event simulation,\nthereby expanding the statistical sample size for more accurate physical\nanalysis. Traditional simulation methods often encounter challenges when\ndealing with complex physical processes and high-dimensional data\ndistributions, resulting in slow performance. To overcome these limitations, we\npropose a solution based on deep learning with the sliced Wasserstein distance\nas the loss function. Our method shows its ability on high precision and\nlarge-scale simulations, and demonstrates its effectiveness in handling complex\nphysical processes. By employing an advanced transformer learning architecture,\nwe initiate the learning process from a Monte Carlo sample, and generate\nhigh-dimensional data while preserving all original distribution features. The\ngenerated data samples have passed the consistence test, that is developed to\ncalculate the confidence of the high-dimentional distributions of the generated\ndata samples through permutation tests. This fast simulation strategy, enabled\nby deep learning, holds significant potential not only for increasing sample\nsizes and reducing statistical uncertainties but also for applications in\nnumerical integration, which is crucial in partial wave analysis,\nhigh-precision sample checks, and other related fields. It opens up new\npossibilities for improving event simulation in high-energy physics research.",
            "author": [
                "Chu-Cheng Pan",
                "Xiang Dong",
                "Yu-Chang Sun",
                "Ao-Yan Cheng",
                "Ao-Bo Wang",
                "Yu-Xuan Hu",
                "Hao Cai"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17897v1",
                "http://arxiv.org/pdf/2310.17897v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17896v1",
            "title": "Inferring to C or not to C: Evolutionary games with Bayesian inferential\n  strategies",
            "updated": "2023-10-27T05:06:34Z",
            "published": "2023-10-27T05:06:34Z",
            "summary": "Strategies for sustaining cooperation and preventing exploitation by selfish\nagents in repeated games have mostly been restricted to Markovian strategies\nwhere the response of an agent depends on the actions in the previous round.\nSuch strategies are characterized by lack of learning. However, learning from\naccumulated evidence over time and using the evidence to dynamically update our\nresponse is a key feature of living organisms. Bayesian inference provides a\nframework for such evidence-based learning mechanisms. It is therefore\nimperative to understand how strategies based on Bayesian learning fare in\nrepeated games with Markovian strategies. Here, we consider a scenario where\nthe Bayesian player uses the accumulated evidence of the opponent's actions\nover several rounds to continuously update her belief about the reactive\nopponent's strategy. The Bayesian player can then act on her inferred belief in\ndifferent ways. By studying repeated Prisoner's dilemma games with such\nBayesian inferential strategies, both in infinite and finite populations, we\nidentify the conditions under which such strategies can be evolutionarily\nstable. We find that a Bayesian strategy that is less altruistic than the\ninferred belief about the opponent's strategy can outperform a larger set of\nreactive strategies, whereas one that is more generous than the inferred belief\nis more successful when the benefit-to-cost ratio of mutual cooperation is\nhigh. Our analysis reveals how learning the opponent's strategy through\nBayesian inference, as opposed to utility maximization, can be beneficial in\nthe long run, in preventing exploitation and eventual invasion by reactive\nstrategies.",
            "author": [
                "Arunava Patra",
                "Supratim Sengupta",
                "Ayan Paul",
                "Sagar Chakraborty"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17896v1",
                "http://arxiv.org/pdf/2310.17896v1"
            ],
            "primary_category": "q-bio.PE",
            "category": [
                "q-bio.PE",
                "physics.bio-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06278v1",
            "title": "Boosting Stock Price Prediction with Anticipated Macro Policy Changes",
            "updated": "2023-10-27T04:57:45Z",
            "published": "2023-10-27T04:57:45Z",
            "summary": "Prediction of stock prices plays a significant role in aiding the\ndecision-making of investors. Considering its importance, a growing literature\nhas emerged trying to forecast stock prices with improved accuracy. In this\nstudy, we introduce an innovative approach for forecasting stock prices with\ngreater accuracy. We incorporate external economic environment-related\ninformation along with stock prices. In our novel approach, we improve the\nperformance of stock price prediction by taking into account variations due to\nfuture expected macroeconomic policy changes as investors adjust their current\nbehavior ahead of time based on expected future macroeconomic policy changes.\nFurthermore, we incorporate macroeconomic variables along with historical stock\nprices to make predictions. Results from this strongly support the inclusion of\nfuture economic policy changes along with current macroeconomic information. We\nconfirm the supremacy of our method over the conventional approach using\nseveral tree-based machine-learning algorithms. Results are strongly conclusive\nacross various machine learning models. Our preferred model outperforms the\nconventional approach with an RMSE value of 1.61 compared to an RMSE value of\n1.75 from the conventional approach.",
            "author": [
                "Md Sabbirul Haque",
                "Md Shahedul Amin",
                "Jonayet Miah",
                "Duc Minh Cao",
                "Ashiqul Haque Ahmed"
            ],
            "link": [
                "http://dx.doi.org/10.32996/jmss",
                "http://arxiv.org/abs/2311.06278v1",
                "http://arxiv.org/pdf/2311.06278v1"
            ],
            "primary_category": "q-fin.ST",
            "category": [
                "q-fin.ST",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17890v1",
            "title": "Submodel Partitioning in Hierarchical Federated Learning: Algorithm\n  Design and Convergence Analysis",
            "updated": "2023-10-27T04:42:59Z",
            "published": "2023-10-27T04:42:59Z",
            "summary": "Hierarchical federated learning (HFL) has demonstrated promising scalability\nadvantages over the traditional \"star-topology\" architecture-based federated\nlearning (FL). However, HFL still imposes significant computation,\ncommunication, and storage burdens on the edge, especially when training a\nlarge-scale model over resource-constrained Internet of Things (IoT) devices.\nIn this paper, we propose hierarchical independent submodel training (HIST), a\nnew FL methodology that aims to address these issues in hierarchical settings.\nThe key idea behind HIST is a hierarchical version of model partitioning, where\nwe partition the global model into disjoint submodels in each round, and\ndistribute them across different cells, so that each cell is responsible for\ntraining only one partition of the full model. This enables each client to save\ncomputation/storage costs while alleviating the communication loads throughout\nthe hierarchy. We characterize the convergence behavior of HIST for non-convex\nloss functions under mild assumptions, showing the impact of several attributes\n(e.g., number of cells, local and global aggregation frequency) on the\nperformance-efficiency tradeoff. Finally, through numerical experiments, we\nverify that HIST is able to save communication costs by a wide margin while\nachieving the same target testing accuracy.",
            "author": [
                "Wenzhi Fang",
                "Dong-Jun Han",
                "Christopher G. Brinton"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17890v1",
                "http://arxiv.org/pdf/2310.17890v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17889v1",
            "title": "Towards optimal multimode fiber imaging by leveraging input polarization\n  and conditional generative adversarial networks",
            "updated": "2023-10-27T04:39:23Z",
            "published": "2023-10-27T04:39:23Z",
            "summary": "Deep learning techniques provide a plausible route towards achieving\npractical imaging through multimode fibers. However, the results produced by\nthese methods are often influenced by physical factors like temperature, fiber\nlength, external perturbations, and polarization state of the input light. The\nimpact of other factors, except input light polarization, has been discussed in\nthe literature for imaging applications. The input polarization has been\nconsidered by researchers while looking at the characterization and control of\npolarization in multimode fibers. Here, we show experimentally that the state\nof polarization of light, being injected at multimode fiber input, affects the\nfidelity of reconstructed images from speckle patterns. Certain polarization\nstates produce high-quality images at fiber output, while some yield degraded\nresults. We have designed a conditional generative adversarial network~(CGAN)\nfor image regeneration at various degrees of input light polarization. We\ndemonstrate that in the case of multimode fibers that are held fixed, optimal\nimaging can be achieved by leveraging our CGAN model with the input light\npolarization state, where the fidelity of images is maximum. Our work exhibits\nhigh average structural similarity index values exceeding 0.9, surpassing the\npreviously reported value of 0.8772. We also show that the model can be\ngeneralized to image adequately for all input light polarization states when\nthe fiber has bends or twists. We anticipate our work will be a stepping stone\ntoward developing high-resolution and less invasive multimode fiber endoscopes.",
            "author": [
                "Jawaria Maqbool",
                "Syed Talal Hassan",
                "M. Imran Cheema"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17889v1",
                "http://arxiv.org/pdf/2310.17889v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17887v1",
            "title": "Impressions: Understanding Visual Semiotics and Aesthetic Impact",
            "updated": "2023-10-27T04:30:18Z",
            "published": "2023-10-27T04:30:18Z",
            "summary": "Is aesthetic impact different from beauty? Is visual salience a reflection of\nits capacity for effective communication? We present Impressions, a novel\ndataset through which to investigate the semiotics of images, and how specific\nvisual features and design choices can elicit specific emotions, thoughts and\nbeliefs. We posit that the impactfulness of an image extends beyond formal\ndefinitions of aesthetics, to its success as a communicative act, where style\ncontributes as much to meaning formation as the subject matter. However, prior\nimage captioning datasets are not designed to empower state-of-the-art\narchitectures to model potential human impressions or interpretations of\nimages. To fill this gap, we design an annotation task heavily inspired by\nimage analysis techniques in the Visual Arts to collect 1,440 image-caption\npairs and 4,320 unique annotations exploring impact, pragmatic image\ndescription, impressions, and aesthetic design choices. We show that existing\nmultimodal image captioning and conditional generation models struggle to\nsimulate plausible human responses to images. However, this dataset\nsignificantly improves their ability to model impressions and aesthetic\nevaluations of images through fine-tuning and few-shot adaptation.",
            "author": [
                "Julia Kruk",
                "Caleb Ziems",
                "Diyi Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17887v1",
                "http://arxiv.org/pdf/2310.17887v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17882v1",
            "title": "Machine Learning Infused Distributed Optimization for Coordinating\n  Virtual Power Plant Assets",
            "updated": "2023-10-27T04:11:13Z",
            "published": "2023-10-27T04:11:13Z",
            "summary": "Amid the increasing interest in the deployment of Distributed Energy\nResources (DERs), the Virtual Power Plant (VPP) has emerged as a pivotal tool\nfor aggregating diverse DERs and facilitating their participation in wholesale\nenergy markets. These VPP deployments have been fueled by the Federal Energy\nRegulatory Commission's Order 2222, which makes DERs and VPPs competitive\nacross market segments. However, the diversity and decentralized nature of DERs\npresent significant challenges to the scalable coordination of VPP assets. To\naddress efficiency and speed bottlenecks, this paper presents a novel machine\nlearning-assisted distributed optimization to coordinate VPP assets. Our\nmethod, named LOOP-MAC(Learning to Optimize the Optimization Process for\nMulti-agent Coordination), adopts a multi-agent coordination perspective where\neach VPP agent manages multiple DERs and utilizes neural network approximators\nto expedite the solution search. The LOOP-MAC method employs a gauge map to\nguarantee strict compliance with local constraints, effectively reducing the\nneed for additional post-processing steps. Our results highlight the advantages\nof LOOP-MAC, showcasing accelerated solution times per iteration and\nsignificantly reduced convergence times. The LOOP-MAC method outperforms\nconventional centralized and distributed optimization methods in optimization\ntasks that require repetitive and sequential execution.",
            "author": [
                "Meiyi Li",
                "Javad Mohammadi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17882v1",
                "http://arxiv.org/pdf/2310.17882v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17880v1",
            "title": "Reconstructive Latent-Space Neural Radiance Fields for Efficient 3D\n  Scene Representations",
            "updated": "2023-10-27T03:52:08Z",
            "published": "2023-10-27T03:52:08Z",
            "summary": "Neural Radiance Fields (NeRFs) have proven to be powerful 3D representations,\ncapable of high quality novel view synthesis of complex scenes. While NeRFs\nhave been applied to graphics, vision, and robotics, problems with slow\nrendering speed and characteristic visual artifacts prevent adoption in many\nuse cases. In this work, we investigate combining an autoencoder (AE) with a\nNeRF, in which latent features (instead of colours) are rendered and then\nconvolutionally decoded. The resulting latent-space NeRF can produce novel\nviews with higher quality than standard colour-space NeRFs, as the AE can\ncorrect certain visual artifacts, while rendering over three times faster. Our\nwork is orthogonal to other techniques for improving NeRF efficiency. Further,\nwe can control the tradeoff between efficiency and image quality by shrinking\nthe AE architecture, achieving over 13 times faster rendering with only a small\ndrop in performance. We hope that our approach can form the basis of an\nefficient, yet high-fidelity, 3D scene representation for downstream tasks,\nespecially when retaining differentiability is useful, as in many robotics\nscenarios requiring continual learning.",
            "author": [
                "Tristan Aumentado-Armstrong",
                "Ashkan Mirzaei",
                "Marcus A. Brubaker",
                "Jonathan Kelly",
                "Alex Levinshtein",
                "Konstantinos G. Derpanis",
                "Igor Gilitschenski"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17880v1",
                "http://arxiv.org/pdf/2310.17880v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "I.2.10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17878v1",
            "title": "A Sublinear-Time Spectral Clustering Oracle with Improved Preprocessing\n  Time",
            "updated": "2023-10-27T03:40:37Z",
            "published": "2023-10-27T03:40:37Z",
            "summary": "We address the problem of designing a sublinear-time spectral clustering\noracle for graphs that exhibit strong clusterability. Such graphs contain $k$\nlatent clusters, each characterized by a large inner conductance (at least\n$\\varphi$) and a small outer conductance (at most $\\varepsilon$). Our aim is to\npreprocess the graph to enable clustering membership queries, with the key\nrequirement that both preprocessing and query answering should be performed in\nsublinear time, and the resulting partition should be consistent with a\n$k$-partition that is close to the ground-truth clustering. Previous oracles\nhave relied on either a $\\textrm{poly}(k)\\log n$ gap between inner and outer\nconductances or exponential (in $k/\\varepsilon$) preprocessing time. Our\nalgorithm relaxes these assumptions, albeit at the cost of a slightly higher\nmisclassification ratio. We also show that our clustering oracle is robust\nagainst a few random edge deletions. To validate our theoretical bounds, we\nconducted experiments on synthetic networks.",
            "author": [
                "Ranran Shen",
                "Pan Peng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17878v1",
                "http://arxiv.org/pdf/2310.17878v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17877v1",
            "title": "ASPIRO: Any-shot Structured Parsing-error-Induced ReprOmpting for\n  Consistent Data-to-Text Generation",
            "updated": "2023-10-27T03:39:51Z",
            "published": "2023-10-27T03:39:51Z",
            "summary": "We present ASPIRO, an approach for structured data verbalisation into short\ntemplate sentences in zero to few-shot settings. Unlike previous methods, our\napproach prompts large language models (LLMs) to directly produce\nentity-agnostic templates, rather than relying on LLMs to faithfully copy the\ngiven example entities, or validating/crafting the templates manually. We\nincorporate LLM re-prompting, triggered by algorithmic parsing checks, as well\nas the PARENT metric induced consistency validation to identify and rectify\ntemplate generation problems in real-time. ASPIRO, compared to direct LLM\noutput, averages 66\\% parsing error rate reduction in generated verbalisations\nof RDF triples on the DART dataset. Our best 5-shot text-davinci-003 setup,\nscoring BLEU of 50.62, METEOR of 45.16, BLEURT of 0.82, NUBIA of 0.87, and\nPARENT of 0.8962 on the Rel2Text dataset, competes effectively with recent\nfine-tuned pre-trained language models.",
            "author": [
                "Martin Vejvar",
                "Yasutaka Fujimoto"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17877v1",
                "http://arxiv.org/pdf/2310.17877v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17874v1",
            "title": "SmooSeg: Smoothness Prior for Unsupervised Semantic Segmentation",
            "updated": "2023-10-27T03:29:25Z",
            "published": "2023-10-27T03:29:25Z",
            "summary": "Unsupervised semantic segmentation is a challenging task that segments images\ninto semantic groups without manual annotation. Prior works have primarily\nfocused on leveraging prior knowledge of semantic consistency or priori\nconcepts from self-supervised learning methods, which often overlook the\ncoherence property of image segments. In this paper, we demonstrate that the\nsmoothness prior, asserting that close features in a metric space share the\nsame semantics, can significantly simplify segmentation by casting unsupervised\nsemantic segmentation as an energy minimization problem. Under this paradigm,\nwe propose a novel approach called SmooSeg that harnesses self-supervised\nlearning methods to model the closeness relationships among observations as\nsmoothness signals. To effectively discover coherent semantic segments, we\nintroduce a novel smoothness loss that promotes piecewise smoothness within\nsegments while preserving discontinuities across different segments.\nAdditionally, to further enhance segmentation quality, we design an asymmetric\nteacher-student style predictor that generates smoothly updated pseudo labels,\nfacilitating an optimal fit between observations and labeling outputs. Thanks\nto the rich supervision cues of the smoothness prior, our SmooSeg significantly\noutperforms STEGO in terms of pixel accuracy on three datasets: COCOStuff\n(+14.9%), Cityscapes (+13.0%), and Potsdam-3 (+5.7%).",
            "author": [
                "Mengcheng Lan",
                "Xinjiang Wang",
                "Yiping Ke",
                "Jiaxing Xu",
                "Litong Feng",
                "Wayne Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17874v1",
                "http://arxiv.org/pdf/2310.17874v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17870v1",
            "title": "Ranking with Slot Constraints",
            "updated": "2023-10-27T03:14:50Z",
            "published": "2023-10-27T03:14:50Z",
            "summary": "We introduce the problem of ranking with slot constraints, which can be used\nto model a wide range of application problems -- from college admission with\nlimited slots for different majors, to composing a stratified cohort of\neligible participants in a medical trial. We show that the conventional\nProbability Ranking Principle (PRP) can be highly sub-optimal for\nslot-constrained ranking problems, and we devise a new ranking algorithm,\ncalled MatchRank. The goal of MatchRank is to produce rankings that maximize\nthe number of filled slots if candidates are evaluated by a human decision\nmaker in the order of the ranking. In this way, MatchRank generalizes the PRP,\nand it subsumes the PRP as a special case when there are no slot constraints.\nOur theoretical analysis shows that MatchRank has a strong approximation\nguarantee without any independence assumptions between slots or candidates.\nFurthermore, we show how MatchRank can be implemented efficiently. Beyond the\ntheoretical guarantees, empirical evaluations show that MatchRank can provide\nsubstantial improvements over a range of synthetic and real-world tasks.",
            "author": [
                "Wentao Guo",
                "Andrew Wang",
                "Bradon Thymes",
                "Thorsten Joachims"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17870v1",
                "http://arxiv.org/pdf/2310.17870v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17869v1",
            "title": "Grid Jigsaw Representation with CLIP: A New Perspective on Image\n  Clustering",
            "updated": "2023-10-27T03:07:05Z",
            "published": "2023-10-27T03:07:05Z",
            "summary": "Unsupervised representation learning for image clustering is essential in\ncomputer vision. Although the advancement of visual models has improved image\nclustering with efficient visual representations, challenges still remain.\nFirstly, these features often lack the ability to represent the internal\nstructure of images, hindering the accurate clustering of visually similar\nimages. Secondly, the existing features tend to lack finer-grained semantic\nlabels, limiting the ability to capture nuanced differences and similarities\nbetween images.\n  In this paper, we first introduce Jigsaw based strategy method for image\nclustering called Grid Jigsaw Representation (GJR) with systematic exposition\nfrom pixel to feature in discrepancy against human and computer. We emphasize\nthat this algorithm, which mimics human jigsaw puzzle, can effectively improve\nthe model to distinguish the spatial feature between different samples and\nenhance the clustering ability. GJR modules are appended to a variety of deep\nconvolutional networks and tested with significant improvements on a wide range\nof benchmark datasets including CIFAR-10, CIFAR-100/20, STL-10, ImageNet-10 and\nImageNetDog-15.\n  On the other hand, convergence efficiency is always an important challenge\nfor unsupervised image clustering. Recently, pretrained representation learning\nhas made great progress and released models can extract mature visual\nrepresentations. It is obvious that use the pretrained model as feature\nextractor can speed up the convergence of clustering where our aim is to\nprovide new perspective in image clustering with reasonable resource\napplication and provide new baseline. Further, we innovate pretrain-based Grid\nJigsaw Representation (pGJR) with improvement by GJR. The experiment results\nshow the effectiveness on the clustering task with respect to the ACC, NMI and\nARI three metrics and super fast convergence speed.",
            "author": [
                "Zijie Song",
                "Zhenzhen Hu",
                "Richang Hong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17869v1",
                "http://arxiv.org/pdf/2310.17869v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17868v1",
            "title": "Resource Allocation for Near-Field Communications: Fundamentals, Tools,\n  and Outlooks",
            "updated": "2023-10-27T03:06:56Z",
            "published": "2023-10-27T03:06:56Z",
            "summary": "Extremely large-scale multiple-input-multiple output (XL-MIMO) is a promising\ntechnology to achieve high spectral efficiency (SE) and energy efficiency (EE)\nin future wireless systems. The larger array aperture of XL-MIMO makes\ncommunication scenarios closer to the near-field region. Therefore, near-field\nresource allocation is essential in realizing the above key performance\nindicators (KPIs). Moreover, the overall performance of XL-MIMO systems heavily\ndepends on the channel characteristics of the selected users, eliminating\ninterference between users through beamforming, power control, etc. The above\nresource allocation issue constitutes a complex joint multi-objective\noptimization problem since many variables and parameters must be optimized,\nincluding the spatial degree of freedom, rate, power allocation, and\ntransmission technique. In this article, we review the basic properties of\nnear-field communications and focus on the corresponding \"resource allocation\"\nproblems. First, we identify available resources in near-field communication\nsystems and highlight their distinctions from far-field communications. Then,\nwe summarize optimization tools, such as numerical techniques and machine\nlearning methods, for addressing near-field resource allocation, emphasizing\ntheir strengths and limitations. Finally, several important research directions\nof near-field communications are pointed out for further investigation.",
            "author": [
                "Bokai Xu",
                "Jiayi Zhang",
                "Hongyang Du",
                "Zhe Wang",
                "Yuanwei Liu",
                "Dusit Niyato",
                "Bo Ai",
                "Khaled B. Letaief"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17868v1",
                "http://arxiv.org/pdf/2310.17868v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17867v1",
            "title": "Reproducibility in Multiple Instance Learning: A Case For Algorithmic\n  Unit Tests",
            "updated": "2023-10-27T03:05:11Z",
            "published": "2023-10-27T03:05:11Z",
            "summary": "Multiple Instance Learning (MIL) is a sub-domain of classification problems\nwith positive and negative labels and a \"bag\" of inputs, where the label is\npositive if and only if a positive element is contained within the bag, and\notherwise is negative. Training in this context requires associating the\nbag-wide label to instance-level information, and implicitly contains a causal\nassumption and asymmetry to the task (i.e., you can't swap the labels without\nchanging the semantics). MIL problems occur in healthcare (one malignant cell\nindicates cancer), cyber security (one malicious executable makes an infected\ncomputer), and many other tasks. In this work, we examine five of the most\nprominent deep-MIL models and find that none of them respects the standard MIL\nassumption. They are able to learn anti-correlated instances, i.e., defaulting\nto \"positive\" labels until seeing a negative counter-example, which should not\nbe possible for a correct MIL model. We suspect that enhancements and other\nworks derived from these models will share the same issue. In any context in\nwhich these models are being used, this creates the potential for learning\nincorrect models, which creates risk of operational failure. We identify and\ndemonstrate this problem via a proposed \"algorithmic unit test\", where we\ncreate synthetic datasets that can be solved by a MIL respecting model, and\nwhich clearly reveal learning that violates MIL assumptions. The five evaluated\nmethods each fail one or more of these tests. This provides a model-agnostic\nway to identify violations of modeling assumptions, which we hope will be\nuseful for future development and evaluation of MIL models.",
            "author": [
                "Edward Raff",
                "James Holt"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17867v1",
                "http://arxiv.org/pdf/2310.17867v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17864v1",
            "title": "TorchAudio 2.1: Advancing speech recognition, self-supervised learning,\n  and audio processing components for PyTorch",
            "updated": "2023-10-27T03:00:51Z",
            "published": "2023-10-27T03:00:51Z",
            "summary": "TorchAudio is an open-source audio and speech processing library built for\nPyTorch. It aims to accelerate the research and development of audio and speech\ntechnologies by providing well-designed, easy-to-use, and performant PyTorch\ncomponents. Its contributors routinely engage with users to understand their\nneeds and fulfill them by developing impactful features. Here, we survey\nTorchAudio's development principles and contents and highlight key features we\ninclude in its latest version (2.1): self-supervised learning pre-trained\npipelines and training recipes, high-performance CTC decoders, speech\nrecognition models and training recipes, advanced media I/O capabilities, and\ntools for performing forced alignment, multi-channel speech enhancement, and\nreference-less speech assessment. For a selection of these features, through\nempirical studies, we demonstrate their efficacy and show that they achieve\ncompetitive or state-of-the-art performance.",
            "author": [
                "Jeff Hwang",
                "Moto Hira",
                "Caroline Chen",
                "Xiaohui Zhang",
                "Zhaoheng Ni",
                "Guangzhi Sun",
                "Pingchuan Ma",
                "Ruizhe Huang",
                "Vineel Pratap",
                "Yuekai Zhang",
                "Anurag Kumar",
                "Chin-Yun Yu",
                "Chuang Zhu",
                "Chunxi Liu",
                "Jacob Kahn",
                "Mirco Ravanelli",
                "Peng Sun",
                "Shinji Watanabe",
                "Yangyang Shi",
                "Yumeng Tao",
                "Robin Scheibler",
                "Samuele Cornell",
                "Sean Kim",
                "Stavros Petridis"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17864v1",
                "http://arxiv.org/pdf/2310.17864v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18382v1",
            "title": "From Generative AI to Generative Internet of Things: Fundamentals,\n  Framework, and Outlooks",
            "updated": "2023-10-27T02:58:11Z",
            "published": "2023-10-27T02:58:11Z",
            "summary": "Generative Artificial Intelligence (GAI) possesses the capabilities of\ngenerating realistic data and facilitating advanced decision-making. By\nintegrating GAI into modern Internet of Things (IoT), Generative Internet of\nThings (GIoT) is emerging and holds immense potential to revolutionize various\naspects of society, enabling more efficient and intelligent IoT applications,\nsuch as smart surveillance and voice assistants. In this article, we present\nthe concept of GIoT and conduct an exploration of its potential prospects.\nSpecifically, we first overview four GAI techniques and investigate promising\nGIoT applications. Then, we elaborate on the main challenges in enabling GIoT\nand propose a general GAI-based secure incentive mechanism framework to address\nthem, in which we adopt Generative Diffusion Models (GDMs) for incentive\nmechanism designs and apply blockchain technologies for secure GIoT management.\nMoreover, we conduct a case study on modern Internet of Vehicle traffic\nmonitoring, which utilizes GDMs to generate effective contracts for\nincentivizing users to contribute sensing data with high quality. Finally, we\nsuggest several open directions worth investigating for the future popularity\nof GIoT.",
            "author": [
                "Jinbo Wen",
                "Jiangtian Nie",
                "Jiawen Kang",
                "Dusit Niyato",
                "Hongyang Du",
                "Yang Zhang",
                "Mohsen Guizani"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18382v1",
                "http://arxiv.org/pdf/2310.18382v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.GT",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18381v1",
            "title": "Unveil Sleep Spindles with Concentration of Frequency and Time",
            "updated": "2023-10-27T02:46:58Z",
            "published": "2023-10-27T02:46:58Z",
            "summary": "Objective: Sleep spindles contain crucial brain dynamics information. We\nintroduce the novel non-linear time-frequency analysis tool 'Concentration of\nFrequency and Time' (ConceFT) to create an interpretable automated algorithm\nfor sleep spindle annotation in EEG data and to measure spindle instantaneous\nfrequencies (IFs). Methods: ConceFT effectively reduces stochastic EEG\ninfluence, enhancing spindle visibility in the time-frequency representation.\nOur automated spindle detection algorithm, ConceFT-Spindle (ConceFT-S), is\ncompared to A7 (non-deep learning) and SUMO (deep learning) using Dream and\nMASS benchmark databases. We also quantify spindle IF dynamics. Results:\nConceFT-S achieves F1 scores of 0.749 in Dream and 0.786 in MASS, which is\nequivalent to or surpass A7 and SUMO with statistical significance. We reveal\nthat spindle IF is generally nonlinear. Conclusion: ConceFT offers an accurate,\ninterpretable EEG-based sleep spindle detection algorithm and enables spindle\nIF quantification.",
            "author": [
                "Riki Shimizu",
                "Hau-Tieng Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18381v1",
                "http://arxiv.org/pdf/2310.18381v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cs.LG",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17852v1",
            "title": "Function Space Bayesian Pseudocoreset for Bayesian Neural Networks",
            "updated": "2023-10-27T02:04:31Z",
            "published": "2023-10-27T02:04:31Z",
            "summary": "A Bayesian pseudocoreset is a compact synthetic dataset summarizing essential\ninformation of a large-scale dataset and thus can be used as a proxy dataset\nfor scalable Bayesian inference. Typically, a Bayesian pseudocoreset is\nconstructed by minimizing a divergence measure between the posterior\nconditioning on the pseudocoreset and the posterior conditioning on the full\ndataset. However, evaluating the divergence can be challenging, particularly\nfor the models like deep neural networks having high-dimensional parameters. In\nthis paper, we propose a novel Bayesian pseudocoreset construction method that\noperates on a function space. Unlike previous methods, which construct and\nmatch the coreset and full data posteriors in the space of model parameters\n(weights), our method constructs variational approximations to the coreset\nposterior on a function space and matches it to the full data posterior in the\nfunction space. By working directly on the function space, our method could\nbypass several challenges that may arise when working on a weight space,\nincluding limited scalability and multi-modality issue. Through various\nexperiments, we demonstrate that the Bayesian pseudocoresets constructed from\nour method enjoys enhanced uncertainty quantification and better robustness\nacross various model architectures.",
            "author": [
                "Balhae Kim",
                "Hyungi Lee",
                "Juho Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17852v1",
                "http://arxiv.org/pdf/2310.17852v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17849v1",
            "title": "On Choosing Initial Values of Iteratively Reweighted $\\ell_1$ Algorithms\n  for the Piece-wise Exponential Penalty",
            "updated": "2023-10-27T01:59:04Z",
            "published": "2023-10-27T01:59:04Z",
            "summary": "Computing the proximal operator of the sparsity-promoting piece-wise\nexponential (PiE) penalty $1-e^{-|x|/\\sigma}$ with a given shape parameter\n$\\sigma>0$, which is treated as a popular nonconvex surrogate of $\\ell_0$-norm,\nis fundamental in feature selection via support vector machines, image\nreconstruction, zero-one programming problems, compressed sensing, etc. Due to\nthe nonconvexity of PiE, for a long time, its proximal operator is frequently\nevaluated via an iteratively reweighted $\\ell_1$ algorithm, which substitutes\nPiE with its first-order approximation, however, the obtained solutions only\nare the critical point. Based on the exact characterization of the proximal\noperator of PiE, we explore how the iteratively reweighted $\\ell_1$ solution\ndeviates from the true proximal operator in certain regions, which can be\nexplicitly identified in terms of $\\sigma$, the initial value and the\nregularization parameter in the definition of the proximal operator. Moreover,\nthe initial value can be adaptively and simply chosen to ensure that the\niteratively reweighted $\\ell_1$ solution belongs to the proximal operator of\nPiE.",
            "author": [
                "Rongrong Lin",
                "Shimin Li",
                "Yulan Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17849v1",
                "http://arxiv.org/pdf/2310.17849v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "22E46, 53C35, 57S20"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17848v1",
            "title": "Boosting Data Analytics With Synthetic Volume Expansion",
            "updated": "2023-10-27T01:57:27Z",
            "published": "2023-10-27T01:57:27Z",
            "summary": "Synthetic data generation, a cornerstone of Generative Artificial\nIntelligence, signifies a paradigm shift in data science by addressing data\nscarcity and privacy while enabling unprecedented performance. As synthetic\ndata gains prominence, questions arise concerning the accuracy of statistical\nmethods when applied to synthetic data compared to raw data. In this article,\nwe introduce the Synthetic Data Generation for Analytics framework. This\nframework employs statistical methods on high-fidelity synthetic data generated\nby advanced models such as tabular diffusion and Generative Pre-trained\nTransformer models. These models, trained on raw data, are further enhanced\nwith insights from pertinent studies. A significant discovery within this\nframework is the generational effect: the error of a statistical method on\nsynthetic data initially diminishes with added synthetic data but may\neventually increase or plateau. This phenomenon, rooted in the complexities of\nreplicating raw data distributions, highlights a \"reflection point\"--an optimal\nthreshold in the size of synthetic data determined by specific error metrics.\nThrough three illustrative case studies-sentiment analysis of texts, predictive\nmodeling of structured data, and inference in tabular data--we demonstrate the\neffectiveness of this framework over traditional ones. We underline its\npotential to amplify various statistical methods, including gradient boosting\nfor prediction and hypothesis testing, thereby underscoring the transformative\npotential of synthetic data generation in data science.",
            "author": [
                "Xiaotong Shen",
                "Yifei Liu",
                "Rex Shen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17848v1",
                "http://arxiv.org/pdf/2310.17848v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17844v1",
            "title": "Adaptive operator learning for infinite-dimensional Bayesian inverse\n  problems",
            "updated": "2023-10-27T01:50:33Z",
            "published": "2023-10-27T01:50:33Z",
            "summary": "The fundamental computational issues in Bayesian inverse problems (BIPs)\ngoverned by partial differential equations (PDEs) stem from the requirement of\nrepeated forward model evaluations. A popular strategy to reduce such cost is\nto replace expensive model simulations by computationally efficient\napproximations using operator learning, motivated by recent progresses in deep\nlearning. However, using the approximated model directly may introduce a\nmodeling error, exacerbating the already ill-posedness of inverse problems.\nThus, balancing between accuracy and efficiency is essential for the effective\nimplementation of such approaches. To this end, we develop an adaptive operator\nlearning framework that can reduce modeling error gradually by forcing the\nsurrogate to be accurate in local areas. This is accomplished by fine-tuning\nthe pre-trained approximate model during the inversion process with adaptive\npoints selected by a greedy algorithm, which requires only a few forward model\nevaluations. To validate our approach, we adopt DeepOnet to construct the\nsurrogate and use unscented Kalman inversion (UKI) to approximate the solution\nof BIPs, respectively. Furthermore, we present rigorous convergence guarantee\nin the linear case using the framework of UKI. We test the approach on several\nbenchmarks, including the Darcy flow, the heat source inversion problem, and\nthe reaction diffusion problems. Numerical results demonstrate that our method\ncan significantly reduce computational costs while maintaining inversion\naccuracy.",
            "author": [
                "Zhiwei Gao",
                "Liang Yan",
                "Tao Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17844v1",
                "http://arxiv.org/pdf/2310.17844v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "stat.CO",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17843v1",
            "title": "A Data-Centric Online Market for Machine Learning: From Discovery to\n  Pricing",
            "updated": "2023-10-27T01:49:13Z",
            "published": "2023-10-27T01:49:13Z",
            "summary": "Data fuels machine learning (ML) - rich and high-quality training data is\nessential to the success of ML. However, to transform ML from the race among a\nfew large corporations to an accessible technology that serves numerous normal\nusers' data analysis requests, there still exist important challenges. One gap\nwe observed is that many ML users can benefit from new data that other data\nowners possess, whereas these data owners sit on piles of data without knowing\nwho can benefit from it. This gap creates the opportunity for building an\nonline market that can automatically connect supply with demand. While online\nmatching markets are prevalent (e.g., ride-hailing systems), designing a\ndata-centric market for ML exhibits many unprecedented challenges.\n  This paper develops new techniques to tackle two core challenges in designing\nsuch a market: (a) to efficiently match demand with supply, we design an\nalgorithm to automatically discover useful data for any ML task from a pool of\nthousands of datasets, achieving high-quality matching between ML models and\ndata; (b) to encourage market participation of ML users without much ML\nexpertise, we design a new pricing mechanism for selling data-augmented ML\nmodels. Furthermore, our market is designed to be API-compatible with existing\nonline ML markets like Vertex AI and Sagemaker, making it easy to use while\nproviding better results due to joint data and model search. We envision that\nthe synergy of our data and model discovery algorithm and pricing mechanism\nwill be an important step towards building a new data-centric online market\nthat serves ML users effectively.",
            "author": [
                "Minbiao Han",
                "Jonathan Light",
                "Steven Xia",
                "Sainyam Galhotra",
                "Raul Castro Fernandez",
                "Haifeng Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17843v1",
                "http://arxiv.org/pdf/2310.17843v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17836v1",
            "title": "Positional Encoding-based Resident Identification in Multi-resident\n  Smart Homes",
            "updated": "2023-10-27T01:29:41Z",
            "published": "2023-10-27T01:29:41Z",
            "summary": "We propose a novel resident identification framework to identify residents in\na multi-occupant smart environment. The proposed framework employs a feature\nextraction model based on the concepts of positional encoding. The feature\nextraction model considers the locations of homes as a graph. We design a novel\nalgorithm to build such graphs from layout maps of smart environments. The\nNode2Vec algorithm is used to transform the graph into high-dimensional node\nembeddings. A Long Short-Term Memory (LSTM) model is introduced to predict the\nidentities of residents using temporal sequences of sensor events with the node\nembeddings. Extensive experiments show that our proposed scheme effectively\nidentifies residents in a multi-occupant environment. Evaluation results on two\nreal-world datasets demonstrate that our proposed approach achieves 94.5% and\n87.9% accuracy, respectively.",
            "author": [
                "Zhiyi Song",
                "Dipankar Chaki",
                "Abdallah Lakhdari",
                "Athman Bouguettaya"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17836v1",
                "http://arxiv.org/pdf/2310.17836v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17835v1",
            "title": "One Style is All you Need to Generate a Video",
            "updated": "2023-10-27T01:17:48Z",
            "published": "2023-10-27T01:17:48Z",
            "summary": "In this paper, we propose a style-based conditional video generative model.\nWe introduce a novel temporal generator based on a set of learned sinusoidal\nbases. Our method learns dynamic representations of various actions that are\nindependent of image content and can be transferred between different actors.\nBeyond the significant enhancement of video quality compared to prevalent\nmethods, we demonstrate that the disentangled dynamic and content permit their\nindependent manipulation, as well as temporal GAN-inversion to retrieve and\ntransfer a video motion from one content or identity to another without further\npreprocessing such as landmark points.",
            "author": [
                "Sandeep Manandhar",
                "Auguste Genovesio"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17835v1",
                "http://arxiv.org/pdf/2310.17835v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18377v1",
            "title": "Large-scale Foundation Models and Generative AI for BigData Neuroscience",
            "updated": "2023-10-27T00:44:40Z",
            "published": "2023-10-27T00:44:40Z",
            "summary": "Recent advances in machine learning have made revolutionary breakthroughs in\ncomputer games, image and natural language understanding, and scientific\ndiscovery. Foundation models and large-scale language models (LLMs) have\nrecently achieved human-like intelligence thanks to BigData. With the help of\nself-supervised learning (SSL) and transfer learning, these models may\npotentially reshape the landscapes of neuroscience research and make a\nsignificant impact on the future. Here we present a mini-review on recent\nadvances in foundation models and generative AI models as well as their\napplications in neuroscience, including natural language and speech, semantic\nmemory, brain-machine interfaces (BMIs), and data augmentation. We argue that\nthis paradigm-shift framework will open new avenues for many neuroscience\nresearch directions and discuss the accompanying challenges and opportunities.",
            "author": [
                "Ran Wang",
                "Zhe Sage Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18377v1",
                "http://arxiv.org/pdf/2310.18377v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cs.AI",
                "cs.HC",
                "cs.LG",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17829v1",
            "title": "Hybrid Optical Turbulence Models Using Machine Learning and Local\n  Measurements",
            "updated": "2023-10-27T00:41:55Z",
            "published": "2023-10-27T00:41:55Z",
            "summary": "Accurate prediction of atmospheric optical turbulence in localized\nenvironments is essential for estimating the performance of free-space optical\nsystems. Macro-meteorological models developed to predict turbulent effects in\none environment may fail when applied in new environments. However, existing\nmacro-meteorological models are expected to offer some predictive power.\nBuilding a new model from locally-measured macro-meteorology and scintillometer\nreadings can require significant time and resources, as well as a large number\nof observations. These challenges motivate the development of a\nmachine-learning informed hybrid model framework. By combining some baseline\nmacro-meteorological model with local observations, hybrid models were trained\nto improve upon the predictive power of each baseline model. Comparisons\nbetween the performance of the hybrid models, the selected baseline\nmacro-meteorological models, and machine-learning models trained only on local\nobservations highlight potential use cases for the hybrid model framework when\nlocal data is expensive to collect. Both the hybrid and data-only models were\ntrained using the Gradient Boosted Decision Tree (GBDT) architecture with a\nvariable number of in-situ meteorological observations. The hybrid and\ndata-only models were found to outperform three baseline macro-meteorological\nmodels, even for low numbers of observations, in some cases as little as one\nday. For the first baseline macro-meteorological model investigated, the hybrid\nmodel achieves an estimated 29% reduction in mean absolute error (MAE) using\nonly one days-equivalent of observation, growing to 41% after only two days,\nand 68% after 180 days-equivalent training data. The number of days-equivalent\ntraining data required is potentially indicative of the seasonal variation in\nthe local microclimate and its propagation environment.",
            "author": [
                "Christopher Jellen",
                "Charles Nelson",
                "John Burkhardt",
                "Cody Brownell"
            ],
            "link": [
                "http://dx.doi.org/10.1364/AO.487280",
                "http://arxiv.org/abs/2310.17829v1",
                "http://arxiv.org/pdf/2310.17829v1"
            ],
            "primary_category": "physics.ao-ph",
            "category": [
                "physics.ao-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18376v1",
            "title": "SQLformer: Deep Auto-Regressive Query Graph Generation for Text-to-SQL\n  Translation",
            "updated": "2023-10-27T00:13:59Z",
            "published": "2023-10-27T00:13:59Z",
            "summary": "In recent years, there has been growing interest in text-to-SQL translation,\nwhich is the task of converting natural language questions into executable SQL\nqueries. This technology is important for its potential to democratize data\nextraction from databases. However, some of its key hurdles include domain\ngeneralisation, which is the ability to adapt to previously unseen databases,\nand alignment of natural language questions with the corresponding SQL queries.\nTo overcome these challenges, we introduce SQLformer, a novel Transformer\narchitecture specifically crafted to perform text-to-SQL translation tasks. Our\nmodel predicts SQL queries as abstract syntax trees (ASTs) in an autoregressive\nway, incorporating structural inductive bias in the encoder and decoder layers.\nThis bias, guided by database table and column selection, aids the decoder in\ngenerating SQL query ASTs represented as graphs in a Breadth-First Search\ncanonical order. Comprehensive experiments illustrate the state-of-the-art\nperformance of SQLformer in the challenging text-to-SQL Spider benchmark. Our\nimplementation is available at https://github.com/AdrianBZG/SQLformer",
            "author": [
                "Adri\u00e1n Bazaga",
                "Pietro Li\u00f2",
                "Gos Micklem"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18376v1",
                "http://arxiv.org/pdf/2310.18376v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17820v1",
            "title": "Sparse Bayesian Multidimensional Item Response Theory",
            "updated": "2023-10-26T23:50:50Z",
            "published": "2023-10-26T23:50:50Z",
            "summary": "Multivariate Item Response Theory (MIRT) is sought-after widely by applied\nresearchers looking for interpretable (sparse) explanations underlying response\npatterns in questionnaire data. There is, however, an unmet demand for such\nsparsity discovery tools in practice. Our paper develops a Bayesian platform\nfor binary and ordinal item MIRT which requires minimal tuning and scales well\non relatively large datasets due to its parallelizable features. Bayesian\nmethodology for MIRT models has traditionally relied on MCMC simulation, which\ncannot only be slow in practice, but also often renders exact sparsity recovery\nimpossible without additional thresholding. In this work, we develop a scalable\nBayesian EM algorithm to estimate sparse factor loadings from binary and\nordinal item responses. We address the seemingly insurmountable problem of\nunknown latent factor dimensionality with tools from Bayesian nonparametrics\nwhich enable estimating the number of factors. Rotations to sparsity through\nparameter expansion further enhance convergence and interpretability without\nidentifiability constraints. In our simulation study, we show that our method\nreliably recovers both the factor dimensionality as well as the latent\nstructure on high-dimensional synthetic data even for small samples. We\ndemonstrate the practical usefulness of our approach on two datasets: an\neducational item response dataset and a quality-of-life measurement dataset.\nBoth demonstrations show that our tool yields interpretable estimates,\nfacilitating interesting discoveries that might otherwise go unnoticed under a\npure confirmatory factor analysis setting. We provide an easy-to-use software\nwhich is a useful new addition to the MIRT toolkit and which will hopefully\nserve as the go-to method for practitioners.",
            "author": [
                "Jiguang Li",
                "Robert Gibbons",
                "Veronika Rockova"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17820v1",
                "http://arxiv.org/pdf/2310.17820v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17813v1",
            "title": "A Spectral Condition for Feature Learning",
            "updated": "2023-10-26T23:17:39Z",
            "published": "2023-10-26T23:17:39Z",
            "summary": "The push to train ever larger neural networks has motivated the study of\ninitialization and training at large network width. A key challenge is to scale\ntraining so that a network's internal representations evolve nontrivially at\nall widths, a process known as feature learning. Here, we show that feature\nlearning is achieved by scaling the spectral norm of weight matrices and their\nupdates like $\\sqrt{\\texttt{fan-out}/\\texttt{fan-in}}$, in contrast to widely\nused but heuristic scalings based on Frobenius norm and entry size. Our\nspectral scaling analysis also leads to an elementary derivation of\n\\emph{maximal update parametrization}. All in all, we aim to provide the reader\nwith a solid conceptual understanding of feature learning in neural networks.",
            "author": [
                "Greg Yang",
                "James B. Simon",
                "Jeremy Bernstein"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17813v1",
                "http://arxiv.org/pdf/2310.17813v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17807v1",
            "title": "Clover: Closed-Loop Verifiable Code Generation",
            "updated": "2023-10-26T22:58:19Z",
            "published": "2023-10-26T22:58:19Z",
            "summary": "The use of large language models for code generation is a rapidly growing\ntrend in software development. However, without effective methods for ensuring\nthe correctness of generated code, this trend could lead to any number of\nundesirable outcomes. In this paper, we lay out a vision for addressing this\nchallenge: the Clover paradigm, short for Closed-Loop Verifiable Code\nGeneration, which reduces correctness checking to the more accessible problem\nof consistency checking. At the core of Clover lies a checker that performs\nconsistency checks among code, docstrings, and formal annotations. The checker\nis implemented using a novel integration of formal verification tools and large\nlanguage models. We provide a theoretical analysis to support our thesis that\nClover should be effective at consistency checking. We also empirically\ninvestigate its feasibility on a hand-designed dataset (CloverBench) featuring\nannotated Dafny programs at a textbook level of difficulty. Experimental\nresults show that for this dataset, (i) LLMs are reasonably successful at\nautomatically generating formal specifications; and (ii) our consistency\nchecker achieves a promising acceptance rate (up to 87%) for correct instances\nwhile maintaining zero tolerance for incorrect ones (no false positives).",
            "author": [
                "Chuyue Sun",
                "Ying Sheng",
                "Oded Padon",
                "Clark Barrett"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17807v1",
                "http://arxiv.org/pdf/2310.17807v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17805v1",
            "title": "Reward Scale Robustness for Proximal Policy Optimization via DreamerV3\n  Tricks",
            "updated": "2023-10-26T22:40:30Z",
            "published": "2023-10-26T22:40:30Z",
            "summary": "Most reinforcement learning methods rely heavily on dense, well-normalized\nenvironment rewards. DreamerV3 recently introduced a model-based method with a\nnumber of tricks that mitigate these limitations, achieving state-of-the-art on\na wide range of benchmarks with a single set of hyperparameters. This result\nsparked discussion about the generality of the tricks, since they appear to be\napplicable to other reinforcement learning algorithms. Our work applies\nDreamerV3's tricks to PPO and is the first such empirical study outside of the\noriginal work. Surprisingly, we find that the tricks presented do not transfer\nas general improvements to PPO. We use a high quality PPO reference\nimplementation and present extensive ablation studies totaling over 10,000 A100\nhours on the Arcade Learning Environment and the DeepMind Control Suite. Though\nour experiments demonstrate that these tricks do not generally outperform PPO,\nwe identify cases where they succeed and offer insight into the relationship\nbetween the implementation tricks. In particular, PPO with these tricks\nperforms comparably to PPO on Atari games with reward clipping and\nsignificantly outperforms PPO without reward clipping.",
            "author": [
                "Ryan Sullivan",
                "Akarsh Kumar",
                "Shengyi Huang",
                "John P. Dickerson",
                "Joseph Suarez"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17805v1",
                "http://arxiv.org/pdf/2310.17805v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17804v1",
            "title": "BlackJack: Secure machine learning on IoT devices through hardware-based\n  shuffling",
            "updated": "2023-10-26T22:37:52Z",
            "published": "2023-10-26T22:37:52Z",
            "summary": "Neural networks are seeing increased use in diverse Internet of Things (IoT)\napplications such as healthcare, smart homes and industrial monitoring. Their\nwidespread use makes neural networks a lucrative target for theft. An attacker\ncan obtain a model without having access to the training data or incurring the\ncost of training. Also, networks trained using private data (e.g., medical\nrecords) can reveal information about this data. Networks can be stolen by\nleveraging side channels such as power traces of the IoT device when it is\nrunning the network. Existing attacks require operations to occur in the same\norder each time; an attacker must collect and analyze several traces of the\ndevice to steal the network. Therefore, to prevent this type of attack, we\nrandomly shuffle the order of operations each time. With shuffling, each\noperation can now happen at many different points in each execution, making the\nattack intractable. However, we show that shuffling in software can leak\ninformation which can be used to subvert this solution. Therefore, to perform\nsecure shuffling and reduce latency, we present BlackJack, hardware added as a\nfunctional unit within the CPU. BlackJack secures neural networks on IoT\ndevices by increasing the time needed for an attack to centuries, while adding\njust 2.46% area, 3.28% power and 0.56% latency overhead on an ARM M0+ SoC.",
            "author": [
                "Karthik Ganesan",
                "Michal Fishkin",
                "Ourong Lin",
                "Natalie Enright Jerger"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17804v1",
                "http://arxiv.org/pdf/2310.17804v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AR",
                "C.1"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03373v1",
            "title": "Unscrambling the Rectification of Adversarial Attacks Transferability\n  across Computer Networks",
            "updated": "2023-10-26T22:36:24Z",
            "published": "2023-10-26T22:36:24Z",
            "summary": "Convolutional neural networks (CNNs) models play a vital role in achieving\nstate-of-the-art performances in various technological fields. CNNs are not\nlimited to Natural Language Processing (NLP) or Computer Vision (CV) but also\nhave substantial applications in other technological domains, particularly in\ncybersecurity. The reliability of CNN's models can be compromised because of\ntheir susceptibility to adversarial attacks, which can be generated\neffortlessly, easily applied, and transferred in real-world scenarios.\n  In this paper, we present a novel and comprehensive method to improve the\nstrength of attacks and assess the transferability of adversarial examples in\nCNNs when such strength changes, as well as whether the transferability\nproperty issue exists in computer network applications. In the context of our\nstudy, we initially examined six distinct modes of attack: the Carlini and\nWagner (C&W), Fast Gradient Sign Method (FGSM), Iterative Fast Gradient Sign\nMethod (I-FGSM), Jacobian-based Saliency Map (JSMA), Limited-memory Broyden\nfletcher Goldfarb Shanno (L-BFGS), and Projected Gradient Descent (PGD) attack.\nWe applied these attack techniques on two popular datasets: the CIC and UNSW\ndatasets. The outcomes of our experiment demonstrate that an improvement in\ntransferability occurs in the targeted scenarios for FGSM, JSMA, LBFGS, and\nother attacks. Our findings further indicate that the threats to security posed\nby adversarial examples, even in computer network applications, necessitate the\ndevelopment of novel defense mechanisms to enhance the security of DL-based\ntechniques.",
            "author": [
                "Ehsan Nowroozi",
                "Samaneh Ghelichkhani",
                "Imran Haider",
                "Ali Dehghantanha"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03373v1",
                "http://arxiv.org/pdf/2311.03373v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17801v1",
            "title": "Image Prior and Posterior Conditional Probability Representation for\n  Efficient Damage Assessment",
            "updated": "2023-10-26T22:17:37Z",
            "published": "2023-10-26T22:17:37Z",
            "summary": "It is important to quantify Damage Assessment (DA) for Human Assistance and\nDisaster Response (HADR) applications. In this paper, to achieve efficient and\nscalable DA in HADR, an image prior and posterior conditional probability\n(IP2CP) is developed as an effective computational imaging representation.\nEquipped with the IP2CP representation, the matching pre- and post-disaster\nimages are effectively encoded into one image that is then processed using deep\nlearning approaches to determine the damage levels. Two scenarios of crucial\nimportance for the practical use of DA in HADR applications are examined:\npixel-wise semantic segmentation and patch-based contrastive learning-based\nglobal damage classification. Results achieved by IP2CP in both scenarios\ndemonstrate promising performances, showing that our IP2CP-based methods within\nthe deep learning framework can effectively achieve data and computational\nefficiency, which is of utmost importance for the DA in HADR applications.",
            "author": [
                "Jie Wei",
                "Weicong Feng",
                "Erik Blasch",
                "Erika Ardiles-Cruz",
                "Haibin Ling"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17801v1",
                "http://arxiv.org/pdf/2310.17801v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "I.4.6, I.5.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17800v1",
            "title": "Interacting Diffusion Processes for Event Sequence Forecasting",
            "updated": "2023-10-26T22:17:25Z",
            "published": "2023-10-26T22:17:25Z",
            "summary": "Neural Temporal Point Processes (TPPs) have emerged as the primary framework\nfor predicting sequences of events that occur at irregular time intervals, but\ntheir sequential nature can hamper performance for long-horizon forecasts. To\naddress this, we introduce a novel approach that incorporates a diffusion\ngenerative model. The model facilitates sequence-to-sequence prediction,\nallowing multi-step predictions based on historical event sequences. In\ncontrast to previous approaches, our model directly learns the joint\nprobability distribution of types and inter-arrival times for multiple events.\nThis allows us to fully leverage the high dimensional modeling capability of\nmodern generative models. Our model is composed of two diffusion processes, one\nfor the time intervals and one for the event types. These processes interact\nthrough their respective denoising functions, which can take as input\nintermediate representations from both processes, allowing the model to learn\ncomplex interactions. We demonstrate that our proposal outperforms\nstate-of-the-art baselines for long-horizon forecasting of TPP.",
            "author": [
                "Mai Zeng",
                "Florence Regol",
                "Mark Coates"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17800v1",
                "http://arxiv.org/pdf/2310.17800v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17797v1",
            "title": "Neuromorphic Online Clustering and Classification",
            "updated": "2023-10-26T21:59:19Z",
            "published": "2023-10-26T21:59:19Z",
            "summary": "The bottom two layers of a neuromorphic architecture are designed and shown\nto be capable of online clustering and supervised classification. An active\nspiking dendrite model is used, and a single dendritic segment performs\nessentially the same function as a classic integrate-and-fire point neuron. A\nsingle dendrite is then composed of multiple segments and is capable of online\nclustering. Although this work focuses primarily on dendrite functionality, a\nmulti-point neuron can be formed by combining multiple dendrites. To\ndemonstrate its clustering capability, a dendrite is applied to spike sorting,\nan important component of brain-computer interface applications. Supervised\nonline classification is implemented as a network composed of multiple\ndendrites and a simple voting mechanism. The dendrites operate independently\nand in parallel. The network learns in an online fashion and can adapt to\nmacro-level changes in the input stream. Achieving brain-like capabilities,\nefficiencies, and adaptability will require a significantly different approach\nthan conventional deep networks that learn via compute-intensive back\npropagation. The model described herein may serve as the foundation for such an\napproach.",
            "author": [
                "J. E. Smith"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17797v1",
                "http://arxiv.org/pdf/2310.17797v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "68T07"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17790v1",
            "title": "Neural Stress Fields for Reduced-order Elastoplasticity and Fracture",
            "updated": "2023-10-26T21:37:32Z",
            "published": "2023-10-26T21:37:32Z",
            "summary": "We propose a hybrid neural network and physics framework for reduced-order\nmodeling of elastoplasticity and fracture. State-of-the-art scientific\ncomputing models like the Material Point Method (MPM) faithfully simulate\nlarge-deformation elastoplasticity and fracture mechanics. However, their long\nruntime and large memory consumption render them unsuitable for applications\nconstrained by computation time and memory usage, e.g., virtual reality. To\novercome these barriers, we propose a reduced-order framework. Our key\ninnovation is training a low-dimensional manifold for the Kirchhoff stress\nfield via an implicit neural representation. This low-dimensional neural stress\nfield (NSF) enables efficient evaluations of stress values and,\ncorrespondingly, internal forces at arbitrary spatial locations. In addition,\nwe also train neural deformation and affine fields to build low-dimensional\nmanifolds for the deformation and affine momentum fields. These neural stress,\ndeformation, and affine fields share the same low-dimensional latent space,\nwhich uniquely embeds the high-dimensional simulation state. After training, we\nrun new simulations by evolving in this single latent space, which drastically\nreduces the computation time and memory consumption. Our general\ncontinuum-mechanics-based reduced-order framework is applicable to any\nphenomena governed by the elastodynamics equation. To showcase the versatility\nof our framework, we simulate a wide range of material behaviors, including\nelastica, sand, metal, non-Newtonian fluids, fracture, contact, and collision.\nWe demonstrate dimension reduction by up to 100,000X and time savings by up to\n10X.",
            "author": [
                "Zeshun Zong",
                "Xuan Li",
                "Minchen Li",
                "Maurizio M. Chiaramonte",
                "Wojciech Matusik",
                "Eitan Grinspun",
                "Kevin Carlberg",
                "Chenfanfu Jiang",
                "Peter Yichen Chen"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3610548.3618207",
                "http://arxiv.org/abs/2310.17790v1",
                "http://arxiv.org/pdf/2310.17790v1"
            ],
            "primary_category": "cs.GR",
            "category": [
                "cs.GR",
                "cs.CE",
                "cs.LG",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17789v1",
            "title": "SVR Algorithm as a Tool for More Optimal Intergalactic Medium Simulation\n  in the Epoch of Reionization",
            "updated": "2023-10-26T21:37:14Z",
            "published": "2023-10-26T21:37:14Z",
            "summary": "All kinds of simulations of the intergalactic medium, such as hydrodynamic\nsimulation, N-body simulation, numerical and semi-numerical simulation, etc.,\nhave been used to realize the history of this medium. One of these simulations\nis 21SSD, which is specifically focused on the epoch of reionization. This\nsimulation deepens our understanding of the physics behind the intergalactic\nmedium by considering the free parameters related to the Wouthuysen-Field\ncoupling fluctuations and X-ray and Lyman line transfers in the intergalactic\nmedium, and by presenting the plots of the power spectrum, brightness\ntemperature, etc. in different redshifts. However, due to many physical\nphenomena that play significant roles in this epoch, simulations of the\nintergalactic medium are usually extremely complex, time-consuming, and require\nvery powerful hardware. In this work, by using the Support Vector Regression\nalgorithm and based on the 21SSD simulation datasets, we have tried to make the\nmachine fully understand the brightness temperature changes in terms of\nredshift for different astrophysical free parameters values. At first, we\ntrained the machine with the results of the 21SSD simulation. Then, the machine\nwas able to predict the brightness temperature in terms of redshift with very\nhigh accuracy for other interval coefficients. Although we have used this\nalgorithm to estimate the brightness temperature, it seems that this algorithm\ncan be easily used for other parts of cosmology and astrophysics. With its\nhelp, it is possible to save time and obtain results with extraordinary\naccuracy similar to complex simulations, even with normal hardware.",
            "author": [
                "S. Mobina Hosseini",
                "Mahsa Berahman",
                "Seyed Sajad Tabasi",
                "Javad T. Firouzjaee"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17789v1",
                "http://arxiv.org/pdf/2310.17789v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17787v1",
            "title": "Evaluation of large language models using an Indian language LGBTI+\n  lexicon",
            "updated": "2023-10-26T21:32:24Z",
            "published": "2023-10-26T21:32:24Z",
            "summary": "Large language models (LLMs) are typically evaluated on the basis of\ntask-based benchmarks such as MMLU. Such benchmarks do not examine responsible\nbehaviour of LLMs in specific contexts. This is particularly true in the LGBTI+\ncontext where social stereotypes may result in variation in LGBTI+ terminology.\nTherefore, domain-specific lexicons or dictionaries may be useful as a\nrepresentative list of words against which the LLM's behaviour needs to be\nevaluated. This paper presents a methodology for evaluation of LLMs using an\nLGBTI+ lexicon in Indian languages. The methodology consists of four steps:\nformulating NLP tasks relevant to the expected behaviour, creating prompts that\ntest LLMs, using the LLMs to obtain the output and, finally, manually\nevaluating the results. Our qualitative analysis shows that the three LLMs we\nexperiment on are unable to detect underlying hateful content. Similarly, we\nobserve limitations in using machine translation as means to evaluate natural\nlanguage understanding in languages other than English. The methodology\npresented in this paper can be useful for LGBTI+ lexicons in other languages as\nwell as other domain-specific lexicons. The work done in this paper opens\navenues for responsible behaviour of LLMs, as demonstrated in the context of\nprevalent social perception of the LGBTI+ community.",
            "author": [
                "Aditya Joshi",
                "Shruta Rawat",
                "Alpana Dange"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17787v1",
                "http://arxiv.org/pdf/2310.17787v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17786v1",
            "title": "Understanding when Dynamics-Invariant Data Augmentations Benefit\n  Model-Free Reinforcement Learning Updates",
            "updated": "2023-10-26T21:28:50Z",
            "published": "2023-10-26T21:28:50Z",
            "summary": "Recently, data augmentation (DA) has emerged as a method for leveraging\ndomain knowledge to inexpensively generate additional data in reinforcement\nlearning (RL) tasks, often yielding substantial improvements in data\nefficiency. While prior work has demonstrated the utility of incorporating\naugmented data directly into model-free RL updates, it is not well-understood\nwhen a particular DA strategy will improve data efficiency. In this paper, we\nseek to identify general aspects of DA responsible for observed learning\nimprovements. Our study focuses on sparse-reward tasks with dynamics-invariant\ndata augmentation functions, serving as an initial step towards a more general\nunderstanding of DA and its integration into RL training. Experimentally, we\nisolate three relevant aspects of DA: state-action coverage, reward density,\nand the number of augmented transitions generated per update (the augmented\nreplay ratio). From our experiments, we draw two conclusions: (1) increasing\nstate-action coverage often has a much greater impact on data efficiency than\nincreasing reward density, and (2) decreasing the augmented replay ratio\nsubstantially improves data efficiency. In fact, certain tasks in our empirical\nstudy are solvable only when the replay ratio is sufficiently low.",
            "author": [
                "Nicholas E. Corrado",
                "Josiah P. Hanna"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17786v1",
                "http://arxiv.org/pdf/2310.17786v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17785v2",
            "title": "Learning Extrinsic Dexterity with Parameterized Manipulation Primitives",
            "updated": "2023-11-02T20:32:09Z",
            "published": "2023-10-26T21:28:23Z",
            "summary": "Many practically relevant robot grasping problems feature a target object for\nwhich all grasps are occluded, e.g., by the environment. Single-shot grasp\nplanning invariably fails in such scenarios. Instead, it is necessary to first\nmanipulate the object into a configuration that affords a grasp. We solve this\nproblem by learning a sequence of actions that utilize the environment to\nchange the object's pose. Concretely, we employ hierarchical reinforcement\nlearning to combine a sequence of learned parameterized manipulation\nprimitives. By learning the low-level manipulation policies, our approach can\ncontrol the object's state through exploiting interactions between the object,\nthe gripper, and the environment. Designing such a complex behavior\nanalytically would be infeasible under uncontrolled conditions, as an analytic\napproach requires accurate physical modeling of the interaction and contact\ndynamics. In contrast, we learn a hierarchical policy model that operates\ndirectly on depth perception data, without the need for object detection, pose\nestimation, or manual design of controllers. We evaluate our approach on\npicking box-shaped objects of various weight, shape, and friction properties\nfrom a constrained table-top workspace. Our method transfers to a real robot\nand is able to successfully complete the object picking task in 98\\% of\nexperimental trials.",
            "author": [
                "Shih-Min Yang",
                "Martin Magnusson",
                "Johannes A. Stork",
                "Todor Stoyanov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17785v2",
                "http://arxiv.org/pdf/2310.17785v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17780v1",
            "title": "AutoCT: Automated CT registration, segmentation, and quantification",
            "updated": "2023-10-26T21:09:47Z",
            "published": "2023-10-26T21:09:47Z",
            "summary": "The processing and analysis of computed tomography (CT) imaging is important\nfor both basic scientific development and clinical applications. In AutoCT, we\nprovide a comprehensive pipeline that integrates an end-to-end automatic\npreprocessing, registration, segmentation, and quantitative analysis of 3D CT\nscans. The engineered pipeline enables atlas-based CT segmentation and\nquantification leveraging diffeomorphic transformations through efficient\nforward and inverse mappings. The extracted localized features from the\ndeformation field allow for downstream statistical learning that may facilitate\nmedical diagnostics. On a lightweight and portable software platform, AutoCT\nprovides a new toolkit for the CT imaging community to underpin the deployment\nof artificial intelligence-driven applications.",
            "author": [
                "Zhe Bai",
                "Abdelilah Essiari",
                "Talita Perciano",
                "Kristofer E. Bouchard"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17780v1",
                "http://arxiv.org/pdf/2310.17780v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17773v1",
            "title": "Graph Convolutional Networks for Complex Traffic Scenario Classification",
            "updated": "2023-10-26T20:51:24Z",
            "published": "2023-10-26T20:51:24Z",
            "summary": "A scenario-based testing approach can reduce the time required to obtain\nstatistically significant evidence of the safety of Automated Driving Systems\n(ADS). Identifying these scenarios in an automated manner is a challenging\ntask. Most methods on scenario classification do not work for complex scenarios\nwith diverse environments (highways, urban) and interaction with other traffic\nagents. This is mirrored in their approaches which model an individual vehicle\nin relation to its environment, but neglect the interaction between multiple\nvehicles (e.g. cut-ins, stationary lead vehicle). Furthermore, existing\ndatasets lack diversity and do not have per-frame annotations to accurately\nlearn the start and end time of a scenario. We propose a method for complex\ntraffic scenario classification that is able to model the interaction of a\nvehicle with the environment, as well as other agents. We use Graph\nConvolutional Networks to model spatial and temporal aspects of these\nscenarios. Expanding the nuScenes and Argoverse 2 driving datasets, we\nintroduce a scenario-labeled dataset, which covers different driving\nenvironments and is annotated per frame. Training our method on this dataset,\nwe present a promising baseline for future research on per-frame complex\nscenario classification.",
            "author": [
                "Tobias Hoek",
                "Holger Caesar",
                "Andreas Falkov\u00e9n",
                "Tommy Johansson"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17773v1",
                "http://arxiv.org/pdf/2310.17773v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "cs.MA",
                "I.2; I.4; I.5"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17772v1",
            "title": "Learning Optimal Classification Trees Robust to Distribution Shifts",
            "updated": "2023-10-26T20:37:29Z",
            "published": "2023-10-26T20:37:29Z",
            "summary": "We consider the problem of learning classification trees that are robust to\ndistribution shifts between training and testing/deployment data. This problem\narises frequently in high stakes settings such as public health and social work\nwhere data is often collected using self-reported surveys which are highly\nsensitive to e.g., the framing of the questions, the time when and place where\nthe survey is conducted, and the level of comfort the interviewee has in\nsharing information with the interviewer. We propose a method for learning\noptimal robust classification trees based on mixed-integer robust optimization\ntechnology. In particular, we demonstrate that the problem of learning an\noptimal robust tree can be cast as a single-stage mixed-integer robust\noptimization problem with a highly nonlinear and discontinuous objective. We\nreformulate this problem equivalently as a two-stage linear robust optimization\nproblem for which we devise a tailored solution procedure based on constraint\ngeneration. We evaluate the performance of our approach on numerous publicly\navailable datasets, and compare the performance to a regularized, non-robust\noptimal tree. We show an increase of up to 12.48% in worst-case accuracy and of\nup to 4.85% in average-case accuracy across several datasets and distribution\nshifts from using our robust solution in comparison to the non-robust one.",
            "author": [
                "Nathan Justin",
                "Sina Aghaei",
                "Andr\u00e9s G\u00f3mez",
                "Phebe Vayanos"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17772v1",
                "http://arxiv.org/pdf/2310.17772v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17770v1",
            "title": "GROOViST: A Metric for Grounding Objects in Visual Storytelling",
            "updated": "2023-10-26T20:27:16Z",
            "published": "2023-10-26T20:27:16Z",
            "summary": "A proper evaluation of stories generated for a sequence of images -- the task\ncommonly referred to as visual storytelling -- must consider multiple aspects,\nsuch as coherence, grammatical correctness, and visual grounding. In this work,\nwe focus on evaluating the degree of grounding, that is, the extent to which a\nstory is about the entities shown in the images. We analyze current metrics,\nboth designed for this purpose and for general vision-text alignment. Given\ntheir observed shortcomings, we propose a novel evaluation tool, GROOViST, that\naccounts for cross-modal dependencies, temporal misalignments (the fact that\nthe order in which entities appear in the story and the image sequence may not\nmatch), and human intuitions on visual grounding. An additional advantage of\nGROOViST is its modular design, where the contribution of each component can be\nassessed and interpreted individually.",
            "author": [
                "Aditya K Surikuchi",
                "Sandro Pezzelle",
                "Raquel Fern\u00e1ndez"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17770v1",
                "http://arxiv.org/pdf/2310.17770v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17769v2",
            "title": "Social Contract AI: Aligning AI Assistants with Implicit Group Norms",
            "updated": "2023-12-03T17:42:33Z",
            "published": "2023-10-26T20:27:03Z",
            "summary": "We explore the idea of aligning an AI assistant by inverting a model of\nusers' (unknown) preferences from observed interactions. To validate our\nproposal, we run proof-of-concept simulations in the economic ultimatum game,\nformalizing user preferences as policies that guide the actions of simulated\nplayers. We find that the AI assistant accurately aligns its behavior to match\nstandard policies from the economic literature (e.g., selfish, altruistic).\nHowever, the assistant's learned policies lack robustness and exhibit limited\ngeneralization in an out-of-distribution setting when confronted with a\ncurrency (e.g., grams of medicine) that was not included in the assistant's\ntraining distribution. Additionally, we find that when there is inconsistency\nin the relationship between language use and an unknown policy (e.g., an\naltruistic policy combined with rude language), the assistant's learning of the\npolicy is slowed. Overall, our preliminary results suggest that developing\nsimulation frameworks in which AI assistants need to infer preferences from\ndiverse users can provide a valuable approach for studying practical alignment\nquestions.",
            "author": [
                "Jan-Philipp Fr\u00e4nken",
                "Sam Kwok",
                "Peixuan Ye",
                "Kanishk Gandhi",
                "Dilip Arumugam",
                "Jared Moore",
                "Alex Tamkin",
                "Tobias Gerstenberg",
                "Noah D. Goodman"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17769v2",
                "http://arxiv.org/pdf/2310.17769v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03372v1",
            "title": "A Declaration of Software Independence",
            "updated": "2023-10-26T20:21:25Z",
            "published": "2023-10-26T20:21:25Z",
            "summary": "A voting system should not merely report the outcome: it should also provide\nsufficient evidence to convince reasonable observers that the reported outcome\nis correct. Many deployed systems, notably paperless DRE machines still in use\nin US elections, fail certainly the second, and quite possibly the first of\nthese requirements. Rivest and Wack proposed the principle of software\nindependence (SI) as a guiding principle and requirement for voting systems. In\nessence, a voting system is SI if its reliance on software is\n``tamper-evident'', that is, if there is a way to detect that material changes\nwere made to the software without inspecting that software. This important\nnotion has so far been formulated only informally.\n  Here, we provide more formal mathematical definitions of SI. This exposes\nsome subtleties and gaps in the original definition, among them: what elements\nof a system must be trusted for an election or system to be SI, how to\nformalize ``detection'' of a change to an election outcome, the fact that SI is\nwith respect to a set of detection mechanisms (which must be legal and\npractical), the need to limit false alarms, and how SI applies when the social\nchoice function is not deterministic.",
            "author": [
                "Wojciech Jamroga",
                "Peter Y. A. Ryan",
                "Steve Schneider",
                "Carsten Schurmann",
                "Philip B. Stark"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03372v1",
                "http://arxiv.org/pdf/2311.03372v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17765v1",
            "title": "Autonomous convergence of STM control parameters using Bayesian\n  Optimization",
            "updated": "2023-10-26T20:15:48Z",
            "published": "2023-10-26T20:15:48Z",
            "summary": "Scanning Tunneling microscopy (STM) is a widely used tool for atomic imaging\nof novel materials and its surface energetics. However, the optimization of the\nimaging conditions is a tedious process due to the extremely sensitive\ntip-surface interaction, and thus limits the throughput efficiency. Here we\ndeploy a machine learning (ML) based framework to achieve optimal-atomically\nresolved imaging conditions in real time. The experimental workflow leverages\nBayesian optimization (BO) method to rapidly improve the image quality, defined\nby the peak intensity in the Fourier space. The outcome of the BO prediction is\nincorporated into the microscope controls, i.e., the current setpoint and the\ntip bias, to dynamically improve the STM scan conditions. We present strategies\nto either selectively explore or exploit across the parameter space. As a\nresult, suitable policies are developed for autonomous convergence of the\ncontrol-parameters. The ML-based framework serves as a general workflow\nmethodology across a wide range of materials.",
            "author": [
                "Ganesh Narasimha",
                "Saban Hus",
                "Arpan Biswas",
                "Rama Vasudevan",
                "Maxim Ziatdinov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17765v1",
                "http://arxiv.org/pdf/2310.17765v1"
            ],
            "primary_category": "physics.app-ph",
            "category": [
                "physics.app-ph",
                "cond-mat.mtrl-sci",
                "physics.data-an"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17764v1",
            "title": "SynergyNet: Bridging the Gap between Discrete and Continuous\n  Representations for Precise Medical Image Segmentation",
            "updated": "2023-10-26T20:13:44Z",
            "published": "2023-10-26T20:13:44Z",
            "summary": "In recent years, continuous latent space (CLS) and discrete latent space\n(DLS) deep learning models have been proposed for medical image analysis for\nimproved performance. However, these models encounter distinct challenges. CLS\nmodels capture intricate details but often lack interpretability in terms of\nstructural representation and robustness due to their emphasis on low-level\nfeatures. Conversely, DLS models offer interpretability, robustness, and the\nability to capture coarse-grained information thanks to their structured latent\nspace. However, DLS models have limited efficacy in capturing fine-grained\ndetails. To address the limitations of both DLS and CLS models, we propose\nSynergyNet, a novel bottleneck architecture designed to enhance existing\nencoder-decoder segmentation frameworks. SynergyNet seamlessly integrates\ndiscrete and continuous representations to harness complementary information\nand successfully preserves both fine and coarse-grained details in the learned\nrepresentations. Our extensive experiment on multi-organ segmentation and\ncardiac datasets demonstrates that SynergyNet outperforms other state of the\nart methods, including TransUNet: dice scores improving by 2.16%, and Hausdorff\nscores improving by 11.13%, respectively. When evaluating skin lesion and brain\ntumor segmentation datasets, we observe a remarkable improvement of 1.71% in\nIntersection-over Union scores for skin lesion segmentation and of 8.58% for\nbrain tumor segmentation. Our innovative approach paves the way for enhancing\nthe overall performance and capabilities of deep learning models in the\ncritical domain of medical image analysis.",
            "author": [
                "Vandan Gorade",
                "Sparsh Mittal",
                "Debesh Jha",
                "Ulas Bagci"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17764v1",
                "http://arxiv.org/pdf/2310.17764v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17761v1",
            "title": "Distributed Personalized Empirical Risk Minimization",
            "updated": "2023-10-26T20:07:33Z",
            "published": "2023-10-26T20:07:33Z",
            "summary": "This paper advocates a new paradigm Personalized Empirical Risk Minimization\n(PERM) to facilitate learning from heterogeneous data sources without imposing\nstringent constraints on computational resources shared by participating\ndevices. In PERM, we aim to learn a distinct model for each client by learning\nwho to learn with and personalizing the aggregation of local empirical losses\nby effectively estimating the statistical discrepancy among data distributions,\nwhich entails optimal statistical accuracy for all local distributions and\novercomes the data heterogeneity issue. To learn personalized models at scale,\nwe propose a distributed algorithm that replaces the standard model averaging\nwith model shuffling to simultaneously optimize PERM objectives for all\ndevices. This also allows us to learn distinct model architectures (e.g.,\nneural networks with different numbers of parameters) for different clients,\nthus confining underlying memory and compute resources of individual clients.\nWe rigorously analyze the convergence of the proposed algorithm and conduct\nexperiments that corroborate the effectiveness of the proposed paradigm.",
            "author": [
                "Yuyang Deng",
                "Mohammad Mahdi Kamani",
                "Pouria Mahdavinia",
                "Mehrdad Mahdavi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17761v1",
                "http://arxiv.org/pdf/2310.17761v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17759v1",
            "title": "Optimal Guarantees for Algorithmic Reproducibility and Gradient\n  Complexity in Convex Optimization",
            "updated": "2023-10-26T19:56:52Z",
            "published": "2023-10-26T19:56:52Z",
            "summary": "Algorithmic reproducibility measures the deviation in outputs of machine\nlearning algorithms upon minor changes in the training process. Previous work\nsuggests that first-order methods would need to trade-off convergence rate\n(gradient complexity) for better reproducibility. In this work, we challenge\nthis perception and demonstrate that both optimal reproducibility and\nnear-optimal convergence guarantees can be achieved for smooth convex\nminimization and smooth convex-concave minimax problems under various\nerror-prone oracle settings. Particularly, given the inexact initialization\noracle, our regularization-based algorithms achieve the best of both worlds -\noptimal reproducibility and near-optimal gradient complexity - for minimization\nand minimax optimization. With the inexact gradient oracle, the near-optimal\nguarantees also hold for minimax optimization. Additionally, with the\nstochastic gradient oracle, we show that stochastic gradient descent ascent is\noptimal in terms of both reproducibility and gradient complexity. We believe\nour results contribute to an enhanced understanding of the\nreproducibility-convergence trade-off in the context of convex optimization.",
            "author": [
                "Liang Zhang",
                "Junchi Yang",
                "Amin Karbasi",
                "Niao He"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17759v1",
                "http://arxiv.org/pdf/2310.17759v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17758v2",
            "title": "Graph Neural Networks for Enhanced Decoding of Quantum LDPC Codes",
            "updated": "2023-11-06T20:44:45Z",
            "published": "2023-10-26T19:56:25Z",
            "summary": "In this work, we propose a fully differentiable iterative decoder for quantum\nlow-density parity-check (LDPC) codes. The proposed algorithm is composed of\nclassical belief propagation (BP) decoding stages and intermediate graph neural\nnetwork (GNN) layers. Both component decoders are defined over the same sparse\ndecoding graph enabling a seamless integration and scalability to large codes.\nThe core idea is to use the GNN component between consecutive BP runs, so that\nthe knowledge from the previous BP run, if stuck in a local minima caused by\ntrapping sets or short cycles in the decoding graph, can be leveraged to better\ninitialize the next BP run. By doing so, the proposed decoder can learn to\ncompensate for sub-optimal BP decoding graphs that result from the design\nconstraints of quantum LDPC codes. Since the entire decoder remains\ndifferentiable, gradient descent-based training is possible. We compare the\nerror rate performance of the proposed decoder against various post-processing\nmethods such as random perturbation, enhanced feedback, augmentation, and\nordered-statistics decoding (OSD) and show that a carefully designed training\nprocess lowers the error-floor significantly. As a result, our proposed decoder\noutperforms the former three methods using significantly fewer post-processing\nattempts. The source code of our experiments is available online.",
            "author": [
                "Anqi Gong",
                "Sebastian Cammerer",
                "Joseph M. Renes"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17758v2",
                "http://arxiv.org/pdf/2310.17758v2"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17755v1",
            "title": "Alzheimers Disease Diagnosis by Deep Learning Using MRI-Based Approaches",
            "updated": "2023-10-26T19:48:08Z",
            "published": "2023-10-26T19:48:08Z",
            "summary": "The most frequent kind of dementia of the nervous system, Alzheimer's\ndisease, weakens several brain processes (such as memory) and eventually\nresults in death. The clinical study uses magnetic resonance imaging to\ndiagnose AD. Deep learning algorithms are capable of pattern recognition and\nfeature extraction from the inputted raw data. As early diagnosis and stage\ndetection are the most crucial elements in enhancing patient care and treatment\noutcomes, deep learning algorithms for MRI images have recently allowed for\ndiagnosing a medical condition at the beginning stage and identifying\nparticular symptoms of Alzheimer's disease. As a result, we aimed to analyze\nfive specific studies focused on AD diagnosis using MRI-based deep learning\nalgorithms between 2021 and 2023 in this study. To completely illustrate the\ndifferences between these techniques and comprehend how deep learning\nalgorithms function, we attempted to explore selected approaches in depth.",
            "author": [
                "Sarasadat Foroughipoor",
                "Kimia Moradi",
                "Hamidreza Bolhasani"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17755v1",
                "http://arxiv.org/pdf/2310.17755v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17752v1",
            "title": "PockEngine: Sparse and Efficient Fine-tuning in a Pocket",
            "updated": "2023-10-26T19:46:11Z",
            "published": "2023-10-26T19:46:11Z",
            "summary": "On-device learning and efficient fine-tuning enable continuous and\nprivacy-preserving customization (e.g., locally fine-tuning large language\nmodels on personalized data). However, existing training frameworks are\ndesigned for cloud servers with powerful accelerators (e.g., GPUs, TPUs) and\nlack the optimizations for learning on the edge, which faces challenges of\nresource limitations and edge hardware diversity. We introduce PockEngine: a\ntiny, sparse and efficient engine to enable fine-tuning on various edge\ndevices. PockEngine supports sparse backpropagation: it prunes the backward\ngraph and sparsely updates the model with measured memory saving and latency\nreduction while maintaining the model quality. Secondly, PockEngine is\ncompilation first: the entire training graph (including forward, backward and\noptimization steps) is derived at compile-time, which reduces the runtime\noverhead and brings opportunities for graph transformations. PockEngine also\nintegrates a rich set of training graph optimizations, thus can further\naccelerate the training cost, including operator reordering and backend\nswitching. PockEngine supports diverse applications, frontends and hardware\nbackends: it flexibly compiles and tunes models defined in\nPyTorch/TensorFlow/Jax and deploys binaries to mobile CPU/GPU/DSPs. We\nevaluated PockEngine on both vision models and large language models.\nPockEngine achieves up to 15 $\\times$ speedup over off-the-shelf TensorFlow\n(Raspberry Pi), 5.6 $\\times$ memory saving back-propagation (Jetson AGX Orin).\nRemarkably, PockEngine enables fine-tuning LLaMav2-7B on NVIDIA Jetson AGX Orin\nat 550 tokens/s, 7.9$\\times$ faster than the PyTorch.",
            "author": [
                "Ligeng Zhu",
                "Lanxiang Hu",
                "Ji Lin",
                "Wei-Chen Wang",
                "Wei-Ming Chen",
                "Chuang Gan",
                "Song Han"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3613424.3614307",
                "http://arxiv.org/abs/2310.17752v1",
                "http://arxiv.org/pdf/2310.17752v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17748v1",
            "title": "Making the End-User a Priority in Benchmarking: OrionBench for\n  Unsupervised Time Series Anomaly Detection",
            "updated": "2023-10-26T19:43:16Z",
            "published": "2023-10-26T19:43:16Z",
            "summary": "Time series anomaly detection is a prevalent problem in many application\ndomains such as patient monitoring in healthcare, forecasting in finance, or\npredictive maintenance in energy. This has led to the emergence of a plethora\nof anomaly detection methods, including more recently, deep learning based\nmethods. Although several benchmarks have been proposed to compare newly\ndeveloped models, they usually rely on one-time execution over a limited set of\ndatasets and the comparison is restricted to a few models. We propose\nOrionBench -- a user centric continuously maintained benchmark for unsupervised\ntime series anomaly detection. The framework provides universal abstractions to\nrepresent models, extensibility to add new pipelines and datasets,\nhyperparameter standardization, pipeline verification, and frequent releases\nwith published benchmarks. We demonstrate the usage of OrionBench, and the\nprogression of pipelines across 15 releases published over the course of three\nyears. Moreover, we walk through two real scenarios we experienced with\nOrionBench that highlight the importance of continuous benchmarks in\nunsupervised time series anomaly detection.",
            "author": [
                "Sarah Alnegheimish",
                "Laure Berti-Equille",
                "Kalyan Veeramachaneni"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17748v1",
                "http://arxiv.org/pdf/2310.17748v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17743v2",
            "title": "StyleBART: Decorate Pretrained Model with Style Adapters for\n  Unsupervised Stylistic Headline Generation",
            "updated": "2023-11-13T06:38:53Z",
            "published": "2023-10-26T19:31:22Z",
            "summary": "Stylistic headline generation is the task to generate a headline that not\nonly summarizes the content of an article, but also reflects a desired style\nthat attracts users. As style-specific article-headline pairs are scarce,\nprevious researches focus on unsupervised approaches with a standard headline\ngeneration dataset and mono-style corpora. In this work, we follow this line\nand propose StyleBART, an unsupervised approach for stylistic headline\ngeneration. Our method decorates the pretrained BART model with adapters that\nare responsible for different styles and allows the generation of headlines\nwith diverse styles by simply switching the adapters. Different from previous\nworks, StyleBART separates the task of style learning and headline generation,\nmaking it possible to freely combine the base model and the style adapters\nduring inference. We further propose an inverse paraphrasing task to enhance\nthe style adapters. Extensive automatic and human evaluations show that\nStyleBART achieves new state-of-the-art performance in the unsupervised\nstylistic headline generation task, producing high-quality headlines with the\ndesired style.",
            "author": [
                "Hanqing Wang",
                "Yajing Luo",
                "Boya Xiong",
                "Guanhua Chen",
                "Yun Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17743v2",
                "http://arxiv.org/pdf/2310.17743v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17742v1",
            "title": "BERT-PIN: A BERT-based Framework for Recovering Missing Data Segments in\n  Time-series Load Profiles",
            "updated": "2023-10-26T19:30:31Z",
            "published": "2023-10-26T19:30:31Z",
            "summary": "Inspired by the success of the Transformer model in natural language\nprocessing and computer vision, this paper introduces BERT-PIN, a Bidirectional\nEncoder Representations from Transformers (BERT) powered Profile Inpainting\nNetwork. BERT-PIN recovers multiple missing data segments (MDSs) using load and\ntemperature time-series profiles as inputs. To adopt a standard Transformer\nmodel structure for profile inpainting, we segment the load and temperature\nprofiles into line segments, treating each segment as a word and the entire\nprofile as a sentence. We incorporate a top candidates selection process in\nBERT-PIN, enabling it to produce a sequence of probability distributions, based\non which users can generate multiple plausible imputed data sets, each\nreflecting different confidence levels. We develop and evaluate BERT-PIN using\nreal-world dataset for two applications: multiple MDSs recovery and demand\nresponse baseline estimation. Simulation results show that BERT-PIN outperforms\nthe existing methods in accuracy while is capable of restoring multiple MDSs\nwithin a longer window. BERT-PIN, served as a pre-trained model, can be\nfine-tuned for conducting many downstream tasks, such as classification and\nsuper resolution.",
            "author": [
                "Yi Hu",
                "Kai Ye",
                "Hyeonjin Kim",
                "Ning Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17742v1",
                "http://arxiv.org/pdf/2310.17742v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17741v1",
            "title": "Probing Light Fermiophobic Higgs Boson via diphoton jets at the HL-LHC",
            "updated": "2023-10-26T19:27:53Z",
            "published": "2023-10-26T19:27:53Z",
            "summary": "In this study, we explore the phenomenological signatures associated with a\nlight fermiophobic Higgs boson, $h_{\\rm f}$, within the type-I\ntwo-Higgs-doublet model at the HL-LHC. Our meticulous parameter scan\nilluminates an intriguing mass range for $m_{h_{\\rm f}}$, spanning\n$[1,10]{\\;{\\rm GeV}}$. This mass range owes its viability to substantial\nparameter points, largely due to the inherent challenges of detecting the soft\ndecay products of $h_{\\rm f}$ at contemporary high-energy colliders. Given that\nthis light $h_{\\rm f}$ ensures $Br(h_{\\rm f}\\to\\gamma\\gamma)\\simeq 1$,\n$Br(H^\\pm \\to h_{\\rm f} W^\\pm)\\simeq 1$, and $M_{H^\\pm}\\lesssim 330{\\;{\\rm\nGeV}}$, we propose a golden discovery channel: $pp\\to h_{\\rm f}H^\\pm\\to\n\\gamma\\gamma\\gamma\\gamma \\,l^\\pm\\nu$, where $l^\\pm$ includes $e^\\pm$ and\n$\\mu^\\pm$. However, a significant obstacle arises as the two photons from the\n$h_{\\rm f}$ decay mostly merge into a single jet due to their proximity within\n$\\Delta R<0.4$. This results in a final state characterized by two jets, rather\nthan four isolated photons, thus intensifying the QCD backgrounds. To tackle\nthis, we devise a strategy within \\textsc{Delphes} to identify jets with two\nleading subparticles as photons, termed diphoton jets. Our thorough\ndetector-level simulations across 18 benchmark points predominantly show signal\nsignificances exceeding the $5\\sigma$ threshold at an integrated luminosity of\n$3{\\;{\\rm ab}^{-1}}$. Furthermore, our approach facilitates accurate mass\nreconstructions for both $m_{h_{\\rm f}}$ and $M_{H^\\pm}$. Notably, in the\nintricate scenarios with heavy charged Higgs bosons, our application of machine\nlearning techniques provides a significant boost in significance.",
            "author": [
                "Daohan Wang",
                "Jin-Hwan Cho",
                "Jinheung Kim",
                "Soojin Lee",
                "Prasenjit Sanyal",
                "Jeonghyeon Song"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17741v1",
                "http://arxiv.org/pdf/2310.17741v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17737v1",
            "title": "ArchBERT: Bi-Modal Understanding of Neural Architectures and Natural\n  Languages",
            "updated": "2023-10-26T18:58:52Z",
            "published": "2023-10-26T18:58:52Z",
            "summary": "Building multi-modal language models has been a trend in the recent years,\nwhere additional modalities such as image, video, speech, etc. are jointly\nlearned along with natural languages (i.e., textual information). Despite the\nsuccess of these multi-modal language models with different modalities, there\nis no existing solution for neural network architectures and natural languages.\nProviding neural architectural information as a new modality allows us to\nprovide fast architecture-2-text and text-2-architecture retrieval/generation\nservices on the cloud with a single inference. Such solution is valuable in\nterms of helping beginner and intermediate ML users to come up with better\nneural architectures or AutoML approaches with a simple text query. In this\npaper, we propose ArchBERT, a bi-modal model for joint learning and\nunderstanding of neural architectures and natural languages, which opens up new\navenues for research in this area. We also introduce a pre-training strategy\nnamed Masked Architecture Modeling (MAM) for a more generalized joint learning.\nMoreover, we introduce and publicly release two new bi-modal datasets for\ntraining and validating our methods. The ArchBERT's performance is verified\nthrough a set of numerical experiments on different downstream tasks such as\narchitecture-oriented reasoning, question answering, and captioning\n(summarization). Datasets, codes, and demos are available supplementary\nmaterials.",
            "author": [
                "Mohammad Akbari",
                "Saeed Ranjbar Alvar",
                "Behnam Kamranian",
                "Amin Banitalebi-Dehkordi",
                "Yong Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17737v1",
                "http://arxiv.org/pdf/2310.17737v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17732v1",
            "title": "GNN-GMVO: Graph Neural Networks for Optimizing Gross Merchandise Value\n  in Similar Item Recommendation",
            "updated": "2023-10-26T18:43:16Z",
            "published": "2023-10-26T18:43:16Z",
            "summary": "Similar item recommendation is a critical task in the e-Commerce industry,\nwhich helps customers explore similar and relevant alternatives based on their\ninterested products. Despite the traditional machine learning models, Graph\nNeural Networks (GNNs), by design, can understand complex relations like\nsimilarity between products. However, in contrast to their wide usage in\nretrieval tasks and their focus on optimizing the relevance, the current GNN\narchitectures are not tailored toward maximizing revenue-related objectives\nsuch as Gross Merchandise Value (GMV), which is one of the major business\nmetrics for e-Commerce companies. In addition, defining accurate edge relations\nin GNNs is non-trivial in large-scale e-Commerce systems, due to the\nheterogeneity nature of the item-item relationships. This work aims to address\nthese issues by designing a new GNN architecture called GNN-GMVO (Graph Neural\nNetwork - Gross Merchandise Value Optimizer). This model directly optimizes GMV\nwhile considering the complex relations between items. In addition, we propose\na customized edge construction method to tailor the model toward similar item\nrecommendation task and alleviate the noisy and complex item-item relations. In\nour comprehensive experiments on three real-world datasets, we show higher\nprediction performance and expected GMV for top ranked items recommended by our\nmodel when compared with selected state-of-the-art benchmark models.",
            "author": [
                "Ramin Giahi",
                "Reza Yousefi Maragheh",
                "Nima Farrokhsiar",
                "Jianpeng Xu",
                "Jason Cho",
                "Evren Korpeoglu",
                "Sushant Kumar",
                "Kannan Achan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17732v1",
                "http://arxiv.org/pdf/2310.17732v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17729v1",
            "title": "Improving Traffic Density Forecasting in Intelligent Transportation\n  Systems Using Gated Graph Neural Networks",
            "updated": "2023-10-26T18:40:28Z",
            "published": "2023-10-26T18:40:28Z",
            "summary": "This study delves into the application of graph neural networks in the realm\nof traffic forecasting, a crucial facet of intelligent transportation systems.\nAccurate traffic predictions are vital for functions like trip planning,\ntraffic control, and vehicle routing in such systems. Three prominent GNN\narchitectures Graph Convolutional Networks (Graph Sample and Aggregation) and\nGated Graph Neural Networks are explored within the context of traffic\nprediction. Each architecture's methodology is thoroughly examined, including\nlayer configurations, activation functions,and hyperparameters. The primary\ngoal is to minimize prediction errors, with GGNNs emerging as the most\neffective choice among the three models. The research outlines outcomes for\neach architecture, elucidating their predictive performance through root mean\nsquared error and mean absolute error (MAE). Hypothetical results reveal\nintriguing insights: GCNs display an RMSE of 9.10 and an MAE of 8.00, while\nGraphSAGE shows improvement with an RMSE of 8.3 and an MAE of 7.5. Gated Graph\nNeural Networks (GGNNs) exhibit the lowest RMSE at 9.15 and an impressive MAE\nof 7.1, positioning them as the frontrunner.",
            "author": [
                "Razib Hayat Khan",
                "Jonayet Miah",
                "S M Yasir Arafat",
                "M M Mahbubul Syeed",
                "Duc M Ca"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17729v1",
                "http://arxiv.org/pdf/2310.17729v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17723v1",
            "title": "ZeroQuant-HERO: Hardware-Enhanced Robust Optimized Post-Training\n  Quantization Framework for W8A8 Transformers",
            "updated": "2023-10-26T18:34:41Z",
            "published": "2023-10-26T18:34:41Z",
            "summary": "Quantization techniques are pivotal in reducing the memory and computational\ndemands of deep neural network inference. Existing solutions, such as\nZeroQuant, offer dynamic quantization for models like BERT and GPT but overlook\ncrucial memory-bounded operators and the complexities of per-token\nquantization. Addressing these gaps, we present a novel, fully\nhardware-enhanced robust optimized post-training W8A8 quantization framework,\nZeroQuant-HERO. This framework uniquely integrates both memory bandwidth and\ncompute-intensive operators, aiming for optimal hardware performance.\nAdditionally, it offers flexibility by allowing specific INT8 modules to switch\nto FP16/BF16 mode, enhancing accuracy.",
            "author": [
                "Zhewei Yao",
                "Reza Yazdani Aminabadi",
                "Stephen Youn",
                "Xiaoxia Wu",
                "Elton Zheng",
                "Yuxiong He"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17723v1",
                "http://arxiv.org/pdf/2310.17723v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17722v1",
            "title": "Large Language Models as Generalizable Policies for Embodied Tasks",
            "updated": "2023-10-26T18:32:05Z",
            "published": "2023-10-26T18:32:05Z",
            "summary": "We show that large language models (LLMs) can be adapted to be generalizable\npolicies for embodied visual tasks. Our approach, called Large LAnguage model\nReinforcement Learning Policy (LLaRP), adapts a pre-trained frozen LLM to take\nas input text instructions and visual egocentric observations and output\nactions directly in the environment. Using reinforcement learning, we train\nLLaRP to see and act solely through environmental interactions. We show that\nLLaRP is robust to complex paraphrasings of task instructions and can\ngeneralize to new tasks that require novel optimal behavior. In particular, on\n1,000 unseen tasks it achieves 42% success rate, 1.7x the success rate of other\ncommon learned baselines or zero-shot applications of LLMs. Finally, to aid the\ncommunity in studying language conditioned, massively multi-task, embodied AI\nproblems we release a novel benchmark, Language Rearrangement, consisting of\n150,000 training and 1,000 testing tasks for language-conditioned\nrearrangement. Video examples of LLaRP in unseen Language Rearrangement\ninstructions are at https://llm-rl.github.io.",
            "author": [
                "Andrew Szot",
                "Max Schwarzer",
                "Harsh Agrawal",
                "Bogdan Mazoure",
                "Walter Talbott",
                "Katherine Metcalf",
                "Natalie Mackraz",
                "Devon Hjelm",
                "Alexander Toshev"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17722v1",
                "http://arxiv.org/pdf/2310.17722v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17720v1",
            "title": "Advancing Brain Tumor Detection: A Thorough Investigation of CNNs,\n  Clustering, and SoftMax Classification in the Analysis of MRI Images",
            "updated": "2023-10-26T18:27:20Z",
            "published": "2023-10-26T18:27:20Z",
            "summary": "Brain tumors pose a significant global health challenge due to their high\nprevalence and mortality rates across all age groups. Detecting brain tumors at\nan early stage is crucial for effective treatment and patient outcomes. This\nstudy presents a comprehensive investigation into the use of Convolutional\nNeural Networks (CNNs) for brain tumor detection using Magnetic Resonance\nImaging (MRI) images. The dataset, consisting of MRI scans from both healthy\nindividuals and patients with brain tumors, was processed and fed into the CNN\narchitecture. The SoftMax Fully Connected layer was employed to classify the\nimages, achieving an accuracy of 98%. To evaluate the CNN's performance, two\nother classifiers, Radial Basis Function (RBF) and Decision Tree (DT), were\nutilized, yielding accuracy rates of 98.24% and 95.64%, respectively. The study\nalso introduced a clustering method for feature extraction, improving CNN's\naccuracy. Sensitivity, Specificity, and Precision were employed alongside\naccuracy to comprehensively evaluate the network's performance. Notably, the\nSoftMax classifier demonstrated the highest accuracy among the categorizers,\nachieving 99.52% accuracy on test data. The presented research contributes to\nthe growing field of deep learning in medical image analysis. The combination\nof CNNs and MRI data offers a promising tool for accurately detecting brain\ntumors, with potential implications for early diagnosis and improved patient\ncare.",
            "author": [
                "Jonayet Miah",
                "Duc M Cao",
                "Md Abu Sayed3",
                "Md Siam Taluckder",
                "Md Sabbirul Haque",
                "Fuad Mahmud"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17720v1",
                "http://arxiv.org/pdf/2310.17720v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17716v1",
            "title": "Unifying (Quantum) Statistical and Parametrized (Quantum) Algorithms",
            "updated": "2023-10-26T18:23:21Z",
            "published": "2023-10-26T18:23:21Z",
            "summary": "Kearns' statistical query (SQ) oracle (STOC'93) lends a unifying perspective\nfor most classical machine learning algorithms. This ceases to be true in\nquantum learning, where many settings do not admit, neither an SQ analog nor a\nquantum statistical query (QSQ) analog. In this work, we take inspiration from\nKearns' SQ oracle and Valiant's weak evaluation oracle (TOCT'14) and establish\na unified perspective bridging the statistical and parametrized learning\nparadigms in a novel way. We explore the problem of learning from an evaluation\noracle, which provides an estimate of function values, and introduce an\nextensive yet intuitive framework that yields unconditional lower bounds for\nlearning from evaluation queries and characterizes the query complexity for\nlearning linear function classes. The framework is directly applicable to the\nQSQ setting and virtually all algorithms based on loss function optimization.\n  Our first application is to extend prior results on the learnability of\noutput distributions of quantum circuits and Clifford unitaries from the SQ to\nthe (multi-copy) QSQ setting, implying exponential separations between learning\nstabilizer states from (multi-copy) QSQs versus from quantum samples. Our\nsecond application is to analyze some popular quantum machine learning (QML)\nsettings. We gain an intuitive picture of the hardness of many QML tasks which\ngoes beyond existing methods such as barren plateaus and the statistical\ndimension, and contains crucial setting-dependent implications. Our framework\nnot only unifies the perspective of cost concentration with that of the\nstatistical dimension in a unified language but exposes their connectedness and\nsimilarity.",
            "author": [
                "Alexander Nietner"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17716v1",
                "http://arxiv.org/pdf/2310.17716v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17712v1",
            "title": "Community Detection and Classification Guarantees Using Embeddings\n  Learned by Node2Vec",
            "updated": "2023-10-26T18:16:23Z",
            "published": "2023-10-26T18:16:23Z",
            "summary": "Embedding the nodes of a large network into an Euclidean space is a common\nobjective in modern machine learning, with a variety of tools available. These\nembeddings can then be used as features for tasks such as community\ndetection/node clustering or link prediction, where they achieve state of the\nart performance. With the exception of spectral clustering methods, there is\nlittle theoretical understanding for other commonly used approaches to learning\nembeddings. In this work we examine the theoretical properties of the\nembeddings learned by node2vec. Our main result shows that the use of k-means\nclustering on the embedding vectors produced by node2vec gives weakly\nconsistent community recovery for the nodes in (degree corrected) stochastic\nblock models. We also discuss the use of these embeddings for node and link\nprediction tasks. We demonstrate this result empirically, and examine how this\nrelates to other embedding tools for network data.",
            "author": [
                "Andrew Davison",
                "S. Carlyle Morgan",
                "Owen G. Ward"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17712v1",
                "http://arxiv.org/pdf/2310.17712v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "cs.SI",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17705v1",
            "title": "A Wireless AI-Generated Content (AIGC) Provisioning Framework Empowered\n  by Semantic Communication",
            "updated": "2023-10-26T18:05:22Z",
            "published": "2023-10-26T18:05:22Z",
            "summary": "Generative AI applications are recently catering to a vast user base by\ncreating diverse and high-quality AI-generated content (AIGC). With the\nproliferation of mobile devices and rapid growth of mobile traffic, providing\nubiquitous access to high-quality AIGC services via wireless communication\nnetworks is becoming the future direction for AIGC products. However, it is\nchallenging to provide optimal AIGC services in wireless networks with unstable\nchannels, limited bandwidth resources, and unevenly distributed computational\nresources. To tackle these challenges, we propose a semantic communication\n(SemCom)-empowered AIGC (SemAIGC) generation and transmission framework, where\nonly semantic information of the content rather than all the binary bits should\nbe extracted and transmitted by using SemCom. Specifically, SemAIGC integrates\ndiffusion-based models within the semantic encoder and decoder for efficient\ncontent generation and flexible adjustment of the computing workload of both\ntransmitter and receiver. Meanwhile, we devise a resource-aware workload\ntrade-off (ROOT) scheme into the SemAIGC framework to intelligently decide\ntransmitter/receiver workload, thus adjusting the utilization of computational\nresource according to service requirements. Simulations verify the superiority\nof our proposed SemAIGC framework in terms of latency and content quality\ncompared to conventional approaches.",
            "author": [
                "Runze Cheng",
                "Yao Sun",
                "Dusit Niyato",
                "Lan Zhang",
                "Lei Zhang",
                "Muhammad Ali Imran"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17705v1",
                "http://arxiv.org/pdf/2310.17705v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.AI",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17690v1",
            "title": "Non-contrastive sentence representations via self-supervision",
            "updated": "2023-10-26T18:00:00Z",
            "published": "2023-10-26T18:00:00Z",
            "summary": "Sample contrastive methods, typically referred to simply as contrastive are\nthe foundation of most unsupervised methods to learn text and sentence\nembeddings. On the other hand, a different class of self-supervised loss\nfunctions and methods have been considered in the computer vision community and\nreferred to as dimension contrastive. In this paper, we thoroughly compare this\nclass of methods with the standard baseline for contrastive sentence\nembeddings, SimCSE. We find that self-supervised embeddings trained using\ndimension contrastive objectives can outperform SimCSE on downstream tasks\nwithout needing auxiliary loss functions.",
            "author": [
                "Marco Farina",
                "Duccio Pappadopulo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17690v1",
                "http://arxiv.org/pdf/2310.17690v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17653v1",
            "title": "Fantastic Gains and Where to Find Them: On the Existence and Prospect of\n  General Knowledge Transfer between Any Pretrained Model",
            "updated": "2023-10-26T17:59:46Z",
            "published": "2023-10-26T17:59:46Z",
            "summary": "Training deep networks requires various design decisions regarding for\ninstance their architecture, data augmentation, or optimization. In this work,\nwe find these training variations to result in networks learning unique feature\nsets from the data. Using public model libraries comprising thousands of models\ntrained on canonical datasets like ImageNet, we observe that for arbitrary\npairings of pretrained models, one model extracts significant data context\nunavailable in the other -- independent of overall performance. Given any\narbitrary pairing of pretrained models and no external rankings (such as\nseparate test sets, e.g. due to data privacy), we investigate if it is possible\nto transfer such \"complementary\" knowledge from one model to another without\nperformance degradation -- a task made particularly difficult as additional\nknowledge can be contained in stronger, equiperformant or weaker models. Yet\nfacilitating robust transfer in scenarios agnostic to pretrained model pairings\nwould unlock auxiliary gains and knowledge fusion from any model repository\nwithout restrictions on model and problem specifics - including from weaker,\nlower-performance models. This work therefore provides an initial, in-depth\nexploration on the viability of such general-purpose knowledge transfer. Across\nlarge-scale experiments, we first reveal the shortcomings of standard knowledge\ndistillation techniques, and then propose a much more general extension through\ndata partitioning for successful transfer between nearly all pretrained models,\nwhich we show can also be done unsupervised. Finally, we assess both the\nscalability and impact of fundamental model properties on successful\nmodel-agnostic knowledge transfer.",
            "author": [
                "Karsten Roth",
                "Lukas Thede",
                "Almut Sophia Koepke",
                "Oriol Vinyals",
                "Olivier H\u00e9naff",
                "Zeynep Akata"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17653v1",
                "http://arxiv.org/pdf/2310.17653v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17651v2",
            "title": "High-Dimensional Prediction for Sequential Decision Making",
            "updated": "2023-10-27T17:59:29Z",
            "published": "2023-10-26T17:59:32Z",
            "summary": "We study the problem of making predictions of an adversarially chosen\nhigh-dimensional state that are unbiased subject to an arbitrary collection of\nconditioning events, with the goal of tailoring these events to downstream\ndecision makers. We give efficient algorithms for solving this problem, as well\nas a number of applications that stem from choosing an appropriate set of\nconditioning events.\n  For example, we can efficiently make predictions targeted at polynomially\nmany decision makers, giving each of them optimal swap regret if they\nbest-respond to our predictions. We generalize this to online combinatorial\noptimization, where the decision makers have a very large action space, to give\nthe first algorithms offering polynomially many decision makers no regret on\npolynomially many subsequences that may depend on their actions and the\ncontext. We apply these results to get efficient no-subsequence-regret\nalgorithms in extensive-form games (EFGs), yielding a new family of regret\nguarantees for EFGs that generalizes some existing EFG regret notions, e.g.\nregret to informed causal deviations, and is generally incomparable to other\nknown such notions.\n  Next, we develop a novel transparent alternative to conformal prediction for\nbuilding valid online adversarial multiclass prediction sets. We produce class\nscores that downstream algorithms can use for producing valid-coverage\nprediction sets, as if these scores were the true conditional class\nprobabilities. We show this implies strong conditional validity guarantees\nincluding set-size-conditional and multigroup-fair coverage for polynomially\nmany downstream prediction sets. Moreover, our class scores can be guaranteed\nto have improved $L_2$ loss, cross-entropy loss, and generally any Bregman\nloss, compared to any collection of benchmark models, yielding a\nhigh-dimensional real-valued version of omniprediction.",
            "author": [
                "Georgy Noarov",
                "Ramya Ramalingam",
                "Aaron Roth",
                "Stephan Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17651v2",
                "http://arxiv.org/pdf/2310.17651v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17650v1",
            "title": "A Coarse-to-Fine Pseudo-Labeling (C2FPL) Framework for Unsupervised\n  Video Anomaly Detection",
            "updated": "2023-10-26T17:59:19Z",
            "published": "2023-10-26T17:59:19Z",
            "summary": "Detection of anomalous events in videos is an important problem in\napplications such as surveillance. Video anomaly detection (VAD) is\nwell-studied in the one-class classification (OCC) and weakly supervised (WS)\nsettings. However, fully unsupervised (US) video anomaly detection methods,\nwhich learn a complete system without any annotation or human supervision, have\nnot been explored in depth. This is because the lack of any ground truth\nannotations significantly increases the magnitude of the VAD challenge. To\naddress this challenge, we propose a simple-but-effective two-stage\npseudo-label generation framework that produces segment-level (normal/anomaly)\npseudo-labels, which can be further used to train a segment-level anomaly\ndetector in a supervised manner. The proposed coarse-to-fine pseudo-label\n(C2FPL) generator employs carefully-designed hierarchical divisive clustering\nand statistical hypothesis testing to identify anomalous video segments from a\nset of completely unlabeled videos. The trained anomaly detector can be\ndirectly applied on segments of an unseen test video to obtain segment-level,\nand subsequently, frame-level anomaly predictions. Extensive studies on two\nlarge-scale public-domain datasets, UCF-Crime and XD-Violence, demonstrate that\nthe proposed unsupervised approach achieves superior performance compared to\nall existing OCC and US methods , while yielding comparable performance to the\nstate-of-the-art WS methods.",
            "author": [
                "Anas Al-lahham",
                "Nurbek Tastan",
                "Zaigham Zaheer",
                "Karthik Nandakumar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17650v1",
                "http://arxiv.org/pdf/2310.17650v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17649v1",
            "title": "6-DoF Stability Field via Diffusion Models",
            "updated": "2023-10-26T17:59:12Z",
            "published": "2023-10-26T17:59:12Z",
            "summary": "A core capability for robot manipulation is reasoning over where and how to\nstably place objects in cluttered environments. Traditionally, robots have\nrelied on object-specific, hand-crafted heuristics in order to perform such\nreasoning, with limited generalizability beyond a small number of object\ninstances and object interaction patterns. Recent approaches instead learn\nnotions of physical interaction, namely motion prediction, but require\nsupervision in the form of labeled object information or come at the cost of\nhigh sample complexity, and do not directly reason over stability or object\nplacement. We present 6-DoFusion, a generative model capable of generating 3D\nposes of an object that produces a stable configuration of a given scene.\nUnderlying 6-DoFusion is a diffusion model that incrementally refines a\nrandomly initialized SE(3) pose to generate a sample from a learned,\ncontext-dependent distribution over stable poses. We evaluate our model on\ndifferent object placement and stacking tasks, demonstrating its ability to\nconstruct stable scenes that involve novel object classes as well as to improve\nthe accuracy of state-of-the-art 3D pose estimation methods.",
            "author": [
                "Takuma Yoneda",
                "Tianchong Jiang",
                "Gregory Shakhnarovich",
                "Matthew R. Walter"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17649v1",
                "http://arxiv.org/pdf/2310.17649v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17688v2",
            "title": "Managing AI Risks in an Era of Rapid Progress",
            "updated": "2023-11-12T14:33:20Z",
            "published": "2023-10-26T17:59:06Z",
            "summary": "In this short consensus paper, we outline risks from upcoming, advanced AI\nsystems. We examine large-scale social harms and malicious uses, as well as an\nirreversible loss of human control over autonomous AI systems. In light of\nrapid and continuing AI progress, we propose urgent priorities for AI R&D and\ngovernance.",
            "author": [
                "Yoshua Bengio",
                "Geoffrey Hinton",
                "Andrew Yao",
                "Dawn Song",
                "Pieter Abbeel",
                "Yuval Noah Harari",
                "Ya-Qin Zhang",
                "Lan Xue",
                "Shai Shalev-Shwartz",
                "Gillian Hadfield",
                "Jeff Clune",
                "Tegan Maharaj",
                "Frank Hutter",
                "At\u0131l\u0131m G\u00fcne\u015f Baydin",
                "Sheila McIlraith",
                "Qiqi Gao",
                "Ashwin Acharya",
                "David Krueger",
                "Anca Dragan",
                "Philip Torr",
                "Stuart Russell",
                "Daniel Kahneman",
                "Jan Brauner",
                "S\u00f6ren Mindermann"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17688v2",
                "http://arxiv.org/pdf/2310.17688v2"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17687v1",
            "title": "Counterfactual Fairness for Predictions using Generative Adversarial\n  Networks",
            "updated": "2023-10-26T17:58:39Z",
            "published": "2023-10-26T17:58:39Z",
            "summary": "Fairness in predictions is of direct importance in practice due to legal,\nethical, and societal reasons. It is often achieved through counterfactual\nfairness, which ensures that the prediction for an individual is the same as\nthat in a counterfactual world under a different sensitive attribute. However,\nachieving counterfactual fairness is challenging as counterfactuals are\nunobservable. In this paper, we develop a novel deep neural network called\nGenerative Counterfactual Fairness Network (GCFN) for making predictions under\ncounterfactual fairness. Specifically, we leverage a tailored generative\nadversarial network to directly learn the counterfactual distribution of the\ndescendants of the sensitive attribute, which we then use to enforce fair\npredictions through a novel counterfactual mediator regularization. If the\ncounterfactual distribution is learned sufficiently well, our method is\nmathematically guaranteed to ensure the notion of counterfactual fairness.\nThereby, our GCFN addresses key shortcomings of existing baselines that are\nbased on inferring latent variables, yet which (a) are potentially correlated\nwith the sensitive attributes and thus lead to bias, and (b) have weak\ncapability in constructing latent representations and thus low prediction\nperformance. Across various experiments, our method achieves state-of-the-art\nperformance. Using a real-world case study from recidivism prediction, we\nfurther demonstrate that our method makes meaningful predictions in practice.",
            "author": [
                "Yuchen Ma",
                "Dennis Frauen",
                "Valentyn Melnychuk",
                "Stefan Feuerriegel"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17687v1",
                "http://arxiv.org/pdf/2310.17687v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17646v1",
            "title": "Do Graph Neural Networks Dream of Landau Damping? Insights from Kinetic\n  Simulations of a Plasma Sheet Model",
            "updated": "2023-10-26T17:58:12Z",
            "published": "2023-10-26T17:58:12Z",
            "summary": "We explore the possibility of fully replacing a plasma physics kinetic\nsimulator with a graph neural network-based simulator. We focus on this class\nof surrogate models given the similarity between their message-passing update\nmechanism and the traditional physics solver update, and the possibility of\nenforcing known physical priors into the graph construction and update. We show\nthat our model learns the kinetic plasma dynamics of the one-dimensional plasma\nmodel, a predecessor of contemporary kinetic plasma simulation codes, and\nrecovers a wide range of well-known kinetic plasma processes, including plasma\nthermalization, electrostatic fluctuations about thermal equilibrium, and the\ndrag on a fast sheet and Landau damping. We compare the performance against the\noriginal plasma model in terms of run-time, conservation laws, and temporal\nevolution of key physical quantities. The limitations of the model are\npresented and possible directions for higher-dimensional surrogate models for\nkinetic plasmas are discussed.",
            "author": [
                "Diogo D Carvalho",
                "Diogo R Ferreira",
                "Luis O Silva"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17646v1",
                "http://arxiv.org/pdf/2310.17646v1"
            ],
            "primary_category": "physics.plasm-ph",
            "category": [
                "physics.plasm-ph",
                "cs.LG",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17645v1",
            "title": "Defending Against Transfer Attacks From Public Models",
            "updated": "2023-10-26T17:58:08Z",
            "published": "2023-10-26T17:58:08Z",
            "summary": "Adversarial attacks have been a looming and unaddressed threat in the\nindustry. However, through a decade-long history of the robustness evaluation\nliterature, we have learned that mounting a strong or optimal attack is\nchallenging. It requires both machine learning and domain expertise. In other\nwords, the white-box threat model, religiously assumed by a large majority of\nthe past literature, is unrealistic. In this paper, we propose a new practical\nthreat model where the adversary relies on transfer attacks through publicly\navailable surrogate models. We argue that this setting will become the most\nprevalent for security-sensitive applications in the future. We evaluate the\ntransfer attacks in this setting and propose a specialized defense method based\non a game-theoretic perspective. The defenses are evaluated under 24 public\nmodels and 11 attack algorithms across three datasets (CIFAR-10, CIFAR-100, and\nImageNet). Under this threat model, our defense, PubDef, outperforms the\nstate-of-the-art white-box adversarial training by a large margin with almost\nno loss in the normal accuracy. For instance, on ImageNet, our defense achieves\n62% accuracy under the strongest transfer attack vs only 36% of the best\nadversarially trained model. Its accuracy when not under attack is only 2%\nlower than that of an undefended model (78% vs 80%). We release our code at\nhttps://github.com/wagner-group/pubdef.",
            "author": [
                "Chawin Sitawarin",
                "Jaewon Chang",
                "David Huang",
                "Wesson Altoyan",
                "David Wagner"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17645v1",
                "http://arxiv.org/pdf/2310.17645v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CR",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17644v1",
            "title": "torchdistill Meets Hugging Face Libraries for Reproducible, Coding-Free\n  Deep Learning Studies: A Case Study on NLP",
            "updated": "2023-10-26T17:57:15Z",
            "published": "2023-10-26T17:57:15Z",
            "summary": "Reproducibility in scientific work has been becoming increasingly important\nin research communities such as machine learning, natural language processing,\nand computer vision communities due to the rapid development of the research\ndomains supported by recent advances in deep learning. In this work, we present\na significantly upgraded version of torchdistill, a modular-driven coding-free\ndeep learning framework significantly upgraded from the initial release, which\nsupports only image classification and object detection tasks for reproducible\nknowledge distillation experiments. To demonstrate that the upgraded framework\ncan support more tasks with third-party libraries, we reproduce the GLUE\nbenchmark results of BERT models using a script based on the upgraded\ntorchdistill, harmonizing with various Hugging Face libraries. All the 27\nfine-tuned BERT models and configurations to reproduce the results are\npublished at Hugging Face, and the model weights have already been widely used\nin research communities. We also reimplement popular small-sized models and new\nknowledge distillation methods and perform additional experiments for computer\nvision tasks.",
            "author": [
                "Yoshitomo Matsubara"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17644v1",
                "http://arxiv.org/pdf/2310.17644v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17643v1",
            "title": "Where you go is who you are -- A study on machine learning based\n  semantic privacy attacks",
            "updated": "2023-10-26T17:56:50Z",
            "published": "2023-10-26T17:56:50Z",
            "summary": "Concerns about data privacy are omnipresent, given the increasing usage of\ndigital applications and their underlying business model that includes selling\nuser data. Location data is particularly sensitive since they allow us to infer\nactivity patterns and interests of users, e.g., by categorizing visited\nlocations based on nearby points of interest (POI). On top of that, machine\nlearning methods provide new powerful tools to interpret big data. In light of\nthese considerations, we raise the following question: What is the actual risk\nthat realistic, machine learning based privacy attacks can obtain meaningful\nsemantic information from raw location data, subject to inaccuracies in the\ndata? In response, we present a systematic analysis of two attack scenarios,\nnamely location categorization and user profiling. Experiments on the\nFoursquare dataset and tracking data demonstrate the potential for abuse of\nhigh-quality spatial information, leading to a significant privacy loss even\nwith location inaccuracy of up to 200m. With location obfuscation of more than\n1 km, spatial information hardly adds any value, but a high privacy risk solely\nfrom temporal information remains. The availability of public context data such\nas POIs plays a key role in inference based on spatial information. Our\nfindings point out the risks of ever-growing databases of tracking data and\nspatial context data, which policymakers should consider for privacy\nregulations, and which could guide individuals in their personal location\nprotection measures.",
            "author": [
                "Nina Wiedemann",
                "Ourania Kounadi",
                "Martin Raubal",
                "Krzysztof Janowicz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17643v1",
                "http://arxiv.org/pdf/2310.17643v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.CE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17642v1",
            "title": "Drive Anywhere: Generalizable End-to-end Autonomous Driving with\n  Multi-modal Foundation Models",
            "updated": "2023-10-26T17:56:35Z",
            "published": "2023-10-26T17:56:35Z",
            "summary": "As autonomous driving technology matures, end-to-end methodologies have\nemerged as a leading strategy, promising seamless integration from perception\nto control via deep learning. However, existing systems grapple with challenges\nsuch as unexpected open set environments and the complexity of black-box\nmodels. At the same time, the evolution of deep learning introduces larger,\nmultimodal foundational models, offering multi-modal visual and textual\nunderstanding. In this paper, we harness these multimodal foundation models to\nenhance the robustness and adaptability of autonomous driving systems, enabling\nout-of-distribution, end-to-end, multimodal, and more explainable autonomy.\nSpecifically, we present an approach to apply end-to-end open-set (any\nenvironment/scene) autonomous driving that is capable of providing driving\ndecisions from representations queryable by image and text. To do so, we\nintroduce a method to extract nuanced spatial (pixel/patch-aligned) features\nfrom transformers to enable the encapsulation of both spatial and semantic\nfeatures. Our approach (i) demonstrates unparalleled results in diverse tests\nwhile achieving significantly greater robustness in out-of-distribution\nsituations, and (ii) allows the incorporation of latent space simulation (via\ntext) for improved training (data augmentation via text) and policy debugging.\nWe encourage the reader to check our explainer video at\nhttps://www.youtube.com/watch?v=4n-DJf8vXxo&feature=youtu.be and to view the\ncode and demos on our project webpage at https://drive-anywhere.github.io/.",
            "author": [
                "Tsun-Hsuan Wang",
                "Alaa Maalouf",
                "Wei Xiao",
                "Yutong Ban",
                "Alexander Amini",
                "Guy Rosman",
                "Sertac Karaman",
                "Daniela Rus"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17642v1",
                "http://arxiv.org/pdf/2310.17642v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17639v2",
            "title": "In-Context Learning Dynamics with Random Binary Sequences",
            "updated": "2023-11-27T21:05:54Z",
            "published": "2023-10-26T17:54:52Z",
            "summary": "Large language models (LLMs) trained on huge corpora of text datasets\ndemonstrate intriguing capabilities, achieving state-of-the-art performance on\ntasks they were not explicitly trained for. The precise nature of LLM\ncapabilities is often mysterious, and different prompts can elicit different\ncapabilities through in-context learning. We propose a framework that enables\nus to analyze in-context learning dynamics to understand latent concepts\nunderlying LLMs' behavioral patterns. This provides a more nuanced\nunderstanding than success-or-failure evaluation benchmarks, but does not\nrequire observing internal activations as a mechanistic interpretation of\ncircuits would. Inspired by the cognitive science of human randomness\nperception, we use random binary sequences as context and study dynamics of\nin-context learning by manipulating properties of context data, such as\nsequence length. In the latest GPT-3.5+ models, we find emergent abilities to\ngenerate seemingly random numbers and learn basic formal languages, with\nstriking in-context learning dynamics where model outputs transition sharply\nfrom seemingly random behaviors to deterministic repetition.",
            "author": [
                "Eric J. Bigelow",
                "Ekdeep Singh Lubana",
                "Robert P. Dick",
                "Hidenori Tanaka",
                "Tomer D. Ullman"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17639v2",
                "http://arxiv.org/pdf/2310.17639v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17638v1",
            "title": "Generative Fractional Diffusion Models",
            "updated": "2023-10-26T17:53:24Z",
            "published": "2023-10-26T17:53:24Z",
            "summary": "We generalize the continuous time framework for score-based generative models\nfrom an underlying Brownian motion (BM) to an approximation of fractional\nBrownian motion (FBM). We derive a continuous reparameterization trick and the\nreverse time model by representing FBM as a stochastic integral over a family\nof Ornstein-Uhlenbeck processes to define generative fractional diffusion\nmodels (GFDM) with driving noise converging to a non-Markovian process of\ninfinite quadratic variation. The Hurst index $H\\in(0,1)$ of FBM enables\ncontrol of the roughness of the distribution transforming path. To the best of\nour knowledge, this is the first attempt to build a generative model upon a\nstochastic process with infinite quadratic variation.",
            "author": [
                "Gabriel Nobis",
                "Marco Aversa",
                "Maximilian Springenberg",
                "Michael Detzel",
                "Stefano Ermon",
                "Shinichi Nakajima",
                "Roderick Murray-Smith",
                "Sebastian Lapuschkin",
                "Christoph Knochenhauer",
                "Luis Oala",
                "Wojciech Samek"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17638v1",
                "http://arxiv.org/pdf/2310.17638v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML",
                "I.2.4; F.4.1; G.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17634v1",
            "title": "Grow Your Limits: Continuous Improvement with Real-World RL for Robotic\n  Locomotion",
            "updated": "2023-10-26T17:51:46Z",
            "published": "2023-10-26T17:51:46Z",
            "summary": "Deep reinforcement learning (RL) can enable robots to autonomously acquire\ncomplex behaviors, such as legged locomotion. However, RL in the real world is\ncomplicated by constraints on efficiency, safety, and overall training\nstability, which limits its practical applicability. We present APRL, a policy\nregularization framework that modulates the robot's exploration over the course\nof training, striking a balance between flexible improvement potential and\nfocused, efficient exploration. APRL enables a quadrupedal robot to efficiently\nlearn to walk entirely in the real world within minutes and continue to improve\nwith more training where prior work saturates in performance. We demonstrate\nthat continued training with APRL results in a policy that is substantially\nmore capable of navigating challenging situations and is able to adapt to\nchanges in dynamics with continued training.",
            "author": [
                "Laura Smith",
                "Yunhao Cao",
                "Sergey Levine"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17634v1",
                "http://arxiv.org/pdf/2310.17634v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17629v1",
            "title": "Approximate Leave-one-out Cross Validation for Regression with $\\ell_1$\n  Regularizers (extended version)",
            "updated": "2023-10-26T17:48:10Z",
            "published": "2023-10-26T17:48:10Z",
            "summary": "The out-of-sample error (OO) is the main quantity of interest in risk\nestimation and model selection. Leave-one-out cross validation (LO) offers a\n(nearly) distribution-free yet computationally demanding approach to estimate\nOO. Recent theoretical work showed that approximate leave-one-out cross\nvalidation (ALO) is a computationally efficient and statistically reliable\nestimate of LO (and OO) for generalized linear models with differentiable\nregularizers. For problems involving non-differentiable regularizers, despite\nsignificant empirical evidence, the theoretical understanding of ALO's error\nremains unknown. In this paper, we present a novel theory for a wide class of\nproblems in the generalized linear model family with non-differentiable\nregularizers. We bound the error |ALO - LO| in terms of intuitive metrics such\nas the size of leave-i-out perturbations in active sets, sample size n, number\nof features p and regularization parameters. As a consequence, for the\n$\\ell_1$-regularized problems, we show that |ALO - LO| goes to zero as p goes\nto infinity while n/p and SNR are fixed and bounded.",
            "author": [
                "Arnab Auddy",
                "Haolin Zou",
                "Kamiar Rahnama Rad",
                "Arian Maleki"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17629v1",
                "http://arxiv.org/pdf/2310.17629v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "stat.ME",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17626v1",
            "title": "A Survey on Transferability of Adversarial Examples across Deep Neural\n  Networks",
            "updated": "2023-10-26T17:45:26Z",
            "published": "2023-10-26T17:45:26Z",
            "summary": "The emergence of Deep Neural Networks (DNNs) has revolutionized various\ndomains, enabling the resolution of complex tasks spanning image recognition,\nnatural language processing, and scientific problem-solving. However, this\nprogress has also exposed a concerning vulnerability: adversarial examples.\nThese crafted inputs, imperceptible to humans, can manipulate machine learning\nmodels into making erroneous predictions, raising concerns for safety-critical\napplications. An intriguing property of this phenomenon is the transferability\nof adversarial examples, where perturbations crafted for one model can deceive\nanother, often with a different architecture. This intriguing property enables\n\"black-box\" attacks, circumventing the need for detailed knowledge of the\ntarget model. This survey explores the landscape of the adversarial\ntransferability of adversarial examples. We categorize existing methodologies\nto enhance adversarial transferability and discuss the fundamental principles\nguiding each approach. While the predominant body of research primarily\nconcentrates on image classification, we also extend our discussion to\nencompass other vision tasks and beyond. Challenges and future prospects are\ndiscussed, highlighting the importance of fortifying DNNs against adversarial\nvulnerabilities in an evolving landscape.",
            "author": [
                "Jindong Gu",
                "Xiaojun Jia",
                "Pau de Jorge",
                "Wenqain Yu",
                "Xinwei Liu",
                "Avery Ma",
                "Yuan Xun",
                "Anjun Hu",
                "Ashkan Khakzar",
                "Zhijiang Li",
                "Xiaochun Cao",
                "Philip Torr"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17626v1",
                "http://arxiv.org/pdf/2310.17626v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17623v2",
            "title": "Proving Test Set Contamination in Black Box Language Models",
            "updated": "2023-11-24T01:45:16Z",
            "published": "2023-10-26T17:43:13Z",
            "summary": "Large language models are trained on vast amounts of internet data, prompting\nconcerns and speculation that they have memorized public benchmarks. Going from\nspeculation to proof of contamination is challenging, as the pretraining data\nused by proprietary models are often not publicly accessible. We show that it\nis possible to provide provable guarantees of test set contamination in\nlanguage models without access to pretraining data or model weights. Our\napproach leverages the fact that when there is no data contamination, all\norderings of an exchangeable benchmark should be equally likely. In contrast,\nthe tendency for language models to memorize example order means that a\ncontaminated language model will find certain canonical orderings to be much\nmore likely than others. Our test flags potential contamination whenever the\nlikelihood of a canonically ordered benchmark dataset is significantly higher\nthan the likelihood after shuffling the examples. We demonstrate that our\nprocedure is sensitive enough to reliably prove test set contamination in\nchallenging situations, including models as small as 1.4 billion parameters, on\nsmall test sets of only 1000 examples, and datasets that appear only a few\ntimes in the pretraining corpus. Using our test, we audit five popular publicly\naccessible language models for test set contamination and find little evidence\nfor pervasive contamination.",
            "author": [
                "Yonatan Oren",
                "Nicole Meister",
                "Niladri Chatterji",
                "Faisal Ladhak",
                "Tatsunori B. Hashimoto"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17623v2",
                "http://arxiv.org/pdf/2310.17623v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17622v1",
            "title": "Combating Representation Learning Disparity with Geometric Harmonization",
            "updated": "2023-10-26T17:41:11Z",
            "published": "2023-10-26T17:41:11Z",
            "summary": "Self-supervised learning (SSL) as an effective paradigm of representation\nlearning has achieved tremendous success on various curated datasets in diverse\nscenarios. Nevertheless, when facing the long-tailed distribution in real-world\napplications, it is still hard for existing methods to capture transferable and\nrobust representation. Conventional SSL methods, pursuing sample-level\nuniformity, easily leads to representation learning disparity where head\nclasses dominate the feature regime but tail classes passively collapse. To\naddress this problem, we propose a novel Geometric Harmonization (GH) method to\nencourage category-level uniformity in representation learning, which is more\nbenign to the minority and almost does not hurt the majority under long-tailed\ndistribution. Specially, GH measures the population statistics of the embedding\nspace on top of self-supervised learning, and then infer an fine-grained\ninstance-wise calibration to constrain the space expansion of head classes and\navoid the passive collapse of tail classes. Our proposal does not alter the\nsetting of SSL and can be easily integrated into existing methods in a low-cost\nmanner. Extensive results on a range of benchmark datasets show the\neffectiveness of GH with high tolerance to the distribution skewness. Our code\nis available at https://github.com/MediaBrain-SJTU/Geometric-Harmonization.",
            "author": [
                "Zhihan Zhou",
                "Jiangchao Yao",
                "Feng Hong",
                "Ya Zhang",
                "Bo Han",
                "Yanfeng Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17622v1",
                "http://arxiv.org/pdf/2310.17622v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17616v1",
            "title": "Verifying Programs with Logic and Extended Proof Rules: Deep Embedding\n  v.s. Shallow Embedding",
            "updated": "2023-10-26T17:37:26Z",
            "published": "2023-10-26T17:37:26Z",
            "summary": "Many foundational program verification tools have been developed to build\nmachine-checked program correctness proofs, a majority of which are based on\nHoare logic. Their program logics, their assertion languages, and their\nunderlying programming languages can be formalized by either a shallow\nembedding or a deep embedding. Tools like Iris and early versions of Verified\nSoftware Toolchain (VST) choose different shallow embeddings to formalize their\nprogram logics. But the pros and cons of these different embeddings were not\nyet well studied. Therefore, we want to study the impact of the program logic's\nembedding on logic's proof rules in this paper. This paper considers a set of\nuseful extended proof rules, and four different logic embeddings: one deep\nembedding and three common shallow embeddings. We prove the validity of these\nextended rules under these embeddings and discuss their main challenges.\nFurthermore, we propose a method to lift existing shallowly embedded logics to\ndeeply embedded ones to greatly simplify proofs of extended rules in specific\nproof systems. We evaluate our results on two existing verification tools. We\nlift the originally shallowly embedded VST to our deeply embedded VST to\nsupport extended rules, and we implement Iris-CF and deeply embedded Iris-Imp\nbased on the Iris framework to evaluate our theory in real verification\nprojects.",
            "author": [
                "Zhongye Wang",
                "Qinxiang Cao",
                "Yichen Tao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17616v1",
                "http://arxiv.org/pdf/2310.17616v1"
            ],
            "primary_category": "cs.PL",
            "category": [
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17614v1",
            "title": "Topological and magnetic properties of the interacting\n  Bernevig-Hughes-Zhang model",
            "updated": "2023-10-26T17:36:11Z",
            "published": "2023-10-26T17:36:11Z",
            "summary": "We investigate the effects of electronic correlations on the\nBernevig-Hughes-Zhang model using the real-space density matrix renormalization\ngroup (DMRG) algorithm. We introduce a method to probe topological phase\ntransitions in systems with strong correlations using DMRG, substantiated by an\nunsupervised machine learning methodology that analyzes the orbital structure\nof the real-space edges. Including the full multi-orbital Hubbard interaction\nterm, we construct a phase diagram as a function of a gap parameter ($m$) and\nthe Hubbard interaction strength ($U$) via exact DMRG simulations on $N\\times\n4$ cylinders. Our analysis confirms that the topological phase persists in the\npresence of interactions, consistent with previous studies, but it also reveals\nan intriguing phase transition from a paramagnetic to an antiferromagnetic\ntopological insulator. The combination of the magnetic structure factor,\nstrength of magnetic moments, and the orbitally resolved density, provides\nreal-space information on both topology and magnetism in a strongly correlated\nsystem.",
            "author": [
                "Rahul Soni",
                "Harini Radhakrishnan",
                "Bernd Rosenow",
                "Gonzalo Alvarez",
                "Adrian Del Maestro"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17614v1",
                "http://arxiv.org/pdf/2310.17614v1"
            ],
            "primary_category": "cond-mat.str-el",
            "category": [
                "cond-mat.str-el"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17611v1",
            "title": "Uncovering Meanings of Embeddings via Partial Orthogonality",
            "updated": "2023-10-26T17:34:32Z",
            "published": "2023-10-26T17:34:32Z",
            "summary": "Machine learning tools often rely on embedding text as vectors of real\nnumbers. In this paper, we study how the semantic structure of language is\nencoded in the algebraic structure of such embeddings. Specifically, we look at\na notion of ``semantic independence'' capturing the idea that, e.g.,\n``eggplant'' and ``tomato'' are independent given ``vegetable''. Although such\nexamples are intuitive, it is difficult to formalize such a notion of semantic\nindependence. The key observation here is that any sensible formalization\nshould obey a set of so-called independence axioms, and thus any algebraic\nencoding of this structure should also obey these axioms. This leads us\nnaturally to use partial orthogonality as the relevant algebraic structure. We\ndevelop theory and methods that allow us to demonstrate that partial\northogonality does indeed capture semantic independence. Complementary to this,\nwe also introduce the concept of independence preserving embeddings where\nembeddings preserve the conditional independence structures of a distribution,\nand we prove the existence of such embeddings and approximations to them.",
            "author": [
                "Yibo Jiang",
                "Bryon Aragam",
                "Victor Veitch"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17611v1",
                "http://arxiv.org/pdf/2310.17611v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17610v1",
            "title": "A qualitative difference between gradient flows of convex functions in\n  finite- and infinite-dimensional Hilbert spaces",
            "updated": "2023-10-26T17:33:52Z",
            "published": "2023-10-26T17:33:52Z",
            "summary": "We consider gradient flow/gradient descent and heavy ball/accelerated\ngradient descent optimization for convex objective functions. In the gradient\nflow case, we prove the following:\n  1. If $f$ does not have a minimizer, the convergence $f(x_t)\\to \\inf f$ can\nbe arbitrarily slow.\n  2. If $f$ does have a minimizer, the excess energy $f(x_t) - \\inf f$ is\nintegrable/summable in time. In particular, $f(x_t) - \\inf f = o(1/t)$ as\n$t\\to\\infty$.\n  3. In Hilbert spaces, this is optimal: $f(x_t) - \\inf f$ can decay to $0$ as\nslowly as any given function which is monotone decreasing and integrable at\n$\\infty$, even for a fixed quadratic objective.\n  4. In finite dimension (or more generally, for all gradient flow curves of\nfinite length), this is not optimal: We prove that there are convex monotone\ndecreasing integrable functions $g(t)$ which decrease to zero slower than\n$f(x_t)-\\inf f$ for the gradient flow of any convex function on $\\mathbb R^d$.\nFor instance, we show that any gradient flow $x_t$ of a convex function $f$ in\nfinite dimension satisfies $\\liminf_{t\\to\\infty} \\big(t\\cdot \\log^2(t)\\cdot\n\\big\\{f(x_t) -\\inf f\\big\\}\\big)=0$.\n  This improves on the commonly reported $O(1/t)$ rate and provides a sharp\ncharacterization of the energy decay law. We also note that it is impossible to\nestablish a rate $O(1/(t\\phi(t))$ for any function $\\phi$ which satisfies\n$\\lim_{t\\to\\infty}\\phi(t) = \\infty$, even asymptotically.\n  Similar results are obtained in related settings for (1) discrete time\ngradient descent, (2) stochastic gradient descent with multiplicative noise and\n(3) the heavy ball ODE. In the case of stochastic gradient descent, the\nsummability of $\\mathbb E[f(x_n) - \\inf f]$ is used to prove that $f(x_n)\\to\n\\inf f$ almost surely - an improvement on the convergence almost surely up to a\nsubsequence which follows from the $O(1/n)$ decay estimate.",
            "author": [
                "Jonathan W. Siegel",
                "Stephan Wojtowytsch"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17610v1",
                "http://arxiv.org/pdf/2310.17610v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG",
                "cs.NA",
                "math.CA",
                "math.NA",
                "stat.ML",
                "26A51, 34A34"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17596v1",
            "title": "MimicGen: A Data Generation System for Scalable Robot Learning using\n  Human Demonstrations",
            "updated": "2023-10-26T17:17:31Z",
            "published": "2023-10-26T17:17:31Z",
            "summary": "Imitation learning from a large set of human demonstrations has proved to be\nan effective paradigm for building capable robot agents. However, the\ndemonstrations can be extremely costly and time-consuming to collect. We\nintroduce MimicGen, a system for automatically synthesizing large-scale, rich\ndatasets from only a small number of human demonstrations by adapting them to\nnew contexts. We use MimicGen to generate over 50K demonstrations across 18\ntasks with diverse scene configurations, object instances, and robot arms from\njust ~200 human demonstrations. We show that robot agents can be effectively\ntrained on this generated dataset by imitation learning to achieve strong\nperformance in long-horizon and high-precision tasks, such as multi-part\nassembly and coffee preparation, across broad initial state distributions. We\nfurther demonstrate that the effectiveness and utility of MimicGen data compare\nfavorably to collecting additional human demonstrations, making it a powerful\nand economical approach towards scaling up robot learning. Datasets, simulation\nenvironments, videos, and more at https://mimicgen.github.io .",
            "author": [
                "Ajay Mandlekar",
                "Soroush Nasiriany",
                "Bowen Wen",
                "Iretiayo Akinola",
                "Yashraj Narang",
                "Linxi Fan",
                "Yuke Zhu",
                "Dieter Fox"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17596v1",
                "http://arxiv.org/pdf/2310.17596v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17594v2",
            "title": "SPA: A Graph Spectral Alignment Perspective for Domain Adaptation",
            "updated": "2023-10-27T08:40:15Z",
            "published": "2023-10-26T17:13:48Z",
            "summary": "Unsupervised domain adaptation (UDA) is a pivotal form in machine learning to\nextend the in-domain model to the distinctive target domains where the data\ndistributions differ. Most prior works focus on capturing the inter-domain\ntransferability but largely overlook rich intra-domain structures, which\nempirically results in even worse discriminability. In this work, we introduce\na novel graph SPectral Alignment (SPA) framework to tackle the tradeoff. The\ncore of our method is briefly condensed as follows: (i)-by casting the DA\nproblem to graph primitives, SPA composes a coarse graph alignment mechanism\nwith a novel spectral regularizer towards aligning the domain graphs in\neigenspaces; (ii)-we further develop a fine-grained message propagation module\n-- upon a novel neighbor-aware self-training mechanism -- in order for enhanced\ndiscriminability in the target domain. On standardized benchmarks, the\nextensive experiments of SPA demonstrate that its performance has surpassed the\nexisting cutting-edge DA methods. Coupled with dense model analysis, we\nconclude that our approach indeed possesses superior efficacy, robustness,\ndiscriminability, and transferability. Code and data are available at:\nhttps://github.com/CrownX/SPA.",
            "author": [
                "Zhiqing Xiao",
                "Haobo Wang",
                "Ying Jin",
                "Lei Feng",
                "Gang Chen",
                "Fei Huang",
                "Junbo Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17594v2",
                "http://arxiv.org/pdf/2310.17594v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17588v1",
            "title": "PAC-tuning:Fine-tuning Pretrained Language Models with PAC-driven\n  Perturbed Gradient Descent",
            "updated": "2023-10-26T17:09:13Z",
            "published": "2023-10-26T17:09:13Z",
            "summary": "Fine-tuning pretrained language models (PLMs) for downstream tasks is a\nlarge-scale optimization problem, in which the choice of the training algorithm\ncritically determines how well the trained model can generalize to unseen test\ndata, especially in the context of few-shot learning. To achieve good\ngeneralization performance and avoid overfitting, techniques such as data\naugmentation and pruning are often applied. However, adding these\nregularizations necessitates heavy tuning of the hyperparameters of\noptimization algorithms, such as the popular Adam optimizer. In this paper, we\npropose a two-stage fine-tuning method, PAC-tuning, to address this\noptimization challenge. First, based on PAC-Bayes training, PAC-tuning directly\nminimizes the PAC-Bayes generalization bound to learn proper parameter\ndistribution. Second, PAC-tuning modifies the gradient by injecting noise with\nthe variance learned in the first stage into the model parameters during\ntraining, resulting in a variant of perturbed gradient descent (PGD). In the\npast, the few-shot scenario posed difficulties for PAC-Bayes training because\nthe PAC-Bayes bound, when applied to large models with limited training data,\nmight not be stringent. Our experimental results across 5 GLUE benchmark tasks\ndemonstrate that PAC-tuning successfully handles the challenges of fine-tuning\ntasks and outperforms strong baseline methods by a visible margin, further\nconfirming the potential to apply PAC training for any other settings where the\nAdam optimizer is currently used for training.",
            "author": [
                "Guangliang Liu",
                "Zhiyu Xue",
                "Xitong Zhang",
                "Kristen Marie Johnson",
                "Rongrong Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17588v1",
                "http://arxiv.org/pdf/2310.17588v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17584v2",
            "title": "A minimax optimal control approach for robust neural ODEs",
            "updated": "2023-11-03T11:37:19Z",
            "published": "2023-10-26T17:07:43Z",
            "summary": "In this paper, we address the adversarial training of neural ODEs from a\nrobust control perspective. This is an alternative to the classical training\nvia empirical risk minimization, and it is widely used to enforce reliable\noutcomes for input perturbations. Neural ODEs allow the interpretation of deep\nneural networks as discretizations of control systems, unlocking powerful tools\nfrom control theory for the development and the understanding of machine\nlearning. In this specific case, we formulate the adversarial training with\nperturbed data as a minimax optimal control problem, for which we derive first\norder optimality conditions in the form of Pontryagin's Maximum Principle. We\nprovide a novel interpretation of robust training leading to an alternative\nweighted technique, which we test on a low-dimensional classification task.",
            "author": [
                "Cristina Cipriani",
                "Alessandro Scagliotti",
                "Tobias W\u00f6hrer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17584v2",
                "http://arxiv.org/pdf/2310.17584v2"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17582v1",
            "title": "Convergence of flow-based generative models via proximal gradient\n  descent in Wasserstein space",
            "updated": "2023-10-26T17:06:23Z",
            "published": "2023-10-26T17:06:23Z",
            "summary": "Flow-based generative models enjoy certain advantages in computing the data\ngeneration and the likelihood, and have recently shown competitive empirical\nperformance. Compared to the accumulating theoretical studies on related\nscore-based diffusion models, analysis of flow-based models, which are\ndeterministic in both forward (data-to-noise) and reverse (noise-to-data)\ndirections, remain sparse. In this paper, we provide a theoretical guarantee of\ngenerating data distribution by a progressive flow model, the so-called JKO\nflow model, which implements the Jordan-Kinderleherer-Otto (JKO) scheme in a\nnormalizing flow network. Leveraging the exponential convergence of the\nproximal gradient descent (GD) in Wasserstein space, we prove the\nKullback-Leibler (KL) guarantee of data generation by a JKO flow model to be\n$O(\\varepsilon^2)$ when using $N \\lesssim \\log (1/\\varepsilon)$ many JKO steps\n($N$ Residual Blocks in the flow) where $\\varepsilon $ is the error in the\nper-step first-order condition. The assumption on data density is merely a\nfinite second moment, and the theory extends to data distributions without\ndensity and when there are inversion errors in the reverse process where we\nobtain KL-$W_2$ mixed error guarantees. The non-asymptotic convergence rate of\nthe JKO-type $W_2$-proximal GD is proved for a general class of convex\nobjective functionals that includes the KL divergence as a special case, which\ncan be of independent interest.",
            "author": [
                "Xiuyuan Cheng",
                "Jianfeng Lu",
                "Yixin Tan",
                "Yao Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17582v1",
                "http://arxiv.org/pdf/2310.17582v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "math.OC",
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18373v1",
            "title": "Can LLMs Grade Short-answer Reading Comprehension Questions :\n  Foundational Literacy Assessment in LMICs",
            "updated": "2023-10-26T17:05:40Z",
            "published": "2023-10-26T17:05:40Z",
            "summary": "This paper presents emerging evidence of using generative large language\nmodels (i.e., GPT-4) to reliably evaluate short-answer reading comprehension\nquestions. Specifically, we explore how various configurations of generative\n(LLMs) are able to evaluate student responses from a new dataset, drawn from a\nbattery of reading assessments conducted with over 150 students in Ghana. As\nthis dataset is novel and hence not used in training runs of GPT, it offers an\nopportunity to test for domain shift and evaluate the generalizability of\ngenerative LLMs, which are predominantly designed and trained on data from\nhigh-income North American countries. We found that GPT-4, with minimal prompt\nengineering performed extremely well on evaluating the novel dataset (Quadratic\nWeighted Kappa 0.923, F1 0.88), substantially outperforming transfer-learning\nbased approaches, and even exceeding expert human raters (Quadratic Weighted\nKappa 0.915, F1 0.87). To the best of our knowledge, our work is the first to\nempirically evaluate the performance of generative LLMs on short-answer reading\ncomprehension questions, using real student data, and suggests that generative\nLLMs have the potential to reliably evaluate foundational literacy. Currently\nthe assessment of formative literacy and numeracy is infrequent in many low and\nmiddle-income countries (LMICs) due to the cost and operational complexities of\nconducting them at scale. Automating the grading process for reading assessment\ncould enable wider usage, and in turn improve decision-making regarding\ncurricula, school management, and teaching practice at the classroom level.\nImportantly, in contrast transfer learning based approaches, generative LLMs\ngeneralize well and the technical barriers to their use are low, making them\nmore feasible to implement and scale in lower resource educational contexts.",
            "author": [
                "Owen Henkel",
                "Libby Hills",
                "Bill Roberts",
                "Joshua McGrane"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18373v1",
                "http://arxiv.org/pdf/2310.18373v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17579v1",
            "title": "BLIS-Net: Classifying and Analyzing Signals on Graphs",
            "updated": "2023-10-26T17:03:14Z",
            "published": "2023-10-26T17:03:14Z",
            "summary": "Graph neural networks (GNNs) have emerged as a powerful tool for tasks such\nas node classification and graph classification. However, much less work has\nbeen done on signal classification, where the data consists of many functions\n(referred to as signals) defined on the vertices of a single graph. These tasks\nrequire networks designed differently from those designed for traditional GNN\ntasks. Indeed, traditional GNNs rely on localized low-pass filters, and signals\nof interest may have intricate multi-frequency behavior and exhibit long range\ninteractions. This motivates us to introduce the BLIS-Net (Bi-Lipschitz\nScattering Net), a novel GNN that builds on the previously introduced geometric\nscattering transform. Our network is able to capture both local and global\nsignal structure and is able to capture both low-frequency and high-frequency\ninformation. We make several crucial changes to the original geometric\nscattering architecture which we prove increase the ability of our network to\ncapture information about the input signal and show that BLIS-Net achieves\nsuperior performance on both synthetic and real-world data sets based on\ntraffic flow and fMRI data.",
            "author": [
                "Charles Xu",
                "Laney Goldman",
                "Valentina Guo",
                "Benjamin Hollander-Bodie",
                "Maedee Trank-Greene",
                "Ian Adelstein",
                "Edward De Brouwer",
                "Rex Ying",
                "Smita Krishnaswamy",
                "Michael Perlmutter"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17579v1",
                "http://arxiv.org/pdf/2310.17579v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17577v2",
            "title": "Global Structure-Aware Diffusion Process for Low-Light Image Enhancement",
            "updated": "2023-10-27T08:26:49Z",
            "published": "2023-10-26T17:01:52Z",
            "summary": "This paper studies a diffusion-based framework to address the low-light image\nenhancement problem. To harness the capabilities of diffusion models, we delve\ninto this intricate process and advocate for the regularization of its inherent\nODE-trajectory. To be specific, inspired by the recent research that low\ncurvature ODE-trajectory results in a stable and effective diffusion process,\nwe formulate a curvature regularization term anchored in the intrinsic\nnon-local structures of image data, i.e., global structure-aware\nregularization, which gradually facilitates the preservation of complicated\ndetails and the augmentation of contrast during the diffusion process. This\nincorporation mitigates the adverse effects of noise and artifacts resulting\nfrom the diffusion process, leading to a more precise and flexible enhancement.\nTo additionally promote learning in challenging regions, we introduce an\nuncertainty-guided regularization technique, which wisely relaxes constraints\non the most extreme regions of the image. Experimental evaluations reveal that\nthe proposed diffusion-based framework, complemented by rank-informed\nregularization, attains distinguished performance in low-light enhancement. The\noutcomes indicate substantial advancements in image quality, noise suppression,\nand contrast amplification in comparison with state-of-the-art methods. We\nbelieve this innovative approach will stimulate further exploration and\nadvancement in low-light image processing, with potential implications for\nother applications of diffusion models. The code is publicly available at\nhttps://github.com/jinnh/GSAD.",
            "author": [
                "Jinhui Hou",
                "Zhiyu Zhu",
                "Junhui Hou",
                "Hui Liu",
                "Huanqiang Zeng",
                "Hui Yuan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17577v2",
                "http://arxiv.org/pdf/2310.17577v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17571v1",
            "title": "Inside the black box: Neural network-based real-time prediction of US\n  recessions",
            "updated": "2023-10-26T16:58:16Z",
            "published": "2023-10-26T16:58:16Z",
            "summary": "Feedforward neural network (FFN) and two specific types of recurrent neural\nnetwork, long short-term memory (LSTM) and gated recurrent unit (GRU), are used\nfor modeling US recessions in the period from 1967 to 2021. The estimated\nmodels are then employed to conduct real-time predictions of the Great\nRecession and the Covid-19 recession in US. Their predictive performances are\ncompared to those of the traditional linear models, the logistic regression\nmodel both with and without the ridge penalty. The out-of-sample performance\nsuggests the application of LSTM and GRU in the area of recession forecasting,\nespecially for the long-term forecasting tasks. They outperform other types of\nmodels across 5 forecasting horizons with respect to different types of\nstatistical performance metrics. Shapley additive explanations (SHAP) method is\napplied to the fitted GRUs across different forecasting horizons to gain\ninsight into the feature importance. The evaluation of predictor importance\ndiffers between the GRU and ridge logistic regression models, as reflected in\nthe variable order determined by SHAP values. When considering the top 5\npredictors, key indicators such as the S\\&P 500 index, real GDP, and private\nresidential fixed investment consistently appear for short-term forecasts (up\nto 3 months). In contrast, for longer-term predictions (6 months or more), the\nterm spread and producer price index become more prominent. These findings are\nsupported by both local interpretable model-agnostic explanations (LIME) and\nmarginal effects.",
            "author": [
                "Seulki Chung"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17571v1",
                "http://arxiv.org/pdf/2310.17571v1"
            ],
            "primary_category": "econ.EM",
            "category": [
                "econ.EM",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17569v1",
            "title": "SD4Match: Learning to Prompt Stable Diffusion Model for Semantic\n  Matching",
            "updated": "2023-10-26T16:58:01Z",
            "published": "2023-10-26T16:58:01Z",
            "summary": "In this paper, we address the challenge of matching semantically similar\nkeypoints across image pairs. Existing research indicates that the intermediate\noutput of the UNet within the Stable Diffusion (SD) can serve as robust image\nfeature maps for such a matching task. We demonstrate that by employing a basic\nprompt tuning technique, the inherent potential of Stable Diffusion can be\nharnessed, resulting in a significant enhancement in accuracy over previous\napproaches. We further introduce a novel conditional prompting module that\nconditions the prompt on the local details of the input image pairs, leading to\na further improvement in performance. We designate our approach as SD4Match,\nshort for Stable Diffusion for Semantic Matching. Comprehensive evaluations of\nSD4Match on the PF-Pascal, PF-Willow, and SPair-71k datasets show that it sets\nnew benchmarks in accuracy across all these datasets. Particularly, SD4Match\noutperforms the previous state-of-the-art by a margin of 12 percentage points\non the challenging SPair-71k dataset.",
            "author": [
                "Xinghui Li",
                "Jingyi Lu",
                "Kai Han",
                "Victor Prisacariu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17569v1",
                "http://arxiv.org/pdf/2310.17569v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17567v1",
            "title": "Skill-Mix: a Flexible and Expandable Family of Evaluations for AI models",
            "updated": "2023-10-26T16:55:05Z",
            "published": "2023-10-26T16:55:05Z",
            "summary": "With LLMs shifting their role from statistical modeling of language to\nserving as general-purpose AI agents, how should LLM evaluations change?\nArguably, a key ability of an AI agent is to flexibly combine, as needed, the\nbasic skills it has learned. The capability to combine skills plays an\nimportant role in (human) pedagogy and also in a paper on emergence phenomena\n(Arora & Goyal, 2023).\n  This work introduces Skill-Mix, a new evaluation to measure ability to\ncombine skills. Using a list of $N$ skills the evaluator repeatedly picks\nrandom subsets of $k$ skills and asks the LLM to produce text combining that\nsubset of skills. Since the number of subsets grows like $N^k$, for even modest\n$k$ this evaluation will, with high probability, require the LLM to produce\ntext significantly different from any text in the training set. The paper\ndevelops a methodology for (a) designing and administering such an evaluation,\nand (b) automatic grading (plus spot-checking by humans) of the results using\nGPT-4 as well as the open LLaMA-2 70B model.\n  Administering a version of to popular chatbots gave results that, while\ngenerally in line with prior expectations, contained surprises. Sizeable\ndifferences exist among model capabilities that are not captured by their\nranking on popular LLM leaderboards (\"cramming for the leaderboard\").\nFurthermore, simple probability calculations indicate that GPT-4's reasonable\nperformance on $k=5$ is suggestive of going beyond \"stochastic parrot\" behavior\n(Bender et al., 2021), i.e., it combines skills in ways that it had not seen\nduring training.\n  We sketch how the methodology can lead to a Skill-Mix based eco-system of\nopen evaluations for AI capabilities of future models.",
            "author": [
                "Dingli Yu",
                "Simran Kaur",
                "Arushi Gupta",
                "Jonah Brown-Cohen",
                "Anirudh Goyal",
                "Sanjeev Arora"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17567v1",
                "http://arxiv.org/pdf/2310.17567v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17561v1",
            "title": "Bifurcations and loss jumps in RNN training",
            "updated": "2023-10-26T16:49:44Z",
            "published": "2023-10-26T16:49:44Z",
            "summary": "Recurrent neural networks (RNNs) are popular machine learning tools for\nmodeling and forecasting sequential data and for inferring dynamical systems\n(DS) from observed time series. Concepts from DS theory (DST) have variously\nbeen used to further our understanding of both, how trained RNNs solve complex\ntasks, and the training process itself. Bifurcations are particularly important\nphenomena in DS, including RNNs, that refer to topological (qualitative)\nchanges in a system's dynamical behavior as one or more of its parameters are\nvaried. Knowing the bifurcation structure of an RNN will thus allow to deduce\nmany of its computational and dynamical properties, like its sensitivity to\nparameter variations or its behavior during training. In particular,\nbifurcations may account for sudden loss jumps observed in RNN training that\ncould severely impede the training process. Here we first mathematically prove\nfor a particular class of ReLU-based RNNs that certain bifurcations are indeed\nassociated with loss gradients tending toward infinity or zero. We then\nintroduce a novel heuristic algorithm for detecting all fixed points and\nk-cycles in ReLU-based RNNs and their existence and stability regions, hence\nbifurcation manifolds in parameter space. In contrast to previous numerical\nalgorithms for finding fixed points and common continuation methods, our\nalgorithm provides exact results and returns fixed points and cycles up to high\norders with surprisingly good scaling behavior. We exemplify the algorithm on\nthe analysis of the training process of RNNs, and find that the recently\nintroduced technique of generalized teacher forcing completely avoids certain\ntypes of bifurcations in training. Thus, besides facilitating the DST analysis\nof trained RNNs, our algorithm provides a powerful instrument for analyzing the\ntraining process itself.",
            "author": [
                "Lukas Eisenmann",
                "Zahra Monfared",
                "Niclas Alexander G\u00f6ring",
                "Daniel Durstewitz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17561v1",
                "http://arxiv.org/pdf/2310.17561v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "math.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17559v1",
            "title": "Instability of computer vision models is a necessary result of the task\n  itself",
            "updated": "2023-10-26T16:48:36Z",
            "published": "2023-10-26T16:48:36Z",
            "summary": "Adversarial examples resulting from instability of current computer vision\nmodels are an extremely important topic due to their potential to compromise\nany application. In this paper we demonstrate that instability is inevitable\ndue to a) symmetries (translational invariance) of the data, b) the categorical\nnature of the classification task, and c) the fundamental discrepancy of\nclassifying images as objects themselves. The issue is further exacerbated by\nnon-exhaustive labelling of the training data. Therefore we conclude that\ninstability is a necessary result of how the problem of computer vision is\ncurrently formulated. While the problem cannot be eliminated, through the\nanalysis of the causes, we have arrived at ways how it can be partially\nalleviated. These include i) increasing the resolution of images, ii) providing\ncontextual information for the image, iii) exhaustive labelling of training\ndata, and iv) preventing attackers from frequent access to the computer vision\nsystem.",
            "author": [
                "Oliver Turnbull",
                "George Cevora"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17559v1",
                "http://arxiv.org/pdf/2310.17559v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17558v1",
            "title": "Towards Matching Phones and Speech Representations",
            "updated": "2023-10-26T16:47:52Z",
            "published": "2023-10-26T16:47:52Z",
            "summary": "Learning phone types from phone instances has been a long-standing problem,\nwhile still being open. In this work, we revisit this problem in the context of\nself-supervised learning, and pose it as the problem of matching cluster\ncentroids to phone embeddings. We study two key properties that enable\nmatching, namely, whether cluster centroids of self-supervised representations\nreduce the variability of phone instances and respect the relationship among\nphones. We then use the matching result to produce pseudo-labels and introduce\na new loss function for improving self-supervised representations. Our\nexperiments show that the matching result captures the relationship among\nphones. Training the new loss function jointly with the regular self-supervised\nlosses, such as APC and CPC, significantly improves the downstream phone\nclassification.",
            "author": [
                "Gene-Ping Yang",
                "Hao Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17558v1",
                "http://arxiv.org/pdf/2310.17558v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17556v1",
            "title": "Efficient Numerical Algorithm for Large-Scale Damped Natural Gradient\n  Descent",
            "updated": "2023-10-26T16:46:13Z",
            "published": "2023-10-26T16:46:13Z",
            "summary": "We propose a new algorithm for efficiently solving the damped Fisher matrix\nin large-scale scenarios where the number of parameters significantly exceeds\nthe number of available samples. This problem is fundamental for natural\ngradient descent and stochastic reconfiguration. Our algorithm is based on\nCholesky decomposition and is generally applicable. Benchmark results show that\nthe algorithm is significantly faster than existing methods.",
            "author": [
                "Yixiao Chen",
                "Hao Xie",
                "Han Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17556v1",
                "http://arxiv.org/pdf/2310.17556v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NA",
                "math.NA",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17555v1",
            "title": "Interactive Robot Learning from Verbal Correction",
            "updated": "2023-10-26T16:46:12Z",
            "published": "2023-10-26T16:46:12Z",
            "summary": "The ability to learn and refine behavior after deployment has become ever\nmore important for robots as we design them to operate in unstructured\nenvironments like households. In this work, we design a new learning system\nbased on large language model (LLM), OLAF, that allows everyday users to teach\na robot using verbal corrections when the robot makes mistakes, e.g., by saying\n\"Stop what you're doing. You should move closer to the cup.\" A key feature of\nOLAF is its ability to update the robot's visuomotor neural policy based on the\nverbal feedback to avoid repeating mistakes in the future. This is in contrast\nto existing LLM-based robotic systems, which only follow verbal commands or\ncorrections but not learn from them. We demonstrate the efficacy of our design\nin experiments where a user teaches a robot to perform long-horizon\nmanipulation tasks both in simulation and on physical hardware, achieving on\naverage 20.0% improvement in policy success rate. Videos and more results are\nat https://ut-austin-rpl.github.io/olaf/",
            "author": [
                "Huihan Liu",
                "Alice Chen",
                "Yuke Zhu",
                "Adith Swaminathan",
                "Andrey Kolobov",
                "Ching-An Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17555v1",
                "http://arxiv.org/pdf/2310.17555v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17552v1",
            "title": "Model-Based Runtime Monitoring with Interactive Imitation Learning",
            "updated": "2023-10-26T16:45:44Z",
            "published": "2023-10-26T16:45:44Z",
            "summary": "Robot learning methods have recently made great strides, but generalization\nand robustness challenges still hinder their widespread deployment. Failing to\ndetect and address potential failures renders state-of-the-art learning systems\nnot combat-ready for high-stakes tasks. Recent advances in interactive\nimitation learning have presented a promising framework for human-robot\nteaming, enabling the robots to operate safely and continually improve their\nperformances over long-term deployments. Nonetheless, existing methods\ntypically require constant human supervision and preemptive feedback, limiting\ntheir practicality in realistic domains. This work aims to endow a robot with\nthe ability to monitor and detect errors during task execution. We introduce a\nmodel-based runtime monitoring algorithm that learns from deployment data to\ndetect system anomalies and anticipate failures. Unlike prior work that cannot\nforesee future failures or requires failure experiences for training, our\nmethod learns a latent-space dynamics model and a failure classifier, enabling\nour method to simulate future action outcomes and detect out-of-distribution\nand high-risk states preemptively. We train our method within an interactive\nimitation learning framework, where it continually updates the model from the\nexperiences of the human-robot team collected using trustworthy deployments.\nConsequently, our method reduces the human workload needed over time while\nensuring reliable task execution. Our method outperforms the baselines across\nsystem-level and unit-test metrics, with 23% and 40% higher success rates in\nsimulation and on physical hardware, respectively. More information at\nhttps://ut-austin-rpl.github.io/sirius-runtime-monitor/",
            "author": [
                "Huihan Liu",
                "Shivin Dass",
                "Roberto Mart\u00edn-Mart\u00edn",
                "Yuke Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17552v1",
                "http://arxiv.org/pdf/2310.17552v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17550v2",
            "title": "Human-Guided Complexity-Controlled Abstractions",
            "updated": "2023-10-27T14:31:25Z",
            "published": "2023-10-26T16:45:34Z",
            "summary": "Neural networks often learn task-specific latent representations that fail to\ngeneralize to novel settings or tasks. Conversely, humans learn discrete\nrepresentations (i.e., concepts or words) at a variety of abstraction levels\n(e.g., \"bird\" vs. \"sparrow\") and deploy the appropriate abstraction based on\ntask. Inspired by this, we train neural models to generate a spectrum of\ndiscrete representations, and control the complexity of the representations\n(roughly, how many bits are allocated for encoding inputs) by tuning the\nentropy of the distribution over representations. In finetuning experiments,\nusing only a small number of labeled examples for a new task, we show that (1)\ntuning the representation to a task-appropriate complexity level supports the\nhighest finetuning performance, and (2) in a human-participant study, users\nwere able to identify the appropriate complexity level for a downstream task\nusing visualizations of discrete representations. Our results indicate a\npromising direction for rapid model finetuning by leveraging human insight.",
            "author": [
                "Andi Peng",
                "Mycal Tucker",
                "Eoin Kenny",
                "Noga Zaslavsky",
                "Pulkit Agrawal",
                "Julie Shah"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17550v2",
                "http://arxiv.org/pdf/2310.17550v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17545v1",
            "title": "Using Buckingham's $\u03c0$ Theorem for Multi-System Learning Transfer: a\n  Case-study with 3 Vehicles Sharing a Database",
            "updated": "2023-10-26T16:42:13Z",
            "published": "2023-10-26T16:42:13Z",
            "summary": "Learning schemes for planning and control are limited by the difficulty of\ncollecting large amounts of experimental data or having to rely on\nhigh-fidelity simulations. This paper explores the potential of a proposed\nlearning scheme that leverages dimensionless numbers based on Buckingham's\n$\\pi$ theorem to improve data efficiency and facilitate knowledge sharing\nbetween similar systems. A case study using car-like robots compares\ntraditional and dimensionless learning models on simulated and experimental\ndata to validate the benefits of the new dimensionless learning approach.\nPreliminary results show that this new dimensionless approach could accelerate\nthe learning rate and improve the accuracy of the model and should be\ninvestigated further.",
            "author": [
                "William Therrien",
                "Olivier Lecompte",
                "Alexandre Girard"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17545v1",
                "http://arxiv.org/pdf/2310.17545v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17544v1",
            "title": "Hierarchical Ensemble-Based Feature Selection for Time Series\n  Forecasting",
            "updated": "2023-10-26T16:40:09Z",
            "published": "2023-10-26T16:40:09Z",
            "summary": "We study a novel ensemble approach for feature selection based on\nhierarchical stacking in cases of non-stationarity and limited number of\nsamples with large number of features. Our approach exploits the co-dependency\nbetween features using a hierarchical structure. Initially, a machine learning\nmodel is trained using a subset of features, and then the model's output is\nupdated using another algorithm with the remaining features to minimize the\ntarget loss. This hierarchical structure allows for flexible depth and feature\nselection. By exploiting feature co-dependency hierarchically, our proposed\napproach overcomes the limitations of traditional feature selection methods and\nfeature importance scores. The effectiveness of the approach is demonstrated on\nsynthetic and real-life datasets, indicating improved performance with\nscalability and stability compared to the traditional methods and\nstate-of-the-art approaches.",
            "author": [
                "Aysin Tumay",
                "Mustafa E. Aydin",
                "Suleyman S. Kozat"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17544v1",
                "http://arxiv.org/pdf/2310.17544v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17540v1",
            "title": "EqDrive: Efficient Equivariant Motion Forecasting with Multi-Modality\n  for Autonomous Driving",
            "updated": "2023-10-26T16:32:34Z",
            "published": "2023-10-26T16:32:34Z",
            "summary": "Forecasting vehicular motions in autonomous driving requires a deep\nunderstanding of agent interactions and the preservation of motion equivariance\nunder Euclidean geometric transformations. Traditional models often lack the\nsophistication needed to handle the intricate dynamics inherent to autonomous\nvehicles and the interaction relationships among agents in the scene. As a\nresult, these models have a lower model capacity, which then leads to higher\nprediction errors and lower training efficiency. In our research, we employ\nEqMotion, a leading equivariant particle, and human prediction model that also\naccounts for invariant agent interactions, for the task of multi-agent vehicle\nmotion forecasting. In addition, we use a multi-modal prediction mechanism to\naccount for multiple possible future paths in a probabilistic manner. By\nleveraging EqMotion, our model achieves state-of-the-art (SOTA) performance\nwith fewer parameters (1.2 million) and a significantly reduced training time\n(less than 2 hours).",
            "author": [
                "Yuping Wang",
                "Jier Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17540v1",
                "http://arxiv.org/pdf/2310.17540v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17538v1",
            "title": "Little Exploration is All You Need",
            "updated": "2023-10-26T16:28:29Z",
            "published": "2023-10-26T16:28:29Z",
            "summary": "The prevailing principle of \"Optimism in the Face of Uncertainty\" advocates\nfor the incorporation of an exploration bonus, generally assumed to be\nproportional to the inverse square root of the visit count ($1/\\sqrt{n}$),\nwhere $n$ is the number of visits to a particular state-action pair. This\napproach, however, exclusively focuses on \"uncertainty,\" neglecting the\ninherent \"difficulty\" of different options. To address this gap, we introduce a\nnovel modification of standard UCB algorithm in the multi-armed bandit problem,\nproposing an adjusted bonus term of $1/n^\\tau$, where $\\tau > 1/2$, that\naccounts for task difficulty. Our proposed algorithm, denoted as UCB$^\\tau$, is\nsubstantiated through comprehensive regret and risk analyses, confirming its\ntheoretical robustness. Comparative evaluations with standard UCB and Thompson\nSampling algorithms on synthetic datasets demonstrate that UCB$^\\tau$ not only\noutperforms in efficacy but also exhibits lower risk across various\nenvironmental conditions and hyperparameter settings.",
            "author": [
                "Henry H. H. Chen",
                "Jiaming Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17538v1",
                "http://arxiv.org/pdf/2310.17538v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17537v1",
            "title": "Neuro-Inspired Fragmentation and Recall to Overcome Catastrophic\n  Forgetting in Curiosity",
            "updated": "2023-10-26T16:28:17Z",
            "published": "2023-10-26T16:28:17Z",
            "summary": "Deep reinforcement learning methods exhibit impressive performance on a range\nof tasks but still struggle on hard exploration tasks in large environments\nwith sparse rewards. To address this, intrinsic rewards can be generated using\nforward model prediction errors that decrease as the environment becomes known,\nand incentivize an agent to explore novel states. While prediction-based\nintrinsic rewards can help agents solve hard exploration tasks, they can suffer\nfrom catastrophic forgetting and actually increase at visited states. We first\nexamine the conditions and causes of catastrophic forgetting in grid world\nenvironments. We then propose a new method FARCuriosity, inspired by how humans\nand animals learn. The method depends on fragmentation and recall: an agent\nfragments an environment based on surprisal, and uses different local curiosity\nmodules (prediction-based intrinsic reward functions) for each fragment so that\nmodules are not trained on the entire environment. At each fragmentation event,\nthe agent stores the current module in long-term memory (LTM) and either\ninitializes a new module or recalls a previously stored module based on its\nmatch with the current state. With fragmentation and recall, FARCuriosity\nachieves less forgetting and better overall performance in games with varied\nand heterogeneous environments in the Atari benchmark suite of tasks. Thus,\nthis work highlights the problem of catastrophic forgetting in prediction-based\ncuriosity methods and proposes a solution.",
            "author": [
                "Jaedong Hwang",
                "Zhang-Wei Hong",
                "Eric Chen",
                "Akhilan Boopathy",
                "Pulkit Agrawal",
                "Ila Fiete"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17537v1",
                "http://arxiv.org/pdf/2310.17537v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17534v1",
            "title": "SoK: Pitfalls in Evaluating Black-Box Attacks",
            "updated": "2023-10-26T16:23:40Z",
            "published": "2023-10-26T16:23:40Z",
            "summary": "Numerous works study black-box attacks on image classifiers. However, these\nworks make different assumptions on the adversary's knowledge and current\nliterature lacks a cohesive organization centered around the threat model. To\nsystematize knowledge in this area, we propose a taxonomy over the threat space\nspanning the axes of feedback granularity, the access of interactive queries,\nand the quality and quantity of the auxiliary data available to the attacker.\nOur new taxonomy provides three key insights. 1) Despite extensive literature,\nnumerous under-explored threat spaces exist, which cannot be trivially solved\nby adapting techniques from well-explored settings. We demonstrate this by\nestablishing a new state-of-the-art in the less-studied setting of access to\ntop-k confidence scores by adapting techniques from well-explored settings of\naccessing the complete confidence vector, but show how it still falls short of\nthe more restrictive setting that only obtains the prediction label,\nhighlighting the need for more research. 2) Identification the threat model of\ndifferent attacks uncovers stronger baselines that challenge prior\nstate-of-the-art claims. We demonstrate this by enhancing an initially weaker\nbaseline (under interactive query access) via surrogate models, effectively\noverturning claims in the respective paper. 3) Our taxonomy reveals\ninteractions between attacker knowledge that connect well to related areas,\nsuch as model inversion and extraction attacks. We discuss how advances in\nother areas can enable potentially stronger black-box attacks. Finally, we\nemphasize the need for a more realistic assessment of attack success by\nfactoring in local attack runtime. This approach reveals the potential for\ncertain attacks to achieve notably higher success rates and the need to\nevaluate attacks in diverse and harder settings, highlighting the need for\nbetter selection criteria.",
            "author": [
                "Fnu Suya",
                "Anshuman Suri",
                "Tingwei Zhang",
                "Jingtao Hong",
                "Yuan Tian",
                "David Evans"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17534v1",
                "http://arxiv.org/pdf/2310.17534v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17531v1",
            "title": "Learning Regularized Graphon Mean-Field Games with Unknown Graphons",
            "updated": "2023-10-26T16:19:24Z",
            "published": "2023-10-26T16:19:24Z",
            "summary": "We design and analyze reinforcement learning algorithms for Graphon\nMean-Field Games (GMFGs). In contrast to previous works that require the\nprecise values of the graphons, we aim to learn the Nash Equilibrium (NE) of\nthe regularized GMFGs when the graphons are unknown. Our contributions are\nthreefold. First, we propose the Proximal Policy Optimization for GMFG\n(GMFG-PPO) algorithm and show that it converges at a rate of $O(T^{-1/3})$\nafter $T$ iterations with an estimation oracle, improving on a previous work by\nXie et al. (ICML, 2021). Second, using kernel embedding of distributions, we\ndesign efficient algorithms to estimate the transition kernels, reward\nfunctions, and graphons from sampled agents. Convergence rates are then derived\nwhen the positions of the agents are either known or unknown. Results for the\ncombination of the optimization algorithm GMFG-PPO and the estimation algorithm\nare then provided. These algorithms are the first specifically designed for\nlearning graphons from sampled agents. Finally, the efficacy of the proposed\nalgorithms are corroborated through simulations. These simulations demonstrate\nthat learning the unknown graphons reduces the exploitability effectively.",
            "author": [
                "Fengzhuo Zhang",
                "Vincent Y. F. Tan",
                "Zhaoran Wang",
                "Zhuoran Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17531v1",
                "http://arxiv.org/pdf/2310.17531v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17530v1",
            "title": "Evaluating Bias and Fairness in Gender-Neutral Pretrained\n  Vision-and-Language Models",
            "updated": "2023-10-26T16:19:19Z",
            "published": "2023-10-26T16:19:19Z",
            "summary": "Pretrained machine learning models are known to perpetuate and even amplify\nexisting biases in data, which can result in unfair outcomes that ultimately\nimpact user experience. Therefore, it is crucial to understand the mechanisms\nbehind those prejudicial biases to ensure that model performance does not\nresult in discriminatory behaviour toward certain groups or populations. In\nthis work, we define gender bias as our case study. We quantify bias\namplification in pretraining and after fine-tuning on three families of\nvision-and-language models. We investigate the connection, if any, between the\ntwo learning stages, and evaluate how bias amplification reflects on model\nperformance. Overall, we find that bias amplification in pretraining and after\nfine-tuning are independent. We then examine the effect of continued\npretraining on gender-neutral data, finding that this reduces group\ndisparities, i.e., promotes fairness, on VQAv2 and retrieval tasks without\nsignificantly compromising task performance.",
            "author": [
                "Laura Cabello",
                "Emanuele Bugliarello",
                "Stephanie Brandl",
                "Desmond Elliott"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17530v1",
                "http://arxiv.org/pdf/2310.17530v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17526v2",
            "title": "Can large language models replace humans in the systematic review\n  process? Evaluating GPT-4's efficacy in screening and extracting data from\n  peer-reviewed and grey literature in multiple languages",
            "updated": "2023-10-27T12:14:27Z",
            "published": "2023-10-26T16:18:30Z",
            "summary": "Systematic reviews are vital for guiding practice, research, and policy, yet\nthey are often slow and labour-intensive. Large language models (LLMs) could\noffer a way to speed up and automate systematic reviews, but their performance\nin such tasks has not been comprehensively evaluated against humans, and no\nstudy has tested GPT-4, the biggest LLM so far. This pre-registered study\nevaluates GPT-4's capability in title/abstract screening, full-text review, and\ndata extraction across various literature types and languages using a\n'human-out-of-the-loop' approach. Although GPT-4 had accuracy on par with human\nperformance in most tasks, results were skewed by chance agreement and dataset\nimbalance. After adjusting for these, there was a moderate level of performance\nfor data extraction, and - barring studies that used highly reliable prompts -\nscreening performance levelled at none to moderate for different stages and\nlanguages. When screening full-text literature using highly reliable prompts,\nGPT-4's performance was 'almost perfect.' Penalising GPT-4 for missing key\nstudies using highly reliable prompts improved its performance even more. Our\nfindings indicate that, currently, substantial caution should be used if LLMs\nare being used to conduct systematic reviews, but suggest that, for certain\nsystematic review tasks delivered under reliable prompts, LLMs can rival human\nperformance.",
            "author": [
                "Qusai Khraisha",
                "Sophie Put",
                "Johanna Kappenberg",
                "Azza Warraitch",
                "Kristin Hadfield"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17526v2",
                "http://arxiv.org/pdf/2310.17526v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17525v1",
            "title": "Measuring Wigner functions of quantum states of light in the\n  undergraduate laboratory",
            "updated": "2023-10-26T16:17:54Z",
            "published": "2023-10-26T16:17:54Z",
            "summary": "In this work, we present an educational activity aimed at measuring the\nWigner distribution functions of quantum states of light in the undergraduate\nlaboratory. This project was conceived by students from various courses within\nthe physics undergraduate curriculum, and its outcomes were used in an\nintroductory Quantum Optics course at the Universidad de los Andes in Bogot\\'a,\nColombia. The activity entails a two-hour laboratory practice in which students\nengage with a pre-aligned experimental setup. They subsequently employ an\nopen-access, custom-made computational graphical user interface to reconstruct\nthe Wigner distribution function for various quantum states of light. Given\nthat the testing phase coincided with the COVID-19 pandemic, we incorporated\nthe capacity to analyze simulated data into the computational user interface.\nThe activity is now part of the course syllabus and its virtual component has\nproven to be highly valuable for the implementation of distance learning in\nquantum optics.",
            "author": [
                "Juan-Rafael \u00c1lvarez",
                "Andr\u00e9s Mart\u00ednez Silva",
                "Alejandra Valencia"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17525v1",
                "http://arxiv.org/pdf/2310.17525v1"
            ],
            "primary_category": "physics.ed-ph",
            "category": [
                "physics.ed-ph",
                "physics.optics",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17523v2",
            "title": "Adaptive Resource Management for Edge Network Slicing using Incremental\n  Multi-Agent Deep Reinforcement Learning",
            "updated": "2023-10-27T09:13:06Z",
            "published": "2023-10-26T16:16:08Z",
            "summary": "Multi-access edge computing provides local resources in mobile networks as\nthe essential means for meeting the demands of emerging ultra-reliable\nlow-latency communications. At the edge, dynamic computing requests require\nadvanced resource management for adaptive network slicing, including resource\nallocations, function scaling and load balancing to utilize only the necessary\nresources in resource-constraint networks. Recent solutions are designed for a\nstatic number of slices. Therefore, the painful process of optimization is\nrequired again with any update on the number of slices. In addition, these\nsolutions intend to maximize instant rewards, neglecting long-term resource\nscheduling. Unlike these efforts, we propose an algorithmic approach based on\nmulti-agent deep deterministic policy gradient (MADDPG) for optimizing resource\nmanagement for edge network slicing. Our objective is two-fold: (i) maximizing\nlong-term network slicing benefits in terms of delay and energy consumption,\nand (ii) adapting to slice number changes. Through simulations, we demonstrate\nthat MADDPG outperforms benchmark solutions including a static slicing-based\none from the literature, achieving stable and high long-term performance.\nAdditionally, we leverage incremental learning to facilitate a dynamic number\nof edge slices, with enhanced performance compared to pre-trained base models.\nRemarkably, this approach yields superior reward performance while saving\napproximately 90% of training time costs.",
            "author": [
                "Haiyuan Li",
                "Yuelin Liu",
                "Xueqing Zhou",
                "Xenofon Vasilakos",
                "Reza Nejabati",
                "Shuangyi Yan",
                "Dimitra Simeonidou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17523v2",
                "http://arxiv.org/pdf/2310.17523v2"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17519v2",
            "title": "FLARE: Fast Learning of Animatable and Relightable Mesh Avatars",
            "updated": "2023-10-27T09:11:32Z",
            "published": "2023-10-26T16:13:00Z",
            "summary": "Our goal is to efficiently learn personalized animatable 3D head avatars from\nvideos that are geometrically accurate, realistic, relightable, and compatible\nwith current rendering systems. While 3D meshes enable efficient processing and\nare highly portable, they lack realism in terms of shape and appearance. Neural\nrepresentations, on the other hand, are realistic but lack compatibility and\nare slow to train and render. Our key insight is that it is possible to\nefficiently learn high-fidelity 3D mesh representations via differentiable\nrendering by exploiting highly-optimized methods from traditional computer\ngraphics and approximating some of the components with neural networks. To that\nend, we introduce FLARE, a technique that enables the creation of animatable\nand relightable mesh avatars from a single monocular video. First, we learn a\ncanonical geometry using a mesh representation, enabling efficient\ndifferentiable rasterization and straightforward animation via learned\nblendshapes and linear blend skinning weights. Second, we follow\nphysically-based rendering and factor observed colors into intrinsic albedo,\nroughness, and a neural representation of the illumination, allowing the\nlearned avatars to be relit in novel scenes. Since our input videos are\ncaptured on a single device with a narrow field of view, modeling the\nsurrounding environment light is non-trivial. Based on the split-sum\napproximation for modeling specular reflections, we address this by\napproximating the pre-filtered environment map with a multi-layer perceptron\n(MLP) modulated by the surface roughness, eliminating the need to explicitly\nmodel the light. We demonstrate that our mesh-based avatar formulation,\ncombined with learned deformation, material, and lighting MLPs, produces\navatars with high-quality geometry and appearance, while also being efficient\nto train and render compared to existing approaches.",
            "author": [
                "Shrisha Bharadwaj",
                "Yufeng Zheng",
                "Otmar Hilliges",
                "Michael J. Black",
                "Victoria Fernandez-Abrevaya"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3618401",
                "http://arxiv.org/abs/2310.17519v2",
                "http://arxiv.org/pdf/2310.17519v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17516v1",
            "title": "Crashing with disorder: Reaching the precision limit with tensor-based\n  wavefront shaping",
            "updated": "2023-10-26T16:12:08Z",
            "published": "2023-10-26T16:12:08Z",
            "summary": "Perturbations in complex media, due to their own dynamical evolution or to\nexternal effects, are often seen as detrimental. Therefore, a common strategy,\nespecially for telecommunication and imaging applications, is to limit the\nsensitivity to those perturbations in order to avoid them. Here, we instead\nconsider crashing straight into them in order to maximize the interaction\nbetween light and the perturbations and thus produce the largest change in\noutput intensity. Our work hinges on the innovative use of tensor-based\ntechniques, presently at the forefront of machine learning explorations, to\nstudy intensity-based measurements where its quadratic relationship to the\nfield prevents the use of standard matrix methods. With this tensor-based\nframework, we are able to identify the optimal crashing channel which maximizes\nthe change in its output intensity distribution and the Fisher information\nencoded in it about a given perturbation. We further demonstrate experimentally\nits superiority for robust and precise sensing applications. Additionally, we\nderive the appropriate strategy to reach the precision limit for\nintensity-based measurements leading to an increase in Fisher information by\nmore than four orders of magnitude with respect to the mean for random\nwavefronts when measured with the pixels of a camera.",
            "author": [
                "Rodrigo Guti\u00e9rrez-Cuevas",
                "Dorian Bouchet",
                "Julien de Rosny",
                "S\u00e9bastien M. Popoff"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17516v1",
                "http://arxiv.org/pdf/2310.17516v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17513v2",
            "title": "The Expressive Power of Low-Rank Adaptation",
            "updated": "2023-10-27T02:36:44Z",
            "published": "2023-10-26T16:08:33Z",
            "summary": "Low-Rank Adaptation (LoRA), a parameter-efficient fine-tuning method that\nleverages low-rank adaptation of weight matrices, has emerged as a prevalent\ntechnique for fine-tuning pre-trained models such as large language models and\ndiffusion models. Despite its huge success in practice, the theoretical\nunderpinnings of LoRA have largely remained unexplored. This paper takes the\nfirst step to bridge this gap by theoretically analyzing the expressive power\nof LoRA. We prove that, for fully connected neural networks, LoRA can adapt any\nmodel $f$ to accurately represent any smaller target model $\\overline{f}$ if\nLoRA-rank $\\geq(\\text{width of }f) \\times \\frac{\\text{depth of\n}\\overline{f}}{\\text{depth of }f}$. We also quantify the approximation error\nwhen LoRA-rank is lower than the threshold. For Transformer networks, we show\nany model can be adapted to a target model of the same size with\nrank-$(\\frac{\\text{embedding size}}{2})$ LoRA adapters.",
            "author": [
                "Yuchen Zeng",
                "Kangwook Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17513v2",
                "http://arxiv.org/pdf/2310.17513v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17512v1",
            "title": "CompeteAI: Understanding the Competition Behaviors in Large Language\n  Model-based Agents",
            "updated": "2023-10-26T16:06:20Z",
            "published": "2023-10-26T16:06:20Z",
            "summary": "Large language models (LLMs) have been widely used as agents to complete\ndifferent tasks, such as personal assistance or event planning. While most work\nhas focused on cooperation and collaboration between agents, little work\nexplores competition, another important mechanism that fosters the development\nof society and economy. In this paper, we seek to examine the competition\nbehaviors in LLM-based agents. We first propose a general framework to study\nthe competition between agents. Then, we implement a practical competitive\nenvironment using GPT-4 to simulate a virtual town with two types of agents,\nincluding restaurant agents and customer agents. Specifically, restaurant\nagents compete with each other to attract more customers, where the competition\nfosters them to transform, such as cultivating new operating strategies. The\nresults of our experiments reveal several interesting findings ranging from\nsocial learning to Matthew Effect, which aligns well with existing sociological\nand economic theories. We believe that competition between agents deserves\nfurther investigation to help us understand society better. The code will be\nreleased soon.",
            "author": [
                "Qinlin Zhao",
                "Jindong Wang",
                "Yixuan Zhang",
                "Yiqiao Jin",
                "Kaijie Zhu",
                "Hao Chen",
                "Xing Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17512v1",
                "http://arxiv.org/pdf/2310.17512v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.HC",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17506v1",
            "title": "Predicting Patient No-Shows in Community Health Clinics: A Case Study in\n  Designing a Data Analytic Product",
            "updated": "2023-10-26T15:56:43Z",
            "published": "2023-10-26T15:56:43Z",
            "summary": "The data science revolution has highlighted the varying roles that data\nanalytic products can play in a different industries and applications. There\nhas been particular interest in using analytic products coupled with\nalgorithmic prediction models to aid in human decision-making. However,\ndetailed descriptions of the decision-making process that leads to the design\nand development of analytic products are lacking in the statistical literature,\nmaking it difficult to accumulate a body of knowledge where students interested\nin the field of data science may look to learn about this process. In this\npaper, we present a case study describing the development of an analytic\nproduct for predicting whether patients will show up for scheduled appointments\nat a community health clinic. We consider the stakeholders involved and their\ninterests, along with the real-world analytical and technical trade-offs\ninvolved in developing and deploying the product. Our goal here is to highlight\nthe decisions made and evaluate them in the context of possible alternatives.\nWe find that although this case study has some unique characteristics, there\nare lessons to be learned that could translate to other settings and\napplications.",
            "author": [
                "Roger D. Peng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17506v1",
                "http://arxiv.org/pdf/2310.17506v1"
            ],
            "primary_category": "stat.AP",
            "category": [
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17502v1",
            "title": "Controllable Generation of Artificial Speaker Embeddings through\n  Discovery of Principal Directions",
            "updated": "2023-10-26T15:54:12Z",
            "published": "2023-10-26T15:54:12Z",
            "summary": "Customizing voice and speaking style in a speech synthesis system with\nintuitive and fine-grained controls is challenging, given that little data with\nappropriate labels is available. Furthermore, editing an existing human's voice\nalso comes with ethical concerns. In this paper, we propose a method to\ngenerate artificial speaker embeddings that cannot be linked to a real human\nwhile offering intuitive and fine-grained control over the voice and speaking\nstyle of the embeddings, without requiring any labels for speaker or style. The\nartificial and controllable embeddings can be fed to a speech synthesis system,\nconditioned on embeddings of real humans during training, without sacrificing\nprivacy during inference.",
            "author": [
                "Florian Lux",
                "Pascal Tilli",
                "Sarina Meyer",
                "Ngoc Thang Vu"
            ],
            "link": [
                "http://dx.doi.org/10.21437/Interspeech.2023-858",
                "http://arxiv.org/abs/2310.17502v1",
                "http://arxiv.org/pdf/2310.17502v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17499v1",
            "title": "The IMS Toucan System for the Blizzard Challenge 2023",
            "updated": "2023-10-26T15:53:29Z",
            "published": "2023-10-26T15:53:29Z",
            "summary": "For our contribution to the Blizzard Challenge 2023, we improved on the\nsystem we submitted to the Blizzard Challenge 2021. Our approach entails a\nrule-based text-to-phoneme processing system that includes rule-based\ndisambiguation of homographs in the French language. It then transforms the\nphonemes to spectrograms as intermediate representations using a fast and\nefficient non-autoregressive synthesis architecture based on Conformer and\nGlow. A GAN based neural vocoder that combines recent state-of-the-art\napproaches converts the spectrogram to the final wave. We carefully designed\nthe data processing, training, and inference procedures for the challenge data.\nOur system identifier is G. Open source code and demo are available.",
            "author": [
                "Florian Lux",
                "Julia Koch",
                "Sarina Meyer",
                "Thomas Bott",
                "Nadja Schauffler",
                "Pavel Denisov",
                "Antje Schweitzer",
                "Ngoc Thang Vu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17499v1",
                "http://arxiv.org/pdf/2310.17499v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17498v1",
            "title": "CBD: A Certified Backdoor Detector Based on Local Dominant Probability",
            "updated": "2023-10-26T15:53:18Z",
            "published": "2023-10-26T15:53:18Z",
            "summary": "Backdoor attack is a common threat to deep neural networks. During testing,\nsamples embedded with a backdoor trigger will be misclassified as an\nadversarial target by a backdoored model, while samples without the backdoor\ntrigger will be correctly classified. In this paper, we present the first\ncertified backdoor detector (CBD), which is based on a novel, adjustable\nconformal prediction scheme based on our proposed statistic local dominant\nprobability. For any classifier under inspection, CBD provides 1) a detection\ninference, 2) the condition under which the attacks are guaranteed to be\ndetectable for the same classification domain, and 3) a probabilistic upper\nbound for the false positive rate. Our theoretical results show that attacks\nwith triggers that are more resilient to test-time noise and have smaller\nperturbation magnitudes are more likely to be detected with guarantees.\nMoreover, we conduct extensive experiments on four benchmark datasets\nconsidering various backdoor types, such as BadNet, CB, and Blend. CBD achieves\ncomparable or even higher detection accuracy than state-of-the-art detectors,\nand it in addition provides detection certification. Notably, for backdoor\nattacks with random perturbation triggers bounded by $\\ell_2\\leq0.75$ which\nachieves more than 90\\% attack success rate, CBD achieves 100\\% (98\\%), 100\\%\n(84\\%), 98\\% (98\\%), and 72\\% (40\\%) empirical (certified) detection true\npositive rates on the four benchmark datasets GTSRB, SVHN, CIFAR-10, and\nTinyImageNet, respectively, with low false positive rates.",
            "author": [
                "Zhen Xiang",
                "Zidi Xiong",
                "Bo Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17498v1",
                "http://arxiv.org/pdf/2310.17498v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17496v2",
            "title": "Tackling Interference Induced by Data Training Loops in A/B Tests: A\n  Weighted Training Approach",
            "updated": "2023-10-29T01:38:36Z",
            "published": "2023-10-26T15:52:34Z",
            "summary": "In modern recommendation systems, the standard pipeline involves training\nmachine learning models on historical data to predict user behaviors and\nimprove recommendations continuously. However, these data training loops can\nintroduce interference in A/B tests, where data generated by control and\ntreatment algorithms, potentially with different distributions, are combined.\nTo address these challenges, we introduce a novel approach called weighted\ntraining. This approach entails training a model to predict the probability of\neach data point appearing in either the treatment or control data and\nsubsequently applying weighted losses during model training. We demonstrate\nthat this approach achieves the least variance among all estimators without\ncausing shifts in the training distributions. Through simulation studies, we\ndemonstrate the lower bias and variance of our approach compared to other\nmethods.",
            "author": [
                "Nian Si"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17496v2",
                "http://arxiv.org/pdf/2310.17496v2"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "cs.LG",
                "econ.EM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17492v1",
            "title": "Orchestration of Emulator Assisted Mobile Edge Tuning for AI Foundation\n  Models: A Multi-Agent Deep Reinforcement Learning Approach",
            "updated": "2023-10-26T15:47:51Z",
            "published": "2023-10-26T15:47:51Z",
            "summary": "The efficient deployment and fine-tuning of foundation models are pivotal in\ncontemporary artificial intelligence. In this study, we present a\ngroundbreaking paradigm integrating Mobile Edge Computing (MEC) with foundation\nmodels, specifically designed to enhance local task performance on user\nequipment (UE). Central to our approach is the innovative Emulator-Adapter\narchitecture, segmenting the foundation model into two cohesive modules. This\ndesign not only conserves computational resources but also ensures adaptability\nand fine-tuning efficiency for downstream tasks. Additionally, we introduce an\nadvanced resource allocation mechanism that is fine-tuned to the needs of the\nEmulator-Adapter structure in decentralized settings. To address the challenges\npresented by this system, we employ a hybrid multi-agent Deep Reinforcement\nLearning (DRL) strategy, adept at handling mixed discrete-continuous action\nspaces, ensuring dynamic and optimal resource allocations. Our comprehensive\nsimulations and validations underscore the practical viability of our approach,\ndemonstrating its robustness, efficiency, and scalability. Collectively, this\nwork offers a fresh perspective on deploying foundation models and balancing\ncomputational efficiency with task proficiency.",
            "author": [
                "Wenhan Yu",
                "Terence Jie Chua",
                "Jun Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17492v1",
                "http://arxiv.org/pdf/2310.17492v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.DC",
                "cs.LG",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17491v1",
            "title": "FedPEAT: Convergence of Federated Learning, Parameter-Efficient Fine\n  Tuning, and Emulator Assisted Tuning for Artificial Intelligence Foundation\n  Models with Mobile Edge Computing",
            "updated": "2023-10-26T15:47:44Z",
            "published": "2023-10-26T15:47:44Z",
            "summary": "The emergence of foundation models, including language and vision models, has\nreshaped AI's landscape, offering capabilities across various applications.\nDeploying and fine-tuning these large models, like GPT-3 and BERT, presents\nchallenges, especially in the current foundation model era. We introduce\nEmulator-Assisted Tuning (EAT) combined with Parameter-Efficient Fine-Tuning\n(PEFT) to form Parameter-Efficient Emulator-Assisted Tuning (PEAT). Further, we\nexpand this into federated learning as Federated PEAT (FedPEAT). FedPEAT uses\nadapters, emulators, and PEFT for federated model tuning, enhancing model\nprivacy and memory efficiency. Adapters adjust pre-trained models, while\nemulators give a compact representation of original models, addressing both\nprivacy and efficiency. Adaptable to various neural networks, our approach also\nuses deep reinforcement learning for hyper-parameter optimization. We tested\nFedPEAT in a unique scenario with a server participating in collaborative\nfederated tuning, showcasing its potential in tackling foundation model\nchallenges.",
            "author": [
                "Terence Jie Chua",
                "Wenhan Yu",
                "Jun Zhao",
                "Kwok-Yan Lam"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17491v1",
                "http://arxiv.org/pdf/2310.17491v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17489v1",
            "title": "Bias in Evaluation Processes: An Optimization-Based Model",
            "updated": "2023-10-26T15:45:01Z",
            "published": "2023-10-26T15:45:01Z",
            "summary": "Biases with respect to socially-salient attributes of individuals have been\nwell documented in evaluation processes used in settings such as admissions and\nhiring. We view such an evaluation process as a transformation of a\ndistribution of the true utility of an individual for a task to an observed\ndistribution and model it as a solution to a loss minimization problem subject\nto an information constraint. Our model has two parameters that have been\nidentified as factors leading to biases: the resource-information trade-off\nparameter in the information constraint and the risk-averseness parameter in\nthe loss function. We characterize the distributions that arise from our model\nand study the effect of the parameters on the observed distribution. The\noutputs of our model enrich the class of distributions that can be used to\ncapture variation across groups in the observed evaluations. We empirically\nvalidate our model by fitting real-world datasets and use it to study the\neffect of interventions in a downstream selection task. These results\ncontribute to an understanding of the emergence of bias in evaluation processes\nand provide tools to guide the deployment of interventions to mitigate biases.",
            "author": [
                "L. Elisa Celis",
                "Amit Kumar",
                "Anay Mehrotra",
                "Nisheeth K. Vishnoi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17489v1",
                "http://arxiv.org/pdf/2310.17489v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17485v1",
            "title": "Fair collaborative vehicle routing: A deep multi-agent reinforcement\n  learning approach",
            "updated": "2023-10-26T15:42:29Z",
            "published": "2023-10-26T15:42:29Z",
            "summary": "Collaborative vehicle routing occurs when carriers collaborate through\nsharing their transportation requests and performing transportation requests on\nbehalf of each other. This achieves economies of scale, thus reducing cost,\ngreenhouse gas emissions and road congestion. But which carrier should partner\nwith whom, and how much should each carrier be compensated? Traditional game\ntheoretic solution concepts are expensive to calculate as the characteristic\nfunction scales exponentially with the number of agents. This would require\nsolving the vehicle routing problem (NP-hard) an exponential number of times.\nWe therefore propose to model this problem as a coalitional bargaining game\nsolved using deep multi-agent reinforcement learning, where - crucially -\nagents are not given access to the characteristic function. Instead, we\nimplicitly reason about the characteristic function; thus, when deployed in\nproduction, we only need to evaluate the expensive post-collaboration vehicle\nrouting problem once. Our contribution is that we are the first to consider\nboth the route allocation problem and gain sharing problem simultaneously -\nwithout access to the expensive characteristic function. Through decentralised\nmachine learning, our agents bargain with each other and agree to outcomes that\ncorrelate well with the Shapley value - a fair profit allocation mechanism.\nImportantly, we are able to achieve a reduction in run-time of 88%.",
            "author": [
                "Stephen Mak",
                "Liming Xu",
                "Tim Pearce",
                "Michael Ostroumov",
                "Alexandra Brintrup"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.trc.2023.104376",
                "http://arxiv.org/abs/2310.17485v1",
                "http://arxiv.org/pdf/2310.17485v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17477v1",
            "title": "Secure short-term load forecasting for smart grids with\n  transformer-based federated learning",
            "updated": "2023-10-26T15:27:55Z",
            "published": "2023-10-26T15:27:55Z",
            "summary": "Electricity load forecasting is an essential task within smart grids to\nassist demand and supply balance. While advanced deep learning models require\nlarge amounts of high-resolution data for accurate short-term load predictions,\nfine-grained load profiles can expose users' electricity consumption behaviors,\nwhich raises privacy and security concerns. One solution to improve data\nprivacy is federated learning, where models are trained locally on private\ndata, and only the trained model parameters are merged and updated on a global\nserver. Therefore, this paper presents a novel transformer-based deep learning\napproach with federated learning for short-term electricity load prediction. To\nevaluate our results, we benchmark our federated learning architecture against\ncentral and local learning and compare the performance of our model to long\nshort-term memory models and convolutional neural networks. Our simulations are\nbased on a dataset from a German university campus and show that\ntransformer-based forecasting is a promising alternative to state-of-the-art\nmodels within federated learning.",
            "author": [
                "Jonas Sievers",
                "Thomas Blank"
            ],
            "link": [
                "http://dx.doi.org/10.1109/ICCEP57914.2023.10247363",
                "http://arxiv.org/abs/2310.17477v1",
                "http://arxiv.org/pdf/2310.17477v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17471v1",
            "title": "Foundation Model Based Native AI Framework in 6G with Cloud-Edge-End\n  Collaboration",
            "updated": "2023-10-26T15:19:40Z",
            "published": "2023-10-26T15:19:40Z",
            "summary": "Future wireless communication networks are in a position to move beyond\ndata-centric, device-oriented connectivity and offer intelligent, immersive\nexperiences based on task-oriented connections, especially in the context of\nthe thriving development of pre-trained foundation models (PFM) and the\nevolving vision of 6G native artificial intelligence (AI). Therefore,\nredefining modes of collaboration between devices and servers and constructing\nnative intelligence libraries become critically important in 6G. In this paper,\nwe analyze the challenges of achieving 6G native AI from the perspectives of\ndata, intelligence, and networks. Then, we propose a 6G native AI framework\nbased on foundation models, provide a customization approach for intent-aware\nPFM, present a construction of a task-oriented AI toolkit, and outline a novel\ncloud-edge-end collaboration paradigm. As a practical use case, we apply this\nframework for orchestration, achieving the maximum sum rate within a wireless\ncommunication system, and presenting preliminary evaluation results. Finally,\nwe outline research directions for achieving native AI in 6G.",
            "author": [
                "Xiang Chen",
                "Zhiheng Guo",
                "Xijun Wang",
                "Howard H. Yang",
                "Chenyuan Feng",
                "Junshen Su",
                "Sihui Zheng",
                "Tony Q. S. Quek"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17471v1",
                "http://arxiv.org/pdf/2310.17471v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.DC",
                "cs.LG",
                "cs.NI",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17470v1",
            "title": "Adaptive Digital Twin for UAV-Assisted Integrated Sensing,\n  Communication, and Computation Networks",
            "updated": "2023-10-26T15:17:15Z",
            "published": "2023-10-26T15:17:15Z",
            "summary": "In this paper, we study a digital twin (DT)-empowered integrated sensing,\ncommunication, and computation network. Specifically, the users perform radar\nsensing and computation offloading on the same spectrum, while unmanned aerial\nvehicles (UAVs) are deployed to provide edge computing service. We first\nformulate a multi-objective optimization problem to minimize the beampattern\nperformance of multi-input multi-output (MIMO) radars and the computation\noffloading energy consumption simultaneously. Then, we explore the prediction\ncapability of DT to provide intelligent offloading decision, where the DT\nestimation deviation is considered. To track this challenge, we reformulate the\noriginal problem as a multi-agent Markov decision process and design a\nmulti-agent proximal policy optimization (MAPPO) framework to achieve a\nflexible learning policy. Furthermore, the Beta-policy and attention mechanism\nare used to improve the training performance. Numerical results show that the\nproposed method is able to balance the performance tradeoff between sensing and\ncomputation functions, while reducing the energy consumption compared with the\nexisting studies.",
            "author": [
                "Bin Li",
                "Wenshuai Liu",
                "Wancheng Xie",
                "Ning Zhang",
                "Yan Zhang"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TGCN.2023.3298039",
                "http://arxiv.org/abs/2310.17470v1",
                "http://arxiv.org/pdf/2310.17470v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17468v1",
            "title": "Cross-modal Active Complementary Learning with Self-refining\n  Correspondence",
            "updated": "2023-10-26T15:15:11Z",
            "published": "2023-10-26T15:15:11Z",
            "summary": "Recently, image-text matching has attracted more and more attention from\nacademia and industry, which is fundamental to understanding the latent\ncorrespondence across visual and textual modalities. However, most existing\nmethods implicitly assume the training pairs are well-aligned while ignoring\nthe ubiquitous annotation noise, a.k.a noisy correspondence (NC), thereby\ninevitably leading to a performance drop. Although some methods attempt to\naddress such noise, they still face two challenging problems: excessive\nmemorizing/overfitting and unreliable correction for NC, especially under high\nnoise. To address the two problems, we propose a generalized Cross-modal Robust\nComplementary Learning framework (CRCL), which benefits from a novel Active\nComplementary Loss (ACL) and an efficient Self-refining Correspondence\nCorrection (SCC) to improve the robustness of existing methods. Specifically,\nACL exploits active and complementary learning losses to reduce the risk of\nproviding erroneous supervision, leading to theoretically and experimentally\ndemonstrated robustness against NC. SCC utilizes multiple self-refining\nprocesses with momentum correction to enlarge the receptive field for\ncorrecting correspondences, thereby alleviating error accumulation and\nachieving accurate and stable corrections. We carry out extensive experiments\non three image-text benchmarks, i.e., Flickr30K, MS-COCO, and CC152K, to verify\nthe superior robustness of our CRCL against synthetic and real-world noisy\ncorrespondences.",
            "author": [
                "Yang Qin",
                "Yuan Sun",
                "Dezhong Peng",
                "Joey Tianyi Zhou",
                "Xi Peng",
                "Peng Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17468v1",
                "http://arxiv.org/pdf/2310.17468v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17467v1",
            "title": "The statistical thermodynamics of generative diffusion models",
            "updated": "2023-10-26T15:15:01Z",
            "published": "2023-10-26T15:15:01Z",
            "summary": "Generative diffusion models have achieved spectacular performance in many\nareas of generative modeling. While the fundamental ideas behind these models\ncome from non-equilibrium physics, in this paper we show that many aspects of\nthese models can be understood using the tools of equilibrium statistical\nmechanics. Using this reformulation, we show that generative diffusion models\nundergo second-order phase transitions corresponding to symmetry breaking\nphenomena. We argue that this lead to a form of instability that lies at the\nheart of their generative capabilities and that can be described by a set of\nmean field critical exponents. We conclude by analyzing recent work connecting\ndiffusion models and associative memory networks in view of the thermodynamic\nformulations.",
            "author": [
                "Luca Ambrogioni"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17467v1",
                "http://arxiv.org/pdf/2310.17467v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17463v1",
            "title": "Bayesian Neural Controlled Differential Equations for Treatment Effect\n  Estimation",
            "updated": "2023-10-26T15:10:35Z",
            "published": "2023-10-26T15:10:35Z",
            "summary": "Treatment effect estimation in continuous time is crucial for personalized\nmedicine. However, existing methods for this task are limited to point\nestimates of the potential outcomes, whereas uncertainty estimates have been\nignored. Needless to say, uncertainty quantification is crucial for reliable\ndecision-making in medical applications. To fill this gap, we propose a novel\nBayesian neural controlled differential equation (BNCDE) for treatment effect\nestimation in continuous time. In our BNCDE, the time dimension is modeled\nthrough a coupled system of neural controlled differential equations and neural\nstochastic differential equations, where the neural stochastic differential\nequations allow for tractable variational Bayesian inference. Thereby, for an\nassigned sequence of treatments, our BNCDE provides meaningful posterior\npredictive distributions of the potential outcomes. To the best of our\nknowledge, ours is the first tailored neural method to provide uncertainty\nestimates of treatment effects in continuous time. As such, our method is of\ndirect practical value for promoting reliable decision-making in medicine.",
            "author": [
                "Konstantin Hess",
                "Valentyn Melnychuk",
                "Dennis Frauen",
                "Stefan Feuerriegel"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17463v1",
                "http://arxiv.org/pdf/2310.17463v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17462v2",
            "title": "Towards Learning Monocular 3D Object Localization From 2D Labels using\n  the Physical Laws of Motion",
            "updated": "2023-11-29T14:33:28Z",
            "published": "2023-10-26T15:10:10Z",
            "summary": "We present a novel method for precise 3D object localization in single images\nfrom a single calibrated camera using only 2D labels. No expensive 3D labels\nare needed. Thus, instead of using 3D labels, our model is trained with\neasy-to-annotate 2D labels along with the physical knowledge of the object's\nmotion. Given this information, the model can infer the latent third dimension,\neven though it has never seen this information during training. Our method is\nevaluated on both synthetic and real-world datasets, and we are able to achieve\na mean distance error of just 6 cm in our experiments on real data. The results\nindicate the method's potential as a step towards learning 3D object location\nestimation, where collecting 3D data for training is not feasible.",
            "author": [
                "Daniel Kienzle",
                "Julian Lorenz",
                "Katja Ludwig",
                "Rainer Lienhart"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17462v2",
                "http://arxiv.org/pdf/2310.17462v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17458v1",
            "title": "Coalitional Bargaining via Reinforcement Learning: An Application to\n  Collaborative Vehicle Routing",
            "updated": "2023-10-26T15:04:23Z",
            "published": "2023-10-26T15:04:23Z",
            "summary": "Collaborative Vehicle Routing is where delivery companies cooperate by\nsharing their delivery information and performing delivery requests on behalf\nof each other. This achieves economies of scale and thus reduces cost,\ngreenhouse gas emissions, and road congestion. But which company should partner\nwith whom, and how much should each company be compensated? Traditional game\ntheoretic solution concepts, such as the Shapley value or nucleolus, are\ndifficult to calculate for the real-world problem of Collaborative Vehicle\nRouting due to the characteristic function scaling exponentially with the\nnumber of agents. This would require solving the Vehicle Routing Problem (an\nNP-Hard problem) an exponential number of times. We therefore propose to model\nthis problem as a coalitional bargaining game where - crucially - agents are\nnot given access to the characteristic function. Instead, we implicitly reason\nabout the characteristic function, and thus eliminate the need to evaluate the\nVRP an exponential number of times - we only need to evaluate it once. Our\ncontribution is that our decentralised approach is both scalable and considers\nthe self-interested nature of companies. The agents learn using a modified\nIndependent Proximal Policy Optimisation. Our RL agents outperform a strong\nheuristic bot. The agents correctly identify the optimal coalitions 79% of the\ntime with an average optimality gap of 4.2% and reduction in run-time of 62%.",
            "author": [
                "Stephen Mak",
                "Liming Xu",
                "Tim Pearce",
                "Michael Ostroumov",
                "Alexandra Brintrup"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17458v1",
                "http://arxiv.org/pdf/2310.17458v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17455v1",
            "title": "OTMatch: Improving Semi-Supervised Learning with Optimal Transport",
            "updated": "2023-10-26T15:01:54Z",
            "published": "2023-10-26T15:01:54Z",
            "summary": "Semi-supervised learning has made remarkable strides by effectively utilizing\na limited amount of labeled data while capitalizing on the abundant information\npresent in unlabeled data. However, current algorithms often prioritize\naligning image predictions with specific classes generated through\nself-training techniques, thereby neglecting the inherent relationships that\nexist within these classes. In this paper, we present a new approach called\nOTMatch, which leverages semantic relationships among classes by employing an\noptimal transport loss function. By utilizing optimal transport, our proposed\nmethod consistently outperforms established state-of-the-art methods. Notably,\nwe observed a substantial improvement of a certain percentage in accuracy\ncompared to the current state-of-the-art method, FreeMatch. OTMatch achieves\n3.18%, 3.46%, and 1.28% error rate reduction over FreeMatch on CIFAR-10 with 1\nlabel per class, STL-10 with 4 labels per class, and ImageNet with 100 labels\nper class, respectively. This demonstrates the effectiveness and superiority of\nour approach in harnessing semantic relationships to enhance learning\nperformance in a semi-supervised setting.",
            "author": [
                "Zhiquan Tan",
                "Kaipeng Zheng",
                "Weiran Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17455v1",
                "http://arxiv.org/pdf/2310.17455v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17451v1",
            "title": "Generating by Understanding: Neural Visual Generation with Logical\n  Symbol Groundings",
            "updated": "2023-10-26T15:00:21Z",
            "published": "2023-10-26T15:00:21Z",
            "summary": "Despite the great success of neural visual generative models in recent years,\nintegrating them with strong symbolic knowledge reasoning systems remains a\nchallenging task. The main challenges are two-fold: one is symbol assignment,\ni.e. bonding latent factors of neural visual generators with meaningful symbols\nfrom knowledge reasoning systems. Another is rule learning, i.e. learning new\nrules, which govern the generative process of the data, to augment the\nknowledge reasoning systems. To deal with these symbol grounding problems, we\npropose a neural-symbolic learning approach, Abductive Visual Generation\n(AbdGen), for integrating logic programming systems with neural visual\ngenerative models based on the abductive learning framework. To achieve\nreliable and efficient symbol assignment, the quantized abduction method is\nintroduced for generating abduction proposals by the nearest-neighbor lookups\nwithin semantic codebooks. To achieve precise rule learning, the contrastive\nmeta-abduction method is proposed to eliminate wrong rules with positive cases\nand avoid less-informative rules with negative cases simultaneously.\nExperimental results on various benchmark datasets show that compared to the\nbaselines, AbdGen requires significantly fewer instance-level labeling\ninformation for symbol assignment. Furthermore, our approach can effectively\nlearn underlying logical generative rules from data, which is out of the\ncapability of existing approaches.",
            "author": [
                "Yifei Peng",
                "Yu Jin",
                "Zhexu Luo",
                "Yao-Xiang Ding",
                "Wang-Zhou Dai",
                "Zhong Ren",
                "Kun Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17451v1",
                "http://arxiv.org/pdf/2310.17451v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17439v1",
            "title": "Designing Hash and Encryption Engines using Quantum Computing",
            "updated": "2023-10-26T14:49:51Z",
            "published": "2023-10-26T14:49:51Z",
            "summary": "Quantum computing (QC) holds the promise of revolutionizing problem-solving\nby exploiting quantum phenomena like superposition and entanglement. It offers\nexponential speed-ups across various domains, from machine learning and\nsecurity to drug discovery and optimization. In parallel, quantum encryption\nand key distribution have garnered substantial interest, leveraging quantum\nengines to enhance cryptographic techniques. Classical cryptography faces\nimminent threats from quantum computing, exemplified by Shors algorithms\ncapacity to breach established encryption schemes. However, quantum circuits\nand algorithms, capitalizing on superposition and entanglement, offer\ninnovative avenues for enhancing security. In this paper we explore\nquantum-based hash functions and encryption to fortify data security. Quantum\nhash functions and encryption can have numerous potential application cases,\nsuch as password storage, digital signatures, cryptography, anti-tampering etc.\nThe integration of quantum and classical methods demonstrates potential in\nsecuring data in the era of quantum computing.",
            "author": [
                "Suryansh Upadhyay",
                "Rupshali Roy",
                "Swaroop Ghosh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17439v1",
                "http://arxiv.org/pdf/2310.17439v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17437v1",
            "title": "Sign Languague Recognition without frame-sequencing constraints: A proof\n  of concept on the Argentinian Sign Language",
            "updated": "2023-10-26T14:47:11Z",
            "published": "2023-10-26T14:47:11Z",
            "summary": "Automatic sign language recognition (SLR) is an important topic within the\nareas of human-computer interaction and machine learning. On the one hand, it\nposes a complex challenge that requires the intervention of various knowledge\nareas, such as video processing, image processing, intelligent systems and\nlinguistics. On the other hand, robust recognition of sign language could\nassist in the translation process and the integration of hearing-impaired\npeople, as well as the teaching of sign language for the hearing population.\n  SLR systems usually employ Hidden Markov Models, Dynamic Time Warping or\nsimilar models to recognize signs. Such techniques exploit the sequential\nordering of frames to reduce the number of hypothesis. This paper presents a\ngeneral probabilistic model for sign classification that combines\nsub-classifiers based on different types of features such as position, movement\nand handshape. The model employs a bag-of-words approach in all classification\nsteps, to explore the hypothesis that ordering is not essential for\nrecognition. The proposed model achieved an accuracy rate of 97% on an\nArgentinian Sign Language dataset containing 64 classes of signs and 3200\nsamples, providing some evidence that indeed recognition without ordering is\npossible.",
            "author": [
                "Franco Ronchetti",
                "Facundo Manuel Quiroga",
                "C\u00e9sar Estrebou",
                "Laura Lanzarini",
                "Alejandro Rosete"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-319-47955-2_28",
                "http://arxiv.org/abs/2310.17437v1",
                "http://arxiv.org/pdf/2310.17437v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17683v1",
            "title": "Sliceformer: Make Multi-head Attention as Simple as Sorting in\n  Discriminative Tasks",
            "updated": "2023-10-26T14:43:07Z",
            "published": "2023-10-26T14:43:07Z",
            "summary": "As one of the most popular neural network modules, Transformer plays a\ncentral role in many fundamental deep learning models, e.g., the ViT in\ncomputer vision and the BERT and GPT in natural language processing. The\neffectiveness of the Transformer is often attributed to its multi-head\nattention (MHA) mechanism. In this study, we discuss the limitations of MHA,\nincluding the high computational complexity due to its ``query-key-value''\narchitecture and the numerical issue caused by its softmax operation.\nConsidering the above problems and the recent development tendency of the\nattention layer, we propose an effective and efficient surrogate of the\nTransformer, called Sliceformer. Our Sliceformer replaces the classic MHA\nmechanism with an extremely simple ``slicing-sorting'' operation, i.e.,\nprojecting inputs linearly to a latent space and sorting them along different\nfeature dimensions (or equivalently, called channels). For each feature\ndimension, the sorting operation implicitly generates an implicit attention map\nwith sparse, full-rank, and doubly-stochastic structures. We consider different\nimplementations of the slicing-sorting operation and analyze their impacts on\nthe Sliceformer. We test the Sliceformer in the Long-Range Arena benchmark,\nimage classification, text classification, and molecular property prediction,\ndemonstrating its advantage in computational complexity and universal\neffectiveness in discriminative tasks. Our Sliceformer achieves comparable or\nbetter performance with lower memory cost and faster speed than the Transformer\nand its variants. Moreover, the experimental results reveal that applying our\nSliceformer can empirically suppress the risk of mode collapse when\nrepresenting data. The code is available at\n\\url{https://github.com/SDS-Lab/sliceformer}.",
            "author": [
                "Shen Yuan",
                "Hongteng Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17683v1",
                "http://arxiv.org/pdf/2310.17683v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17432v1",
            "title": "Likelihood-based Out-of-Distribution Detection with Denoising Diffusion\n  Probabilistic Models",
            "updated": "2023-10-26T14:40:30Z",
            "published": "2023-10-26T14:40:30Z",
            "summary": "Out-of-Distribution detection between dataset pairs has been extensively\nexplored with generative models. We show that likelihood-based\nOut-of-Distribution detection can be extended to diffusion models by leveraging\nthe fact that they, like other likelihood-based generative models, are\ndramatically affected by the input sample complexity. Currently, all\nOut-of-Distribution detection methods with Diffusion Models are\nreconstruction-based. We propose a new likelihood ratio for Out-of-Distribution\ndetection with Deep Denoising Diffusion Models, which we call the Complexity\nCorrected Likelihood Ratio. Our likelihood ratio is constructed using Evidence\nLower-Bound evaluations from an individual model at various noising levels. We\npresent results that are comparable to state-of-the-art Out-of-Distribution\ndetection methods with generative models.",
            "author": [
                "Joseph Goodier",
                "Neill D. F. Campbell"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17432v1",
                "http://arxiv.org/pdf/2310.17432v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17431v1",
            "title": "Efficient safe learning for controller tuning with experimental\n  validation",
            "updated": "2023-10-26T14:40:11Z",
            "published": "2023-10-26T14:40:11Z",
            "summary": "Optimization-based controller tuning is challenging because it requires\nformulating optimization problems explicitly as functions of controller\nparameters. Safe learning algorithms overcome the challenge by creating\nsurrogate models from measured data. To ensure safety, such data-driven\nalgorithms often rely on exhaustive grid search, which is computationally\ninefficient. In this paper, we propose a novel approach to safe learning by\nformulating a series of optimization problems instead of a grid search. We also\ndevelop a method for initializing the optimization problems to guarantee\nfeasibility while using numerical solvers. The performance of the new method is\nfirst validated in a simulated precision motion system, demonstrating improved\ncomputational efficiency, and illustrating the role of exploiting numerical\nsolvers to reach the desired precision. Experimental validation on an\nindustrial-grade precision motion system confirms that the proposed algorithm\nachieves 30% better tracking at sub-micrometer precision as a state-of-the-art\nsafe learning algorithm, improves the default auto-tuning solution, and reduces\nthe computational cost seven times compared to learning algorithms based on\nexhaustive search.",
            "author": [
                "Marta Zagorowska",
                "Christopher K\u00f6nig",
                "Hanlin Yu",
                "Efe C. Balta",
                "Alisa Rupenyan",
                "John Lygeros"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17431v1",
                "http://arxiv.org/pdf/2310.17431v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17430v1",
            "title": "A near-autonomous and incremental intrusion detection system through\n  active learning of known and unknown attacks",
            "updated": "2023-10-26T14:37:54Z",
            "published": "2023-10-26T14:37:54Z",
            "summary": "Intrusion detection is a traditional practice of security experts, however,\nthere are several issues which still need to be tackled. Therefore, in this\npaper, after highlighting these issues, we present an architecture for a hybrid\nIntrusion Detection System (IDS) for an adaptive and incremental detection of\nboth known and unknown attacks. The IDS is composed of supervised and\nunsupervised modules, namely, a Deep Neural Network (DNN) and the K-Nearest\nNeighbors (KNN) algorithm, respectively. The proposed system is near-autonomous\nsince the intervention of the expert is minimized through the active learning\n(AL) approach. A query strategy for the labeling process is presented, it aims\nat teaching the supervised module to detect unknown attacks and improve the\ndetection of the already-known attacks. This teaching is achieved through\nsliding windows (SW) in an incremental fashion where the DNN is retrained when\nthe data is available over time, thus rendering the IDS adaptive to cope with\nthe evolutionary aspect of the network traffic. A set of experiments was\nconducted on the CICIDS2017 dataset in order to evaluate the performance of the\nIDS, promising results were obtained.",
            "author": [
                "Lynda Boukela",
                "Gongxuan Zhang",
                "Meziane Yacoub",
                "Samia Bouzefrane"
            ],
            "link": [
                "http://dx.doi.org/10.1109/SPAC53836.2021.9539947",
                "http://arxiv.org/abs/2310.17430v1",
                "http://arxiv.org/pdf/2310.17430v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "68"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17429v1",
            "title": "LSA64: An Argentinian Sign Language Dataset",
            "updated": "2023-10-26T14:37:01Z",
            "published": "2023-10-26T14:37:01Z",
            "summary": "Automatic sign language recognition is a research area that encompasses\nhuman-computer interaction, computer vision and machine learning. Robust\nautomatic recognition of sign language could assist in the translation process\nand the integration of hearing-impaired people, as well as the teaching of sign\nlanguage to the hearing population. Sign languages differ significantly in\ndifferent countries and even regions, and their syntax and semantics are\ndifferent as well from those of written languages. While the techniques for\nautomatic sign language recognition are mostly the same for different\nlanguages, training a recognition system for a new language requires having an\nentire dataset for that language. This paper presents a dataset of 64 signs\nfrom the Argentinian Sign Language (LSA). The dataset, called LSA64, contains\n3200 videos of 64 different LSA signs recorded by 10 subjects, and is a first\nstep towards building a comprehensive research-level dataset of Argentinian\nsigns, specifically tailored to sign language recognition or other machine\nlearning tasks. The subjects that performed the signs wore colored gloves to\nease the hand tracking and segmentation steps, allowing experiments on the\ndataset to focus specifically on the recognition of signs. We also present a\npre-processed version of the dataset, from which we computed statistics of\nmovement, position and handshape of the signs.",
            "author": [
                "Franco Ronchetti",
                "Facundo Manuel Quiroga",
                "C\u00e9sar Estrebou",
                "Laura Lanzarini",
                "Alejandro Rosete"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17429v1",
                "http://arxiv.org/pdf/2310.17429v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "I.5.4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17427v1",
            "title": "Handshape recognition for Argentinian Sign Language using ProbSom",
            "updated": "2023-10-26T14:32:44Z",
            "published": "2023-10-26T14:32:44Z",
            "summary": "Automatic sign language recognition is an important topic within the areas of\nhuman-computer interaction and machine learning. On the one hand, it poses a\ncomplex challenge that requires the intervention of various knowledge areas,\nsuch as video processing, image processing, intelligent systems and\nlinguistics. On the other hand, robust recognition of sign language could\nassist in the translation process and the integration of hearing-impaired\npeople.\n  This paper offers two main contributions: first, the creation of a database\nof handshapes for the Argentinian Sign Language (LSA), which is a topic that\nhas barely been discussed so far. Secondly, a technique for image processing,\ndescriptor extraction and subsequent handshape classification using a\nsupervised adaptation of self-organizing maps that is called ProbSom. This\ntechnique is compared to others in the state of the art, such as Support Vector\nMachines (SVM), Random Forests, and Neural Networks.\n  The database that was built contains 800 images with 16 LSA handshapes, and\nis a first step towards building a comprehensive database of Argentinian signs.\nThe ProbSom-based neural classifier, using the proposed descriptor, achieved an\naccuracy rate above 90%.",
            "author": [
                "Franco Ronchetti",
                "Facundo Manuel Quiroga",
                "C\u00e9sar Estrebou",
                "Laura Lanzarini"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17427v1",
                "http://arxiv.org/pdf/2310.17427v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17426v1",
            "title": "Stealthy SWAPs: Adversarial SWAP Injection in Multi-Tenant Quantum\n  Computing",
            "updated": "2023-10-26T14:31:21Z",
            "published": "2023-10-26T14:31:21Z",
            "summary": "Quantum computing (QC) holds tremendous promise in revolutionizing\nproblem-solving across various domains. It has been suggested in literature\nthat 50+ qubits are sufficient to achieve quantum advantage (i.e., to surpass\nsupercomputers in solving certain class of optimization problems).The hardware\nsize of existing Noisy Intermediate-Scale Quantum (NISQ) computers have been\never increasing over the years. Therefore, Multi-tenant computing (MTC) has\nemerged as a potential solution for efficient hardware utilization, enabling\nshared resource access among multiple quantum programs. However, MTC can also\nbring new security concerns. This paper proposes one such threat for MTC in\nsuperconducting quantum hardware i.e., adversarial SWAP gate injection in\nvictims program during compilation for MTC. We present a representative\nscheduler designed for optimal resource allocation. To demonstrate the impact\nof this attack model, we conduct a detailed case study using a sample\nscheduler. Exhaustive experiments on circuits with varying depths and qubits\noffer valuable insights into the repercussions of these attacks. We report a\nmax of approximately 55 percent and a median increase of approximately 25\npercent in SWAP overhead. As a countermeasure, we also propose a sample machine\nlearning model for detecting any abnormal user behavior and priority\nadjustment.",
            "author": [
                "Suryansh Upadhyay",
                "Swaroop Ghosh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17426v1",
                "http://arxiv.org/pdf/2310.17426v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17417v1",
            "title": "Training for Open-Ended Drilling through a Virtual Reality Simulation",
            "updated": "2023-10-26T14:22:30Z",
            "published": "2023-10-26T14:22:30Z",
            "summary": "Virtual Reality (VR) can support effective and scalable training of\npsychomotor skills in manufacturing. However, many industry training modules\noffer experiences that are close-ended and do not allow for human error. We aim\nto address this gap in VR training tools for psychomotor skills training by\nexploring an open-ended approach to the system design. We designed a VR\ntraining simulation prototype to perform open-ended practice of drilling using\na 3-axis milling machine. The simulation employs near \"end-to-end\" instruction\nthrough a safety module, a setup and drilling tutorial, open-ended practice\ncomplete with warnings of mistakes and failures, and a function to assess the\ngeometries and locations of drilled holes against an engineering drawing. We\ndeveloped and conducted a user study within an undergraduate-level introductory\nfabrication course to investigate the impact of open-ended VR practice on\nlearning outcomes. Study results reveal positive trends, with the VR group\nsuccessfully completing the machining task of drilling at a higher rate (75% vs\n64%), with fewer mistakes (1.75 vs 2.14 score), and in less time (17.67 mins vs\n21.57 mins) compared to the control group. We discuss our findings and\nlimitations and implications for the design of open-ended VR training systems\nfor learning psychomotor skills.",
            "author": [
                "Hing Lie",
                "Kachina Studer",
                "Zhen Zhao",
                "Ben Thomson",
                "Dishita G Turakhia",
                "John Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17417v1",
                "http://arxiv.org/pdf/2310.17417v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17416v1",
            "title": "Goals are Enough: Inducing AdHoc cooperation among unseen Multi-Agent\n  systems in IMFs",
            "updated": "2023-10-26T14:21:36Z",
            "published": "2023-10-26T14:21:36Z",
            "summary": "Intent-based management will play a critical role in achieving customers'\nexpectations in the next-generation mobile networks. Traditional methods cannot\nperform efficient resource management since they tend to handle each\nexpectation independently. Existing approaches, e.g., based on multi-agent\nreinforcement learning (MARL) allocate resources in an efficient fashion when\nthere are conflicting expectations on the network slice. However, in reality,\nsystems are often far more complex to be addressed by a standalone MARL\nformulation. Often there exists a hierarchical structure of intent fulfilment\nwhere multiple pre-trained, self-interested agents may need to be further\norchestrated by a supervisor or controller agent. Such agents may arrive in the\nsystem adhoc, which then needs to be orchestrated along with other available\nagents. Retraining the whole system every time is often infeasible given the\nassociated time and cost. Given the challenges, such adhoc coordination of\npre-trained systems could be achieved through an intelligent supervisor agent\nwhich incentivizes pre-trained RL/MARL agents through sets of dynamic contracts\n(goals or bonuses) and encourages them to act as a cohesive unit towards\nfulfilling a global expectation. Some approaches use a rule-based supervisor\nagent and deploy the hierarchical constituent agents sequentially, based on\nhuman-coded rules.\n  In the current work, we propose a framework whereby pre-trained agents can be\norchestrated in parallel leveraging an AI-based supervisor agent. For this, we\npropose to use Adhoc-Teaming approaches which assign optimal goals to the MARL\nagents and incentivize them to exhibit certain desired behaviours. Results on\nthe network emulator show that the proposed approach results in faster and\nimproved fulfilment of expectations when compared to rule-based approaches and\neven generalizes to changes in environments.",
            "author": [
                "Kaushik Dey",
                "Satheesh K. Perepu",
                "Abir Das"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17416v1",
                "http://arxiv.org/pdf/2310.17416v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17415v1",
            "title": "PETA: Evaluating the Impact of Protein Transfer Learning with Sub-word\n  Tokenization on Downstream Applications",
            "updated": "2023-10-26T14:20:44Z",
            "published": "2023-10-26T14:20:44Z",
            "summary": "Large protein language models are adept at capturing the underlying\nevolutionary information in primary structures, offering significant practical\nvalue for protein engineering. Compared to natural language models, protein\namino acid sequences have a smaller data volume and a limited combinatorial\nspace. Choosing an appropriate vocabulary size to optimize the pre-trained\nmodel is a pivotal issue. Moreover, despite the wealth of benchmarks and\nstudies in the natural language community, there remains a lack of a\ncomprehensive benchmark for systematically evaluating protein language model\nquality. Given these challenges, PETA trained language models with 14 different\nvocabulary sizes under three tokenization methods. It conducted thousands of\ntests on 33 diverse downstream datasets to assess the models' transfer learning\ncapabilities, incorporating two classification heads and three random seeds to\nmitigate potential biases. Extensive experiments indicate that vocabulary sizes\nbetween 50 and 200 optimize the model, whereas sizes exceeding 800\ndetrimentally affect the model's representational performance. Our code, model\nweights and datasets are available at\nhttps://github.com/ginnm/ProteinPretraining.",
            "author": [
                "Yang Tan",
                "Mingchen Li",
                "Pan Tan",
                "Ziyi Zhou",
                "Huiqun Yu",
                "Guisheng Fan",
                "Liang Hong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17415v1",
                "http://arxiv.org/pdf/2310.17415v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "q-bio.BM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17410v1",
            "title": "Synthesizing Efficiently Monitorable Formulas in Metric Temporal Logic",
            "updated": "2023-10-26T14:13:15Z",
            "published": "2023-10-26T14:13:15Z",
            "summary": "In runtime verification, manually formalizing a specification for monitoring\nsystem executions is a tedious and error-prone process. To address this issue,\nwe consider the problem of automatically synthesizing formal specifications\nfrom system executions. To demonstrate our approach, we consider the popular\nspecification language Metric Temporal Logic (MTL), which is particularly\ntailored towards specifying temporal properties for cyber-physical systems\n(CPS). Most of the classical approaches for synthesizing temporal logic\nformulas aim at minimizing the size of the formula. However, for efficiency in\nmonitoring, along with the size, the amount of \"lookahead\" required for the\nspecification becomes relevant, especially for safety-critical applications. We\nformalize this notion and devise a learning algorithm that synthesizes concise\nformulas having bounded lookahead. To do so, our algorithm reduces the\nsynthesis task to a series of satisfiability problems in Linear Real Arithmetic\n(LRA) and generates MTL formulas from their satisfying assignments. The\nreduction uses a novel encoding of a popular MTL monitoring procedure using\nLRA. Finally, we implement our algorithm in a tool called TEAL and demonstrate\nits ability to synthesize efficiently monitorable MTL formulas in a CPS\napplication.",
            "author": [
                "Ritam Raha",
                "Rajarshi Roy",
                "Nathanael Fijalkow",
                "Daniel Neider",
                "Guillermo A. Perez"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17410v1",
                "http://arxiv.org/pdf/2310.17410v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17407v1",
            "title": "Meaning and understanding in large language models",
            "updated": "2023-10-26T14:06:14Z",
            "published": "2023-10-26T14:06:14Z",
            "summary": "Can a machine understand the meanings of natural language? Recent\ndevelopments in the generative large language models (LLMs) of artificial\nintelligence have led to the belief that traditional philosophical assumptions\nabout machine understanding of language need to be revised. This article\ncritically evaluates the prevailing tendency to regard machine language\nperformance as mere syntactic manipulation and the simulation of understanding,\nwhich is only partial and very shallow, without sufficient referential\ngrounding in the world. The aim is to highlight the conditions crucial to\nattributing natural language understanding to state-of-the-art LLMs, where it\ncan be legitimately argued that LLMs not only use syntax but also semantics,\ntheir understanding not being simulated but duplicated; and determine how they\nground the meanings of linguistic expressions.",
            "author": [
                "Vladim\u00edr Havl\u00edk"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17407v1",
                "http://arxiv.org/pdf/2310.17407v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17405v1",
            "title": "Causal Modeling with Stationary Diffusions",
            "updated": "2023-10-26T14:01:17Z",
            "published": "2023-10-26T14:01:17Z",
            "summary": "We develop a novel approach towards causal inference. Rather than structural\nequations over a causal graph, we learn stochastic differential equations\n(SDEs) whose stationary densities model a system's behavior under\ninterventions. These stationary diffusion models do not require the formalism\nof causal graphs, let alone the common assumption of acyclicity. We show that\nin several cases, they generalize to unseen interventions on their variables,\noften better than classical approaches. Our inference method is based on a new\ntheoretical result that expresses a stationarity condition on the diffusion's\ngenerator in a reproducing kernel Hilbert space. The resulting kernel deviation\nfrom stationarity (KDS) is an objective function of independent interest.",
            "author": [
                "Lars Lorch",
                "Andreas Krause",
                "Bernhard Sch\u00f6lkopf"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17405v1",
                "http://arxiv.org/pdf/2310.17405v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17404v1",
            "title": "Invariance Measures for Neural Networks",
            "updated": "2023-10-26T13:59:39Z",
            "published": "2023-10-26T13:59:39Z",
            "summary": "Invariances in neural networks are useful and necessary for many tasks.\nHowever, the representation of the invariance of most neural network models has\nnot been characterized. We propose measures to quantify the invariance of\nneural networks in terms of their internal representation. The measures are\nefficient and interpretable, and can be applied to any neural network model.\nThey are also more sensitive to invariance than previously defined measures. We\nvalidate the measures and their properties in the domain of affine\ntransformations and the CIFAR10 and MNIST datasets, including their stability\nand interpretability. Using the measures, we perform a first analysis of CNN\nmodels and show that their internal invariance is remarkably stable to random\nweight initializations, but not to changes in dataset or transformation. We\nbelieve the measures will enable new avenues of research in invariance\nrepresentation.",
            "author": [
                "Facundo Manuel Quiroga",
                "Jordina Torrents-Barrena",
                "Laura Cristina Lanzarini",
                "Domenec Puig-Valls"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.asoc.2022.109817",
                "http://arxiv.org/abs/2310.17404v1",
                "http://arxiv.org/pdf/2310.17404v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17403v2",
            "title": "Detection Defenses: An Empty Promise against Adversarial Patch Attacks\n  on Optical Flow",
            "updated": "2023-11-02T08:28:29Z",
            "published": "2023-10-26T13:56:12Z",
            "summary": "Adversarial patches undermine the reliability of optical flow predictions\nwhen placed in arbitrary scene locations. Therefore, they pose a realistic\nthreat to real-world motion detection and its downstream applications.\nPotential remedies are defense strategies that detect and remove adversarial\npatches, but their influence on the underlying motion prediction has not been\ninvestigated. In this paper, we thoroughly examine the currently available\ndetect-and-remove defenses ILP and LGS for a wide selection of state-of-the-art\noptical flow methods, and illuminate their side effects on the quality and\nrobustness of the final flow predictions. In particular, we implement\ndefense-aware attacks to investigate whether current defenses are able to\nwithstand attacks that take the defense mechanism into account. Our experiments\nyield two surprising results: Detect-and-remove defenses do not only lower the\noptical flow quality on benign scenes, in doing so, they also harm the\nrobustness under patch attacks for all tested optical flow methods except\nFlowNetC. As currently employed detect-and-remove defenses fail to deliver the\npromised adversarial robustness for optical flow, they evoke a false sense of\nsecurity. The code is available at\nhttps://github.com/cv-stuttgart/DetectionDefenses.",
            "author": [
                "Erik Scheurer",
                "Jenny Schmalfuss",
                "Alexander Lis",
                "Andr\u00e9s Bruhn"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17403v2",
                "http://arxiv.org/pdf/2310.17403v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17402v1",
            "title": "Learning to learn with an evolutionary strategy applied to variational\n  quantum algorithms",
            "updated": "2023-10-26T13:55:01Z",
            "published": "2023-10-26T13:55:01Z",
            "summary": "Variational Quantum Algorithms (VQAs) employ quantum circuits parameterized\nby $U$, optimized using classical methods to minimize a cost function. While\nVQAs have found broad applications, certain challenges persist. Notably, a\nsignificant computational burden arises during parameter optimization. The\nprevailing ``parameter shift rule'' mandates a double evaluation of the cost\nfunction for each parameter. In this article, we introduce a novel optimization\napproach named ``Learning to Learn with an Evolutionary Strategy'' (LLES). LLES\nunifies ``Learning to Learn'' and ``Evolutionary Strategy'' methods. ``Learning\nto Learn'' treats optimization as a learning problem, utilizing recurrent\nneural networks to iteratively propose VQA parameters. Conversely,\n``Evolutionary Strategy'' employs gradient searches to estimate function\ngradients. Our optimization method is applied to two distinct tasks:\ndetermining the ground state of an Ising Hamiltonian and training a quantum\nneural network. Results underscore the efficacy of this novel approach.\nAdditionally, we identify a key hyperparameter that significantly influences\ngradient estimation using the ``Evolutionary Strategy'' method.",
            "author": [
                "Lucas Friedrich",
                "Jonas Maziero"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17402v1",
                "http://arxiv.org/pdf/2310.17402v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17395v1",
            "title": "Learning Temporal Sentence Grounding From Narrated EgoVideos",
            "updated": "2023-10-26T13:46:20Z",
            "published": "2023-10-26T13:46:20Z",
            "summary": "The onset of long-form egocentric datasets such as Ego4D and EPIC-Kitchens\npresents a new challenge for the task of Temporal Sentence Grounding (TSG).\nCompared to traditional benchmarks on which this task is evaluated, these\ndatasets offer finer-grained sentences to ground in notably longer videos. In\nthis paper, we develop an approach for learning to ground sentences in these\ndatasets using only narrations and their corresponding rough narration\ntimestamps. We propose to artificially merge clips to train for temporal\ngrounding in a contrastive manner using text-conditioning attention. This Clip\nMerging (CliMer) approach is shown to be effective when compared with a high\nperforming TSG method -- e.g. mean R@1 improves from 3.9 to 5.7 on Ego4D and\nfrom 10.7 to 13.0 on EPIC-Kitchens. Code and data splits available from:\nhttps://github.com/keflanagan/CliMer",
            "author": [
                "Kevin Flanagan",
                "Dima Damen",
                "Michael Wray"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17395v1",
                "http://arxiv.org/pdf/2310.17395v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17394v1",
            "title": "Enhancing Graph Neural Networks with Structure-Based Prompt",
            "updated": "2023-10-26T13:46:18Z",
            "published": "2023-10-26T13:46:18Z",
            "summary": "Graph Neural Networks (GNNs) are powerful in learning semantics of graph\ndata. Recently, a new paradigm \"pre-train, prompt\" has shown promising results\nin adapting GNNs to various tasks with less supervised data. The success of\nsuch paradigm can be attributed to the more consistent objectives of\npre-training and task-oriented prompt tuning, where the pre-trained knowledge\ncan be effectively transferred to downstream tasks. However, an overlooked\nissue of existing studies is that the structure information of graph is usually\nexploited during pre-training for learning node representations, while\nneglected in the prompt tuning stage for learning task-specific parameters. To\nbridge this gap, we propose a novel structure-based prompting method for GNNs,\nnamely SAP, which consistently exploits structure information in both\npre-training and prompt tuning stages. In particular, SAP 1) employs a\ndual-view contrastive learning to align the latent semantic spaces of node\nattributes and graph structure, and 2) incorporates structure information in\nprompted graph to elicit more pre-trained knowledge in prompt tuning. We\nconduct extensive experiments on node classification and graph classification\ntasks to show the effectiveness of SAP. Moreover, we show that SAP can lead to\nbetter performance in more challenging few-shot scenarios on both homophilous\nand heterophilous graphs.",
            "author": [
                "Qingqing Ge",
                "Zeyuan Zhao",
                "Yiding Liu",
                "Anfeng Cheng",
                "Xiang Li",
                "Shuaiqiang Wang",
                "Dawei Yin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17394v1",
                "http://arxiv.org/pdf/2310.17394v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17386v1",
            "title": "A Challenge in Reweighting Data with Bilevel Optimization",
            "updated": "2023-10-26T13:33:26Z",
            "published": "2023-10-26T13:33:26Z",
            "summary": "In many scenarios, one uses a large training set to train a model with the\ngoal of performing well on a smaller testing set with a different distribution.\nLearning a weight for each data point of the training set is an appealing\nsolution, as it ideally allows one to automatically learn the importance of\neach training point for generalization on the testing set. This task is usually\nformalized as a bilevel optimization problem. Classical bilevel solvers are\nbased on a warm-start strategy where both the parameters of the models and the\ndata weights are learned at the same time. We show that this joint dynamic may\nlead to sub-optimal solutions, for which the final data weights are very\nsparse. This finding illustrates the difficulty of data reweighting and offers\na clue as to why this method is rarely used in practice.",
            "author": [
                "Anastasia Ivanova",
                "Pierre Ablin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17386v1",
                "http://arxiv.org/pdf/2310.17386v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17385v1",
            "title": "Multitask Online Learning: Listen to the Neighborhood Buzz",
            "updated": "2023-10-26T13:32:49Z",
            "published": "2023-10-26T13:32:49Z",
            "summary": "We study multitask online learning in a setting where agents can only\nexchange information with their neighbors on an arbitrary communication\nnetwork. We introduce $\\texttt{MT-CO}_2\\texttt{OL}$, a decentralized algorithm\nfor this setting whose regret depends on the interplay between the task\nsimilarities and the network structure. Our analysis shows that the regret of\n$\\texttt{MT-CO}_2\\texttt{OL}$ is never worse (up to constants) than the bound\nobtained when agents do not share information. On the other hand, our bounds\nsignificantly improve when neighboring agents operate on similar tasks. In\naddition, we prove that our algorithm can be made differentially private with a\nnegligible impact on the regret when the losses are linear. Finally, we provide\nexperimental support for our theory.",
            "author": [
                "Juliette Achddou",
                "Nicol\u00f2 Cesa-Bianchi",
                "Pierre Laforgue"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17385v1",
                "http://arxiv.org/pdf/2310.17385v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17383v1",
            "title": "On the recognition of the game type based on physiological signals and\n  eye tracking",
            "updated": "2023-10-26T13:27:23Z",
            "published": "2023-10-26T13:27:23Z",
            "summary": "Automated interpretation of signals yields many impressive applications from\nthe area of affective computing and human activity recognition (HAR). In this\npaper we ask the question about possibility of cognitive activity recognition\non the base of particular set of signals. We use recognition of the game played\nby the participant as a playground for exploration of the problem. We build\nclassifier of three different games (Space Invaders, Tetris, Tower Defence) and\ninter-game pause. We validate classifier in the player-independent and\nplayer-dependent scenario. We discuss the improvement in the player-dependent\nscenario in the context of biometric person recognition. On the base of the\nresults obtained in game classification, we consider potential applications in\nsmart surveillance and quantified self.",
            "author": [
                "\u0141ukasz Czekaj",
                "\u0141ukasz Radzinski",
                "Mateusz Kolimaga",
                "Jakub Domaszewicz",
                "Robert Kit\u0142owski",
                "Mariusz Szwoch",
                "W\u0142odzis\u0142aw Duch"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17383v1",
                "http://arxiv.org/pdf/2310.17383v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17378v2",
            "title": "Optimization dependent generalization bound for ReLU networks based on\n  sensitivity in the tangent bundle",
            "updated": "2023-12-04T15:57:40Z",
            "published": "2023-10-26T13:14:13Z",
            "summary": "Recent advances in deep learning have given us some very promising results on\nthe generalization ability of deep neural networks, however literature still\nlacks a comprehensive theory explaining why heavily over-parametrized models\nare able to generalize well while fitting the training data. In this paper we\npropose a PAC type bound on the generalization error of feedforward ReLU\nnetworks via estimating the Rademacher complexity of the set of networks\navailable from an initial parameter vector via gradient descent. The key idea\nis to bound the sensitivity of the network's gradient to perturbation of the\ninput data along the optimization trajectory. The obtained bound does not\nexplicitly depend on the depth of the network. Our results are experimentally\nverified on the MNIST and CIFAR-10 datasets.",
            "author": [
                "D\u00e1niel R\u00e1cz",
                "Mih\u00e1ly Petreczky",
                "Andr\u00e1s Csert\u00e1n",
                "B\u00e1lint Dar\u00f3czy"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17378v2",
                "http://arxiv.org/pdf/2310.17378v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "68",
                "I.2.6"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17376v1",
            "title": "A Risk Management Perspective on Statistical Estimation and Generalized\n  Variational Inference",
            "updated": "2023-10-26T13:13:50Z",
            "published": "2023-10-26T13:13:50Z",
            "summary": "Generalized variational inference (GVI) provides an optimization-theoretic\nframework for statistical estimation that encapsulates many traditional\nestimation procedures. The typical GVI problem is to compute a distribution of\nparameters that maximizes the expected payoff minus the divergence of the\ndistribution from a specified prior. In this way, GVI enables likelihood-free\nestimation with the ability to control the influence of the prior by tuning the\nso-called learning rate. Recently, GVI was shown to outperform traditional\nBayesian inference when the model and prior distribution are misspecified. In\nthis paper, we introduce and analyze a new GVI formulation based on utility\ntheory and risk management. Our formulation is to maximize the expected payoff\nwhile enforcing constraints on the maximizing distribution. We recover the\noriginal GVI distribution by choosing the feasible set to include a constraint\non the divergence of the distribution from the prior. In doing so, we\nautomatically determine the learning rate as the Lagrange multiplier for the\nconstraint. In this setting, we are able to transform the infinite-dimensional\nestimation problem into a two-dimensional convex program. This reformulation\nfurther provides an analytic expression for the optimal density of parameters.\nIn addition, we prove asymptotic consistency results for empirical\napproximations of our optimal distributions. Throughout, we draw connections\nbetween our estimation procedure and risk management. In fact, we demonstrate\nthat our estimation procedure is equivalent to evaluating a risk measure. We\ntest our procedure on an estimation problem with a misspecified model and prior\ndistribution, and conclude with some extensions of our approach.",
            "author": [
                "Aurya S. Javeed",
                "Drew P. Kouri",
                "Thomas M. Surowiec"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17376v1",
                "http://arxiv.org/pdf/2310.17376v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "math.PR",
                "math.ST",
                "stat.TH",
                "62A10, 62A15, 62C12, 62G05, 62G07"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17373v1",
            "title": "FMMRec: Fairness-aware Multimodal Recommendation",
            "updated": "2023-10-26T13:10:59Z",
            "published": "2023-10-26T13:10:59Z",
            "summary": "Recently, multimodal recommendations have gained increasing attention for\neffectively addressing the data sparsity problem by incorporating\nmodality-based representations. Although multimodal recommendations excel in\naccuracy, the introduction of different modalities (e.g., images, text, and\naudio) may expose more users' sensitive information (e.g., gender and age) to\nrecommender systems, resulting in potentially more serious unfairness issues.\nDespite many efforts on fairness, existing fairness-aware methods are either\nincompatible with multimodal scenarios, or lead to suboptimal fairness\nperformance due to neglecting sensitive information of multimodal content. To\nachieve counterfactual fairness in multimodal recommendations, we propose a\nnovel fairness-aware multimodal recommendation approach (dubbed as FMMRec) to\ndisentangle the sensitive and non-sensitive information from modal\nrepresentations and leverage the disentangled modal representations to guide\nfairer representation learning. Specifically, we first disentangle biased and\nfiltered modal representations by maximizing and minimizing their sensitive\nattribute prediction ability respectively. With the disentangled modal\nrepresentations, we mine the modality-based unfair and fair (corresponding to\nbiased and filtered) user-user structures for enhancing explicit user\nrepresentation with the biased and filtered neighbors from the corresponding\nstructures, followed by adversarially filtering out sensitive information.\nExperiments on two real-world public datasets demonstrate the superiority of\nour FMMRec relative to the state-of-the-art baselines. Our source code is\navailable at https://anonymous.4open.science/r/FMMRec.",
            "author": [
                "Weixin Chen",
                "Li Chen",
                "Yongxin Ni",
                "Yuhan Zhao",
                "Fajie Yuan",
                "Yongfeng Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17373v1",
                "http://arxiv.org/pdf/2310.17373v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17368v1",
            "title": "Leveraging Contextual Information for Robustness in Vehicle Routing\n  Problems",
            "updated": "2023-10-26T12:59:21Z",
            "published": "2023-10-26T12:59:21Z",
            "summary": "We investigate the benefit of using contextual information in data-driven\ndemand predictions to solve the robust capacitated vehicle routing problem with\ntime windows. Instead of estimating the demand distribution or its mean, we\nintroduce contextual machine learning models that predict demand quantiles even\nwhen the number of historical observations for some or all customers is\nlimited. We investigate the use of such predicted quantiles to make routing\ndecisions, comparing deterministic with robust optimization models.\nFurthermore, we evaluate the efficiency and robustness of the decisions\nobtained, both using exact or heuristic methods to solve the optimization\nmodels. Our extensive computational experiments show that using a robust\noptimization model and predicting multiple quantiles is promising when\nsubstantial historical data is available. In scenarios with a limited demand\nhistory, using a deterministic model with just a single quantile exhibits\ngreater potential. Interestingly, our results also indicate that the use of\nappropriate quantile demand values within a deterministic model results in\nsolutions with robustness levels comparable to those of robust models. This is\nimportant because, in most applications, practitioners use deterministic models\nas the industry standard, even in an uncertain environment. Furthermore, as\nthey present fewer computational challenges and require only a single demand\nvalue prediction, deterministic models paired with an appropriate machine\nlearning model hold the potential for robust decision-making.",
            "author": [
                "Ali \u0130rfan Mahmuto\u011fullar\u0131",
                "Tias Guns"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17368v1",
                "http://arxiv.org/pdf/2310.17368v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17360v1",
            "title": "Towards Unifying Diffusion Models for Probabilistic Spatio-Temporal\n  Graph Learning",
            "updated": "2023-10-26T12:48:43Z",
            "published": "2023-10-26T12:48:43Z",
            "summary": "Spatio-temporal graph learning is a fundamental problem in the Web of Things\nera, which enables a plethora of Web applications such as smart cities, human\nmobility and climate analysis. Existing approaches tackle different learning\ntasks independently, tailoring their models to unique task characteristics.\nThese methods, however, fall short of modeling intrinsic uncertainties in the\nspatio-temporal data. Meanwhile, their specialized designs limit their\nuniversality as general spatio-temporal learning solutions. In this paper, we\npropose to model the learning tasks in a unified perspective, viewing them as\npredictions based on conditional information with shared spatio-temporal\npatterns. Based on this proposal, we introduce Unified Spatio-Temporal\nDiffusion Models (USTD) to address the tasks uniformly within the\nuncertainty-aware diffusion framework. USTD is holistically designed,\ncomprising a shared spatio-temporal encoder and attention-based denoising\nnetworks that are task-specific. The shared encoder, optimized by a\npre-training strategy, effectively captures conditional spatio-temporal\npatterns. The denoising networks, utilizing both cross- and self-attention,\nintegrate conditional dependencies and generate predictions. Opting for\nforecasting and kriging as downstream tasks, we design Gated Attention (SGA)\nand Temporal Gated Attention (TGA) for each task, with different emphases on\nthe spatial and temporal dimensions, respectively. By combining the advantages\nof deterministic encoders and probabilistic diffusion models, USTD achieves\nstate-of-the-art performances compared to deterministic and probabilistic\nbaselines in both tasks, while also providing valuable uncertainty estimates.",
            "author": [
                "Junfeng Hu",
                "Xu Liu",
                "Zhencheng Fan",
                "Yuxuan Liang",
                "Roger Zimmermann"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17360v1",
                "http://arxiv.org/pdf/2310.17360v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17359v1",
            "title": "SE(3) Diffusion Model-based Point Cloud Registration for Robust 6D\n  Object Pose Estimation",
            "updated": "2023-10-26T12:47:26Z",
            "published": "2023-10-26T12:47:26Z",
            "summary": "In this paper, we introduce an SE(3) diffusion model-based point cloud\nregistration framework for 6D object pose estimation in real-world scenarios.\nOur approach formulates the 3D registration task as a denoising diffusion\nprocess, which progressively refines the pose of the source point cloud to\nobtain a precise alignment with the model point cloud. Training our framework\ninvolves two operations: An SE(3) diffusion process and an SE(3) reverse\nprocess. The SE(3) diffusion process gradually perturbs the optimal rigid\ntransformation of a pair of point clouds by continuously injecting noise\n(perturbation transformation). By contrast, the SE(3) reverse process focuses\non learning a denoising network that refines the noisy transformation\nstep-by-step, bringing it closer to the optimal transformation for accurate\npose estimation. Unlike standard diffusion models used in linear Euclidean\nspaces, our diffusion model operates on the SE(3) manifold. This requires\nexploiting the linear Lie algebra $\\mathfrak{se}(3)$ associated with SE(3) to\nconstrain the transformation transitions during the diffusion and reverse\nprocesses. Additionally, to effectively train our denoising network, we derive\na registration-specific variational lower bound as the optimization objective\nfor model learning. Furthermore, we show that our denoising network can be\nconstructed with a surrogate registration model, making our approach applicable\nto different deep registration networks. Extensive experiments demonstrate that\nour diffusion registration framework presents outstanding pose estimation\nperformance on the real-world TUD-L, LINEMOD, and Occluded-LINEMOD datasets.",
            "author": [
                "Haobo Jiang",
                "Mathieu Salzmann",
                "Zheng Dang",
                "Jin Xie",
                "Jian Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17359v1",
                "http://arxiv.org/pdf/2310.17359v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17356v1",
            "title": "Sky Imager-Based Forecast of Solar Irradiance Using Machine Learning",
            "updated": "2023-10-26T12:44:45Z",
            "published": "2023-10-26T12:44:45Z",
            "summary": "Ahead-of-time forecasting of the output power of power plants is essential\nfor the stability of the electricity grid and ensuring uninterrupted service.\nHowever, forecasting renewable energy sources is difficult due to the chaotic\nbehavior of natural energy sources. This paper presents a new approach to\nestimate short-term solar irradiance from sky images. The~proposed algorithm\nextracts features from sky images and use learning-based techniques to estimate\nthe solar irradiance. The~performance of proposed machine learning (ML)\nalgorithm is evaluated using two publicly available datasets of sky images.\nThe~datasets contain over 350,000 images for an interval of 16 years, from 2004\nto 2020, with the corresponding global horizontal irradiance (GHI) of each\nimage as the ground truth. Compared to the state-of-the-art computationally\nheavy algorithms proposed in the literature, our approach achieves competitive\nresults with much less computational complexity for both nowcasting and\nforecasting up to 4 h ahead of time.",
            "author": [
                "Anas Al-lahham",
                "Obaidah Theeb",
                "Khaled Elalem",
                "Tariq A. Alshawi",
                "Saleh A. Alshebeili"
            ],
            "link": [
                "http://dx.doi.org/10.3390/electronics9101700",
                "http://arxiv.org/abs/2310.17356v1",
                "http://arxiv.org/pdf/2310.17356v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17355v2",
            "title": "Exploring the Trie of Rules: a fast data structure for the\n  representation of association rules",
            "updated": "2023-11-21T13:27:01Z",
            "published": "2023-10-26T12:44:33Z",
            "summary": "Association rule mining techniques can generate a large volume of sequential\ndata when implemented on transactional databases. Extracting insights from a\nlarge set of association rules has been found to be a challenging process. When\nexamining a ruleset, the fundamental question is how to summarise and represent\nmeaningful mined knowledge efficiently. Many algorithms and strategies have\nbeen developed to address issue of knowledge extraction; however, the\neffectiveness of this process can be limited by the data structures. A better\ndata structure can sufficiently affect the speed of the knowledge extraction\nprocess. This paper proposes a novel data structure, called the Trie of rules,\nfor storing a ruleset that is generated by association rule mining. The\nresulting data structure is a prefix-tree graph structure made of pre-mined\nrules. This graph stores the rules as paths within the prefix-tree in a way\nthat similar rules overlay each other. Each node in the tree represents a rule\nwhere a consequent is this node, and an antecedent is a path from this node to\nthe root of the tree. The evaluation showed that the proposed representation\ntechnique is promising. It compresses a ruleset with almost no data loss and\nbenefits in terms of time for basic operations such as searching for a specific\nrule and sorting, which is the base for many knowledge discovery methods.\nMoreover, our method demonstrated a significant improvement in traversing time,\nachieving an 8-fold increase compared to traditional data structures.",
            "author": [
                "Mikhail Kudriavtsev",
                "Marija Bezbradica",
                "Andrew McCarren"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17355v2",
                "http://arxiv.org/pdf/2310.17355v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "I.2.4; H.3.3; E.1"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17353v1",
            "title": "Cultural Adaptation of Recipes",
            "updated": "2023-10-26T12:39:20Z",
            "published": "2023-10-26T12:39:20Z",
            "summary": "Building upon the considerable advances in Large Language Models (LLMs), we\nare now equipped to address more sophisticated tasks demanding a nuanced\nunderstanding of cross-cultural contexts. A key example is recipe adaptation,\nwhich goes beyond simple translation to include a grasp of ingredients,\nculinary techniques, and dietary preferences specific to a given culture. We\nintroduce a new task involving the translation and cultural adaptation of\nrecipes between Chinese and English-speaking cuisines. To support this\ninvestigation, we present CulturalRecipes, a unique dataset comprised of\nautomatically paired recipes written in Mandarin Chinese and English. This\ndataset is further enriched with a human-written and curated test set. In this\nintricate task of cross-cultural recipe adaptation, we evaluate the performance\nof various methods, including GPT-4 and other LLMs, traditional machine\ntranslation, and information retrieval techniques. Our comprehensive analysis\nincludes both automatic and human evaluation metrics. While GPT-4 exhibits\nimpressive abilities in adapting Chinese recipes into English, it still lags\nbehind human expertise when translating English recipes into Chinese. This\nunderscores the multifaceted nature of cultural adaptations. We anticipate that\nthese insights will significantly contribute to future research on\nculturally-aware language models and their practical application in culturally\ndiverse contexts.",
            "author": [
                "Yong Cao",
                "Yova Kementchedjhieva",
                "Ruixiang Cui",
                "Antonia Karamolegkou",
                "Li Zhou",
                "Megan Dare",
                "Lucia Donatelli",
                "Daniel Hershcovich"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17353v1",
                "http://arxiv.org/pdf/2310.17353v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17348v1",
            "title": "Network Intrusion Detection with Edge-Directed Graph Multi-Head\n  Attention Networks",
            "updated": "2023-10-26T12:30:11Z",
            "published": "2023-10-26T12:30:11Z",
            "summary": "A network intrusion usually involves a number of network locations. Data flow\n(including the data generated by intrusion behaviors) among these locations\n(usually represented by IP addresses) naturally forms a graph. Thus, graph\nneural networks (GNNs) have been used in the construction of intrusion\ndetection models in recent years since they have an excellent ability to\ncapture graph topological features of intrusion data flow. However, existing\nGNN models treat node mean aggregation equally in node information aggregation.\nIn reality, the correlations of nodes and their neighbors as well as the linked\nedges are different. Assigning higher weights to nodes and edges with high\nsimilarity can highlight the correlation among them, which will enhance the\naccuracy and expressiveness of the model. To this end, this paper proposes\nnovel Edge-Directed Graph Multi-Head Attention Networks (EDGMAT) for network\nintrusion detection. The proposed EDGMAT model introduces a multi-head\nattention mechanism into the intrusion detection model. Additional weight\nlearning is realized through the combination of a multi-head attention\nmechanism and edge features. Weighted aggregation makes better use of the\nrelationship between different network traffic data. Experimental results on\nfour recent NIDS benchmark datasets show that the performance of EDGMAT in\nterms of weighted F1-Score is significantly better than that of four\nstate-of-the-art models in multi-class detection tasks.",
            "author": [
                "Xiang Li",
                "Jing Zhang",
                "Yali Yuan",
                "Cangqi Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17348v1",
                "http://arxiv.org/pdf/2310.17348v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17342v1",
            "title": "ACT-SQL: In-Context Learning for Text-to-SQL with\n  Automatically-Generated Chain-of-Thought",
            "updated": "2023-10-26T12:16:25Z",
            "published": "2023-10-26T12:16:25Z",
            "summary": "Recently Large Language Models (LLMs) have been proven to have strong\nabilities in various domains and tasks. We study the problem of prompt\ndesigning in the text-to-SQL task and attempt to improve the LLMs' reasoning\nability when generating SQL queries. Besides the trivial few-shot in-context\nlearning setting, we design our chain-of-thought (CoT) prompt with a similar\nmethod to schema linking. We provide a method named ACT-SQL to automatically\ngenerate auto-CoT exemplars and thus the whole process doesn't need manual\nlabeling. Our approach is cost-saving since we only use the LLMs' API call once\nwhen generating one SQL query. Furthermore, we extend our in-context learning\nmethod to the multi-turn text-to-SQL task. The experiment results show that the\nLLMs' performance can benefit from our ACT-SQL approach. Our approach achieves\nSOTA performance on the Spider dev set among existing in-context learning\napproaches.",
            "author": [
                "Hanchong Zhang",
                "Ruisheng Cao",
                "Lu Chen",
                "Hongshen Xu",
                "Kai Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17342v1",
                "http://arxiv.org/pdf/2310.17342v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17341v3",
            "title": "De-novo Chemical Reaction Generation by Means of Temporal Convolutional\n  Neural Networks",
            "updated": "2023-11-01T23:27:13Z",
            "published": "2023-10-26T12:15:56Z",
            "summary": "We present here a combination of two networks, Recurrent Neural Networks\n(RNN) and Temporarily Convolutional Neural Networks (TCN) in de novo reaction\ngeneration using the novel Reaction Smiles-like representation of reactions\n(CGRSmiles) with atom mapping directly incorporated. Recurrent Neural Networks\nare known for their autoregressive properties and are frequently used in\nlanguage modelling with direct application to SMILES generation. The relatively\nnovel TCNs possess similar properties with wide receptive field while obeying\nthe causality required for natural language processing (NLP). The combination\nof both latent representations expressed through TCN and RNN results in an\noverall better performance compared to RNN alone. Additionally, it is shown\nthat different fine-tuning protocols have a profound impact on generative scope\nof the model when applied on a dataset of interest via transfer learning.",
            "author": [
                "Andrei Buin",
                "Hung Yi Chiang",
                "S. Andrew Gadsden",
                "Faraz A. Alderson"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17341v3",
                "http://arxiv.org/pdf/2310.17341v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17335v1",
            "title": "A multi-artifact EEG denoising by frequency-based deep learning",
            "updated": "2023-10-26T12:01:47Z",
            "published": "2023-10-26T12:01:47Z",
            "summary": "Electroencephalographic (EEG) signals are fundamental to neuroscience\nresearch and clinical applications such as brain-computer interfaces and\nneurological disorder diagnosis. These signals are typically a combination of\nneurological activity and noise, originating from various sources, including\nphysiological artifacts like ocular and muscular movements. Under this setting,\nwe tackle the challenge of distinguishing neurological activity from\nnoise-related sources. We develop a novel EEG denoising model that operates in\nthe frequency domain, leveraging prior knowledge about noise spectral features\nto adaptively compute optimal convolutional filters for noise separation. The\nmodel is trained to learn an empirical relationship connecting the spectral\ncharacteristics of noise and noisy signal to a non-linear transformation which\nallows signal denoising. Performance evaluation on the EEGdenoiseNet dataset\nshows that the proposed model achieves optimal results according to both\ntemporal and spectral metrics. The model is found to remove physiological\nartifacts from input EEG data, thus achieving effective EEG denoising. Indeed,\nthe model performance either matches or outperforms that achieved by benchmark\nmodels, proving to effectively remove both muscle and ocular artifacts without\nthe need to perform any training on the particular type of artifact.",
            "author": [
                "Matteo Gabardi",
                "Aurora Saibene",
                "Francesca Gasparini",
                "Daniele Rizzo",
                "Fabio Antonio Stella"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17335v1",
                "http://arxiv.org/pdf/2310.17335v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17332v1",
            "title": "On Forecast Stability",
            "updated": "2023-10-26T11:55:30Z",
            "published": "2023-10-26T11:55:30Z",
            "summary": "Forecasts are typically not produced in a vacuum but in a business context,\nwhere forecasts are generated on a regular basis and interact with each other.\nFor decisions, it may be important that forecasts do not change arbitrarily,\nand are stable in some sense. However, this area has received only limited\nattention in the forecasting literature. In this paper, we explore two types of\nforecast stability that we call vertical stability and horizontal stability.\nThe existing works in the literature are only applicable to certain base models\nand extending these frameworks to be compatible with any base model is not\nstraightforward. Furthermore, these frameworks can only stabilise the forecasts\nvertically. To fill this gap, we propose a simple linear-interpolation-based\napproach that is applicable to stabilise the forecasts provided by any base\nmodel vertically and horizontally. The approach can produce both accurate and\nstable forecasts. Using N-BEATS, Pooled Regression and LightGBM as the base\nmodels, in our evaluation on four publicly available datasets, the proposed\nframework is able to achieve significantly higher stability and/or accuracy\ncompared to a set of benchmarks including a state-of-the-art forecast\nstabilisation method across three error metrics and six stability metrics.",
            "author": [
                "Rakshitha Godahewa",
                "Christoph Bergmeir",
                "Zeynep Erkin Baz",
                "Chengjun Zhu",
                "Zhangdi Song",
                "Salvador Garc\u00eda",
                "Dario Benavides"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17332v1",
                "http://arxiv.org/pdf/2310.17332v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17330v1",
            "title": "CQM: Curriculum Reinforcement Learning with a Quantized World Model",
            "updated": "2023-10-26T11:50:58Z",
            "published": "2023-10-26T11:50:58Z",
            "summary": "Recent curriculum Reinforcement Learning (RL) has shown notable progress in\nsolving complex tasks by proposing sequences of surrogate tasks. However, the\nprevious approaches often face challenges when they generate curriculum goals\nin a high-dimensional space. Thus, they usually rely on manually specified goal\nspaces. To alleviate this limitation and improve the scalability of the\ncurriculum, we propose a novel curriculum method that automatically defines the\nsemantic goal space which contains vital information for the curriculum\nprocess, and suggests curriculum goals over it. To define the semantic goal\nspace, our method discretizes continuous observations via vector\nquantized-variational autoencoders (VQ-VAE) and restores the temporal relations\nbetween the discretized observations by a graph. Concurrently, ours suggests\nuncertainty and temporal distance-aware curriculum goals that converges to the\nfinal goals over the automatically composed goal space. We demonstrate that the\nproposed method allows efficient explorations in an uninformed environment with\nraw goal examples only. Also, ours outperforms the state-of-the-art curriculum\nRL methods on data efficiency and performance, in various goal-reaching tasks\neven with ego-centric visual inputs.",
            "author": [
                "Seungjae Lee",
                "Daesol Cho",
                "Jonghae Park",
                "H. Jin Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17330v1",
                "http://arxiv.org/pdf/2310.17330v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17326v1",
            "title": "Studies of $\u03b7$ and $\u03b7'$ production in $pp$ and $p$Pb collisions",
            "updated": "2023-10-26T11:45:11Z",
            "published": "2023-10-26T11:45:11Z",
            "summary": "The production of $\\eta$ and $\\eta'$ mesons is studied in proton-proton and\nproton-lead collisions collected with the LHCb detector. Proton-proton\ncollisions are studied at center-of-mass energies of $5.02$ and $13~{\\rm TeV}$,\nand proton-lead collisions are studied at a center-of-mass energy per nucleon\nof $8.16~{\\rm TeV}$. The studies are performed in center-of-mass rapidity\nregions $2.5<y_{\\rm c.m.}<3.5$ (forward rapidity) and $-4.0<y_{\\rm c.m.}<-3.0$\n(backward rapidity) defined relative to the proton beam direction. The $\\eta$\nand $\\eta'$ production cross sections are measured differentially as a function\nof transverse momentum for $1.5<p_{\\rm T}<10~{\\rm GeV}$ and $3<p_{\\rm\nT}<10~{\\rm GeV}$, respectively. The differential cross sections are used to\ncalculate nuclear modification factors. The nuclear modification factors for\n$\\eta$ and $\\eta'$ mesons agree at both forward and backward rapidity, showing\nno significant evidence of mass dependence. The differential cross sections of\n$\\eta$ mesons are also used to calculate $\\eta/\\pi^0$ cross section ratios,\nwhich show evidence of a deviation from the world average. These studies offer\nnew constraints on mass-dependent nuclear effects in heavy-ion collisions, as\nwell as $\\eta$ and $\\eta'$ meson fragmentation.",
            "author": [
                "LHCb collaboration",
                "R. Aaij",
                "A. S. W. Abdelmotteleb",
                "C. Abellan Beteta",
                "F. Abudin\u00e9n",
                "T. Ackernley",
                "B. Adeva",
                "M. Adinolfi",
                "P. Adlarson",
                "C. Agapopoulou",
                "C. A. Aidala",
                "Z. Ajaltouni",
                "S. Akar",
                "K. Akiba",
                "P. Albicocco",
                "J. Albrecht",
                "F. Alessio",
                "M. Alexander",
                "A. Alfonso Albero",
                "Z. Aliouche",
                "P. Alvarez Cartelle",
                "R. Amalric",
                "S. Amato",
                "J. L. Amey",
                "Y. Amhis",
                "L. An",
                "L. Anderlini",
                "M. Andersson",
                "A. Andreianov",
                "P. Andreola",
                "M. Andreotti",
                "D. Andreou",
                "A. A. Anelli",
                "D. Ao",
                "F. Archilli",
                "M. Argenton",
                "S. Arguedas Cuendis",
                "A. Artamonov",
                "M. Artuso",
                "E. Aslanides",
                "M. Atzeni",
                "B. Audurier",
                "D. Bacher",
                "I. Bachiller Perea",
                "S. Bachmann",
                "M. Bachmayer",
                "J. J. Back",
                "A. Bailly-reyre",
                "P. Baladron Rodriguez",
                "V. Balagura",
                "W. Baldini",
                "J. Baptista de Souza Leite",
                "M. Barbetti",
                "I. R. Barbosa",
                "R. J. Barlow",
                "S. Barsuk",
                "W. Barter",
                "M. Bartolini",
                "F. Baryshnikov",
                "J. M. Basels",
                "G. Bassi",
                "B. Batsukh",
                "A. Battig",
                "A. Bay",
                "A. Beck",
                "M. Becker",
                "F. Bedeschi",
                "I. B. Bediaga",
                "A. Beiter",
                "S. Belin",
                "V. Bellee",
                "K. Belous",
                "I. Belov",
                "I. Belyaev",
                "G. Benane",
                "G. Bencivenni",
                "E. Ben-Haim",
                "A. Berezhnoy",
                "R. Bernet",
                "S. Bernet Andres",
                "H. C. Bernstein",
                "C. Bertella",
                "A. Bertolin",
                "C. Betancourt",
                "F. Betti",
                "J. Bex",
                "Ia. Bezshyiko",
                "J. Bhom",
                "M. S. Bieker",
                "N. V. Biesuz",
                "P. Billoir",
                "A. Biolchini",
                "M. Birch",
                "F. C. R. Bishop",
                "A. Bitadze",
                "A. Bizzeti",
                "M. P. Blago",
                "T. Blake",
                "F. Blanc",
                "J. E. Blank",
                "S. Blusk",
                "D. Bobulska",
                "V. Bocharnikov",
                "J. A. Boelhauve",
                "O. Boente Garcia",
                "T. Boettcher",
                "A. Bohare",
                "A. Boldyrev",
                "C. S. Bolognani",
                "R. Bolzonella",
                "N. Bondar",
                "F. Borgato",
                "S. Borghi",
                "M. Borsato",
                "J. T. Borsuk",
                "S. A. Bouchiba",
                "T. J. V. Bowcock",
                "A. Boyer",
                "C. Bozzi",
                "M. J. Bradley",
                "S. Braun",
                "A. Brea Rodriguez",
                "N. Breer",
                "J. Brodzicka",
                "A. Brossa Gonzalo",
                "J. Brown",
                "D. Brundu",
                "A. Buonaura",
                "L. Buonincontri",
                "A. T. Burke",
                "C. Burr",
                "A. Bursche",
                "A. Butkevich",
                "J. S. Butter",
                "J. Buytaert",
                "W. Byczynski",
                "S. Cadeddu",
                "H. Cai",
                "R. Calabrese",
                "L. Calefice",
                "S. Cali",
                "M. Calvi",
                "M. Calvo Gomez",
                "J. Cambon Bouzas",
                "P. Campana",
                "D. H. Campora Perez",
                "A. F. Campoverde Quezada",
                "S. Capelli",
                "L. Capriotti",
                "R. Caravaca-Mora",
                "A. Carbone",
                "L. Carcedo Salgado",
                "R. Cardinale",
                "A. Cardini",
                "P. Carniti",
                "L. Carus",
                "A. Casais Vidal",
                "R. Caspary",
                "G. Casse",
                "J. Castro Godinez",
                "M. Cattaneo",
                "G. Cavallero",
                "V. Cavallini",
                "S. Celani",
                "J. Cerasoli",
                "D. Cervenkov",
                "S. Cesare",
                "A. J. Chadwick",
                "I. Chahrour",
                "M. Charles",
                "Ph. Charpentier",
                "C. A. Chavez Barajas",
                "M. Chefdeville",
                "C. Chen",
                "S. Chen",
                "A. Chernov",
                "S. Chernyshenko",
                "V. Chobanova",
                "S. Cholak",
                "M. Chrzaszcz",
                "A. Chubykin",
                "V. Chulikov",
                "P. Ciambrone",
                "M. F. Cicala",
                "X. Cid Vidal",
                "G. Ciezarek",
                "P. Cifra",
                "P. E. L. Clarke",
                "M. Clemencic",
                "H. V. Cliff",
                "J. Closier",
                "J. L. Cobbledick",
                "C. Cocha Toapaxi",
                "V. Coco",
                "J. Cogan",
                "E. Cogneras",
                "L. Cojocariu",
                "P. Collins",
                "T. Colombo",
                "A. Comerma-Montells",
                "L. Congedo",
                "A. Contu",
                "N. Cooke",
                "I. Corredoira",
                "A. Correia",
                "G. Corti",
                "J. J. Cottee Meldrum",
                "B. Couturier",
                "D. C. Craik",
                "M. Cruz Torres",
                "R. Currie",
                "C. L. Da Silva",
                "S. Dadabaev",
                "L. Dai",
                "X. Dai",
                "E. Dall'Occo",
                "J. Dalseno",
                "C. D'Ambrosio",
                "J. Daniel",
                "A. Danilina",
                "P. d'Argent",
                "A. Davidson",
                "J. E. Davies",
                "A. Davis",
                "O. De Aguiar Francisco",
                "C. De Angelis",
                "J. de Boer",
                "K. De Bruyn",
                "S. De Capua",
                "M. De Cian",
                "U. De Freitas Carneiro Da Graca",
                "E. De Lucia",
                "J. M. De Miranda",
                "L. De Paula",
                "M. De Serio",
                "D. De Simone",
                "P. De Simone",
                "F. De Vellis",
                "J. A. de Vries",
                "F. Debernardis",
                "D. Decamp",
                "V. Dedu",
                "L. Del Buono",
                "B. Delaney",
                "H. -P. Dembinski",
                "J. Deng",
                "V. Denysenko",
                "O. Deschamps",
                "F. Dettori",
                "B. Dey",
                "P. Di Nezza",
                "I. Diachkov",
                "S. Didenko",
                "S. Ding",
                "V. Dobishuk",
                "A. D. Docheva",
                "A. Dolmatov",
                "C. Dong",
                "A. M. Donohoe",
                "F. Dordei",
                "A. C. dos Reis",
                "L. Douglas",
                "A. G. Downes",
                "W. Duan",
                "P. Duda",
                "M. W. Dudek",
                "L. Dufour",
                "V. Duk",
                "P. Durante",
                "M. M. Duras",
                "J. M. Durham",
                "A. Dziurda",
                "A. Dzyuba",
                "S. Easo",
                "E. Eckstein",
                "U. Egede",
                "A. Egorychev",
                "V. Egorychev",
                "C. Eirea Orro",
                "S. Eisenhardt",
                "E. Ejopu",
                "S. Ek-In",
                "L. Eklund",
                "M. Elashri",
                "J. Ellbracht",
                "S. Ely",
                "A. Ene",
                "E. Epple",
                "S. Escher",
                "J. Eschle",
                "S. Esen",
                "T. Evans",
                "F. Fabiano",
                "L. N. Falcao",
                "Y. Fan",
                "B. Fang",
                "L. Fantini",
                "M. Faria",
                "K. Farmer",
                "D. Fazzini",
                "L. Felkowski",
                "M. Feng",
                "M. Feo",
                "M. Fernandez Gomez",
                "A. D. Fernez",
                "F. Ferrari",
                "F. Ferreira Rodrigues",
                "S. Ferreres Sole",
                "M. Ferrillo",
                "M. Ferro-Luzzi",
                "S. Filippov",
                "R. A. Fini",
                "M. Fiorini",
                "M. Firlej",
                "K. M. Fischer",
                "D. S. Fitzgerald",
                "C. Fitzpatrick",
                "T. Fiutowski",
                "F. Fleuret",
                "M. Fontana",
                "F. Fontanelli",
                "L. F. Foreman",
                "R. Forty",
                "D. Foulds-Holt",
                "M. Franco Sevilla",
                "M. Frank",
                "E. Franzoso",
                "G. Frau",
                "C. Frei",
                "D. A. Friday",
                "L. Frontini",
                "J. Fu",
                "Q. Fuehring",
                "Y. Fujii",
                "T. Fulghesu",
                "E. Gabriel",
                "G. Galati",
                "M. D. Galati",
                "A. Gallas Torreira",
                "D. Galli",
                "S. Gambetta",
                "M. Gandelman",
                "P. Gandini",
                "H. Gao",
                "R. Gao",
                "Y. Gao",
                "Y. Gao",
                "Y. Gao",
                "M. Garau",
                "L. M. Garcia Martin",
                "P. Garcia Moreno",
                "J. Garc\u00eda Pardi\u00f1as",
                "B. Garcia Plana",
                "K. G. Garg",
                "L. Garrido",
                "C. Gaspar",
                "R. E. Geertsema",
                "L. L. Gerken",
                "E. Gersabeck",
                "M. Gersabeck",
                "T. Gershon",
                "Z. Ghorbanimoghaddam",
                "L. Giambastiani",
                "F. I. Giasemis",
                "V. Gibson",
                "H. K. Giemza",
                "A. L. Gilman",
                "M. Giovannetti",
                "A. Giovent\u00f9",
                "P. Gironella Gironell",
                "C. Giugliano",
                "M. A. Giza",
                "E. L. Gkougkousis",
                "F. C. Glaser",
                "V. V. Gligorov",
                "C. G\u00f6bel",
                "E. Golobardes",
                "D. Golubkov",
                "A. Golutvin",
                "A. Gomes",
                "S. Gomez Fernandez",
                "F. Goncalves Abrantes",
                "M. Goncerz",
                "G. Gong",
                "J. A. Gooding",
                "I. V. Gorelov",
                "C. Gotti",
                "J. P. Grabowski",
                "L. A. Granado Cardoso",
                "E. Graug\u00e9s",
                "E. Graverini",
                "L. Grazette",
                "G. Graziani",
                "A. T. Grecu",
                "L. M. Greeven",
                "N. A. Grieser",
                "L. Grillo",
                "S. Gromov",
                "C. Gu",
                "M. Guarise",
                "M. Guittiere",
                "V. Guliaeva",
                "P. A. G\u00fcnther",
                "A. -K. Guseinov",
                "E. Gushchin",
                "Y. Guz",
                "T. Gys",
                "T. Hadavizadeh",
                "C. Hadjivasiliou",
                "G. Haefeli",
                "C. Haen",
                "J. Haimberger",
                "M. Hajheidari",
                "T. Halewood-leagas",
                "M. M. Halvorsen",
                "P. M. Hamilton",
                "J. Hammerich",
                "Q. Han",
                "X. Han",
                "S. Hansmann-Menzemer",
                "L. Hao",
                "N. Harnew",
                "T. Harrison",
                "M. Hartmann",
                "C. Hasse",
                "J. He",
                "K. Heijhoff",
                "F. Hemmer",
                "C. Henderson",
                "R. D. L. Henderson",
                "A. M. Hennequin",
                "K. Hennessy",
                "L. Henry",
                "J. Herd",
                "J. Heuel",
                "A. Hicheur",
                "D. Hill",
                "S. E. Hollitt",
                "J. Horswill",
                "R. Hou",
                "Y. Hou",
                "N. Howarth",
                "J. Hu",
                "J. Hu",
                "W. Hu",
                "X. Hu",
                "W. Huang",
                "W. Hulsbergen",
                "R. J. Hunter",
                "M. Hushchyn",
                "D. Hutchcroft",
                "M. Idzik",
                "D. Ilin",
                "P. Ilten",
                "A. Inglessi",
                "A. Iniukhin",
                "A. Ishteev",
                "K. Ivshin",
                "R. Jacobsson",
                "H. Jage",
                "S. J. Jaimes Elles",
                "S. Jakobsen",
                "E. Jans",
                "B. K. Jashal",
                "A. Jawahery",
                "V. Jevtic",
                "E. Jiang",
                "X. Jiang",
                "Y. Jiang",
                "Y. J. Jiang",
                "M. John",
                "D. Johnson",
                "C. R. Jones",
                "T. P. Jones",
                "S. Joshi",
                "B. Jost",
                "N. Jurik",
                "I. Juszczak",
                "D. Kaminaris",
                "S. Kandybei",
                "Y. Kang",
                "M. Karacson",
                "D. Karpenkov",
                "M. Karpov",
                "A. M. Kauniskangas",
                "J. W. Kautz",
                "F. Keizer",
                "D. M. Keller",
                "M. Kenzie",
                "T. Ketel",
                "A. Khanal",
                "B. Khanji",
                "A. Kharisova",
                "S. Kholodenko",
                "G. Khreich",
                "T. Kirn",
                "V. S. Kirsebom",
                "O. Kitouni",
                "S. Klaver",
                "N. Kleijne",
                "K. Klimaszewski",
                "M. R. Kmiec",
                "S. Koliiev",
                "L. Kolk",
                "A. Konoplyannikov",
                "P. Kopciewicz",
                "P. Koppenburg",
                "M. Korolev",
                "I. Kostiuk",
                "O. Kot",
                "S. Kotriakhova",
                "A. Kozachuk",
                "P. Kravchenko",
                "L. Kravchuk",
                "M. Kreps",
                "S. Kretzschmar",
                "P. Krokovny",
                "W. Krupa",
                "W. Krzemien",
                "J. Kubat",
                "S. Kubis",
                "W. Kucewicz",
                "M. Kucharczyk",
                "V. Kudryavtsev",
                "E. Kulikova",
                "A. Kupsc",
                "B. K. Kutsenko",
                "D. Lacarrere",
                "A. Lai",
                "A. Lampis",
                "D. Lancierini",
                "C. Landesa Gomez",
                "J. J. Lane",
                "R. Lane",
                "C. Langenbruch",
                "J. Langer",
                "O. Lantwin",
                "T. Latham",
                "F. Lazzari",
                "C. Lazzeroni",
                "R. Le Gac",
                "S. H. Lee",
                "R. Lef\u00e8vre",
                "A. Leflat",
                "S. Legotin",
                "M. Lehuraux",
                "O. Leroy",
                "T. Lesiak",
                "B. Leverington",
                "A. Li",
                "H. Li",
                "K. Li",
                "L. Li",
                "P. Li",
                "P. -R. Li",
                "S. Li",
                "T. Li",
                "T. Li",
                "Y. Li",
                "Y. Li",
                "Z. Li",
                "Z. Lian",
                "X. Liang",
                "C. Lin",
                "T. Lin",
                "R. Lindner",
                "V. Lisovskyi",
                "R. Litvinov",
                "G. Liu",
                "H. Liu",
                "K. Liu",
                "Q. Liu",
                "S. Liu",
                "Y. Liu",
                "Y. Liu",
                "Y. L. Liu",
                "A. Lobo Salvia",
                "A. Loi",
                "J. Lomba Castro",
                "T. Long",
                "J. H. Lopes",
                "A. Lopez Huertas",
                "S. L\u00f3pez Soli\u00f1o",
                "G. H. Lovell",
                "C. Lucarelli",
                "D. Lucchesi",
                "S. Luchuk",
                "M. Lucio Martinez",
                "V. Lukashenko",
                "Y. Luo",
                "A. Lupato",
                "E. Luppi",
                "K. Lynch",
                "X. -R. Lyu",
                "G. M. Ma",
                "R. Ma",
                "S. Maccolini",
                "F. Machefert",
                "F. Maciuc",
                "I. Mackay",
                "L. R. Madhan Mohan",
                "M. M. Madurai",
                "A. Maevskiy",
                "D. Magdalinski",
                "D. Maisuzenko",
                "M. W. Majewski",
                "J. J. Malczewski",
                "S. Malde",
                "B. Malecki",
                "L. Malentacca",
                "A. Malinin",
                "T. Maltsev",
                "G. Manca",
                "G. Mancinelli",
                "C. Mancuso",
                "R. Manera Escalero",
                "D. Manuzzi",
                "D. Marangotto",
                "J. F. Marchand",
                "R. Marchevski",
                "U. Marconi",
                "S. Mariani",
                "C. Marin Benito",
                "J. Marks",
                "A. M. Marshall",
                "P. J. Marshall",
                "G. Martelli",
                "G. Martellotti",
                "L. Martinazzoli",
                "M. Martinelli",
                "D. Martinez Santos",
                "F. Martinez Vidal",
                "A. Massafferri",
                "M. Materok",
                "R. Matev",
                "A. Mathad",
                "V. Matiunin",
                "C. Matteuzzi",
                "K. R. Mattioli",
                "A. Mauri",
                "E. Maurice",
                "J. Mauricio",
                "P. Mayencourt",
                "M. Mazurek",
                "M. McCann",
                "L. Mcconnell",
                "T. H. McGrath",
                "N. T. McHugh",
                "A. McNab",
                "R. McNulty",
                "B. Meadows",
                "P. Medley",
                "G. Meier",
                "D. Melnychuk",
                "M. Merk",
                "A. Merli",
                "L. Meyer Garcia",
                "D. Miao",
                "H. Miao",
                "M. Mikhasenko",
                "D. A. Milanes",
                "A. Minotti",
                "E. Minucci",
                "T. Miralles",
                "S. E. Mitchell",
                "B. Mitreska",
                "D. S. Mitzel",
                "A. Modak",
                "A. M\u00f6dden",
                "R. A. Mohammed",
                "R. D. Moise",
                "S. Mokhnenko",
                "T. Momb\u00e4cher",
                "M. Monk",
                "I. A. Monroy",
                "S. Monteil",
                "A. Morcillo Gomez",
                "G. Morello",
                "M. J. Morello",
                "M. P. Morgenthaler",
                "J. Moron",
                "A. B. Morris",
                "A. G. Morris",
                "R. Mountain",
                "H. Mu",
                "Z. M. Mu",
                "E. Muhammad",
                "F. Muheim",
                "M. Mulder",
                "K. M\u00fcller",
                "F. M{\u0169}noz-Rojas",
                "R. Murta",
                "P. Naik",
                "T. Nakada",
                "R. Nandakumar",
                "T. Nanut",
                "I. Nasteva",
                "M. Needham",
                "N. Neri",
                "S. Neubert",
                "N. Neufeld",
                "P. Neustroev",
                "R. Newcombe",
                "J. Nicolini",
                "D. Nicotra",
                "E. M. Niel",
                "N. Nikitin",
                "P. Nogga",
                "N. S. Nolte",
                "C. Normand",
                "J. Novoa Fernandez",
                "G. Nowak",
                "C. Nunez",
                "H. N. Nur",
                "A. Oblakowska-Mucha",
                "V. Obraztsov",
                "T. Oeser",
                "S. Okamura",
                "R. Oldeman",
                "F. Oliva",
                "M. Olocco",
                "C. J. G. Onderwater",
                "R. H. O'Neil",
                "J. M. Otalora Goicochea",
                "T. Ovsiannikova",
                "P. Owen",
                "A. Oyanguren",
                "O. Ozcelik",
                "K. O. Padeken",
                "B. Pagare",
                "P. R. Pais",
                "T. Pajero",
                "A. Palano",
                "M. Palutan",
                "G. Panshin",
                "L. Paolucci",
                "A. Papanestis",
                "M. Pappagallo",
                "L. L. Pappalardo",
                "C. Pappenheimer",
                "C. Parkes",
                "B. Passalacqua",
                "G. Passaleva",
                "D. Passaro",
                "A. Pastore",
                "M. Patel",
                "J. Patoc",
                "C. Patrignani",
                "C. J. Pawley",
                "A. Pellegrino",
                "M. Pepe Altarelli",
                "S. Perazzini",
                "D. Pereima",
                "A. Pereiro Castro",
                "P. Perret",
                "A. Perro",
                "K. Petridis",
                "A. Petrolini",
                "S. Petrucci",
                "H. Pham",
                "L. Pica",
                "M. Piccini",
                "B. Pietrzyk",
                "G. Pietrzyk",
                "D. Pinci",
                "F. Pisani",
                "M. Pizzichemi",
                "V. Placinta",
                "M. Plo Casasus",
                "F. Polci",
                "M. Poli Lener",
                "A. Poluektov",
                "N. Polukhina",
                "I. Polyakov",
                "E. Polycarpo",
                "S. Ponce",
                "D. Popov",
                "S. Poslavskii",
                "K. Prasanth",
                "C. Prouve",
                "V. Pugatch",
                "V. Puill",
                "G. Punzi",
                "H. R. Qi",
                "W. Qian",
                "N. Qin",
                "S. Qu",
                "R. Quagliani",
                "R. I. Rabadan Trejo",
                "B. Rachwal",
                "J. H. Rademacker",
                "M. Rama",
                "M. Ram\u00edrez Garc\u00eda",
                "M. Ramos Pernas",
                "M. S. Rangel",
                "F. Ratnikov",
                "G. Raven",
                "M. Rebollo De Miguel",
                "F. Redi",
                "J. Reich",
                "F. Reiss",
                "Z. Ren",
                "P. K. Resmi",
                "R. Ribatti",
                "G. R. Ricart",
                "D. Riccardi",
                "S. Ricciardi",
                "K. Richardson",
                "M. Richardson-Slipper",
                "K. Rinnert",
                "P. Robbe",
                "G. Robertson",
                "E. Rodrigues",
                "E. Rodriguez Fernandez",
                "J. A. Rodriguez Lopez",
                "E. Rodriguez Rodriguez",
                "A. Rogovskiy",
                "D. L. Rolf",
                "A. Rollings",
                "P. Roloff",
                "V. Romanovskiy",
                "M. Romero Lamas",
                "A. Romero Vidal",
                "G. Romolini",
                "F. Ronchetti",
                "M. Rotondo",
                "S. R. Roy",
                "M. S. Rudolph",
                "T. Ruf",
                "M. Ruiz Diaz",
                "R. A. Ruiz Fernandez",
                "J. Ruiz Vidal",
                "A. Ryzhikov",
                "J. Ryzka",
                "J. J. Saborido Silva",
                "R. Sadek",
                "N. Sagidova",
                "N. Sahoo",
                "B. Saitta",
                "M. Salomoni",
                "C. Sanchez Gras",
                "I. Sanderswood",
                "R. Santacesaria",
                "C. Santamarina Rios",
                "M. Santimaria",
                "L. Santoro",
                "E. Santovetti",
                "A. Saputi",
                "D. Saranin",
                "G. Sarpis",
                "M. Sarpis",
                "A. Sarti",
                "C. Satriano",
                "A. Satta",
                "M. Saur",
                "D. Savrina",
                "H. Sazak",
                "L. G. Scantlebury Smead",
                "A. Scarabotto",
                "S. Schael",
                "S. Scherl",
                "A. M. Schertz",
                "M. Schiller",
                "H. Schindler",
                "M. Schmelling",
                "B. Schmidt",
                "S. Schmitt",
                "H. Schmitz",
                "O. Schneider",
                "A. Schopper",
                "N. Schulte",
                "S. Schulte",
                "M. H. Schune",
                "R. Schwemmer",
                "G. Schwering",
                "B. Sciascia",
                "A. Sciuccati",
                "S. Sellam",
                "A. Semennikov",
                "M. Senghi Soares",
                "A. Sergi",
                "N. Serra",
                "L. Sestini",
                "A. Seuthe",
                "Y. Shang",
                "D. M. Shangase",
                "M. Shapkin",
                "I. Shchemerov",
                "L. Shchutska",
                "T. Shears",
                "L. Shekhtman",
                "Z. Shen",
                "S. Sheng",
                "V. Shevchenko",
                "B. Shi",
                "E. B. Shields",
                "Y. Shimizu",
                "E. Shmanin",
                "R. Shorkin",
                "J. D. Shupperd",
                "R. Silva Coutinho",
                "G. Simi",
                "S. Simone",
                "N. Skidmore",
                "R. Skuza",
                "T. Skwarnicki",
                "M. W. Slater",
                "J. C. Smallwood",
                "E. Smith",
                "K. Smith",
                "M. Smith",
                "A. Snoch",
                "L. Soares Lavra",
                "M. D. Sokoloff",
                "F. J. P. Soler",
                "A. Solomin",
                "A. Solovev",
                "I. Solovyev",
                "R. Song",
                "Y. Song",
                "Y. Song",
                "Y. S. Song",
                "F. L. Souza De Almeida",
                "B. Souza De Paula",
                "E. Spadaro Norella",
                "E. Spedicato",
                "J. G. Speer",
                "E. Spiridenkov",
                "P. Spradlin",
                "V. Sriskaran",
                "F. Stagni",
                "M. Stahl",
                "S. Stahl",
                "S. Stanislaus",
                "E. N. Stein",
                "O. Steinkamp",
                "O. Stenyakin",
                "H. Stevens",
                "D. Strekalina",
                "Y. Su",
                "F. Suljik",
                "J. Sun",
                "L. Sun",
                "Y. Sun",
                "P. N. Swallow",
                "K. Swientek",
                "F. Swystun",
                "A. Szabelski",
                "T. Szumlak",
                "M. Szymanski",
                "Y. Tan",
                "S. Taneja",
                "M. D. Tat",
                "A. Terentev",
                "F. Terzuoli",
                "F. Teubert",
                "E. Thomas",
                "D. J. D. Thompson",
                "H. Tilquin",
                "V. Tisserand",
                "S. T'Jampens",
                "M. Tobin",
                "L. Tomassetti",
                "G. Tonani",
                "X. Tong",
                "D. Torres Machado",
                "L. Toscano",
                "D. Y. Tou",
                "C. Trippl",
                "G. Tuci",
                "N. Tuning",
                "L. H. Uecker",
                "A. Ukleja",
                "D. J. Unverzagt",
                "E. Ursov",
                "A. Usachov",
                "A. Ustyuzhanin",
                "U. Uwer",
                "V. Vagnoni",
                "A. Valassi",
                "G. Valenti",
                "N. Valls Canudas",
                "H. Van Hecke",
                "E. van Herwijnen",
                "C. B. Van Hulse",
                "R. Van Laak",
                "M. van Veghel",
                "R. Vazquez Gomez",
                "P. Vazquez Regueiro",
                "C. V\u00e1zquez Sierra",
                "S. Vecchi",
                "J. J. Velthuis",
                "M. Veltri",
                "A. Venkateswaran",
                "M. Vesterinen",
                "D. Vieira",
                "M. Vieites Diaz",
                "X. Vilasis-Cardona",
                "E. Vilella Figueras",
                "A. Villa",
                "P. Vincent",
                "F. C. Volle",
                "D. vom Bruch",
                "V. Vorobyev",
                "N. Voropaev",
                "K. Vos",
                "G. Vouters",
                "C. Vrahas",
                "J. Walsh",
                "E. J. Walton",
                "G. Wan",
                "C. Wang",
                "G. Wang",
                "J. Wang",
                "J. Wang",
                "J. Wang",
                "J. Wang",
                "M. Wang",
                "N. W. Wang",
                "R. Wang",
                "X. Wang",
                "X. W. Wang",
                "Y. Wang",
                "Z. Wang",
                "Z. Wang",
                "Z. Wang",
                "J. A. Ward",
                "N. K. Watson",
                "D. Websdale",
                "Y. Wei",
                "B. D. C. Westhenry",
                "D. J. White",
                "M. Whitehead",
                "A. R. Wiederhold",
                "D. Wiedner",
                "G. Wilkinson",
                "M. K. Wilkinson",
                "M. Williams",
                "M. R. J. Williams",
                "R. Williams",
                "F. F. Wilson",
                "W. Wislicki",
                "M. Witek",
                "L. Witola",
                "C. P. Wong",
                "G. Wormser",
                "S. A. Wotton",
                "H. Wu",
                "J. Wu",
                "Y. Wu",
                "K. Wyllie",
                "S. Xian",
                "Z. Xiang",
                "Y. Xie",
                "A. Xu",
                "J. Xu",
                "L. Xu",
                "L. Xu",
                "M. Xu",
                "Z. Xu",
                "Z. Xu",
                "Z. Xu",
                "D. Yang",
                "S. Yang",
                "X. Yang",
                "Y. Yang",
                "Z. Yang",
                "Z. Yang",
                "V. Yeroshenko",
                "H. Yeung",
                "H. Yin",
                "C. Y. Yu",
                "J. Yu",
                "X. Yuan",
                "E. Zaffaroni",
                "M. Zavertyaev",
                "M. Zdybal",
                "M. Zeng",
                "C. Zhang",
                "D. Zhang",
                "J. Zhang",
                "L. Zhang",
                "S. Zhang",
                "S. Zhang",
                "Y. Zhang",
                "Y. Zhang",
                "Y. Z. Zhang",
                "Y. Zhao",
                "A. Zharkova",
                "A. Zhelezov",
                "X. Z. Zheng",
                "Y. Zheng",
                "T. Zhou",
                "X. Zhou",
                "Y. Zhou",
                "V. Zhovkovska",
                "L. Z. Zhu",
                "X. Zhu",
                "X. Zhu",
                "Z. Zhu",
                "V. Zhukov",
                "J. Zhuo",
                "Q. Zou",
                "D. Zuliani",
                "G. Zunica"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17326v1",
                "http://arxiv.org/pdf/2310.17326v1"
            ],
            "primary_category": "nucl-ex",
            "category": [
                "nucl-ex",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17325v1",
            "title": "C-Disentanglement: Discovering Causally-Independent Generative Factors\n  under an Inductive Bias of Confounder",
            "updated": "2023-10-26T11:44:42Z",
            "published": "2023-10-26T11:44:42Z",
            "summary": "Representation learning assumes that real-world data is generated by a few\nsemantically meaningful generative factors (i.e., sources of variation) and\naims to discover them in the latent space. These factors are expected to be\ncausally disentangled, meaning that distinct factors are encoded into separate\nlatent variables, and changes in one factor will not affect the values of the\nothers. Compared to statistical independence, causal disentanglement allows\nmore controllable data generation, improved robustness, and better\ngeneralization. However, most existing work assumes unconfoundedness in the\ndiscovery process, that there are no common causes to the generative factors\nand thus obtain only statistical independence. In this paper, we recognize the\nimportance of modeling confounders in discovering causal generative factors.\nUnfortunately, such factors are not identifiable without proper inductive bias.\nWe fill the gap by introducing a framework entitled Confounded-Disentanglement\n(C-Disentanglement), the first framework that explicitly introduces the\ninductive bias of confounder via labels from domain expertise. In addition, we\naccordingly propose an approach to sufficiently identify the causally\ndisentangled factors under any inductive bias of the confounder. We conduct\nextensive experiments on both synthetic and real-world datasets. Our method\ndemonstrates competitive results compared to various SOTA baselines in\nobtaining causally disentangled features and downstream tasks under domain\nshifts.",
            "author": [
                "Xiaoyu Liu",
                "Jiaxin Yuan",
                "Bang An",
                "Yuancheng Xu",
                "Yifan Yang",
                "Furong Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17325v1",
                "http://arxiv.org/pdf/2310.17325v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17681v1",
            "title": "Feature Extraction and Classification from Planetary Science Datasets\n  enabled by Machine Learning",
            "updated": "2023-10-26T11:43:55Z",
            "published": "2023-10-26T11:43:55Z",
            "summary": "In this paper we present two examples of recent investigations that we have\nundertaken, applying Machine Learning (ML) neural networks (NN) to image\ndatasets from outer planet missions to achieve feature recognition. Our first\ninvestigation was to recognize ice blocks (also known as rafts, plates,\npolygons) in the chaos regions of fractured ice on Europa. We used a transfer\nlearning approach, adding and training new layers to an industry-standard Mask\nR-CNN (Region-based Convolutional Neural Network) to recognize labeled blocks\nin a training dataset. Subsequently, the updated model was tested against a new\ndataset, achieving 68% precision. In a different application, we applied the\nMask R-CNN to recognize clouds on Titan, again through updated training\nfollowed by testing against new data, with a precision of 95% over 369 images.\nWe evaluate the relative successes of our techniques and suggest how training\nand recognition could be further improved. The new approaches we have used for\nplanetary datasets can further be applied to similar recognition tasks on other\nplanets, including Earth. For imagery of outer planets in particular, the\ntechnique holds the possibility of greatly reducing the volume of returned\ndata, via onboard identification of the most interesting image subsets, or by\nreturning only differential data (images where changes have occurred) greatly\nenhancing the information content of the final data stream.",
            "author": [
                "Conor Nixon",
                "Zachary Yahn",
                "Ethan Duncan",
                "Ian Neidel",
                "Alyssa Mills",
                "Beno\u00eet Seignovert",
                "Andrew Larsen",
                "Kathryn Gansler",
                "Charles Liles",
                "Catherine Walker",
                "Douglas Trent",
                "John Santerre"
            ],
            "link": [
                "http://dx.doi.org/10.1109/AERO55745.2023.10115556",
                "http://arxiv.org/abs/2310.17681v1",
                "http://arxiv.org/pdf/2310.17681v1"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP",
                "astro-ph.IM",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.16122v1",
            "title": "Semantic Generative Augmentations for Few-Shot Counting",
            "updated": "2023-10-26T11:42:48Z",
            "published": "2023-10-26T11:42:48Z",
            "summary": "With the availability of powerful text-to-image diffusion models, recent\nworks have explored the use of synthetic data to improve image classification\nperformances. These works show that it can effectively augment or even replace\nreal data. In this work, we investigate how synthetic data can benefit few-shot\nclass-agnostic counting. This requires to generate images that correspond to a\ngiven input number of objects. However, text-to-image models struggle to grasp\nthe notion of count. We propose to rely on a double conditioning of Stable\nDiffusion with both a prompt and a density map in order to augment a training\ndataset for few-shot counting. Due to the small dataset size, the fine-tuned\nmodel tends to generate images close to the training images. We propose to\nenhance the diversity of synthesized images by exchanging captions between\nimages thus creating unseen configurations of object types and spatial layout.\nOur experiments show that our diversified generation strategy significantly\nimproves the counting accuracy of two recent and performing few-shot counting\nmodels on FSC147 and CARPK.",
            "author": [
                "Perla Doubinsky",
                "Nicolas Audebert",
                "Michel Crucianu",
                "Herv\u00e9 Le Borgne"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16122v1",
                "http://arxiv.org/pdf/2311.16122v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17319v1",
            "title": "Trust Region Methods For Nonconvex Stochastic Optimization Beyond\n  Lipschitz Smoothness",
            "updated": "2023-10-26T11:37:28Z",
            "published": "2023-10-26T11:37:28Z",
            "summary": "In many important machine learning applications, the standard assumption of\nhaving a globally Lipschitz continuous gradient may fail to hold. This paper\ndelves into a more general $(L_0, L_1)$-smoothness setting, which gains\nparticular significance within the realms of deep neural networks and\ndistributionally robust optimization (DRO). We demonstrate the significant\nadvantage of trust region methods for stochastic nonconvex optimization under\nsuch generalized smoothness assumption. We show that first-order trust region\nmethods can recover the normalized and clipped stochastic gradient as special\ncases and then provide a unified analysis to show their convergence to\nfirst-order stationary conditions. Motivated by the important application of\nDRO, we propose a generalized high-order smoothness condition, under which\nsecond-order trust region methods can achieve a complexity of\n$\\mathcal{O}(\\epsilon^{-3.5})$ for convergence to second-order stationary\npoints. By incorporating variance reduction, the second-order trust region\nmethod obtains an even better complexity of $\\mathcal{O}(\\epsilon^{-3})$,\nmatching the optimal bound for standard smooth optimization. To our best\nknowledge, this is the first work to show convergence beyond the first-order\nstationary condition for generalized smooth optimization. Preliminary\nexperiments show that our proposed algorithms perform favorably compared with\nexisting methods.",
            "author": [
                "Chenghan Xie",
                "Chenxi Li",
                "Chuwen Zhang",
                "Qi Deng",
                "Dongdong Ge",
                "Yinyu Ye"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17319v1",
                "http://arxiv.org/pdf/2310.17319v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17306v3",
            "title": "FormaT5: Abstention and Examples for Conditional Table Formatting with\n  Natural Language",
            "updated": "2023-11-01T17:31:30Z",
            "published": "2023-10-26T11:05:15Z",
            "summary": "Formatting is an important property in tables for visualization,\npresentation, and analysis. Spreadsheet software allows users to automatically\nformat their tables by writing data-dependent conditional formatting (CF)\nrules. Writing such rules is often challenging for users as it requires them to\nunderstand and implement the underlying logic. We present FormaT5, a\ntransformer-based model that can generate a CF rule given the target table and\na natural language description of the desired formatting logic. We find that\nuser descriptions for these tasks are often under-specified or ambiguous,\nmaking it harder for code generation systems to accurately learn the desired\nrule in a single step. To tackle this problem of under-specification and\nminimise argument errors, FormaT5 learns to predict placeholders though an\nabstention objective. These placeholders can then be filled by a second model\nor, when examples of rows that should be formatted are available, by a\nprogramming-by-example system. To evaluate FormaT5 on diverse and real\nscenarios, we create an extensive benchmark of 1053 CF tasks, containing\nreal-world descriptions collected from four different sources. We release our\nbenchmarks to encourage research in this area. Abstention and filling allow\nFormaT5 to outperform 8 different neural approaches on our benchmarks, both\nwith and without examples. Our results illustrate the value of building\ndomain-specific learning systems.",
            "author": [
                "Mukul Singh",
                "Jos\u00e9 Cambronero",
                "Sumit Gulwani",
                "Vu Le",
                "Carina Negreanu",
                "Elnaz Nouri",
                "Mohammad Raza",
                "Gust Verbruggen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17306v3",
                "http://arxiv.org/pdf/2310.17306v3"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.DB",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17303v1",
            "title": "Demonstration-Regularized RL",
            "updated": "2023-10-26T10:54:47Z",
            "published": "2023-10-26T10:54:47Z",
            "summary": "Incorporating expert demonstrations has empirically helped to improve the\nsample efficiency of reinforcement learning (RL). This paper quantifies\ntheoretically to what extent this extra information reduces RL's sample\ncomplexity. In particular, we study the demonstration-regularized reinforcement\nlearning that leverages the expert demonstrations by KL-regularization for a\npolicy learned by behavior cloning. Our findings reveal that using\n$N^{\\mathrm{E}}$ expert demonstrations enables the identification of an optimal\npolicy at a sample complexity of order\n$\\widetilde{\\mathcal{O}}(\\mathrm{Poly}(S,A,H)/(\\varepsilon^2 N^{\\mathrm{E}}))$\nin finite and $\\widetilde{\\mathcal{O}}(\\mathrm{Poly}(d,H)/(\\varepsilon^2\nN^{\\mathrm{E}}))$ in linear Markov decision processes, where $\\varepsilon$ is\nthe target precision, $H$ the horizon, $A$ the number of action, $S$ the number\nof states in the finite case and $d$ the dimension of the feature space in the\nlinear case. As a by-product, we provide tight convergence guarantees for the\nbehaviour cloning procedure under general assumptions on the policy classes.\nAdditionally, we establish that demonstration-regularized methods are provably\nefficient for reinforcement learning from human feedback (RLHF). In this\nrespect, we provide theoretical evidence showing the benefits of\nKL-regularization for RLHF in tabular and linear MDPs. Interestingly, we avoid\npessimism injection by employing computationally feasible regularization to\nhandle reward estimation uncertainty, thus setting our approach apart from the\nprior works.",
            "author": [
                "Daniil Tiapkin",
                "Denis Belomestny",
                "Daniele Calandriello",
                "Eric Moulines",
                "Alexey Naumov",
                "Pierre Perrault",
                "Michal Valko",
                "Pierre Menard"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17303v1",
                "http://arxiv.org/pdf/2310.17303v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17293v1",
            "title": "Learning with a linear loss function. Excess risk and estimation bounds\n  for ERM, minmax MOM and their regularized versions. Applications to\n  robustness in sparse PCA",
            "updated": "2023-10-26T10:18:39Z",
            "published": "2023-10-26T10:18:39Z",
            "summary": "Motivated by several examples, we consider a general framework of learning\nwith linear loss functions. In this context, we provide excess risk and\nestimation bounds that hold with large probability for four estimators: ERM,\nminmax MOM and their regularized versions. These general bounds are applied for\nthe problem of robustness in sparse PCA. In particular, we improve the state of\nthe art result for this this problems, obtain results under weak moment\nassumptions as well as for adversarial contaminated data.",
            "author": [
                "Guillaume Lecu\u00e9",
                "Lucie Neirac"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17293v1",
                "http://arxiv.org/pdf/2310.17293v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "stat.TH",
                "62F35"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17284v1",
            "title": "Learning to Abstract with Nonparametric Variational Information\n  Bottleneck",
            "updated": "2023-10-26T10:04:31Z",
            "published": "2023-10-26T10:04:31Z",
            "summary": "Learned representations at the level of characters, sub-words, words and\nsentences, have each contributed to advances in understanding different NLP\ntasks and linguistic phenomena. However, learning textual embeddings is costly\nas they are tokenization specific and require different models to be trained\nfor each level of abstraction. We introduce a novel language representation\nmodel which can learn to compress to different levels of abstraction at\ndifferent layers of the same model. We apply Nonparametric Variational\nInformation Bottleneck (NVIB) to stacked Transformer self-attention layers in\nthe encoder, which encourages an information-theoretic compression of the\nrepresentations through the model. We find that the layers within the model\ncorrespond to increasing levels of abstraction and that their representations\nare more linguistically informed. Finally, we show that NVIB compression\nresults in a model which is more robust to adversarial perturbations.",
            "author": [
                "Melika Behjati",
                "Fabio Fehr",
                "James Henderson"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17284v1",
                "http://arxiv.org/pdf/2310.17284v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17679v1",
            "title": "Fast Scalable and Accurate Discovery of DAGs Using the Best Order Score\n  Search and Grow-Shrink Trees",
            "updated": "2023-10-26T10:03:12Z",
            "published": "2023-10-26T10:03:12Z",
            "summary": "Learning graphical conditional independence structures is an important\nmachine learning problem and a cornerstone of causal discovery. However, the\naccuracy and execution time of learning algorithms generally struggle to scale\nto problems with hundreds of highly connected variables -- for instance,\nrecovering brain networks from fMRI data. We introduce the best order score\nsearch (BOSS) and grow-shrink trees (GSTs) for learning directed acyclic graphs\n(DAGs) in this paradigm. BOSS greedily searches over permutations of variables,\nusing GSTs to construct and score DAGs from permutations. GSTs efficiently\ncache scores to eliminate redundant calculations. BOSS achieves\nstate-of-the-art performance in accuracy and execution time, comparing\nfavorably to a variety of combinatorial and gradient-based learning algorithms\nunder a broad range of conditions. To demonstrate its practicality, we apply\nBOSS to two sets of resting-state fMRI data: simulated data with\npseudo-empirical noise distributions derived from randomized empirical fMRI\ncortical signals and clinical data from 3T fMRI scans processed into cortical\nparcels. BOSS is available for use within the TETRAD project which includes\nPython and R wrappers.",
            "author": [
                "Bryan Andrews",
                "Joseph Ramsey",
                "Ruben Sanchez-Romero",
                "Jazmin Camchong",
                "Erich Kummerfeld"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17679v1",
                "http://arxiv.org/pdf/2310.17679v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17281v1",
            "title": "BEVContrast: Self-Supervision in BEV Space for Automotive Lidar Point\n  Clouds",
            "updated": "2023-10-26T10:02:33Z",
            "published": "2023-10-26T10:02:33Z",
            "summary": "We present a surprisingly simple and efficient method for self-supervision of\n3D backbone on automotive Lidar point clouds. We design a contrastive loss\nbetween features of Lidar scans captured in the same scene. Several such\napproaches have been proposed in the literature from PointConstrast, which uses\na contrast at the level of points, to the state-of-the-art TARL, which uses a\ncontrast at the level of segments, roughly corresponding to objects. While the\nformer enjoys a great simplicity of implementation, it is surpassed by the\nlatter, which however requires a costly pre-processing. In BEVContrast, we\ndefine our contrast at the level of 2D cells in the Bird's Eye View plane.\nResulting cell-level representations offer a good trade-off between the\npoint-level representations exploited in PointContrast and segment-level\nrepresentations exploited in TARL: we retain the simplicity of PointContrast\n(cell representations are cheap to compute) while surpassing the performance of\nTARL in downstream semantic segmentation.",
            "author": [
                "Corentin Sautier",
                "Gilles Puy",
                "Alexandre Boulch",
                "Renaud Marlet",
                "Vincent Lepetit"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17281v1",
                "http://arxiv.org/pdf/2310.17281v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17273v3",
            "title": "Looping in the Human: Collaborative and Explainable Bayesian\n  Optimization",
            "updated": "2023-11-06T19:25:58Z",
            "published": "2023-10-26T09:50:31Z",
            "summary": "Like many optimizers, Bayesian optimization often falls short of gaining user\ntrust due to opacity. While attempts have been made to develop human-centric\noptimizers, they typically assume user knowledge is well-specified and\nerror-free, employing users mainly as supervisors of the optimization process.\nWe relax these assumptions and propose a more balanced human-AI partnership\nwith our Collaborative and Explainable Bayesian Optimization (CoExBO)\nframework. Instead of explicitly requiring a user to provide a knowledge model,\nCoExBO employs preference learning to seamlessly integrate human insights into\nthe optimization, resulting in algorithmic suggestions that resonate with user\npreference. CoExBO explains its candidate selection every iteration to foster\ntrust, empowering users with a clearer grasp of the optimization. Furthermore,\nCoExBO offers a no-harm guarantee, allowing users to make mistakes; even with\nextreme adversarial interventions, the algorithm converges asymptotically to a\nvanilla Bayesian optimization. We validate CoExBO's efficacy through human-AI\nteaming experiments in lithium-ion battery design, highlighting substantial\nimprovements over conventional methods.",
            "author": [
                "Masaki Adachi",
                "Brady Planden",
                "David A. Howey",
                "Krikamol Muandet",
                "Michael A. Osborne",
                "Siu Lun Chau"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17273v3",
                "http://arxiv.org/pdf/2310.17273v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.HC",
                "stat.ML",
                "62C10, 62F15"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17271v1",
            "title": "Understanding the Role of Input Token Characters in Language Models: How\n  Does Information Loss Affect Performance?",
            "updated": "2023-10-26T09:47:50Z",
            "published": "2023-10-26T09:47:50Z",
            "summary": "Understanding how and what pre-trained language models (PLMs) learn about\nlanguage is an open challenge in natural language processing. Previous work has\nfocused on identifying whether they capture semantic and syntactic information,\nand how the data or the pre-training objective affects their performance.\nHowever, to the best of our knowledge, no previous work has specifically\nexamined how information loss in input token characters affects the performance\nof PLMs. In this study, we address this gap by pre-training language models\nusing small subsets of characters from individual tokens. Surprisingly, we find\nthat pre-training even under extreme settings, i.e. using only one character of\neach token, the performance retention in standard NLU benchmarks and probing\ntasks compared to full-token models is high. For instance, a model pre-trained\nonly on single first characters from tokens achieves performance retention of\napproximately $90$\\% and $77$\\% of the full-token model in SuperGLUE and GLUE\ntasks, respectively.",
            "author": [
                "Ahmed Alajrami",
                "Katerina Margatina",
                "Nikolaos Aletras"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17271v1",
                "http://arxiv.org/pdf/2310.17271v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17264v1",
            "title": "Variance of ML-based software fault predictors: are we really improving\n  fault prediction?",
            "updated": "2023-10-26T09:31:32Z",
            "published": "2023-10-26T09:31:32Z",
            "summary": "Software quality assurance activities become increasingly difficult as\nsoftware systems become more and more complex and continuously grow in size.\nMoreover, testing becomes even more expensive when dealing with large-scale\nsystems. Thus, to effectively allocate quality assurance resources, researchers\nhave proposed fault prediction (FP) which utilizes machine learning (ML) to\npredict fault-prone code areas. However, ML algorithms typically make use of\nstochastic elements to increase the prediction models' generalizability and\nefficiency of the training process. These stochastic elements, also known as\nnondeterminism-introducing (NI) factors, lead to variance in the training\nprocess and as a result, lead to variance in prediction accuracy and training\ntime. This variance poses a challenge for reproducibility in research. More\nimportantly, while fault prediction models may have shown good performance in\nthe lab (e.g., often-times involving multiple runs and averaging outcomes),\nhigh variance of results can pose the risk that these models show low\nperformance when applied in practice. In this work, we experimentally analyze\nthe variance of a state-of-the-art fault prediction approach. Our experimental\nresults indicate that NI factors can indeed cause considerable variance in the\nfault prediction models' accuracy. We observed a maximum variance of 10.10% in\nterms of the per-class accuracy metric. We thus, also discuss how to deal with\nsuch variance.",
            "author": [
                "Xhulja Shahini",
                "Domenic Bubel",
                "Andreas Metzger"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17264v1",
                "http://arxiv.org/pdf/2310.17264v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17256v1",
            "title": "fairret: a Framework for Differentiable Fairness Regularization Terms",
            "updated": "2023-10-26T09:13:15Z",
            "published": "2023-10-26T09:13:15Z",
            "summary": "Current tools for machine learning fairness only admit a limited range of\nfairness definitions and have seen little integration with automatic\ndifferentiation libraries, despite the central role these libraries play in\nmodern machine learning pipelines.\n  We introduce a framework of fairness regularization terms (fairrets) which\nquantify bias as modular objectives that are easily integrated in automatic\ndifferentiation pipelines. By employing a general definition of fairness in\nterms of linear-fractional statistics, a wide class of fairrets can be computed\nefficiently. Experiments show the behavior of their gradients and their utility\nin enforcing fairness with minimal loss of predictive power compared to\nbaselines. Our contribution includes a PyTorch implementation of the fairret\nframework.",
            "author": [
                "Maarten Buyl",
                "MaryBeth Defrance",
                "Tijl De Bie"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17256v1",
                "http://arxiv.org/pdf/2310.17256v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17255v2",
            "title": "Generalizing to Unseen Domains in Diabetic Retinopathy Classification",
            "updated": "2023-10-27T04:34:33Z",
            "published": "2023-10-26T09:11:55Z",
            "summary": "Diabetic retinopathy (DR) is caused by long-standing diabetes and is among\nthe fifth leading cause for visual impairments. The process of early diagnosis\nand treatments could be helpful in curing the disease, however, the detection\nprocedure is rather challenging and mostly tedious. Therefore, automated\ndiabetic retinopathy classification using deep learning techniques has gained\ninterest in the medical imaging community. Akin to several other real-world\napplications of deep learning, the typical assumption of i.i.d data is also\nviolated in DR classification that relies on deep learning. Therefore,\ndeveloping DR classification methods robust to unseen distributions is of great\nvalue. In this paper, we study the problem of generalizing a model to unseen\ndistributions or domains (a.k.a domain generalization) in DR classification. To\nthis end, we propose a simple and effective domain generalization (DG) approach\nthat achieves self-distillation in vision transformers (ViT) via a novel\nprediction softening mechanism. This prediction softening is an adaptive convex\ncombination one-hot labels with the model's own knowledge. We perform extensive\nexperiments on challenging open-source DR classification datasets under both\nmulti-source and single-source DG settings with three different ViT backbones\nto establish the efficacy and applicability of our approach against competing\nmethods. For the first time, we report the performance of several\nstate-of-the-art DG methods on open-source DR classification datasets after\nconducting thorough experiments. Finally, our method is also capable of\ndelivering improved calibration performance than other methods, showing its\nsuitability for safety-critical applications, including healthcare. We hope\nthat our contributions would investigate more DG research across the medical\nimaging community.",
            "author": [
                "Chamuditha Jayanga Galappaththige",
                "Gayal Kuruppu",
                "Muhammad Haris Khan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17255v2",
                "http://arxiv.org/pdf/2310.17255v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17253v2",
            "title": "Exactly energy-conserving electromagnetic Particle-in-Cell method in\n  curvilinear coordinates",
            "updated": "2023-10-27T13:06:06Z",
            "published": "2023-10-26T09:06:43Z",
            "summary": "In this paper, we introduce and discuss an exactly energy-conserving\nParticle-in-Cell method for arbitrary curvilinear coordinates. The flexibility\nprovided by curvilinear coordinates enables the study of plasmas in\ncomplex-shaped domains by aligning the grid to the given geometry, or by\nfocusing grid resolution on regions of interest without overresolving the\nsurrounding, potentially uninteresting domain. We have achieved this through\nthe introduction of the metric tensor, the Jacobian matrix, and contravariant\noperators combined with an energy-conserving fully implicit solver. We\ndemonstrate the method's capabilities using a Python implementation to study\nseveral one- and two-dimensional test cases: the electrostatic two-stream\ninstability, the electromagnetic Weibel instability, and the geomagnetic\nenvironment modeling (GEM) reconnection challenge. The test results confirm the\ncapability of our new method to reproduce theoretical expectations (e.g.\ninstability growth rates) and the corresponding results obtained with a\nCartesian uniform grid when using curvilinear grids. Simultaneously, we show\nthat the method conserves energy to machine precision in all cases.",
            "author": [
                "Joost Croonen",
                "Luca Pezzini",
                "Fabio Bacchini",
                "Giovanni Lapenta"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17253v2",
                "http://arxiv.org/pdf/2310.17253v2"
            ],
            "primary_category": "physics.plasm-ph",
            "category": [
                "physics.plasm-ph",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17250v1",
            "title": "IDENAS: Internal Dependency Exploration for Neural Architecture Search",
            "updated": "2023-10-26T08:58:29Z",
            "published": "2023-10-26T08:58:29Z",
            "summary": "Machine learning is a powerful tool for extracting valuable information and\nmaking various predictions from diverse datasets. Traditional algorithms rely\non well-defined input and output variables however, there are scenarios where\nthe distinction between the input and output variables and the underlying,\nassociated (input and output) layers of the model, are unknown. Neural\nArchitecture Search (NAS) and Feature Selection have emerged as promising\nsolutions in such scenarios. This research proposes IDENAS, an Internal\nDependency-based Exploration for Neural Architecture Search, integrating NAS\nwith feature selection. The methodology explores internal dependencies in the\ncomplete parameter space for classification involving 1D sensor and 2D image\ndata as well. IDENAS employs a modified encoder-decoder model and the\nSequential Forward Search (SFS) algorithm, combining input-output configuration\nsearch with embedded feature selection. Experimental results demonstrate\nIDENASs superior performance in comparison to other algorithms, showcasing its\neffectiveness in model development pipelines and automated machine learning. On\naverage, IDENAS achieved significant modelling improvements, underscoring its\nsignificant contribution to advancing the state-of-the-art in neural\narchitecture search and feature selection integration.",
            "author": [
                "Anh T. Hoang",
                "Zsolt J. Viharos"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17250v1",
                "http://arxiv.org/pdf/2310.17250v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.NE",
                "68T07, 68T10, 93A10",
                "I.5.2; I.5.1; I.2.6"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17247v1",
            "title": "Grokking Beyond Neural Networks: An Empirical Exploration with Model\n  Complexity",
            "updated": "2023-10-26T08:47:42Z",
            "published": "2023-10-26T08:47:42Z",
            "summary": "In some settings neural networks exhibit a phenomenon known as grokking,\nwhere they achieve perfect or near-perfect accuracy on the validation set long\nafter the same performance has been achieved on the training set. In this\npaper, we discover that grokking is not limited to neural networks but occurs\nin other settings such as Gaussian process (GP) classification, GP regression\nand linear regression. We also uncover a mechanism by which to induce grokking\non algorithmic datasets via the addition of dimensions containing spurious\ninformation. The presence of the phenomenon in non-neural architectures\nprovides evidence that grokking is not specific to SGD or weight norm\nregularisation. Instead, grokking may be possible in any setting where solution\nsearch is guided by complexity and error. Based on this insight and further\ntrends we see in the training trajectories of a Bayesian neural network (BNN)\nand GP regression model, we make progress towards a more general theory of\ngrokking. Specifically, we hypothesise that the phenomenon is governed by the\naccessibility of certain regions in the error and complexity landscapes.",
            "author": [
                "Jack Miller",
                "Charles O'Neill",
                "Thang Bui"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17247v1",
                "http://arxiv.org/pdf/2310.17247v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17245v1",
            "title": "CROP: Conservative Reward for Model-based Offline Policy Optimization",
            "updated": "2023-10-26T08:45:23Z",
            "published": "2023-10-26T08:45:23Z",
            "summary": "Offline reinforcement learning (RL) aims to optimize policy using collected\ndata without online interactions. Model-based approaches are particularly\nappealing for addressing offline RL challenges due to their capability to\nmitigate the limitations of offline data through data generation using models.\nPrior research has demonstrated that introducing conservatism into the model or\nQ-function during policy optimization can effectively alleviate the prevalent\ndistribution drift problem in offline RL. However, the investigation into the\nimpacts of conservatism in reward estimation is still lacking. This paper\nproposes a novel model-based offline RL algorithm, Conservative Reward for\nmodel-based Offline Policy optimization (CROP), which conservatively estimates\nthe reward in model training. To achieve a conservative reward estimation, CROP\nsimultaneously minimizes the estimation error and the reward of random actions.\nTheoretical analysis shows that this conservative reward mechanism leads to a\nconservative policy evaluation and helps mitigate distribution drift.\nExperiments on D4RL benchmarks showcase that the performance of CROP is\ncomparable to the state-of-the-art baselines. Notably, CROP establishes an\ninnovative connection between offline and online RL, highlighting that offline\nRL problems can be tackled by adopting online RL techniques to the empirical\nMarkov decision process trained with a conservative reward. The source code is\navailable with https://github.com/G0K0URURI/CROP.git.",
            "author": [
                "Hao Li",
                "Xiao-Hu Zhou",
                "Xiao-Liang Xie",
                "Shi-Qi Liu",
                "Zhen-Qiu Feng",
                "Xiao-Yin Liu",
                "Mei-Jiang Gui",
                "Tian-Yu Xiang",
                "De-Xing Huang",
                "Bo-Xian Yao",
                "Zeng-Guang Hou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17245v1",
                "http://arxiv.org/pdf/2310.17245v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17238v1",
            "title": "Joint Entity and Relation Extraction with Span Pruning and Hypergraph\n  Neural Networks",
            "updated": "2023-10-26T08:36:39Z",
            "published": "2023-10-26T08:36:39Z",
            "summary": "Entity and Relation Extraction (ERE) is an important task in information\nextraction. Recent marker-based pipeline models achieve state-of-the-art\nperformance, but still suffer from the error propagation issue. Also, most of\ncurrent ERE models do not take into account higher-order interactions between\nmultiple entities and relations, while higher-order modeling could be\nbeneficial.In this work, we propose HyperGraph neural network for ERE\n($\\hgnn{}$), which is built upon the PL-marker (a state-of-the-art marker-based\npipleline model). To alleviate error propagation,we use a high-recall pruner\nmechanism to transfer the burden of entity identification and labeling from the\nNER module to the joint module of our model. For higher-order modeling, we\nbuild a hypergraph, where nodes are entities (provided by the span pruner) and\nrelations thereof, and hyperedges encode interactions between two different\nrelations or between a relation and its associated subject and object entities.\nWe then run a hypergraph neural network for higher-order inference by applying\nmessage passing over the built hypergraph. Experiments on three widely used\nbenchmarks (\\acef{}, \\ace{} and \\scierc{}) for ERE task show significant\nimprovements over the previous state-of-the-art PL-marker.",
            "author": [
                "Zhaohui Yan",
                "Songlin Yang",
                "Wei Liu",
                "Kewei Tu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17238v1",
                "http://arxiv.org/pdf/2310.17238v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17237v1",
            "title": "A Unified Framework for Rank-based Loss Minimization",
            "updated": "2023-10-26T08:35:32Z",
            "published": "2023-10-26T08:35:32Z",
            "summary": "The empirical loss, commonly referred to as the average loss, is extensively\nutilized for training machine learning models. However, in order to address the\ndiverse performance requirements of machine learning models, the use of the\nrank-based loss is prevalent, replacing the empirical loss in many cases. The\nrank-based loss comprises a weighted sum of sorted individual losses,\nencompassing both convex losses like the spectral risk, which includes the\nempirical risk and conditional value-at-risk, and nonconvex losses such as the\nhuman-aligned risk and the sum of the ranked range loss. In this paper, we\nintroduce a unified framework for the optimization of the rank-based loss\nthrough the utilization of a proximal alternating direction method of\nmultipliers. We demonstrate the convergence and convergence rate of the\nproposed algorithm under mild conditions. Experiments conducted on synthetic\nand real datasets illustrate the effectiveness and efficiency of the proposed\nalgorithm.",
            "author": [
                "Rufeng Xiao",
                "Yuze Ge",
                "Rujun Jiang",
                "Yifan Yan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17237v1",
                "http://arxiv.org/pdf/2310.17237v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17234v1",
            "title": "Computationally Feasible Strategies",
            "updated": "2023-10-26T08:31:02Z",
            "published": "2023-10-26T08:31:02Z",
            "summary": "Real-life agents seldom have unlimited reasoning power. In this paper, we\npropose and study a new formal notion of computationally bounded strategic\nability in multi-agent systems. The notion characterizes the ability of a set\nof agents to synthesize an executable strategy in the form of a Turing machine\nwithin a given complexity class, that ensures the satisfaction of a temporal\nobjective in a parameterized game arena. We show that the new concept induces a\nproper hierarchy of strategic abilities -- in particular, polynomial-time\nabilities are strictly weaker than the exponential-time ones. We also propose\nan ``adaptive'' variant of computational ability which allows for different\nstrategies for each parameter value, and show that the two notions do not\ncoincide. Finally, we define and study the model-checking problem for\ncomputational strategies. We show that the problem is undecidable even for\nseverely restricted inputs, and present our first steps towards decidable\nfragments.",
            "author": [
                "Catalin Dima",
                "Wojciech Jamroga"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17234v1",
                "http://arxiv.org/pdf/2310.17234v1"
            ],
            "primary_category": "cs.MA",
            "category": [
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17233v1",
            "title": "EMMA-X: An EM-like Multilingual Pre-training Algorithm for Cross-lingual\n  Representation Learning",
            "updated": "2023-10-26T08:31:00Z",
            "published": "2023-10-26T08:31:00Z",
            "summary": "Expressing universal semantics common to all languages is helpful in\nunderstanding the meanings of complex and culture-specific sentences. The\nresearch theme underlying this scenario focuses on learning universal\nrepresentations across languages with the usage of massive parallel corpora.\nHowever, due to the sparsity and scarcity of parallel data, there is still a\nbig challenge in learning authentic ``universals'' for any two languages. In\nthis paper, we propose EMMA-X: an EM-like Multilingual pre-training Algorithm,\nto learn (X)Cross-lingual universals with the aid of excessive multilingual\nnon-parallel data. EMMA-X unifies the cross-lingual representation learning\ntask and an extra semantic relation prediction task within an EM framework.\nBoth the extra semantic classifier and the cross-lingual sentence encoder\napproximate the semantic relation of two sentences, and supervise each other\nuntil convergence. To evaluate EMMA-X, we conduct experiments on XRETE, a newly\nintroduced benchmark containing 12 widely studied cross-lingual tasks that\nfully depend on sentence-level representations. Results reveal that EMMA-X\nachieves state-of-the-art performance. Further geometric analysis of the built\nrepresentation space with three requirements demonstrates the superiority of\nEMMA-X over advanced models.",
            "author": [
                "Ping Guo",
                "Xiangpeng Wei",
                "Yue Hu",
                "Baosong Yang",
                "Dayiheng Liu",
                "Fei Huang",
                "Jun Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17233v1",
                "http://arxiv.org/pdf/2310.17233v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17230v1",
            "title": "Codebook Features: Sparse and Discrete Interpretability for Neural\n  Networks",
            "updated": "2023-10-26T08:28:48Z",
            "published": "2023-10-26T08:28:48Z",
            "summary": "Understanding neural networks is challenging in part because of the dense,\ncontinuous nature of their hidden states. We explore whether we can train\nneural networks to have hidden states that are sparse, discrete, and more\ninterpretable by quantizing their continuous features into what we call\ncodebook features. Codebook features are produced by finetuning neural networks\nwith vector quantization bottlenecks at each layer, producing a network whose\nhidden features are the sum of a small number of discrete vector codes chosen\nfrom a larger codebook. Surprisingly, we find that neural networks can operate\nunder this extreme bottleneck with only modest degradation in performance. This\nsparse, discrete bottleneck also provides an intuitive way of controlling\nneural network behavior: first, find codes that activate when the desired\nbehavior is present, then activate those same codes during generation to elicit\nthat behavior. We validate our approach by training codebook Transformers on\nseveral different datasets. First, we explore a finite state machine dataset\nwith far more hidden states than neurons. In this setting, our approach\novercomes the superposition problem by assigning states to distinct codes, and\nwe find that we can make the neural network behave as if it is in a different\nstate by activating the code for that state. Second, we train Transformer\nlanguage models with up to 410M parameters on two natural language datasets. We\nidentify codes in these models representing diverse, disentangled concepts\n(ranging from negative emotions to months of the year) and find that we can\nguide the model to generate different topics by activating the appropriate\ncodes during inference. Overall, codebook features appear to be a promising\nunit of analysis and control for neural networks and interpretability. Our\ncodebase and models are open-sourced at\nhttps://github.com/taufeeque9/codebook-features.",
            "author": [
                "Alex Tamkin",
                "Mohammad Taufeeque",
                "Noah D. Goodman"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17230v1",
                "http://arxiv.org/pdf/2310.17230v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17220v2",
            "title": "Validating Digital Traces with Survey Data: The Use Case of Religiosity",
            "updated": "2023-11-09T13:20:52Z",
            "published": "2023-10-26T08:17:22Z",
            "summary": "This paper tests the validity of a digital trace database (Politus) obtained\nfrom Twitter, with a recently conducted representative social survey, focusing\non the use case of religiosity in Turkey. Religiosity scores in the research\nare extracted using supervised machine learning under the Politus project. The\nvalidation analysis depends on two steps. First, we compare the performances of\ntwo alternative tweet-to-user transformation strategies, and second, test for\nthe impact of resampling via the MRP technique. Estimates of the Politus are\nexamined at both aggregate and region-level. The results are intriguing for\nfuture research on measuring public opinion via social media data.",
            "author": [
                "M. Fuat K\u0131na",
                "Erdem Y\u00f6r\u00fck",
                "Ali H\u00fcrriyeto\u011flu",
                "Melih Can Yard\u0131",
                "\u015e\u00fckr\u00fc Ats\u0131zelti",
                "F\u0131rat Duru\u015fan",
                "O\u011fuz G\u00fcrerk",
                "Tolga Etg\u00fc",
                "Z\u00fcbeyir Ni\u015fanc\u0131",
                "Osman Mutlu",
                "Gizem Bacaks\u0131zlar Turbic",
                "Yusuf Akbulut"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17220v2",
                "http://arxiv.org/pdf/2310.17220v2"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17218v1",
            "title": "Prototypical Contrastive Learning-based CLIP Fine-tuning for Object\n  Re-identification",
            "updated": "2023-10-26T08:12:53Z",
            "published": "2023-10-26T08:12:53Z",
            "summary": "This work aims to adapt large-scale pre-trained vision-language models, such\nas contrastive language-image pretraining (CLIP), to enhance the performance of\nobject reidentification (Re-ID) across various supervision settings. Although\nprompt learning has enabled a recent work named CLIP-ReID to achieve promising\nperformance, the underlying mechanisms and the necessity of prompt learning\nremain unclear due to the absence of semantic labels in ReID tasks. In this\nwork, we first analyze the role prompt learning in CLIP-ReID and identify its\nlimitations. Based on our investigations, we propose a simple yet effective\napproach to adapt CLIP for supervised object Re-ID. Our approach directly\nfine-tunes the image encoder of CLIP using a prototypical contrastive learning\n(PCL) loss, eliminating the need for prompt learning. Experimental results on\nboth person and vehicle Re-ID datasets demonstrate the competitiveness of our\nmethod compared to CLIP-ReID. Furthermore, we extend our PCL-based CLIP\nfine-tuning approach to unsupervised scenarios, where we achieve state-of-the\nart performance.",
            "author": [
                "Jiachen Li",
                "Xiaojin Gong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17218v1",
                "http://arxiv.org/pdf/2310.17218v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17217v1",
            "title": "Beyond MLE: Convex Learning for Text Generation",
            "updated": "2023-10-26T08:08:43Z",
            "published": "2023-10-26T08:08:43Z",
            "summary": "Maximum likelihood estimation (MLE) is a statistical method used to estimate\nthe parameters of a probability distribution that best explain the observed\ndata. In the context of text generation, MLE is often used to train generative\nlanguage models, which can then be used to generate new text. However, we argue\nthat MLE is not always necessary and optimal, especially for closed-ended text\ngeneration tasks like machine translation. In these tasks, the goal of model is\nto generate the most appropriate response, which does not necessarily require\nit to estimate the entire data distribution with MLE. To this end, we propose a\nnovel class of training objectives based on convex functions, which enables\ntext generation models to focus on highly probable outputs without having to\nestimate the entire data distribution. We investigate the theoretical\nproperties of the optimal predicted distribution when applying convex functions\nto the loss, demonstrating that convex functions can sharpen the optimal\ndistribution, thereby enabling the model to better capture outputs with high\nprobabilities. Experiments on various text generation tasks and models show the\neffectiveness of our approach. It enables autoregressive models to bridge the\ngap between greedy and beam search, and facilitates the learning of\nnon-autoregressive models with a maximum improvement of 9+ BLEU points.\nMoreover, our approach also exhibits significant impact on large language\nmodels (LLMs), substantially enhancing their generative capability on various\ntasks. Source code is available at\n\\url{https://github.com/ictnlp/Convex-Learning}.",
            "author": [
                "Chenze Shao",
                "Zhengrui Ma",
                "Min Zhang",
                "Yang Feng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17217v1",
                "http://arxiv.org/pdf/2310.17217v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17216v1",
            "title": "Three-dimensional Bone Image Synthesis with Generative Adversarial\n  Networks",
            "updated": "2023-10-26T08:08:17Z",
            "published": "2023-10-26T08:08:17Z",
            "summary": "Medical image processing has been highlighted as an area where deep\nlearning-based models have the greatest potential. However, in the medical\nfield in particular, problems of data availability and privacy are hampering\nresearch progress and thus rapid implementation in clinical routine. The\ngeneration of synthetic data not only ensures privacy, but also allows to\n\\textit{draw} new patients with specific characteristics, enabling the\ndevelopment of data-driven models on a much larger scale. This work\ndemonstrates that three-dimensional generative adversarial networks (GANs) can\nbe efficiently trained to generate high-resolution medical volumes with finely\ndetailed voxel-based architectures. In addition, GAN inversion is successfully\nimplemented for the three-dimensional setting and used for extensive research\non model interpretability and applications such as image morphing, attribute\nediting and style mixing. The results are comprehensively validated on a\ndatabase of three-dimensional HR-pQCT instances representing the bone\nmicro-architecture of the distal radius.",
            "author": [
                "Christoph Angermann",
                "Johannes Bereiter-Payr",
                "Kerstin Stock",
                "Markus Haltmeier",
                "Gerald Degenhart"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17216v1",
                "http://arxiv.org/pdf/2310.17216v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17209v1",
            "title": "Weakly-Supervised Surgical Phase Recognition",
            "updated": "2023-10-26T07:54:47Z",
            "published": "2023-10-26T07:54:47Z",
            "summary": "A key element of computer-assisted surgery systems is phase recognition of\nsurgical videos. Existing phase recognition algorithms require frame-wise\nannotation of a large number of videos, which is time and money consuming. In\nthis work we join concepts of graph segmentation with self-supervised learning\nto derive a random-walk solution for per-frame phase prediction. Furthermore,\nwe utilize within our method two forms of weak supervision: sparse timestamps\nor few-shot learning. The proposed algorithm enjoys low complexity and can\noperate in lowdata regimes. We validate our method by running experiments with\nthe public Cholec80 dataset of laparoscopic cholecystectomy videos,\ndemonstrating promising performance in multiple setups.",
            "author": [
                "Roy Hirsch",
                "Regev Cohen",
                "Mathilde Caron",
                "Tomer Golany",
                "Daniel Freedman",
                "Ehud Rivlin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17209v1",
                "http://arxiv.org/pdf/2310.17209v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17207v1",
            "title": "Efficient Data Fusion using the Tsetlin Machine",
            "updated": "2023-10-26T07:49:25Z",
            "published": "2023-10-26T07:49:25Z",
            "summary": "We propose a novel way of assessing and fusing noisy dynamic data using a\nTsetlin Machine. Our approach consists in monitoring how explanations in form\nof logical clauses that a TM learns changes with possible noise in dynamic\ndata. This way TM can recognize the noise by lowering weights of previously\nlearned clauses, or reflect it in the form of new clauses. We also perform a\ncomprehensive experimental study using notably different datasets that\ndemonstrated high performance of the proposed approach.",
            "author": [
                "Rupsa Saha",
                "Vladimir I. Zadorozhny",
                "Ole-Christoffer Granmo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17207v1",
                "http://arxiv.org/pdf/2310.17207v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.16121v1",
            "title": "Real-Time Neural Materials using Block-Compressed Features",
            "updated": "2023-10-26T07:45:58Z",
            "published": "2023-10-26T07:45:58Z",
            "summary": "Neural materials typically consist of a collection of neural features along\nwith a decoder network. The main challenge in integrating such models in\nreal-time rendering pipelines lies in the large size required to store their\nfeatures in GPU memory and the complexity of evaluating the network\nefficiently. We present a neural material model whose features and decoder are\nspecifically designed to be used in real-time rendering pipelines. Our\nframework leverages hardware-based block compression (BC) texture formats to\nstore the learned features and trains the model to output the material\ninformation continuously in space and scale. To achieve this, we organize the\nfeatures in a block-based manner and emulate BC6 decompression during training,\nmaking it possible to export them as regular BC6 textures. This structure\nallows us to use high resolution features while maintaining a low memory\nfootprint. Consequently, this enhances our model's overall capability, enabling\nthe use of a lightweight and simple decoder architecture that can be evaluated\ndirectly in a shader. Furthermore, since the learned features can be decoded\ncontinuously, it allows for random uv sampling and smooth transition between\nscales without needing any subsequent filtering. As a result, our neural\nmaterial has a small memory footprint, can be decoded extremely fast adding a\nminimal computational overhead to the rendering pipeline.",
            "author": [
                "Cl\u00e9ment Weinreich",
                "Louis de Oliveira",
                "Antoine Houdard",
                "Georges Nader"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16121v1",
                "http://arxiv.org/pdf/2311.16121v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17202v1",
            "title": "miditok: A Python package for MIDI file tokenization",
            "updated": "2023-10-26T07:37:44Z",
            "published": "2023-10-26T07:37:44Z",
            "summary": "Recent progress in natural language processing has been adapted to the\nsymbolic music modality. Language models, such as Transformers, have been used\nwith symbolic music for a variety of tasks among which music generation,\nmodeling or transcription, with state-of-the-art performances. These models are\nbeginning to be used in production products. To encode and decode music for the\nbackbone model, they need to rely on tokenizers, whose role is to serialize\nmusic into sequences of distinct elements called tokens. MidiTok is an\nopen-source library allowing to tokenize symbolic music with great flexibility\nand extended features. It features the most popular music tokenizations, under\na unified API. It is made to be easily used and extensible for everyone.",
            "author": [
                "Nathan Fradet",
                "Jean-Pierre Briot",
                "Fabien Chhel",
                "Amal El Fallah Seghrouchni",
                "Nicolas Gutowski"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17202v1",
                "http://arxiv.org/pdf/2310.17202v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17200v1",
            "title": "Taming Gradient Variance in Federated Learning with Networked Control\n  Variates",
            "updated": "2023-10-26T07:32:52Z",
            "published": "2023-10-26T07:32:52Z",
            "summary": "Federated learning, a decentralized approach to machine learning, faces\nsignificant challenges such as extensive communication overheads, slow\nconvergence, and unstable improvements. These challenges primarily stem from\nthe gradient variance due to heterogeneous client data distributions. To\naddress this, we introduce a novel Networked Control Variates (FedNCV)\nframework for Federated Learning. We adopt the REINFORCE Leave-One-Out (RLOO)\nas a fundamental control variate unit in the FedNCV framework, implemented at\nboth client and server levels. At the client level, the RLOO control variate is\nemployed to optimize local gradient updates, mitigating the variance introduced\nby data samples. Once relayed to the server, the RLOO-based estimator further\nprovides an unbiased and low-variance aggregated gradient, leading to robust\nglobal updates. This dual-side application is formalized as a linear\ncombination of composite control variates. We provide a mathematical expression\ncapturing this integration of double control variates within FedNCV and present\nthree theoretical results with corresponding proofs. This unique dual structure\nequips FedNCV to address data heterogeneity and scalability issues, thus\npotentially paving the way for large-scale applications. Moreover, we tested\nFedNCV on six diverse datasets under a Dirichlet distribution with {\\alpha} =\n0.1, and benchmarked its performance against six SOTA methods, demonstrating\nits superiority.",
            "author": [
                "Xingyan Chen",
                "Yaling Liu",
                "Huaming Du",
                "Mu Wang",
                "Yu Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17200v1",
                "http://arxiv.org/pdf/2310.17200v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17194v1",
            "title": "Privacy-preserving Representation Learning for Speech Understanding",
            "updated": "2023-10-26T07:20:23Z",
            "published": "2023-10-26T07:20:23Z",
            "summary": "Existing privacy-preserving speech representation learning methods target a\nsingle application domain. In this paper, we present a novel framework to\nanonymize utterance-level speech embeddings generated by pre-trained encoders\nand show its effectiveness for a range of speech classification tasks.\nSpecifically, given the representations from a pre-trained encoder, we train a\nTransformer to estimate the representations for the same utterances spoken by\nother speakers. During inference, the extracted representations can be\nconverted into different identities to preserve privacy. We compare the results\nwith the voice anonymization baselines from the VoicePrivacy 2022 challenge. We\nevaluate our framework on speaker identification for privacy and emotion\nrecognition, depression classification, and intent classification for utility.\nOur method outperforms the baselines on privacy and utility in paralinguistic\ntasks and achieves comparable performance for intent classification.",
            "author": [
                "Minh Tran",
                "Mohammad Soleymani"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17194v1",
                "http://arxiv.org/pdf/2310.17194v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17191v1",
            "title": "How do Language Models Bind Entities in Context?",
            "updated": "2023-10-26T07:10:31Z",
            "published": "2023-10-26T07:10:31Z",
            "summary": "To correctly use in-context information, language models (LMs) must bind\nentities to their attributes. For example, given a context describing a \"green\nsquare\" and a \"blue circle\", LMs must bind the shapes to their respective\ncolors. We analyze LM representations and identify the binding ID mechanism: a\ngeneral mechanism for solving the binding problem, which we observe in every\nsufficiently large model from the Pythia and LLaMA families. Using causal\ninterventions, we show that LMs' internal activations represent binding\ninformation by attaching binding ID vectors to corresponding entities and\nattributes. We further show that binding ID vectors form a continuous subspace,\nin which distances between binding ID vectors reflect their discernability.\nOverall, our results uncover interpretable strategies in LMs for representing\nsymbolic knowledge in-context, providing a step towards understanding general\nin-context reasoning in large-scale LMs.",
            "author": [
                "Jiahai Feng",
                "Jacob Steinhardt"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17191v1",
                "http://arxiv.org/pdf/2310.17191v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17190v1",
            "title": "Lookup Table meets Local Laplacian Filter: Pyramid Reconstruction\n  Network for Tone Mapping",
            "updated": "2023-10-26T07:05:38Z",
            "published": "2023-10-26T07:05:38Z",
            "summary": "Tone mapping aims to convert high dynamic range (HDR) images to low dynamic\nrange (LDR) representations, a critical task in the camera imaging pipeline. In\nrecent years, 3-Dimensional LookUp Table (3D LUT) based methods have gained\nattention due to their ability to strike a favorable balance between\nenhancement performance and computational efficiency. However, these methods\noften fail to deliver satisfactory results in local areas since the look-up\ntable is a global operator for tone mapping, which works based on pixel values\nand fails to incorporate crucial local information. To this end, this paper\naims to address this issue by exploring a novel strategy that integrates global\nand local operators by utilizing closed-form Laplacian pyramid decomposition\nand reconstruction. Specifically, we employ image-adaptive 3D LUTs to\nmanipulate the tone in the low-frequency image by leveraging the specific\ncharacteristics of the frequency information. Furthermore, we utilize local\nLaplacian filters to refine the edge details in the high-frequency components\nin an adaptive manner. Local Laplacian filters are widely used to preserve edge\ndetails in photographs, but their conventional usage involves manual tuning and\nfixed implementation within camera imaging pipelines or photo editing tools. We\npropose to learn parameter value maps progressively for local Laplacian filters\nfrom annotated data using a lightweight network. Our model achieves\nsimultaneous global tone manipulation and local edge detail preservation in an\nend-to-end manner. Extensive experimental results on two benchmark datasets\ndemonstrate that the proposed method performs favorably against\nstate-of-the-art methods.",
            "author": [
                "Feng Zhang",
                "Ming Tian",
                "Zhiqiang Li",
                "Bin Xu",
                "Qingbo Lu",
                "Changxin Gao",
                "Nong Sang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17190v1",
                "http://arxiv.org/pdf/2310.17190v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17189v1",
            "title": "Exploring Iterative Refinement with Diffusion Models for Video Grounding",
            "updated": "2023-10-26T07:04:44Z",
            "published": "2023-10-26T07:04:44Z",
            "summary": "Video grounding aims to localize the target moment in an untrimmed video\ncorresponding to a given sentence query. Existing methods typically select the\nbest prediction from a set of predefined proposals or directly regress the\ntarget span in a single-shot manner, resulting in the absence of a systematical\nprediction refinement process. In this paper, we propose DiffusionVG, a novel\nframework with diffusion models that formulates video grounding as a\nconditional generation task, where the target span is generated from Gaussian\nnoise inputs and interatively refined in the reverse diffusion process. During\ntraining, DiffusionVG progressively adds noise to the target span with a fixed\nforward diffusion process and learns to recover the target span in the reverse\ndiffusion process. In inference, DiffusionVG can generate the target span from\nGaussian noise inputs by the learned reverse diffusion process conditioned on\nthe video-sentence representations. Our DiffusionVG follows the encoder-decoder\narchitecture, which firstly encodes the video-sentence features and iteratively\ndenoises the predicted spans in its specialized span refining decoder. Without\nbells and whistles, our DiffusionVG demonstrates competitive or even superior\nperformance compared to existing well-crafted models on mainstream Charades-STA\nand ActivityNet Captions benchmarks.",
            "author": [
                "Xiao Liang",
                "Tao Shi",
                "Yaoyuan Liang",
                "Te Tao",
                "Shao-Lun Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17189v1",
                "http://arxiv.org/pdf/2310.17189v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17187v1",
            "title": "Multi-level Gated Bayesian Recurrent Neural Network for State Estimation",
            "updated": "2023-10-26T06:46:43Z",
            "published": "2023-10-26T06:46:43Z",
            "summary": "The optimality of Bayesian filtering relies on the completeness of prior\nmodels, while deep learning holds a distinct advantage in learning models from\noffline data. Nevertheless, the current fusion of these two methodologies\nremains largely ad hoc, lacking a theoretical foundation. This paper presents a\nnovel solution, namely a multi-level gated Bayesian recurrent neural network\nspecifically designed to state estimation under model mismatches. Firstly, we\ntransform the non-Markov state-space model into an equivalent first-order\nMarkov model with memory. It is a generalized transformation that overcomes the\nlimitations of the first-order Markov property and enables recursive filtering.\nSecondly, by deriving a data-assisted joint state-memory-mismatch Bayesian\nfiltering, we design a Bayesian multi-level gated framework that includes a\nmemory update gate for capturing the temporal regularities in state evolution,\na state prediction gate with the evolution mismatch compensation, and a state\nupdate gate with the observation mismatch compensation. The Gaussian\napproximation implementation of the filtering process within the gated\nframework is derived, taking into account the computational efficiency.\nFinally, the corresponding internal neural network structures and end-to-end\ntraining methods are designed. The Bayesian filtering theory enhances the\ninterpretability of the proposed gated network, enabling the effective\nintegration of offline data and prior models within functionally explicit gated\nunits. In comprehensive experiments, including simulations and real-world\ndatasets, the proposed gated network demonstrates superior estimation\nperformance compared to benchmark filters and state-of-the-art deep learning\nfiltering methods.",
            "author": [
                "Shi Yan",
                "Yan Liang",
                "Le Zheng",
                "Mingyang Fan",
                "Binglu Wang",
                "Xiaoxu Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17187v1",
                "http://arxiv.org/pdf/2310.17187v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17185v2",
            "title": "Adaptive importance sampling for Deep Ritz",
            "updated": "2023-10-30T11:42:29Z",
            "published": "2023-10-26T06:35:08Z",
            "summary": "We introduce an adaptive sampling method for the Deep Ritz method aimed at\nsolving partial differential equations (PDEs). Two deep neural networks are\nused. One network is employed to approximate the solution of PDEs, while the\nother one is a deep generative model used to generate new collocation points to\nrefine the training set. The adaptive sampling procedure consists of two main\nsteps. The first step is solving the PDEs using the Deep Ritz method by\nminimizing an associated variational loss discretized by the collocation points\nin the training set. The second step involves generating a new training set,\nwhich is then used in subsequent computations to further improve the accuracy\nof the current approximate solution. We treat the integrand in the variational\nloss as an unnormalized probability density function (PDF) and approximate it\nusing a deep generative model called bounded KRnet. The new samples and their\nassociated PDF values are obtained from the bounded KRnet. With these new\nsamples and their associated PDF values, the variational loss can be\napproximated more accurately by importance sampling. Compared to the original\nDeep Ritz method, the proposed adaptive method improves accuracy, especially\nfor problems characterized by low regularity and high dimensionality. We\ndemonstrate the effectiveness of our new method through a series of numerical\nexperiments.",
            "author": [
                "Xiaoliang Wan",
                "Tao Zhou",
                "Yuancheng Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17185v2",
                "http://arxiv.org/pdf/2310.17185v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17179v3",
            "title": "Linking intra- and extra-cellular metabolic domains via neural-network\n  surrogates for dynamic metabolic control",
            "updated": "2023-11-19T02:12:55Z",
            "published": "2023-10-26T06:06:24Z",
            "summary": "In this study, we aim to optimize biotechnological production by manipulating\nintracellular metabolic fluxes in microbial cell factories. Model-based dynamic\noptimization is proposed to determine the optimal dynamic trajectories of the\nmanipulatable intracellular fluxes. A challenge emerges as existing models are\noften oversimplified, lacking insights into intracellular metabolism, or are\nexcessively complex, leading to numerical and implementation challenges in\noptimal control (e.g., related to bilevel optimizations). We propose a solution\ninvolving a machine-learning surrogate derived from steady-state\nconstraint-based metabolic modeling. This surrogate bridges the gap between\nmanipulatable intracellular fluxes and process exchange rates. By integrating\nthe surrogate model with simple macro-kinetic dynamic models, we can develop\nhybrid machine-learning-supported dynamic models. Conveniently, the\nmanipulatable intracellular fluxes in these augmented models can be exploited\nas dynamic optimization degrees of freedom. We apply this modeling and\noptimization strategy to a representative metabolic network that showcases\ncommon challenges in dynamic metabolic control. We also present an example of\ncybernetic control to counteract system uncertainties. Our approach facilitates\nthe in silico evaluation of dynamic metabolic interventions and can aid in the\nselection of suitable control and actuation strategies.",
            "author": [
                "Sebasti\u00e1n Espinel-R\u00edos",
                "Jos\u00e9 L. Avalos"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17179v3",
                "http://arxiv.org/pdf/2310.17179v3"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17178v1",
            "title": "Graphical Object-Centric Actor-Critic",
            "updated": "2023-10-26T06:05:12Z",
            "published": "2023-10-26T06:05:12Z",
            "summary": "There have recently been significant advances in the problem of unsupervised\nobject-centric representation learning and its application to downstream tasks.\nThe latest works support the argument that employing disentangled object\nrepresentations in image-based object-centric reinforcement learning tasks\nfacilitates policy learning. We propose a novel object-centric reinforcement\nlearning algorithm combining actor-critic and model-based approaches to utilize\nthese representations effectively. In our approach, we use a transformer\nencoder to extract object representations and graph neural networks to\napproximate the dynamics of an environment. The proposed method fills a\nresearch gap in developing efficient object-centric world models for\nreinforcement learning settings that can be used for environments with discrete\nor continuous action spaces. Our algorithm performs better in a visually\ncomplex 3D robotic environment and a 2D environment with compositional\nstructure than the state-of-the-art model-free actor-critic algorithm built\nupon transformer architecture and the state-of-the-art monolithic model-based\nalgorithm.",
            "author": [
                "Leonid Ugadiarov",
                "Aleksandr I. Panov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17178v1",
                "http://arxiv.org/pdf/2310.17178v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17176v1",
            "title": "A Deep Learning Approach to Teeth Segmentation and Orientation from\n  Panoramic X-rays",
            "updated": "2023-10-26T06:01:25Z",
            "published": "2023-10-26T06:01:25Z",
            "summary": "Accurate teeth segmentation and orientation are fundamental in modern oral\nhealthcare, enabling precise diagnosis, treatment planning, and dental implant\ndesign. In this study, we present a comprehensive approach to teeth\nsegmentation and orientation from panoramic X-ray images, leveraging deep\nlearning techniques. We build our model based on FUSegNet, a popular model\noriginally developed for wound segmentation, and introduce modifications by\nincorporating grid-based attention gates into the skip connections. We\nintroduce oriented bounding box (OBB) generation through principal component\nanalysis (PCA) for precise tooth orientation estimation. Evaluating our\napproach on the publicly available DNS dataset, comprising 543 panoramic X-ray\nimages, we achieve the highest Intersection-over-Union (IoU) score of 82.43%\nand Dice Similarity Coefficient (DSC) score of 90.37% among compared models in\nteeth instance segmentation. In OBB analysis, we obtain the Rotated IoU (RIoU)\nscore of 82.82%. We also conduct detailed analyses of individual tooth labels\nand categorical performance, shedding light on strengths and weaknesses. The\nproposed model's accuracy and versatility offer promising prospects for\nimproving dental diagnoses, treatment planning, and personalized healthcare in\nthe oral domain. Our generated OBB coordinates and codes are available at\nhttps://github.com/mrinal054/Instance_teeth_segmentation.",
            "author": [
                "Mrinal Kanti Dhar",
                "Mou Deb",
                "D. Madhab",
                "Zeyun Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17176v1",
                "http://arxiv.org/pdf/2310.17176v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17173v1",
            "title": "DSAC-C: Constrained Maximum Entropy for Robust Discrete Soft-Actor\n  Critic",
            "updated": "2023-10-26T05:54:51Z",
            "published": "2023-10-26T05:54:51Z",
            "summary": "We present a novel extension to the family of Soft Actor-Critic (SAC)\nalgorithms. We argue that based on the Maximum Entropy Principle, discrete SAC\ncan be further improved via additional statistical constraints derived from a\nsurrogate critic policy. Furthermore, our findings suggests that these\nconstraints provide an added robustness against potential domain shifts, which\nare essential for safe deployment of reinforcement learning agents in the\nreal-world. We provide theoretical analysis and show empirical results on low\ndata regimes for both in-distribution and out-of-distribution variants of Atari\n2600 games.",
            "author": [
                "Dexter Neo",
                "Tsuhan Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17173v1",
                "http://arxiv.org/pdf/2310.17173v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17168v1",
            "title": "Learning an Inventory Control Policy with General Inventory Arrival\n  Dynamics",
            "updated": "2023-10-26T05:49:13Z",
            "published": "2023-10-26T05:49:13Z",
            "summary": "In this paper we address the problem of learning and backtesting inventory\ncontrol policies in the presence of general arrival dynamics -- which we term\nas a quantity-over-time arrivals model (QOT). We also allow for order\nquantities to be modified as a post-processing step to meet vendor constraints\nsuch as order minimum and batch size constraints -- a common practice in real\nsupply chains. To the best of our knowledge this is the first work to handle\neither arbitrary arrival dynamics or an arbitrary downstream post-processing of\norder quantities. Building upon recent work (Madeka et al., 2022) we similarly\nformulate the periodic review inventory control problem as an exogenous\ndecision process, where most of the state is outside the control of the agent.\nMadeka et al. (2022) show how to construct a simulator that replays historic\ndata to solve this class of problem. In our case, we incorporate a deep\ngenerative model for the arrivals process as part of the history replay. By\nformulating the problem as an exogenous decision process, we can apply results\nfrom Madeka et al. (2022) to obtain a reduction to supervised learning.\nFinally, we show via simulation studies that this approach yields statistically\nsignificant improvements in profitability over production baselines. Using data\nfrom an ongoing real-world A/B test, we show that Gen-QOT generalizes well to\noff-policy data.",
            "author": [
                "Sohrab Andaz",
                "Carson Eisenach",
                "Dhruv Madeka",
                "Kari Torkkola",
                "Randy Jia",
                "Dean Foster",
                "Sham Kakade"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17168v1",
                "http://arxiv.org/pdf/2310.17168v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17167v1",
            "title": "Improving Denoising Diffusion Models via Simultaneous Estimation of\n  Image and Noise",
            "updated": "2023-10-26T05:43:07Z",
            "published": "2023-10-26T05:43:07Z",
            "summary": "This paper introduces two key contributions aimed at improving the speed and\nquality of images generated through inverse diffusion processes. The first\ncontribution involves reparameterizing the diffusion process in terms of the\nangle on a quarter-circular arc between the image and noise, specifically\nsetting the conventional $\\displaystyle \\sqrt{\\bar{\\alpha}}=\\cos(\\eta)$. This\nreparameterization eliminates two singularities and allows for the expression\nof diffusion evolution as a well-behaved ordinary differential equation (ODE).\nIn turn, this allows higher order ODE solvers such as Runge-Kutta methods to be\nused effectively. The second contribution is to directly estimate both the\nimage ($\\mathbf{x}_0$) and noise ($\\mathbf{\\epsilon}$) using our network, which\nenables more stable calculations of the update step in the inverse diffusion\nsteps, as accurate estimation of both the image and noise are crucial at\ndifferent stages of the process. Together with these changes, our model\nachieves faster generation, with the ability to converge on high-quality images\nmore quickly, and higher quality of the generated images, as measured by\nmetrics such as Frechet Inception Distance (FID), spatial Frechet Inception\nDistance (sFID), precision, and recall.",
            "author": [
                "Zhenkai Zhang",
                "Krista A. Ehinger",
                "Tom Drummond"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17167v1",
                "http://arxiv.org/pdf/2310.17167v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17162v1",
            "title": "Content-based Controls For Music Large Language Modeling",
            "updated": "2023-10-26T05:24:38Z",
            "published": "2023-10-26T05:24:38Z",
            "summary": "Recent years have witnessed a rapid growth of large-scale language models in\nthe domain of music audio. Such models enable end-to-end generation of\nhigher-quality music, and some allow conditioned generation using text\ndescriptions. However, the control power of text controls on music is\nintrinsically limited, as they can only describe music indirectly through\nmeta-data (such as singers and instruments) or high-level representations (such\nas genre and emotion). We aim to further equip the models with direct and\ncontent-based controls on innate music languages such as pitch, chords and drum\ntrack. To this end, we contribute Coco-Mulla, a content-based control method\nfor music large language modeling. It uses a parameter-efficient fine-tuning\n(PEFT) method tailored for Transformer-based audio models. Experiments show\nthat our approach achieved high-quality music generation with low-resource\nsemi-supervised learning, tuning with less than 4% parameters compared to the\noriginal model and training on a small dataset with fewer than 300 songs.\nMoreover, our approach enables effective content-based controls, and we\nillustrate the control power via chords and rhythms, two of the most salient\nfeatures of music audio. Furthermore, we show that by combining content-based\ncontrols and text descriptions, our system achieves flexible music variation\ngeneration and style transfer. Our source codes and demos are available online.",
            "author": [
                "Liwei Lin",
                "Gus Xia",
                "Junyan Jiang",
                "Yixiao Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17162v1",
                "http://arxiv.org/pdf/2310.17162v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17161v1",
            "title": "Structure discovery in Atomic Force Microscopy imaging of ice",
            "updated": "2023-10-26T05:20:06Z",
            "published": "2023-10-26T05:20:06Z",
            "summary": "The interaction of water with surfaces is crucially important in a wide range\nof natural and technological settings. In particular, at low temperatures,\nunveiling the atomistic structure of adsorbed water clusters would provide\nvaluable data for understanding the ice nucleation process. Using\nhigh-resolution Atomic Force Microscopy (AFM) and Scanning Tunnelling\nMicroscopy, several studies have demonstrated the presence of water pentamers,\nhexamers, heptamers (and of their combinations) on a variety of metallic\nsurfaces, as well the initial stages of 2D ice growth on an insulating surface.\nHowever, in all these cases, the observed structures were completely flat,\nproviding a relatively straightforward path to interpretation. Here, we present\nhigh-resolution AFM measurements of several new water clusters on Au(111) and\nCu(111), whose understanding presents significant challenges, due to both their\nhighly 3D configuration and to their large size. For each of them, we use a\ncombination of machine learning, atomistic modelling with neural network\npotentials and statistical sampling to propose an underlying atomic structure,\nfinally comparing its AFM simulated images to the experimental ones. These\nresults provide new insights into the early phases of ice formation, which is a\nubiquitous phenomenon ranging from biology to astrophysics.",
            "author": [
                "F. Priante",
                "N. Oinonen",
                "Y. Tian",
                "D. Guan",
                "C. Xu",
                "S. Cai",
                "P. Liljeroth",
                "Y. Jiang",
                "A. S. Foster"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17161v1",
                "http://arxiv.org/pdf/2310.17161v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17159v1",
            "title": "MaxEnt Loss: Constrained Maximum Entropy for Calibration under\n  Out-of-Distribution Shift",
            "updated": "2023-10-26T05:10:57Z",
            "published": "2023-10-26T05:10:57Z",
            "summary": "We present a new loss function that addresses the out-of-distribution (OOD)\ncalibration problem. While many objective functions have been proposed to\neffectively calibrate models in-distribution, our findings show that they do\nnot always fare well OOD. Based on the Principle of Maximum Entropy, we\nincorporate helpful statistical constraints observed during training,\ndelivering better model calibration without sacrificing accuracy. We provide\ntheoretical analysis and show empirically that our method works well in\npractice, achieving state-of-the-art calibration on both synthetic and\nreal-world benchmarks.",
            "author": [
                "Dexter Neo",
                "Stefan Winkler",
                "Tsuhan Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17159v1",
                "http://arxiv.org/pdf/2310.17159v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17158v2",
            "title": "CosmosDSR -- a methodology for automated detection and tracking of\n  orbital debris using the Unscented Kalman Filter",
            "updated": "2023-10-31T11:22:04Z",
            "published": "2023-10-26T05:02:19Z",
            "summary": "The Kessler syndrome refers to the escalating space debris from frequent\nspace activities, threatening future space exploration. Addressing this issue\nis vital. Several AI models, including Convolutional Neural Networks, Kernel\nPrincipal Component Analysis, and Model-Agnostic Meta- Learning have been\nassessed with various data types. Earlier studies highlighted the combination\nof the YOLO object detector and a linear Kalman filter (LKF) for object\ndetection and tracking. Advancing this, the current paper introduces a novel\nmethodology for the Comprehensive Orbital Surveillance and Monitoring Of Space\nby Detecting Satellite Residuals (CosmosDSR) by combining YOLOv3 with an\nUnscented Kalman Filter (UKF) for tracking satellites in sequential images.\nUsing the Spacecraft Recognition Leveraging Knowledge of Space Environment\n(SPARK) dataset for training and testing, the YOLOv3 precisely detected and\nclassified all satellite categories (Mean Average Precision=97.18%, F1=0.95)\nwith few errors (TP=4163, FP=209, FN=237). Both CosmosDSR and an implemented\nLKF used for comparison tracked satellites accurately for a mean squared error\n(MSE) and root mean squared error (RME) of MSE=2.83/RMSE=1.66 for UKF and\nMSE=2.84/RMSE=1.66 for LKF. The current study is limited to images generated in\na space simulation environment, but the CosmosDSR methodology shows great\npotential in detecting and tracking satellites, paving the way for solutions to\nthe Kessler syndrome.",
            "author": [
                "Daniel S. Roll",
                "Zeyneb Kurt",
                "Wai Lok Woo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17158v2",
                "http://arxiv.org/pdf/2310.17158v2"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP",
                "astro-ph.IM",
                "cs.AI",
                "cs.CV",
                "68",
                "I.2.6; K.3.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17157v1",
            "title": "Deja Vu: Contextual Sparsity for Efficient LLMs at Inference Time",
            "updated": "2023-10-26T05:01:09Z",
            "published": "2023-10-26T05:01:09Z",
            "summary": "Large language models (LLMs) with hundreds of billions of parameters have\nsparked a new wave of exciting AI applications. However, they are\ncomputationally expensive at inference time. Sparsity is a natural approach to\nreduce this cost, but existing methods either require costly retraining, have\nto forgo LLM's in-context learning ability, or do not yield wall-clock time\nspeedup on modern hardware. We hypothesize that contextual sparsity, which are\nsmall, input-dependent sets of attention heads and MLP parameters that yield\napproximately the same output as the dense model for a given input, can address\nthese issues. We show that contextual sparsity exists, that it can be\naccurately predicted, and that we can exploit it to speed up LLM inference in\nwall-clock time without compromising LLM's quality or in-context learning\nability. Based on these insights, we propose DejaVu, a system that uses a\nlow-cost algorithm to predict contextual sparsity on the fly given inputs to\neach layer, along with an asynchronous and hardware-aware implementation that\nspeeds up LLM inference. We validate that DejaVu can reduce the inference\nlatency of OPT-175B by over 2X compared to the state-of-the-art\nFasterTransformer, and over 6X compared to the widely used Hugging Face\nimplementation, without compromising model quality. The code is available at\nhttps://github.com/FMInference/DejaVu.",
            "author": [
                "Zichang Liu",
                "Jue Wang",
                "Tri Dao",
                "Tianyi Zhou",
                "Binhang Yuan",
                "Zhao Song",
                "Anshumali Shrivastava",
                "Ce Zhang",
                "Yuandong Tian",
                "Christopher Re",
                "Beidi Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17157v1",
                "http://arxiv.org/pdf/2310.17157v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17156v1",
            "title": "Learning depth from monocular video sequences",
            "updated": "2023-10-26T05:00:41Z",
            "published": "2023-10-26T05:00:41Z",
            "summary": "Learning single image depth estimation model from monocular video sequence is\na very challenging problem. In this paper, we propose a novel training loss\nwhich enables us to include more images for supervision during the training\nprocess. We propose a simple yet effective model to account the frame to frame\npixel motion. We also design a novel network architecture for single image\nestimation. When combined, our method produces state of the art results for\nmonocular depth estimation on the KITTI dataset in the self-supervised setting.",
            "author": [
                "Zhenwei Luo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17156v1",
                "http://arxiv.org/pdf/2310.17156v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17678v1",
            "title": "Spatio-Temporal Meta Contrastive Learning",
            "updated": "2023-10-26T04:56:31Z",
            "published": "2023-10-26T04:56:31Z",
            "summary": "Spatio-temporal prediction is crucial in numerous real-world applications,\nincluding traffic forecasting and crime prediction, which aim to improve public\ntransportation and safety management. Many state-of-the-art models demonstrate\nthe strong capability of spatio-temporal graph neural networks (STGNN) to\ncapture complex spatio-temporal correlations. However, despite their\neffectiveness, existing approaches do not adequately address several key\nchallenges. Data quality issues, such as data scarcity and sparsity, lead to\ndata noise and a lack of supervised signals, which significantly limit the\nperformance of STGNN. Although recent STGNN models with contrastive learning\naim to address these challenges, most of them use pre-defined augmentation\nstrategies that heavily depend on manual design and cannot be customized for\ndifferent Spatio-Temporal Graph (STG) scenarios. To tackle these challenges, we\npropose a new spatio-temporal contrastive learning (CL4ST) framework to encode\nrobust and generalizable STG representations via the STG augmentation paradigm.\nSpecifically, we design the meta view generator to automatically construct node\nand edge augmentation views for each disentangled spatial and temporal graph in\na data-driven manner. The meta view generator employs meta networks with\nparameterized generative model to customize the augmentations for each input.\nThis personalizes the augmentation strategies for every STG and endows the\nlearning framework with spatio-temporal-aware information. Additionally, we\nintegrate a unified spatio-temporal graph attention network with the proposed\nmeta view generator and two-branch graph contrastive learning paradigms.\nExtensive experiments demonstrate that our CL4ST significantly improves\nperformance over various state-of-the-art baselines in traffic and crime\nprediction.",
            "author": [
                "Jiabin Tang",
                "Lianghao Xia",
                "Jie Hu",
                "Chao Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17678v1",
                "http://arxiv.org/pdf/2310.17678v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17154v1",
            "title": "Deep Imbalanced Regression via Hierarchical Classification Adjustment",
            "updated": "2023-10-26T04:54:39Z",
            "published": "2023-10-26T04:54:39Z",
            "summary": "Regression tasks in computer vision, such as age estimation or counting, are\noften formulated into classification by quantizing the target space into\nclasses. Yet real-world data is often imbalanced -- the majority of training\nsamples lie in a head range of target values, while a minority of samples span\na usually larger tail range. By selecting the class quantization, one can\nadjust imbalanced regression targets into balanced classification outputs,\nthough there are trade-offs in balancing classification accuracy and\nquantization error. To improve regression performance over the entire range of\ndata, we propose to construct hierarchical classifiers for solving imbalanced\nregression tasks. The fine-grained classifiers limit the quantization error\nwhile being modulated by the coarse predictions to ensure high accuracy.\nStandard hierarchical classification approaches, however, when applied to the\nregression problem, fail to ensure that predicted ranges remain consistent\nacross the hierarchy. As such, we propose a range-preserving distillation\nprocess that can effectively learn a single classifier from the set of\nhierarchical classifiers. Our novel hierarchical classification adjustment\n(HCA) for imbalanced regression shows superior results on three diverse tasks:\nage estimation, crowd counting and depth estimation. We will release the source\ncode upon acceptance.",
            "author": [
                "Haipeng Xiong",
                "Angela Yao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17154v1",
                "http://arxiv.org/pdf/2310.17154v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17153v1",
            "title": "Hierarchical Semi-Implicit Variational Inference with Application to\n  Diffusion Model Acceleration",
            "updated": "2023-10-26T04:52:28Z",
            "published": "2023-10-26T04:52:28Z",
            "summary": "Semi-implicit variational inference (SIVI) has been introduced to expand the\nanalytical variational families by defining expressive semi-implicit\ndistributions in a hierarchical manner. However, the single-layer architecture\ncommonly used in current SIVI methods can be insufficient when the target\nposterior has complicated structures. In this paper, we propose hierarchical\nsemi-implicit variational inference, called HSIVI, which generalizes SIVI to\nallow more expressive multi-layer construction of semi-implicit distributions.\nBy introducing auxiliary distributions that interpolate between a simple base\ndistribution and the target distribution, the conditional layers can be trained\nby progressively matching these auxiliary distributions one layer after\nanother. Moreover, given pre-trained score networks, HSIVI can be used to\naccelerate the sampling process of diffusion models with the score matching\nobjective. We show that HSIVI significantly enhances the expressiveness of SIVI\non several Bayesian inference problems with complicated target distributions.\nWhen used for diffusion model acceleration, we show that HSIVI can produce high\nquality samples comparable to or better than the existing fast diffusion model\nbased samplers with a small number of function evaluations on various datasets.",
            "author": [
                "Longlin Yu",
                "Tianyu Xie",
                "Yu Zhu",
                "Tong Yang",
                "Xiangyu Zhang",
                "Cheng Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17153v1",
                "http://arxiv.org/pdf/2310.17153v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17152v1",
            "title": "Technical Note: Feasibility of translating 3.0T-trained Deep-Learning\n  Segmentation Models Out-of-the-Box on Low-Field MRI 0.55T Knee-MRI of Healthy\n  Controls",
            "updated": "2023-10-26T04:52:25Z",
            "published": "2023-10-26T04:52:25Z",
            "summary": "In the current study, our purpose is to evaluate the feasibility of applying\ndeep learning (DL) enabled algorithms to quantify bilateral knee biomarkers in\nhealthy controls scanned at 0.55T and compared with 3.0T. The current study\nassesses the performance of standard in-practice bone, and cartilage\nsegmentation algorithms at 0.55T, both qualitatively and quantitatively, in\nterms of comparing segmentation performance, areas of improvement, and\ncompartment-wise cartilage thickness values between 0.55T vs. 3.0T. Initial\nresults demonstrate a usable to good technical feasibility of translating\nexisting quantitative deep-learning-based image segmentation techniques,\ntrained on 3.0T, out of 0.55T for knee MRI, in a multi-vendor acquisition\nenvironment. Especially in terms of segmenting cartilage compartments, the\nmodels perform almost equivalent to 3.0T in terms of Likert ranking. The 0.55T\nlow-field sustainable and easy-to-install MRI, as demonstrated, thus, can be\nutilized for evaluating knee cartilage thickness and bone segmentations aided\nby established DL algorithms trained at higher-field strengths out-of-the-box\ninitially. This could be utilized at the far-spread point-of-care locations\nwith a lack of radiologists available to manually segment low-field images, at\nleast till a decent base of low-field data pool is collated. With further\nfine-tuning with manual labeling of low-field data or utilizing synthesized\nhigher SNR images from low-field images, OA biomarker quantification\nperformance is potentially guaranteed to be further improved.",
            "author": [
                "Rupsa Bhattacharjee",
                "Zehra Akkaya",
                "Johanna Luitjens",
                "Pan Su",
                "Yang Yang",
                "Valentina Pedoia",
                "Sharmila Majumdar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17152v1",
                "http://arxiv.org/pdf/2310.17152v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17149v1",
            "title": "Explainable Spatio-Temporal Graph Neural Networks",
            "updated": "2023-10-26T04:47:28Z",
            "published": "2023-10-26T04:47:28Z",
            "summary": "Spatio-temporal graph neural networks (STGNNs) have gained popularity as a\npowerful tool for effectively modeling spatio-temporal dependencies in diverse\nreal-world urban applications, including intelligent transportation and public\nsafety. However, the black-box nature of STGNNs limits their interpretability,\nhindering their application in scenarios related to urban resource allocation\nand policy formulation. To bridge this gap, we propose an Explainable\nSpatio-Temporal Graph Neural Networks (STExplainer) framework that enhances\nSTGNNs with inherent explainability, enabling them to provide accurate\npredictions and faithful explanations simultaneously. Our framework integrates\na unified spatio-temporal graph attention network with a positional information\nfusion layer as the STG encoder and decoder, respectively. Furthermore, we\npropose a structure distillation approach based on the Graph Information\nBottleneck (GIB) principle with an explainable objective, which is instantiated\nby the STG encoder and decoder. Through extensive experiments, we demonstrate\nthat our STExplainer outperforms state-of-the-art baselines in terms of\npredictive accuracy and explainability metrics (i.e., sparsity and fidelity) on\ntraffic and crime prediction tasks. Furthermore, our model exhibits superior\nrepresentation ability in alleviating data missing and sparsity issues. The\nimplementation code is available at: https://github.com/HKUDS/STExplainer.",
            "author": [
                "Jiabin Tang",
                "Lianghao Xia",
                "Chao Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17149v1",
                "http://arxiv.org/pdf/2310.17149v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17146v1",
            "title": "Counterfactual-Augmented Importance Sampling for Semi-Offline Policy\n  Evaluation",
            "updated": "2023-10-26T04:41:19Z",
            "published": "2023-10-26T04:41:19Z",
            "summary": "In applying reinforcement learning (RL) to high-stakes domains, quantitative\nand qualitative evaluation using observational data can help practitioners\nunderstand the generalization performance of new policies. However, this type\nof off-policy evaluation (OPE) is inherently limited since offline data may not\nreflect the distribution shifts resulting from the application of new policies.\nOn the other hand, online evaluation by collecting rollouts according to the\nnew policy is often infeasible, as deploying new policies in these domains can\nbe unsafe. In this work, we propose a semi-offline evaluation framework as an\nintermediate step between offline and online evaluation, where human users\nprovide annotations of unobserved counterfactual trajectories. While tempting\nto simply augment existing data with such annotations, we show that this naive\napproach can lead to biased results. Instead, we design a new family of OPE\nestimators based on importance sampling (IS) and a novel weighting scheme that\nincorporate counterfactual annotations without introducing additional bias. We\nanalyze the theoretical properties of our approach, showing its potential to\nreduce both bias and variance compared to standard IS estimators. Our analyses\nreveal important practical considerations for handling biased, noisy, or\nmissing annotations. In a series of proof-of-concept experiments involving\nbandits and a healthcare-inspired simulator, we demonstrate that our approach\noutperforms purely offline IS estimators and is robust to imperfect\nannotations. Our framework, combined with principled human-centered design of\nannotation solicitation, can enable the application of RL in high-stakes\ndomains.",
            "author": [
                "Shengpu Tang",
                "Jenna Wiens"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17146v1",
                "http://arxiv.org/pdf/2310.17146v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12864v1",
            "title": "OptScaler: A Hybrid Proactive-Reactive Framework for Robust Autoscaling\n  in the Cloud",
            "updated": "2023-10-26T04:38:48Z",
            "published": "2023-10-26T04:38:48Z",
            "summary": "Autoscaling is a vital mechanism in cloud computing that supports the\nautonomous adjustment of computing resources under dynamic workloads. A primary\ngoal of autoscaling is to stabilize resource utilization at a desirable level,\nthus reconciling the need for resource-saving with the satisfaction of Service\nLevel Objectives (SLOs). Existing proactive autoscaling methods anticipate the\nfuture workload and scale the resources in advance, whereas the reliability may\nsuffer from prediction deviations arising from the frequent fluctuations and\nnoise of cloud workloads; reactive methods rely on real-time system feedback,\nwhile the hysteretic nature of reactive methods could cause violations of the\nrigorous SLOs. To this end, this paper presents OptScaler, a hybrid autoscaling\nframework that integrates the power of both proactive and reactive methods for\nregulating CPU utilization. Specifically, the proactive module of OptScaler\nconsists of a sophisticated workload prediction model and an optimization\nmodel, where the former provides reliable inputs to the latter for making\noptimal scaling decisions. The reactive module provides a self-tuning estimator\nof CPU utilization to the optimization model. We embed Model Predictive Control\n(MPC) mechanism and robust optimization techniques into the optimization model\nto further enhance its reliability. Numerical results have demonstrated the\nsuperiority of both the workload prediction model and the hybrid framework of\nOptScaler in the scenario of online services compared to prevalent reactive,\nproactive, or hybrid autoscalers. OptScaler has been successfully deployed at\nAlipay, supporting the autoscaling of applets in the world-leading payment\nplatform.",
            "author": [
                "Ding Zou",
                "Wei Lu",
                "Zhibo Zhu",
                "Xingyu Lu",
                "Jun Zhou",
                "Xiaojin Wang",
                "Kangyu Liu",
                "Haiqing Wang",
                "Kefan Wang",
                "Renen Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12864v1",
                "http://arxiv.org/pdf/2311.12864v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17141v1",
            "title": "Neural style transfer of weak lensing mass maps",
            "updated": "2023-10-26T04:25:41Z",
            "published": "2023-10-26T04:25:41Z",
            "summary": "We propose a new generative model of projected cosmic mass density maps\ninferred from weak gravitational lensing observations of distant galaxies (weak\nlensing mass maps). We construct the model based on a neural style transfer so\nthat it can transform Gaussian weak lensing mass maps into deeply non-Gaussian\ncounterparts as predicted in ray-tracing lensing simulations. We develop an\nunpaired image-to-image translation method with Cycle-Consistent Generative\nAdversarial Networks (Cycle GAN), which learn efficient mapping from an input\ndomain to a target domain. Our model is designed to enjoy important advantages;\nit is trainable with no need for paired simulation data, flexible to make the\ninput domain visually meaningful, and expandable to rapidly-produce a map with\na larger sky coverage than training data without additional learning. Using\n10,000 lensing simulations, we find that appropriate labeling of training data\nbased on field variance requires the model to exhibit a desired diversity of\nvarious summary statistics for weak lensing mass maps. Compared with a popular\nlog-normal model, our model improves in predicting the statistical natures of\nthree-point correlations and local properties of rare high-density regions. We\nalso demonstrate that our model enables us to produce a continuous map with a\nsky coverage of $\\sim166\\, \\mathrm{deg}^2$ but similar non-Gaussian features to\ntraining data covering $\\sim12\\, \\mathrm{deg}^2$ in a GPU minute. Hence, our\nmodel can be beneficial to massive productions of synthetic weak lensing mass\nmaps, which is of great importance in future precise real-world analyses.",
            "author": [
                "Masato Shirasaki",
                "Shiro Ikeda"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17141v1",
                "http://arxiv.org/pdf/2310.17141v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17139v1",
            "title": "Understanding and Addressing the Pitfalls of Bisimulation-based\n  Representations in Offline Reinforcement Learning",
            "updated": "2023-10-26T04:20:55Z",
            "published": "2023-10-26T04:20:55Z",
            "summary": "While bisimulation-based approaches hold promise for learning robust state\nrepresentations for Reinforcement Learning (RL) tasks, their efficacy in\noffline RL tasks has not been up to par. In some instances, their performance\nhas even significantly underperformed alternative methods. We aim to understand\nwhy bisimulation methods succeed in online settings, but falter in offline\ntasks. Our analysis reveals that missing transitions in the dataset are\nparticularly harmful to the bisimulation principle, leading to ineffective\nestimation. We also shed light on the critical role of reward scaling in\nbounding the scale of bisimulation measurements and of the value error they\ninduce. Based on these findings, we propose to apply the expectile operator for\nrepresentation learning to our offline RL setting, which helps to prevent\noverfitting to incomplete data. Meanwhile, by introducing an appropriate reward\nscaling strategy, we avoid the risk of feature collapse in representation\nspace. We implement these recommendations on two state-of-the-art\nbisimulation-based algorithms, MICo and SimSR, and demonstrate performance\ngains on two benchmark suites: D4RL and Visual D4RL. Codes are provided at\n\\url{https://github.com/zanghyu/Offline_Bisimulation}.",
            "author": [
                "Hongyu Zang",
                "Xin Li",
                "Leiji Zhang",
                "Yang Liu",
                "Baigui Sun",
                "Riashat Islam",
                "Remi Tachet des Combes",
                "Romain Laroche"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17139v1",
                "http://arxiv.org/pdf/2310.17139v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17138v1",
            "title": "A Classifier Using Global Character Level and Local Sub-unit Level\n  Features for Hindi Online Handwritten Character Recognition",
            "updated": "2023-10-26T04:20:39Z",
            "published": "2023-10-26T04:20:39Z",
            "summary": "A classifier is developed that defines a joint distribution of global\ncharacter features, number of sub-units and local sub-unit features to model\nHindi online handwritten characters. The classifier uses latent variables to\nmodel the structure of sub-units. The classifier uses histograms of points,\norientations, and dynamics of orientations (HPOD) features to represent\ncharacters at global character level and local sub-unit level and is\nindependent of character stroke order and stroke direction variations. The\nparameters of the classifier is estimated using maximum likelihood method.\nDifferent classifiers and features used in other studies are considered in this\nstudy for classification performance comparison with the developed classifier.\nThe classifiers considered are Second Order Statistics (SOS), Sub-space (SS),\nFisher Discriminant (FD), Feedforward Neural Network (FFN) and Support Vector\nMachines (SVM) and the features considered are Spatio Temporal (ST), Discrete\nFourier Transform (DFT), Discrete Cosine Transform (SCT), Discrete Wavelet\nTransform (DWT), Spatial (SP) and Histograms of Oriented Gradients (HOG). Hindi\ncharacter datasets used for training and testing the developed classifier\nconsist of samples of handwritten characters from 96 different character\nclasses. There are 12832 samples with an average of 133 samples per character\nclass in the training set and 2821 samples with an average of 29 samples per\ncharacter class in the testing set. The developed classifier has the highest\naccuracy of 93.5\\% on the testing set compared to that of the classifiers\ntrained on different features extracted from the same training set and\nevaluated on the same testing set considered in this study.",
            "author": [
                "Anand Sharma",
                "A. G. Ramakrishnan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17138v1",
                "http://arxiv.org/pdf/2310.17138v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17137v1",
            "title": "Large-Scale Gaussian Processes via Alternating Projection",
            "updated": "2023-10-26T04:20:36Z",
            "published": "2023-10-26T04:20:36Z",
            "summary": "Gaussian process (GP) hyperparameter optimization requires repeatedly solving\nlinear systems with $n \\times n$ kernel matrices. To address the prohibitive\n$\\mathcal{O}(n^3)$ time complexity, recent work has employed fast iterative\nnumerical methods, like conjugate gradients (CG). However, as datasets increase\nin magnitude, the corresponding kernel matrices become increasingly\nill-conditioned and still require $\\mathcal{O}(n^2)$ space without\npartitioning. Thus, while CG increases the size of datasets GPs can be trained\non, modern datasets reach scales beyond its applicability. In this work, we\npropose an iterative method which only accesses subblocks of the kernel matrix,\neffectively enabling \\emph{mini-batching}. Our algorithm, based on alternating\nprojection, has $\\mathcal{O}(n)$ per-iteration time and space complexity,\nsolving many of the practical challenges of scaling GPs to very large datasets.\nTheoretically, we prove our method enjoys linear convergence and empirically we\ndemonstrate its robustness to ill-conditioning. On large-scale benchmark\ndatasets up to four million datapoints our approach accelerates training by a\nfactor of 2$\\times$ to 27$\\times$ compared to CG.",
            "author": [
                "Kaiwen Wu",
                "Jonathan Wenger",
                "Haydn Jones",
                "Geoff Pleiss",
                "Jacob R. Gardner"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17137v1",
                "http://arxiv.org/pdf/2310.17137v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17133v1",
            "title": "Incorporating Probing Signals into Multimodal Machine Translation via\n  Visual Question-Answering Pairs",
            "updated": "2023-10-26T04:13:49Z",
            "published": "2023-10-26T04:13:49Z",
            "summary": "This paper presents an in-depth study of multimodal machine translation\n(MMT), examining the prevailing understanding that MMT systems exhibit\ndecreased sensitivity to visual information when text inputs are complete.\nInstead, we attribute this phenomenon to insufficient cross-modal interaction,\nrather than image information redundancy. A novel approach is proposed to\ngenerate parallel Visual Question-Answering (VQA) style pairs from the source\ntext, fostering more robust cross-modal interaction. Using Large Language\nModels (LLMs), we explicitly model the probing signal in MMT to convert it into\nVQA-style data to create the Multi30K-VQA dataset. An MMT-VQA multitask\nlearning framework is introduced to incorporate explicit probing signals from\nthe dataset into the MMT training process. Experimental results on two\nwidely-used benchmarks demonstrate the effectiveness of this novel approach.\nOur code and data would be available at:\n\\url{https://github.com/libeineu/MMT-VQA}.",
            "author": [
                "Yuxin Zuo",
                "Bei Li",
                "Chuanhao Lv",
                "Tong Zheng",
                "Tong Xiao",
                "Jingbo Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17133v1",
                "http://arxiv.org/pdf/2310.17133v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17132v1",
            "title": "Unleashing the potential of GNNs via Bi-directional Knowledge Transfer",
            "updated": "2023-10-26T04:11:49Z",
            "published": "2023-10-26T04:11:49Z",
            "summary": "Based on the message-passing paradigm, there has been an amount of research\nproposing diverse and impressive feature propagation mechanisms to improve the\nperformance of GNNs. However, less focus has been put on feature\ntransformation, another major operation of the message-passing framework. In\nthis paper, we first empirically investigate the performance of the feature\ntransformation operation in several typical GNNs. Unexpectedly, we notice that\nGNNs do not completely free up the power of the inherent feature transformation\noperation. By this observation, we propose the Bi-directional Knowledge\nTransfer (BiKT), a plug-and-play approach to unleash the potential of the\nfeature transformation operations without modifying the original architecture.\nTaking the feature transformation operation as a derived representation\nlearning model that shares parameters with the original GNN, the direct\nprediction by this model provides a topological-agnostic knowledge feedback\nthat can further instruct the learning of GNN and the feature transformations\ntherein. On this basis, BiKT not only allows us to acquire knowledge from both\nthe GNN and its derived model but promotes each other by injecting the\nknowledge into the other. In addition, a theoretical analysis is further\nprovided to demonstrate that BiKT improves the generalization bound of the GNNs\nfrom the perspective of domain adaption. An extensive group of experiments on\nup to 7 datasets with 5 typical GNNs demonstrates that BiKT brings up to 0.5% -\n4% performance gain over the original GNN, which means a boosted GNN is\nobtained. Meanwhile, the derived model also shows a powerful performance to\ncompete with or even surpass the original GNN, enabling us to flexibly apply it\nindependently to some other specific downstream tasks.",
            "author": [
                "Shuai Zheng",
                "Zhizhe Liu",
                "Zhenfeng Zhu",
                "Xingxing Zhang",
                "Jianxin Li",
                "Yao Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17132v1",
                "http://arxiv.org/pdf/2310.17132v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17131v1",
            "title": "Virtual Accessory Try-On via Keypoint Hallucination",
            "updated": "2023-10-26T04:11:34Z",
            "published": "2023-10-26T04:11:34Z",
            "summary": "The virtual try-on task refers to fitting the clothes from one image onto\nanother portrait image. In this paper, we focus on virtual accessory try-on,\nwhich fits accessory (e.g., glasses, ties) onto a face or portrait image.\nUnlike clothing try-on, which relies on human silhouette as guidance, accessory\ntry-on warps the accessory into an appropriate location and shape to generate a\nplausible composite image. In contrast to previous try-on methods that treat\nforeground (i.e., accessories) and background (i.e., human faces or bodies)\nequally, we propose a background-oriented network to utilize the prior\nknowledge of human bodies and accessories. Specifically, our approach learns\nthe human body priors and hallucinates the target locations of specified\nforeground keypoints in the background. Then our approach will inject\nforeground information with accessory priors into the background UNet. Based on\nthe hallucinated target locations, the warping parameters are calculated to\nwarp the foreground. Moreover, this background-oriented network can also easily\nincorporate auxiliary human face/body semantic segmentation supervision to\nfurther boost performance. Experiments conducted on STRAT dataset validate the\neffectiveness of our proposed method.",
            "author": [
                "Junhong Gou",
                "Bo Zhang",
                "Li Niu",
                "Jianfu Zhang",
                "Jianlou Si",
                "Chen Qian",
                "Liqing Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17131v1",
                "http://arxiv.org/pdf/2310.17131v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17128v1",
            "title": "Task-driven Prompt Evolution for Foundation Models",
            "updated": "2023-10-26T04:08:07Z",
            "published": "2023-10-26T04:08:07Z",
            "summary": "Promptable foundation models, particularly Segment Anything Model (SAM), have\nemerged as a promising alternative to the traditional task-specific supervised\nlearning for image segmentation. However, many evaluation studies have found\nthat their performance on medical imaging modalities to be underwhelming\ncompared to conventional deep learning methods. In the world of large\npre-trained language and vision-language models, learning prompt from\ndownstream tasks has achieved considerable success in improving performance. In\nthis work, we propose a plug-and-play Prompt Optimization Technique for\nfoundation models like SAM (SAMPOT) that utilizes the downstream segmentation\ntask to optimize the human-provided prompt to obtain improved performance. We\ndemonstrate the utility of SAMPOT on lung segmentation in chest X-ray images\nand obtain an improvement on a significant number of cases ($\\sim75\\%$) over\nhuman-provided initial prompts. We hope this work will lead to further\ninvestigations in the nascent field of automatic visual prompt-tuning.",
            "author": [
                "Rachana Sathish",
                "Rahul Venkataramani",
                "K S Shriram",
                "Prasad Sudhakar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17128v1",
                "http://arxiv.org/pdf/2310.17128v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17127v1",
            "title": "A Method for Network Intrusion Detection Using Flow Sequence and BERT\n  Framework",
            "updated": "2023-10-26T03:56:40Z",
            "published": "2023-10-26T03:56:40Z",
            "summary": "A Network Intrusion Detection System (NIDS) is a tool that identifies\npotential threats to a network. Recently, different flow-based NIDS designs\nutilizing Machine Learning (ML) algorithms have been proposed as solutions to\ndetect intrusions efficiently. However, conventional ML-based classifiers have\nnot seen widespread adoption in the real world due to their poor domain\nadaptation capability. In this research, our goal is to explore the possibility\nof using sequences of flows to improve the domain adaptation capability of\nnetwork intrusion detection systems. Our proposal employs natural language\nprocessing techniques and Bidirectional Encoder Representations from\nTransformers framework, which is an effective technique for modeling data with\nrespect to its context. Early empirical results show that our approach has\nimproved domain adaptation capability compared to previous approaches. The\nproposed approach provides a new research method for building a robust\nintrusion detection system.",
            "author": [
                "Loc Gia Nguyen",
                "Kohei Watabe"
            ],
            "link": [
                "http://dx.doi.org/10.1109/ICC45041.2023.10279335",
                "http://arxiv.org/abs/2310.17127v1",
                "http://arxiv.org/pdf/2310.17127v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17126v1",
            "title": "Deep Learning on SAR Imagery: Transfer Learning Versus Randomly\n  Initialized Weights",
            "updated": "2023-10-26T03:52:54Z",
            "published": "2023-10-26T03:52:54Z",
            "summary": "Deploying deep learning on Synthetic Aperture Radar (SAR) data is becoming\nmore common for mapping purposes. One such case is sea ice, which is highly\ndynamic and rapidly changes as a result of the combined effect of wind,\ntemperature, and ocean currents. Therefore, frequent mapping of sea ice is\nnecessary to ensure safe marine navigation. However, there is a general\nshortage of expert-labeled data to train deep learning algorithms. Fine-tuning\na pre-trained model on SAR imagery is a potential solution. In this paper, we\ncompare the performance of deep learning models trained from scratch using\nrandomly initialized weights against pre-trained models that we fine-tune for\nthis purpose. Our results show that pre-trained models lead to better results,\nespecially on test samples from the melt season.",
            "author": [
                "Morteza Karimzadeh",
                "Rafael Pires de Lima"
            ],
            "link": [
                "http://dx.doi.org/10.1109/IGARSS52108.2023.10281892",
                "http://arxiv.org/abs/2310.17126v1",
                "http://arxiv.org/pdf/2310.17126v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17124v1",
            "title": "Implicit Regularization in Over-Parameterized Support Vector Machine",
            "updated": "2023-10-26T03:51:10Z",
            "published": "2023-10-26T03:51:10Z",
            "summary": "In this paper, we design a regularization-free algorithm for high-dimensional\nsupport vector machines (SVMs) by integrating over-parameterization with\nNesterov's smoothing method, and provide theoretical guarantees for the induced\nimplicit regularization phenomenon. In particular, we construct an\nover-parameterized hinge loss function and estimate the true parameters by\nleveraging regularization-free gradient descent on this loss function. The\nutilization of Nesterov's method enhances the computational efficiency of our\nalgorithm, especially in terms of determining the stopping criterion and\nreducing computational complexity. With appropriate choices of initialization,\nstep size, and smoothness parameter, we demonstrate that unregularized gradient\ndescent achieves a near-oracle statistical convergence rate. Additionally, we\nverify our theoretical findings through a variety of numerical experiments and\ncompare the proposed method with explicit regularization. Our results\nillustrate the advantages of employing implicit regularization via gradient\ndescent in conjunction with over-parameterization in sparse SVMs.",
            "author": [
                "Yang Sui",
                "Xin He",
                "Yang Bai"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17124v1",
                "http://arxiv.org/pdf/2310.17124v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17122v1",
            "title": "Enhancing sea ice segmentation in Sentinel-1 images with atrous\n  convolutions",
            "updated": "2023-10-26T03:43:28Z",
            "published": "2023-10-26T03:43:28Z",
            "summary": "Due to the growing volume of remote sensing data and the low latency required\nfor safe marine navigation, machine learning (ML) algorithms are being\ndeveloped to accelerate sea ice chart generation, currently a manual\ninterpretation task. However, the low signal-to-noise ratio of the freely\navailable Sentinel-1 Synthetic Aperture Radar (SAR) imagery, the ambiguity of\nbackscatter signals for ice types, and the scarcity of open-source\nhigh-resolution labelled data makes automating sea ice mapping challenging. We\nuse Extreme Earth version 2, a high-resolution benchmark dataset generated for\nML training and evaluation, to investigate the effectiveness of ML for\nautomated sea ice mapping. Our customized pipeline combines ResNets and Atrous\nSpatial Pyramid Pooling for SAR image segmentation. We investigate the\nperformance of our model for: i) binary classification of sea ice and open\nwater in a segmentation framework; and ii) a multiclass segmentation of five\nsea ice types. For binary ice-water classification, models trained with our\nlargest training set have weighted F1 scores all greater than 0.95 for January\nand July test scenes. Specifically, the median weighted F1 score was 0.98,\nindicating high performance for both months. By comparison, a competitive\nbaseline U-Net has a weighted average F1 score of ranging from 0.92 to 0.94\n(median 0.93) for July, and 0.97 to 0.98 (median 0.97) for January. Multiclass\nice type classification is more challenging, and even though our models achieve\n2% improvement in weighted F1 average compared to the baseline U-Net, test\nweighted F1 is generally between 0.6 and 0.80. Our approach can efficiently\nsegment full SAR scenes in one run, is faster than the baseline U-Net, retains\nspatial resolution and dimension, and is more robust against noise compared to\napproaches that rely on patch classification.",
            "author": [
                "Rafael Pires de Lima",
                "Behzad Vahedi",
                "Nick Hughes",
                "Andrew P. Barrett",
                "Walter Meier",
                "Morteza Karimzadeh"
            ],
            "link": [
                "http://dx.doi.org/10.1080/01431161.2023.2248560",
                "http://arxiv.org/abs/2310.17122v1",
                "http://arxiv.org/pdf/2310.17122v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17120v1",
            "title": "Topic Segmentation of Semi-Structured and Unstructured Conversational\n  Datasets using Language Models",
            "updated": "2023-10-26T03:37:51Z",
            "published": "2023-10-26T03:37:51Z",
            "summary": "Breaking down a document or a conversation into multiple contiguous segments\nbased on its semantic structure is an important and challenging problem in NLP,\nwhich can assist many downstream tasks. However, current works on topic\nsegmentation often focus on segmentation of structured texts. In this paper, we\ncomprehensively analyze the generalization capabilities of state-of-the-art\ntopic segmentation models on unstructured texts. We find that: (a) Current\nstrategies of pre-training on a large corpus of structured text such as\nWiki-727K do not help in transferability to unstructured conversational data.\n(b) Training from scratch with only a relatively small-sized dataset of the\ntarget unstructured domain improves the segmentation results by a significant\nmargin. We stress-test our proposed Topic Segmentation approach by\nexperimenting with multiple loss functions, in order to mitigate effects of\nimbalance in unstructured conversational datasets. Our empirical evaluation\nindicates that Focal Loss function is a robust alternative to Cross-Entropy and\nre-weighted Cross-Entropy loss function when segmenting unstructured and\nsemi-structured chats.",
            "author": [
                "Reshmi Ghosh",
                "Harjeet Singh Kajal",
                "Sharanya Kamath",
                "Dhuri Shrivastava",
                "Samyadeep Basu",
                "Hansi Zeng",
                "Soundararajan Srinivasan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17120v1",
                "http://arxiv.org/pdf/2310.17120v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17116v1",
            "title": "Real-time Neonatal Chest Sound Separation using Deep Learning",
            "updated": "2023-10-26T03:05:40Z",
            "published": "2023-10-26T03:05:40Z",
            "summary": "Auscultation for neonates is a simple and non-invasive method of providing\ndiagnosis for cardiovascular and respiratory disease. Such diagnosis often\nrequires high-quality heart and lung sounds to be captured during auscultation.\nHowever, in most cases, obtaining such high-quality sounds is non-trivial due\nto the chest sounds containing a mixture of heart, lung, and noise sounds. As\nsuch, additional preprocessing is needed to separate the chest sounds into\nheart and lung sounds. This paper proposes a novel deep-learning approach to\nseparate such chest sounds into heart and lung sounds. Inspired by the\nConv-TasNet model, the proposed model has an encoder, decoder, and mask\ngenerator. The encoder consists of a 1D convolution model and the decoder\nconsists of a transposed 1D convolution. The mask generator is constructed\nusing stacked 1D convolutions and transformers. The proposed model outperforms\nprevious methods in terms of objective distortion measures by 2.01 dB to 5.06\ndB in the artificial dataset, as well as computation time, with at least a\n17-time improvement. Therefore, our proposed model could be a suitable\npreprocessing step for any phonocardiogram-based health monitoring system.",
            "author": [
                "Yang Yi Poh",
                "Ethan Grooby",
                "Kenneth Tan",
                "Lindsay Zhou",
                "Arrabella King",
                "Ashwin Ramanathan",
                "Atul Malhotra",
                "Mehrtash Harandi",
                "Faezeh Marzbanrad"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17116v1",
                "http://arxiv.org/pdf/2310.17116v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17115v1",
            "title": "Optimal Robotic Assembly Sequence Planning: A Sequential Decision-Making\n  Approach",
            "updated": "2023-10-26T03:01:14Z",
            "published": "2023-10-26T03:01:14Z",
            "summary": "The optimal robot assembly planning problem is challenging due to the\nnecessity of finding the optimal solution amongst an exponentially vast number\nof possible plans, all while satisfying a selection of constraints.\nTraditionally, robotic assembly planning problems have been solved using\nheuristics, but these methods are specific to a given objective structure or\nset of problem parameters. In this paper, we propose a novel approach to\nrobotic assembly planning that poses assembly sequencing as a sequential\ndecision making problem, enabling us to harness methods that far outperform the\nstate-of-the-art. We formulate the problem as a Markov Decision Process (MDP)\nand utilize Dynamic Programming (DP) to find optimal assembly policies for\nmoderately sized strictures. We further expand our framework to exploit the\ndeterministic nature of assembly planning and introduce a class of optimal\nGraph Exploration Assembly Planners (GEAPs). For larger structures, we show how\nReinforcement Learning (RL) enables us to learn policies that generate high\nreward assembly sequences. We evaluate our approach on a variety of robotic\nassembly problems, such as the assembly of the Hubble Space Telescope, the\nInternational Space Station, and the James Webb Space Telescope. We further\nshowcase how our DP, GEAP, and RL implementations are capable of finding\noptimal solutions under a variety of different objective functions and how our\nformulation allows us to translate precedence constraints to branch pruning and\nthus further improve performance. We have published our code at\nhttps://github.com/labicon/ORASP-Code.",
            "author": [
                "Kartik Nagpal",
                "Negar Mehr"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17115v1",
                "http://arxiv.org/pdf/2310.17115v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17114v1",
            "title": "On the Convergence of CART under Sufficient Impurity Decrease Condition",
            "updated": "2023-10-26T03:01:11Z",
            "published": "2023-10-26T03:01:11Z",
            "summary": "The decision tree is a flexible machine learning model that finds its success\nin numerous applications. It is usually fitted in a recursively greedy manner\nusing CART. In this paper, we investigate the convergence rate of CART under a\nregression setting. First, we establish an upper bound on the prediction error\nof CART under a sufficient impurity decrease (SID) condition\n\\cite{chi2022asymptotic} -- our result improves upon the known result by\n\\cite{chi2022asymptotic} under a similar assumption. Furthermore, we provide\nexamples that demonstrate the error bound cannot be further improved by more\nthan a constant or a logarithmic factor. Second, we introduce a set of easily\nverifiable sufficient conditions for the SID condition. Specifically, we\ndemonstrate that the SID condition can be satisfied in the case of an additive\nmodel, provided that the component functions adhere to a ``locally reverse\nPoincar{\\'e} inequality\". We discuss several well-known function classes in\nnon-parametric estimation to illustrate the practical utility of this concept.",
            "author": [
                "Rahul Mazumder",
                "Haoyue Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17114v1",
                "http://arxiv.org/pdf/2310.17114v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17110v1",
            "title": "LLM4DyG: Can Large Language Models Solve Problems on Dynamic Graphs?",
            "updated": "2023-10-26T02:37:43Z",
            "published": "2023-10-26T02:37:43Z",
            "summary": "In an era marked by the increasing adoption of Large Language Models (LLMs)\nfor various tasks, there is a growing focus on exploring LLMs' capabilities in\nhandling web data, particularly graph data. Dynamic graphs, which capture\ntemporal network evolution patterns, are ubiquitous in real-world web data.\nEvaluating LLMs' competence in understanding spatial-temporal information on\ndynamic graphs is essential for their adoption in web applications, which\nremains unexplored in the literature. In this paper, we bridge the gap via\nproposing to evaluate LLMs' spatial-temporal understanding abilities on dynamic\ngraphs, to the best of our knowledge, for the first time. Specifically, we\npropose the LLM4DyG benchmark, which includes nine specially designed tasks\nconsidering the capability evaluation of LLMs from both temporal and spatial\ndimensions. Then, we conduct extensive experiments to analyze the impacts of\ndifferent data generators, data statistics, prompting techniques, and LLMs on\nthe model performance. Finally, we propose Disentangled Spatial-Temporal\nThoughts (DST2) for LLMs on dynamic graphs to enhance LLMs' spatial-temporal\nunderstanding abilities. Our main observations are: 1) LLMs have preliminary\nspatial-temporal understanding abilities on dynamic graphs, 2) Dynamic graph\ntasks show increasing difficulties for LLMs as the graph size and density\nincrease, while not sensitive to the time span and data generation mechanism,\n3) the proposed DST2 prompting method can help to improve LLMs'\nspatial-temporal understanding abilities on dynamic graphs for most tasks. The\ndata and codes will be open-sourced at publication time.",
            "author": [
                "Zeyang Zhang",
                "Xin Wang",
                "Ziwei Zhang",
                "Haoyang Li",
                "Yijian Qin",
                "Simin Wu",
                "Wenwu Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17110v1",
                "http://arxiv.org/pdf/2310.17110v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18257v1",
            "title": "MIM-GAN-based Anomaly Detection for Multivariate Time Series Data",
            "updated": "2023-10-26T02:09:39Z",
            "published": "2023-10-26T02:09:39Z",
            "summary": "The loss function of Generative adversarial network(GAN) is an important\nfactor that affects the quality and diversity of the generated samples for\nanomaly detection. In this paper, we propose an unsupervised multiple time\nseries anomaly detection algorithm based on the GAN with message importance\nmeasure(MIM-GAN). In particular, the time series data is divided into\nsubsequences using a sliding window. Then a generator and a discriminator\ndesigned based on the Long Short-Term Memory (LSTM) are employed to capture the\ntemporal correlations of the time series data. To avoid the local optimal\nsolution of loss function and the model collapse, we introduce an exponential\ninformation measure into the loss function of GAN. Additionally, a discriminant\nreconstruction score consisting on discrimination and reconstruction loss is\ntaken into account. The global optimal solution for the loss function is\nderived and the model collapse is proved to be avoided in our proposed\nMIM-GAN-based anomaly detection algorithm. Experimental results show that the\nproposed MIM-GAN-based anomaly detection algorithm has superior performance in\nterms of precision, recall, and F1 score.",
            "author": [
                "Shan Lu",
                "Zhicheng Dong",
                "Donghong Cai",
                "Fang Fang",
                "Dongcai Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18257v1",
                "http://arxiv.org/pdf/2310.18257v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17101v1",
            "title": "Multi-Speaker Expressive Speech Synthesis via Semi-supervised\n  Contrastive Learning",
            "updated": "2023-10-26T01:58:38Z",
            "published": "2023-10-26T01:58:38Z",
            "summary": "This paper aims to build an expressive TTS system for multi-speakers,\nsynthesizing a target speaker's speech with multiple styles and emotions. To\nthis end, we propose a novel contrastive learning-based TTS approach to\ntransfer style and emotion across speakers. Specifically, we construct\npositive-negative sample pairs at both utterance and category (such as\nemotion-happy or style-poet or speaker A) levels and leverage contrastive\nlearning to better extract disentangled style, emotion, and speaker\nrepresentations from speech. Furthermore, we introduce a semi-supervised\ntraining strategy to the proposed approach to effectively leverage multi-domain\ndata, including style-labeled data, emotion-labeled data, and unlabeled data.\nWe integrate the learned representations into an improved VITS model, enabling\nit to synthesize expressive speech with diverse styles and emotions for a\ntarget speaker. Experiments on multi-domain data demonstrate the good design of\nour model.",
            "author": [
                "Xinfa Zhu",
                "Yuke Li",
                "Yi Lei",
                "Ning Jiang",
                "Guoqing Zhao",
                "Lei Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17101v1",
                "http://arxiv.org/pdf/2310.17101v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17100v1",
            "title": "Network Design through Graph Neural Networks: Identifying Challenges and\n  Improving Performance",
            "updated": "2023-10-26T01:45:20Z",
            "published": "2023-10-26T01:45:20Z",
            "summary": "Graph Neural Network (GNN) research has produced strategies to modify a\ngraph's edges using gradients from a trained GNN, with the goal of network\ndesign. However, the factors which govern gradient-based editing are\nunderstudied, obscuring why edges are chosen and if edits are grounded in an\nedge's importance. Thus, we begin by analyzing the gradient computation in\nprevious works, elucidating the factors that influence edits and highlighting\nthe potential over-reliance on structural properties. Specifically, we find\nthat edges can achieve high gradients due to structural biases, rather than\nimportance, leading to erroneous edits when the factors are unrelated to the\ndesign task. To improve editing, we propose ORE, an iterative editing method\nthat (a) edits the highest scoring edges and (b) re-embeds the edited graph to\nrefresh gradients, leading to less biased edge choices. We empirically study\nORE through a set of proposed design tasks, each with an external validation\nmethod, demonstrating that ORE improves upon previous methods by up to 50%.",
            "author": [
                "Donald Loveland",
                "Rajmonda Caceres"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17100v1",
                "http://arxiv.org/pdf/2310.17100v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17097v2",
            "title": "Navigating Data Heterogeneity in Federated Learning A Semi-Supervised\n  Approach for Object Detection",
            "updated": "2023-10-27T17:13:00Z",
            "published": "2023-10-26T01:40:28Z",
            "summary": "Federated Learning (FL) has emerged as a potent framework for training models\nacross distributed data sources while maintaining data privacy. Nevertheless,\nit faces challenges with limited high-quality labels and non-IID client data,\nparticularly in applications like autonomous driving. To address these hurdles,\nwe navigate the uncharted waters of Semi-Supervised Federated Object Detection\n(SSFOD). We present a pioneering SSFOD framework, designed for scenarios where\nlabeled data reside only at the server while clients possess unlabeled data.\nNotably, our method represents the inaugural implementation of SSFOD for\nclients with 0% labeled non-IID data, a stark contrast to previous studies that\nmaintain some subset of labels at each client. We propose FedSTO, a two-stage\nstrategy encompassing Selective Training followed by Orthogonally enhanced\nfull-parameter training, to effectively address data shift (e.g. weather\nconditions) between server and clients. Our contributions include selectively\nrefining the backbone of the detector to avert overfitting, orthogonality\nregularization to boost representation divergence, and local EMA-driven pseudo\nlabel assignment to yield high-quality pseudo labels. Extensive validation on\nprominent autonomous driving datasets (BDD100K, Cityscapes, and SODA10M)\nattests to the efficacy of our approach, demonstrating state-of-the-art\nresults. Remarkably, FedSTO, using just 20-30% of labels, performs nearly as\nwell as fully-supervised centralized training methods.",
            "author": [
                "Taehyeon Kim",
                "Eric Lin",
                "Junu Lee",
                "Christian Lau",
                "Vaikkunth Mugunthan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17097v2",
                "http://arxiv.org/pdf/2310.17097v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17091v1",
            "title": "Detecting stealthy cyberattacks on adaptive cruise control vehicles: A\n  machine learning approach",
            "updated": "2023-10-26T01:22:10Z",
            "published": "2023-10-26T01:22:10Z",
            "summary": "With the advent of vehicles equipped with advanced driver-assistance systems,\nsuch as adaptive cruise control (ACC) and other automated driving features, the\npotential for cyberattacks on these automated vehicles (AVs) has emerged. While\novert attacks that force vehicles to collide may be easily identified, more\ninsidious attacks, which only slightly alter driving behavior, can result in\nnetwork-wide increases in congestion, fuel consumption, and even crash risk\nwithout being easily detected. To address the detection of such attacks, we\nfirst present a traffic model framework for three types of potential\ncyberattacks: malicious manipulation of vehicle control commands, false data\ninjection attacks on sensor measurements, and denial-of-service (DoS) attacks.\nWe then investigate the impacts of these attacks at both the individual vehicle\n(micro) and traffic flow (macro) levels. A novel generative adversarial network\n(GAN)-based anomaly detection model is proposed for real-time identification of\nsuch attacks using vehicle trajectory data. We provide numerical evidence {to\ndemonstrate} the efficacy of our machine learning approach in detecting\ncyberattacks on ACC-equipped vehicles. The proposed method is compared against\nsome recently proposed neural network models and observed to have higher\naccuracy in identifying anomalous driving behaviors of ACC vehicles.",
            "author": [
                "Tianyi Li",
                "Mingfeng Shang",
                "Shian Wang",
                "Raphael Stern"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17091v1",
                "http://arxiv.org/pdf/2310.17091v1"
            ],
            "primary_category": "cs.MA",
            "category": [
                "cs.MA",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17087v1",
            "title": "Good regularity creates large learning rate implicit biases: edge of\n  stability, balancing, and catapult",
            "updated": "2023-10-26T01:11:17Z",
            "published": "2023-10-26T01:11:17Z",
            "summary": "Large learning rates, when applied to gradient descent for nonconvex\noptimization, yield various implicit biases including the edge of stability\n(Cohen et al., 2021), balancing (Wang et al., 2022), and catapult (Lewkowycz et\nal., 2020). These phenomena cannot be well explained by classical optimization\ntheory. Though significant theoretical progress has been made in understanding\nthese implicit biases, it remains unclear for which objective functions would\nthey occur. This paper provides an initial step in answering this question,\nnamely that these implicit biases are in fact various tips of the same iceberg.\nThey occur when the objective function of optimization has some good\nregularity, which, in combination with a provable preference of large learning\nrate gradient descent for moving toward flatter regions, results in these\nnontrivial dynamical phenomena. To establish this result, we develop a new\nglobal convergence theory under large learning rates, for a family of nonconvex\nfunctions without globally Lipschitz continuous gradient, which was typically\nassumed in existing convergence analysis. A byproduct is the first\nnon-asymptotic convergence rate bound for large-learning-rate gradient descent\noptimization of nonconvex functions. We also validate our theory with\nexperiments on neural networks, where different losses, activation functions,\nand batch normalization all can significantly affect regularity and lead to\nvery different training dynamics.",
            "author": [
                "Yuqing Wang",
                "Zhenghao Xu",
                "Tuo Zhao",
                "Molei Tao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17087v1",
                "http://arxiv.org/pdf/2310.17087v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.DS",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17086v1",
            "title": "Transformers Learn Higher-Order Optimization Methods for In-Context\n  Learning: A Study with Linear Models",
            "updated": "2023-10-26T01:08:47Z",
            "published": "2023-10-26T01:08:47Z",
            "summary": "Transformers are remarkably good at in-context learning (ICL) -- learning\nfrom demonstrations without parameter updates -- but how they perform ICL\nremains a mystery. Recent work suggests that Transformers may learn in-context\nby internally running Gradient Descent, a first-order optimization method. In\nthis paper, we instead demonstrate that Transformers learn to implement\nhigher-order optimization methods to perform ICL. Focusing on in-context linear\nregression, we show that Transformers learn to implement an algorithm very\nsimilar to Iterative Newton's Method, a higher-order optimization method,\nrather than Gradient Descent. Empirically, we show that predictions from\nsuccessive Transformer layers closely match different iterations of Newton's\nMethod linearly, with each middle layer roughly computing 3 iterations. In\ncontrast, exponentially more Gradient Descent steps are needed to match an\nadditional Transformers layer; this suggests that Transformers have an\ncomparable rate of convergence with high-order methods such as Iterative\nNewton, which are exponentially faster than Gradient Descent. We also show that\nTransformers can learn in-context on ill-conditioned data, a setting where\nGradient Descent struggles but Iterative Newton succeeds. Finally, we show\ntheoretical results which support our empirical findings and have a close\ncorrespondence with them: we prove that Transformers can implement $k$\niterations of Newton's method with $\\mathcal{O}(k)$ layers.",
            "author": [
                "Deqing Fu",
                "Tian-Qi Chen",
                "Robin Jia",
                "Vatsal Sharan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17086v1",
                "http://arxiv.org/pdf/2310.17086v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17080v1",
            "title": "Automating lichen monitoring in ecological studies using instance\n  segmentation of time-lapse images",
            "updated": "2023-10-26T00:45:19Z",
            "published": "2023-10-26T00:45:19Z",
            "summary": "Lichens are symbiotic organisms composed of fungi, algae, and/or\ncyanobacteria that thrive in a variety of environments. They play important\nroles in carbon and nitrogen cycling, and contribute directly and indirectly to\nbiodiversity. Ecologists typically monitor lichens by using them as indicators\nto assess air quality and habitat conditions. In particular, epiphytic lichens,\nwhich live on trees, are key markers of air quality and environmental health. A\nnew method of monitoring epiphytic lichens involves using time-lapse cameras to\ngather images of lichen populations. These cameras are used by ecologists in\nNewfoundland and Labrador to subsequently analyze and manually segment the\nimages to determine lichen thalli condition and change. These methods are\ntime-consuming and susceptible to observer bias. In this work, we aim to\nautomate the monitoring of lichens over extended periods and to estimate their\nbiomass and condition to facilitate the task of ecologists. To accomplish this,\nour proposed framework uses semantic segmentation with an effective training\napproach to automate monitoring and biomass estimation of epiphytic lichens on\ntime-lapse images. We show that our method has the potential to significantly\nimprove the accuracy and efficiency of lichen population monitoring, making it\na valuable tool for forest ecologists and environmental scientists to evaluate\nthe impact of climate change on Canada's forests. To the best of our knowledge,\nthis is the first time that such an approach has been used to assist ecologists\nin monitoring and analyzing epiphytic lichens.",
            "author": [
                "Safwen Naimi",
                "Olfa Koubaa",
                "Wassim Bouachir",
                "Guillaume-Alexandre Bilodeau",
                "Gregory Jeddore",
                "Patricia Baines",
                "David Correia",
                "Andre Arsenault"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17080v1",
                "http://arxiv.org/pdf/2310.17080v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17078v1",
            "title": "HCT: Hybrid Convnet-Transformer for Parkinson's disease detection and\n  severity prediction from gait",
            "updated": "2023-10-26T00:43:15Z",
            "published": "2023-10-26T00:43:15Z",
            "summary": "In this paper, we propose a novel deep learning method based on a new Hybrid\nConvNet-Transformer architecture to detect and stage Parkinson's disease (PD)\nfrom gait data. We adopt a two-step approach by dividing the problem into two\nsub-problems. Our Hybrid ConvNet-Transformer model first distinguishes healthy\nversus parkinsonian patients. If the patient is parkinsonian, a multi-class\nHybrid ConvNet-Transformer model determines the Hoehn and Yahr (H&Y) score to\nassess the PD severity stage. Our hybrid architecture exploits the strengths of\nboth Convolutional Neural Networks (ConvNets) and Transformers to accurately\ndetect PD and determine the severity stage. In particular, we take advantage of\nConvNets to capture local patterns and correlations in the data, while we\nexploit Transformers for handling long-term dependencies in the input signal.\nWe show that our hybrid method achieves superior performance when compared to\nother state-of-the-art methods, with a PD detection accuracy of 97% and a\nseverity staging accuracy of 87%. Our source code is available at:\nhttps://github.com/SafwenNaimi",
            "author": [
                "Safwen Naimi",
                "Wassim Bouachir",
                "Guillaume-Alexandre Bilodeau"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17078v1",
                "http://arxiv.org/pdf/2310.17078v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17075v2",
            "title": "HyperFields: Towards Zero-Shot Generation of NeRFs from Text",
            "updated": "2023-10-27T14:35:04Z",
            "published": "2023-10-26T00:36:03Z",
            "summary": "We introduce HyperFields, a method for generating text-conditioned Neural\nRadiance Fields (NeRFs) with a single forward pass and (optionally) some\nfine-tuning. Key to our approach are: (i) a dynamic hypernetwork, which learns\na smooth mapping from text token embeddings to the space of NeRFs; (ii) NeRF\ndistillation training, which distills scenes encoded in individual NeRFs into\none dynamic hypernetwork. These techniques enable a single network to fit over\na hundred unique scenes. We further demonstrate that HyperFields learns a more\ngeneral map between text and NeRFs, and consequently is capable of predicting\nnovel in-distribution and out-of-distribution scenes -- either zero-shot or\nwith a few finetuning steps. Finetuning HyperFields benefits from accelerated\nconvergence thanks to the learned general map, and is capable of synthesizing\nnovel scenes 5 to 10 times faster than existing neural optimization-based\nmethods. Our ablation experiments show that both the dynamic architecture and\nNeRF distillation are critical to the expressivity of HyperFields.",
            "author": [
                "Sudarshan Babu",
                "Richard Liu",
                "Avery Zhou",
                "Michael Maire",
                "Greg Shakhnarovich",
                "Rana Hanocka"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17075v2",
                "http://arxiv.org/pdf/2310.17075v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17074v1",
            "title": "Benign Oscillation of Stochastic Gradient Descent with Large Learning\n  Rates",
            "updated": "2023-10-26T00:35:40Z",
            "published": "2023-10-26T00:35:40Z",
            "summary": "In this work, we theoretically investigate the generalization properties of\nneural networks (NN) trained by stochastic gradient descent (SGD) algorithm\nwith large learning rates. Under such a training regime, our finding is that,\nthe oscillation of the NN weights caused by the large learning rate SGD\ntraining turns out to be beneficial to the generalization of the NN, which\npotentially improves over the same NN trained by SGD with small learning rates\nthat converges more smoothly. In view of this finding, we call such a\nphenomenon \"benign oscillation\". Our theory towards demystifying such a\nphenomenon builds upon the feature learning perspective of deep learning.\nSpecifically, we consider a feature-noise data generation model that consists\nof (i) weak features which have a small $\\ell_2$-norm and appear in each data\npoint; (ii) strong features which have a larger $\\ell_2$-norm but only appear\nin a certain fraction of all data points; and (iii) noise. We prove that NNs\ntrained by oscillating SGD with a large learning rate can effectively learn the\nweak features in the presence of those strong features. In contrast, NNs\ntrained by SGD with a small learning rate can only learn the strong features\nbut makes little progress in learning the weak features. Consequently, when it\ncomes to the new testing data which consist of only weak features, the NN\ntrained by oscillating SGD with a large learning rate could still make correct\npredictions consistently, while the NN trained by small learning rate SGD\nfails. Our theory sheds light on how large learning rate training benefits the\ngeneralization of NNs. Experimental results demonstrate our finding on \"benign\noscillation\".",
            "author": [
                "Miao Lu",
                "Beining Wu",
                "Xiaodong Yang",
                "Difan Zou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17074v1",
                "http://arxiv.org/pdf/2310.17074v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17072v1",
            "title": "Isometric Motion Manifold Primitives",
            "updated": "2023-10-26T00:28:37Z",
            "published": "2023-10-26T00:28:37Z",
            "summary": "The Motion Manifold Primitive (MMP) produces, for a given task, a continuous\nmanifold of trajectories each of which can successfully complete the task. It\nconsists of the decoder function that parametrizes the manifold and the\nprobability density in the latent coordinate space. In this paper, we first\nshow that the MMP performance can significantly degrade due to the geometric\ndistortion in the latent space -- by distortion, we mean that similar motions\nare not located nearby in the latent space. We then propose {\\it Isometric\nMotion Manifold Primitives (IMMP)} whose latent coordinate space preserves the\ngeometry of the manifold. For this purpose, we formulate and use a Riemannian\nmetric for the motion space (i.e., parametric curve space), which we call a\n{\\it CurveGeom Riemannian metric}. Experiments with planar obstacle-avoiding\nmotions and pushing manipulation tasks show that IMMP significantly outperforms\nexisting MMP methods. Code is available at\nhttps://github.com/Gabe-YHLee/IMMP-public.",
            "author": [
                "Yonghyeon Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17072v1",
                "http://arxiv.org/pdf/2310.17072v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17064v1",
            "title": "math-PVS: A Large Language Model Framework to Map Scientific\n  Publications to PVS Theories",
            "updated": "2023-10-25T23:54:04Z",
            "published": "2023-10-25T23:54:04Z",
            "summary": "As artificial intelligence (AI) gains greater adoption in a wide variety of\napplications, it has immense potential to contribute to mathematical discovery,\nby guiding conjecture generation, constructing counterexamples, assisting in\nformalizing mathematics, and discovering connections between different\nmathematical areas, to name a few.\n  While prior work has leveraged computers for exhaustive mathematical proof\nsearch, recent efforts based on large language models (LLMs) aspire to position\ncomputing platforms as co-contributors in the mathematical research process.\nDespite their current limitations in logic and mathematical tasks, there is\ngrowing interest in melding theorem proving systems with foundation models.\nThis work investigates the applicability of LLMs in formalizing advanced\nmathematical concepts and proposes a framework that can critically review and\ncheck mathematical reasoning in research papers. Given the noted reasoning\nshortcomings of LLMs, our approach synergizes the capabilities of proof\nassistants, specifically PVS, with LLMs, enabling a bridge between textual\ndescriptions in academic papers and formal specifications in PVS. By harnessing\nthe PVS environment, coupled with data ingestion and conversion mechanisms, we\nenvision an automated process, called \\emph{math-PVS}, to extract and formalize\nmathematical theorems from research papers, offering an innovative tool for\nacademic review and discovery.",
            "author": [
                "Hassen Saidi",
                "Susmit Jha",
                "Tuhin Sahai"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17064v1",
                "http://arxiv.org/pdf/2310.17064v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.LG",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17063v1",
            "title": "Coreset Markov Chain Monte Carlo",
            "updated": "2023-10-25T23:53:27Z",
            "published": "2023-10-25T23:53:27Z",
            "summary": "A Bayesian coreset is a small, weighted subset of data that replaces the full\ndataset during inference in order to reduce computational cost. However, state\nof the art methods for tuning coreset weights are expensive, require nontrivial\nuser input, and impose constraints on the model. In this work, we propose a new\nmethod -- Coreset MCMC -- that simulates a Markov chain targeting the coreset\nposterior, while simultaneously updating the coreset weights using those same\ndraws. Coreset MCMC is simple to implement and tune, and can be used with any\nexisting MCMC kernel. We analyze Coreset MCMC in a representative setting to\nobtain key insights about the convergence behaviour of the method. Empirical\nresults demonstrate that Coreset MCMC provides higher quality posterior\napproximations and reduced computational cost compared with other coreset\nconstruction methods. Further, compared with other general subsampling MCMC\nmethods, we find that Coreset MCMC has a higher sampling efficiency with\ncompetitively accurate posterior approximations.",
            "author": [
                "Naitong Chen",
                "Trevor Campbell"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17063v1",
                "http://arxiv.org/pdf/2310.17063v1"
            ],
            "primary_category": "stat.CO",
            "category": [
                "stat.CO",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17060v1",
            "title": "Aplicacion de Robots Humanoides como Guias Interactivos en Museos: Una\n  Simulacion con el Robot NAO",
            "updated": "2023-10-25T23:44:09Z",
            "published": "2023-10-25T23:44:09Z",
            "summary": "This article presents an application that evaluates the feasibility of\nhumanoid robots as interactive guides in art museums. The application entailes\nprogramming a NAO robot and a chatbot to provide information about art pieces\nin a simulated museum environment. In this controlled scenario, the learning\nemployees interact with the robot and the chatbot. The result is a skilled\nparticipation in the interactions, along with the effectiveness of the robot\nand chatbot that communicates the basic details of the art objects. You see\nnatural and fluid interactions between the students and the robot. This\nsuggests that the addition of humanoid robots to museums may provide a better\nexperience for visitors, but also the need to continue to do more to optimize\nthe quality of interaction. This study contributes to understanding the\npossibilities and requirements of applying humanoid technologies in a cultural\ncontext.",
            "author": [
                "Hiago Sodre",
                "Pablo Moraes",
                "Monica Rodriguez",
                "Victor Castelli",
                "Pamela Barboza",
                "Martin Mattos",
                "Guillermo Vivas",
                "Bruna de Vargas",
                "Tobias D\u00f6rnbach",
                "Ricardo Grando"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17060v1",
                "http://arxiv.org/pdf/2310.17060v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17056v1",
            "title": "Strategizing EV Charging and Renewable Integration in Texas",
            "updated": "2023-10-25T23:34:25Z",
            "published": "2023-10-25T23:34:25Z",
            "summary": "Exploring the convergence of electric vehicles (EVs), renewable energy, and\nsmart grid technologies in the context of Texas, this study addresses\nchallenges hindering the widespread adoption of EVs. Acknowledging their\nenvironmental benefits, the research focuses on grid stability concerns,\nuncoordinated charging patterns, and the complicated relationship between EVs\nand renewable energy sources. Dynamic time warping (DTW) clustering and k-means\nclustering methodologies categorize days based on total load and net load,\noffering nuanced insights into daily electricity consumption and renewable\nenergy generation patterns. By establishing optimal charging and\nvehicle-to-grid (V2G) windows tailored to specific load characteristics, the\nstudy provides a sophisticated methodology for strategic decision-making in\nenergy consumption and renewable integration. The findings contribute to the\nongoing discourse on achieving a sustainable and resilient energy future\nthrough the seamless integration of EVs into smart grids.",
            "author": [
                "Mohammad Mohammadi",
                "Jesse Thornburg"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17056v1",
                "http://arxiv.org/pdf/2310.17056v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17054v1",
            "title": "BOOST: Harnessing Black-Box Control to Boost Commonsense in LMs'\n  Generation",
            "updated": "2023-10-25T23:32:12Z",
            "published": "2023-10-25T23:32:12Z",
            "summary": "Large language models (LLMs) such as GPT-3 have demonstrated a strong\ncapability to generate coherent and contextually relevant text. However, amidst\ntheir successes, a crucial issue persists: their generated outputs still lack\ncommonsense at times. Moreover, fine-tuning the entire LLM towards more\ncommonsensical outputs is computationally expensive if not infeasible. In this\npaper, we present a computation-efficient framework that steers a frozen\nPre-Trained Language Model (PTLM) towards more commonsensical generation (i.e.,\nproducing a plausible output that incorporates a list of concepts in a\nmeaningful way). Specifically, we first construct a reference-free evaluator\nthat assigns a sentence with a commonsensical score by grounding the sentence\nto a dynamic commonsense knowledge base from four different relational aspects.\nWe then use the scorer as the oracle for commonsense knowledge, and extend the\ncontrollable generation method called NADO to train an auxiliary head that\nguides a fixed PTLM to better satisfy the oracle. We test our framework on a\nseries of GPT-2-, Flan-T5-, and Alpaca-based language models (LMs) on two\nconstrained concept-to-sentence benchmarks. Human evaluation results\ndemonstrate that our method consistently leads to the most commonsensical\noutputs.",
            "author": [
                "Yufei Tian",
                "Felix Zhang",
                "Nanyun Peng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17054v1",
                "http://arxiv.org/pdf/2310.17054v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17052v2",
            "title": "Real-Time Performance of OPC UA",
            "updated": "2023-11-19T17:57:05Z",
            "published": "2023-10-25T23:25:22Z",
            "summary": "OPC UA is an industry-standard machine-to-machine communication protocol in\nthe Industrial Internet of Things. It relies on time-sensitive networking to\nmeet the real-time requirements of various applications. Time-sensitive\nnetworking is implemented through various queueing disciplines (qdiscs),\nincluding Time Aware Priority, Multiqueue Priority, Earliest TxTime First, and\nCredit-Based Shaper. Despite their significance, prior studies on these qdiscs\nhave been limited to a few. They have often been confined to point-to-point\nnetwork topologies using proprietary software or specialized hardware. This\nstudy builds upon existing research by evaluating all these qdiscs in\npoint-to-point and bridged topologies using open-source software on commercial\noff-the-shelf hardware. We first identify the optimal configuration for each\nqdisc and then compare their jitter, latency, and reliability through\nexperiments. Our results show that open-source OPC UA on commercial\noff-the-shelf hardware can effectively meet the stringent real-time\nrequirements of many industrial applications and provide a foundation for\nfuture research and practical deployments.",
            "author": [
                "Erkin Kirdan",
                "Filip Rezabek",
                "Nikolas M\u00fclbauer",
                "Georg Carle",
                "Marc-Oliver Pahl"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17052v2",
                "http://arxiv.org/pdf/2310.17052v2"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17050v1",
            "title": "Exploring Question Decomposition for Zero-Shot VQA",
            "updated": "2023-10-25T23:23:57Z",
            "published": "2023-10-25T23:23:57Z",
            "summary": "Visual question answering (VQA) has traditionally been treated as a\nsingle-step task where each question receives the same amount of effort, unlike\nnatural human question-answering strategies. We explore a question\ndecomposition strategy for VQA to overcome this limitation. We probe the\nability of recently developed large vision-language models to use human-written\ndecompositions and produce their own decompositions of visual questions,\nfinding they are capable of learning both tasks from demonstrations alone.\nHowever, we show that naive application of model-written decompositions can\nhurt performance. We introduce a model-driven selective decomposition approach\nfor second-guessing predictions and correcting errors, and validate its\neffectiveness on eight VQA tasks across three domains, showing consistent\nimprovements in accuracy, including improvements of >20% on medical VQA\ndatasets and boosting the zero-shot performance of BLIP-2 above chance on a VQA\nreformulation of the challenging Winoground task. Project Site:\nhttps://zaidkhan.me/decomposition-0shot-vqa/",
            "author": [
                "Zaid Khan",
                "Vijay Kumar BG",
                "Samuel Schulter",
                "Manmohan Chandraker",
                "Yun Fu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17050v1",
                "http://arxiv.org/pdf/2310.17050v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17675v1",
            "title": "Early Detection of Tuberculosis with Machine Learning Cough Audio\n  Analysis: Towards More Accessible Global Triaging Usage",
            "updated": "2023-10-25T23:22:20Z",
            "published": "2023-10-25T23:22:20Z",
            "summary": "Tuberculosis (TB), a bacterial disease mainly affecting the lungs, is one of\nthe leading infectious causes of mortality worldwide. To prevent TB from\nspreading within the body, which causes life-threatening complications, timely\nand effective anti-TB treatment is crucial. Cough, an objective biomarker for\nTB, is a triage tool that monitors treatment response and regresses with\nsuccessful therapy. Current gold standards for TB diagnosis are slow or\ninaccessible, especially in rural areas where TB is most prevalent. In\naddition, current machine learning (ML) diagnosis research, like utilizing\nchest radiographs, is ineffective and does not monitor treatment progression.\nTo enable effective diagnosis, an ensemble model was developed that analyzes,\nusing a novel ML architecture, coughs' acoustic epidemiologies from\nsmartphones' microphones to detect TB. The architecture includes a 2D-CNN and\nXGBoost that was trained on 724,964 cough audio samples and demographics from 7\ncountries. After feature extraction (Mel-spectrograms) and data augmentation\n(IR-convolution), the model achieved AUROC (area under the receiving operator\ncharacteristic) of 88%, surpassing WHO's requirements for screening tests. The\nresults are available within 15 seconds and can easily be accessible via a\nmobile app. This research helps to improve TB diagnosis through a promising\naccurate, quick, and accessible triaging tool.",
            "author": [
                "Chandra Suda"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17675v1",
                "http://arxiv.org/pdf/2310.17675v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.LG",
                "cs.SD",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17049v1",
            "title": "Learning Repeatable Speech Embeddings Using An Intra-class Correlation\n  Regularizer",
            "updated": "2023-10-25T23:21:46Z",
            "published": "2023-10-25T23:21:46Z",
            "summary": "A good supervised embedding for a specific machine learning task is only\nsensitive to changes in the label of interest and is invariant to other\nconfounding factors. We leverage the concept of repeatability from measurement\ntheory to describe this property and propose to use the intra-class correlation\ncoefficient (ICC) to evaluate the repeatability of embeddings. We then propose\na novel regularizer, the ICC regularizer, as a complementary component for\ncontrastive losses to guide deep neural networks to produce embeddings with\nhigher repeatability. We use simulated data to explain why the ICC regularizer\nworks better on minimizing the intra-class variance than the contrastive loss\nalone. We implement the ICC regularizer and apply it to three speech tasks:\nspeaker verification, voice style conversion, and a clinical application for\ndetecting dysphonic voice. The experimental results demonstrate that adding an\nICC regularizer can improve the repeatability of learned embeddings compared to\nonly using the contrastive loss; further, these embeddings lead to improved\nperformance in these downstream tasks.",
            "author": [
                "Jianwei Zhang",
                "Suren Jayasuriya",
                "Visar Berisha"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17049v1",
                "http://arxiv.org/pdf/2310.17049v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.AI",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17044v1",
            "title": "Learning to Rank for Active Learning via Multi-Task Bilevel Optimization",
            "updated": "2023-10-25T22:50:09Z",
            "published": "2023-10-25T22:50:09Z",
            "summary": "Active learning is a promising paradigm to reduce the labeling cost by\nstrategically requesting labels to improve model performance. However, existing\nactive learning methods often rely on expensive acquisition function to\ncompute, extensive modeling retraining and multiple rounds of interaction with\nannotators. To address these limitations, we propose a novel approach for\nactive learning, which aims to select batches of unlabeled instances through a\nlearned surrogate model for data acquisition. A key challenge in this approach\nis developing an acquisition function that generalizes well, as the history of\ndata, which forms part of the utility function's input, grows over time. Our\nnovel algorithmic contribution is a bilevel multi-task bilevel optimization\nframework that predicts the relative utility -- measured by the validation\naccuracy -- of different training sets, and ensures the learned acquisition\nfunction generalizes effectively. For cases where validation accuracy is\nexpensive to evaluate, we introduce efficient interpolation-based surrogate\nmodels to estimate the utility function, reducing the evaluation cost. We\ndemonstrate the performance of our approach through extensive experiments on\nstandard active classification benchmarks. By employing our learned utility\nfunction, we show significant improvements over traditional techniques, paving\nthe way for more efficient and effective utility maximization in active\nlearning applications.",
            "author": [
                "Zixin Ding",
                "Si Chen",
                "Ruoxi Jia",
                "Yuxin Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17044v1",
                "http://arxiv.org/pdf/2310.17044v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17042v1",
            "title": "StochGradAdam: Accelerating Neural Networks Training with Stochastic\n  Gradient Sampling",
            "updated": "2023-10-25T22:45:31Z",
            "published": "2023-10-25T22:45:31Z",
            "summary": "In the rapidly advancing domain of deep learning optimization, this paper\nunveils the StochGradAdam optimizer, a novel adaptation of the well-regarded\nAdam algorithm. Central to StochGradAdam is its gradient sampling technique.\nThis method not only ensures stable convergence but also leverages the\nadvantages of selective gradient consideration, fostering robust training by\npotentially mitigating the effects of noisy or outlier data and enhancing the\nexploration of the loss landscape for more dependable convergence. In both\nimage classification and segmentation tasks, StochGradAdam has demonstrated\nsuperior performance compared to the traditional Adam optimizer. By judiciously\nsampling a subset of gradients at each iteration, the optimizer is optimized\nfor managing intricate models. The paper provides a comprehensive exploration\nof StochGradAdam's methodology, from its mathematical foundations to bias\ncorrection strategies, heralding a promising advancement in deep learning\ntraining techniques.",
            "author": [
                "Juyoung Yun"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17042v1",
                "http://arxiv.org/pdf/2310.17042v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17037v1",
            "title": "Event-by-event Comparison between Machine-Learning- and\n  Transfer-Matrix-based Unfolding Methods",
            "updated": "2023-10-25T22:28:04Z",
            "published": "2023-10-25T22:28:04Z",
            "summary": "The unfolding of detector effects is a key aspect of comparing experimental\ndata with theoretical predictions. In recent years, different Machine-Learning\nmethods have been developed to provide novel features, e.g. high dimensionality\nor a probabilistic single-event unfolding based on generative neural networks.\nTraditionally, many analyses unfold detector effects using\ntransfer-matrix--based algorithms, which are well established in\nlow-dimensional unfolding. They yield an unfolded distribution of the total\nspectrum, together with its covariance matrix. This paper proposes a method to\nobtain probabilistic single-event unfolded distributions, together with their\nuncertainties and correlations, for the transfer-matrix--based unfolding. The\nalgorithm is first validated on a toy model and then applied to pseudo-data for\nthe $pp\\rightarrow Z\\gamma \\gamma$ process. In both examples the performance is\ncompared to the single-event unfolding of the Machine-Learning--based Iterative\ncINN unfolding (IcINN).",
            "author": [
                "Mathias Backes",
                "Anja Butter",
                "Monica Dunford",
                "Bogdan Malaescu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17037v1",
                "http://arxiv.org/pdf/2310.17037v1"
            ],
            "primary_category": "physics.data-an",
            "category": [
                "physics.data-an",
                "hep-ex",
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17032v1",
            "title": "Quantum Long Short-Term Memory (QLSTM) vs Classical LSTM in Time Series\n  Forecasting: A Comparative Study in Solar Power Forecasting",
            "updated": "2023-10-25T22:19:05Z",
            "published": "2023-10-25T22:19:05Z",
            "summary": "Accurately forecasting solar power generation is crucial in the global\nprogression towards sustainable energy systems. In this study, we conduct a\nmeticulous comparison between Quantum Long Short-Term Memory (QLSTM) and\nclassical Long Short-Term Memory (LSTM) models for solar power production\nforecasting. Our controlled experiments reveal promising advantages of QLSTMs,\nincluding accelerated training convergence and substantially reduced test loss\nwithin the initial epoch compared to classical LSTMs. These empirical findings\ndemonstrate QLSTM's potential to swiftly assimilate complex time series\nrelationships, enabled by quantum phenomena like superposition. However,\nrealizing QLSTM's full capabilities necessitates further research into model\nvalidation across diverse conditions, systematic hyperparameter optimization,\nhardware noise resilience, and applications to correlated renewable forecasting\nproblems. With continued progress, quantum machine learning can offer a\nparadigm shift in renewable energy time series prediction. This pioneering work\nprovides initial evidence substantiating quantum advantages over classical\nLSTM, while acknowledging present limitations. Through rigorous benchmarking\ngrounded in real-world data, our study elucidates a promising trajectory for\nquantum learning in renewable forecasting. Additional research and development\ncan further actualize this potential to achieve unprecedented accuracy and\nreliability in predicting solar power generation worldwide.",
            "author": [
                "Saad Zafar Khan",
                "Nazeefa Muzammil",
                "Syed Mohammad Hassan Zaidi",
                "Abdulah Jeza Aljohani",
                "Haibat Khan",
                "Salman Ghafoor"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17032v1",
                "http://arxiv.org/pdf/2310.17032v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17029v1",
            "title": "Toward the use of proxies for efficient learning manipulation and\n  locomotion strategies on soft robots",
            "updated": "2023-10-25T22:12:58Z",
            "published": "2023-10-25T22:12:58Z",
            "summary": "Soft robots are naturally designed to perform safe interactions with their\nenvironment, like locomotion and manipulation. In the literature, there are now\nmany concepts, often bio-inspired, to propose new modes of locomotion or\ngrasping. However, a methodology for implementing motion planning of these\ntasks, as exists for rigid robots, is still lacking. One of the difficulties\ncomes from the modeling of these robots, which is very different, as it is\nbased on the mechanics of deformable bodies. These models, whose dimension is\noften very large, make learning and optimization methods very costly. In this\npaper, we propose a proxy approach, as exists for humanoid robotics. This proxy\nis a simplified model of the robot that enables frugal learning of a motion\nstrategy. This strategy is then transferred to the complete model to obtain the\ncorresponding actuation inputs. Our methodology is illustrated and analyzed on\ntwo classical designs of soft robots doing manipulation and locomotion tasks.",
            "author": [
                "Etienne M\u00e9nager",
                "Quentin Peyron",
                "Christian Duriez"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17029v1",
                "http://arxiv.org/pdf/2310.17029v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17023v1",
            "title": "On the Identifiability and Interpretability of Gaussian Process Models",
            "updated": "2023-10-25T22:00:29Z",
            "published": "2023-10-25T22:00:29Z",
            "summary": "In this paper, we critically examine the prevalent practice of using additive\nmixtures of Mat\\'ern kernels in single-output Gaussian process (GP) models and\nexplore the properties of multiplicative mixtures of Mat\\'ern kernels for\nmulti-output GP models. For the single-output case, we derive a series of\ntheoretical results showing that the smoothness of a mixture of Mat\\'ern\nkernels is determined by the least smooth component and that a GP with such a\nkernel is effectively equivalent to the least smooth kernel component.\nFurthermore, we demonstrate that none of the mixing weights or parameters\nwithin individual kernel components are identifiable. We then turn our\nattention to multi-output GP models and analyze the identifiability of the\ncovariance matrix $A$ in the multiplicative kernel $K(x,y) = AK_0(x,y)$, where\n$K_0$ is a standard single output kernel such as Mat\\'ern. We show that $A$ is\nidentifiable up to a multiplicative constant, suggesting that multiplicative\nmixtures are well suited for multi-output tasks. Our findings are supported by\nextensive simulations and real applications for both single- and multi-output\nsettings. This work provides insight into kernel selection and interpretation\nfor GP models, emphasizing the importance of choosing appropriate kernel\nstructures for different tasks.",
            "author": [
                "Jiawen Chen",
                "Wancen Mu",
                "Yun Li",
                "Didong Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17023v1",
                "http://arxiv.org/pdf/2310.17023v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "62M30"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17022v1",
            "title": "Controlled Decoding from Language Models",
            "updated": "2023-10-25T22:00:05Z",
            "published": "2023-10-25T22:00:05Z",
            "summary": "We propose controlled decoding (CD), a novel off-policy reinforcement\nlearning method to control the autoregressive generation from language models\ntowards high reward outcomes. CD solves an off-policy reinforcement learning\nproblem through a value function for the reward, which we call a prefix scorer.\nThe prefix scorer is used at inference time to steer the generation towards\nhigher reward outcomes. We show that the prefix scorer may be trained on\n(possibly) off-policy data to predict the expected reward when decoding is\ncontinued from a partially decoded response. We empirically demonstrate that CD\nis effective as a control mechanism on Reddit conversations corpus. We also\nshow that the modularity of the design of CD makes it possible to control for\nmultiple rewards, effectively solving a multi-objective reinforcement learning\nproblem with no additional complexity. Finally, we show that CD can be applied\nin a novel blockwise fashion at inference-time, again without the need for any\ntraining-time changes, essentially bridging the gap between the popular\nbest-of-$K$ strategy and token-level reinforcement learning. This makes CD a\npromising approach for alignment of language models.",
            "author": [
                "Sidharth Mudgal",
                "Jong Lee",
                "Harish Ganapathy",
                "YaGuang Li",
                "Tao Wang",
                "Yanping Huang",
                "Zhifeng Chen",
                "Heng-Tze Cheng",
                "Michael Collins",
                "Trevor Strohman",
                "Jilin Chen",
                "Alex Beutel",
                "Ahmad Beirami"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17022v1",
                "http://arxiv.org/pdf/2310.17022v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17021v2",
            "title": "Streaming Factor Trajectory Learning for Temporal Tensor Decomposition",
            "updated": "2023-11-07T23:05:42Z",
            "published": "2023-10-25T21:58:52Z",
            "summary": "Practical tensor data is often along with time information. Most existing\ntemporal decomposition approaches estimate a set of fixed factors for the\nobjects in each tensor mode, and hence cannot capture the temporal evolution of\nthe objects' representation. More important, we lack an effective approach to\ncapture such evolution from streaming data, which is common in real-world\napplications. To address these issues, we propose Streaming Factor Trajectory\nLearning for temporal tensor decomposition. We use Gaussian processes (GPs) to\nmodel the trajectory of factors so as to flexibly estimate their temporal\nevolution. To address the computational challenges in handling streaming data,\nwe convert the GPs into a state-space prior by constructing an equivalent\nstochastic differential equation (SDE). We develop an efficient online\nfiltering algorithm to estimate a decoupled running posterior of the involved\nfactor states upon receiving new data. The decoupled estimation enables us to\nconduct standard Rauch-Tung-Striebel smoothing to compute the full posterior of\nall the trajectories in parallel, without the need for revisiting any previous\ndata. We have shown the advantage of SFTL in both synthetic tasks and\nreal-world applications. The code is available at\n{https://github.com/xuangu-fang/Streaming-Factor-Trajectory-Learning}.",
            "author": [
                "Shikai Fang",
                "Xin Yu",
                "Shibo Li",
                "Zheng Wang",
                "Robert Kirby",
                "Shandian Zhe"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17021v2",
                "http://arxiv.org/pdf/2310.17021v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17019v1",
            "title": "Conditionally Combining Robot Skills using Large Language Models",
            "updated": "2023-10-25T21:46:34Z",
            "published": "2023-10-25T21:46:34Z",
            "summary": "This paper combines two contributions. First, we introduce an extension of\nthe Meta-World benchmark, which we call \"Language-World,\" which allows a large\nlanguage model to operate in a simulated robotic environment using\nsemi-structured natural language queries and scripted skills described using\nnatural language. By using the same set of tasks as Meta-World, Language-World\nresults can be easily compared to Meta-World results, allowing for a point of\ncomparison between recent methods using Large Language Models (LLMs) and those\nusing Deep Reinforcement Learning. Second, we introduce a method we call Plan\nConditioned Behavioral Cloning (PCBC), that allows finetuning the behavior of\nhigh-level plans using end-to-end demonstrations. Using Language-World, we show\nthat PCBC is able to achieve strong performance in a variety of few-shot\nregimes, often achieving task generalization with as little as a single\ndemonstration. We have made Language-World available as open-source software at\nhttps://github.com/krzentner/language-world/.",
            "author": [
                "K. R. Zentner",
                "Ryan Julian",
                "Brian Ichter",
                "Gaurav S. Sukhatme"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17019v1",
                "http://arxiv.org/pdf/2310.17019v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17015v3",
            "title": "Data Augmentation for Emotion Detection in Small Imbalanced Text Data",
            "updated": "2023-10-30T13:33:16Z",
            "published": "2023-10-25T21:29:36Z",
            "summary": "Emotion recognition in text, the task of identifying emotions such as joy or\nanger, is a challenging problem in NLP with many applications. One of the\nchallenges is the shortage of available datasets that have been annotated with\nemotions. Certain existing datasets are small, follow different emotion\ntaxonomies and display imbalance in their emotion distribution. In this work,\nwe studied the impact of data augmentation techniques precisely when applied to\nsmall imbalanced datasets, for which current state-of-the-art models (such as\nRoBERTa) under-perform. Specifically, we utilized four data augmentation\nmethods (Easy Data Augmentation EDA, static and contextual Embedding-based, and\nProtAugment) on three datasets that come from different sources and vary in\nsize, emotion categories and distributions. Our experimental results show that\nusing the augmented data when training the classifier model leads to\nsignificant improvements. Finally, we conducted two case studies: a) directly\nusing the popular chat-GPT API to paraphrase text using different prompts, and\nb) using external data to augment the training set. Results show the promising\npotential of these methods.",
            "author": [
                "Anna Koufakou",
                "Diego Grisales",
                "Ragy Costa de jesus",
                "Oscar Fox"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17015v3",
                "http://arxiv.org/pdf/2310.17015v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17010v1",
            "title": "This Reads Like That: Deep Learning for Interpretable Natural Language\n  Processing",
            "updated": "2023-10-25T21:18:35Z",
            "published": "2023-10-25T21:18:35Z",
            "summary": "Prototype learning, a popular machine learning method designed for inherently\ninterpretable decisions, leverages similarities to learned prototypes for\nclassifying new data. While it is mainly applied in computer vision, in this\nwork, we build upon prior research and further explore the extension of\nprototypical networks to natural language processing. We introduce a learned\nweighted similarity measure that enhances the similarity computation by\nfocusing on informative dimensions of pre-trained sentence embeddings.\nAdditionally, we propose a post-hoc explainability mechanism that extracts\nprediction-relevant words from both the prototype and input sentences. Finally,\nwe empirically demonstrate that our proposed method not only improves\npredictive performance on the AG News and RT Polarity datasets over a previous\nprototype-based approach, but also improves the faithfulness of explanations\ncompared to rationale-based recurrent convolutions.",
            "author": [
                "Claudio Fanconi",
                "Moritz Vandenhirtz",
                "Severin Husmann",
                "Julia E. Vogt"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17010v1",
                "http://arxiv.org/pdf/2310.17010v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17009v1",
            "title": "Simulation based stacking",
            "updated": "2023-10-25T21:17:12Z",
            "published": "2023-10-25T21:17:12Z",
            "summary": "Simulation-based inference has been popular for amortized Bayesian\ncomputation. It is typical to have more than one posterior approximation, from\ndifferent inference algorithms, different architectures, or simply the\nrandomness of initialization and stochastic gradients. With a provable\nasymptotic guarantee, we present a general stacking framework to make use of\nall available posterior approximations. Our stacking method is able to combine\ndensities, simulation draws, confidence intervals, and moments, and address the\noverall precision, calibration, coverage, and bias at the same time. We\nillustrate our method on several benchmark simulations and a challenging\ncosmological inference task.",
            "author": [
                "Yuling Yao",
                "Bruno R\u00e9galdo-Saint Blancard",
                "Justin Domke"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17009v1",
                "http://arxiv.org/pdf/2310.17009v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "cs.LG",
                "stat.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17006v1",
            "title": "Mode Selection and Target Classification in Cognitive Radar Networks",
            "updated": "2023-10-25T21:08:13Z",
            "published": "2023-10-25T21:08:13Z",
            "summary": "Cognitive Radar Networks were proposed by Simon Haykin in 2006 to address\nproblems with large legacy radar implementations - primarily, single-point\nvulnerabilities and lack of adaptability. This work proposes to leverage the\nadaptability of cognitive radar networks to trade between active radar\nobservation, which uses high power and risks interception, and passive signal\nparameter estimation, which uses target emissions to gain side information and\nlower the power necessary to accurately track multiple targets. The goal of the\nnetwork is to learn over many target tracks both the characteristics of the\ntargets as well as the optimal action choices for each type of target. In order\nto select between the available actions, we utilize a multi-armed bandit model,\nusing current class information as prior information. When the active radar\naction is selected, the node estimates the physical behavior of targets through\nthe radar emissions. When the passive action is selected, the node estimates\nthe radio behavior of targets through passive sensing. Over many target tracks,\nthe network collects the observed behavior of targets and forms clusters of\nsimilarly-behaved targets. In this way, the network meta-learns the target\nclass distributions while learning the optimal mode selections for each target\nclass.",
            "author": [
                "William W. Howard",
                "Samuel R. Shebert",
                "Benjamin H. Kirk",
                "R. Michael Buehrer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17006v1",
                "http://arxiv.org/pdf/2310.17006v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12862v1",
            "title": "TorchSparse++: Efficient Training and Inference Framework for Sparse\n  Convolution on GPUs",
            "updated": "2023-10-25T21:02:38Z",
            "published": "2023-10-25T21:02:38Z",
            "summary": "Sparse convolution plays a pivotal role in emerging workloads, including\npoint cloud processing in AR/VR, autonomous driving, and graph understanding in\nrecommendation systems. Since the computation pattern is sparse and irregular,\nspecialized high-performance kernels are required. Existing GPU libraries offer\ntwo dataflow types for sparse convolution. The gather-GEMM-scatter dataflow is\neasy to implement but not optimal in performance, while the dataflows with\noverlapped computation and memory access (e.g.implicit GEMM) are highly\nperformant but have very high engineering costs. In this paper, we introduce\nTorchSparse++, a new GPU library that achieves the best of both worlds. We\ncreate a highly efficient Sparse Kernel Generator that generates performant\nsparse convolution kernels at less than one-tenth of the engineering cost of\nthe current state-of-the-art system. On top of this, we design the Sparse\nAutotuner, which extends the design space of existing sparse convolution\nlibraries and searches for the best dataflow configurations for training and\ninference workloads. Consequently, TorchSparse++ achieves 2.9x, 3.3x, 2.2x and\n1.7x measured end-to-end speedup on an NVIDIA A100 GPU over state-of-the-art\nMinkowskiEngine, SpConv 1.2, TorchSparse and SpConv v2 in inference; and is\n1.2-1.3x faster than SpConv v2 in mixed precision training across seven\nrepresentative autonomous driving benchmarks. It also seamlessly supports graph\nconvolutions, achieving 2.6-7.6x faster inference speed compared with\nstate-of-the-art graph deep learning libraries.",
            "author": [
                "Haotian Tang",
                "Shang Yang",
                "Zhijian Liu",
                "Ke Hong",
                "Zhongming Yu",
                "Xiuyu Li",
                "Guohao Dai",
                "Yu Wang",
                "Song Han"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12862v1",
                "http://arxiv.org/pdf/2311.12862v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.CV",
                "cs.LG",
                "cs.PF"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17002v1",
            "title": "Faster Recalibration of an Online Predictor via Approachability",
            "updated": "2023-10-25T20:59:48Z",
            "published": "2023-10-25T20:59:48Z",
            "summary": "Predictive models in ML need to be trustworthy and reliable, which often at\nthe very least means outputting calibrated probabilities. This can be\nparticularly difficult to guarantee in the online prediction setting when the\noutcome sequence can be generated adversarially. In this paper we introduce a\ntechnique using Blackwell's approachability theorem for taking an online\npredictive model which might not be calibrated and transforming its predictions\nto calibrated predictions without much increase to the loss of the original\nmodel. Our proposed algorithm achieves calibration and accuracy at a faster\nrate than existing techniques arXiv:1607.03594 and is the first algorithm to\noffer a flexible tradeoff between calibration error and accuracy in the online\nsetting. We demonstrate this by characterizing the space of jointly achievable\ncalibration and regret using our technique.",
            "author": [
                "Princewill Okoroafor",
                "Robert Kleinberg",
                "Wen Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17002v1",
                "http://arxiv.org/pdf/2310.17002v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16999v2",
            "title": "Trust, but Verify: Robust Image Segmentation using Deep Learning",
            "updated": "2023-10-29T04:09:48Z",
            "published": "2023-10-25T20:55:07Z",
            "summary": "We describe a method for verifying the output of a deep neural network for\nmedical image segmentation that is robust to several classes of random as well\nas worst-case perturbations i.e. adversarial attacks. This method is based on a\ngeneral approach recently developed by the authors called \"Trust, but Verify\"\nwherein an auxiliary verification network produces predictions about certain\nmasked features in the input image using the segmentation as an input. A\nwell-designed auxiliary network will produce high-quality predictions when the\ninput segmentations are accurate, but will produce low-quality predictions when\nthe segmentations are incorrect. Checking the predictions of such a network\nwith the original image allows us to detect bad segmentations. However, to\nensure the verification method is truly robust, we need a method for checking\nthe quality of the predictions that does not itself rely on a black-box neural\nnetwork. Indeed, we show that previous methods for segmentation evaluation that\ndo use deep neural regression networks are vulnerable to false negatives i.e.\ncan inaccurately label bad segmentations as good. We describe the design of a\nverification network that avoids such vulnerability and present results to\ndemonstrate its robustness compared to previous methods.",
            "author": [
                "Fahim Ahmed Zaman",
                "Xiaodong Wu",
                "Weiyu Xu",
                "Milan Sonka",
                "Raghuraman Mudumbai"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16999v2",
                "http://arxiv.org/pdf/2310.16999v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16996v1",
            "title": "Towards Continually Learning Application Performance Models",
            "updated": "2023-10-25T20:48:46Z",
            "published": "2023-10-25T20:48:46Z",
            "summary": "Machine learning-based performance models are increasingly being used to\nbuild critical job scheduling and application optimization decisions.\nTraditionally, these models assume that data distribution does not change as\nmore samples are collected over time. However, owing to the complexity and\nheterogeneity of production HPC systems, they are susceptible to hardware\ndegradation, replacement, and/or software patches, which can lead to drift in\nthe data distribution that can adversely affect the performance models. To this\nend, we develop continually learning performance models that account for the\ndistribution drift, alleviate catastrophic forgetting, and improve\ngeneralizability. Our best model was able to retain accuracy, regardless of\nhaving to learn the new distribution of data inflicted by system changes, while\ndemonstrating a 2x improvement in the prediction accuracy of the whole data\nsequence in comparison to the naive approach.",
            "author": [
                "Ray A. O. Sinurat",
                "Anurag Daram",
                "Haryadi S. Gunawi",
                "Robert B. Ross",
                "Sandeep Madireddy"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16996v1",
                "http://arxiv.org/pdf/2310.16996v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16995v1",
            "title": "Quality > Quantity: Synthetic Corpora from Foundation Models for\n  Closed-Domain Extractive Question Answering",
            "updated": "2023-10-25T20:48:16Z",
            "published": "2023-10-25T20:48:16Z",
            "summary": "Domain adaptation, the process of training a model in one domain and applying\nit to another, has been extensively explored in machine learning. While\ntraining a domain-specific foundation model (FM) from scratch is an option,\nrecent methods have focused on adapting pre-trained FMs for domain-specific\ntasks. However, our experiments reveal that either approach does not\nconsistently achieve state-of-the-art (SOTA) results in the target domain. In\nthis work, we study extractive question answering within closed domains and\nintroduce the concept of targeted pre-training. This involves determining and\ngenerating relevant data to further pre-train our models, as opposed to the\nconventional philosophy of utilizing domain-specific FMs trained on a wide\nrange of data. Our proposed framework uses Galactica to generate synthetic,\n``targeted'' corpora that align with specific writing styles and topics, such\nas research papers and radiology reports. This process can be viewed as a form\nof knowledge distillation. We apply our method to two biomedical extractive\nquestion answering datasets, COVID-QA and RadQA, achieving a new benchmark on\nthe former and demonstrating overall improvements on the latter. Code available\nat https://github.com/saptarshi059/CDQA-v1-Targetted-PreTraining/tree/main.",
            "author": [
                "Saptarshi Sengupta",
                "Connor Heaton",
                "Shreya Ghosh",
                "Preslav Nakov",
                "Prasenjit Mitra"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16995v1",
                "http://arxiv.org/pdf/2310.16995v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16992v1",
            "title": "How well can machine-generated texts be identified and can language\n  models be trained to avoid identification?",
            "updated": "2023-10-25T20:43:07Z",
            "published": "2023-10-25T20:43:07Z",
            "summary": "With the rise of generative pre-trained transformer models such as GPT-3,\nGPT-NeoX, or OPT, distinguishing human-generated texts from machine-generated\nones has become important. We refined five separate language models to generate\nsynthetic tweets, uncovering that shallow learning classification algorithms,\nlike Naive Bayes, achieve detection accuracy between 0.6 and 0.8.\n  Shallow learning classifiers differ from human-based detection, especially\nwhen using higher temperature values during text generation, resulting in a\nlower detection rate. Humans prioritize linguistic acceptability, which tends\nto be higher at lower temperature values. In contrast, transformer-based\nclassifiers have an accuracy of 0.9 and above. We found that using a\nreinforcement learning approach to refine our generative models can\nsuccessfully evade BERT-based classifiers with a detection accuracy of 0.15 or\nless.",
            "author": [
                "Sinclair Schneider",
                "Florian Steuber",
                "Joao A. G. Schneider",
                "Gabi Dreo Rodosek"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16992v1",
                "http://arxiv.org/pdf/2310.16992v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16991v1",
            "title": "An Efficient Deep Learning-based approach for Recognizing Agricultural\n  Pests in the Wild",
            "updated": "2023-10-25T20:42:20Z",
            "published": "2023-10-25T20:42:20Z",
            "summary": "One of the biggest challenges that the farmers go through is to fight insect\npests during agricultural product yields. The problem can be solved easily and\navoid economic losses by taking timely preventive measures. This requires\nidentifying insect pests in an easy and effective manner. Most of the insect\nspecies have similarities between them. Without proper help from the\nagriculturist academician it is very challenging for the farmers to identify\nthe crop pests accurately. To address this issue we have done extensive\nexperiments considering different methods to find out the best method among\nall. This paper presents a detailed overview of the experiments done on mainly\na robust dataset named IP102 including transfer learning with finetuning,\nattention mechanism and custom architecture. Some example from another dataset\nD0 is also shown to show robustness of our experimented techniques.",
            "author": [
                "Mohtasim Hadi Rafi",
                "Mohammad Ratul Mahjabin",
                "Md Sabbir Rahman"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16991v1",
                "http://arxiv.org/pdf/2310.16991v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16990v1",
            "title": "STEER: Semantic Turn Extension-Expansion Recognition for Voice\n  Assistants",
            "updated": "2023-10-25T20:41:30Z",
            "published": "2023-10-25T20:41:30Z",
            "summary": "In the context of a voice assistant system, steering refers to the phenomenon\nin which a user issues a follow-up command attempting to direct or clarify a\nprevious turn. We propose STEER, a steering detection model that predicts\nwhether a follow-up turn is a user's attempt to steer the previous command.\nConstructing a training dataset for steering use cases poses challenges due to\nthe cold-start problem. To overcome this, we developed heuristic rules to\nsample opt-in usage data, approximating positive and negative samples without\nany annotation. Our experimental results show promising performance in\nidentifying steering intent, with over 95% accuracy on our sampled data.\nMoreover, STEER, in conjunction with our sampling strategy, aligns effectively\nwith real-world steering scenarios, as evidenced by its strong zero-shot\nperformance on a human-graded evaluation set. In addition to relying solely on\nuser transcripts as input, we introduce STEER+, an enhanced version of the\nmodel. STEER+ utilizes a semantic parse tree to provide more context on\nout-of-vocabulary words, such as named entities that often occur at the\nsentence boundary. This further improves model performance, reducing error rate\nin domains where entities frequently appear, such as messaging. Lastly, we\npresent a data analysis that highlights the improvement in user experience when\nvoice assistants support steering use cases.",
            "author": [
                "Leon Liyang Zhang",
                "Jiarui Lu",
                "Joel Ruben Antony Moniz",
                "Aditya Kulkarni",
                "Dhivya Piraviperumal",
                "Tien Dung Tran",
                "Nicholas Tzou",
                "Hong Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16990v1",
                "http://arxiv.org/pdf/2310.16990v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16986v1",
            "title": "Probabilistic Integral Circuits",
            "updated": "2023-10-25T20:38:18Z",
            "published": "2023-10-25T20:38:18Z",
            "summary": "Continuous latent variables (LVs) are a key ingredient of many generative\nmodels, as they allow modelling expressive mixtures with an uncountable number\nof components. In contrast, probabilistic circuits (PCs) are hierarchical\ndiscrete mixtures represented as computational graphs composed of input, sum\nand product units. Unlike continuous LV models, PCs provide tractable inference\nbut are limited to discrete LVs with categorical (i.e. unordered) states. We\nbridge these model classes by introducing probabilistic integral circuits\n(PICs), a new language of computational graphs that extends PCs with integral\nunits representing continuous LVs. In the first place, PICs are symbolic\ncomputational graphs and are fully tractable in simple cases where analytical\nintegration is possible. In practice, we parameterise PICs with light-weight\nneural nets delivering an intractable hierarchical continuous mixture that can\nbe approximated arbitrarily well with large PCs using numerical quadrature. On\nseveral distribution estimation benchmarks, we show that such PIC-approximating\nPCs systematically outperform PCs commonly learned via expectation-maximization\nor SGD.",
            "author": [
                "Gennaro Gala",
                "Cassio de Campos",
                "Robert Peharz",
                "Antonio Vergari",
                "Erik Quaeghebeur"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16986v1",
                "http://arxiv.org/pdf/2310.16986v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16981v1",
            "title": "Reimagining Synthetic Tabular Data Generation through Data-Centric AI: A\n  Comprehensive Benchmark",
            "updated": "2023-10-25T20:32:02Z",
            "published": "2023-10-25T20:32:02Z",
            "summary": "Synthetic data serves as an alternative in training machine learning models,\nparticularly when real-world data is limited or inaccessible. However, ensuring\nthat synthetic data mirrors the complex nuances of real-world data is a\nchallenging task. This paper addresses this issue by exploring the potential of\nintegrating data-centric AI techniques which profile the data to guide the\nsynthetic data generation process. Moreover, we shed light on the often ignored\nconsequences of neglecting these data profiles during synthetic data generation\n-- despite seemingly high statistical fidelity. Subsequently, we propose a\nnovel framework to evaluate the integration of data profiles to guide the\ncreation of more representative synthetic data. In an empirical study, we\nevaluate the performance of five state-of-the-art models for tabular data\ngeneration on eleven distinct tabular datasets. The findings offer critical\ninsights into the successes and limitations of current synthetic data\ngeneration techniques. Finally, we provide practical recommendations for\nintegrating data-centric insights into the synthetic data generation process,\nwith a specific focus on classification performance, model selection, and\nfeature selection. This study aims to reevaluate conventional approaches to\nsynthetic data generation and promote the application of data-centric AI\ntechniques in improving the quality and effectiveness of synthetic data.",
            "author": [
                "Lasse Hansen",
                "Nabeel Seedat",
                "Mihaela van der Schaar",
                "Andrija Petrovic"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16981v1",
                "http://arxiv.org/pdf/2310.16981v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16979v1",
            "title": "Unsupervised Domain Adaptation for Semantic Segmentation with Pseudo\n  Label Self-Refinement",
            "updated": "2023-10-25T20:31:07Z",
            "published": "2023-10-25T20:31:07Z",
            "summary": "Deep learning-based solutions for semantic segmentation suffer from\nsignificant performance degradation when tested on data with different\ncharacteristics than what was used during the training. Adapting the models\nusing annotated data from the new domain is not always practical. Unsupervised\nDomain Adaptation (UDA) approaches are crucial in deploying these models in the\nactual operating conditions. Recent state-of-the-art (SOTA) UDA methods employ\na teacher-student self-training approach, where a teacher model is used to\ngenerate pseudo-labels for the new data which in turn guide the training\nprocess of the student model. Though this approach has seen a lot of success,\nit suffers from the issue of noisy pseudo-labels being propagated in the\ntraining process. To address this issue, we propose an auxiliary pseudo-label\nrefinement network (PRN) for online refining of the pseudo labels and also\nlocalizing the pixels whose predicted labels are likely to be noisy. Being able\nto improve the quality of pseudo labels and select highly reliable ones, PRN\nhelps self-training of segmentation models to be robust against pseudo label\nnoise propagation during different stages of adaptation. We evaluate our\napproach on benchmark datasets with three different domain shifts, and our\napproach consistently performs significantly better than the previous\nstate-of-the-art methods.",
            "author": [
                "Xingchen Zhao",
                "Niluthpol Chowdhury Mithun",
                "Abhinav Rajvanshi",
                "Han-Pang Chiu",
                "Supun Samarasekera"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16979v1",
                "http://arxiv.org/pdf/2310.16979v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16978v1",
            "title": "The Significance of Machine Learning in Clinical Disease Diagnosis: A\n  Review",
            "updated": "2023-10-25T20:28:22Z",
            "published": "2023-10-25T20:28:22Z",
            "summary": "The global need for effective disease diagnosis remains substantial, given\nthe complexities of various disease mechanisms and diverse patient symptoms. To\ntackle these challenges, researchers, physicians, and patients are turning to\nmachine learning (ML), an artificial intelligence (AI) discipline, to develop\nsolutions. By leveraging sophisticated ML and AI methods, healthcare\nstakeholders gain enhanced diagnostic and treatment capabilities. However,\nthere is a scarcity of research focused on ML algorithms for enhancing the\naccuracy and computational efficiency. This research investigates the capacity\nof machine learning algorithms to improve the transmission of heart rate data\nin time series healthcare metrics, concentrating particularly on optimizing\naccuracy and efficiency. By exploring various ML algorithms used in healthcare\napplications, the review presents the latest trends and approaches in ML-based\ndisease diagnosis (MLBDD). The factors under consideration include the\nalgorithm utilized, the types of diseases targeted, the data types employed,\nthe applications, and the evaluation metrics. This review aims to shed light on\nthe prospects of ML in healthcare, particularly in disease diagnosis. By\nanalyzing the current literature, the study provides insights into\nstate-of-the-art methodologies and their performance metrics.",
            "author": [
                "S M Atikur Rahman",
                "Sifat Ibtisum",
                "Ehsan Bazgir",
                "Tumpa Barai"
            ],
            "link": [
                "http://dx.doi.org/10.5120/ijca2023923147",
                "http://arxiv.org/abs/2310.16978v1",
                "http://arxiv.org/pdf/2310.16978v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16976v1",
            "title": "On the Interplay between Social Welfare and Tractability of Equilibria",
            "updated": "2023-10-25T20:22:51Z",
            "published": "2023-10-25T20:22:51Z",
            "summary": "Computational tractability and social welfare (aka. efficiency) of equilibria\nare two fundamental but in general orthogonal considerations in algorithmic\ngame theory. Nevertheless, we show that when (approximate) full efficiency can\nbe guaranteed via a smoothness argument \\`a la Roughgarden, Nash equilibria are\napproachable under a family of no-regret learning algorithms, thereby enabling\nfast and decentralized computation. We leverage this connection to obtain new\nconvergence results in large games -- wherein the number of players $n \\gg 1$\n-- under the well-documented property of full efficiency via smoothness in the\nlimit. Surprisingly, our framework unifies equilibrium computation in disparate\nclasses of problems including games with vanishing strategic sensitivity and\ntwo-player zero-sum games, illuminating en route an immediate but overlooked\nequivalence between smoothness and a well-studied condition in the optimization\nliterature known as the Minty property. Finally, we establish that a family of\nno-regret dynamics attains a welfare bound that improves over the smoothness\nframework while at the same time guaranteeing convergence to the set of coarse\ncorrelated equilibria. We show this by employing the clairvoyant mirror descent\nalgortihm recently introduced by Piliouras et al.",
            "author": [
                "Ioannis Anagnostides",
                "Tuomas Sandholm"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16976v1",
                "http://arxiv.org/pdf/2310.16976v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16975v1",
            "title": "Efficient Neural Network Approaches for Conditional Optimal Transport\n  with Applications in Bayesian Inference",
            "updated": "2023-10-25T20:20:09Z",
            "published": "2023-10-25T20:20:09Z",
            "summary": "We present two neural network approaches that approximate the solutions of\nstatic and dynamic conditional optimal transport (COT) problems, respectively.\nBoth approaches enable sampling and density estimation of conditional\nprobability distributions, which are core tasks in Bayesian inference. Our\nmethods represent the target conditional distributions as transformations of a\ntractable reference distribution and, therefore, fall into the framework of\nmeasure transport. COT maps are a canonical choice within this framework, with\ndesirable properties such as uniqueness and monotonicity. However, the\nassociated COT problems are computationally challenging, even in moderate\ndimensions. To improve the scalability, our numerical algorithms leverage\nneural networks to parameterize COT maps. Our methods exploit the structure of\nthe static and dynamic formulations of the COT problem. PCP-Map models\nconditional transport maps as the gradient of a partially input convex neural\nnetwork (PICNN) and uses a novel numerical implementation to increase\ncomputational efficiency compared to state-of-the-art alternatives. COT-Flow\nmodels conditional transports via the flow of a regularized neural ODE; it is\nslower to train but offers faster sampling. We demonstrate their effectiveness\nand efficiency by comparing them with state-of-the-art approaches using\nbenchmark datasets and Bayesian inverse problems.",
            "author": [
                "Zheyu Oliver Wang",
                "Ricardo Baptista",
                "Youssef Marzouk",
                "Lars Ruthotto",
                "Deepanshu Verma"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16975v1",
                "http://arxiv.org/pdf/2310.16975v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "62F15, 62M45"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16961v1",
            "title": "Neural Distributed Compressor Discovers Binning",
            "updated": "2023-10-25T20:02:20Z",
            "published": "2023-10-25T20:02:20Z",
            "summary": "We consider lossy compression of an information source when the decoder has\nlossless access to a correlated one. This setup, also known as the Wyner-Ziv\nproblem, is a special case of distributed source coding. To this day, practical\napproaches for the Wyner-Ziv problem have neither been fully developed nor\nheavily investigated. We propose a data-driven method based on machine learning\nthat leverages the universal function approximation capability of artificial\nneural networks. We find that our neural network-based compression scheme,\nbased on variational vector quantization, recovers some principles of the\noptimum theoretical solution of the Wyner-Ziv setup, such as binning in the\nsource space as well as optimal combination of the quantization index and side\ninformation, for exemplary sources. These behaviors emerge although no\nstructure exploiting knowledge of the source distributions was imposed. Binning\nis a widely used tool in information theoretic proofs and methods, and to our\nknowledge, this is the first time it has been explicitly observed to emerge\nfrom data-driven learning.",
            "author": [
                "Ezgi Ozyilkan",
                "Johannes Ball\u00e9",
                "Elza Erkip"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16961v1",
                "http://arxiv.org/pdf/2310.16961v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16960v1",
            "title": "Privately Aligning Language Models with Reinforcement Learning",
            "updated": "2023-10-25T19:58:51Z",
            "published": "2023-10-25T19:58:51Z",
            "summary": "Positioned between pre-training and user deployment, aligning large language\nmodels (LLMs) through reinforcement learning (RL) has emerged as a prevailing\nstrategy for training instruction following-models such as ChatGPT. In this\nwork, we initiate the study of privacy-preserving alignment of LLMs through\nDifferential Privacy (DP) in conjunction with RL. Following the influential\nwork of Ziegler et al. (2020), we study two dominant paradigms: (i) alignment\nvia RL without human in the loop (e.g., positive review generation) and (ii)\nalignment via RL from human feedback (RLHF) (e.g., summarization in a\nhuman-preferred way). We give a new DP framework to achieve alignment via RL,\nand prove its correctness. Our experimental results validate the effectiveness\nof our approach, offering competitive utility while ensuring strong privacy\nprotections.",
            "author": [
                "Fan Wu",
                "Huseyin A. Inan",
                "Arturs Backurs",
                "Varun Chandrasekaran",
                "Janardhan Kulkarni",
                "Robert Sim"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16960v1",
                "http://arxiv.org/pdf/2310.16960v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16959v1",
            "title": "Improving Few-shot Generalization of Safety Classifiers via Data\n  Augmented Parameter-Efficient Fine-Tuning",
            "updated": "2023-10-25T19:57:07Z",
            "published": "2023-10-25T19:57:07Z",
            "summary": "As large language models (LLMs) are widely adopted, new safety issues and\npolicies emerge, to which existing safety classifiers do not generalize well.\nIf we have only observed a few examples of violations of a new safety rule, how\ncan we build a classifier to detect violations? In this paper, we study the\nnovel setting of domain-generalized few-shot learning for LLM-based text safety\nclassifiers. Unlike prior few-shot work, these new safety issues can be hard to\nuncover and we do not get to choose the few examples. We demonstrate that\nexisting few-shot techniques do not perform well in this setting, and rather we\npropose to do parameter-efficient fine-tuning (PEFT) combined with augmenting\ntraining data based on similar examples in prior existing rules. We empirically\nshow that our approach of similarity-based data-augmentation + prompt-tuning\n(DAPT) consistently outperforms baselines that either do not rely on data\naugmentation or on PEFT by 7-17% F1 score in the Social Chemistry moral\njudgement and 9-13% AUC in the Toxicity detection tasks, even when the new rule\nis loosely correlated with existing ones.",
            "author": [
                "Ananth Balashankar",
                "Xiao Ma",
                "Aradhana Sinha",
                "Ahmad Beirami",
                "Yao Qin",
                "Jilin Chen",
                "Alex Beutel"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16959v1",
                "http://arxiv.org/pdf/2310.16959v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16958v1",
            "title": "Transferring a molecular foundation model for polymer property\n  predictions",
            "updated": "2023-10-25T19:55:00Z",
            "published": "2023-10-25T19:55:00Z",
            "summary": "Transformer-based large language models have remarkable potential to\naccelerate design optimization for applications such as drug development and\nmaterials discovery. Self-supervised pretraining of transformer models requires\nlarge-scale datasets, which are often sparsely populated in topical areas such\nas polymer science. State-of-the-art approaches for polymers conduct data\naugmentation to generate additional samples but unavoidably incurs extra\ncomputational costs. In contrast, large-scale open-source datasets are\navailable for small molecules and provide a potential solution to data scarcity\nthrough transfer learning. In this work, we show that using transformers\npretrained on small molecules and fine-tuned on polymer properties achieve\ncomparable accuracy to those trained on augmented polymer datasets for a series\nof benchmark prediction tasks.",
            "author": [
                "Pei Zhang",
                "Logan Kearney",
                "Debsindhu Bhowmik",
                "Zachary Fox",
                "Amit K. Naskar",
                "John Gounley"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16958v1",
                "http://arxiv.org/pdf/2310.16958v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16955v1",
            "title": "Break it, Imitate it, Fix it: Robustness by Generating Human-Like\n  Attacks",
            "updated": "2023-10-25T19:51:37Z",
            "published": "2023-10-25T19:51:37Z",
            "summary": "Real-world natural language processing systems need to be robust to human\nadversaries. Collecting examples of human adversaries for training is an\neffective but expensive solution. On the other hand, training on synthetic\nattacks with small perturbations - such as word-substitution - does not\nactually improve robustness to human adversaries. In this paper, we propose an\nadversarial training framework that uses limited human adversarial examples to\ngenerate more useful adversarial examples at scale. We demonstrate the\nadvantages of this system on the ANLI and hate speech detection benchmark\ndatasets - both collected via an iterative, adversarial\nhuman-and-model-in-the-loop procedure. Compared to training only on observed\nhuman attacks, also training on our synthetic adversarial examples improves\nmodel robustness to future rounds. In ANLI, we see accuracy gains on the\ncurrent set of attacks (44.1%$\\,\\to\\,$50.1%) and on two future unseen rounds of\nhuman generated attacks (32.5%$\\,\\to\\,$43.4%, and 29.4%$\\,\\to\\,$40.2%). In hate\nspeech detection, we see AUC gains on current attacks (0.76 $\\to$ 0.84) and a\nfuture round (0.77 $\\to$ 0.79). Attacks from methods that do not learn the\ndistribution of existing human adversaries, meanwhile, degrade robustness.",
            "author": [
                "Aradhana Sinha",
                "Ananth Balashankar",
                "Ahmad Beirami",
                "Thi Avrahami",
                "Jilin Chen",
                "Alex Beutel"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16955v1",
                "http://arxiv.org/pdf/2310.16955v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16954v1",
            "title": "Improving Performance in Colorectal Cancer Histology Decomposition using\n  Deep and Ensemble Machine Learning",
            "updated": "2023-10-25T19:46:27Z",
            "published": "2023-10-25T19:46:27Z",
            "summary": "In routine colorectal cancer management, histologic samples stained with\nhematoxylin and eosin are commonly used. Nonetheless, their potential for\ndefining objective biomarkers for patient stratification and treatment\nselection is still being explored. The current gold standard relies on\nexpensive and time-consuming genetic tests. However, recent research highlights\nthe potential of convolutional neural networks (CNNs) in facilitating the\nextraction of clinically relevant biomarkers from these readily available\nimages. These CNN-based biomarkers can predict patient outcomes comparably to\ngolden standards, with the added advantages of speed, automation, and minimal\ncost. The predictive potential of CNN-based biomarkers fundamentally relies on\nthe ability of convolutional neural networks (CNNs) to classify diverse tissue\ntypes from whole slide microscope images accurately. Consequently, enhancing\nthe accuracy of tissue class decomposition is critical to amplifying the\nprognostic potential of imaging-based biomarkers. This study introduces a\nhybrid Deep and ensemble machine learning model that surpassed all preceding\nsolutions for this classification task. Our model achieved 96.74% accuracy on\nthe external test set and 99.89% on the internal test set. Recognizing the\npotential of these models in advancing the task, we have made them publicly\navailable for further research and development.",
            "author": [
                "Fabi Prezja",
                "Leevi Annala",
                "Sampsa Kiiskinen",
                "Suvi Lahtinen",
                "Timo Ojala",
                "Pekka Ruusuvuori",
                "Teijo Kuopio"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16954v1",
                "http://arxiv.org/pdf/2310.16954v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16945v4",
            "title": "Causal Q-Aggregation for CATE Model Selection",
            "updated": "2023-11-11T02:24:24Z",
            "published": "2023-10-25T19:27:05Z",
            "summary": "Accurate estimation of conditional average treatment effects (CATE) is at the\ncore of personalized decision making. While there is a plethora of models for\nCATE estimation, model selection is a nontrivial task, due to the fundamental\nproblem of causal inference. Recent empirical work provides evidence in favor\nof proxy loss metrics with double robust properties and in favor of model\nensembling. However, theoretical understanding is lacking. Direct application\nof prior theoretical work leads to suboptimal oracle model selection rates due\nto the non-convexity of the model selection problem. We provide regret rates\nfor the major existing CATE ensembling approaches and propose a new CATE model\nensembling approach based on Q-aggregation using the doubly robust loss. Our\nmain result shows that causal Q-aggregation achieves statistically optimal\noracle model selection regret rates of $\\frac{\\log(M)}{n}$ (with $M$ models and\n$n$ samples), with the addition of higher-order estimation error terms related\nto products of errors in the nuisance functions. Crucially, our regret rate\ndoes not require that any of the candidate CATE models be close to the truth.\nWe validate our new method on many semi-synthetic datasets and also provide\nextensions of our work to CATE model selection with instrumental variables and\nunobserved confounding.",
            "author": [
                "Hui Lan",
                "Vasilis Syrgkanis"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16945v4",
                "http://arxiv.org/pdf/2310.16945v4"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "econ.EM",
                "math.ST",
                "stat.TH",
                "62F07(Primary), 62D20(Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16944v1",
            "title": "Zephyr: Direct Distillation of LM Alignment",
            "updated": "2023-10-25T19:25:16Z",
            "published": "2023-10-25T19:25:16Z",
            "summary": "We aim to produce a smaller language model that is aligned to user intent.\nPrevious research has shown that applying distilled supervised fine-tuning\n(dSFT) on larger models significantly improves task accuracy; however, these\nmodels are unaligned, i.e. they do not respond well to natural prompts. To\ndistill this property, we experiment with the use of preference data from AI\nFeedback (AIF). Starting from a dataset of outputs ranked by a teacher model,\nwe apply distilled direct preference optimization (dDPO) to learn a chat model\nwith significantly improved intent alignment. The approach requires only a few\nhours of training without any additional sampling during fine-tuning. The final\nresult, Zephyr-7B, sets the state-of-the-art on chat benchmarks for 7B\nparameter models, and requires no human annotation. In particular, results on\nMT-Bench show that Zephyr-7B surpasses Llama2-Chat-70B, the best open-access\nRLHF-based model. Code, models, data, and tutorials for the system are\navailable at https://github.com/huggingface/alignment-handbook.",
            "author": [
                "Lewis Tunstall",
                "Edward Beeching",
                "Nathan Lambert",
                "Nazneen Rajani",
                "Kashif Rasul",
                "Younes Belkada",
                "Shengyi Huang",
                "Leandro von Werra",
                "Cl\u00e9mentine Fourrier",
                "Nathan Habib",
                "Nathan Sarrazin",
                "Omar Sanseviero",
                "Alexander M. Rush",
                "Thomas Wolf"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16944v1",
                "http://arxiv.org/pdf/2310.16944v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16941v1",
            "title": "Exploring Behavior Discovery Methods for Heterogeneous Swarms of\n  Limited-Capability Robots",
            "updated": "2023-10-25T19:20:32Z",
            "published": "2023-10-25T19:20:32Z",
            "summary": "We study the problem of determining the emergent behaviors that are possible\ngiven a functionally heterogeneous swarm of robots with limited capabilities.\nPrior work has considered behavior search for homogeneous swarms and proposed\nthe use of novelty search over either a hand-specified or learned behavior\nspace followed by clustering to return a taxonomy of emergent behaviors to the\nuser. In this paper, we seek to better understand the role of novelty search\nand the efficacy of using clustering to discover novel emergent behaviors.\nThrough a large set of experiments and ablations, we analyze the effect of\nrepresentations, evolutionary search, and various clustering methods in the\nsearch for novel behaviors in a heterogeneous swarm. Our results indicate that\nprior methods fail to discover many interesting behaviors and that an iterative\nhuman-in-the-loop discovery process discovers more behaviors than random\nsearch, swarm chemistry, and automated behavior discovery. The combined\ndiscoveries of our experiments uncover 23 emergent behaviors, 18 of which are\nnovel discoveries. To the best of our knowledge, these are the first known\nemergent behaviors for heterogeneous swarms of computation-free agents. Videos,\ncode, and appendix are available at the project website:\nhttps://sites.google.com/view/heterogeneous-bd-methods",
            "author": [
                "Connor Mattson",
                "Jeremy C. Clark",
                "Daniel S. Brown"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16941v1",
                "http://arxiv.org/pdf/2310.16941v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16937v1",
            "title": "Learning Transfers over Several Programming Languages",
            "updated": "2023-10-25T19:04:33Z",
            "published": "2023-10-25T19:04:33Z",
            "summary": "Large language models (LLMs) have recently become remarkably good at\nimproving developer productivity for high-resource programming languages. These\nmodels use two kinds of data: large amounts of unlabeled code samples for\npretraining and relatively smaller amounts of labeled code samples for\nfine-tuning or in-context learning. Unfortunately, many programming languages\nare low-resource, lacking labeled samples for most tasks and often even lacking\nunlabeled samples. Therefore, users of low-resource languages (e.g., legacy or\nnew languages) miss out on the benefits of LLMs. Cross-lingual transfer\nlearning uses data from a source language to improve model performance on a\ntarget language. It has been well-studied for natural languages, but has\nreceived little attention for programming languages. This paper reports\nextensive experiments on four tasks using a transformer-based LLM and 11 to 41\nprogramming languages to explore the following questions. First, how well\ncross-lingual transfer works for a given task across different language pairs.\nSecond, given a task and target language, how to best choose a source language.\nThird, the characteristics of a language pair that are predictive of transfer\nperformance, and fourth, how that depends on the given task.",
            "author": [
                "Razan Baltaji",
                "Saurabh Pujar",
                "Louis Mandel",
                "Martin Hirzel",
                "Luca Buratti",
                "Lav Varshney"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16937v1",
                "http://arxiv.org/pdf/2310.16937v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "I.2.7; I.2.5"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16936v2",
            "title": "Diagnosing Alzheimer's Disease using Early-Late Multimodal Data Fusion\n  with Jacobian Maps",
            "updated": "2023-10-27T18:02:42Z",
            "published": "2023-10-25T19:02:57Z",
            "summary": "Alzheimer's disease (AD) is a prevalent and debilitating neurodegenerative\ndisorder impacting a large aging population. Detecting AD in all its\npresymptomatic and symptomatic stages is crucial for early intervention and\ntreatment. An active research direction is to explore machine learning methods\nthat harness multimodal data fusion to outperform human inspection of medical\nscans. However, existing multimodal fusion models have limitations, including\nredundant computation, complex architecture, and simplistic handling of missing\ndata. Moreover, the preprocessing pipelines of medical scans remain\ninadequately detailed and are seldom optimized for individual subjects. In this\npaper, we propose an efficient early-late fusion (ELF) approach, which\nleverages a convolutional neural network for automated feature extraction and\nrandom forests for their competitive performance on small datasets.\nAdditionally, we introduce a robust preprocessing pipeline that adapts to the\nunique characteristics of individual subjects and makes use of whole brain\nimages rather than slices or patches. Moreover, to tackle the challenge of\ndetecting subtle changes in brain volume, we transform images into the Jacobian\ndomain (JD) to enhance both accuracy and robustness in our classification.\nUsing MRI and CT images from the OASIS-3 dataset, our experiments demonstrate\nthe effectiveness of the ELF approach in classifying AD into four stages with\nan accuracy of 97.19%.",
            "author": [
                "Yasmine Mustafa",
                "Tie Luo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16936v2",
                "http://arxiv.org/pdf/2310.16936v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16931v1",
            "title": "CL-MASR: A Continual Learning Benchmark for Multilingual ASR",
            "updated": "2023-10-25T18:55:40Z",
            "published": "2023-10-25T18:55:40Z",
            "summary": "Modern multilingual automatic speech recognition (ASR) systems like Whisper\nhave made it possible to transcribe audio in multiple languages with a single\nmodel. However, current state-of-the-art ASR models are typically evaluated on\nindividual languages or in a multi-task setting, overlooking the challenge of\ncontinually learning new languages. There is insufficient research on how to\nadd new languages without losing valuable information from previous data.\nFurthermore, existing continual learning benchmarks focus mostly on vision and\nlanguage tasks, leaving continual learning for multilingual ASR largely\nunexplored. To bridge this gap, we propose CL-MASR, a benchmark designed for\nstudying multilingual ASR in a continual learning setting. CL-MASR provides a\ndiverse set of continual learning methods implemented on top of large-scale\npretrained ASR models, along with common metrics to assess the effectiveness of\nlearning new languages while addressing the issue of catastrophic forgetting.\nTo the best of our knowledge, CL-MASR is the first continual learning benchmark\nfor the multilingual ASR task. The code is available at\nhttps://github.com/speechbrain/benchmarks.",
            "author": [
                "Luca Della Libera",
                "Pooneh Mousavi",
                "Salah Zaiem",
                "Cem Subakan",
                "Mirco Ravanelli"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16931v1",
                "http://arxiv.org/pdf/2310.16931v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16924v1",
            "title": "Physician Detection of Clinical Harm in Machine Translation: Quality\n  Estimation Aids in Reliance and Backtranslation Identifies Critical Errors",
            "updated": "2023-10-25T18:44:14Z",
            "published": "2023-10-25T18:44:14Z",
            "summary": "A major challenge in the practical use of Machine Translation (MT) is that\nusers lack guidance to make informed decisions about when to rely on outputs.\nProgress in quality estimation research provides techniques to automatically\nassess MT quality, but these techniques have primarily been evaluated in vitro\nby comparison against human judgments outside of a specific context of use.\nThis paper evaluates quality estimation feedback in vivo with a human study\nsimulating decision-making in high-stakes medical settings. Using Emergency\nDepartment discharge instructions, we study how interventions based on quality\nestimation versus backtranslation assist physicians in deciding whether to show\nMT outputs to a patient. We find that quality estimation improves appropriate\nreliance on MT, but backtranslation helps physicians detect more clinically\nharmful errors that QE alone often misses.",
            "author": [
                "Nikita Mehandru",
                "Sweta Agrawal",
                "Yimin Xiao",
                "Elaine C Khoong",
                "Ge Gao",
                "Marine Carpuat",
                "Niloufar Salehi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16924v1",
                "http://arxiv.org/pdf/2310.16924v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16921v1",
            "title": "On the connection between least squares, regularization, and classical\n  shadows",
            "updated": "2023-10-25T18:39:08Z",
            "published": "2023-10-25T18:39:08Z",
            "summary": "Classical shadows (CS) offer a resource-efficient means to estimate quantum\nobservables, circumventing the need for exhaustive state tomography. Here, we\nclarify and explore the connection between CS techniques and least squares (LS)\nand regularized least squares (RLS) methods commonly used in machine learning\nand data analysis. By formal identification of LS and RLS ``shadows''\ncompletely analogous to those in CS -- namely, point estimators calculated from\nthe empirical frequencies of single measurements -- we show that both RLS and\nCS can be viewed as regularizers for the underdetermined regime, replacing the\npseudoinverse with invertible alternatives. Through numerical simulations, we\nevaluate RLS and CS from three distinct angles: the tradeoff in bias and\nvariance, mismatch between the expected and actual measurement distributions,\nand the interplay between the number of measurements and number of shots per\nmeasurement. Compared to CS, RLS attains lower variance at the expense of bias,\nis robust to distribution mismatch, and is more sensitive to the number of\nshots for a fixed number of state copies -- differences that can be understood\nfrom the distinct approaches taken to regularization. Conceptually, our\nintegration of LS, RLS, and CS under a unifying ``shadow'' umbrella aids in\nadvancing the overall picture of CS techniques, while practically our results\nhighlight the tradeoffs intrinsic to these measurement approaches, illuminating\nthe circumstances under which either RLS or CS would be preferred, such as\nunverified randomness for the former or unbiased estimation for the latter.",
            "author": [
                "Zhihui Zhu",
                "Joseph M. Lukens",
                "Brian T. Kirby"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16921v1",
                "http://arxiv.org/pdf/2310.16921v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16920v1",
            "title": "Smoothed Gradient Clipping and Error Feedback for Distributed\n  Optimization under Heavy-Tailed Noise",
            "updated": "2023-10-25T18:38:38Z",
            "published": "2023-10-25T18:38:38Z",
            "summary": "Motivated by understanding and analysis of large-scale machine learning under\nheavy-tailed gradient noise, we study distributed optimization with smoothed\ngradient clipping, i.e., in which certain smoothed clipping operators are\napplied to the gradients or gradient estimates computed from local clients\nprior to further processing. While vanilla gradient clipping has proven\neffective in mitigating the impact of heavy-tailed gradient noises in\nnon-distributed setups, it incurs bias that causes convergence issues in\nheterogeneous distributed settings. To address the inherent bias introduced by\ngradient clipping, we develop a smoothed clipping operator, and propose a\ndistributed gradient method equipped with an error feedback mechanism, i.e.,\nthe clipping operator is applied on the difference between some local gradient\nestimator and local stochastic gradient. We establish that, for the first time\nin the strongly convex setting with heavy-tailed gradient noises that may not\nhave finite moments of order greater than one, the proposed distributed\ngradient method's mean square error (MSE) converges to zero at a rate\n$O(1/t^\\iota)$, $\\iota \\in (0, 0.4)$, where the exponent $\\iota$ stays bounded\naway from zero as a function of the problem condition number and the first\nabsolute moment of the noise. Numerical experiments validate our theoretical\nfindings.",
            "author": [
                "Shuhua Yu",
                "Dusan Jakovetic",
                "Soummya Kar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16920v1",
                "http://arxiv.org/pdf/2310.16920v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16917v2",
            "title": "MimicTouch: Learning Human's Control Strategy with Multi-Modal Tactile\n  Feedback",
            "updated": "2023-11-01T22:42:20Z",
            "published": "2023-10-25T18:34:06Z",
            "summary": "In robotics and artificial intelligence, the integration of tactile\nprocessing is becoming increasingly pivotal, especially in learning to execute\nintricate tasks like alignment and insertion. However, existing works focusing\non tactile methods for insertion tasks predominantly rely on robot\nteleoperation data and reinforcement learning, which do not utilize the rich\ninsights provided by human's control strategy guided by tactile feedback. For\nutilizing human sensations, methodologies related to learning from humans\npredominantly leverage visual feedback, often overlooking the invaluable\ntactile feedback that humans inherently employ to finish complex manipulations.\nAddressing this gap, we introduce \"MimicTouch\", a novel framework that mimics\nhuman's tactile-guided control strategy. In this framework, we initially\ncollect multi-modal tactile datasets from human demonstrators, incorporating\nhuman tactile-guided control strategies for task completion. The subsequent\nstep involves instructing robots through imitation learning using multi-modal\nsensor data and retargeted human motions. To further mitigate the embodiment\ngap between humans and robots, we employ online residual reinforcement learning\non the physical robot. Through comprehensive experiments, we validate the\nsafety of MimicTouch in transferring a latent policy learned through imitation\nlearning from human to robot. This ongoing work will pave the way for a broader\nspectrum of tactile-guided robotic applications.",
            "author": [
                "Kelin Yu",
                "Yunhai Han",
                "Matthew Zhu",
                "Ye Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16917v2",
                "http://arxiv.org/pdf/2310.16917v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16912v1",
            "title": "Transformer-based Atmospheric Density Forecasting",
            "updated": "2023-10-25T18:23:41Z",
            "published": "2023-10-25T18:23:41Z",
            "summary": "As the peak of the solar cycle approaches in 2025 and the ability of a single\ngeomagnetic storm to significantly alter the orbit of Resident Space Objects\n(RSOs), techniques for atmospheric density forecasting are vital for space\nsituational awareness. While linear data-driven methods, such as dynamic mode\ndecomposition with control (DMDc), have been used previously for forecasting\natmospheric density, deep learning-based forecasting has the ability to capture\nnonlinearities in data. By learning multiple layer weights from historical\natmospheric density data, long-term dependencies in the dataset are captured in\nthe mapping between the current atmospheric density state and control input to\nthe atmospheric density state at the next timestep. This work improves upon\nprevious linear propagation methods for atmospheric density forecasting, by\ndeveloping a nonlinear transformer-based architecture for atmospheric density\nforecasting. Empirical NRLMSISE-00 and JB2008, as well as physics-based TIEGCM\natmospheric density models are compared for forecasting with DMDc and with the\ntransformer-based propagator.",
            "author": [
                "Julia Briden",
                "Peng Mun Siew",
                "Victor Rodriguez-Fernandez",
                "Richard Linares"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16912v1",
                "http://arxiv.org/pdf/2310.16912v1"
            ],
            "primary_category": "physics.ao-ph",
            "category": [
                "physics.ao-ph",
                "cs.LG",
                "physics.space-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18367v1",
            "title": "Unsupervised Learning of Molecular Embeddings for Enhanced Clustering\n  and Emergent Properties for Chemical Compounds",
            "updated": "2023-10-25T18:00:24Z",
            "published": "2023-10-25T18:00:24Z",
            "summary": "The detailed analysis of molecular structures and properties holds great\npotential for drug development discovery through machine learning. Developing\nan emergent property in the model to understand molecules would broaden the\nhorizons for development with a new computational tool. We introduce various\nmethods to detect and cluster chemical compounds based on their SMILES data.\nOur first method, analyzing the graphical structures of chemical compounds\nusing embedding data, employs vector search to meet our threshold value. The\nresults yielded pronounced, concentrated clusters, and the method produced\nfavorable results in querying and understanding the compounds. We also used\nnatural language description embeddings stored in a vector database with\nGPT3.5, which outperforms the base model. Thus, we introduce a similarity\nsearch and clustering algorithm to aid in searching for and interacting with\nmolecules, enhancing efficiency in chemical exploration and enabling future\ndevelopment of emergent properties in molecular property prediction models.",
            "author": [
                "Jaiveer Gill",
                "Ratul Chakraborty",
                "Reetham Gubba",
                "Amy Liu",
                "Shrey Jain",
                "Chirag Iyer",
                "Obaid Khwaja",
                "Saurav Kumar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18367v1",
                "http://arxiv.org/pdf/2310.18367v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16838v1",
            "title": "SparseDFF: Sparse-View Feature Distillation for One-Shot Dexterous\n  Manipulation",
            "updated": "2023-10-25T17:59:41Z",
            "published": "2023-10-25T17:59:41Z",
            "summary": "Humans excel at transferring manipulation skills across diverse object\nshapes, poses, and appearances due to their understanding of semantic\ncorrespondences between different instances. To endow robots with a similar\nhigh-level understanding, we develop a Distilled Feature Field (DFF) for 3D\nscenes, leveraging large 2D vision models to distill semantic features from\nmultiview images. While current research demonstrates advanced performance in\nreconstructing DFFs from dense views, the development of learning a DFF from\nsparse views is relatively nascent, despite its prevalence in numerous\nmanipulation tasks with fixed cameras. In this work, we introduce SparseDFF, a\nnovel method for acquiring view-consistent 3D DFFs from sparse RGBD\nobservations, enabling one-shot learning of dexterous manipulations that are\ntransferable to novel scenes. Specifically, we map the image features to the 3D\npoint cloud, allowing for propagation across the 3D space to establish a dense\nfeature field. At the core of SparseDFF is a lightweight feature refinement\nnetwork, optimized with a contrastive loss between pairwise views after\nback-projecting the image features onto the 3D point cloud. Additionally, we\nimplement a point-pruning mechanism to augment feature continuity within each\nlocal neighborhood. By establishing coherent feature fields on both source and\ntarget scenes, we devise an energy function that facilitates the minimization\nof feature discrepancies w.r.t. the end-effector parameters between the\ndemonstration and the target manipulation. We evaluate our approach using a\ndexterous hand, mastering real-world manipulations on both rigid and deformable\nobjects, and showcase robust generalization in the face of object and\nscene-context variations.",
            "author": [
                "Qianxu Wang",
                "Haotong Zhang",
                "Congyue Deng",
                "Yang You",
                "Hao Dong",
                "Yixin Zhu",
                "Leonidas Guibas"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16838v1",
                "http://arxiv.org/pdf/2310.16838v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16837v2",
            "title": "RDBench: ML Benchmark for Relational Databases",
            "updated": "2023-10-30T16:51:30Z",
            "published": "2023-10-25T17:59:34Z",
            "summary": "Benefiting from high-quality datasets and standardized evaluation metrics,\nmachine learning (ML) has achieved sustained progress and widespread\napplications. However, while applying machine learning to relational databases\n(RDBs), the absence of a well-established benchmark remains a significant\nobstacle to the development of ML. To address this issue, we introduce ML\nBenchmark For Relational Databases (RDBench), a standardized benchmark that\naims to promote reproducible ML research on RDBs that include multiple tables.\nRDBench offers diverse RDB datasets of varying scales, domains, and relational\nstructures, organized into 4 levels. Notably, to simplify the adoption of\nRDBench for diverse ML domains, for any given database, RDBench exposes three\ntypes of interfaces including tabular data, homogeneous graphs, and\nheterogeneous graphs, sharing the same underlying task definition. For the\nfirst time, RDBench enables meaningful comparisons between ML methods from\ndiverse domains, ranging from XGBoost to Graph Neural Networks, under RDB\nprediction tasks. We design multiple classification and regression tasks for\neach RDB dataset and report averaged results over the same dataset, further\nenhancing the robustness of the experimental findings. RDBench is implemented\nwith DBGym, a user-friendly platform for ML research and application on\ndatabases, enabling benchmarking new ML methods with RDBench at ease.",
            "author": [
                "Zizhao Zhang",
                "Yi Yang",
                "Lutong Zou",
                "He Wen",
                "Tao Feng",
                "Jiaxuan You"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16837v2",
                "http://arxiv.org/pdf/2310.16837v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DB",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16835v1",
            "title": "Proposal-Contrastive Pretraining for Object Detection from Fewer Data",
            "updated": "2023-10-25T17:59:26Z",
            "published": "2023-10-25T17:59:26Z",
            "summary": "The use of pretrained deep neural networks represents an attractive way to\nachieve strong results with few data available. When specialized in dense\nproblems such as object detection, learning local rather than global\ninformation in images has proven to be more efficient. However, for\nunsupervised pretraining, the popular contrastive learning requires a large\nbatch size and, therefore, a lot of resources. To address this problem, we are\ninterested in transformer-based object detectors that have recently gained\ntraction in the community with good performance and with the particularity of\ngenerating many diverse object proposals.\n  In this work, we present Proposal Selection Contrast (ProSeCo), a novel\nunsupervised overall pretraining approach that leverages this property. ProSeCo\nuses the large number of object proposals generated by the detector for\ncontrastive learning, which allows the use of a smaller batch size, combined\nwith object-level features to learn local information in the images. To improve\nthe effectiveness of the contrastive loss, we introduce the object location\ninformation in the selection of positive examples to take into account multiple\noverlapping object proposals. When reusing pretrained backbone, we advocate for\nconsistency in learning local information between the backbone and the\ndetection head.\n  We show that our method outperforms state of the art in unsupervised\npretraining for object detection on standard and novel benchmarks in learning\nwith fewer data.",
            "author": [
                "Quentin Bouniot",
                "Romaric Audigier",
                "Ang\u00e9lique Loesch",
                "Amaury Habrard"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16835v1",
                "http://arxiv.org/pdf/2310.16835v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16834v1",
            "title": "Discrete Diffusion Language Modeling by Estimating the Ratios of the\n  Data Distribution",
            "updated": "2023-10-25T17:59:12Z",
            "published": "2023-10-25T17:59:12Z",
            "summary": "Despite their groundbreaking performance for many generative modeling tasks,\ndiffusion models have fallen short on discrete data domains such as natural\nlanguage. Crucially, standard diffusion models rely on the well-established\ntheory of score matching, but efforts to generalize this to discrete structures\nhave not yielded the same empirical gains. In this work, we bridge this gap by\nproposing score entropy, a novel discrete score matching loss that is more\nstable than existing methods, forms an ELBO for maximum likelihood training,\nand can be efficiently optimized with a denoising variant. We scale our Score\nEntropy Discrete Diffusion models (SEDD) to the experimental setting of GPT-2,\nachieving highly competitive likelihoods while also introducing distinct\nalgorithmic advantages. In particular, when comparing similarly sized SEDD and\nGPT-2 models, SEDD attains comparable perplexities (normally within $+10\\%$ of\nand sometimes outperforming the baseline). Furthermore, SEDD models learn a\nmore faithful sequence distribution (around $4\\times$ better compared to GPT-2\nmodels with ancestral sampling as measured by large models), can trade off\ncompute for generation quality (needing only $16\\times$ fewer network\nevaluations to match GPT-2), and enables arbitrary infilling beyond the\nstandard left to right prompting.",
            "author": [
                "Aaron Lou",
                "Chenlin Meng",
                "Stefano Ermon"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16834v1",
                "http://arxiv.org/pdf/2310.16834v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16832v2",
            "title": "LightSpeed: Light and Fast Neural Light Fields on Mobile Devices",
            "updated": "2023-10-26T20:02:03Z",
            "published": "2023-10-25T17:59:05Z",
            "summary": "Real-time novel-view image synthesis on mobile devices is prohibitive due to\nthe limited computational power and storage. Using volumetric rendering\nmethods, such as NeRF and its derivatives, on mobile devices is not suitable\ndue to the high computational cost of volumetric rendering. On the other hand,\nrecent advances in neural light field representations have shown promising\nreal-time view synthesis results on mobile devices. Neural light field methods\nlearn a direct mapping from a ray representation to the pixel color. The\ncurrent choice of ray representation is either stratified ray sampling or\nPlucker coordinates, overlooking the classic light slab (two-plane)\nrepresentation, the preferred representation to interpolate between light field\nviews. In this work, we find that using the light slab representation is an\nefficient representation for learning a neural light field. More importantly,\nit is a lower-dimensional ray representation enabling us to learn the 4D ray\nspace using feature grids which are significantly faster to train and render.\nAlthough mostly designed for frontal views, we show that the light-slab\nrepresentation can be further extended to non-frontal scenes using a\ndivide-and-conquer strategy. Our method offers superior rendering quality\ncompared to previous light field methods and achieves a significantly improved\ntrade-off between rendering quality and speed.",
            "author": [
                "Aarush Gupta",
                "Junli Cao",
                "Chaoyang Wang",
                "Ju Hu",
                "Sergey Tulyakov",
                "Jian Ren",
                "L\u00e1szl\u00f3 A Jeni"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16832v2",
                "http://arxiv.org/pdf/2310.16832v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16831v2",
            "title": "PERF: Panoramic Neural Radiance Field from a Single Panorama",
            "updated": "2023-10-28T16:50:41Z",
            "published": "2023-10-25T17:59:01Z",
            "summary": "Neural Radiance Field (NeRF) has achieved substantial progress in novel view\nsynthesis given multi-view images. Recently, some works have attempted to train\na NeRF from a single image with 3D priors. They mainly focus on a limited field\nof view with a few occlusions, which greatly limits their scalability to\nreal-world 360-degree panoramic scenarios with large-size occlusions. In this\npaper, we present PERF, a 360-degree novel view synthesis framework that trains\na panoramic neural radiance field from a single panorama. Notably, PERF allows\n3D roaming in a complex scene without expensive and tedious image collection.\nTo achieve this goal, we propose a novel collaborative RGBD inpainting method\nand a progressive inpainting-and-erasing method to lift up a 360-degree 2D\nscene to a 3D scene. Specifically, we first predict a panoramic depth map as\ninitialization given a single panorama and reconstruct visible 3D regions with\nvolume rendering. Then we introduce a collaborative RGBD inpainting approach\ninto a NeRF for completing RGB images and depth maps from random views, which\nis derived from an RGB Stable Diffusion model and a monocular depth estimator.\nFinally, we introduce an inpainting-and-erasing strategy to avoid inconsistent\ngeometry between a newly-sampled view and reference views. The two components\nare integrated into the learning of NeRFs in a unified optimization framework\nand achieve promising results. Extensive experiments on Replica and a new\ndataset PERF-in-the-wild demonstrate the superiority of our PERF over\nstate-of-the-art methods. Our PERF can be widely used for real-world\napplications, such as panorama-to-3D, text-to-3D, and 3D scene stylization\napplications. Project page and code are available at\nhttps://perf-project.github.io/ and https://github.com/perf-project/PeRF.",
            "author": [
                "Guangcong Wang",
                "Peng Wang",
                "Zhaoxi Chen",
                "Wenping Wang",
                "Chen Change Loy",
                "Ziwei Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16831v2",
                "http://arxiv.org/pdf/2310.16831v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16828v1",
            "title": "TD-MPC2: Scalable, Robust World Models for Continuous Control",
            "updated": "2023-10-25T17:57:07Z",
            "published": "2023-10-25T17:57:07Z",
            "summary": "TD-MPC is a model-based reinforcement learning (RL) algorithm that performs\nlocal trajectory optimization in the latent space of a learned implicit\n(decoder-free) world model. In this work, we present TD-MPC2: a series of\nimprovements upon the TD-MPC algorithm. We demonstrate that TD-MPC2 improves\nsignificantly over baselines across 104 online RL tasks spanning 4 diverse task\ndomains, achieving consistently strong results with a single set of\nhyperparameters. We further show that agent capabilities increase with model\nand data size, and successfully train a single 317M parameter agent to perform\n80 tasks across multiple task domains, embodiments, and action spaces. We\nconclude with an account of lessons, opportunities, and risks associated with\nlarge TD-MPC2 agents. Explore videos, models, data, code, and more at\nhttps://nicklashansen.github.io/td-mpc2",
            "author": [
                "Nicklas Hansen",
                "Hao Su",
                "Xiaolong Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16828v1",
                "http://arxiv.org/pdf/2310.16828v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16826v2",
            "title": "Deep machine learning for meteor monitoring: advances with transfer\n  learning and gradient-weighted class activation mapping",
            "updated": "2023-10-26T10:49:13Z",
            "published": "2023-10-25T17:56:28Z",
            "summary": "In recent decades, the use of optical detection systems for meteor studies\nhas increased dramatically, resulting in huge amounts of data being analyzed.\nAutomated meteor detection tools are essential for studying the continuous\nmeteoroid incoming flux, recovering fresh meteorites, and achieving a better\nunderstanding of our Solar System. Concerning meteor detection, distinguishing\nfalse positives between meteor and non-meteor images has traditionally been\nperformed by hand, which is significantly time-consuming. To address this\nissue, we developed a fully automated pipeline that uses Convolutional Neural\nNetworks (CNNs) to classify candidate meteor detections. Our new method is able\nto detect meteors even in images that contain static elements such as clouds,\nthe Moon, and buildings. To accurately locate the meteor within each frame, we\nemploy the Gradient-weighted Class Activation Mapping (Grad-CAM) technique.\nThis method facilitates the identification of the region of interest by\nmultiplying the activations from the last convolutional layer with the average\nof the gradients across the feature map of that layer. By combining these\nfindings with the activation map derived from the first convolutional layer, we\neffectively pinpoint the most probable pixel location of the meteor. We trained\nand evaluated our model on a large dataset collected by the Spanish Meteor\nNetwork (SPMN) and achieved a precision of 98\\%. Our new methodology presented\nhere has the potential to reduce the workload of meteor scientists and station\noperators and improve the accuracy of meteor tracking and classification.",
            "author": [
                "Eloy Pe\u00f1a-Asensio",
                "Josep M. Trigo-Rodr\u00edguez",
                "Pau Gr\u00e8bol-Tom\u00e0s",
                "David Regordosa-Avellana",
                "Albert Rimola"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16826v2",
                "http://arxiv.org/pdf/2310.16826v2"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP",
                "astro-ph.IM",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16825v1",
            "title": "CommonCanvas: An Open Diffusion Model Trained with Creative-Commons\n  Images",
            "updated": "2023-10-25T17:56:07Z",
            "published": "2023-10-25T17:56:07Z",
            "summary": "We assemble a dataset of Creative-Commons-licensed (CC) images, which we use\nto train a set of open diffusion models that are qualitatively competitive with\nStable Diffusion 2 (SD2). This task presents two challenges: (1)\nhigh-resolution CC images lack the captions necessary to train text-to-image\ngenerative models; (2) CC images are relatively scarce. In turn, to address\nthese challenges, we use an intuitive transfer learning technique to produce a\nset of high-quality synthetic captions paired with curated CC images. We then\ndevelop a data- and compute-efficient training recipe that requires as little\nas 3% of the LAION-2B data needed to train existing SD2 models, but obtains\ncomparable quality. These results indicate that we have a sufficient number of\nCC images (~70 million) for training high-quality models. Our training recipe\nalso implements a variety of optimizations that achieve ~3X training speed-ups,\nenabling rapid model iteration. We leverage this recipe to train several\nhigh-quality text-to-image models, which we dub the CommonCanvas family. Our\nlargest model achieves comparable performance to SD2 on a human evaluation,\ndespite being trained on our CC dataset that is significantly smaller than\nLAION and using synthetic captions for training. We release our models, data,\nand code at\nhttps://github.com/mosaicml/diffusion/blob/main/assets/common-canvas.md",
            "author": [
                "Aaron Gokaslan",
                "A. Feder Cooper",
                "Jasmine Collins",
                "Landan Seguin",
                "Austin Jacobson",
                "Mihir Patel",
                "Jonathan Frankle",
                "Cory Stephenson",
                "Volodymyr Kuleshov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16825v1",
                "http://arxiv.org/pdf/2310.16825v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16819v1",
            "title": "CATE Lasso: Conditional Average Treatment Effect Estimation with\n  High-Dimensional Linear Regression",
            "updated": "2023-10-25T17:51:07Z",
            "published": "2023-10-25T17:51:07Z",
            "summary": "In causal inference about two treatments, Conditional Average Treatment\nEffects (CATEs) play an important role as a quantity representing an\nindividualized causal effect, defined as a difference between the expected\noutcomes of the two treatments conditioned on covariates. This study assumes\ntwo linear regression models between a potential outcome and covariates of the\ntwo treatments and defines CATEs as a difference between the linear regression\nmodels. Then, we propose a method for consistently estimating CATEs even under\nhigh-dimensional and non-sparse parameters. In our study, we demonstrate that\ndesirable theoretical properties, such as consistency, remain attainable even\nwithout assuming sparsity explicitly if we assume a weaker assumption called\nimplicit sparsity originating from the definition of CATEs. In this assumption,\nwe suppose that parameters of linear models in potential outcomes can be\ndivided into treatment-specific and common parameters, where the\ntreatment-specific parameters take difference values between each linear\nregression model, while the common parameters remain identical. Thus, in a\ndifference between two linear regression models, the common parameters\ndisappear, leaving only differences in the treatment-specific parameters.\nConsequently, the non-zero parameters in CATEs correspond to the differences in\nthe treatment-specific parameters. Leveraging this assumption, we develop a\nLasso regression method specialized for CATE estimation and present that the\nestimator is consistent. Finally, we confirm the soundness of the proposed\nmethod by simulation studies.",
            "author": [
                "Masahiro Kato",
                "Masaaki Imaizumi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16819v1",
                "http://arxiv.org/pdf/2310.16819v1"
            ],
            "primary_category": "econ.EM",
            "category": [
                "econ.EM",
                "cs.LG",
                "stat.AP",
                "stat.ME",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16812v1",
            "title": "Accurate Crop Spraying with RTK and Machine Learning on an Autonomous\n  Field Robot",
            "updated": "2023-10-25T17:40:36Z",
            "published": "2023-10-25T17:40:36Z",
            "summary": "The agriculture sector requires a lot of labor and resources. Hence, farmers\nare constantly being pressed for technology and automation to be\ncost-effective. In this context, autonomous robots can play a very important\nrole in carrying out agricultural tasks such as spraying, sowing, inspection,\nand even harvesting. This paper presents one such autonomous robot that is able\nto identify plants and spray agro-chemicals precisely. The robot uses machine\nvision technologies to find plants and RTK-GPS technology to navigate the robot\nalong a predetermined path. The experiments were conducted in a field of potted\nplants in which successful results have been obtained.",
            "author": [
                "W. M. T. D. Wijesundara",
                "T. D. Wanigathunga",
                "M. N. C. Waas",
                "R. T. Hithanadura",
                "S. R. Munasinghe"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16812v1",
                "http://arxiv.org/pdf/2310.16812v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16804v2",
            "title": "Learning COVID-19 Regional Transmission Using Universal Differential\n  Equations in a SIR model",
            "updated": "2023-11-03T12:21:05Z",
            "published": "2023-10-25T17:35:01Z",
            "summary": "Highly-interconnected societies difficult to model the spread of infectious\ndiseases such as COVID-19. Single-region SIR models fail to account for\nincoming forces of infection and expanding them to a large number of\ninteracting regions involves many assumptions that do not hold in the real\nworld. We propose using Universal Differential Equations (UDEs) to capture the\ninfluence of neighboring regions and improve the model's predictions in a\ncombined SIR+UDE model. UDEs are differential equations totally or partially\ndefined by a deep neural network (DNN). We include an additive term to the SIR\nequations composed by a DNN that learns the incoming force of infection from\nthe other regions. The learning is performed using automatic differentiation\nand gradient descent to approach the change in the target system caused by the\nstate of the neighboring regions. We compared the proposed model using a\nsimulated COVID-19 outbreak against a single-region SIR and a fully data-driven\nmodel composed only of a DNN. The proposed UDE+SIR model generates predictions\nthat capture the outbreak dynamic more accurately, but a decay in performance\nis observed at the last stages of the outbreak. The single-area SIR and the\nfully data-driven approach do not capture the proper dynamics accurately. Once\nthe predictions were obtained, we employed the SINDy algorithm to substitute\nthe DNN with a regression, removing the black box element of the model with no\nconsiderable increase in the error levels.",
            "author": [
                "Adrian Rojas-Campos",
                "Lukas Stelz",
                "Pascal Nieters"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16804v2",
                "http://arxiv.org/pdf/2310.16804v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16803v1",
            "title": "Language Agnostic Code Embeddings",
            "updated": "2023-10-25T17:34:52Z",
            "published": "2023-10-25T17:34:52Z",
            "summary": "Recently, code language models have achieved notable advancements in\naddressing a diverse array of essential code comprehension and generation\ntasks. Yet, the field lacks a comprehensive deep dive and understanding of the\ncode embeddings of multilingual code models. In this paper, we present a\ncomprehensive study on multilingual code embeddings, focusing on the\ncross-lingual capabilities of these embeddings across different programming\nlanguages. Through probing experiments, we demonstrate that code embeddings\ncomprise two distinct components: one deeply tied to the nuances and syntax of\na specific language, and the other remaining agnostic to these details,\nprimarily focusing on semantics. Further, we show that when we isolate and\neliminate this language-specific component, we witness significant improvements\nin downstream code retrieval tasks, leading to an absolute increase of up to\n+17 in the Mean Reciprocal Rank (MRR).",
            "author": [
                "Saiteja Utpala",
                "Alex Gu",
                "Pin Yu Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16803v1",
                "http://arxiv.org/pdf/2310.16803v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16802v1",
            "title": "From Molecules to Materials: Pre-training Large Generalizable Models for\n  Atomic Property Prediction",
            "updated": "2023-10-25T17:32:23Z",
            "published": "2023-10-25T17:32:23Z",
            "summary": "Foundation models have been transformational in machine learning fields such\nas natural language processing and computer vision. Similar success in atomic\nproperty prediction has been limited due to the challenges of training\neffective models across multiple chemical domains. To address this, we\nintroduce Joint Multi-domain Pre-training (JMP), a supervised pre-training\nstrategy that simultaneously trains on multiple datasets from different\nchemical domains, treating each dataset as a unique pre-training task within a\nmulti-task framework. Our combined training dataset consists of $\\sim$120M\nsystems from OC20, OC22, ANI-1x, and Transition-1x. We evaluate performance and\ngeneralization by fine-tuning over a diverse set of downstream tasks and\ndatasets including: QM9, rMD17, MatBench, QMOF, SPICE, and MD22. JMP\ndemonstrates an average improvement of 59% over training from scratch, and\nmatches or sets state-of-the-art on 34 out of 40 tasks. Our work highlights the\npotential of pre-training strategies that utilize diverse data to advance\nproperty prediction across chemical domains, especially for low-data tasks.",
            "author": [
                "Nima Shoghi",
                "Adeesh Kolluru",
                "John R. Kitchin",
                "Zachary W. Ulissi",
                "C. Lawrence Zitnick",
                "Brandon M. Wood"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16802v1",
                "http://arxiv.org/pdf/2310.16802v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16795v1",
            "title": "QMoE: Practical Sub-1-Bit Compression of Trillion-Parameter Models",
            "updated": "2023-10-25T17:24:53Z",
            "published": "2023-10-25T17:24:53Z",
            "summary": "Mixture-of-Experts (MoE) architectures offer a general solution to the high\ninference costs of large language models (LLMs) via sparse routing, bringing\nfaster and more accurate models, at the cost of massive parameter counts. For\nexample, the SwitchTransformer-c2048 model has 1.6 trillion parameters,\nrequiring 3.2TB of accelerator memory to run efficiently, which makes practical\ndeployment challenging and expensive. In this paper, we present a solution to\nthis memory problem, in form of a new compression and execution framework\ncalled QMoE. Specifically, QMoE consists of a scalable algorithm which\naccurately compresses trillion-parameter MoEs to less than 1 bit per parameter,\nin a custom format co-designed with bespoke GPU decoding kernels to facilitate\nefficient end-to-end compressed inference, with minor runtime overheads\nrelative to uncompressed execution. Concretely, QMoE can compress the 1.6\ntrillion parameter SwitchTransformer-c2048 model to less than 160GB (20x\ncompression, 0.8 bits per parameter) at only minor accuracy loss, in less than\na day on a single GPU. This enables, for the first time, the execution of a\ntrillion-parameter model on affordable commodity hardware, like a single server\nwith 4x NVIDIA A6000 or 8x NVIDIA 3090 GPUs, at less than 5% runtime overhead\nrelative to ideal uncompressed inference. The source code and compressed models\nare available at github.com/IST-DASLab/qmoe.",
            "author": [
                "Elias Frantar",
                "Dan Alistarh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16795v1",
                "http://arxiv.org/pdf/2310.16795v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16792v1",
            "title": "Learning Independent Program and Architecture Representations for\n  Generalizable Performance Modeling",
            "updated": "2023-10-25T17:24:01Z",
            "published": "2023-10-25T17:24:01Z",
            "summary": "This paper proposes PerfVec, a novel deep learning-based performance modeling\nframework that learns high-dimensional, independent/orthogonal program and\nmicroarchitecture representations. Once learned, a program representation can\nbe used to predict its performance on any microarchitecture, and likewise, a\nmicroarchitecture representation can be applied in the performance prediction\nof any program. Additionally, PerfVec yields a foundation model that captures\nthe performance essence of instructions, which can be directly used by\ndevelopers in numerous performance modeling related tasks without incurring its\ntraining cost. The evaluation demonstrates that PerfVec is more general,\nefficient, and accurate than previous approaches.",
            "author": [
                "Lingda Li",
                "Thomas Flynn",
                "Adolfy Hoisie"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16792v1",
                "http://arxiv.org/pdf/2310.16792v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16791v2",
            "title": "Covert Planning against Imperfect Observers",
            "updated": "2023-11-01T17:44:46Z",
            "published": "2023-10-25T17:23:57Z",
            "summary": "Covert planning refers to a class of constrained planning problems where an\nagent aims to accomplish a task with minimal information leaked to a passive\nobserver to avoid detection. However, existing methods of covert planning often\nconsider deterministic environments or do not exploit the observer's imperfect\ninformation. This paper studies how covert planning can leverage the coupling\nof stochastic dynamics and the observer's imperfect observation to achieve\noptimal task performance without being detected. Specifically, we employ a\nMarkov decision process to model the interaction between the agent and its\nstochastic environment, and a partial observation function to capture the\nleaked information to a passive observer. Assuming the observer employs\nhypothesis testing to detect if the observation deviates from a nominal policy,\nthe covert planning agent aims to maximize the total discounted reward while\nkeeping the probability of being detected as an adversary below a given\nthreshold. We prove that finite-memory policies are more powerful than\nMarkovian policies in covert planning. Then, we develop a primal-dual proximal\npolicy gradient method with a two-time-scale update to compute a (locally)\noptimal covert policy. We demonstrate the effectiveness of our methods using a\nstochastic gridworld example. Our experimental results illustrate that the\nproposed method computes a policy that maximizes the adversary's expected\nreward without violating the detection constraint, and empirically demonstrates\nhow the environmental noises can influence the performance of the covert\npolicies.",
            "author": [
                "Haoxiang Ma",
                "Chongyang Shi",
                "Shuo Han",
                "Michael R. Dorothy",
                "Jie Fu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16791v2",
                "http://arxiv.org/pdf/2310.16791v2"
            ],
            "primary_category": "cs.MA",
            "category": [
                "cs.MA",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16790v1",
            "title": "Improving a Named Entity Recognizer Trained on Noisy Data with a Few\n  Clean Instances",
            "updated": "2023-10-25T17:23:37Z",
            "published": "2023-10-25T17:23:37Z",
            "summary": "To achieve state-of-the-art performance, one still needs to train NER models\non large-scale, high-quality annotated data, an asset that is both costly and\ntime-intensive to accumulate. In contrast, real-world applications often resort\nto massive low-quality labeled data through non-expert annotators via\ncrowdsourcing and external knowledge bases via distant supervision as a\ncost-effective alternative. However, these annotation methods result in noisy\nlabels, which in turn lead to a notable decline in performance. Hence, we\npropose to denoise the noisy NER data with guidance from a small set of clean\ninstances. Along with the main NER model we train a discriminator model and use\nits outputs to recalibrate the sample weights. The discriminator is capable of\ndetecting both span and category errors with different discriminative prompts.\nResults on public crowdsourcing and distant supervision datasets show that the\nproposed method can consistently improve performance with a small guidance set.",
            "author": [
                "Zhendong Chu",
                "Ruiyi Zhang",
                "Tong Yu",
                "Rajiv Jain",
                "Vlad I Morariu",
                "Jiuxiang Gu",
                "Ani Nenkova"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16790v1",
                "http://arxiv.org/pdf/2310.16790v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16789v2",
            "title": "Detecting Pretraining Data from Large Language Models",
            "updated": "2023-11-03T05:27:37Z",
            "published": "2023-10-25T17:21:23Z",
            "summary": "Although large language models (LLMs) are widely deployed, the data used to\ntrain them is rarely disclosed. Given the incredible scale of this data, up to\ntrillions of tokens, it is all but certain that it includes potentially\nproblematic text such as copyrighted materials, personally identifiable\ninformation, and test data for widely reported reference benchmarks. However,\nwe currently have no way to know which data of these types is included or in\nwhat proportions. In this paper, we study the pretraining data detection\nproblem: given a piece of text and black-box access to an LLM without knowing\nthe pretraining data, can we determine if the model was trained on the provided\ntext? To facilitate this study, we introduce a dynamic benchmark WIKIMIA that\nuses data created before and after model training to support gold truth\ndetection. We also introduce a new detection method Min-K% Prob based on a\nsimple hypothesis: an unseen example is likely to contain a few outlier words\nwith low probabilities under the LLM, while a seen example is less likely to\nhave words with such low probabilities. Min-K% Prob can be applied without any\nknowledge about the pretraining corpus or any additional training, departing\nfrom previous detection methods that require training a reference model on data\nthat is similar to the pretraining data. Moreover, our experiments demonstrate\nthat Min-K% Prob achieves a 7.4% improvement on WIKIMIA over these previous\nmethods. We apply Min-K% Prob to three real-world scenarios, copyrighted book\ndetection, contaminated downstream example detection and privacy auditing of\nmachine unlearning, and find it a consistently effective solution.",
            "author": [
                "Weijia Shi",
                "Anirudh Ajith",
                "Mengzhou Xia",
                "Yangsibo Huang",
                "Daogao Liu",
                "Terra Blevins",
                "Danqi Chen",
                "Luke Zettlemoyer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16789v2",
                "http://arxiv.org/pdf/2310.16789v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16788v1",
            "title": "The GOOSE Dataset for Perception in Unstructured Environments",
            "updated": "2023-10-25T17:20:38Z",
            "published": "2023-10-25T17:20:38Z",
            "summary": "The potential for deploying autonomous systems can be significantly increased\nby improving the perception and interpretation of the environment. However, the\ndevelopment of deep learning-based techniques for autonomous systems in\nunstructured outdoor environments poses challenges due to limited data\navailability for training and testing. To address this gap, we present the\nGerman Outdoor and Offroad Dataset (GOOSE), a comprehensive dataset\nspecifically designed for unstructured outdoor environments. The GOOSE dataset\nincorporates 10 000 labeled pairs of images and point clouds, which are\nutilized to train a range of state-of-the-art segmentation models on both image\nand point cloud data. We open source the dataset, along with an ontology for\nunstructured terrain, as well as dataset standards and guidelines. This\ninitiative aims to establish a common framework, enabling the seamless\ninclusion of existing datasets and a fast way to enhance the perception\ncapabilities of various robots operating in unstructured environments. The\ndataset, pre-trained models for offroad perception, and additional\ndocumentation can be found at https://goose-dataset.de/.",
            "author": [
                "Peter Mortimer",
                "Raphael Hagmanns",
                "Miguel Granero",
                "Thorsten Luettel",
                "Janko Petereit",
                "Hans-Joachim Wuensche"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16788v1",
                "http://arxiv.org/pdf/2310.16788v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16787v3",
            "title": "The Data Provenance Initiative: A Large Scale Audit of Dataset Licensing\n  & Attribution in AI",
            "updated": "2023-11-04T19:10:06Z",
            "published": "2023-10-25T17:20:26Z",
            "summary": "The race to train language models on vast, diverse, and inconsistently\ndocumented datasets has raised pressing concerns about the legal and ethical\nrisks for practitioners. To remedy these practices threatening data\ntransparency and understanding, we convene a multi-disciplinary effort between\nlegal and machine learning experts to systematically audit and trace 1800+ text\ndatasets. We develop tools and standards to trace the lineage of these\ndatasets, from their source, creators, series of license conditions,\nproperties, and subsequent use. Our landscape analysis highlights the sharp\ndivides in composition and focus of commercially open vs closed datasets, with\nclosed datasets monopolizing important categories: lower resource languages,\nmore creative tasks, richer topic variety, newer and more synthetic training\ndata. This points to a deepening divide in the types of data that are made\navailable under different license conditions, and heightened implications for\njurisdictional legal interpretations of copyright and fair use. We also observe\nfrequent miscategorization of licenses on widely used dataset hosting sites,\nwith license omission of 70%+ and error rates of 50%+. This points to a crisis\nin misattribution and informed use of the most popular datasets driving many\nrecent breakthroughs. As a contribution to ongoing improvements in dataset\ntransparency and responsible use, we release our entire audit, with an\ninteractive UI, the Data Provenance Explorer, which allows practitioners to\ntrace and filter on data provenance for the most popular open source finetuning\ndata collections: www.dataprovenance.org.",
            "author": [
                "Shayne Longpre",
                "Robert Mahari",
                "Anthony Chen",
                "Naana Obeng-Marnu",
                "Damien Sileo",
                "William Brannon",
                "Niklas Muennighoff",
                "Nathan Khazam",
                "Jad Kabbara",
                "Kartik Perisetla",
                "Xinyi Wu",
                "Enrico Shippole",
                "Kurt Bollacker",
                "Tongshuang Wu",
                "Luis Villa",
                "Sandy Pentland",
                "Sara Hooker"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16787v3",
                "http://arxiv.org/pdf/2310.16787v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16786v1",
            "title": "The Simplest Inflationary Potentials",
            "updated": "2023-10-25T17:20:19Z",
            "published": "2023-10-25T17:20:19Z",
            "summary": "Inflation is a highly favoured theory for the early Universe. It is\ncompatible with current observations of the cosmic microwave background and\nlarge scale structure and is a driver in the quest to detect primordial\ngravitational waves. It is also, given the current quality of the data, highly\nunder-determined with a large number of candidate implementations. We use a new\nmethod in symbolic regression to generate all possible simple scalar field\npotentials for one of two possible basis sets of operators. Treating these as\nsingle-field, slow-roll inflationary models we then score them with an\ninformation-theoretic metric (\"minimum description length\") that quantifies\ntheir efficiency in compressing the information in the Planck data. We explore\ntwo possible priors on the parameter space of potentials, one related to the\nfunctions' structural complexity and one that uses a Katz back-off language\nmodel to prefer functions that may be theoretically motivated. This enables us\nto identify the inflaton potentials that optimally balance simplicity with\naccuracy at explaining the Planck data, which may subsequently find theoretical\nmotivation. Our exploratory study opens the door to extraction of fundamental\nphysics directly from data, and may be augmented with more refined theoretical\npriors in the quest for a complete understanding of the early Universe.",
            "author": [
                "Tom\u00e1s Sousa",
                "Deaglan J. Bartlett",
                "Harry Desmond",
                "Pedro G. Ferreira"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16786v1",
                "http://arxiv.org/pdf/2310.16786v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "cs.LG",
                "gr-qc",
                "hep-ph",
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16783v1",
            "title": "S$^3$-TTA: Scale-Style Selection for Test-Time Augmentation in\n  Biomedical Image Segmentation",
            "updated": "2023-10-25T17:19:14Z",
            "published": "2023-10-25T17:19:14Z",
            "summary": "Deep-learning models have been successful in biomedical image segmentation.\nTo generalize for real-world deployment, test-time augmentation (TTA) methods\nare often used to transform the test image into different versions that are\nhopefully closer to the training domain. Unfortunately, due to the vast\ndiversity of instance scale and image styles, many augmented test images\nproduce undesirable results, thus lowering the overall performance. This work\nproposes a new TTA framework, S$^3$-TTA, which selects the suitable image scale\nand style for each test image based on a transformation consistency metric. In\naddition, S$^3$-TTA constructs an end-to-end augmentation-segmentation\njoint-training pipeline to ensure a task-oriented augmentation. On public\nbenchmarks for cell and lung segmentation, S$^3$-TTA demonstrates improvements\nover the prior art by 3.4% and 1.3%, respectively, by simply augmenting the\ninput data in testing phase.",
            "author": [
                "Kangxian Xie",
                "Siyu Huang",
                "Sebastian Cajas Ordone",
                "Hanspeter Pfister",
                "Donglai Wei"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16783v1",
                "http://arxiv.org/pdf/2310.16783v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16781v1",
            "title": "Kiki or Bouba? Sound Symbolism in Vision-and-Language Models",
            "updated": "2023-10-25T17:15:55Z",
            "published": "2023-10-25T17:15:55Z",
            "summary": "Although the mapping between sound and meaning in human language is assumed\nto be largely arbitrary, research in cognitive science has shown that there are\nnon-trivial correlations between particular sounds and meanings across\nlanguages and demographic groups, a phenomenon known as sound symbolism. Among\nthe many dimensions of meaning, sound symbolism is particularly salient and\nwell-demonstrated with regards to cross-modal associations between language and\nthe visual domain. In this work, we address the question of whether sound\nsymbolism is reflected in vision-and-language models such as CLIP and Stable\nDiffusion. Using zero-shot knowledge probing to investigate the inherent\nknowledge of these models, we find strong evidence that they do show this\npattern, paralleling the well-known kiki-bouba effect in psycholinguistics. Our\nwork provides a novel method for demonstrating sound symbolism and\nunderstanding its nature using computational tools. Our code will be made\npublicly available.",
            "author": [
                "Morris Alper",
                "Hadar Averbuch-Elor"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16781v1",
                "http://arxiv.org/pdf/2310.16781v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16779v3",
            "title": "Multi-scale Diffusion Denoised Smoothing",
            "updated": "2023-10-27T17:51:17Z",
            "published": "2023-10-25T17:11:21Z",
            "summary": "Along with recent diffusion models, randomized smoothing has become one of a\nfew tangible approaches that offers adversarial robustness to models at scale,\ne.g., those of large pre-trained models. Specifically, one can perform\nrandomized smoothing on any classifier via a simple \"denoise-and-classify\"\npipeline, so-called denoised smoothing, given that an accurate denoiser is\navailable - such as diffusion model. In this paper, we present scalable methods\nto address the current trade-off between certified robustness and accuracy in\ndenoised smoothing. Our key idea is to \"selectively\" apply smoothing among\nmultiple noise scales, coined multi-scale smoothing, which can be efficiently\nimplemented with a single diffusion model. This approach also suggests a new\nobjective to compare the collective robustness of multi-scale smoothed\nclassifiers, and questions which representation of diffusion model would\nmaximize the objective. To address this, we propose to further fine-tune\ndiffusion model (a) to perform consistent denoising whenever the original image\nis recoverable, but (b) to generate rather diverse outputs otherwise. Our\nexperiments show that the proposed multi-scale smoothing scheme combined with\ndiffusion fine-tuning enables strong certified robustness available with high\nnoise level while maintaining its accuracy close to non-smoothed classifiers.",
            "author": [
                "Jongheon Jeong",
                "Jinwoo Shin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16779v3",
                "http://arxiv.org/pdf/2310.16779v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16778v1",
            "title": "Navigating Socio-Emotional Risk through Comfort-Building in a Physics\n  Teaching Community of Practice: A Case Study",
            "updated": "2023-10-25T17:10:46Z",
            "published": "2023-10-25T17:10:46Z",
            "summary": "In teacher professional development (PD), grouping teachers with varying\nlevels of experience can be a productive and empowering way to stimulate the\nexchange and co-generation of content and pedagogical knowledge. However, less\nexperienced teachers can face socio-emotional risks when engaging in\ncollaborative science content reasoning tasks with more experienced colleagues\n(Finkelstein, Jaber, & Dini, 2018), and these risks may impact the\ncollaborative experience of both parties and the learning environment in\nteacher PD. This descriptive case study examines the process of productively\nnavigating socio-emotional risks and interpersonal tensions encountered by a\nveteran and pre-service physics teacher during one episode of discussing\nphysics content. We use a single term, comfort-building, to encapsulate\ndiscursive moves that result in increased feelings of comfort and safety by the\nparticipants. Comfort-building includes moves that serve to mitigate social\nrisk, ease tension, and avoid discomfort, as well as those geared toward\nfinding common ground and co-navigating challenges. These moves can carve out\nconversational space for teachers to more confidently face risks associated\nwith being accountable to the physics content knowledge and engage in\ndiscipline-based conversations more deeply. The presented episode in this study\nwas followed by video-stimulated individual interviews to determine how\nconsciously the teachers connected their participation to explicit risk and\ncomfort. This case study highlights an affective dimension for consideration in\nthe continued study and facilitation of science teaching communities of\npractice, especially ones that bring together teachers with a variety of\nbackgrounds and skill sets.",
            "author": [
                "Maggie Mahmood",
                "Hamideh Talafian",
                "Devyn Shafer",
                "Morten Lundsgaard",
                "Eric Kuo",
                "Tim Stelzer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16778v1",
                "http://arxiv.org/pdf/2310.16778v1"
            ],
            "primary_category": "physics.ed-ph",
            "category": [
                "physics.ed-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16777v1",
            "title": "MixerFlow for Image Modelling",
            "updated": "2023-10-25T17:10:37Z",
            "published": "2023-10-25T17:10:37Z",
            "summary": "Normalising flows are statistical models that transform a complex density\ninto a simpler density through the use of bijective transformations enabling\nboth density estimation and data generation from a single model. In the context\nof image modelling, the predominant choice has been the Glow-based\narchitecture, whereas alternative architectures remain largely unexplored in\nthe research community. In this work, we propose a novel architecture called\nMixerFlow, based on the MLP-Mixer architecture, further unifying the generative\nand discriminative modelling architectures. MixerFlow offers an effective\nmechanism for weight sharing for flow-based models. Our results demonstrate\nbetter density estimation on image datasets under a fixed computational budget\nand scales well as the image resolution increases, making MixeFlow a powerful\nyet simple alternative to the Glow-based architectures. We also show that\nMixerFlow provides more informative embeddings than Glow-based architectures.",
            "author": [
                "Eshant English",
                "Matthias Kirchler",
                "Christoph Lippert"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16777v1",
                "http://arxiv.org/pdf/2310.16777v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16772v2",
            "title": "AI Agent as Urban Planner: Steering Stakeholder Dynamics in Urban\n  Planning via Consensus-based Multi-Agent Reinforcement Learning",
            "updated": "2023-11-09T15:18:20Z",
            "published": "2023-10-25T17:04:11Z",
            "summary": "In urban planning, land use readjustment plays a pivotal role in aligning\nland use configurations with the current demands for sustainable urban\ndevelopment. However, present-day urban planning practices face two main\nissues. Firstly, land use decisions are predominantly dependent on human\nexperts. Besides, while resident engagement in urban planning can promote urban\nsustainability and livability, it is challenging to reconcile the diverse\ninterests of stakeholders. To address these challenges, we introduce a\nConsensus-based Multi-Agent Reinforcement Learning framework for real-world\nland use readjustment. This framework serves participatory urban planning,\nallowing diverse intelligent agents as stakeholder representatives to vote for\npreferred land use types. Within this framework, we propose a novel consensus\nmechanism in reward design to optimize land utilization through collective\ndecision making. To abstract the structure of the complex urban system, the\ngeographic information of cities is transformed into a spatial graph structure\nand then processed by graph neural networks. Comprehensive experiments on both\ntraditional top-down planning and participatory planning methods from\nreal-world communities indicate that our computational framework enhances\nglobal benefits and accommodates diverse interests, leading to improved\nsatisfaction across different demographic groups. By integrating Multi-Agent\nReinforcement Learning, our framework ensures that participatory urban planning\ndecisions are more dynamic and adaptive to evolving community needs and\nprovides a robust platform for automating complex real-world urban planning\nprocesses.",
            "author": [
                "Kejiang Qian",
                "Lingjun Mao",
                "Xin Liang",
                "Yimin Ding",
                "Jin Gao",
                "Xinran Wei",
                "Ziyi Guo",
                "Jiajie Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16772v2",
                "http://arxiv.org/pdf/2310.16772v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16764v1",
            "title": "ConvNets Match Vision Transformers at Scale",
            "updated": "2023-10-25T16:52:13Z",
            "published": "2023-10-25T16:52:13Z",
            "summary": "Many researchers believe that ConvNets perform well on small or moderately\nsized datasets, but are not competitive with Vision Transformers when given\naccess to datasets on the web-scale. We challenge this belief by evaluating a\nperformant ConvNet architecture pre-trained on JFT-4B, a large labelled dataset\nof images often used for training foundation models. We consider pre-training\ncompute budgets between 0.4k and 110k TPU-v4 core compute hours, and train a\nseries of networks of increasing depth and width from the NFNet model family.\nWe observe a log-log scaling law between held out loss and compute budget.\nAfter fine-tuning on ImageNet, NFNets match the reported performance of Vision\nTransformers with comparable compute budgets. Our strongest fine-tuned model\nachieves a Top-1 accuracy of 90.4%.",
            "author": [
                "Samuel L. Smith",
                "Andrew Brock",
                "Leonard Berrada",
                "Soham De"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16764v1",
                "http://arxiv.org/pdf/2310.16764v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16763v1",
            "title": "SuperHF: Supervised Iterative Learning from Human Feedback",
            "updated": "2023-10-25T16:52:00Z",
            "published": "2023-10-25T16:52:00Z",
            "summary": "While large language models demonstrate remarkable capabilities, they often\npresent challenges in terms of safety, alignment with human values, and\nstability during training. Here, we focus on two prevalent methods used to\nalign these models, Supervised Fine-Tuning (SFT) and Reinforcement Learning\nfrom Human Feedback (RLHF). SFT is simple and robust, powering a host of\nopen-source models, while RLHF is a more sophisticated method used in top-tier\nmodels like ChatGPT but also suffers from instability and susceptibility to\nreward hacking. We propose a novel approach, Supervised Iterative Learning from\nHuman Feedback (SuperHF), which seeks to leverage the strengths of both\nmethods. Our hypothesis is two-fold: that the reward model used in RLHF is\ncritical for efficient data use and model generalization and that the use of\nProximal Policy Optimization (PPO) in RLHF may not be necessary and could\ncontribute to instability issues. SuperHF replaces PPO with a simple supervised\nloss and a Kullback-Leibler (KL) divergence prior. It creates its own training\ndata by repeatedly sampling a batch of model outputs and filtering them through\nthe reward model in an online learning regime. We then break down the reward\noptimization problem into three components: robustly optimizing the training\nrewards themselves, preventing reward hacking-exploitation of the reward model\nthat degrades model performance-as measured by a novel METEOR similarity\nmetric, and maintaining good performance on downstream evaluations. Our\nexperimental results show SuperHF exceeds PPO-based RLHF on the training\nobjective, easily and favorably trades off high reward with low reward hacking,\nimproves downstream calibration, and performs the same on our GPT-4 based\nqualitative evaluation scheme all the while being significantly simpler to\nimplement, highlighting SuperHF's potential as a competitive language model\nalignment technique.",
            "author": [
                "Gabriel Mukobi",
                "Peter Chatain",
                "Su Fong",
                "Robert Windesheim",
                "Gitta Kutyniok",
                "Kush Bhatia",
                "Silas Alberti"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16763v1",
                "http://arxiv.org/pdf/2310.16763v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16761v1",
            "title": "IntenDD: A Unified Contrastive Learning Approach for Intent Detection\n  and Discovery",
            "updated": "2023-10-25T16:50:24Z",
            "published": "2023-10-25T16:50:24Z",
            "summary": "Identifying intents from dialogue utterances forms an integral component of\ntask-oriented dialogue systems. Intent-related tasks are typically formulated\neither as a classification task, where the utterances are classified into\npredefined categories or as a clustering task when new and previously unknown\nintent categories need to be discovered from these utterances. Further, the\nintent classification may be modeled in a multiclass (MC) or multilabel (ML)\nsetup. While typically these tasks are modeled as separate tasks, we propose\nIntenDD, a unified approach leveraging a shared utterance encoding backbone.\nIntenDD uses an entirely unsupervised contrastive learning strategy for\nrepresentation learning, where pseudo-labels for the unlabeled utterances are\ngenerated based on their lexical features. Additionally, we introduce a\ntwo-step post-processing setup for the classification tasks using modified\nadsorption. Here, first, the residuals in the training data are propagated\nfollowed by smoothing the labels both modeled in a transductive setting.\nThrough extensive evaluations on various benchmark datasets, we find that our\napproach consistently outperforms competitive baselines across all three tasks.\nOn average, IntenDD reports percentage improvements of 2.32%, 1.26%, and 1.52%\nin their respective metrics for few-shot MC, few-shot ML, and the intent\ndiscovery tasks respectively.",
            "author": [
                "Bhavuk Singhal",
                "Ashim Gupta",
                "Shivasankaran V P",
                "Amrith Krishna"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16761v1",
                "http://arxiv.org/pdf/2310.16761v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16753v1",
            "title": "PROMINET: Prototype-based Multi-View Network for Interpretable Email\n  Response Prediction",
            "updated": "2023-10-25T16:39:00Z",
            "published": "2023-10-25T16:39:00Z",
            "summary": "Email is a widely used tool for business communication, and email marketing\nhas emerged as a cost-effective strategy for enterprises. While previous\nstudies have examined factors affecting email marketing performance, limited\nresearch has focused on understanding email response behavior by considering\nemail content and metadata. This study proposes a Prototype-based Multi-view\nNetwork (PROMINET) that incorporates semantic and structural information from\nemail data. By utilizing prototype learning, the PROMINET model generates\nlatent exemplars, enabling interpretable email response prediction. The model\nmaps learned semantic and structural exemplars to observed samples in the\ntraining data at different levels of granularity, such as document, sentence,\nor phrase. The approach is evaluated on two real-world email datasets: the\nEnron corpus and an in-house Email Marketing corpus. Experimental results\ndemonstrate that the PROMINET model outperforms baseline models, achieving a\n~3% improvement in F1 score on both datasets. Additionally, the model provides\ninterpretability through prototypes at different granularity levels while\nmaintaining comparable performance to non-interpretable models. The learned\nprototypes also show potential for generating suggestions to enhance email text\nediting and improve the likelihood of effective email responses. This research\ncontributes to enhancing sender-receiver communication and customer engagement\nin email interactions.",
            "author": [
                "Yuqing Wang",
                "Prashanth Vijayaraghavan",
                "Ehsan Degan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16753v1",
                "http://arxiv.org/pdf/2310.16753v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16752v1",
            "title": "Simple, Scalable and Effective Clustering via One-Dimensional\n  Projections",
            "updated": "2023-10-25T16:37:45Z",
            "published": "2023-10-25T16:37:45Z",
            "summary": "Clustering is a fundamental problem in unsupervised machine learning with\nmany applications in data analysis. Popular clustering algorithms such as\nLloyd's algorithm and $k$-means++ can take $\\Omega(ndk)$ time when clustering\n$n$ points in a $d$-dimensional space (represented by an $n\\times d$ matrix\n$X$) into $k$ clusters. In applications with moderate to large $k$, the\nmultiplicative $k$ factor can become very expensive. We introduce a simple\nrandomized clustering algorithm that provably runs in expected time\n$O(\\mathrm{nnz}(X) + n\\log n)$ for arbitrary $k$. Here $\\mathrm{nnz}(X)$ is the\ntotal number of non-zero entries in the input dataset $X$, which is upper\nbounded by $nd$ and can be significantly smaller for sparse datasets. We prove\nthat our algorithm achieves approximation ratio $\\smash{\\widetilde{O}(k^4)}$ on\nany input dataset for the $k$-means objective. We also believe that our\ntheoretical analysis is of independent interest, as we show that the\napproximation ratio of a $k$-means algorithm is approximately preserved under a\nclass of projections and that $k$-means++ seeding can be implemented in\nexpected $O(n \\log n)$ time in one dimension. Finally, we show experimentally\nthat our clustering algorithm gives a new tradeoff between running time and\ncluster quality compared to previous state-of-the-art methods for these tasks.",
            "author": [
                "Moses Charikar",
                "Monika Henzinger",
                "Lunjia Hu",
                "Maxmilian V\u00f6tsch",
                "Erik Waingarten"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16752v1",
                "http://arxiv.org/pdf/2310.16752v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16750v1",
            "title": "Metrically Scaled Monocular Depth Estimation through Sparse Priors for\n  Underwater Robots",
            "updated": "2023-10-25T16:32:31Z",
            "published": "2023-10-25T16:32:31Z",
            "summary": "In this work, we address the problem of real-time dense depth estimation from\nmonocular images for mobile underwater vehicles. We formulate a deep learning\nmodel that fuses sparse depth measurements from triangulated features to\nimprove the depth predictions and solve the problem of scale ambiguity. To\nallow prior inputs of arbitrary sparsity, we apply a dense parameterization\nmethod. Our model extends recent state-of-the-art approaches to monocular image\nbased depth estimation, using an efficient encoder-decoder backbone and modern\nlightweight transformer optimization stage to encode global context. The\nnetwork is trained in a supervised fashion on the forward-looking underwater\ndataset, FLSea. Evaluation results on this dataset demonstrate significant\nimprovement in depth prediction accuracy by the fusion of the sparse feature\npriors. In addition, without any retraining, our method achieves similar depth\nprediction accuracy on a downward looking dataset we collected with a diver\noperated camera rig, conducting a survey of a coral reef. The method achieves\nreal-time performance, running at 160 FPS on a laptop GPU and 7 FPS on a single\nCPU core and is suitable for direct deployment on embedded systems. The\nimplementation of this work is made publicly available at\nhttps://github.com/ebnerluca/uw_depth.",
            "author": [
                "Luca Ebner",
                "Gideon Billings",
                "Stefan Williams"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16750v1",
                "http://arxiv.org/pdf/2310.16750v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16749v1",
            "title": "DISCO: A Large Scale Human Annotated Corpus for Disfluency Correction in\n  Indo-European Languages",
            "updated": "2023-10-25T16:32:02Z",
            "published": "2023-10-25T16:32:02Z",
            "summary": "Disfluency correction (DC) is the process of removing disfluent elements like\nfillers, repetitions and corrections from spoken utterances to create readable\nand interpretable text. DC is a vital post-processing step applied to Automatic\nSpeech Recognition (ASR) outputs, before subsequent processing by downstream\nlanguage understanding tasks. Existing DC research has primarily focused on\nEnglish due to the unavailability of large-scale open-source datasets. Towards\nthe goal of multilingual disfluency correction, we present a high-quality\nhuman-annotated DC corpus covering four important Indo-European languages:\nEnglish, Hindi, German and French. We provide extensive analysis of results of\nstate-of-the-art DC models across all four languages obtaining F1 scores of\n97.55 (English), 94.29 (Hindi), 95.89 (German) and 92.97 (French). To\ndemonstrate the benefits of DC on downstream tasks, we show that DC leads to\n5.65 points increase in BLEU scores on average when used in conjunction with a\nstate-of-the-art Machine Translation (MT) system. We release code to run our\nexperiments along with our annotated dataset here.",
            "author": [
                "Vineet Bhat",
                "Preethi Jyothi",
                "Pushpak Bhattacharyya"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16749v1",
                "http://arxiv.org/pdf/2310.16749v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16748v1",
            "title": "Integrated Freeway and Arterial Traffic Control to Improve Freeway\n  Mobility without Compromising Arterial Traffic Conditions Using Q-Learning",
            "updated": "2023-10-25T16:29:28Z",
            "published": "2023-10-25T16:29:28Z",
            "summary": "Freeway and arterial transportation networks are operated individually in\nmost cities nowadays. The lack of coordination between the two increases the\nseverity of traffic congestion when they are heavily loaded. To address the\nissue, we propose an integrated traffic control strategy that coordinates\nfreeway traffic control (variable speed limit control, lane change\nrecommendations, ramp metering) and arterial signal timing using Q-learning.\nThe agent is trained offline in a single-section road network first, and then\nimplemented online in a large simulation network with real-world traffic\ndemands. The online data are collected to further improve the agent's\nperformance via continuous learning. We observe significant reductions in\nfreeway travel time and number of stops and a slight increase in on-ramp queue\nlengths by implementing the proposed approach in scenarios with traffic\ncongestion. Meanwhile, the queue lengths of adjacent arterial intersections are\nmaintained at the same level. The benefits of the coordination mechanism is\nverified by comparing the proposed approach with an uncoordinated Q-learning\nalgorithm and a decentralized feedback control strategy.",
            "author": [
                "Tianchen Yuan",
                "Petros A. Ioannou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16748v1",
                "http://arxiv.org/pdf/2310.16748v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16745v1",
            "title": "Design Space Exploration of Sparsity-Aware Application-Specific Spiking\n  Neural Network Accelerators",
            "updated": "2023-10-25T16:22:03Z",
            "published": "2023-10-25T16:22:03Z",
            "summary": "Spiking Neural Networks (SNNs) offer a promising alternative to Artificial\nNeural Networks (ANNs) for deep learning applications, particularly in\nresource-constrained systems. This is largely due to their inherent sparsity,\ninfluenced by factors such as the input dataset, the length of the spike train,\nand the network topology. While a few prior works have demonstrated the\nadvantages of incorporating sparsity into the hardware design, especially in\nterms of reducing energy consumption, the impact on hardware resources has not\nyet been explored. This is where design space exploration (DSE) becomes\ncrucial, as it allows for the optimization of hardware performance by tailoring\nboth the hardware and model parameters to suit specific application needs.\nHowever, DSE can be extremely challenging given the potentially large design\nspace and the interplay of hardware architecture design choices and\napplication-specific model parameters.\n  In this paper, we propose a flexible hardware design that leverages the\nsparsity of SNNs to identify highly efficient, application-specific accelerator\ndesigns. We develop a high-level, cycle-accurate simulation framework for this\nhardware and demonstrate the framework's benefits in enabling detailed and\nfine-grained exploration of SNN design choices, such as the layer-wise\nlogical-to-hardware ratio (LHR). Our experimental results show that our design\ncan (i) achieve up to $76\\%$ reduction in hardware resources and (ii) deliver a\nspeed increase of up to $31.25\\times$, while requiring $27\\%$ fewer hardware\nresources compared to sparsity-oblivious designs. We further showcase the\nrobustness of our framework by varying spike train lengths with different\nneuron population sizes to find the optimal trade-off points between accuracy\nand hardware latency.",
            "author": [
                "Ilkin Aliyev. Kama Svoboda",
                "Tosiron Adegbija"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16745v1",
                "http://arxiv.org/pdf/2310.16745v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16742v1",
            "title": "Interferometric Neural Networks",
            "updated": "2023-10-25T16:17:47Z",
            "published": "2023-10-25T16:17:47Z",
            "summary": "On the one hand, artificial neural networks have many successful applications\nin the field of machine learning and optimization. On the other hand,\ninterferometers are integral parts of any field that deals with waves such as\noptics, astronomy, and quantum physics. Here, we introduce neural networks\ncomposed of interferometers and then build generative adversarial networks from\nthem. Our networks do not have any classical layer and can be realized on\nquantum computers or photonic chips. We demonstrate their applicability for\ncombinatorial optimization, image classification, and image generation. For\ncombinatorial optimization, our network consistently converges to the global\noptimum or remains within a narrow range of it. In multi-class image\nclassification tasks, our networks achieve accuracies of 93% and 83%. Lastly,\nwe show their capability to generate images of digits from 0 to 9 as well as\nhuman faces.",
            "author": [
                "Arun Sehrawat"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16742v1",
                "http://arxiv.org/pdf/2310.16742v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16741v1",
            "title": "Stochastic Latent Transformer: Efficient Modelling of Stochastically\n  Forced Zonal Jets",
            "updated": "2023-10-25T16:17:00Z",
            "published": "2023-10-25T16:17:00Z",
            "summary": "We introduce the 'Stochastic Latent Transformer', a probabilistic deep\nlearning approach for efficient reduced-order modelling of stochastic partial\ndifferential equations (SPDEs). Despite recent advances in deep learning for\nfluid mechanics, limited research has explored modelling stochastically driven\nflows - which play a crucial role in understanding a broad spectrum of\nphenomena, from jets on giant planets to ocean circulation and the variability\nof midlatitude weather. The model architecture consists of a\nstochastically-forced transformer, paired with a translation-equivariant\nautoencoder, that we demonstrate is capable of reproducing system dynamics\nacross various integration periods. We demonstrate its effectiveness applied to\na well-researched zonal jet system, with the neural network achieving a\nfive-order-of-magnitude speedup compared to numerical integration. This\nfacilitates the cost-effective generation of large ensembles, enabling the\nexploration of statistical questions concerning probabilities of spontaneous\ntransition events.",
            "author": [
                "Ira J. S. Shokar",
                "Rich R. Kerswell",
                "Peter H. Haynes"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16741v1",
                "http://arxiv.org/pdf/2310.16741v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.ao-ph",
                "physics.flu-dyn",
                "68T07, 37N10, 35R60"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16730v1",
            "title": "MultiPrompter: Cooperative Prompt Optimization with Multi-Agent\n  Reinforcement Learning",
            "updated": "2023-10-25T15:58:51Z",
            "published": "2023-10-25T15:58:51Z",
            "summary": "Recently, there has been an increasing interest in automated prompt\noptimization based on reinforcement learning (RL). This approach offers\nimportant advantages, such as generating interpretable prompts and being\ncompatible with black-box foundation models. However, the substantial prompt\nspace size poses challenges for RL-based methods, often leading to suboptimal\npolicy convergence. This paper introduces MultiPrompter, a new framework that\nviews prompt optimization as a cooperative game between prompters which take\nturns composing a prompt together. Our cooperative prompt optimization\neffectively reduces the problem size and helps prompters learn optimal prompts.\nWe test our method on the text-to-image task and show its ability to generate\nhigher-quality images than baselines.",
            "author": [
                "Dong-Ki Kim",
                "Sungryull Sohn",
                "Lajanugen Logeswaran",
                "Dongsub Shim",
                "Honglak Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16730v1",
                "http://arxiv.org/pdf/2310.16730v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16728v1",
            "title": "A Finely Segmented Semi-Monolithic Detector tailored for High Resolution\n  PET",
            "updated": "2023-10-25T15:56:36Z",
            "published": "2023-10-25T15:56:36Z",
            "summary": "Preclinical research and organ-dedicated applications require high-resolution\npositron emission tomography (PET) detectors to visualize small structures and\nunderstand biological processes at a finer level of detail. Current commercial\nsystems often employ finely pixelated or monolithic scintillators, each with\nits limitations. We present a semi-monolithic detector, tailored for\nhigh-resolution PET applications, and merging concepts of monolithic and\npixelated crystals. The detector features slabs measuring (24 x 10 x 1) sq. mm,\ncoupled to a 12 x 12 readout channel photosensor with 4 mm pitch. The slabs are\ngrouped in two arrays of 44 slabs each to achieve a higher optical photon\ndensity. We employ a fan beam collimator for fast calibration to train\nmachine-learning-based positioning models for all three dimensions, including\nslab identification and depth-of-interaction (DOI), utilizing gradient tree\nboosting (GTB). Energy calculation was based on a position-dependent energy\ncalibration. Using an analytical timing calibration, time skews were corrected\nfor coincidence timing resolution (CTR) estimation. Leveraging\nmachine-learning-based calibration in all three dimensions, we achieved high\ndetector spatial resolution: down to 1.18 mm full width at half maximum (FWHM)\ndetector spatial resolution and 0.75 mm mean absolute error (MAE) in the\nplanar-monolithic direction along the slabs, and 2.14 mm FWHM and 1.03 mm MAE\nfor depth-of-interaction (DOI) at an energy window of (435-585) keV. Correct\nslab interaction identification exceeded 80%, alongside an energy resolution of\n13.8% and a CTR of 450 ps FWHM. Therewith, the introduced finely segmented,\nhigh-resolution slab detector demonstrates an appealing performance suitable\nfor high-resolution PET applications. The current benchtop-based detector\ncalibration routine allows these detectors to be used in PET systems.",
            "author": [
                "Yannick Kuhl",
                "Florian Mueller",
                "Stephan Naunheim",
                "Matthias Bovelett",
                "Janko Lambertus",
                "David Schug",
                "Bjoern Weissler",
                "Eike Gegenmantel",
                "Pierre Gebhardt",
                "Volkmar Schulz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16728v1",
                "http://arxiv.org/pdf/2310.16728v1"
            ],
            "primary_category": "physics.med-ph",
            "category": [
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16727v1",
            "title": "AI Hazard Management: A framework for the systematic management of root\n  causes for AI risks",
            "updated": "2023-10-25T15:55:50Z",
            "published": "2023-10-25T15:55:50Z",
            "summary": "Recent advancements in the field of Artificial Intelligence (AI) establish\nthe basis to address challenging tasks. However, with the integration of AI,\nnew risks arise. Therefore, to benefit from its advantages, it is essential to\nadequately handle the risks associated with AI. Existing risk management\nprocesses in related fields, such as software systems, need to sufficiently\nconsider the specifics of AI. A key challenge is to systematically and\ntransparently identify and address AI risks' root causes - also called AI\nhazards. This paper introduces the AI Hazard Management (AIHM) framework, which\nprovides a structured process to systematically identify, assess, and treat AI\nhazards. The proposed process is conducted in parallel with the development to\nensure that any AI hazard is captured at the earliest possible stage of the AI\nsystem's life cycle. In addition, to ensure the AI system's auditability, the\nproposed framework systematically documents evidence that the potential impact\nof identified AI hazards could be reduced to a tolerable level. The framework\nbuilds upon an AI hazard list from a comprehensive state-of-the-art analysis.\nAlso, we provide a taxonomy that supports the optimal treatment of the\nidentified AI hazards. Additionally, we illustrate how the AIHM framework can\nincrease the overall quality of a power grid AI use case by systematically\nreducing the impact of identified hazards to an acceptable level.",
            "author": [
                "Ronald Schnitzer",
                "Andreas Hapfelmeier",
                "Sven Gaube",
                "Sonja Zillner"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16727v1",
                "http://arxiv.org/pdf/2310.16727v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16717v2",
            "title": "Rebuild City Buildings from Off-Nadir Aerial Images with Offset-Building\n  Model (OBM)",
            "updated": "2023-11-03T13:34:00Z",
            "published": "2023-10-25T15:44:50Z",
            "summary": "Accurate measurement of the offset from roof-to-footprint in\nvery-high-resolution remote sensing imagery is crucial for urban information\nextraction tasks. With the help of deep learning, existing methods typically\nrely on two-stage CNN models to extract regions of interest on building feature\nmaps. At the first stage, a Region Proposal Network (RPN) is applied to extract\nthousands of ROIs (Region of Interests) which will post-imported into a\nRegion-based Convolutional Neural Networks (RCNN) to extract wanted\ninformation. However, because of inflexible RPN, these methods often lack\neffective user interaction, encounter difficulties in instance correspondence,\nand struggle to keep up with the advancements in general artificial\nintelligence. This paper introduces an interactive Transformer model combined\nwith a prompt encoder to precisely extract building segmentation as well as the\noffset vectors from roofs to footprints. In our model, a powerful module,\nnamely ROAM, was tailored for common problems in predicting roof-to-footprint\noffsets. We tested our model's feasibility on the publicly available BONAI\ndataset, achieving a significant reduction in Prompt-Instance-Level offset\nerrors ranging from 14.6% to 16.3%. Additionally, we developed a Distance-NMS\nalgorithm tailored for large-scale building offsets, significantly enhancing\nthe accuracy of predicted building offset angles and lengths in a\nstraightforward and efficient manner. To further validate the model's\nrobustness, we created a new test set using 0.5m remote sensing imagery from\nHuizhou, China, for inference testing. Our code, training methods, and the\nupdated dataset will be accessable at https://github.com/likaiucas.",
            "author": [
                "Kai Li",
                "Yupeng Deng",
                "Yunlong Kong",
                "Diyou Liu",
                "Jingbo Chen",
                "Yu Meng",
                "Junxian Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16717v2",
                "http://arxiv.org/pdf/2310.16717v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "I.4.6; I.4.7; I.3.5; I.5.1"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16712v1",
            "title": "LLM Performance Predictors are good initializers for Architecture Search",
            "updated": "2023-10-25T15:34:30Z",
            "published": "2023-10-25T15:34:30Z",
            "summary": "Large language models (LLMs) have become an integral component in solving a\nwide range of NLP tasks. In this work, we explore a novel use case of using\nLLMs to build performance predictors (PP): models that, given a specific deep\nneural network architecture, predict its performance on a downstream task. We\ndesign PP prompts for LLMs consisting of: (i) role: description of the role\nassigned to the LLM, (ii) instructions: set of instructions to be followed by\nthe LLM to carry out performance prediction, (iii) hyperparameters: a\ndefinition of each architecture-specific hyperparameter and (iv)\ndemonstrations: sample architectures along with their efficiency metrics and\n'training from scratch' performance. For machine translation (MT) tasks, we\ndiscover that GPT-4 with our PP prompts (LLM-PP) can predict the performance of\narchitecture with a mean absolute error matching the SOTA and a marginal\ndegradation in rank correlation coefficient compared to SOTA performance\npredictors. Further, we show that the predictions from LLM-PP can be distilled\nto a small regression model (LLM-Distill-PP). LLM-Distill-PP models\nsurprisingly retain the performance of LLM-PP largely and can be a\ncost-effective alternative for heavy use cases of performance estimation.\nSpecifically, for neural architecture search (NAS), we propose a Hybrid-Search\nalgorithm for NAS (HS-NAS), which uses LLM-Distill-PP for the initial part of\nsearch, resorting to the baseline predictor for rest of the search. We show\nthat HS-NAS performs very similar to SOTA NAS across benchmarks, reduces search\nhours by 50% roughly, and in some cases, improves latency, GFLOPs, and model\nsize.",
            "author": [
                "Ganesh Jawahar",
                "Muhammad Abdul-Mageed",
                "Laks V. S. Lakshmanan",
                "Dujian Ding"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16712v1",
                "http://arxiv.org/pdf/2310.16712v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16706v1",
            "title": "Nighttime Driver Behavior Prediction Using Taillight Signal Recognition\n  via CNN-SVM Classifier",
            "updated": "2023-10-25T15:23:33Z",
            "published": "2023-10-25T15:23:33Z",
            "summary": "This paper aims to enhance the ability to predict nighttime driving behavior\nby identifying taillights of both human-driven and autonomous vehicles. The\nproposed model incorporates a customized detector designed to accurately detect\nfront-vehicle taillights on the road. At the beginning of the detector, a\nlearnable pre-processing block is implemented, which extracts deep features\nfrom input images and calculates the data rarity for each feature. In the next\nstep, drawing inspiration from soft attention, a weighted binary mask is\ndesigned that guides the model to focus more on predetermined regions. This\nresearch utilizes Convolutional Neural Networks (CNNs) to extract\ndistinguishing characteristics from these areas, then reduces dimensions using\nPrincipal Component Analysis (PCA). Finally, the Support Vector Machine (SVM)\nis used to predict the behavior of the vehicles. To train and evaluate the\nmodel, a large-scale dataset is collected from two types of dash-cams and\nInsta360 cameras from the rear view of Ford Motor Company vehicles. This\ndataset includes over 12k frames captured during both daytime and nighttime\nhours. To address the limited nighttime data, a unique pixel-wise image\nprocessing technique is implemented to convert daytime images into realistic\nnight images. The findings from the experiments demonstrate that the proposed\nmethodology can accurately categorize vehicle behavior with 92.14% accuracy,\n97.38% specificity, 92.09% sensitivity, 92.10% F1-measure, and 0.895 Cohen's\nKappa Statistic. Further details are available at\nhttps://github.com/DeepCar/Taillight_Recognition.",
            "author": [
                "Amir Hossein Barshooi",
                "Elmira Bagheri"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16706v1",
                "http://arxiv.org/pdf/2310.16706v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16705v1",
            "title": "Wasserstein Gradient Flow over Variational Parameter Space for\n  Variational Inference",
            "updated": "2023-10-25T15:20:53Z",
            "published": "2023-10-25T15:20:53Z",
            "summary": "Variational inference (VI) can be cast as an optimization problem in which\nthe variational parameters are tuned to closely align a variational\ndistribution with the true posterior. The optimization task can be approached\nthrough vanilla gradient descent in black-box VI or natural-gradient descent in\nnatural-gradient VI. In this work, we reframe VI as the optimization of an\nobjective that concerns probability distributions defined over a\n\\textit{variational parameter space}. Subsequently, we propose Wasserstein\ngradient descent for tackling this optimization problem. Notably, the\noptimization techniques, namely black-box VI and natural-gradient VI, can be\nreinterpreted as specific instances of the proposed Wasserstein gradient\ndescent. To enhance the efficiency of optimization, we develop practical\nmethods for numerically solving the discrete gradient flows. We validate the\neffectiveness of the proposed methods through empirical experiments on a\nsynthetic dataset, supplemented by theoretical analyses.",
            "author": [
                "Dai Hai Nguyen",
                "Tetsuya Sakurai",
                "Hiroshi Mamitsuka"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16705v1",
                "http://arxiv.org/pdf/2310.16705v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16698v1",
            "title": "Causal Discovery with Generalized Linear Models through Peeling\n  Algorithms",
            "updated": "2023-10-25T15:12:24Z",
            "published": "2023-10-25T15:12:24Z",
            "summary": "This article presents a novel method for causal discovery with generalized\nstructural equation models suited for analyzing diverse types of outcomes,\nincluding discrete, continuous, and mixed data. Causal discovery often faces\nchallenges due to unmeasured confounders that hinder the identification of\ncausal relationships. The proposed approach addresses this issue by developing\ntwo peeling algorithms (bottom-up and top-down) to ascertain causal\nrelationships and valid instruments. This approach first reconstructs a\nsuper-graph to represent ancestral relationships between variables, using a\npeeling algorithm based on nodewise GLM regressions that exploit relationships\nbetween primary and instrumental variables. Then, it estimates parent-child\neffects from the ancestral relationships using another peeling algorithm while\ndeconfounding a child's model with information borrowed from its parents'\nmodels. The article offers a theoretical analysis of the proposed approach,\nwhich establishes conditions for model identifiability and provides statistical\nguarantees for accurately discovering parent-child relationships via the\npeeling algorithms. Furthermore, the article presents numerical experiments\nshowcasing the effectiveness of our approach in comparison to state-of-the-art\nstructure learning methods without confounders. Lastly, it demonstrates an\napplication to Alzheimer's disease (AD), highlighting the utility of the method\nin constructing gene-to-gene and gene-to-disease regulatory networks involving\nSingle Nucleotide Polymorphisms (SNPs) for healthy and AD subjects.",
            "author": [
                "Minjie Wang",
                "Xiaotong Shen",
                "Wei Pan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16698v1",
                "http://arxiv.org/pdf/2310.16698v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16697v1",
            "title": "$O(1/\\varepsilon)$ is the answer in online weighted throughput\n  maximization",
            "updated": "2023-10-25T15:11:18Z",
            "published": "2023-10-25T15:11:18Z",
            "summary": "We study a fundamental online scheduling problem where jobs with processing\ntimes, weights, and deadlines arrive online over time at their release dates.\nThe task is to preemptively schedule these jobs on a single or multiple\n(possibly unrelated) machines with the objective to maximize the weighted\nthroughput, the total weight of jobs that complete before their deadline. To\novercome known lower bounds for the competitive analysis, we assume that each\njob arrives with some slack $\\varepsilon > 0$; that is, the time window for\nprocessing job $j$ on any machine $i$ on which it can be executed has length at\nleast $(1+\\varepsilon)$ times $j$'s processing time on machine $i$. Our\ncontribution is a best possible online algorithm for weighted throughput\nmaximization on unrelated machines: Our algorithm is\n$O\\big(\\frac1\\varepsilon\\big)$-competitive, which matches the lower bound for\nunweighted throughput maximization on a single machine. Even for a single\nmachine, it was not known whether the problem with weighted jobs is \"harder\"\nthan the problem with unweighted jobs. Thus, we answer this question and close\nweighted throughput maximization on a single machine with a best possible\ncompetitive ratio $\\Theta\\big(\\frac1\\varepsilon\\big)$. While we focus on\nnon-migratory schedules, our algorithm achieves the same (up to constants)\nperformance guarantee when compared to an optimal migratory schedule.",
            "author": [
                "Franziska Eberle"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16697v1",
                "http://arxiv.org/pdf/2310.16697v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16696v1",
            "title": "Interpretable time series neural representation for classification\n  purposes",
            "updated": "2023-10-25T15:06:57Z",
            "published": "2023-10-25T15:06:57Z",
            "summary": "Deep learning has made significant advances in creating efficient\nrepresentations of time series data by automatically identifying complex\npatterns. However, these approaches lack interpretability, as the time series\nis transformed into a latent vector that is not easily interpretable. On the\nother hand, Symbolic Aggregate approximation (SAX) methods allow the creation\nof symbolic representations that can be interpreted but do not capture complex\npatterns effectively. In this work, we propose a set of requirements for a\nneural representation of univariate time series to be interpretable. We propose\na new unsupervised neural architecture that meets these requirements. The\nproposed model produces consistent, discrete, interpretable, and visualizable\nrepresentations. The model is learned independently of any downstream tasks in\nan unsupervised setting to ensure robustness. As a demonstration of the\neffectiveness of the proposed model, we propose experiments on classification\ntasks using UCR archive datasets. The obtained results are extensively compared\nto other interpretable models and state-of-the-art neural representation\nlearning models. The experiments show that the proposed model yields, on\naverage better results than other interpretable approaches on multiple\ndatasets. We also present qualitative experiments to asses the interpretability\nof the approach.",
            "author": [
                "Etienne Le Naour",
                "Ghislain Agoua",
                "Nicolas Baskiotis",
                "Vincent Guigue"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16696v1",
                "http://arxiv.org/pdf/2310.16696v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16695v1",
            "title": "From Pointwise to Powerhouse: Initialising Neural Networks with\n  Generative Models",
            "updated": "2023-10-25T15:06:32Z",
            "published": "2023-10-25T15:06:32Z",
            "summary": "Traditional initialisation methods, e.g. He and Xavier, have been effective\nin avoiding the problem of vanishing or exploding gradients in neural networks.\nHowever, they only use simple pointwise distributions, which model\none-dimensional variables. Moreover, they ignore most information about the\narchitecture and disregard past training experiences. These limitations can be\novercome by employing generative models for initialisation. In this paper, we\nintroduce two groups of new initialisation methods. First, we locally\ninitialise weight groups by employing variational autoencoders. Secondly, we\nglobally initialise full weight sets by employing graph hypernetworks. We\nthoroughly evaluate the impact of the employed generative models on\nstate-of-the-art neural networks in terms of accuracy, convergence speed and\nensembling. Our results show that global initialisations result in higher\naccuracy and faster initial convergence speed. However, the implementation\nthrough graph hypernetworks leads to diminished ensemble performance on out of\ndistribution data. To counteract, we propose a modification called noise graph\nhypernetwork, which encourages diversity in the produced ensemble members.\nFurthermore, our approach might be able to transfer learned knowledge to\ndifferent image distributions. Our work provides insights into the potential,\nthe trade-offs and possible modifications of these new initialisation methods.",
            "author": [
                "Christian Harder",
                "Moritz Fuchs",
                "Yuri Tolkach",
                "Anirban Mukhopadhyay"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16695v1",
                "http://arxiv.org/pdf/2310.16695v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "J.3; I.5.1; I.5.4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16694v1",
            "title": "DSAM-GN:Graph Network based on Dynamic Similarity Adjacency Matrices for\n  Vehicle Re-identification",
            "updated": "2023-10-25T15:04:57Z",
            "published": "2023-10-25T15:04:57Z",
            "summary": "In recent years, vehicle re-identification (Re-ID) has gained increasing\nimportance in various applications such as assisted driving systems, traffic\nflow management, and vehicle tracking, due to the growth of intelligent\ntransportation systems. However, the presence of extraneous background\ninformation and occlusions can interfere with the learning of discriminative\nfeatures, leading to significant variations in the same vehicle image across\ndifferent scenarios. This paper proposes a method, named graph network based on\ndynamic similarity adjacency matrices (DSAM-GN), which incorporates a novel\napproach for constructing adjacency matrices to capture spatial relationships\nof local features and reduce background noise. Specifically, the proposed\nmethod divides the extracted vehicle features into different patches as nodes\nwithin the graph network. A spatial attention-based similarity adjacency matrix\ngeneration (SASAMG) module is employed to compute similarity matrices of nodes,\nand a dynamic erasure operation is applied to disconnect nodes with low\nsimilarity, resulting in similarity adjacency matrices. Finally, the nodes and\nsimilarity adjacency matrices are fed into graph networks to extract more\ndiscriminative features for vehicle Re-ID. Experimental results on public\ndatasets VeRi-776 and VehicleID demonstrate the effectiveness of the proposed\nmethod compared with recent works.",
            "author": [
                "Yuejun Jiao",
                "Song Qiu",
                "Mingsong Chen",
                "Dingding Han",
                "Qingli Li",
                "Yue Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16694v1",
                "http://arxiv.org/pdf/2310.16694v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17816v1",
            "title": "Local Discovery by Partitioning: Polynomial-Time Causal Discovery Around\n  Exposure-Outcome Pairs",
            "updated": "2023-10-25T14:53:10Z",
            "published": "2023-10-25T14:53:10Z",
            "summary": "This work addresses the problem of automated covariate selection under\nlimited prior knowledge. Given an exposure-outcome pair {X,Y} and a variable\nset Z of unknown causal structure, the Local Discovery by Partitioning (LDP)\nalgorithm partitions Z into subsets defined by their relation to {X,Y}. We\nenumerate eight exhaustive and mutually exclusive partitions of any arbitrary Z\nand leverage this taxonomy to differentiate confounders from other variable\ntypes. LDP is motivated by valid adjustment set identification, but avoids the\npretreatment assumption commonly made by automated covariate selection methods.\nWe provide theoretical guarantees that LDP returns a valid adjustment set for\nany Z that meets sufficient graphical conditions. Under stronger conditions, we\nprove that partition labels are asymptotically correct. Total independence\ntests is worst-case quadratic in |Z|, with sub-quadratic runtimes observed\nempirically. We numerically validate our theoretical guarantees on synthetic\nand semi-synthetic graphs. Adjustment sets from LDP yield less biased and more\nprecise average treatment effect estimates than baselines, with LDP\noutperforming on confounder recall, test count, and runtime for valid\nadjustment set discovery.",
            "author": [
                "Jacqueline Maasch",
                "Weishen Pan",
                "Shantanu Gupta",
                "Volodymyr Kuleshov",
                "Kyra Gan",
                "Fei Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17816v1",
                "http://arxiv.org/pdf/2310.17816v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16688v1",
            "title": "Learning-based adaption of robotic friction models",
            "updated": "2023-10-25T14:50:15Z",
            "published": "2023-10-25T14:50:15Z",
            "summary": "In the Fourth Industrial Revolution, wherein artificial intelligence and the\nautomation of machines occupy a central role, the deployment of robots is\nindispensable. However, the manufacturing process using robots, especially in\ncollaboration with humans, is highly intricate. In particular, modeling the\nfriction torque in robotic joints is a longstanding problem due to the lack of\na good mathematical description. This motivates the usage of data-driven\nmethods in recent works. However, model-based and data-driven models often\nexhibit limitations in their ability to generalize beyond the specific dynamics\nthey were trained on, as we demonstrate in this paper. To address this\nchallenge, we introduce a novel approach based on residual learning, which aims\nto adapt an existing friction model to new dynamics using as little data as\npossible. We validate our approach by training a base neural network on a\nsymmetric friction data set to learn an accurate relation between the velocity\nand the friction torque. Subsequently, to adapt to more complex asymmetric\nsettings, we train a second network on a small dataset, focusing on predicting\nthe residual of the initial network's output. By combining the output of both\nnetworks in a suitable manner, our proposed estimator outperforms the\nconventional model-based approach and the base neural network significantly.\nFurthermore, we evaluate our method on trajectories involving external loads\nand still observe a substantial improvement, approximately 60-70\\%, over the\nconventional approach. Our method does not rely on data with external load\nduring training, eliminating the need for external torque sensors. This\ndemonstrates the generalization capability of our approach, even with a small\namount of data-only 43 seconds of a robot movement-enabling adaptation to\ndiverse scenarios based on prior knowledge about friction in different\nsettings.",
            "author": [
                "Philipp Scholl",
                "Maged Iskandar",
                "Sebastian Wolf",
                "Jinoh Lee",
                "Aras Bacho",
                "Alexander Dietrich",
                "Alin Albu-Sch\u00e4ffer",
                "Gitta Kutyniok"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16688v1",
                "http://arxiv.org/pdf/2310.16688v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16686v1",
            "title": "Dynamics Generalisation in Reinforcement Learning via Adaptive\n  Context-Aware Policies",
            "updated": "2023-10-25T14:50:05Z",
            "published": "2023-10-25T14:50:05Z",
            "summary": "While reinforcement learning has achieved remarkable successes in several\ndomains, its real-world application is limited due to many methods failing to\ngeneralise to unfamiliar conditions. In this work, we consider the problem of\ngeneralising to new transition dynamics, corresponding to cases in which the\nenvironment's response to the agent's actions differs. For example, the\ngravitational force exerted on a robot depends on its mass and changes the\nrobot's mobility. Consequently, in such cases, it is necessary to condition an\nagent's actions on extrinsic state information and pertinent contextual\ninformation reflecting how the environment responds. While the need for\ncontext-sensitive policies has been established, the manner in which context is\nincorporated architecturally has received less attention. Thus, in this work,\nwe present an investigation into how context information should be incorporated\ninto behaviour learning to improve generalisation. To this end, we introduce a\nneural network architecture, the Decision Adapter, which generates the weights\nof an adapter module and conditions the behaviour of an agent on the context\ninformation. We show that the Decision Adapter is a useful generalisation of a\npreviously proposed architecture and empirically demonstrate that it results in\nsuperior generalisation performance compared to previous approaches in several\nenvironments. Beyond this, the Decision Adapter is more robust to irrelevant\ndistractor variables than several alternative methods.",
            "author": [
                "Michael Beukman",
                "Devon Jarvis",
                "Richard Klein",
                "Steven James",
                "Benjamin Rosman"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16686v1",
                "http://arxiv.org/pdf/2310.16686v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16684v1",
            "title": "Local Statistics for Generative Image Detection",
            "updated": "2023-10-25T14:47:32Z",
            "published": "2023-10-25T14:47:32Z",
            "summary": "Diffusion models (DMs) are generative models that learn to synthesize images\nfrom Gaussian noise. DMs can be trained to do a variety of tasks such as image\ngeneration and image super-resolution. Researchers have made significant\nimprovement in the capability of synthesizing photorealistic images in the past\nfew years. These successes also hasten the need to address the potential misuse\nof synthesized images. In this paper, we highlight the effectiveness of\ncomputing local statistics, as opposed to global statistics, in distinguishing\ndigital camera images from DM-generated images. We hypothesized that local\nstatistics should be used to address the spatial non-stationarity problem in\nimages. We show that our approach produced promising results and it is also\nrobust to various perturbations such as image resizing and JPEG compression.",
            "author": [
                "Yung Jer Wong",
                "Teck Khim Ng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16684v1",
                "http://arxiv.org/pdf/2310.16684v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16681v1",
            "title": "BabyStories: Can Reinforcement Learning Teach Baby Language Models to\n  Write Better Stories?",
            "updated": "2023-10-25T14:45:48Z",
            "published": "2023-10-25T14:45:48Z",
            "summary": "Language models have seen significant growth in the size of their corpus,\nleading to notable performance improvements. Yet, there has been limited\nprogress in developing models that handle smaller, more human-like datasets. As\npart of the BabyLM shared task, this study explores the impact of reinforcement\nlearning from human feedback (RLHF) on language models pretrained from scratch\nwith a limited training corpus. Comparing two GPT-2 variants, the larger model\nperforms better in storytelling tasks after RLHF fine-tuning. These findings\nsuggest that RLHF techniques may be more advantageous for larger models due to\ntheir higher learning and adaptation capacity, though more experiments are\nneeded to confirm this finding. These insights highlight the potential benefits\nof RLHF fine-tuning for language models within limited data, enhancing their\nability to maintain narrative focus and coherence while adhering better to\ninitial instructions in storytelling tasks. The code for this work is publicly\nat https://github.com/Zephyr1022/BabyStories-UTSA.",
            "author": [
                "Xingmeng Zhao",
                "Tongnian Wang",
                "Sheri Osborn",
                "Anthony Rios"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16681v1",
                "http://arxiv.org/pdf/2310.16681v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16678v1",
            "title": "Robust and Actively Secure Serverless Collaborative Learning",
            "updated": "2023-10-25T14:43:03Z",
            "published": "2023-10-25T14:43:03Z",
            "summary": "Collaborative machine learning (ML) is widely used to enable institutions to\nlearn better models from distributed data. While collaborative approaches to\nlearning intuitively protect user data, they remain vulnerable to either the\nserver, the clients, or both, deviating from the protocol. Indeed, because the\nprotocol is asymmetric, a malicious server can abuse its power to reconstruct\nclient data points. Conversely, malicious clients can corrupt learning with\nmalicious updates. Thus, both clients and servers require a guarantee when the\nother cannot be trusted to fully cooperate. In this work, we propose a\npeer-to-peer (P2P) learning scheme that is secure against malicious servers and\nrobust to malicious clients. Our core contribution is a generic framework that\ntransforms any (compatible) algorithm for robust aggregation of model updates\nto the setting where servers and clients can act maliciously. Finally, we\ndemonstrate the computational efficiency of our approach even with 1-million\nparameter models trained by 100s of peers on standard datasets.",
            "author": [
                "Olive Franzese",
                "Adam Dziedzic",
                "Christopher A. Choquette-Choo",
                "Mark R. Thomas",
                "Muhammad Ahmad Kaleem",
                "Stephan Rabanser",
                "Congyu Fang",
                "Somesh Jha",
                "Nicolas Papernot",
                "Xiao Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16678v1",
                "http://arxiv.org/pdf/2310.16678v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16677v1",
            "title": "Machine Learning Approaches for Fine-Grained Symptom Estimation in\n  Schizophrenia: A Comprehensive Review",
            "updated": "2023-10-25T14:42:58Z",
            "published": "2023-10-25T14:42:58Z",
            "summary": "Schizophrenia is a severe yet treatable mental disorder, it is diagnosed\nusing a multitude of primary and secondary symptoms. Diagnosis and treatment\nfor each individual depends on the severity of the symptoms, therefore there is\na need for accurate, personalised assessments. However, the process can be both\ntime-consuming and subjective; hence, there is a motivation to explore\nautomated methods that can offer consistent diagnosis and precise symptom\nassessments, thereby complementing the work of healthcare practitioners.\nMachine Learning has demonstrated impressive capabilities across numerous\ndomains, including medicine; the use of Machine Learning in patient assessment\nholds great promise for healthcare professionals and patients alike, as it can\nlead to more consistent and accurate symptom estimation.This survey aims to\nreview methodologies that utilise Machine Learning for diagnosis and assessment\nof schizophrenia. Contrary to previous reviews that primarily focused on binary\nclassification, this work recognises the complexity of the condition and\ninstead, offers an overview of Machine Learning methods designed for\nfine-grained symptom estimation. We cover multiple modalities, namely Medical\nImaging, Electroencephalograms and Audio-Visual, as the illness symptoms can\nmanifest themselves both in a patient's pathology and behaviour. Finally, we\nanalyse the datasets and methodologies used in the studies and identify trends,\ngaps as well as opportunities for future research.",
            "author": [
                "Niki Maria Foteinopoulou",
                "Ioannis Patras"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16677v1",
                "http://arxiv.org/pdf/2310.16677v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16676v2",
            "title": "SSLCL: An Efficient Model-Agnostic Supervised Contrastive Learning\n  Framework for Emotion Recognition in Conversations",
            "updated": "2023-11-18T11:50:52Z",
            "published": "2023-10-25T14:41:14Z",
            "summary": "Emotion recognition in conversations (ERC) is a rapidly evolving task within\nthe natural language processing community, which aims to detect the emotions\nexpressed by speakers during a conversation. Recently, a growing number of ERC\nmethods have focused on leveraging supervised contrastive learning (SCL) to\nenhance the robustness and generalizability of learned features. However,\ncurrent SCL-based approaches in ERC are impeded by the constraint of large\nbatch sizes and the lack of compatibility with most existing ERC models. To\naddress these challenges, we propose an efficient and model-agnostic SCL\nframework named Supervised Sample-Label Contrastive Learning with Soft-HGR\nMaximal Correlation (SSLCL), which eliminates the need for a large batch size\nand can be seamlessly integrated with existing ERC models without introducing\nany model-specific assumptions. Specifically, we introduce a novel perspective\non utilizing label representations by projecting discrete labels into dense\nembeddings through a shallow multilayer perceptron, and formulate the training\nobjective to maximize the similarity between sample features and their\ncorresponding ground-truth label embeddings, while minimizing the similarity\nbetween sample features and label embeddings of disparate classes. Moreover, we\ninnovatively adopt the Soft-HGR maximal correlation as a measure of similarity\nbetween sample features and label embeddings, leading to significant\nperformance improvements over conventional similarity measures. Additionally,\nmultimodal cues of utterances are effectively leveraged by SSLCL as data\naugmentations to boost model performances. Extensive experiments on two ERC\nbenchmark datasets, IEMOCAP and MELD, demonstrate the compatibility and\nsuperiority of our proposed SSLCL framework compared to existing\nstate-of-the-art SCL methods. Our code is available at\n\\url{https://github.com/TaoShi1998/SSLCL}.",
            "author": [
                "Tao Shi",
                "Xiao Liang",
                "Yaoyuan Liang",
                "Xinyi Tong",
                "Shao-Lun Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16676v2",
                "http://arxiv.org/pdf/2310.16676v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16667v1",
            "title": "CoDet: Co-Occurrence Guided Region-Word Alignment for Open-Vocabulary\n  Object Detection",
            "updated": "2023-10-25T14:31:02Z",
            "published": "2023-10-25T14:31:02Z",
            "summary": "Deriving reliable region-word alignment from image-text pairs is critical to\nlearn object-level vision-language representations for open-vocabulary object\ndetection. Existing methods typically rely on pre-trained or self-trained\nvision-language models for alignment, which are prone to limitations in\nlocalization accuracy or generalization capabilities. In this paper, we propose\nCoDet, a novel approach that overcomes the reliance on pre-aligned\nvision-language space by reformulating region-word alignment as a co-occurring\nobject discovery problem. Intuitively, by grouping images that mention a shared\nconcept in their captions, objects corresponding to the shared concept shall\nexhibit high co-occurrence among the group. CoDet then leverages visual\nsimilarities to discover the co-occurring objects and align them with the\nshared concept. Extensive experiments demonstrate that CoDet has superior\nperformances and compelling scalability in open-vocabulary detection, e.g., by\nscaling up the visual backbone, CoDet achieves 37.0 $\\text{AP}^m_{novel}$ and\n44.7 $\\text{AP}^m_{all}$ on OV-LVIS, surpassing the previous SoTA by 4.2\n$\\text{AP}^m_{novel}$ and 9.8 $\\text{AP}^m_{all}$. Code is available at\nhttps://github.com/CVMI-Lab/CoDet.",
            "author": [
                "Chuofan Ma",
                "Yi Jiang",
                "Xin Wen",
                "Zehuan Yuan",
                "Xiaojuan Qi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16667v1",
                "http://arxiv.org/pdf/2310.16667v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16665v1",
            "title": "Robust Source-Free Domain Adaptation for Fundus Image Segmentation",
            "updated": "2023-10-25T14:25:18Z",
            "published": "2023-10-25T14:25:18Z",
            "summary": "Unsupervised Domain Adaptation (UDA) is a learning technique that transfers\nknowledge learned in the source domain from labelled training data to the\ntarget domain with only unlabelled data. It is of significant importance to\nmedical image segmentation because of the usual lack of labelled training data.\nAlthough extensive efforts have been made to optimize UDA techniques to improve\nthe accuracy of segmentation models in the target domain, few studies have\naddressed the robustness of these models under UDA. In this study, we propose a\ntwo-stage training strategy for robust domain adaptation. In the source\ntraining stage, we utilize adversarial sample augmentation to enhance the\nrobustness and generalization capability of the source model. And in the target\ntraining stage, we propose a novel robust pseudo-label and pseudo-boundary\n(PLPB) method, which effectively utilizes unlabeled target data to generate\npseudo labels and pseudo boundaries that enable model self-adaptation without\nrequiring source data. Extensive experimental results on cross-domain fundus\nimage segmentation confirm the effectiveness and versatility of our method.\nSource code of this study is openly accessible at\nhttps://github.com/LinGrayy/PLPB.",
            "author": [
                "Lingrui Li",
                "Yanfeng Zhou",
                "Ge Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16665v1",
                "http://arxiv.org/pdf/2310.16665v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16870v2",
            "title": "MACP: Efficient Model Adaptation for Cooperative Perception",
            "updated": "2023-11-07T05:42:48Z",
            "published": "2023-10-25T14:24:42Z",
            "summary": "Vehicle-to-vehicle (V2V) communications have greatly enhanced the perception\ncapabilities of connected and automated vehicles (CAVs) by enabling information\nsharing to \"see through the occlusions\", resulting in significant performance\nimprovements. However, developing and training complex multi-agent perception\nmodels from scratch can be expensive and unnecessary when existing single-agent\nmodels show remarkable generalization capabilities. In this paper, we propose a\nnew framework termed MACP, which equips a single-agent pre-trained model with\ncooperation capabilities. We approach this objective by identifying the key\nchallenges of shifting from single-agent to cooperative settings, adapting the\nmodel by freezing most of its parameters and adding a few lightweight modules.\nWe demonstrate in our experiments that the proposed framework can effectively\nutilize cooperative observations and outperform other state-of-the-art\napproaches in both simulated and real-world cooperative perception benchmarks\nwhile requiring substantially fewer tunable parameters with reduced\ncommunication costs. Our source code is available at\nhttps://github.com/PurdueDigitalTwin/MACP.",
            "author": [
                "Yunsheng Ma",
                "Juanwu Lu",
                "Can Cui",
                "Sicheng Zhao",
                "Xu Cao",
                "Wenqian Ye",
                "Ziran Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16870v2",
                "http://arxiv.org/pdf/2310.16870v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16662v1",
            "title": "Deep Learning Techniques for Cervical Cancer Diagnosis based on\n  Pathology and Colposcopy Images",
            "updated": "2023-10-25T14:23:40Z",
            "published": "2023-10-25T14:23:40Z",
            "summary": "Cervical cancer is a prevalent disease affecting millions of women worldwide\nevery year. It requires significant attention, as early detection during the\nprecancerous stage provides an opportunity for a cure. The screening and\ndiagnosis of cervical cancer rely on cytology and colposcopy methods. Deep\nlearning, a promising technology in computer vision, has emerged as a potential\nsolution to improve the accuracy and efficiency of cervical cancer screening\ncompared to traditional clinical inspection methods that are prone to human\nerror. This review article discusses cervical cancer and its screening\nprocesses, followed by the Deep Learning training process and the\nclassification, segmentation, and detection tasks for cervical cancer\ndiagnosis. Additionally, we explored the most common public datasets used in\nboth cytology and colposcopy and highlighted the popular and most utilized\narchitectures that researchers have applied to both cytology and colposcopy. We\nreviewed 24 selected practical papers in this study and summarized them. This\narticle highlights the remarkable efficiency in enhancing the precision and\nspeed of cervical cancer analysis by Deep Learning, bringing us closer to early\ndiagnosis and saving lives.",
            "author": [
                "Hana Ahmadzadeh Sarhangi",
                "Dorsa Beigifard",
                "Elahe Farmani",
                "Hamidreza Bolhasani"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16662v1",
                "http://arxiv.org/pdf/2310.16662v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16659v1",
            "title": "UAV Pathfinding in Dynamic Obstacle Avoidance with Multi-agent\n  Reinforcement Learning",
            "updated": "2023-10-25T14:21:22Z",
            "published": "2023-10-25T14:21:22Z",
            "summary": "Multi-agent reinforcement learning based methods are significant for online\nplanning of feasible and safe paths for agents in dynamic and uncertain\nscenarios. Although some methods like fully centralized and fully decentralized\nmethods achieve a certain measure of success, they also encounter problems such\nas dimension explosion and poor convergence, respectively. In this paper, we\npropose a novel centralized training with decentralized execution method based\non multi-agent reinforcement learning to solve the dynamic obstacle avoidance\nproblem online. In this approach, each agent communicates only with the central\nplanner or only with its neighbors, respectively, to plan feasible and safe\npaths online. We improve our methods based on the idea of model predictive\ncontrol to increase the training efficiency and sample utilization of agents.\nThe experimental results in both simulation, indoor, and outdoor environments\nvalidate the effectiveness of our method. The video is available at\nhttps://www.bilibili.com/video/BV1gw41197hV/?vd_source=9de61aecdd9fb684e546d032ef7fe7bf",
            "author": [
                "Qizhen Wu",
                "Lei Chen",
                "Kexin Liu",
                "Jinhu Lv"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16659v1",
                "http://arxiv.org/pdf/2310.16659v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16656v1",
            "title": "A Picture is Worth a Thousand Words: Principled Recaptioning Improves\n  Image Generation",
            "updated": "2023-10-25T14:10:08Z",
            "published": "2023-10-25T14:10:08Z",
            "summary": "Text-to-image diffusion models achieved a remarkable leap in capabilities\nover the last few years, enabling high-quality and diverse synthesis of images\nfrom a textual prompt. However, even the most advanced models often struggle to\nprecisely follow all of the directions in their prompts. The vast majority of\nthese models are trained on datasets consisting of (image, caption) pairs where\nthe images often come from the web, and the captions are their HTML alternate\ntext. A notable example is the LAION dataset, used by Stable Diffusion and\nother models. In this work we observe that these captions are often of low\nquality, and argue that this significantly affects the model's capability to\nunderstand nuanced semantics in the textual prompts. We show that by relabeling\nthe corpus with a specialized automatic captioning model and training a\ntext-to-image model on the recaptioned dataset, the model benefits\nsubstantially across the board. First, in overall image quality: e.g. FID 14.84\nvs. the baseline of 17.87, and 64.3% improvement in faithful image generation\naccording to human evaluation. Second, in semantic alignment, e.g. semantic\nobject accuracy 84.34 vs. 78.90, counting alignment errors 1.32 vs. 1.44 and\npositional alignment 62.42 vs. 57.60. We analyze various ways to relabel the\ncorpus and provide evidence that this technique, which we call RECAP, both\nreduces the train-inference discrepancy and provides the model with more\ninformation per example, increasing sample efficiency and allowing the model to\nbetter understand the relations between captions and images.",
            "author": [
                "Eyal Segalis",
                "Dani Valevski",
                "Danny Lumen",
                "Yossi Matias",
                "Yaniv Leviathan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16656v1",
                "http://arxiv.org/pdf/2310.16656v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16655v2",
            "title": "Towards Control-Centric Representations in Reinforcement Learning from\n  Images",
            "updated": "2023-10-27T10:14:16Z",
            "published": "2023-10-25T14:09:53Z",
            "summary": "Image-based Reinforcement Learning is a practical yet challenging task. A\nmajor hurdle lies in extracting control-centric representations while\ndisregarding irrelevant information. While approaches that follow the\nbisimulation principle exhibit the potential in learning state representations\nto address this issue, they still grapple with the limited expressive capacity\nof latent dynamics and the inadaptability to sparse reward environments. To\naddress these limitations, we introduce ReBis, which aims to capture\ncontrol-centric information by integrating reward-free control information\nalongside reward-specific knowledge. ReBis utilizes a transformer architecture\nto implicitly model the dynamics and incorporates block-wise masking to\neliminate spatiotemporal redundancy. Moreover, ReBis combines\nbisimulation-based loss with asymmetric reconstruction loss to prevent feature\ncollapse in environments with sparse rewards. Empirical studies on two large\nbenchmarks, including Atari games and DeepMind Control Suit, demonstrate that\nReBis has superior performance compared to existing methods, proving its\neffectiveness.",
            "author": [
                "Chen Liu",
                "Hongyu Zang",
                "Xin Li",
                "Yong Heng",
                "Yifei Wang",
                "Zhen Fang",
                "Yisen Wang",
                "Mingzhong Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16655v2",
                "http://arxiv.org/pdf/2310.16655v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16653v1",
            "title": "Adaptive importance sampling for heavy-tailed distributions via\n  $\u03b1$-divergence minimization",
            "updated": "2023-10-25T14:07:08Z",
            "published": "2023-10-25T14:07:08Z",
            "summary": "Adaptive importance sampling (AIS) algorithms are widely used to approximate\nexpectations with respect to complicated target probability distributions. When\nthe target has heavy tails, existing AIS algorithms can provide inconsistent\nestimators or exhibit slow convergence, as they often neglect the target's tail\nbehaviour. To avoid this pitfall, we propose an AIS algorithm that approximates\nthe target by Student-t proposal distributions. We adapt location and scale\nparameters by matching the escort moments - which are defined even for\nheavy-tailed distributions - of the target and the proposal. These updates\nminimize the $\\alpha$-divergence between the target and the proposal, thereby\nconnecting with variational inference. We then show that the\n$\\alpha$-divergence can be approximated by a generalized notion of effective\nsample size and leverage this new perspective to adapt the tail parameter with\nBayesian optimization. We demonstrate the efficacy of our approach through\napplications to synthetic targets and a Bayesian Student-t regression task on a\nreal example with clinical trial data.",
            "author": [
                "Thomas Guilmeau",
                "Nicola Branchini",
                "Emilie Chouzenoux",
                "V\u00edctor Elvira"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16653v1",
                "http://arxiv.org/pdf/2310.16653v1"
            ],
            "primary_category": "stat.CO",
            "category": [
                "stat.CO",
                "stat.ME",
                "stat.ML",
                "62-08"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16652v1",
            "title": "How Robust is Federated Learning to Communication Error? A Comparison\n  Study Between Uplink and Downlink Channels",
            "updated": "2023-10-25T14:03:11Z",
            "published": "2023-10-25T14:03:11Z",
            "summary": "Because of its privacy-preserving capability, federated learning (FL) has\nattracted significant attention from both academia and industry. However, when\nbeing implemented over wireless networks, it is not clear how much\ncommunication error can be tolerated by FL. This paper investigates the\nrobustness of FL to the uplink and downlink communication error. Our\ntheoretical analysis reveals that the robustness depends on two critical\nparameters, namely the number of clients and the numerical range of model\nparameters. It is also shown that the uplink communication in FL can tolerate a\nhigher bit error rate (BER) than downlink communication, and this difference is\nquantified by a proposed formula. The findings and theoretical analyses are\nfurther validated by extensive experiments.",
            "author": [
                "Linping Qu",
                "Shenghui Song",
                "Chi-Ying Tsui",
                "Yuyi Mao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16652v1",
                "http://arxiv.org/pdf/2310.16652v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16648v1",
            "title": "Posterior Consistency for Missing Data in Variational Autoencoders",
            "updated": "2023-10-25T13:56:02Z",
            "published": "2023-10-25T13:56:02Z",
            "summary": "We consider the problem of learning Variational Autoencoders (VAEs), i.e., a\ntype of deep generative model, from data with missing values. Such data is\nomnipresent in real-world applications of machine learning because complete\ndata is often impossible or too costly to obtain. We particularly focus on\nimproving a VAE's amortized posterior inference, i.e., the encoder, which in\nthe case of missing data can be susceptible to learning inconsistent posterior\ndistributions regarding the missingness. To this end, we provide a formal\ndefinition of posterior consistency and propose an approach for regularizing an\nencoder's posterior distribution which promotes this consistency. We observe\nthat the proposed regularization suggests a different training objective than\nthat typically considered in the literature when facing missing values.\nFurthermore, we empirically demonstrate that our regularization leads to\nimproved performance in missing value settings in terms of reconstruction\nquality and downstream tasks utilizing uncertainty in the latent space. This\nimproved performance can be observed for many classes of VAEs including VAEs\nequipped with normalizing flows.",
            "author": [
                "Timur Sudak",
                "Sebastian Tschiatschek"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16648v1",
                "http://arxiv.org/pdf/2310.16648v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16647v1",
            "title": "Achieving Constraints in Neural Networks: A Stochastic Augmented\n  Lagrangian Approach",
            "updated": "2023-10-25T13:55:35Z",
            "published": "2023-10-25T13:55:35Z",
            "summary": "Regularizing Deep Neural Networks (DNNs) is essential for improving\ngeneralizability and preventing overfitting. Fixed penalty methods, though\ncommon, lack adaptability and suffer from hyperparameter sensitivity. In this\npaper, we propose a novel approach to DNN regularization by framing the\ntraining process as a constrained optimization problem. Where the data fidelity\nterm is the minimization objective and the regularization terms serve as\nconstraints. Then, we employ the Stochastic Augmented Lagrangian (SAL) method\nto achieve a more flexible and efficient regularization mechanism. Our approach\nextends beyond black-box regularization, demonstrating significant improvements\nin white-box models, where weights are often subject to hard constraints to\nensure interpretability. Experimental results on image-based classification on\nMNIST, CIFAR10, and CIFAR100 datasets validate the effectiveness of our\napproach. SAL consistently achieves higher Accuracy while also achieving better\nconstraint satisfaction, thus showcasing its potential for optimizing DNNs\nunder constrained settings.",
            "author": [
                "Diogo Lavado",
                "Cl\u00e1udia Soares",
                "Alessandra Micheletti"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16647v1",
                "http://arxiv.org/pdf/2310.16647v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16646v1",
            "title": "Model predictive control-based value estimation for efficient\n  reinforcement learning",
            "updated": "2023-10-25T13:55:14Z",
            "published": "2023-10-25T13:55:14Z",
            "summary": "Reinforcement learning suffers from limitations in real practices primarily\ndue to the numbers of required interactions with virtual environments. It\nresults in a challenging problem that we are implausible to obtain an optimal\nstrategy only with a few attempts for many learning method. Hereby, we design\nan improved reinforcement learning method based on model predictive control\nthat models the environment through a data-driven approach. Based on learned\nenvironmental model, it performs multi-step prediction to estimate the value\nfunction and optimize the policy. The method demonstrates higher learning\nefficiency, faster convergent speed of strategies tending to the optimal value,\nand fewer sample capacity space required by experience replay buffers.\nExperimental results, both in classic databases and in a dynamic obstacle\navoidance scenario for unmanned aerial vehicle, validate the proposed\napproaches.",
            "author": [
                "Qizhen Wu",
                "Kexin Liu",
                "Lei Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16646v1",
                "http://arxiv.org/pdf/2310.16646v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16640v1",
            "title": "EmoCLIP: A Vision-Language Method for Zero-Shot Video Facial Expression\n  Recognition",
            "updated": "2023-10-25T13:43:36Z",
            "published": "2023-10-25T13:43:36Z",
            "summary": "Facial Expression Recognition (FER) is a crucial task in affective computing,\nbut its conventional focus on the seven basic emotions limits its applicability\nto the complex and expanding emotional spectrum. To address the issue of new\nand unseen emotions present in dynamic in-the-wild FER, we propose a novel\nvision-language model that utilises sample-level text descriptions (i.e.\ncaptions of the context, expressions or emotional cues) as natural language\nsupervision, aiming to enhance the learning of rich latent representations, for\nzero-shot classification. To test this, we evaluate using zero-shot\nclassification of the model trained on sample-level descriptions on four\npopular dynamic FER datasets. Our findings show that this approach yields\nsignificant improvements when compared to baseline methods. Specifically, for\nzero-shot video FER, we outperform CLIP by over 10\\% in terms of Weighted\nAverage Recall and 5\\% in terms of Unweighted Average Recall on several\ndatasets. Furthermore, we evaluate the representations obtained from the\nnetwork trained using sample-level descriptions on the downstream task of\nmental health symptom estimation, achieving performance comparable or superior\nto state-of-the-art methods and strong agreement with human experts. Namely, we\nachieve a Pearson's Correlation Coefficient of up to 0.85 on schizophrenia\nsymptom severity estimation, which is comparable to human experts' agreement.\nThe code is publicly available at: https://github.com/NickyFot/EmoCLIP.",
            "author": [
                "Niki Maria Foteinopoulou",
                "Ioannis Patras"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16640v1",
                "http://arxiv.org/pdf/2310.16640v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16639v2",
            "title": "Driving through the Concept Gridlock: Unraveling Explainability\n  Bottlenecks in Automated Driving",
            "updated": "2023-10-26T15:15:39Z",
            "published": "2023-10-25T13:39:04Z",
            "summary": "Concept bottleneck models have been successfully used for explainable machine\nlearning by encoding information within the model with a set of human-defined\nconcepts. In the context of human-assisted or autonomous driving,\nexplainability models can help user acceptance and understanding of decisions\nmade by the autonomous vehicle, which can be used to rationalize and explain\ndriver or vehicle behavior. We propose a new approach using concept bottlenecks\nas visual features for control command predictions and explanations of user and\nvehicle behavior. We learn a human-understandable concept layer that we use to\nexplain sequential driving scenes while learning vehicle control commands. This\napproach can then be used to determine whether a change in a preferred gap or\nsteering commands from a human (or autonomous vehicle) is led by an external\nstimulus or change in preferences. We achieve competitive performance to latent\nvisual features while gaining interpretability within our model setup.",
            "author": [
                "Jessica Echterhoff",
                "An Yan",
                "Kyungtae Han",
                "Amr Abdelraouf",
                "Rohit Gupta",
                "Julian McAuley"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16639v2",
                "http://arxiv.org/pdf/2310.16639v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16638v2",
            "title": "Robust Covariate Shift Adaptation for Density-Ratio Estimation",
            "updated": "2023-10-26T02:53:20Z",
            "published": "2023-10-25T13:38:29Z",
            "summary": "Consider a scenario where we have access to train data with both covariates\nand outcomes while test data only contains covariates. In this scenario, our\nprimary aim is to predict the missing outcomes of the test data. With this\nobjective in mind, we train parametric regression models under a covariate\nshift, where covariate distributions are different between the train and test\ndata. For this problem, existing studies have proposed covariate shift\nadaptation via importance weighting using the density ratio. This approach\naverages the train data losses, each weighted by an estimated ratio of the\ncovariate densities between the train and test data, to approximate the\ntest-data risk. Although it allows us to obtain a test-data risk minimizer, its\nperformance heavily relies on the accuracy of the density ratio estimation.\nMoreover, even if the density ratio can be consistently estimated, the\nestimation errors of the density ratio also yield bias in the estimators of the\nregression model's parameters of interest. To mitigate these challenges, we\nintroduce a doubly robust estimator for covariate shift adaptation via\nimportance weighting, which incorporates an additional estimator for the\nregression function. Leveraging double machine learning techniques, our\nestimator reduces the bias arising from the density ratio estimation errors. We\ndemonstrate the asymptotic distribution of the regression parameter estimator.\nNotably, our estimator remains consistent if either the density ratio estimator\nor the regression function is consistent, showcasing its robustness against\npotential errors in density ratio estimation. Finally, we confirm the soundness\nof our proposed method via simulation studies.",
            "author": [
                "Masahiro Kato"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16638v2",
                "http://arxiv.org/pdf/2310.16638v2"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "cs.LG",
                "econ.EM",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16869v2",
            "title": "Single-pixel imaging based on deep learning",
            "updated": "2023-11-17T03:33:15Z",
            "published": "2023-10-25T13:35:25Z",
            "summary": "Single-pixel imaging can collect images at the wavelengths outside the reach\nof conventional focal plane array detectors. However, the limited image quality\nand lengthy computational times for iterative reconstruction still impede the\npractical application of single-pixel imaging. Recently, deep learning has been\nintroduced into single-pixel imaging, which has attracted a lot of attention\ndue to its exceptional reconstruction quality, fast reconstruction speed, and\nthe potential to complete advanced sensing tasks without reconstructing images.\nHere, this advance is discussed and some opinions are offered. Firstly, based\non the fundamental principles of single-pixel imaging and deep learning, the\nprinciples and algorithms of single-pixel imaging based on deep learning are\ndescribed and analyzed. Subsequently, the implementation technologies of\nsingle-pixel imaging based on deep learning are reviewed. They are divided into\nsuper-resolution single-pixel imaging, single-pixel imaging through scattering\nmedia, photon-level single-pixel imaging, optical encryption based on\nsingle-pixel imaging, color single-pixel imaging, and image-free sensing\naccording to diverse application fields. Finally, major challenges and\ncorresponding feasible approaches are discussed, as well as more possible\napplications in the future.",
            "author": [
                "Kai Song",
                "Yaoxing Bian",
                "Ku Wu",
                "Hongrui Liu",
                "Shuangping Han",
                "Jiaming Li",
                "Jiazhao Tian",
                "Chengbin Qin",
                "Jianyong Hu",
                "Liantuan Xiao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16869v2",
                "http://arxiv.org/pdf/2310.16869v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16633v1",
            "title": "Photometric Redshifts with Copula Entropy",
            "updated": "2023-10-25T13:33:40Z",
            "published": "2023-10-25T13:33:40Z",
            "summary": "In this paper we propose to apply copula entropy (CE) to photometric\nredshifts. CE is used to measure the correlations between photometric\nmeasurements and redshifts and then the measurements associated with high CEs\nare selected for predicting redshifts. We verified the proposed method on the\nSDSS quasar data. Experimental results show that the accuracy of photometric\nredshifts is improved with the selected measurements compared to the results\nwith all the measurements used in the experiments, especially for the samples\nwith high redshifts. The measurements selected with CE include luminosity\nmagnitude, the brightness in ultraviolet band with standard deviation, and the\nbrightness of the other four bands. Since CE is a rigorously defined\nmathematical concept, the models such derived is interpretable.",
            "author": [
                "Jian Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16633v1",
                "http://arxiv.org/pdf/2310.16633v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "astro-ph.CO",
                "astro-ph.IM",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16626v1",
            "title": "Scalable Causal Structure Learning via Amortized Conditional\n  Independence Testing",
            "updated": "2023-10-25T13:23:40Z",
            "published": "2023-10-25T13:23:40Z",
            "summary": "Controlling false positives (Type I errors) through statistical hypothesis\ntesting is a foundation of modern scientific data analysis. Existing causal\nstructure discovery algorithms either do not provide Type I error control or\ncannot scale to the size of modern scientific datasets. We consider a variant\nof the causal discovery problem with two sets of nodes, where the only edges of\ninterest form a bipartite causal subgraph between the sets. We develop Scalable\nCausal Structure Learning (SCSL), a method for causal structure discovery on\nbipartite subgraphs that provides Type I error control. SCSL recasts the\ndiscovery problem as a simultaneous hypothesis testing problem and uses\ndiscrete optimization over the set of possible confounders to obtain an upper\nbound on the test statistic for each edge. Semi-synthetic simulations\ndemonstrate that SCSL scales to handle graphs with hundreds of nodes while\nmaintaining error control and good power. We demonstrate the practical\napplicability of the method by applying it to a cancer dataset to reveal\nconnections between somatic gene mutations and metastases to different tissues.",
            "author": [
                "James Leiner",
                "Brian Manzo",
                "Aaditya Ramdas",
                "Wesley Tansey"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16626v1",
                "http://arxiv.org/pdf/2310.16626v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16624v1",
            "title": "Free-form Flows: Make Any Architecture a Normalizing Flow",
            "updated": "2023-10-25T13:23:08Z",
            "published": "2023-10-25T13:23:08Z",
            "summary": "Normalizing Flows are generative models that directly maximize the\nlikelihood. Previously, the design of normalizing flows was largely constrained\nby the need for analytical invertibility. We overcome this constraint by a\ntraining procedure that uses an efficient estimator for the gradient of the\nchange of variables formula. This enables any dimension-preserving neural\nnetwork to serve as a generative model through maximum likelihood training. Our\napproach allows placing the emphasis on tailoring inductive biases precisely to\nthe task at hand. Specifically, we achieve excellent results in molecule\ngeneration benchmarks utilizing $E(n)$-equivariant networks. Moreover, our\nmethod is competitive in an inverse problem benchmark, while employing\noff-the-shelf ResNet architectures.",
            "author": [
                "Felix Draxler",
                "Peter Sorrenson",
                "Lea Zimmermann",
                "Armand Rousselot",
                "Ullrich K\u00f6the"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16624v1",
                "http://arxiv.org/pdf/2310.16624v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16620v1",
            "title": "SpikingJelly: An open-source machine learning infrastructure platform\n  for spike-based intelligence",
            "updated": "2023-10-25T13:15:17Z",
            "published": "2023-10-25T13:15:17Z",
            "summary": "Spiking neural networks (SNNs) aim to realize brain-inspired intelligence on\nneuromorphic chips with high energy efficiency by introducing neural dynamics\nand spike properties. As the emerging spiking deep learning paradigm attracts\nincreasing interest, traditional programming frameworks cannot meet the demands\nof the automatic differentiation, parallel computation acceleration, and high\nintegration of processing neuromorphic datasets and deployment. In this work,\nwe present the SpikingJelly framework to address the aforementioned dilemma. We\ncontribute a full-stack toolkit for pre-processing neuromorphic datasets,\nbuilding deep SNNs, optimizing their parameters, and deploying SNNs on\nneuromorphic chips. Compared to existing methods, the training of deep SNNs can\nbe accelerated $11\\times$, and the superior extensibility and flexibility of\nSpikingJelly enable users to accelerate custom models at low costs through\nmultilevel inheritance and semiautomatic code generation. SpikingJelly paves\nthe way for synthesizing truly energy-efficient SNN-based machine intelligence\nsystems, which will enrich the ecology of neuromorphic computing.",
            "author": [
                "Wei Fang",
                "Yanqi Chen",
                "Jianhao Ding",
                "Zhaofei Yu",
                "Timoth\u00e9e Masquelier",
                "Ding Chen",
                "Liwei Huang",
                "Huihui Zhou",
                "Guoqi Li",
                "Yonghong Tian"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16620v1",
                "http://arxiv.org/pdf/2310.16620v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.LG",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16616v1",
            "title": "Context Does Matter: End-to-end Panoptic Narrative Grounding with\n  Deformable Attention Refined Matching Network",
            "updated": "2023-10-25T13:12:39Z",
            "published": "2023-10-25T13:12:39Z",
            "summary": "Panoramic Narrative Grounding (PNG) is an emerging visual grounding task that\naims to segment visual objects in images based on dense narrative captions. The\ncurrent state-of-the-art methods first refine the representation of phrase by\naggregating the most similar $k$ image pixels, and then match the refined text\nrepresentations with the pixels of the image feature map to generate\nsegmentation results. However, simply aggregating sampled image features\nignores the contextual information, which can lead to phrase-to-pixel\nmis-match. In this paper, we propose a novel learning framework called\nDeformable Attention Refined Matching Network (DRMN), whose main idea is to\nbring deformable attention in the iterative process of feature learning to\nincorporate essential context information of different scales of pixels. DRMN\niteratively re-encodes pixels with the deformable attention network after\nupdating the feature representation of the top-$k$ most similar pixels. As\nsuch, DRMN can lead to accurate yet discriminative pixel representations,\npurify the top-$k$ most similar pixels, and consequently alleviate the\nphrase-to-pixel mis-match substantially.Experimental results show that our\nnovel design significantly improves the matching results between text phrases\nand image pixels. Concretely, DRMN achieves new state-of-the-art performance on\nthe PNG benchmark with an average recall improvement 3.5%. The codes are\navailable in: https://github.com/JaMesLiMers/DRMN.",
            "author": [
                "Yiming Lin",
                "Xiao-Bo Jin",
                "Qiufeng Wang",
                "Kaizhu Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16616v1",
                "http://arxiv.org/pdf/2310.16616v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16608v1",
            "title": "Performative Prediction: Past and Future",
            "updated": "2023-10-25T13:02:45Z",
            "published": "2023-10-25T13:02:45Z",
            "summary": "Predictions in the social world generally influence the target of prediction,\na phenomenon known as performativity. Self-fulfilling and self-negating\npredictions are examples of performativity. Of fundamental importance to\neconomics, finance, and the social sciences, the notion has been absent from\nthe development of machine learning. In machine learning applications,\nperformativity often surfaces as distribution shift. A predictive model\ndeployed on a digital platform, for example, influences consumption and thereby\nchanges the data-generating distribution. We survey the recently founded area\nof performative prediction that provides a definition and conceptual framework\nto study performativity in machine learning. A consequence of performative\nprediction is a natural equilibrium notion that gives rise to new optimization\nchallenges. Another consequence is a distinction between learning and steering,\ntwo mechanisms at play in performative prediction. The notion of steering is in\nturn intimately related to questions of power in digital markets. We review the\nnotion of performative power that gives an answer to the question how much a\nplatform can steer participants through its predictions. We end on a discussion\nof future directions, such as the role that performativity plays in contesting\nalgorithmic systems.",
            "author": [
                "Moritz Hardt",
                "Celestine Mendler-D\u00fcnner"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16608v1",
                "http://arxiv.org/pdf/2310.16608v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16867v1",
            "title": "An Explainable Deep Learning-Based Method For Schizophrenia Diagnosis\n  Using Generative Data-Augmentation",
            "updated": "2023-10-25T12:55:16Z",
            "published": "2023-10-25T12:55:16Z",
            "summary": "In this study, we leverage a deep learning-based method for the automatic\ndiagnosis of schizophrenia using EEG brain recordings. This approach utilizes\ngenerative data augmentation, a powerful technique that enhances the accuracy\nof the diagnosis. To enable the utilization of time-frequency features,\nspectrograms were extracted from the raw signals. After exploring several\nneural network architectural setups, a proper convolutional neural network\n(CNN) was used for the initial diagnosis. Subsequently, using Wasserstein GAN\nwith Gradient Penalty (WGAN-GP) and Variational Autoencoder (VAE), two\ndifferent synthetic datasets were generated in order to augment the initial\ndataset and address the over-fitting issue. The augmented dataset using VAE\nachieved a 3.0\\% improvement in accuracy reaching up to 99.0\\% and yielded a\nlower loss value as well as a faster convergence. Finally, we addressed the\nlack of trust in black-box models using the Local Interpretable Model-agnostic\nExplanations (LIME) algorithm to determine the most important superpixels\n(frequencies) in the diagnosis process.",
            "author": [
                "Mehrshad Saadatinia",
                "Armin Salimi-Badr"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16867v1",
                "http://arxiv.org/pdf/2310.16867v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16606v2",
            "title": "AirFL-Mem: Improving Communication-Learning Trade-Off by Long-Term\n  Memory",
            "updated": "2023-10-28T02:44:22Z",
            "published": "2023-10-25T12:51:38Z",
            "summary": "Addressing the communication bottleneck inherent in federated learning (FL),\nover-the-air FL (AirFL) has emerged as a promising solution, which is, however,\nhampered by deep fading conditions. In this paper, we propose AirFL-Mem, a\nnovel scheme designed to mitigate the impact of deep fading by implementing a\n\\emph{long-term} memory mechanism. Convergence bounds are provided that account\nfor long-term memory, as well as for existing AirFL variants with short-term\nmemory, for general non-convex objectives. The theory demonstrates that\nAirFL-Mem exhibits the same convergence rate of federated averaging (FedAvg)\nwith ideal communication, while the performance of existing schemes is\ngenerally limited by error floors. The theoretical results are also leveraged\nto propose a novel convex optimization strategy for the truncation threshold\nused for power control in the presence of Rayleigh fading channels.\nExperimental results validate the analysis, confirming the advantages of a\nlong-term memory mechanism for the mitigation of deep fading.",
            "author": [
                "Haifeng Wen",
                "Hong Xing",
                "Osvaldo Simeone"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16606v2",
                "http://arxiv.org/pdf/2310.16606v2"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.LG",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16602v1",
            "title": "Parcel loss prediction in last-mile delivery: deep and non-deep\n  approaches with insights from Explainable AI",
            "updated": "2023-10-25T12:46:34Z",
            "published": "2023-10-25T12:46:34Z",
            "summary": "Within the domain of e-commerce retail, an important objective is the\nreduction of parcel loss during the last-mile delivery phase. The\never-increasing availability of data, including product, customer, and order\ninformation, has made it possible for the application of machine learning in\nparcel loss prediction. However, a significant challenge arises from the\ninherent imbalance in the data, i.e., only a very low percentage of parcels are\nlost. In this paper, we propose two machine learning approaches, namely, Data\nBalance with Supervised Learning (DBSL) and Deep Hybrid Ensemble Learning\n(DHEL), to accurately predict parcel loss. The practical implication of such\npredictions is their value in aiding e-commerce retailers in optimizing\ninsurance-related decision-making policies. We conduct a comprehensive\nevaluation of the proposed machine learning models using one year data from\nBelgian shipments. The findings show that the DHEL model, which combines a\nfeed-forward autoencoder with a random forest, achieves the highest\nclassification performance. Furthermore, we use the techniques from Explainable\nAI (XAI) to illustrate how prediction models can be used in enhancing business\nprocesses and augmenting the overall value proposition for e-commerce retailers\nin the last mile delivery.",
            "author": [
                "Jan de Leeuw",
                "Zaharah Bukhsh",
                "Yingqian Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16602v1",
                "http://arxiv.org/pdf/2310.16602v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16600v2",
            "title": "Balancing central and marginal rejection when combining independent\n  significance tests",
            "updated": "2023-11-13T20:22:03Z",
            "published": "2023-10-25T12:45:49Z",
            "summary": "A common approach to evaluating the significance of a collection of\n$p$-values combines them with a pooling function, in particular when the\noriginal data are not available. These pooled $p$-values convert a sample of\n$p$-values into a single number which behaves like a univariate $p$-value. To\nclarify discussion of these functions, a telescoping series of alternative\nhypotheses are introduced that communicate the strength and prevalence of\nnon-null evidence in the $p$-values before general pooling formulae are\ndiscussed. A pattern noticed in the UMP pooled $p$-value for a particular\nalternative motivates the definition and discussion of central and marginal\nrejection levels at $\\alpha$. It is proven that central rejection is always\ngreater than or equal to marginal rejection, motivating a quotient to measure\nthe balance between the two for pooled $p$-values. A combining function based\non the $\\chi^2_{\\kappa}$ quantile transformation is proposed to control this\nquotient and shown to be robust to mis-specified parameters relative to the\nUMP. Different powers for different parameter settings motivate a map of\nplausible alternatives based on where this pooled $p$-value is minimized.",
            "author": [
                "Chris Salahub",
                "Wayne Oldford"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16600v2",
                "http://arxiv.org/pdf/2310.16600v2"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "cs.AI",
                "cs.LG",
                "62-02",
                "G.3; I.2.m; J.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16597v2",
            "title": "Beyond IID weights: sparse and low-rank deep Neural Networks are also\n  Gaussian Processes",
            "updated": "2023-11-19T18:30:35Z",
            "published": "2023-10-25T12:38:36Z",
            "summary": "The infinitely wide neural network has been proven a useful and manageable\nmathematical model that enables the understanding of many phenomena appearing\nin deep learning. One example is the convergence of random deep networks to\nGaussian processes that allows a rigorous analysis of the way the choice of\nactivation function and network weights impacts the training dynamics. In this\npaper, we extend the seminal proof of Matthews et al. (2018) to a larger class\nof initial weight distributions (which we call PSEUDO-IID), including the\nestablished cases of IID and orthogonal weights, as well as the emerging\nlow-rank and structured sparse settings celebrated for their computational\nspeed-up benefits. We show that fully-connected and convolutional networks\ninitialized with PSEUDO-IID distributions are all effectively equivalent up to\ntheir variance. Using our results, one can identify the Edge-of-Chaos for a\nbroader class of neural networks and tune them at criticality in order to\nenhance their training.",
            "author": [
                "Thiziri Nait-Saada",
                "Alireza Naderi",
                "Jared Tanner"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16597v2",
                "http://arxiv.org/pdf/2310.16597v2"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16592v1",
            "title": "Over-the-air Federated Policy Gradient",
            "updated": "2023-10-25T12:28:20Z",
            "published": "2023-10-25T12:28:20Z",
            "summary": "In recent years, over-the-air aggregation has been widely considered in\nlarge-scale distributed learning, optimization, and sensing. In this paper, we\npropose the over-the-air federated policy gradient algorithm, where all agents\nsimultaneously broadcast an analog signal carrying local information to a\ncommon wireless channel, and a central controller uses the received aggregated\nwaveform to update the policy parameters. We investigate the effect of noise\nand channel distortion on the convergence of the proposed algorithm, and\nestablish the complexities of communication and sampling for finding an\n$\\epsilon$-approximate stationary point. Finally, we present some simulation\nresults to show the effectiveness of the algorithm.",
            "author": [
                "Huiwen Yang",
                "Lingying Huang",
                "Subhrakanti Dey",
                "Ling Shi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16592v1",
                "http://arxiv.org/pdf/2310.16592v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16588v1",
            "title": "Multi-parallel-task Time-delay Reservoir Computing combining a Silicon\n  Microring with WDM",
            "updated": "2023-10-25T12:24:56Z",
            "published": "2023-10-25T12:24:56Z",
            "summary": "We numerically demonstrate a microring-based time-delay reservoir computing\nscheme that simultaneously solves three tasks involving time-series prediction,\nclassification, and wireless channel equalization. Each task performed on a\nwavelength-multiplexed channel achieves state-of-the-art performance with\noptimized power and frequency detuning.",
            "author": [
                "Bernard J. Giron Castro",
                "Christophe Peucheret",
                "Darko Zibar",
                "Francesco Da Ros"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16588v1",
                "http://arxiv.org/pdf/2310.16588v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.ET",
                "cs.LG",
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16587v1",
            "title": "Adaptive Uncertainty Estimation via High-Dimensional Testing on Latent\n  Representations",
            "updated": "2023-10-25T12:22:18Z",
            "published": "2023-10-25T12:22:18Z",
            "summary": "Uncertainty estimation aims to evaluate the confidence of a trained deep\nneural network. However, existing uncertainty estimation approaches rely on\nlow-dimensional distributional assumptions and thus suffer from the high\ndimensionality of latent features. Existing approaches tend to focus on\nuncertainty on discrete classification probabilities, which leads to poor\ngeneralizability to uncertainty estimation for other tasks. Moreover, most of\nthe literature requires seeing the out-of-distribution (OOD) data in the\ntraining for better estimation of uncertainty, which limits the uncertainty\nestimation performance in practice because the OOD data are typically unseen.\nTo overcome these limitations, we propose a new framework using data-adaptive\nhigh-dimensional hypothesis testing for uncertainty estimation, which leverages\nthe statistical properties of the feature representations. Our method directly\noperates on latent representations and thus does not require retraining the\nfeature encoder under a modified objective. The test statistic relaxes the\nfeature distribution assumptions to high dimensionality, and it is more\ndiscriminative to uncertainties in the latent representations. We demonstrate\nthat encoding features with Bayesian neural networks can enhance testing\nperformance and lead to more accurate uncertainty estimation. We further\nintroduce a family-wise testing procedure to determine the optimal threshold of\nOOD detection, which minimizes the false discovery rate (FDR). Extensive\nexperiments validate the satisfactory performance of our framework on\nuncertainty estimation and task-specific prediction over a variety of\ncompetitors. The experiments on the OOD detection task also show satisfactory\nperformance of our method when the OOD data are unseen in the training. Codes\nare available at https://github.com/HKU-MedAI/bnn_uncertainty.",
            "author": [
                "Tsai Hor Chan",
                "Kin Wai Lau",
                "Jiajun Shen",
                "Guosheng Yin",
                "Lequan Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16587v1",
                "http://arxiv.org/pdf/2310.16587v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16584v1",
            "title": "Learning to Explain: A Model-Agnostic Framework for Explaining Black Box\n  Models",
            "updated": "2023-10-25T12:18:00Z",
            "published": "2023-10-25T12:18:00Z",
            "summary": "We present Learning to Explain (LTX), a model-agnostic framework designed for\nproviding post-hoc explanations for vision models. The LTX framework introduces\nan \"explainer\" model that generates explanation maps, highlighting the crucial\nregions that justify the predictions made by the model being explained. To\ntrain the explainer, we employ a two-stage process consisting of initial\npretraining followed by per-instance finetuning. During both stages of\ntraining, we utilize a unique configuration where we compare the explained\nmodel's prediction for a masked input with its original prediction for the\nunmasked input. This approach enables the use of a novel counterfactual\nobjective, which aims to anticipate the model's output using masked versions of\nthe input image. Importantly, the LTX framework is not restricted to a specific\nmodel architecture and can provide explanations for both Transformer-based and\nconvolutional models. Through our evaluations, we demonstrate that LTX\nsignificantly outperforms the current state-of-the-art in explainability across\nvarious metrics.",
            "author": [
                "Oren Barkan",
                "Yuval Asher",
                "Amit Eshel",
                "Yehonatan Elisha",
                "Noam Koenigstein"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16584v1",
                "http://arxiv.org/pdf/2310.16584v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16581v1",
            "title": "Hybrid Minimax-MCTS and Difficulty Adjustment for General Game Playing",
            "updated": "2023-10-25T12:13:40Z",
            "published": "2023-10-25T12:13:40Z",
            "summary": "Board games are a great source of entertainment for all ages, as they create\na competitive and engaging environment, as well as stimulating learning and\nstrategic thinking. It is common for digital versions of board games, as any\nother type of digital games, to offer the option to select the difficulty of\nthe game. This is usually done by customizing the search parameters of the AI\nalgorithm. However, this approach cannot be extended to General Game Playing\nagents, as different games might require different parametrization for each\ndifficulty level. In this paper, we present a general approach to implement an\nartificial intelligence opponent with difficulty levels for zero-sum games,\ntogether with a propose of a Minimax-MCTS hybrid algorithm, which combines the\nminimax search process with GGP aspects of MCTS. This approach was tested in\nour mobile application LoBoGames, an extensible board games platform, that is\nintended to have an broad catalog of games, with an emphasis on accessibility:\nthe platform is friendly to visually-impaired users, and is compatible with\nmore than 92\\% of Android devices. The tests in this work indicate that both\nthe hybrid Minimax-MCTS and the new difficulty adjustment system are promising\nGGP approaches that could be expanded in future work.",
            "author": [
                "Marco Ant\u00f4nio Athayde de Aguiar Vieira",
                "Anderson Rocha Tavares",
                "Renato Perez Ribas"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16581v1",
                "http://arxiv.org/pdf/2310.16581v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16579v1",
            "title": "WSDMS: Debunk Fake News via Weakly Supervised Detection of Misinforming\n  Sentences with Contextualized Social Wisdom",
            "updated": "2023-10-25T12:06:55Z",
            "published": "2023-10-25T12:06:55Z",
            "summary": "In recent years, we witness the explosion of false and unconfirmed\ninformation (i.e., rumors) that went viral on social media and shocked the\npublic. Rumors can trigger versatile, mostly controversial stance expressions\namong social media users. Rumor verification and stance detection are different\nyet relevant tasks. Fake news debunking primarily focuses on determining the\ntruthfulness of news articles, which oversimplifies the issue as fake news\noften combines elements of both truth and falsehood. Thus, it becomes crucial\nto identify specific instances of misinformation within the articles. In this\nresearch, we investigate a novel task in the field of fake news debunking,\nwhich involves detecting sentence-level misinformation. One of the major\nchallenges in this task is the absence of a training dataset with\nsentence-level annotations regarding veracity. Inspired by the Multiple\nInstance Learning (MIL) approach, we propose a model called Weakly Supervised\nDetection of Misinforming Sentences (WSDMS). This model only requires bag-level\nlabels for training but is capable of inferring both sentence-level\nmisinformation and article-level veracity, aided by relevant social media\nconversations that are attentively contextualized with news sentences. We\nevaluate WSDMS on three real-world benchmarks and demonstrate that it\noutperforms existing state-of-the-art baselines in debunking fake news at both\nthe sentence and article levels.",
            "author": [
                "Ruichao Yang",
                "Wei Gao",
                "Jing Ma",
                "Hongzhan Lin",
                "Zhiwei Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16579v1",
                "http://arxiv.org/pdf/2310.16579v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16577v1",
            "title": "Mapping the magnetic field using a magnetometer array with noisy input\n  Gaussian process regression",
            "updated": "2023-10-25T12:00:45Z",
            "published": "2023-10-25T12:00:45Z",
            "summary": "Ferromagnetic materials in indoor environments give rise to disturbances in\nthe ambient magnetic field. Maps of these magnetic disturbances can be used for\nindoor localisation. A Gaussian process can be used to learn the spatially\nvarying magnitude of the magnetic field using magnetometer measurements and\ninformation about the position of the magnetometer. The position of the\nmagnetometer, however, is frequently only approximately known. This negatively\naffects the quality of the magnetic field map. In this paper, we investigate\nhow an array of magnetometers can be used to improve the quality of the\nmagnetic field map. The position of the array is approximately known, but the\nrelative locations of the magnetometers on the array are known. We include this\ninformation in a novel method to make a map of the ambient magnetic field. We\nstudy the properties of our method in simulation and show that our method\nimproves the map quality. We also demonstrate the efficacy of our method with\nexperimental data for the mapping of the magnetic field using an array of 30\nmagnetometers.",
            "author": [
                "Thomas Edridge",
                "Manon Kok"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16577v1",
                "http://arxiv.org/pdf/2310.16577v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16574v1",
            "title": "Large-scale magnetic field maps using structured kernel interpolation\n  for Gaussian process regression",
            "updated": "2023-10-25T11:58:18Z",
            "published": "2023-10-25T11:58:18Z",
            "summary": "We present a mapping algorithm to compute large-scale magnetic field maps in\nindoor environments with approximate Gaussian process (GP) regression. Mapping\nthe spatial variations in the ambient magnetic field can be used for\nlocalization algorithms in indoor areas. To compute such a map, GP regression\nis a suitable tool because it provides predictions of the magnetic field at new\nlocations along with uncertainty quantification. Because full GP regression has\na complexity that grows cubically with the number of data points,\napproximations for GPs have been extensively studied. In this paper, we build\non the structured kernel interpolation (SKI) framework, speeding up inference\nby exploiting efficient Krylov subspace methods. More specifically, we\nincorporate SKI with derivatives (D-SKI) into the scalar potential model for\nmagnetic field modeling and compute both predictive mean and covariance with a\ncomplexity that is linear in the data points. In our simulations, we show that\nour method achieves better accuracy than current state-of-the-art methods on\nmagnetic field maps with a growing mapping area. In our large-scale\nexperiments, we construct magnetic field maps from up to 40000\nthree-dimensional magnetic field measurements in less than two minutes on a\nstandard laptop.",
            "author": [
                "Clara Menzen",
                "Marnix Fetter",
                "Manon Kok"
            ],
            "link": [
                "http://dx.doi.org/10.23919/FUSION52260.2023.10224210",
                "http://arxiv.org/abs/2310.16574v1",
                "http://arxiv.org/pdf/2310.16574v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16573v1",
            "title": "Adapt Anything: Tailor Any Image Classifiers across Domains And\n  Categories Using Text-to-Image Diffusion Models",
            "updated": "2023-10-25T11:58:14Z",
            "published": "2023-10-25T11:58:14Z",
            "summary": "We do not pursue a novel method in this paper, but aim to study if a modern\ntext-to-image diffusion model can tailor any task-adaptive image classifier\nacross domains and categories. Existing domain adaptive image classification\nworks exploit both source and target data for domain alignment so as to\ntransfer the knowledge learned from the labeled source data to the unlabeled\ntarget data. However, as the development of the text-to-image diffusion model,\nwe wonder if the high-fidelity synthetic data from the text-to-image generator\ncan serve as a surrogate of the source data in real world. In this way, we do\nnot need to collect and annotate the source data for each domain adaptation\ntask in a one-for-one manner. Instead, we utilize only one off-the-shelf\ntext-to-image model to synthesize images with category labels derived from the\ncorresponding text prompts, and then leverage the surrogate data as a bridge to\ntransfer the knowledge embedded in the task-agnostic text-to-image generator to\nthe task-oriented image classifier via domain adaptation. Such a one-for-all\nadaptation paradigm allows us to adapt anything in the world using only one\ntext-to-image generator as well as the corresponding unlabeled target data.\nExtensive experiments validate the feasibility of the proposed idea, which even\nsurpasses the state-of-the-art domain adaptation works using the source data\ncollected and annotated in real world.",
            "author": [
                "Weijie Chen",
                "Haoyu Wang",
                "Shicai Yang",
                "Lei Zhang",
                "Wei Wei",
                "Yanning Zhang",
                "Luojun Lin",
                "Di Xie",
                "Yueting Zhuang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16573v1",
                "http://arxiv.org/pdf/2310.16573v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16569v1",
            "title": "Flow-Attention-based Spatio-Temporal Aggregation Network for 3D Mask\n  Detection",
            "updated": "2023-10-25T11:54:21Z",
            "published": "2023-10-25T11:54:21Z",
            "summary": "Anti-spoofing detection has become a necessity for face recognition systems\ndue to the security threat posed by spoofing attacks. Despite great success in\ntraditional attacks, most deep-learning-based methods perform poorly in 3D\nmasks, which can highly simulate real faces in appearance and structure,\nsuffering generalizability insufficiency while focusing only on the spatial\ndomain with single frame input. This has been mitigated by the recent\nintroduction of a biomedical technology called rPPG (remote\nphotoplethysmography). However, rPPG-based methods are sensitive to noisy\ninterference and require at least one second (> 25 frames) of observation time,\nwhich induces high computational overhead. To address these challenges, we\npropose a novel 3D mask detection framework, called FASTEN\n(Flow-Attention-based Spatio-Temporal aggrEgation Network). We tailor the\nnetwork for focusing more on fine-grained details in large movements, which can\neliminate redundant spatio-temporal feature interference and quickly capture\nsplicing traces of 3D masks in fewer frames. Our proposed network contains\nthree key modules: 1) a facial optical flow network to obtain non-RGB\ninter-frame flow information; 2) flow attention to assign different\nsignificance to each frame; 3) spatio-temporal aggregation to aggregate\nhigh-level spatial features and temporal transition features. Through extensive\nexperiments, FASTEN only requires five frames of input and outperforms eight\ncompetitors for both intra-dataset and cross-dataset evaluations in terms of\nmultiple detection metrics. Moreover, FASTEN has been deployed in real-world\nmobile devices for practical 3D mask detection.",
            "author": [
                "Yuxin Cao",
                "Yian Li",
                "Yumeng Zhu",
                "Derui Wang",
                "Minhui Xue"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16569v1",
                "http://arxiv.org/pdf/2310.16569v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16566v1",
            "title": "Model-enhanced Contrastive Reinforcement Learning for Sequential\n  Recommendation",
            "updated": "2023-10-25T11:43:29Z",
            "published": "2023-10-25T11:43:29Z",
            "summary": "Reinforcement learning (RL) has been widely applied in recommendation systems\ndue to its potential in optimizing the long-term engagement of users. From the\nperspective of RL, recommendation can be formulated as a Markov decision\nprocess (MDP), where recommendation system (agent) can interact with users\n(environment) and acquire feedback (reward signals).However, it is impractical\nto conduct online interactions with the concern on user experience and\nimplementation complexity, and we can only train RL recommenders with offline\ndatasets containing limited reward signals and state transitions. Therefore,\nthe data sparsity issue of reward signals and state transitions is very severe,\nwhile it has long been overlooked by existing RL recommenders.Worse still, RL\nmethods learn through the trial-and-error mode, but negative feedback cannot be\nobtained in implicit feedback recommendation tasks, which aggravates the\noverestimation problem of offline RL recommender. To address these challenges,\nwe propose a novel RL recommender named model-enhanced contrastive\nreinforcement learning (MCRL). On the one hand, we learn a value function to\nestimate the long-term engagement of users, together with a conservative value\nlearning mechanism to alleviate the overestimation problem.On the other hand,\nwe construct some positive and negative state-action pairs to model the reward\nfunction and state transition function with contrastive learning to exploit the\ninternal structure information of MDP. Experiments demonstrate that the\nproposed method significantly outperforms existing offline RL and\nself-supervised RL methods with different representative backbone networks on\ntwo real-world datasets.",
            "author": [
                "Chengpeng Li",
                "Zhengyi Yang",
                "Jizhi Zhang",
                "Jiancan Wu",
                "Dingxian Wang",
                "Xiangnan He",
                "Xiang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16566v1",
                "http://arxiv.org/pdf/2310.16566v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16560v1",
            "title": "Label Propagation for Graph Label Noise",
            "updated": "2023-10-25T11:28:26Z",
            "published": "2023-10-25T11:28:26Z",
            "summary": "Label noise is a common challenge in large datasets, as it can significantly\ndegrade the generalization ability of deep neural networks. Most existing\nstudies focus on noisy labels in computer vision; however, graph models\nencompass both node features and graph topology as input, and become more\nsusceptible to label noise through message-passing mechanisms. Recently, only a\nfew works have been proposed to tackle the label noise on graphs. One major\nlimitation is that they assume the graph is homophilous and the labels are\nsmoothly distributed. Nevertheless, real-world graphs may contain varying\ndegrees of heterophily or even be heterophily-dominated, leading to the\ninadequacy of current methods. In this paper, we study graph label noise in the\ncontext of arbitrary heterophily, with the aim of rectifying noisy labels and\nassigning labels to previously unlabeled nodes. We begin by conducting two\nempirical analyses to explore the impact of graph homophily on graph label\nnoise. Following observations, we propose a simple yet efficient algorithm,\ndenoted as LP4GLN. Specifically, LP4GLN is an iterative algorithm with three\nsteps: (1) reconstruct the graph to recover the homophily property, (2) utilize\nlabel propagation to rectify the noisy labels, (3) select high-confidence\nlabels to retain for the next iteration. By iterating these steps, we obtain a\nset of correct labels, ultimately achieving high accuracy in the node\nclassification task. The theoretical analysis is also provided to demonstrate\nits remarkable denoising \"effect\". Finally, we conduct experiments on 10\nbenchmark datasets under varying graph heterophily levels and noise types,\ncomparing the performance of LP4GLN with 7 typical baselines. Our results\nillustrate the superior performance of the proposed LP4GLN.",
            "author": [
                "Yao Cheng",
                "Caihua Shan",
                "Yifei Shen",
                "Xiang Li",
                "Siqiang Luo",
                "Dongsheng Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16560v1",
                "http://arxiv.org/pdf/2310.16560v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16555v2",
            "title": "Towards Information Theory-Based Discovery of Equivariances",
            "updated": "2023-11-14T11:37:40Z",
            "published": "2023-10-25T11:19:40Z",
            "summary": "The presence of symmetries imposes a stringent set of constraints on a\nsystem. This constrained structure allows intelligent agents interacting with\nsuch a system to drastically improve the efficiency of learning and\ngeneralization, through the internalisation of the system's symmetries into\ntheir information-processing. In parallel, principled models of\ncomplexity-constrained learning and behaviour make increasing use of\ninformation-theoretic methods. Here, we wish to marry these two perspectives\nand understand whether and in which form the information-theoretic lens can\n\"see\" the effect of symmetries of a system. For this purpose, we propose a\nnovel variant of the Information Bottleneck principle, which has served as a\nproductive basis for many principled studies of learning and\ninformation-constrained adaptive behaviour. We show (in the discrete case) that\nour approach formalises a certain duality between symmetry and information\nparsimony: namely, channel equivariances can be characterised by the optimal\nmutual information-preserving joint compression of the channel's input and\noutput. This information-theoretic treatment furthermore suggests a principled\nnotion of \"soft\" equivariance, whose \"coarseness\" is measured by the amount of\ninput-output mutual information preserved by the corresponding optimal\ncompression. This new notion offers a bridge between the field of bounded\nrationality and the study of symmetries in neural representations. The\nframework may also allow (exact and soft) equivariances to be automatically\ndiscovered.",
            "author": [
                "Hippolyte Charvin",
                "Nicola Catenacci Volpi",
                "Daniel Polani"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16555v2",
                "http://arxiv.org/pdf/2310.16555v2"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.NE",
                "math.GR",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16552v1",
            "title": "DECWA : Density-Based Clustering using Wasserstein Distance",
            "updated": "2023-10-25T11:10:08Z",
            "published": "2023-10-25T11:10:08Z",
            "summary": "Clustering is a data analysis method for extracting knowledge by discovering\ngroups of data called clusters. Among these methods, state-of-the-art\ndensity-based clustering methods have proven to be effective for\narbitrary-shaped clusters. Despite their encouraging results, they suffer to\nfind low-density clusters, near clusters with similar densities, and\nhigh-dimensional data. Our proposals are a new characterization of clusters and\na new clustering algorithm based on spatial density and probabilistic approach.\nFirst of all, sub-clusters are built using spatial density represented as\nprobability density function ($p.d.f$) of pairwise distances between points. A\nmethod is then proposed to agglomerate similar sub-clusters by using both their\ndensity ($p.d.f$) and their spatial distance. The key idea we propose is to use\nthe Wasserstein metric, a powerful tool to measure the distance between $p.d.f$\nof sub-clusters. We show that our approach outperforms other state-of-the-art\ndensity-based clustering methods on a wide variety of datasets.",
            "author": [
                "Nabil El Malki",
                "Robin Cugny",
                "Olivier Teste",
                "Franck Ravat"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3340531.3412125",
                "http://arxiv.org/abs/2310.16552v1",
                "http://arxiv.org/pdf/2310.16552v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16550v1",
            "title": "Dynamic Processing Neural Network Architecture For Hearing Loss\n  Compensation",
            "updated": "2023-10-25T11:04:32Z",
            "published": "2023-10-25T11:04:32Z",
            "summary": "This paper proposes neural networks for compensating sensorineural hearing\nloss. The aim of the hearing loss compensation task is to transform a speech\nsignal to increase speech intelligibility after further processing by a person\nwith a hearing impairment, which is modeled by a hearing loss model. We propose\nan interpretable model called dynamic processing network, which has a structure\nsimilar to band-wise dynamic compressor. The network is differentiable, and\ntherefore allows to learn its parameters to maximize speech intelligibility.\nMore generic models based on convolutional layers were tested as well. The\nperformance of the tested architectures was assessed using spectro-temporal\nobjective index (STOI) with hearing-threshold noise and hearing aid speech\nintelligibility (HASPI) metrics. The dynamic processing network gave a\nsignificant improvement of STOI and HASPI in comparison to popular compressive\ngain prescription rule Camfit. A large enough convolutional network could\noutperform the interpretable model with the cost of larger computational load.\nFinally, a combination of the dynamic processing network with convolutional\nneural network gave the best results in terms of STOI and HASPI.",
            "author": [
                "Szymon Drgas",
                "Lars Bramsl\u00f8w",
                "Archontis Politis",
                "Gaurav Naithani",
                "Tuomas Virtanen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16550v1",
                "http://arxiv.org/pdf/2310.16550v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16547v1",
            "title": "AdaMEC: Towards a Context-Adaptive and Dynamically-Combinable DNN\n  Deployment Framework for Mobile Edge Computing",
            "updated": "2023-10-25T10:53:53Z",
            "published": "2023-10-25T10:53:53Z",
            "summary": "With the rapid development of deep learning, recent research on intelligent\nand interactive mobile applications (e.g., health monitoring, speech\nrecognition) has attracted extensive attention. And these applications\nnecessitate the mobile edge computing scheme, i.e., offloading partial\ncomputation from mobile devices to edge devices for inference acceleration and\ntransmission load reduction. The current practices have relied on collaborative\nDNN partition and offloading to satisfy the predefined latency requirements,\nwhich is intractable to adapt to the dynamic deployment context at runtime.\nAdaMEC, a context-adaptive and dynamically-combinable DNN deployment framework\nis proposed to meet these requirements for mobile edge computing, which\nconsists of three novel techniques. First, once-for-all DNN pre-partition\ndivides DNN at the primitive operator level and stores partitioned modules into\nexecutable files, defined as pre-partitioned DNN atoms. Second,\ncontext-adaptive DNN atom combination and offloading introduces a graph-based\ndecision algorithm to quickly search the suitable combination of atoms and\nadaptively make the offloading plan under dynamic deployment contexts. Third,\nruntime latency predictor provides timely latency feedback for DNN deployment\nconsidering both DNN configurations and dynamic contexts. Extensive experiments\ndemonstrate that AdaMEC outperforms state-of-the-art baselines in terms of\nlatency reduction by up to 62.14% and average memory saving by 55.21%.",
            "author": [
                "Bowen Pang",
                "Sicong Liu",
                "Hongli Wang",
                "Bin Guo",
                "Yuzhan Wang",
                "Hao Wang",
                "Zhenli Sheng",
                "Zhongyi Wang",
                "Zhiwen Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16547v1",
                "http://arxiv.org/pdf/2310.16547v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16546v3",
            "title": "Pitfall of Optimism: Distributional Reinforcement Learning by\n  Randomizing Risk Criterion",
            "updated": "2023-12-05T05:14:37Z",
            "published": "2023-10-25T10:53:04Z",
            "summary": "Distributional reinforcement learning algorithms have attempted to utilize\nestimated uncertainty for exploration, such as optimism in the face of\nuncertainty. However, using the estimated variance for optimistic exploration\nmay cause biased data collection and hinder convergence or performance. In this\npaper, we present a novel distributional reinforcement learning algorithm that\nselects actions by randomizing risk criterion to avoid one-sided tendency on\nrisk. We provide a perturbed distributional Bellman optimality operator by\ndistorting the risk measure and prove the convergence and optimality of the\nproposed method with the weaker contraction property. Our theoretical results\nsupport that the proposed method does not fall into biased exploration and is\nguaranteed to converge to an optimal return. Finally, we empirically show that\nour method outperforms other existing distribution-based algorithms in various\nenvironments including Atari 55 games.",
            "author": [
                "Taehyun Cho",
                "Seungyub Han",
                "Heesoo Lee",
                "Kyungjae Lee",
                "Jungwoo Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16546v3",
                "http://arxiv.org/pdf/2310.16546v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18366v1",
            "title": "A Multilingual Virtual Guide for Self-Attachment Technique",
            "updated": "2023-10-25T10:50:18Z",
            "published": "2023-10-25T10:50:18Z",
            "summary": "In this work, we propose a computational framework that leverages existing\nout-of-language data to create a conversational agent for the delivery of\nSelf-Attachment Technique (SAT) in Mandarin. Our framework does not require\nlarge-scale human translations, yet it achieves a comparable performance whilst\nalso maintaining safety and reliability. We propose two different methods of\naugmenting available response data through empathetic rewriting. We evaluate\nour chatbot against a previous, English-only SAT chatbot through non-clinical\nhuman trials (N=42), each lasting five days, and quantitatively show that we\nare able to attain a comparable level of performance to the English SAT\nchatbot. We provide qualitative analysis on the limitations of our study and\nsuggestions with the aim of guiding future improvements.",
            "author": [
                "Alicia Jiayun Law",
                "Ruoyu Hu",
                "Lisa Alazraki",
                "Anandha Gopalan",
                "Neophytos Polydorou",
                "Abbas Edalat"
            ],
            "link": [
                "http://dx.doi.org/10.1109/CogMI56440.2022.00025",
                "http://arxiv.org/abs/2310.18366v1",
                "http://arxiv.org/pdf/2310.18366v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16540v1",
            "title": "Dual Defense: Adversarial, Traceable, and Invisible Robust Watermarking\n  against Face Swapping",
            "updated": "2023-10-25T10:39:51Z",
            "published": "2023-10-25T10:39:51Z",
            "summary": "The malicious applications of deep forgery, represented by face swapping,\nhave introduced security threats such as misinformation dissemination and\nidentity fraud. While some research has proposed the use of robust watermarking\nmethods to trace the copyright of facial images for post-event traceability,\nthese methods cannot effectively prevent the generation of forgeries at the\nsource and curb their dissemination. To address this problem, we propose a\nnovel comprehensive active defense mechanism that combines traceability and\nadversariality, called Dual Defense. Dual Defense invisibly embeds a single\nrobust watermark within the target face to actively respond to sudden cases of\nmalicious face swapping. It disrupts the output of the face swapping model\nwhile maintaining the integrity of watermark information throughout the entire\ndissemination process. This allows for watermark extraction at any stage of\nimage tracking for traceability. Specifically, we introduce a watermark\nembedding network based on original-domain feature impersonation attack. This\nnetwork learns robust adversarial features of target facial images and embeds\nwatermarks, seeking a well-balanced trade-off between watermark invisibility,\nadversariality, and traceability through perceptual adversarial encoding\nstrategies. Extensive experiments demonstrate that Dual Defense achieves\noptimal overall defense success rates and exhibits promising universality in\nanti-face swapping tasks and dataset generalization ability. It maintains\nimpressive adversariality and traceability in both original and robust\nsettings, surpassing current forgery defense methods that possess only one of\nthese capabilities, including CMUA-Watermark, Anti-Forgery, FakeTagger, or PGD\nmethods.",
            "author": [
                "Yunming Zhang",
                "Dengpan Ye",
                "Caiyun Xie",
                "Long Tang",
                "Chuanxi Chen",
                "Ziyi Liu",
                "Jiacheng Deng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16540v1",
                "http://arxiv.org/pdf/2310.16540v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16538v1",
            "title": "FedTherapist: Mental Health Monitoring with User-Generated Linguistic\n  Expressions on Smartphones via Federated Learning",
            "updated": "2023-10-25T10:35:09Z",
            "published": "2023-10-25T10:35:09Z",
            "summary": "Psychiatrists diagnose mental disorders via the linguistic use of patients.\nStill, due to data privacy, existing passive mental health monitoring systems\nuse alternative features such as activity, app usage, and location via mobile\ndevices. We propose FedTherapist, a mobile mental health monitoring system that\nutilizes continuous speech and keyboard input in a privacy-preserving way via\nfederated learning. We explore multiple model designs by comparing their\nperformance and overhead for FedTherapist to overcome the complex nature of\non-device language model training on smartphones. We further propose a\nContext-Aware Language Learning (CALL) methodology to effectively utilize\nsmartphones' large and noisy text for mental health signal sensing. Our\nIRB-approved evaluation of the prediction of self-reported depression, stress,\nanxiety, and mood from 46 participants shows higher accuracy of FedTherapist\ncompared with the performance with non-language features, achieving 0.15 AUROC\nimprovement and 8.21% MAE reduction.",
            "author": [
                "Jaemin Shin",
                "Hyungjun Yoon",
                "Seungjoo Lee",
                "Sungjoon Park",
                "Yunxin Liu",
                "Jinho D. Choi",
                "Sung-Ju Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16538v1",
                "http://arxiv.org/pdf/2310.16538v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16532v1",
            "title": "Learning Robust Deep Visual Representations from EEG Brain Recordings",
            "updated": "2023-10-25T10:26:07Z",
            "published": "2023-10-25T10:26:07Z",
            "summary": "Decoding the human brain has been a hallmark of neuroscientists and\nArtificial Intelligence researchers alike. Reconstruction of visual images from\nbrain Electroencephalography (EEG) signals has garnered a lot of interest due\nto its applications in brain-computer interfacing. This study proposes a\ntwo-stage method where the first step is to obtain EEG-derived features for\nrobust learning of deep representations and subsequently utilize the learned\nrepresentation for image generation and classification. We demonstrate the\ngeneralizability of our feature extraction pipeline across three different\ndatasets using deep-learning architectures with supervised and contrastive\nlearning methods. We have performed the zero-shot EEG classification task to\nsupport the generalizability claim further. We observed that a subject\ninvariant linearly separable visual representation was learned using EEG data\nalone in an unimodal setting that gives better k-means accuracy as compared to\na joint representation learning between EEG and images. Finally, we propose a\nnovel framework to transform unseen images into the EEG space and reconstruct\nthem with approximation, showcasing the potential for image reconstruction from\nEEG signals. Our proposed image synthesis method from EEG shows 62.9% and\n36.13% inception score improvement on the EEGCVPR40 and the Thoughtviz\ndatasets, which is better than state-of-the-art performance in GAN.",
            "author": [
                "Prajwal Singh",
                "Dwip Dalal",
                "Gautam Vashishtha",
                "Krishna Miyapuram",
                "Shanmuganathan Raman"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16532v1",
                "http://arxiv.org/pdf/2310.16532v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16528v1",
            "title": "CUNI Submission to MRL 2023 Shared Task on Multi-lingual Multi-task\n  Information Retrieval",
            "updated": "2023-10-25T10:22:49Z",
            "published": "2023-10-25T10:22:49Z",
            "summary": "We present the Charles University system for the MRL~2023 Shared Task on\nMulti-lingual Multi-task Information Retrieval. The goal of the shared task was\nto develop systems for named entity recognition and question answering in\nseveral under-represented languages. Our solutions to both subtasks rely on the\ntranslate-test approach. We first translate the unlabeled examples into English\nusing a multilingual machine translation model. Then, we run inference on the\ntranslated data using a strong task-specific model. Finally, we project the\nlabeled data back into the original language. To keep the inferred tags on the\ncorrect positions in the original language, we propose a method based on\nscoring the candidate positions using a label-sensitive translation model. In\nboth settings, we experiment with finetuning the classification models on the\ntranslated data. However, due to a domain mismatch between the development data\nand the shared task validation and test sets, the finetuned models could not\noutperform our baselines.",
            "author": [
                "Jind\u0159ich Helcl",
                "Jind\u0159ich Libovick\u00fd"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16528v1",
                "http://arxiv.org/pdf/2310.16528v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16527v1",
            "title": "Enhancing Document Information Analysis with Multi-Task Pre-training: A\n  Robust Approach for Information Extraction in Visually-Rich Documents",
            "updated": "2023-10-25T10:22:30Z",
            "published": "2023-10-25T10:22:30Z",
            "summary": "This paper introduces a deep learning model tailored for document information\nanalysis, emphasizing document classification, entity relation extraction, and\ndocument visual question answering. The proposed model leverages\ntransformer-based models to encode all the information present in a document\nimage, including textual, visual, and layout information. The model is\npre-trained and subsequently fine-tuned for various document image analysis\ntasks. The proposed model incorporates three additional tasks during the\npre-training phase, including reading order identification of different layout\nsegments in a document image, layout segments categorization as per PubLayNet,\nand generation of the text sequence within a given layout segment (text block).\nThe model also incorporates a collective pre-training scheme where losses of\nall the tasks under consideration, including pre-training and fine-tuning tasks\nwith all datasets, are considered. Additional encoder and decoder blocks are\nadded to the RoBERTa network to generate results for all tasks. The proposed\nmodel achieved impressive results across all tasks, with an accuracy of 95.87%\non the RVL-CDIP dataset for document classification, F1 scores of 0.9306,\n0.9804, 0.9794, and 0.8742 on the FUNSD, CORD, SROIE, and Kleister-NDA datasets\nrespectively for entity relation extraction, and an ANLS score of 0.8468 on the\nDocVQA dataset for visual question answering. The results highlight the\neffectiveness of the proposed model in understanding and interpreting complex\ndocument layouts and content, making it a promising tool for document analysis\ntasks.",
            "author": [
                "Tofik Ali",
                "Partha Pratim Roy"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16527v1",
                "http://arxiv.org/pdf/2310.16527v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16525v1",
            "title": "Cyclic Directed Probabilistic Graphical Model: A Proposal Based on\n  Structured Outcomes",
            "updated": "2023-10-25T10:19:03Z",
            "published": "2023-10-25T10:19:03Z",
            "summary": "In the process of building (structural learning) a probabilistic graphical\nmodel from a set of observed data, the directional, cyclic dependencies between\nthe random variables of the model are often found. Existing graphical models\nsuch as Bayesian and Markov networks can reflect such dependencies. However,\nthis requires complicating those models, such as adding additional variables or\ndividing the model graph into separate subgraphs. Herein, we describe a\nprobabilistic graphical model - probabilistic relation network - that allows\nthe direct capture of directional cyclic dependencies during structural\nlearning. This model is based on the simple idea that each sample of the\nobserved data can be represented by an arbitrary graph (structured outcome),\nwhich reflects the structure of the dependencies of the variables included in\nthe sample. Each of the outcomes contains only a part of the graphical model\nstructure; however, a complete graph of the probabilistic model is obtained by\ncombining different outcomes. Such a graph, unlike Bayesian and Markov\nnetworks, can be directed and can have cycles. We explored the full joint\ndistribution and conditional distribution and conditional independence\nproperties of variables in the proposed model. We defined the algorithms for\nconstructing of the model from the dataset and for calculating the conditional\nand full joint distributions. We also performed a numerical comparison with\nBayesian and Markov networks. This model does not violate the probability\naxioms, and it supports learning from observed data. Notably, it supports\nprobabilistic inference, making it a prospective tool in data analysis and in\nexpert and design-making applications.",
            "author": [
                "Oleksii Sirotkin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16525v1",
                "http://arxiv.org/pdf/2310.16525v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "62H22 (Primary) 05C38, 62H11 (Secondary)",
                "G.3; H.1.0"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16524v1",
            "title": "Can You Rely on Your Model Evaluation? Improving Model Evaluation with\n  Synthetic Test Data",
            "updated": "2023-10-25T10:18:44Z",
            "published": "2023-10-25T10:18:44Z",
            "summary": "Evaluating the performance of machine learning models on diverse and\nunderrepresented subgroups is essential for ensuring fairness and reliability\nin real-world applications. However, accurately assessing model performance\nbecomes challenging due to two main issues: (1) a scarcity of test data,\nespecially for small subgroups, and (2) possible distributional shifts in the\nmodel's deployment setting, which may not align with the available test data.\nIn this work, we introduce 3S Testing, a deep generative modeling framework to\nfacilitate model evaluation by generating synthetic test sets for small\nsubgroups and simulating distributional shifts. Our experiments demonstrate\nthat 3S Testing outperforms traditional baselines -- including real test data\nalone -- in estimating model performance on minority subgroups and under\nplausible distributional shifts. In addition, 3S offers intervals around its\nperformance estimates, exhibiting superior coverage of the ground truth\ncompared to existing approaches. Overall, these results raise the question of\nwhether we need a paradigm shift away from limited real test data towards\nsynthetic test data.",
            "author": [
                "Boris van Breugel",
                "Nabeel Seedat",
                "Fergus Imrie",
                "Mihaela van der Schaar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16524v1",
                "http://arxiv.org/pdf/2310.16524v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16520v1",
            "title": "Towards Self-Interpretable Graph-Level Anomaly Detection",
            "updated": "2023-10-25T10:10:07Z",
            "published": "2023-10-25T10:10:07Z",
            "summary": "Graph-level anomaly detection (GLAD) aims to identify graphs that exhibit\nnotable dissimilarity compared to the majority in a collection. However,\ncurrent works primarily focus on evaluating graph-level abnormality while\nfailing to provide meaningful explanations for the predictions, which largely\nlimits their reliability and application scope. In this paper, we investigate a\nnew challenging problem, explainable GLAD, where the learning objective is to\npredict the abnormality of each graph sample with corresponding explanations,\ni.e., the vital subgraph that leads to the predictions. To address this\nchallenging problem, we propose a Self-Interpretable Graph aNomaly dETection\nmodel (SIGNET for short) that detects anomalous graphs as well as generates\ninformative explanations simultaneously. Specifically, we first introduce the\nmulti-view subgraph information bottleneck (MSIB) framework, serving as the\ndesign basis of our self-interpretable GLAD approach. This way SIGNET is able\nto not only measure the abnormality of each graph based on cross-view mutual\ninformation but also provide informative graph rationales by extracting\nbottleneck subgraphs from the input graph and its dual hypergraph in a\nself-supervised way. Extensive experiments on 16 datasets demonstrate the\nanomaly detection capability and self-interpretability of SIGNET.",
            "author": [
                "Yixin Liu",
                "Kaize Ding",
                "Qinghua Lu",
                "Fuyi Li",
                "Leo Yu Zhang",
                "Shirui Pan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16520v1",
                "http://arxiv.org/pdf/2310.16520v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16516v1",
            "title": "Particle-based Variational Inference with Generalized Wasserstein\n  Gradient Flow",
            "updated": "2023-10-25T10:05:42Z",
            "published": "2023-10-25T10:05:42Z",
            "summary": "Particle-based variational inference methods (ParVIs) such as Stein\nvariational gradient descent (SVGD) update the particles based on the\nkernelized Wasserstein gradient flow for the Kullback-Leibler (KL) divergence.\nHowever, the design of kernels is often non-trivial and can be restrictive for\nthe flexibility of the method. Recent works show that functional gradient flow\napproximations with quadratic form regularization terms can improve\nperformance. In this paper, we propose a ParVI framework, called generalized\nWasserstein gradient descent (GWG), based on a generalized Wasserstein gradient\nflow of the KL divergence, which can be viewed as a functional gradient method\nwith a broader class of regularizers induced by convex functions. We show that\nGWG exhibits strong convergence guarantees. We also provide an adaptive version\nthat automatically chooses Wasserstein metric to accelerate convergence. In\nexperiments, we demonstrate the effectiveness and efficiency of the proposed\nframework on both simulated and real data problems.",
            "author": [
                "Ziheng Cheng",
                "Shiyue Zhang",
                "Longlin Yu",
                "Cheng Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16516v1",
                "http://arxiv.org/pdf/2310.16516v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16506v2",
            "title": "Identifying Reasons for Bias: An Argumentation-Based Approach",
            "updated": "2023-10-26T21:35:42Z",
            "published": "2023-10-25T09:47:15Z",
            "summary": "As algorithmic decision-making systems become more prevalent in society,\nensuring the fairness of these systems is becoming increasingly important.\nWhilst there has been substantial research in building fair algorithmic\ndecision-making systems, the majority of these methods require access to the\ntraining data, including personal characteristics, and are not transparent\nregarding which individuals are classified unfairly. In this paper, we propose\na novel model-agnostic argumentation-based method to determine why an\nindividual is classified differently in comparison to similar individuals. Our\nmethod uses a quantitative argumentation framework to represent attribute-value\npairs of an individual and of those similar to them, and uses a well-known\nsemantics to identify the attribute-value pairs in the individual contributing\nmost to their different classification. We evaluate our method on two datasets\ncommonly used in the fairness literature and illustrate its effectiveness in\nthe identification of bias.",
            "author": [
                "Madeleine Waller",
                "Odinaldo Rodrigues",
                "Oana Cocarascu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16506v2",
                "http://arxiv.org/pdf/2310.16506v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16502v2",
            "title": "Assessing the overall and partial causal well-specification of nonlinear\n  additive noise models",
            "updated": "2023-10-26T12:29:40Z",
            "published": "2023-10-25T09:44:16Z",
            "summary": "We propose a method to detect model misspecifications in nonlinear causal\nadditive and potentially heteroscedastic noise models. We aim to identify\npredictor variables for which we can infer the causal effect even in cases of\nsuch misspecification. We develop a general framework based on knowledge of the\nmultivariate observational data distribution and we then propose an algorithm\nfor finite sample data, discuss its asymptotic properties, and illustrate its\nperformance on simulated and real data.",
            "author": [
                "Christoph Schultheiss",
                "Peter B\u00fchlmann"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16502v2",
                "http://arxiv.org/pdf/2310.16502v2"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12861v1",
            "title": "A versatile circuit for emulating active biological dendrites applied to\n  sound localisation and neuron imitation",
            "updated": "2023-10-25T09:42:24Z",
            "published": "2023-10-25T09:42:24Z",
            "summary": "Sophisticated machine learning struggles to transition onto battery-operated\ndevices due to the high-power consumption of neural networks. Researchers have\nturned to neuromorphic engineering, inspired by biological neural networks, for\nmore efficient solutions. While previous research focused on artificial neurons\nand synapses, an essential component has been overlooked: dendrites. Dendrites\ntransmit inputs from synapses to the neuron's soma, applying both passive and\nactive transformations. However, neuromorphic circuits replace these\nsophisticated computational channels with metallic interconnects. In this\nstudy, we introduce a versatile circuit that emulates a segment of a dendrite\nwhich exhibits gain, introduces delays, and performs integration. We show how\nsound localisation - a biological example of dendritic computation - is not\npossible with the existing passive dendrite circuits but can be achieved using\nthis proposed circuit. We also find that dendrites can form bursting neurons.\nThis significant discovery suggests the potential to fabricate neural networks\nsolely comprised of dendrite circuits.",
            "author": [
                "Daniel John Mannion"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12861v1",
                "http://arxiv.org/pdf/2311.12861v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.AI",
                "cs.ET",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16499v1",
            "title": "Data Optimization in Deep Learning: A Survey",
            "updated": "2023-10-25T09:33:57Z",
            "published": "2023-10-25T09:33:57Z",
            "summary": "Large-scale, high-quality data are considered an essential factor for the\nsuccessful application of many deep learning techniques. Meanwhile, numerous\nreal-world deep learning tasks still have to contend with the lack of\nsufficient amounts of high-quality data. Additionally, issues such as model\nrobustness, fairness, and trustworthiness are also closely related to training\ndata. Consequently, a huge number of studies in the existing literature have\nfocused on the data aspect in deep learning tasks. Some typical data\noptimization techniques include data augmentation, logit perturbation, sample\nweighting, and data condensation. These techniques usually come from different\ndeep learning divisions and their theoretical inspirations or heuristic\nmotivations may seem unrelated to each other. This study aims to organize a\nwide range of existing data optimization methodologies for deep learning from\nthe previous literature, and makes the effort to construct a comprehensive\ntaxonomy for them. The constructed taxonomy considers the diversity of split\ndimensions, and deep sub-taxonomies are constructed for each dimension. On the\nbasis of the taxonomy, connections among the extensive data optimization\nmethods for deep learning are built in terms of four aspects. We probe into\nrendering several promising and interesting future directions. The constructed\ntaxonomy and the revealed connections will enlighten the better understanding\nof existing methods and the design of novel data optimization techniques.\nFurthermore, our aspiration for this survey is to promote data optimization as\nan independent subdivision of deep learning. A curated, up-to-date list of\nresources related to data optimization in deep learning is available at\n\\url{https://github.com/YaoRujing/Data-Optimization}.",
            "author": [
                "Ou Wu",
                "Rujing Yao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16499v1",
                "http://arxiv.org/pdf/2310.16499v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16496v1",
            "title": "Citizen participation: crowd-sensed sustainable indoor location services",
            "updated": "2023-10-25T09:30:22Z",
            "published": "2023-10-25T09:30:22Z",
            "summary": "In the present era of sustainable innovation, the circular economy paradigm\ndictates the optimal use and exploitation of existing finite resources. At the\nsame time, the transition to smart infrastructures requires considerable\ninvestment in capital, resources and people. In this work, we present a general\nmachine learning approach for offering indoor location awareness without the\nneed to invest in additional and specialised hardware. We explore use cases\nwhere visitors equipped with their smart phone would interact with the\navailable WiFi infrastructure to estimate their location, since the indoor\nrequirement poses a limitation to standard GPS solutions. Results have shown\nthat the proposed approach achieves a less than 2m accuracy and the model is\nresilient even in the case where a substantial number of BSSIDs are dropped.",
            "author": [
                "Ioannis Nasios",
                "Konstantinos Vogklis",
                "Avleen Malhi",
                "Anastasia Vayona",
                "Panos Chatziadam",
                "Vasilis Katos"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16496v1",
                "http://arxiv.org/pdf/2310.16496v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16494v1",
            "title": "Lang3DSG: Language-based contrastive pre-training for 3D Scene Graph\n  prediction",
            "updated": "2023-10-25T09:26:16Z",
            "published": "2023-10-25T09:26:16Z",
            "summary": "D scene graphs are an emerging 3D scene representation, that models both the\nobjects present in the scene as well as their relationships. However, learning\n3D scene graphs is a challenging task because it requires not only object\nlabels but also relationship annotations, which are very scarce in datasets.\nWhile it is widely accepted that pre-training is an effective approach to\nimprove model performance in low data regimes, in this paper, we find that\nexisting pre-training methods are ill-suited for 3D scene graphs. To solve this\nissue, we present the first language-based pre-training approach for 3D scene\ngraphs, whereby we exploit the strong relationship between scene graphs and\nlanguage. To this end, we leverage the language encoder of CLIP, a popular\nvision-language model, to distill its knowledge into our graph-based network.\nWe formulate a contrastive pre-training, which aligns text embeddings of\nrelationships (subject-predicate-object triplets) and predicted 3D graph\nfeatures. Our method achieves state-of-the-art results on the main semantic 3D\nscene graph benchmark by showing improved effectiveness over pre-training\nbaselines and outperforming all the existing fully supervised scene graph\nprediction methods by a significant margin. Furthermore, since our scene graph\nfeatures are language-aligned, it allows us to query the language space of the\nfeatures in a zero-shot manner. In this paper, we show an example of utilizing\nthis property of the features to predict the room type of a scene without\nfurther training.",
            "author": [
                "Sebastian Koch",
                "Pedro Hermosilla",
                "Narunas Vaskevicius",
                "Mirco Colosi",
                "Timo Ropinski"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16494v1",
                "http://arxiv.org/pdf/2310.16494v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16492v1",
            "title": "On the Powerfulness of Textual Outlier Exposure for Visual OoD Detection",
            "updated": "2023-10-25T09:19:45Z",
            "published": "2023-10-25T09:19:45Z",
            "summary": "Successful detection of Out-of-Distribution (OoD) data is becoming\nincreasingly important to ensure safe deployment of neural networks. One of the\nmain challenges in OoD detection is that neural networks output overconfident\npredictions on OoD data, make it difficult to determine OoD-ness of data solely\nbased on their predictions. Outlier exposure addresses this issue by\nintroducing an additional loss that encourages low-confidence predictions on\nOoD data during training. While outlier exposure has shown promising potential\nin improving OoD detection performance, all previous studies on outlier\nexposure have been limited to utilizing visual outliers. Drawing inspiration\nfrom the recent advancements in vision-language pre-training, this paper\nventure out to the uncharted territory of textual outlier exposure. First, we\nuncover the benefits of using textual outliers by replacing real or virtual\noutliers in the image-domain with textual equivalents. Then, we propose various\nways of generating preferable textual outliers. Our extensive experiments\ndemonstrate that generated textual outliers achieve competitive performance on\nlarge-scale OoD and hard OoD benchmarks. Furthermore, we conduct empirical\nanalyses of textual outliers to provide primary criteria for designing\nadvantageous textual outliers: near-distribution, descriptiveness, and\ninclusion of visual semantics.",
            "author": [
                "Sangha Park",
                "Jisoo Mok",
                "Dahuin Jung",
                "Saehyung Lee",
                "Sungroh Yoon"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16492v1",
                "http://arxiv.org/pdf/2310.16492v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16491v1",
            "title": "TSONN: Time-stepping-oriented neural network for solving partial\n  differential equations",
            "updated": "2023-10-25T09:19:40Z",
            "published": "2023-10-25T09:19:40Z",
            "summary": "Deep neural networks (DNNs), especially physics-informed neural networks\n(PINNs), have recently become a new popular method for solving forward and\ninverse problems governed by partial differential equations (PDEs). However,\nthese methods still face challenges in achieving stable training and obtaining\ncorrect results in many problems, since minimizing PDE residuals with PDE-based\nsoft constraint make the problem ill-conditioned. Different from all existing\nmethods that directly minimize PDE residuals, this work integrates\ntime-stepping method with deep learning, and transforms the original\nill-conditioned optimization problem into a series of well-conditioned\nsub-problems over given pseudo time intervals. The convergence of model\ntraining is significantly improved by following the trajectory of the pseudo\ntime-stepping process, yielding a robust optimization-based PDE solver. Our\nresults show that the proposed method achieves stable training and correct\nresults in many problems that standard PINNs fail to solve, requiring only a\nsimple modification on the loss function. In addition, we demonstrate several\nnovel properties and advantages of time-stepping methods within the framework\nof neural network-based optimization approach, in comparison to traditional\ngrid-based numerical method. Specifically, explicit scheme allows significantly\nlarger time step, while implicit scheme can be implemented as straightforwardly\nas explicit scheme.",
            "author": [
                "Wenbo Cao",
                "Weiwei Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16491v1",
                "http://arxiv.org/pdf/2310.16491v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16487v1",
            "title": "Hyperparameter Optimization for Multi-Objective Reinforcement Learning",
            "updated": "2023-10-25T09:17:25Z",
            "published": "2023-10-25T09:17:25Z",
            "summary": "Reinforcement learning (RL) has emerged as a powerful approach for tackling\ncomplex problems. The recent introduction of multi-objective reinforcement\nlearning (MORL) has further expanded the scope of RL by enabling agents to make\ntrade-offs among multiple objectives. This advancement not only has broadened\nthe range of problems that can be tackled but also created numerous\nopportunities for exploration and advancement. Yet, the effectiveness of RL\nagents heavily relies on appropriately setting their hyperparameters. In\npractice, this task often proves to be challenging, leading to unsuccessful\ndeployments of these techniques in various instances. Hence, prior research has\nexplored hyperparameter optimization in RL to address this concern.\n  This paper presents an initial investigation into the challenge of\nhyperparameter optimization specifically for MORL. We formalize the problem,\nhighlight its distinctive challenges, and propose a systematic methodology to\naddress it. The proposed methodology is applied to a well-known environment\nusing a state-of-the-art MORL algorithm, and preliminary results are reported.\nOur findings indicate that the proposed methodology can effectively provide\nhyperparameter configurations that significantly enhance the performance of\nMORL agents. Furthermore, this study identifies various future research\nopportunities to further advance the field of hyperparameter optimization for\nMORL.",
            "author": [
                "Florian Felten",
                "Daniel Gareev",
                "El-Ghazali Talbi",
                "Gr\u00e9goire Danoy"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16487v1",
                "http://arxiv.org/pdf/2310.16487v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16485v1",
            "title": "A Comprehensive Python Library for Deep Learning-Based Event Detection\n  in Multivariate Time Series Data and Information Retrieval in NLP",
            "updated": "2023-10-25T09:13:19Z",
            "published": "2023-10-25T09:13:19Z",
            "summary": "Event detection in time series data is crucial in various domains, including\nfinance, healthcare, cybersecurity, and science. Accurately identifying events\nin time series data is vital for making informed decisions, detecting\nanomalies, and predicting future trends. Despite extensive research exploring\ndiverse methods for event detection in time series, with deep learning\napproaches being among the most advanced, there is still room for improvement\nand innovation in this field. In this paper, we present a new deep learning\nsupervised method for detecting events in multivariate time series data. Our\nmethod combines four distinct novelties compared to existing deep-learning\nsupervised methods. Firstly, it is based on regression instead of binary\nclassification. Secondly, it does not require labeled datasets where each point\nis labeled; instead, it only requires reference events defined as time points\nor intervals of time. Thirdly, it is designed to be robust by using a stacked\nensemble learning meta-model that combines deep learning models, ranging from\nclassic feed-forward neural networks (FFNs) to state-of-the-art architectures\nlike transformers. This ensemble approach can mitigate individual model\nweaknesses and biases, resulting in more robust predictions. Finally, to\nfacilitate practical implementation, we have developed a Python package to\naccompany our proposed method. The package, called eventdetector-ts, can be\ninstalled through the Python Package Index (PyPI). In this paper, we present\nour method and provide a comprehensive guide on the usage of the package. We\nshowcase its versatility and effectiveness through different real-world use\ncases from natural language processing (NLP) to financial security domains.",
            "author": [
                "Menouar Azib",
                "Benjamin Renard",
                "Philippe Garnier",
                "Vincent G\u00e9not",
                "Nicolas Andr\u00e9"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16485v1",
                "http://arxiv.org/pdf/2310.16485v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17671v1",
            "title": "Transfer of Reinforcement Learning-Based Controllers from Model- to\n  Hardware-in-the-Loop",
            "updated": "2023-10-25T09:13:12Z",
            "published": "2023-10-25T09:13:12Z",
            "summary": "The process of developing control functions for embedded systems is\nresource-, time-, and data-intensive, often resulting in sub-optimal cost and\nsolutions approaches. Reinforcement Learning (RL) has great potential for\nautonomously training agents to perform complex control tasks with minimal\nhuman intervention. Due to costly data generation and safety constraints,\nhowever, its application is mostly limited to purely simulated domains. To use\nRL effectively in embedded system function development, the generated agents\nmust be able to handle real-world applications. In this context, this work\nfocuses on accelerating the training process of RL agents by combining Transfer\nLearning (TL) and X-in-the-Loop (XiL) simulation. For the use case of transient\nexhaust gas re-circulation control for an internal combustion engine, use of a\ncomputationally cheap Model-in-the-Loop (MiL) simulation is made to select a\nsuitable algorithm, fine-tune hyperparameters, and finally train candidate\nagents for the transfer. These pre-trained RL agents are then fine-tuned in a\nHardware-in-the-Loop (HiL) system via TL. The transfer revealed the need for\nadjusting the reward parameters when advancing to real hardware. Further, the\ncomparison between a purely HiL-trained and a transferred agent showed a\nreduction of training time by a factor of 5.9. The results emphasize the\nnecessity to train RL agents with real hardware, and demonstrate that the\nmaturity of the transferred policies affects both training time and\nperformance, highlighting the strong synergies between TL and XiL simulation.",
            "author": [
                "Mario Picerno",
                "Lucas Koch",
                "Kevin Badalian",
                "Marius Wegener",
                "Joschka Schaub",
                "Charles Robert Koch",
                "Jakob Andert"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17671v1",
                "http://arxiv.org/pdf/2310.17671v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16484v1",
            "title": "Subspace Chronicles: How Linguistic Information Emerges, Shifts and\n  Interacts during Language Model Training",
            "updated": "2023-10-25T09:09:55Z",
            "published": "2023-10-25T09:09:55Z",
            "summary": "Representational spaces learned via language modeling are fundamental to\nNatural Language Processing (NLP), however there has been limited understanding\nregarding how and when during training various types of linguistic information\nemerge and interact. Leveraging a novel information theoretic probing suite,\nwhich enables direct comparisons of not just task performance, but their\nrepresentational subspaces, we analyze nine tasks covering syntax, semantics\nand reasoning, across 2M pre-training steps and five seeds. We identify\ncritical learning phases across tasks and time, during which subspaces emerge,\nshare information, and later disentangle to specialize. Across these phases,\nsyntactic knowledge is acquired rapidly after 0.5% of full training. Continued\nperformance improvements primarily stem from the acquisition of open-domain\nknowledge, while semantics and reasoning tasks benefit from later boosts to\nlong-range contextualization and higher specialization. Measuring cross-task\nsimilarity further reveals that linguistically related tasks share information\nthroughout training, and do so more during the critical phase of learning than\nbefore or after. Our findings have implications for model interpretability,\nmulti-task learning, and learning from limited data.",
            "author": [
                "Max M\u00fcller-Eberstein",
                "Rob van der Goot",
                "Barbara Plank",
                "Ivan Titov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16484v1",
                "http://arxiv.org/pdf/2310.16484v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16483v1",
            "title": "Gramian Attention Heads are Strong yet Efficient Vision Learners",
            "updated": "2023-10-25T09:08:58Z",
            "published": "2023-10-25T09:08:58Z",
            "summary": "We introduce a novel architecture design that enhances expressiveness by\nincorporating multiple head classifiers (\\ie, classification heads) instead of\nrelying on channel expansion or additional building blocks. Our approach\nemploys attention-based aggregation, utilizing pairwise feature similarity to\nenhance multiple lightweight heads with minimal resource overhead. We compute\nthe Gramian matrices to reinforce class tokens in an attention layer for each\nhead. This enables the heads to learn more discriminative representations,\nenhancing their aggregation capabilities. Furthermore, we propose a learning\nalgorithm that encourages heads to complement each other by reducing\ncorrelation for aggregation. Our models eventually surpass state-of-the-art\nCNNs and ViTs regarding the accuracy-throughput trade-off on ImageNet-1K and\ndeliver remarkable performance across various downstream tasks, such as COCO\nobject instance segmentation, ADE20k semantic segmentation, and fine-grained\nvisual classification datasets. The effectiveness of our framework is\nsubstantiated by practical experimental results and further underpinned by\ngeneralization error bound. We release the code publicly at:\nhttps://github.com/Lab-LVM/imagenet-models.",
            "author": [
                "Jongbin Ryu",
                "Dongyoon Han",
                "Jongwoo Lim"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16483v1",
                "http://arxiv.org/pdf/2310.16483v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12860v1",
            "title": "On the stability, correctness and plausibility of visual explanation\n  methods based on feature importance",
            "updated": "2023-10-25T08:59:21Z",
            "published": "2023-10-25T08:59:21Z",
            "summary": "In the field of Explainable AI, multiples evaluation metrics have been\nproposed in order to assess the quality of explanation methods w.r.t. a set of\ndesired properties. In this work, we study the articulation between the\nstability, correctness and plausibility of explanations based on feature\nimportance for image classifiers. We show that the existing metrics for\nevaluating these properties do not always agree, raising the issue of what\nconstitutes a good evaluation metric for explanations. Finally, in the\nparticular case of stability and correctness, we show the possible limitations\nof some evaluation metrics and propose new ones that take into account the\nlocal behaviour of the model under test.",
            "author": [
                "Romain Xu-Darme",
                "Jenny Benois-Pineau",
                "Romain Giot",
                "Georges Qu\u00e9not",
                "Zakaria Chihani",
                "Marie-Christine Rousset",
                "Alexey Zhukov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12860v1",
                "http://arxiv.org/pdf/2311.12860v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16477v1",
            "title": "Show from Tell: Audio-Visual Modelling in Clinical Settings",
            "updated": "2023-10-25T08:55:48Z",
            "published": "2023-10-25T08:55:48Z",
            "summary": "Auditory and visual signals usually present together and correlate with each\nother, not only in natural environments but also in clinical settings. However,\nthe audio-visual modelling in the latter case can be more challenging, due to\nthe different sources of audio/video signals and the noise (both signal-level\nand semantic-level) in auditory signals -- usually speech. In this paper, we\nconsider audio-visual modelling in a clinical setting, providing a solution to\nlearn medical representations that benefit various clinical tasks, without\nhuman expert annotation. A simple yet effective multi-modal self-supervised\nlearning framework is proposed for this purpose. The proposed approach is able\nto localise anatomical regions of interest during ultrasound imaging, with only\nspeech audio as a reference. Experimental evaluations on a large-scale clinical\nmulti-modal ultrasound video dataset show that the proposed self-supervised\nmethod learns good transferable anatomical representations that boost the\nperformance of automated downstream clinical tasks, even outperforming\nfully-supervised solutions.",
            "author": [
                "Jianbo Jiao",
                "Mohammad Alsharid",
                "Lior Drukker",
                "Aris T. Papageorghiou",
                "Andrew Zisserman",
                "J. Alison Noble"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16477v1",
                "http://arxiv.org/pdf/2310.16477v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16473v1",
            "title": "Symphony of experts: orchestration with adversarial insights in\n  reinforcement learning",
            "updated": "2023-10-25T08:53:51Z",
            "published": "2023-10-25T08:53:51Z",
            "summary": "Structured reinforcement learning leverages policies with advantageous\nproperties to reach better performance, particularly in scenarios where\nexploration poses challenges. We explore this field through the concept of\norchestration, where a (small) set of expert policies guides decision-making;\nthe modeling thereof constitutes our first contribution. We then establish\nvalue-functions regret bounds for orchestration in the tabular setting by\ntransferring regret-bound results from adversarial settings. We generalize and\nextend the analysis of natural policy gradient in Agarwal et al. [2021, Section\n5.3] to arbitrary adversarial aggregation strategies. We also extend it to the\ncase of estimated advantage functions, providing insights into sample\ncomplexity both in expectation and high probability. A key point of our\napproach lies in its arguably more transparent proofs compared to existing\nmethods. Finally, we present simulations for a stochastic matching toy model.",
            "author": [
                "Matthieu Jonckheere",
                "Chiara Mignacco",
                "Gilles Stoltz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16473v1",
                "http://arxiv.org/pdf/2310.16473v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16466v1",
            "title": "Learning Continuous Network Emerging Dynamics from Scarce Observations\n  via Data-Adaptive Stochastic Processes",
            "updated": "2023-10-25T08:44:05Z",
            "published": "2023-10-25T08:44:05Z",
            "summary": "Learning network dynamics from the empirical structure and spatio-temporal\nobservation data is crucial to revealing the interaction mechanisms of complex\nnetworks in a wide range of domains. However, most existing methods only aim at\nlearning network dynamic behaviors generated by a specific ordinary\ndifferential equation instance, resulting in ineffectiveness for new ones, and\ngenerally require dense observations. The observed data, especially from\nnetwork emerging dynamics, are usually difficult to obtain, which brings\ntrouble to model learning. Therefore, how to learn accurate network dynamics\nwith sparse, irregularly-sampled, partial, and noisy observations remains a\nfundamental challenge. We introduce Neural ODE Processes for Network Dynamics\n(NDP4ND), a new class of stochastic processes governed by stochastic\ndata-adaptive network dynamics, to overcome the challenge and learn continuous\nnetwork dynamics from scarce observations. Intensive experiments conducted on\nvarious network dynamics in ecological population evolution, phototaxis\nmovement, brain activity, epidemic spreading, and real-world empirical systems,\ndemonstrate that the proposed method has excellent data adaptability and\ncomputational efficiency, and can adapt to unseen network emerging dynamics,\nproducing accurate interpolation and extrapolation with reducing the ratio of\nrequired observation data to only about 6\\% and improving the learning speed\nfor new dynamics by three orders of magnitude.",
            "author": [
                "Jiaxu Cui",
                "Bingyi Sun",
                "Jiming Liu",
                "Bo Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16466v1",
                "http://arxiv.org/pdf/2310.16466v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16459v1",
            "title": "DualMatch: Robust Semi-Supervised Learning with Dual-Level Interaction",
            "updated": "2023-10-25T08:34:05Z",
            "published": "2023-10-25T08:34:05Z",
            "summary": "Semi-supervised learning provides an expressive framework for exploiting\nunlabeled data when labels are insufficient. Previous semi-supervised learning\nmethods typically match model predictions of different data-augmented views in\na single-level interaction manner, which highly relies on the quality of\npseudo-labels and results in semi-supervised learning not robust. In this\npaper, we propose a novel SSL method called DualMatch, in which the class\nprediction jointly invokes feature embedding in a dual-level interaction\nmanner. DualMatch requires consistent regularizations for data augmentation,\nspecifically, 1) ensuring that different augmented views are regulated with\nconsistent class predictions, and 2) ensuring that different data of one class\nare regulated with similar feature embeddings. Extensive experiments\ndemonstrate the effectiveness of DualMatch. In the standard SSL setting, the\nproposal achieves 9% error reduction compared with SOTA methods, even in a more\nchallenging class-imbalanced setting, the proposal can still achieve 6% error\nreduction. Code is available at https://github.com/CWangAI/DualMatch",
            "author": [
                "Cong Wang",
                "Xiaofeng Cao",
                "Lanzhe Guo2",
                "Zenglin Shi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16459v1",
                "http://arxiv.org/pdf/2310.16459v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16457v1",
            "title": "Towards Explainability in Monocular Depth Estimation",
            "updated": "2023-10-25T08:31:04Z",
            "published": "2023-10-25T08:31:04Z",
            "summary": "The estimation of depth in two-dimensional images has long been a challenging\nand extensively studied subject in computer vision. Recently, significant\nprogress has been made with the emergence of Deep Learning-based approaches,\nwhich have proven highly successful. This paper focuses on the explainability\nin monocular depth estimation methods, in terms of how humans perceive depth.\nThis preliminary study emphasizes on one of the most significant visual cues,\nthe relative size, which is prominent in almost all viewed images. We designed\na specific experiment to mimic the experiments in humans and have tested\nstate-of-the-art methods to indirectly assess the explainability in the context\ndefined. In addition, we observed that measuring the accuracy required further\nattention and a particular approach is proposed to this end. The results show\nthat a mean accuracy of around 77% across methods is achieved, with some of the\nmethods performing markedly better, thus, indirectly revealing their\ncorresponding potential to uncover monocular depth cues, like relative size.",
            "author": [
                "Vasileios Arampatzakis",
                "George Pavlidis",
                "Kyriakos Pantoglou",
                "Nikolaos Mitianoudis",
                "Nikos Papamarkos"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16457v1",
                "http://arxiv.org/pdf/2310.16457v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17670v1",
            "title": "Unknown Health States Recognition With Collective Decision Based Deep\n  Learning Networks In Predictive Maintenance Applications",
            "updated": "2023-10-25T08:24:48Z",
            "published": "2023-10-25T08:24:48Z",
            "summary": "At present, decision making solutions developed based on deep learning (DL)\nmodels have received extensive attention in predictive maintenance (PM)\napplications along with the rapid improvement of computing power. Relying on\nthe superior properties of shared weights and spatial pooling, Convolutional\nNeural Network (CNN) can learn effective representations of health states from\nindustrial data. Many developed CNN-based schemes, such as advanced CNNs that\nintroduce residual learning and multi-scale learning, have shown good\nperformance in health state recognition tasks under the assumption that all the\nclasses are known. However, these schemes have no ability to deal with new\nabnormal samples that belong to state classes not part of the training set. In\nthis paper, a collective decision framework for different CNNs is proposed. It\nis based on a One-vs-Rest network (OVRN) to simultaneously achieve\nclassification of known and unknown health states. OVRN learn state-specific\ndiscriminative features and enhance the ability to reject new abnormal samples\nincorporated to different CNNs. According to the validation results on the\npublic dataset of Tennessee Eastman Process (TEP), the proposed CNN-based\ndecision schemes incorporating OVRN have outstanding recognition ability for\nsamples of unknown heath states, while maintaining satisfactory accuracy on\nknown states. The results show that the new DL framework outperforms\nconventional CNNs, and the one based on residual and multi-scale learning has\nthe best overall performance.",
            "author": [
                "Chuyue Lou",
                "M. Amine Atoui"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17670v1",
                "http://arxiv.org/pdf/2310.17670v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12859v1",
            "title": "Joint Multi-View Collaborative Clustering",
            "updated": "2023-10-25T08:23:45Z",
            "published": "2023-10-25T08:23:45Z",
            "summary": "Data is increasingly being collected from multiple sources and described by\nmultiple views. These multi-view data provide richer information than\ntraditional single-view data. Fusing the former for specific tasks is an\nessential component of multi-view clustering. Since the goal of multi-view\nclustering algorithms is to discover the common latent structure shared by\nmultiple views, the majority of proposed solutions overlook the advantages of\nincorporating knowledge derived from horizontal collaboration between\nmulti-view data and the final consensus. To fill this gap, we propose the Joint\nMulti-View Collaborative Clustering (JMVCC) solution, which involves the\ngeneration of basic partitions using Non-negative Matrix Factorization (NMF)\nand the horizontal collaboration principle, followed by the fusion of these\nlocal partitions using ensemble clustering. Furthermore, we propose a weighting\nmethod to reduce the risk of negative collaboration (i.e., views with low\nquality) during the generation and fusion of local partitions. The experimental\nresults, which were obtained using a variety of data sets, demonstrate that\nJMVCC outperforms other multi-view clustering algorithms and is robust to noisy\nviews.",
            "author": [
                "Yasser Khalafaoui",
                "Basarab Matei",
                "Nistor Grozavu",
                "Martino Lovisetto"
            ],
            "link": [
                "http://dx.doi.org/10.1109/IJCNN54540.2023.10192014",
                "http://arxiv.org/abs/2311.12859v1",
                "http://arxiv.org/pdf/2311.12859v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16453v1",
            "title": "ClearMark: Intuitive and Robust Model Watermarking via Transposed Model\n  Training",
            "updated": "2023-10-25T08:16:55Z",
            "published": "2023-10-25T08:16:55Z",
            "summary": "Due to costly efforts during data acquisition and model training, Deep Neural\nNetworks (DNNs) belong to the intellectual property of the model creator.\nHence, unauthorized use, theft, or modification may lead to legal\nrepercussions. Existing DNN watermarking methods for ownership proof are often\nnon-intuitive, embed human-invisible marks, require trust in algorithmic\nassessment that lacks human-understandable attributes, and rely on rigid\nthresholds, making it susceptible to failure in cases of partial watermark\nerasure.\n  This paper introduces ClearMark, the first DNN watermarking method designed\nfor intuitive human assessment. ClearMark embeds visible watermarks, enabling\nhuman decision-making without rigid value thresholds while allowing\ntechnology-assisted evaluations. ClearMark defines a transposed model\narchitecture allowing to use of the model in a backward fashion to interwove\nthe watermark with the main task within all model parameters. Compared to\nexisting watermarking methods, ClearMark produces visual watermarks that are\neasy for humans to understand without requiring complex verification algorithms\nor strict thresholds. The watermark is embedded within all model parameters and\nentangled with the main task, exhibiting superior robustness. It shows an\n8,544-bit watermark capacity comparable to the strongest existing work.\nCrucially, ClearMark's effectiveness is model and dataset-agnostic, and\nresilient against adversarial model manipulations, as demonstrated in a\ncomprehensive study performed with four datasets and seven architectures.",
            "author": [
                "Torsten Krau\u00df",
                "Jasper Stang",
                "Alexandra Dmitrienko"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16453v1",
                "http://arxiv.org/pdf/2310.16453v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16452v2",
            "title": "Faithful Path Language Modelling for Explainable Recommendation over\n  Knowledge Graph",
            "updated": "2023-11-12T22:38:04Z",
            "published": "2023-10-25T08:14:49Z",
            "summary": "Path reasoning methods over knowledge graphs have gained popularity for their\npotential to improve transparency in recommender systems. However, the\nresulting models still rely on pre-trained knowledge graph embeddings, fail to\nfully exploit the interdependence between entities and relations in the KG for\nrecommendation, and may generate inaccurate explanations. In this paper, we\nintroduce PEARLM, a novel approach that efficiently captures user behaviour and\nproduct-side knowledge through language modelling. With our approach, knowledge\ngraph embeddings are directly learned from paths over the KG by the language\nmodel, which also unifies entities and relations in the same optimisation\nspace. Constraints on the sequence decoding additionally guarantee path\nfaithfulness with respect to the KG. Experiments on two datasets show the\neffectiveness of our approach compared to state-of-the-art baselines. Source\ncode and datasets: AVAILABLE AFTER GETTING ACCEPTED.",
            "author": [
                "Giacomo Balloccu",
                "Ludovico Boratto",
                "Christian Cancedda",
                "Gianni Fenu",
                "Mirko Marras"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16452v2",
                "http://arxiv.org/pdf/2310.16452v2"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16446v1",
            "title": "Diversity Enhanced Narrative Question Generation for Storybooks",
            "updated": "2023-10-25T08:10:04Z",
            "published": "2023-10-25T08:10:04Z",
            "summary": "Question generation (QG) from a given context can enhance comprehension,\nengagement, assessment, and overall efficacy in learning or conversational\nenvironments. Despite recent advancements in QG, the challenge of enhancing or\nmeasuring the diversity of generated questions often remains unaddressed. In\nthis paper, we introduce a multi-question generation model (mQG), which is\ncapable of generating multiple, diverse, and answerable questions by focusing\non context and questions. To validate the answerability of the generated\nquestions, we employ a SQuAD2.0 fine-tuned question answering model,\nclassifying the questions as answerable or not. We train and evaluate mQG on\nthe FairytaleQA dataset, a well-structured QA dataset based on storybooks, with\nnarrative questions. We further apply a zero-shot adaptation on the TellMeWhy\nand SQuAD1.1 datasets. mQG shows promising results across various evaluation\nmetrics, among strong baselines.",
            "author": [
                "Hokeun Yoon",
                "JinYeong Bak"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16446v1",
                "http://arxiv.org/pdf/2310.16446v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16444v1",
            "title": "How can neuromorphic hardware attain brain-like functional capabilities?",
            "updated": "2023-10-25T08:09:52Z",
            "published": "2023-10-25T08:09:52Z",
            "summary": "Research on neuromorphic computing is driven by the vision that we can\nemulate brain-like computing capability, learning capability, and\nenergy-efficiency in novel hardware. Unfortunately, this vision has so far been\npursued in a half-hearted manner. Most current neuromorphic hardware (NMHW)\nemploys brain-like spiking neurons instead of standard artificial neurons. This\nis a good first step, which does improve the energy-efficiency of some\ncomputations, see \\citep{rao2022long} for one of many examples. But current\narchitectures and training methods for networks of spiking neurons in NMHW are\nlargely copied from artificial neural networks. Hence it is not surprising that\nthey inherit many deficiencies of artificial neural networks, rather than\nattaining brain-like functional capabilities.\n  Of course, the brain is very complex, and we cannot implement all its details\nin NMHW. Instead, we need to focus on principles that are both easy to\nimplement in NMHW and are likely to support brain-like functionality. The goal\nof this article is to highlight some of them.",
            "author": [
                "Wolfgang Maass"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16444v1",
                "http://arxiv.org/pdf/2310.16444v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16441v1",
            "title": "Grokking in Linear Estimators -- A Solvable Model that Groks without\n  Understanding",
            "updated": "2023-10-25T08:08:44Z",
            "published": "2023-10-25T08:08:44Z",
            "summary": "Grokking is the intriguing phenomenon where a model learns to generalize long\nafter it has fit the training data. We show both analytically and numerically\nthat grokking can surprisingly occur in linear networks performing linear tasks\nin a simple teacher-student setup with Gaussian inputs. In this setting, the\nfull training dynamics is derived in terms of the training and generalization\ndata covariance matrix. We present exact predictions on how the grokking time\ndepends on input and output dimensionality, train sample size, regularization,\nand network initialization. We demonstrate that the sharp increase in\ngeneralization accuracy may not imply a transition from \"memorization\" to\n\"understanding\", but can simply be an artifact of the accuracy measure. We\nprovide empirical verification for our calculations, along with preliminary\nresults indicating that some predictions also hold for deeper networks, with\nnon-linear activations.",
            "author": [
                "Noam Levi",
                "Alon Beck",
                "Yohai Bar-Sinai"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16441v1",
                "http://arxiv.org/pdf/2310.16441v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cond-mat.dis-nn",
                "cs.LG",
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17669v1",
            "title": "An Approach for Efficient Neural Architecture Search Space Definition",
            "updated": "2023-10-25T08:07:29Z",
            "published": "2023-10-25T08:07:29Z",
            "summary": "As we advance in the fast-growing era of Machine Learning, various new and\nmore complex neural architectures are arising to tackle problem more\nefficiently. On the one hand their efficient usage requires advanced knowledge\nand expertise, which is most of the time difficult to find on the labor market.\nOn the other hand, searching for an optimized neural architecture is a\ntime-consuming task when it is performed manually using a trial and error\napproach. Hence, a method and a tool support is needed to assist users of\nneural architectures, leading to an eagerness in the field of Automatic Machine\nLearning (AutoML). When it comes to Deep Learning, an important part of AutoML\nis the Neural Architecture Search (NAS). In this paper, we propose a novel\ncell-based hierarchical search space, easy to comprehend and manipulate. The\nobjectives of the proposed approach are to optimize the search-time and to be\ngeneral enough to handle most of state of the art Convolutional Neural Networks\n(CNN) architectures.",
            "author": [
                "L\u00e9o Pouy",
                "Fouad Khenfri",
                "Patrick Leserf",
                "Chokri Mraidha",
                "Cherif Larouci"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17669v1",
                "http://arxiv.org/pdf/2310.17669v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16437v1",
            "title": "Non-isotropic Persistent Homology: Leveraging the Metric Dependency of\n  PH",
            "updated": "2023-10-25T08:03:17Z",
            "published": "2023-10-25T08:03:17Z",
            "summary": "Persistent Homology is a widely used topological data analysis tool that\ncreates a concise description of the topological properties of a point cloud\nbased on a specified filtration. Most filtrations used for persistent homology\ndepend (implicitly) on a chosen metric, which is typically agnostically chosen\nas the standard Euclidean metric on $\\mathbb{R}^n$. Recent work has tried to\nuncover the 'true' metric on the point cloud using distance-to-measure\nfunctions, in order to obtain more meaningful persistent homology results. Here\nwe propose an alternative look at this problem: we posit that information on\nthe point cloud is lost when restricting persistent homology to a single\n(correct) distance function. Instead, we show how by varying the distance\nfunction on the underlying space and analysing the corresponding shifts in the\npersistence diagrams, we can extract additional topological and geometrical\ninformation. Finally, we numerically show that non-isotropic persistent\nhomology can extract information on orientation, orientational variance, and\nscaling of randomly generated point clouds with good accuracy and conduct some\nexperiments on real-world data.",
            "author": [
                "Vincent P. Grande",
                "Michael T. Schaub"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16437v1",
                "http://arxiv.org/pdf/2310.16437v1"
            ],
            "primary_category": "math.AT",
            "category": [
                "math.AT",
                "cs.CG",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16436v2",
            "title": "DDCoT: Duty-Distinct Chain-of-Thought Prompting for Multimodal Reasoning\n  in Language Models",
            "updated": "2023-10-26T04:16:52Z",
            "published": "2023-10-25T08:03:10Z",
            "summary": "A long-standing goal of AI systems is to perform complex multimodal reasoning\nlike humans. Recently, large language models (LLMs) have made remarkable\nstrides in such multi-step reasoning on the language modality solely by\nleveraging the chain of thought (CoT) to mimic human thinking. However, the\ntransfer of these advancements to multimodal contexts introduces heightened\nchallenges, including but not limited to the impractical need for\nlabor-intensive annotation and the limitations in terms of flexibility,\ngeneralizability, and explainability. To evoke CoT reasoning in multimodality,\nthis work first conducts an in-depth analysis of these challenges posed by\nmultimodality and presents two key insights: \"keeping critical thinking\" and\n\"letting everyone do their jobs\" in multimodal CoT reasoning. Furthermore, this\nstudy proposes a novel DDCoT prompting that maintains a critical attitude\nthrough negative-space prompting and incorporates multimodality into reasoning\nby first dividing the reasoning responsibility of LLMs into reasoning and\nrecognition and then integrating the visual recognition capability of visual\nmodels into the joint reasoning process. The rationales generated by DDCoT not\nonly improve the reasoning abilities of both large and small language models in\nzero-shot prompting and fine-tuning learning, significantly outperforming\nstate-of-the-art methods but also exhibit impressive generalizability and\nexplainability.",
            "author": [
                "Ge Zheng",
                "Bin Yang",
                "Jiajin Tang",
                "Hong-Yu Zhou",
                "Sibei Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16436v2",
                "http://arxiv.org/pdf/2310.16436v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16431v1",
            "title": "An experimental protocol to access immersiveness in video games",
            "updated": "2023-10-25T07:57:50Z",
            "published": "2023-10-25T07:57:50Z",
            "summary": "In the video game industry, great importance is given to the experience that\nthe user has while playing a game. In particular, this experience benefits from\nthe players' perceived sense of being in the game or immersion. The level of\nuser immersion depends not only on the game's content but also on how the game\nis displayed, thus on its User Interface (UI) and the Head's-Up Display (HUD).\nAnother factor influencing immersiveness that has been found in the literature\nis the player's expertise: the more experience the user has with a specific\ngame, the less they need information on the screen to be immersed in the game.\nPlayer's level of immersion can be accessed by using both questionnaires of\ntheir perceived experience and exploiting their behavioural and physiological\nresponses while playing the target game. Therefore, in this paper, we propose\nan experimental protocol to access immersiveness of gamers while playing a\nthird-person shooter (Fortnite) with UIs with a standard, a dietetic, and a\nproposed HUD. A subjective evaluation of the immersion will be provided by\ncompleting the Immersive Experience Questionnaire (IEQ), while objective\nindicators will be provided by face tracking, behaviour and physiological\nresponses analyses. The ultimate goal of this study is to define guidelines for\nvideo game UI development that can enhance the players' immersion.",
            "author": [
                "Marika Malaspina",
                "Jessica Amianto Barbato",
                "Marco Cremaschi",
                "Francesca Gasparini",
                "Alessandra Grossi",
                "Aurora Saibene"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16431v1",
                "http://arxiv.org/pdf/2310.16431v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16430v1",
            "title": "An Integrative Paradigm for Enhanced Stroke Prediction: Synergizing\n  XGBoost and xDeepFM Algorithms",
            "updated": "2023-10-25T07:55:02Z",
            "published": "2023-10-25T07:55:02Z",
            "summary": "Stroke prediction plays a crucial role in preventing and managing this\ndebilitating condition. In this study, we address the challenge of stroke\nprediction using a comprehensive dataset, and propose an ensemble model that\ncombines the power of XGBoost and xDeepFM algorithms. Our work aims to improve\nupon existing stroke prediction models by achieving higher accuracy and\nrobustness. Through rigorous experimentation, we validate the effectiveness of\nour ensemble model using the AUC metric. Through comparing our findings with\nthose of other models in the field, we gain valuable insights into the merits\nand drawbacks of various approaches. This, in turn, contributes significantly\nto the progress of machine learning and deep learning techniques specifically\nin the domain of stroke prediction.",
            "author": [
                "Weinan Dai",
                "Yifeng Jiang",
                "Chengjie Mou",
                "Chongyu Zhang"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3627377.3627382",
                "http://arxiv.org/abs/2310.16430v1",
                "http://arxiv.org/pdf/2310.16430v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16428v1",
            "title": "Similarity-driven and Task-driven Models for Diversity of Opinion in\n  Crowdsourcing Markets",
            "updated": "2023-10-25T07:50:57Z",
            "published": "2023-10-25T07:50:57Z",
            "summary": "The recent boom in crowdsourcing has opened up a new avenue for utilizing\nhuman intelligence in the realm of data analysis. This innovative approach\nprovides a powerful means for connecting online workers to tasks that cannot\neffectively be done solely by machines or conducted by professional experts due\nto cost constraints. Within the field of social science, four elements are\nrequired to construct a sound crowd - Diversity of Opinion, Independence,\nDecentralization and Aggregation. However, while the other three components\nhave already been investigated and implemented in existing crowdsourcing\nplatforms, 'Diversity of Opinion' has not been functionally enabled yet. From a\ncomputational point of view, constructing a wise crowd necessitates\nquantitatively modeling and taking diversity into account. There are usually\ntwo paradigms in a crowdsourcing marketplace for worker selection: building a\ncrowd to wait for tasks to come and selecting workers for a given task. We\npropose similarity-driven and task-driven models for both paradigms. Also, we\ndevelop efficient and effective algorithms for recruiting a limited number of\nworkers with optimal diversity in both models. To validate our solutions, we\nconduct extensive experiments using both synthetic datasets and real data sets.",
            "author": [
                "Chen Jason Zhang",
                "Yunrui Liu",
                "Pengcheng Zeng",
                "Ting Wu",
                "Lei Chen",
                "Pan Hui",
                "Fei Hao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16428v1",
                "http://arxiv.org/pdf/2310.16428v1"
            ],
            "primary_category": "stat.AP",
            "category": [
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16419v1",
            "title": "Open Knowledge Base Canonicalization with Multi-task Unlearning",
            "updated": "2023-10-25T07:13:06Z",
            "published": "2023-10-25T07:13:06Z",
            "summary": "The construction of large open knowledge bases (OKBs) is integral to many\napplications in the field of mobile computing. Noun phrases and relational\nphrases in OKBs often suffer from redundancy and ambiguity, which calls for the\ninvestigation on OKB canonicalization. However, in order to meet the\nrequirements of some privacy protection regulations and to ensure the\ntimeliness of the data, the canonicalized OKB often needs to remove some\nsensitive information or outdated data. The machine unlearning in OKB\ncanonicalization is an excellent solution to the above problem. Current\nsolutions address OKB canonicalization by devising advanced clustering\nalgorithms and using knowledge graph embedding (KGE) to further facilitate the\ncanonicalization process. Effective schemes are urgently needed to fully\nsynergise machine unlearning with clustering and KGE learning. To this end, we\nput forward a multi-task unlearning framework, namely MulCanon, to tackle\nmachine unlearning problem in OKB canonicalization. Specifically, the noise\ncharacteristics in the diffusion model are utilized to achieve the effect of\nmachine unlearning for data in OKB. MulCanon unifies the learning objectives of\ndiffusion model, KGE and clustering algorithms, and adopts a two-step\nmulti-task learning paradigm for training. A thorough experimental study on\npopular OKB canonicalization datasets validates that MulCanon achieves advanced\nmachine unlearning effects.",
            "author": [
                "Bingchen Liu",
                "Shihao Hou",
                "Weixin Zeng",
                "Xiang Zhao",
                "Shijun Liu",
                "Li Pan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16419v1",
                "http://arxiv.org/pdf/2310.16419v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16417v1",
            "title": "Enhanced Simultaneous Machine Translation with Word-level Policies",
            "updated": "2023-10-25T07:10:42Z",
            "published": "2023-10-25T07:10:42Z",
            "summary": "Recent years have seen remarkable advances in the field of Simultaneous\nMachine Translation (SiMT) due to the introduction of innovative policies that\ndictate whether to READ or WRITE at each step of the translation process.\nHowever, a common assumption in many existing studies is that operations are\ncarried out at the subword level, even though the standard unit for input and\noutput in most practical scenarios is typically at the word level. This paper\ndemonstrates that policies devised and validated at the subword level are\nsurpassed by those operating at the word level, which process multiple subwords\nto form a complete word in a single step. Additionally, we suggest a method to\nboost SiMT models using language models (LMs), wherein the proposed word-level\npolicy plays a vital role in addressing the subword disparity between LMs and\nSiMT models. Code is available at https://github.com/xl8-ai/WordSiMT.",
            "author": [
                "Kang Kim",
                "Hankyu Cho"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16417v1",
                "http://arxiv.org/pdf/2310.16417v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16412v1",
            "title": "FlatMatch: Bridging Labeled Data and Unlabeled Data with Cross-Sharpness\n  for Semi-Supervised Learning",
            "updated": "2023-10-25T06:57:59Z",
            "published": "2023-10-25T06:57:59Z",
            "summary": "Semi-Supervised Learning (SSL) has been an effective way to leverage abundant\nunlabeled data with extremely scarce labeled data. However, most SSL methods\nare commonly based on instance-wise consistency between different data\ntransformations. Therefore, the label guidance on labeled data is hard to be\npropagated to unlabeled data. Consequently, the learning process on labeled\ndata is much faster than on unlabeled data which is likely to fall into a local\nminima that does not favor unlabeled data, leading to sub-optimal\ngeneralization performance. In this paper, we propose FlatMatch which minimizes\na cross-sharpness measure to ensure consistent learning performance between the\ntwo datasets. Specifically, we increase the empirical risk on labeled data to\nobtain a worst-case model which is a failure case that needs to be enhanced.\nThen, by leveraging the richness of unlabeled data, we penalize the prediction\ndifference (i.e., cross-sharpness) between the worst-case model and the\noriginal model so that the learning direction is beneficial to generalization\non unlabeled data. Therefore, we can calibrate the learning process without\nbeing limited to insufficient label information. As a result, the mismatched\nlearning performance can be mitigated, further enabling the effective\nexploitation of unlabeled data and improving SSL performance. Through\ncomprehensive validation, we show FlatMatch achieves state-of-the-art results\nin many SSL settings.",
            "author": [
                "Zhuo Huang",
                "Li Shen",
                "Jun Yu",
                "Bo Han",
                "Tongliang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16412v1",
                "http://arxiv.org/pdf/2310.16412v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "Machine Learning"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16410v1",
            "title": "Bridging the Human-AI Knowledge Gap: Concept Discovery and Transfer in\n  AlphaZero",
            "updated": "2023-10-25T06:49:26Z",
            "published": "2023-10-25T06:49:26Z",
            "summary": "Artificial Intelligence (AI) systems have made remarkable progress, attaining\nsuper-human performance across various domains. This presents us with an\nopportunity to further human knowledge and improve human expert performance by\nleveraging the hidden knowledge encoded within these highly performant AI\nsystems. Yet, this knowledge is often hard to extract, and may be hard to\nunderstand or learn from. Here, we show that this is possible by proposing a\nnew method that allows us to extract new chess concepts in AlphaZero, an AI\nsystem that mastered the game of chess via self-play without human supervision.\nOur analysis indicates that AlphaZero may encode knowledge that extends beyond\nthe existing human knowledge, but knowledge that is ultimately not beyond human\ngrasp, and can be successfully learned from. In a human study, we show that\nthese concepts are learnable by top human experts, as four top chess\ngrandmasters show improvements in solving the presented concept prototype\npositions. This marks an important first milestone in advancing the frontier of\nhuman knowledge by leveraging AI; a development that could bear profound\nimplications and help us shape how we interact with AI systems across many AI\napplications.",
            "author": [
                "Lisa Schut",
                "Nenad Tomasev",
                "Tom McGrath",
                "Demis Hassabis",
                "Ulrich Paquet",
                "Been Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16410v1",
                "http://arxiv.org/pdf/2310.16410v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.HC",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16409v1",
            "title": "Multiple Key-value Strategy in Recommendation Systems Incorporating\n  Large Language Model",
            "updated": "2023-10-25T06:49:19Z",
            "published": "2023-10-25T06:49:19Z",
            "summary": "Recommendation system (RS) plays significant roles in matching users\ninformation needs for Internet applications, and it usually utilizes the\nvanilla neural network as the backbone to handle embedding details. Recently,\nthe large language model (LLM) has exhibited emergent abilities and achieved\ngreat breakthroughs both in the CV and NLP communities. Thus, it is logical to\nincorporate RS with LLM better, which has become an emerging research\ndirection. Although some existing works have made their contributions to this\nissue, they mainly consider the single key situation (e.g. historical\ninteractions), especially in sequential recommendation. The situation of\nmultiple key-value data is simply neglected. This significant scenario is\nmainstream in real practical applications, where the information of users (e.g.\nage, occupation, etc) and items (e.g. title, category, etc) has more than one\nkey. Therefore, we aim to implement sequential recommendations based on\nmultiple key-value data by incorporating RS with LLM. In particular, we\ninstruct tuning a prevalent open-source LLM (Llama 7B) in order to inject\ndomain knowledge of RS into the pre-trained LLM. Since we adopt multiple\nkey-value strategies, LLM is hard to learn well among these keys. Thus the\ngeneral and innovative shuffle and mask strategies, as an innovative manner of\ndata argument, are designed. To demonstrate the effectiveness of our approach,\nextensive experiments are conducted on the popular and suitable dataset\nMovieLens which contains multiple keys-value. The experimental results\ndemonstrate that our approach can nicely and effectively complete this\nchallenging issue.",
            "author": [
                "Dui Wang",
                "Xiangyu Hou",
                "Xiaohui Yang",
                "Bo Zhang",
                "Renbing Chen",
                "Daiyue Xue"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16409v1",
                "http://arxiv.org/pdf/2310.16409v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16407v1",
            "title": "Information-Theoretic Generalization Analysis for Topology-aware\n  Heterogeneous Federated Edge Learning over Noisy Channels",
            "updated": "2023-10-25T06:46:48Z",
            "published": "2023-10-25T06:46:48Z",
            "summary": "With the rapid growth of edge intelligence, the deployment of federated\nlearning (FL) over wireless networks has garnered increasing attention, which\nis called Federated Edge Learning (FEEL). In FEEL, both mobile devices\ntransmitting model parameters over noisy channels and collecting data in\ndiverse environments pose challenges to the generalization of trained models.\nMoreover, devices can engage in decentralized FL via Device-to-Device\ncommunication while the communication topology of connected devices also\nimpacts the generalization of models. Most recent theoretical studies overlook\nthe incorporation of all these effects into FEEL when developing generalization\nanalyses. In contrast, our work presents an information-theoretic\ngeneralization analysis for topology-aware FEEL in the presence of data\nheterogeneity and noisy channels. Additionally, we propose a novel\nregularization method called Federated Global Mutual Information Reduction\n(FedGMIR) to enhance the performance of models based on our analysis. Numerical\nresults validate our theoretical findings and provide evidence for the\neffectiveness of the proposed method.",
            "author": [
                "Zheshun Wu",
                "Zenglin Xu",
                "Hongfang Yu",
                "Jie Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16407v1",
                "http://arxiv.org/pdf/2310.16407v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.LG",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16406v1",
            "title": "Challenges of Radio Frequency Fingerprinting: From Data Collection to\n  Deployment",
            "updated": "2023-10-25T06:45:49Z",
            "published": "2023-10-25T06:45:49Z",
            "summary": "Radio Frequency Fingerprinting (RFF) techniques promise to authenticate\nwireless devices at the physical layer based on inherent hardware imperfections\nintroduced during manufacturing. Such RF transmitter imperfections are\nreflected into over-the-air signals, allowing receivers to accurately identify\nthe RF transmitting source. Recent advances in Machine Learning, particularly\nin Deep Learning (DL), have improved the ability of RFF systems to extract and\nlearn complex features that make up the device-specific fingerprint. However,\nintegrating DL techniques with RFF and operating the system in real-world\nscenarios presents numerous challenges. This article identifies and analyzes\nthese challenges while considering the three reference phases of any DL-based\nRFF system: (i) data collection and preprocessing, (ii) training, and finally,\n(iii) deployment. Our investigation points out the current open problems that\nprevent real deployment of RFF while discussing promising future directions,\nthus paving the way for further research in the area.",
            "author": [
                "Saeif Alhazbi",
                "Ahmed Hussain",
                "Savio Sciancalepore",
                "Gabriele Oligeri",
                "Panos Papadimitratos"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16406v1",
                "http://arxiv.org/pdf/2310.16406v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16405v1",
            "title": "Binary State Recognition by Robots using Visual Question Answering of\n  Pre-Trained Vision-Language Model",
            "updated": "2023-10-25T06:44:22Z",
            "published": "2023-10-25T06:44:22Z",
            "summary": "Recognition of the current state is indispensable for the operation of a\nrobot. There are various states to be recognized, such as whether an elevator\ndoor is open or closed, whether an object has been grasped correctly, and\nwhether the TV is turned on or off. Until now, these states have been\nrecognized by programmatically describing the state of a point cloud or raw\nimage, by annotating and learning images, by using special sensors, etc. In\ncontrast to these methods, we apply Visual Question Answering (VQA) from a\nPre-Trained Vision-Language Model (PTVLM) trained on a large-scale dataset, to\nsuch binary state recognition. This idea allows us to intuitively describe\nstate recognition in language without any re-training, thereby improving the\nrecognition ability of robots in a simple and general way. We summarize various\ntechniques in questioning methods and image processing, and clarify their\nproperties through experiments.",
            "author": [
                "Kento Kawaharazuka",
                "Yoshiki Obinata",
                "Naoaki Kanazawa",
                "Kei Okada",
                "Masayuki Inaba"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16405v1",
                "http://arxiv.org/pdf/2310.16405v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16401v2",
            "title": "Graph Neural Networks with a Distribution of Parametrized Graphs",
            "updated": "2023-10-28T14:14:19Z",
            "published": "2023-10-25T06:38:24Z",
            "summary": "Traditionally, graph neural networks have been trained using a single\nobserved graph. However, the observed graph represents only one possible\nrealization. In many applications, the graph may encounter uncertainties, such\nas having erroneous or missing edges, as well as edge weights that provide\nlittle informative value. To address these challenges and capture additional\ninformation previously absent in the observed graph, we introduce latent\nvariables to parameterize and generate multiple graphs. We obtain the maximum\nlikelihood estimate of the network parameters in an Expectation-Maximization\n(EM) framework based on the multiple graphs. Specifically, we iteratively\ndetermine the distribution of the graphs using a Markov Chain Monte Carlo\n(MCMC) method, incorporating the principles of PAC-Bayesian theory. Numerical\nexperiments demonstrate improvements in performance against baseline models on\nnode classification for heterogeneous graphs and graph regression on chemistry\ndatasets.",
            "author": [
                "See Hian Lee",
                "Feng Ji",
                "Kelin Xia",
                "Wee Peng Tay"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16401v2",
                "http://arxiv.org/pdf/2310.16401v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16397v1",
            "title": "Learning Efficient Surrogate Dynamic Models with Graph Spline Networks",
            "updated": "2023-10-25T06:32:47Z",
            "published": "2023-10-25T06:32:47Z",
            "summary": "While complex simulations of physical systems have been widely used in\nengineering and scientific computing, lowering their often prohibitive\ncomputational requirements has only recently been tackled by deep learning\napproaches. In this paper, we present GraphSplineNets, a novel deep-learning\nmethod to speed up the forecasting of physical systems by reducing the grid\nsize and number of iteration steps of deep surrogate models. Our method uses\ntwo differentiable orthogonal spline collocation methods to efficiently predict\nresponse at any location in time and space. Additionally, we introduce an\nadaptive collocation strategy in space to prioritize sampling from the most\nimportant regions. GraphSplineNets improve the accuracy-speedup tradeoff in\nforecasting various dynamical systems with increasing complexity, including the\nheat equation, damped wave propagation, Navier-Stokes equations, and real-world\nocean currents in both regular and irregular domains.",
            "author": [
                "Chuanbo Hua",
                "Federico Berto",
                "Michael Poli",
                "Stefano Massaroli",
                "Jinkyoo Park"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16397v1",
                "http://arxiv.org/pdf/2310.16397v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.LG",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16391v1",
            "title": "Winning Prize Comes from Losing Tickets: Improve Invariant Learning by\n  Exploring Variant Parameters for Out-of-Distribution Generalization",
            "updated": "2023-10-25T06:10:57Z",
            "published": "2023-10-25T06:10:57Z",
            "summary": "Out-of-Distribution (OOD) Generalization aims to learn robust models that\ngeneralize well to various environments without fitting to\ndistribution-specific features. Recent studies based on Lottery Ticket\nHypothesis (LTH) address this problem by minimizing the learning target to find\nsome of the parameters that are critical to the task. However, in OOD problems,\nsuch solutions are suboptimal as the learning task contains severe distribution\nnoises, which can mislead the optimization process. Therefore, apart from\nfinding the task-related parameters (i.e., invariant parameters), we propose\nExploring Variant parameters for Invariant Learning (EVIL) which also leverages\nthe distribution knowledge to find the parameters that are sensitive to\ndistribution shift (i.e., variant parameters). Once the variant parameters are\nleft out of invariant learning, a robust subnetwork that is resistant to\ndistribution shift can be found. Additionally, the parameters that are\nrelatively stable across distributions can be considered invariant ones to\nimprove invariant learning. By fully exploring both variant and invariant\nparameters, our EVIL can effectively identify a robust subnetwork to improve\nOOD generalization. In extensive experiments on integrated testbed: DomainBed,\nEVIL can effectively and efficiently enhance many popular methods, such as ERM,\nIRM, SAM, etc.",
            "author": [
                "Zhuo Huang",
                "Muyang Li",
                "Li Shen",
                "Jun Yu",
                "Chen Gong",
                "Bo Han",
                "Tongliang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16391v1",
                "http://arxiv.org/pdf/2310.16391v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "Computer Vision and Pattern Recognition"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16390v1",
            "title": "Evaluating Pre-trained Language Models for Repairing API Misuses",
            "updated": "2023-10-25T06:10:22Z",
            "published": "2023-10-25T06:10:22Z",
            "summary": "API misuses often lead to software bugs, crashes, and vulnerabilities. While\nseveral API misuse detectors have been proposed, there are no automatic repair\ntools specifically designed for this purpose. In a recent study,\ntest-suite-based automatic program repair (APR) tools were found to be\nineffective in repairing API misuses. Still, since the study focused on\nnon-learning-aided APR tools, it remains unknown whether learning-aided APR\ntools are capable of fixing API misuses. In recent years, pre-trained language\nmodels (PLMs) have succeeded greatly in many natural language processing tasks.\nThere is a rising interest in applying PLMs to APR. However, there has not been\nany study that investigates the effectiveness of PLMs in repairing API misuse.\n  To fill this gap, we conduct a comprehensive empirical study on 11\nlearning-aided APR tools, which include 9 of the state-of-the-art\ngeneral-purpose PLMs and two APR tools. We evaluate these models with an\nAPI-misuse repair dataset, consisting of two variants. Our results show that\nPLMs perform better than the studied APR tools in repairing API misuses. Among\nthe 9 pre-trained models tested, CodeT5 is the best performer in the exact\nmatch. We also offer insights and potential exploration directions for future\nresearch.",
            "author": [
                "Ting Zhang",
                "Ivana Clairine Irsan",
                "Ferdian Thung",
                "David Lo",
                "Asankhaya Sharma",
                "Lingxiao Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16390v1",
                "http://arxiv.org/pdf/2310.16390v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16389v1",
            "title": "MVFAN: Multi-View Feature Assisted Network for 4D Radar Object Detection",
            "updated": "2023-10-25T06:10:07Z",
            "published": "2023-10-25T06:10:07Z",
            "summary": "4D radar is recognized for its resilience and cost-effectiveness under\nadverse weather conditions, thus playing a pivotal role in autonomous driving.\nWhile cameras and LiDAR are typically the primary sensors used in perception\nmodules for autonomous vehicles, radar serves as a valuable supplementary\nsensor. Unlike LiDAR and cameras, radar remains unimpaired by harsh weather\nconditions, thereby offering a dependable alternative in challenging\nenvironments. Developing radar-based 3D object detection not only augments the\ncompetency of autonomous vehicles but also provides economic benefits. In\nresponse, we propose the Multi-View Feature Assisted Network (\\textit{MVFAN}),\nan end-to-end, anchor-free, and single-stage framework for 4D-radar-based 3D\nobject detection for autonomous vehicles. We tackle the issue of insufficient\nfeature utilization by introducing a novel Position Map Generation module to\nenhance feature learning by reweighing foreground and background points, and\ntheir features, considering the irregular distribution of radar point clouds.\nAdditionally, we propose a pioneering backbone, the Radar Feature Assisted\nbackbone, explicitly crafted to fully exploit the valuable Doppler velocity and\nreflectivity data provided by the 4D radar sensor. Comprehensive experiments\nand ablation studies carried out on Astyx and VoD datasets attest to the\nefficacy of our framework. The incorporation of Doppler velocity and RCS\nreflectivity dramatically improves the detection performance for small moving\nobjects such as pedestrians and cyclists. Consequently, our approach culminates\nin a highly optimized 4D-radar-based 3D object detection capability for\nautonomous driving systems, setting a new standard in the field.",
            "author": [
                "Qiao Yan",
                "Yihan Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16389v1",
                "http://arxiv.org/pdf/2310.16389v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16861v1",
            "title": "General Point Model with Autoencoding and Autoregressive",
            "updated": "2023-10-25T06:08:24Z",
            "published": "2023-10-25T06:08:24Z",
            "summary": "The pre-training architectures of large language models encompass various\ntypes, including autoencoding models, autoregressive models, and\nencoder-decoder models. We posit that any modality can potentially benefit from\na large language model, as long as it undergoes vector quantization to become\ndiscrete tokens. Inspired by GLM, we propose a General Point Model (GPM) which\nseamlessly integrates autoencoding and autoregressive tasks in point cloud\ntransformer. This model is versatile, allowing fine-tuning for downstream point\ncloud representation tasks, as well as unconditional and conditional generation\ntasks. GPM enhances masked prediction in autoencoding through various forms of\nmask padding tasks, leading to improved performance in point cloud\nunderstanding. Additionally, GPM demonstrates highly competitive results in\nunconditional point cloud generation tasks, even exhibiting the potential for\nconditional generation tasks by modifying the input's conditional information.\nCompared to models like Point-BERT, MaskPoint and PointMAE, our GPM achieves\nsuperior performance in point cloud understanding tasks. Furthermore, the\nintegration of autoregressive and autoencoding within the same transformer\nunderscores its versatility across different downstream tasks.",
            "author": [
                "Zhe Li",
                "Zhangyang Gao",
                "Cheng Tan",
                "Stan Z. Li",
                "Laurence T. Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16861v1",
                "http://arxiv.org/pdf/2310.16861v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16387v1",
            "title": "Frequency-Aware Transformer for Learned Image Compression",
            "updated": "2023-10-25T05:59:25Z",
            "published": "2023-10-25T05:59:25Z",
            "summary": "Learned image compression (LIC) has gained traction as an effective solution\nfor image storage and transmission in recent years. However, existing LIC\nmethods are redundant in latent representation due to limitations in capturing\nanisotropic frequency components and preserving directional details. To\novercome these challenges, we propose a novel frequency-aware transformer (FAT)\nblock that for the first time achieves multiscale directional ananlysis for\nLIC. The FAT block comprises frequency-decomposition window attention (FDWA)\nmodules to capture multiscale and directional frequency components of natural\nimages. Additionally, we introduce frequency-modulation feed-forward network\n(FMFFN) to adaptively modulate different frequency components, improving\nrate-distortion performance. Furthermore, we present a transformer-based\nchannel-wise autoregressive (T-CA) model that effectively exploits channel\ndependencies. Experiments show that our method achieves state-of-the-art\nrate-distortion performance compared to existing LIC methods, and evidently\noutperforms latest standardized codec VTM-12.1 by 14.5%, 15.1%, 13.0% in\nBD-rate on the Kodak, Tecnick, and CLIC datasets.",
            "author": [
                "Han Li",
                "Shaohui Li",
                "Wenrui Dai",
                "Chenglin Li",
                "Junni Zou",
                "Hongkai Xiong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16387v1",
                "http://arxiv.org/pdf/2310.16387v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16384v1",
            "title": "Distributed Uncertainty Quantification of Kernel Interpolation on\n  Spheres",
            "updated": "2023-10-25T05:52:02Z",
            "published": "2023-10-25T05:52:02Z",
            "summary": "For radial basis function (RBF) kernel interpolation of scattered data,\nSchaback in 1995 proved that the attainable approximation error and the\ncondition number of the underlying interpolation matrix cannot be made small\nsimultaneously. He referred to this finding as an \"uncertainty relation\", an\nundesirable consequence of which is that RBF kernel interpolation is\nsusceptible to noisy data. In this paper, we propose and study a distributed\ninterpolation method to manage and quantify the uncertainty brought on by\ninterpolating noisy spherical data of non-negligible magnitude. We also present\nnumerical simulation results showing that our method is practical and robust in\nterms of handling noisy data from challenging computing environments.",
            "author": [
                "Shao-Bo Lin",
                "Xingping Sun",
                "Di Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16384v1",
                "http://arxiv.org/pdf/2310.16384v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.LG",
                "cs.NA",
                "math.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16380v1",
            "title": "A model for multi-attack classification to improve intrusion detection\n  performance using deep learning approaches",
            "updated": "2023-10-25T05:38:44Z",
            "published": "2023-10-25T05:38:44Z",
            "summary": "This proposed model introduces novel deep learning methodologies. The\nobjective here is to create a reliable intrusion detection mechanism to help\nidentify malicious attacks. Deep learning based solution framework is developed\nconsisting of three approaches. The first approach is Long-Short Term Memory\nRecurrent Neural Network (LSTM-RNN) with seven optimizer functions such as\nadamax, SGD, adagrad, adam, RMSprop, nadam and adadelta. The model is evaluated\non NSL-KDD dataset and classified multi attack classification. The model has\noutperformed with adamax optimizer in terms of accuracy, detection rate and low\nfalse alarm rate. The results of LSTM-RNN with adamax optimizer is compared\nwith existing shallow machine and deep learning models in terms of accuracy,\ndetection rate and low false alarm rate. The multi model methodology consisting\nof Recurrent Neural Network (RNN), Long-Short Term Memory Recurrent Neural\nNetwork (LSTM-RNN), and Deep Neural Network (DNN). The multi models are\nevaluated on bench mark datasets such as KDD99, NSL-KDD, and UNSWNB15 datasets.\nThe models self-learnt the features and classifies the attack classes as\nmulti-attack classification. The models RNN, and LSTM-RNN provide considerable\nperformance compared to other existing methods on KDD99 and NSL-KDD dataset",
            "author": [
                "Arun Kumar Silivery",
                "Ram Mohan Rao Kovvur"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.measen.2023.100924",
                "http://arxiv.org/abs/2310.16380v1",
                "http://arxiv.org/pdf/2310.16380v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16376v1",
            "title": "GADY: Unsupervised Anomaly Detection on Dynamic Graphs",
            "updated": "2023-10-25T05:27:45Z",
            "published": "2023-10-25T05:27:45Z",
            "summary": "Anomaly detection on dynamic graphs refers to detecting entities whose\nbehaviors obviously deviate from the norms observed within graphs and their\ntemporal information. This field has drawn increasing attention due to its\napplication in finance, network security, social networks, and more. However,\nexisting methods face two challenges: dynamic structure constructing challenge\n- difficulties in capturing graph structure with complex time information and\nnegative sampling challenge - unable to construct excellent negative samples\nfor unsupervised learning. To address these challenges, we propose Unsupervised\nGenerative Anomaly Detection on Dynamic Graphs (GADY). To tackle the first\nchallenge, we propose a continuous dynamic graph model to capture the\nfine-grained information, which breaks the limit of existing discrete methods.\nSpecifically, we employ a message-passing framework combined with positional\nfeatures to get edge embeddings, which are decoded to identify anomalies. For\nthe second challenge, we pioneer the use of Generative Adversarial Networks to\ngenerate negative interactions. Moreover, we design a loss function to alter\nthe training goal of the generator while ensuring the diversity and quality of\ngenerated samples. Extensive experiments demonstrate that our proposed GADY\nsignificantly outperforms the previous state-of-the-art method on three\nreal-world datasets. Supplementary experiments further validate the\neffectiveness of our model design and the necessity of each module.",
            "author": [
                "Shiqi Lou",
                "Qingyue Zhang",
                "Shujie Yang",
                "Yuyang Tian",
                "Zhaoxuan Tan",
                "Minnan Luo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16376v1",
                "http://arxiv.org/pdf/2310.16376v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16375v1",
            "title": "DyExplainer: Explainable Dynamic Graph Neural Networks",
            "updated": "2023-10-25T05:26:33Z",
            "published": "2023-10-25T05:26:33Z",
            "summary": "Graph Neural Networks (GNNs) resurge as a trending research subject owing to\ntheir impressive ability to capture representations from graph-structured data.\nHowever, the black-box nature of GNNs presents a significant challenge in terms\nof comprehending and trusting these models, thereby limiting their practical\napplications in mission-critical scenarios. Although there has been substantial\nprogress in the field of explaining GNNs in recent years, the majority of these\nstudies are centered on static graphs, leaving the explanation of dynamic GNNs\nlargely unexplored. Dynamic GNNs, with their ever-evolving graph structures,\npose a unique challenge and require additional efforts to effectively capture\ntemporal dependencies and structural relationships. To address this challenge,\nwe present DyExplainer, a novel approach to explaining dynamic GNNs on the fly.\nDyExplainer trains a dynamic GNN backbone to extract representations of the\ngraph at each snapshot, while simultaneously exploring structural relationships\nand temporal dependencies through a sparse attention technique. To preserve the\ndesired properties of the explanation, such as structural consistency and\ntemporal continuity, we augment our approach with contrastive learning\ntechniques to provide priori-guided regularization. To model longer-term\ntemporal dependencies, we develop a buffer-based live-updating scheme for\ntraining. The results of our extensive experiments on various datasets\ndemonstrate the superiority of DyExplainer, not only providing faithful\nexplainability of the model predictions but also significantly improving the\nmodel prediction accuracy, as evidenced in the link prediction task.",
            "author": [
                "Tianchun Wang",
                "Dongsheng Luo",
                "Wei Cheng",
                "Haifeng Chen",
                "Xiang Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16375v1",
                "http://arxiv.org/pdf/2310.16375v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16374v1",
            "title": "Joint Distributional Learning via Cramer-Wold Distance",
            "updated": "2023-10-25T05:24:23Z",
            "published": "2023-10-25T05:24:23Z",
            "summary": "The assumption of conditional independence among observed variables,\nprimarily used in the Variational Autoencoder (VAE) decoder modeling, has\nlimitations when dealing with high-dimensional datasets or complex correlation\nstructures among observed variables. To address this issue, we introduced the\nCramer-Wold distance regularization, which can be computed in a closed-form, to\nfacilitate joint distributional learning for high-dimensional datasets.\nAdditionally, we introduced a two-step learning method to enable flexible prior\nmodeling and improve the alignment between the aggregated posterior and the\nprior distribution. Furthermore, we provide theoretical distinctions from\nexisting methods within this category. To evaluate the synthetic data\ngeneration performance of our proposed approach, we conducted experiments on\nhigh-dimensional datasets with multiple categorical variables. Given that many\nreadily available datasets and data science applications involve such datasets,\nour experiments demonstrate the effectiveness of our proposed methodology.",
            "author": [
                "Seunghwan An",
                "Jong-June Jeon"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16374v1",
                "http://arxiv.org/pdf/2310.16374v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16364v1",
            "title": "Towards Large-scale Masked Face Recognition",
            "updated": "2023-10-25T05:04:47Z",
            "published": "2023-10-25T05:04:47Z",
            "summary": "During the COVID-19 coronavirus epidemic, almost everyone is wearing masks,\nwhich poses a huge challenge for deep learning-based face recognition\nalgorithms. In this paper, we will present our \\textbf{championship} solutions\nin ICCV MFR WebFace260M and InsightFace unconstrained tracks. We will focus on\nfour challenges in large-scale masked face recognition, i.e., super-large scale\ntraining, data noise handling, masked and non-masked face recognition accuracy\nbalancing, and how to design inference-friendly model architecture. We hope\nthat the discussion on these four aspects can guide future research towards\nmore robust masked face recognition systems.",
            "author": [
                "Manyuan Zhang",
                "Bingqi Ma",
                "Guanglu Song",
                "Yunxiao Wang",
                "Hongsheng Li",
                "Yu Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16364v1",
                "http://arxiv.org/pdf/2310.16364v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16363v1",
            "title": "Finite Time Analysis of Constrained Actor Critic and Constrained Natural\n  Actor Critic Algorithms",
            "updated": "2023-10-25T05:04:00Z",
            "published": "2023-10-25T05:04:00Z",
            "summary": "Actor Critic methods have found immense applications on a wide range of\nReinforcement Learning tasks especially when the state-action space is large.\nIn this paper, we consider actor critic and natural actor critic algorithms\nwith function approximation for constrained Markov decision processes (C-MDP)\ninvolving inequality constraints and carry out a non-asymptotic analysis for\nboth of these algorithms in a non-i.i.d (Markovian) setting. We consider the\nlong-run average cost criterion where both the objective and the constraint\nfunctions are suitable policy-dependent long-run averages of certain prescribed\ncost functions. We handle the inequality constraints using the Lagrange\nmultiplier method. We prove that these algorithms are guaranteed to find a\nfirst-order stationary point (i.e., $\\Vert \\nabla L(\\theta,\\gamma)\\Vert_2^2\n\\leq \\epsilon$) of the performance (Lagrange) function $L(\\theta,\\gamma)$, with\na sample complexity of $\\mathcal{\\tilde{O}}(\\epsilon^{-2.5})$ in the case of\nboth Constrained Actor Critic (C-AC) and Constrained Natural Actor Critic\n(C-NAC) algorithms.We also show the results of experiments on a few different\ngrid world settings and observe good empirical performance using both of these\nalgorithms. In particular, for large grid sizes, Constrained Natural Actor\nCritic shows slightly better results than Constrained Actor Critic while the\nlatter is slightly better for a small grid size.",
            "author": [
                "Prashansa Panda",
                "Shalabh Bhatnagar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16363v1",
                "http://arxiv.org/pdf/2310.16363v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16362v1",
            "title": "Neural Potential Field for Obstacle-Aware Local Motion Planning",
            "updated": "2023-10-25T05:00:21Z",
            "published": "2023-10-25T05:00:21Z",
            "summary": "Model predictive control (MPC) may provide local motion planning for mobile\nrobotic platforms. The challenging aspect is the analytic representation of\ncollision cost for the case when both the obstacle map and robot footprint are\narbitrary. We propose a Neural Potential Field: a neural network model that\nreturns a differentiable collision cost based on robot pose, obstacle map, and\nrobot footprint. The differentiability of our model allows its usage within the\nMPC solver. It is computationally hard to solve problems with a very high\nnumber of parameters. Therefore, our architecture includes neural image\nencoders, which transform obstacle maps and robot footprints into embeddings,\nwhich reduce problem dimensionality by two orders of magnitude. The reference\ndata for network training are generated based on algorithmic calculation of a\nsigned distance function. Comparative experiments showed that the proposed\napproach is comparable with existing local planners: it provides trajectories\nwith outperforming smoothness, comparable path length, and safe distance from\nobstacles. Experiment on Husky UGV mobile robot showed that our approach allows\nreal-time and safe local planning. The code for our approach is presented at\nhttps://github.com/cog-isa/NPField together with demo video.",
            "author": [
                "Muhammad Alhaddad",
                "Konstantin Mironov",
                "Aleksey Staroverov",
                "Aleksandr Panov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16362v1",
                "http://arxiv.org/pdf/2310.16362v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16355v1",
            "title": "Redco: A Lightweight Tool to Automate Distributed Training of LLMs on\n  Any GPU/TPUs",
            "updated": "2023-10-25T04:32:35Z",
            "published": "2023-10-25T04:32:35Z",
            "summary": "The recent progress of AI can be largely attributed to large language models\n(LLMs). However, their escalating memory requirements introduce challenges for\nmachine learning (ML) researchers and engineers. Addressing this requires\ndevelopers to partition a large model to distribute it across multiple GPUs or\nTPUs. This necessitates considerable coding and intricate configuration efforts\nwith existing model parallel tools, such as Megatron-LM, DeepSpeed, and Alpa.\nThese tools require users' expertise in machine learning systems (MLSys),\ncreating a bottleneck in LLM development, particularly for developers without\nMLSys background. In this work, we present Redco, a lightweight and\nuser-friendly tool crafted to automate distributed training and inference for\nLLMs, as well as to simplify ML pipeline development. The design of Redco\nemphasizes two key aspects. Firstly, to automate model parallism, our study\nidentifies two straightforward rules to generate tensor parallel strategies for\nany given LLM. Integrating these rules into Redco facilitates effortless\ndistributed LLM training and inference, eliminating the need of additional\ncoding or complex configurations. We demonstrate the effectiveness by applying\nRedco on a set of LLM architectures, such as GPT-J, LLaMA, T5, and OPT, up to\nthe size of 66B. Secondly, we propose a mechanism that allows for the\ncustomization of diverse ML pipelines through the definition of merely three\nfunctions, eliminating redundant and formulaic code like multi-host related\nprocessing. This mechanism proves adaptable across a spectrum of ML algorithms,\nfrom foundational language modeling to complex algorithms like meta-learning\nand reinforcement learning. Consequently, Redco implementations exhibit much\nfewer code lines compared to their official counterparts.",
            "author": [
                "Bowen Tan",
                "Yun Zhu",
                "Lijuan Liu",
                "Hongyi Wang",
                "Yonghao Zhuang",
                "Jindong Chen",
                "Eric Xing",
                "Zhiting Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16355v1",
                "http://arxiv.org/pdf/2310.16355v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16350v2",
            "title": "Unraveling Feature Extraction Mechanisms in Neural Networks",
            "updated": "2023-10-26T03:26:30Z",
            "published": "2023-10-25T04:22:40Z",
            "summary": "The underlying mechanism of neural networks in capturing precise knowledge\nhas been the subject of consistent research efforts. In this work, we propose a\ntheoretical approach based on Neural Tangent Kernels (NTKs) to investigate such\nmechanisms. Specifically, considering the infinite network width, we\nhypothesize the learning dynamics of target models may intuitively unravel the\nfeatures they acquire from training data, deepening our insights into their\ninternal mechanisms. We apply our approach to several fundamental models and\nreveal how these models leverage statistical features during gradient descent\nand how they are integrated into final decisions. We also discovered that the\nchoice of activation function can affect feature extraction. For instance, the\nuse of the \\textit{ReLU} activation function could potentially introduce a bias\nin features, providing a plausible explanation for its replacement with\nalternative functions in recent pre-trained language models. Additionally, we\nfind that while self-attention and CNN models may exhibit limitations in\nlearning n-grams, multiplication-based models seem to excel in this area. We\nverify these theoretical findings through experiments and find that they can be\napplied to analyze language modeling tasks, which can be regarded as a special\nvariant of classification. Our contributions offer insights into the roles and\ncapacities of fundamental components within large language models, thereby\naiding the broader understanding of these complex systems.",
            "author": [
                "Xiaobing Sun",
                "Jiaxi Li",
                "Wei Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16350v2",
                "http://arxiv.org/pdf/2310.16350v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16338v1",
            "title": "Generative Pre-training for Speech with Flow Matching",
            "updated": "2023-10-25T03:40:50Z",
            "published": "2023-10-25T03:40:50Z",
            "summary": "Generative models have gained more and more attention in recent years for\ntheir remarkable success in tasks that required estimating and sampling data\ndistribution to generate high-fidelity synthetic data. In speech,\ntext-to-speech synthesis and neural vocoder are good examples where generative\nmodels have shined. While generative models have been applied to different\napplications in speech, there exists no general-purpose generative model that\nmodels speech directly. In this work, we take a step toward this direction by\nshowing a single pre-trained generative model can be adapted to different\ndownstream tasks with strong performance. Specifically, we pre-trained a\ngenerative model, named SpeechFlow, on 60k hours of untranscribed speech with\nFlow Matching and masked conditions. Experiment results show the pre-trained\ngenerative model can be fine-tuned with task-specific data to match or surpass\nexisting expert models on speech enhancement, separation, and synthesis. Our\nwork suggested a foundational model for generation tasks in speech can be built\nwith generative pre-training.",
            "author": [
                "Alexander H. Liu",
                "Matt Le",
                "Apoorv Vyas",
                "Bowen Shi",
                "Andros Tjandra",
                "Wei-Ning Hsu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16338v1",
                "http://arxiv.org/pdf/2310.16338v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.CL",
                "cs.LG",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16336v1",
            "title": "SMURF-THP: Score Matching-based UnceRtainty quantiFication for\n  Transformer Hawkes Process",
            "updated": "2023-10-25T03:33:45Z",
            "published": "2023-10-25T03:33:45Z",
            "summary": "Transformer Hawkes process models have shown to be successful in modeling\nevent sequence data. However, most of the existing training methods rely on\nmaximizing the likelihood of event sequences, which involves calculating some\nintractable integral. Moreover, the existing methods fail to provide\nuncertainty quantification for model predictions, e.g., confidence intervals\nfor the predicted event's arrival time. To address these issues, we propose\nSMURF-THP, a score-based method for learning Transformer Hawkes process and\nquantifying prediction uncertainty. Specifically, SMURF-THP learns the score\nfunction of events' arrival time based on a score-matching objective that\navoids the intractable computation. With such a learned score function, we can\nsample arrival time of events from the predictive distribution. This naturally\nallows for the quantification of uncertainty by computing confidence intervals\nover the generated samples. We conduct extensive experiments in both event type\nprediction and uncertainty quantification of arrival time. In all the\nexperiments, SMURF-THP outperforms existing likelihood-based methods in\nconfidence calibration while exhibiting comparable prediction accuracy.",
            "author": [
                "Zichong Li",
                "Yanbo Xu",
                "Simiao Zuo",
                "Haoming Jiang",
                "Chao Zhang",
                "Tuo Zhao",
                "Hongyuan Zha"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16336v1",
                "http://arxiv.org/pdf/2310.16336v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16335v1",
            "title": "Defense Against Model Extraction Attacks on Recommender Systems",
            "updated": "2023-10-25T03:30:42Z",
            "published": "2023-10-25T03:30:42Z",
            "summary": "The robustness of recommender systems has become a prominent topic within the\nresearch community. Numerous adversarial attacks have been proposed, but most\nof them rely on extensive prior knowledge, such as all the white-box attacks or\nmost of the black-box attacks which assume that certain external knowledge is\navailable. Among these attacks, the model extraction attack stands out as a\npromising and practical method, involving training a surrogate model by\nrepeatedly querying the target model. However, there is a significant gap in\nthe existing literature when it comes to defending against model extraction\nattacks on recommender systems. In this paper, we introduce Gradient-based\nRanking Optimization (GRO), which is the first defense strategy designed to\ncounter such attacks. We formalize the defense as an optimization problem,\naiming to minimize the loss of the protected target model while maximizing the\nloss of the attacker's surrogate model. Since top-k ranking lists are\nnon-differentiable, we transform them into swap matrices which are instead\ndifferentiable. These swap matrices serve as input to a student model that\nemulates the surrogate model's behavior. By back-propagating the loss of the\nstudent model, we obtain gradients for the swap matrices. These gradients are\nused to compute a swap loss, which maximizes the loss of the student model. We\nconducted experiments on three benchmark datasets to evaluate the performance\nof GRO, and the results demonstrate its superior effectiveness in defending\nagainst model extraction attacks.",
            "author": [
                "Sixiao Zhang",
                "Hongzhi Yin",
                "Hongxu Chen",
                "Cheng Long"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16335v1",
                "http://arxiv.org/pdf/2310.16335v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16334v1",
            "title": "AccoMontage-3: Full-Band Accompaniment Arrangement via Sequential Style\n  Transfer and Multi-Track Function Prior",
            "updated": "2023-10-25T03:30:37Z",
            "published": "2023-10-25T03:30:37Z",
            "summary": "We propose AccoMontage-3, a symbolic music automation system capable of\ngenerating multi-track, full-band accompaniment based on the input of a lead\nmelody with chords (i.e., a lead sheet). The system contains three modular\ncomponents, each modelling a vital aspect of full-band composition. The first\ncomponent is a piano arranger that generates piano accompaniment for the lead\nsheet by transferring texture styles to the chords using latent chord-texture\ndisentanglement and heuristic retrieval of texture donors. The second component\norchestrates the piano accompaniment score into full-band arrangement according\nto the orchestration style encoded by individual track functions. The third\ncomponent, which connects the previous two, is a prior model characterizing the\nglobal structure of orchestration style over the whole piece of music. From end\nto end, the system learns to generate full-band accompaniment in a\nself-supervised fashion, applying style transfer at two levels of polyphonic\ncomposition: texture and orchestration. Experiments show that our system\noutperforms the baselines significantly, and the modular design offers\neffective controls in a musically meaningful way.",
            "author": [
                "Jingwei Zhao",
                "Gus Xia",
                "Ye Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16334v1",
                "http://arxiv.org/pdf/2310.16334v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.AI",
                "cs.MM",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16332v1",
            "title": "Corrupting Neuron Explanations of Deep Visual Features",
            "updated": "2023-10-25T03:28:37Z",
            "published": "2023-10-25T03:28:37Z",
            "summary": "The inability of DNNs to explain their black-box behavior has led to a recent\nsurge of explainability methods. However, there are growing concerns that these\nexplainability methods are not robust and trustworthy. In this work, we perform\nthe first robustness analysis of Neuron Explanation Methods under a unified\npipeline and show that these explanations can be significantly corrupted by\nrandom noises and well-designed perturbations added to their probing data. We\nfind that even adding small random noise with a standard deviation of 0.02 can\nalready change the assigned concepts of up to 28% neurons in the deeper layers.\nFurthermore, we devise a novel corruption algorithm and show that our algorithm\ncan manipulate the explanation of more than 80% neurons by poisoning less than\n10% of probing data. This raises the concern of trusting Neuron Explanation\nMethods in real-life safety and fairness critical applications.",
            "author": [
                "Divyansh Srivastava",
                "Tuomas Oikarinen",
                "Tsui-Wei Weng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16332v1",
                "http://arxiv.org/pdf/2310.16332v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16331v1",
            "title": "Brain-Inspired Reservoir Computing Using Memristors with Tunable\n  Dynamics and Short-Term Plasticity",
            "updated": "2023-10-25T03:27:43Z",
            "published": "2023-10-25T03:27:43Z",
            "summary": "Recent advancements in reservoir computing research have created a demand for\nanalog devices with dynamics that can facilitate the physical implementation of\nreservoirs, promising faster information processing while consuming less energy\nand occupying a smaller area footprint. Studies have demonstrated that dynamic\nmemristors, with nonlinear and short-term memory dynamics, are excellent\ncandidates as information-processing devices or reservoirs for temporal\nclassification and prediction tasks. Previous implementations relied on\nnominally identical memristors that applied the same nonlinear transformation\nto the input data, which is not enough to achieve a rich state space. To\naddress this limitation, researchers either diversified the data encoding\nacross multiple memristors or harnessed the stochastic device-to-device\nvariability among the memristors. However, this approach requires additional\npre-processing steps and leads to synchronization issues. Instead, it is\npreferable to encode the data once and pass it through a reservoir layer\nconsisting of memristors with distinct dynamics. Here, we demonstrate that\nion-channel-based memristors with voltage-dependent dynamics can be\ncontrollably and predictively tuned through voltage or adjustment of the ion\nchannel concentration to exhibit diverse dynamic properties. We show, through\nexperiments and simulations, that reservoir layers constructed with a small\nnumber of distinct memristors exhibit significantly higher predictive and\nclassification accuracies with a single data encoding. We found that for a\nsecond-order nonlinear dynamical system prediction task, the varied memristor\nreservoir experimentally achieved a normalized mean square error of 0.0015\nusing only five distinct memristors. Moreover, in a neural activity\nclassification task, a reservoir of just three distinct memristors\nexperimentally attained an accuracy of 96.5%.",
            "author": [
                "Nicholas X. Armendarez",
                "Ahmed S. Mohamed",
                "Anurag Dhungel",
                "Md Razuan Hossain",
                "Md Sakib Hasan",
                "Joseph S. Najem"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16331v1",
                "http://arxiv.org/pdf/2310.16331v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16326v1",
            "title": "Reinforcement Learning for SBM Graphon Games with Re-Sampling",
            "updated": "2023-10-25T03:14:48Z",
            "published": "2023-10-25T03:14:48Z",
            "summary": "The Mean-Field approximation is a tractable approach for studying large\npopulation dynamics. However, its assumption on homogeneity and universal\nconnections among all agents limits its applicability in many real-world\nscenarios. Multi-Population Mean-Field Game (MP-MFG) models have been\nintroduced in the literature to address these limitations. When the underlying\nStochastic Block Model is known, we show that a Policy Mirror Ascent algorithm\nfinds the MP-MFG Nash Equilibrium. In more realistic scenarios where the block\nmodel is unknown, we propose a re-sampling scheme from a graphon integrated\nwith the finite N-player MP-MFG model. We develop a novel learning framework\nbased on a Graphon Game with Re-Sampling (GGR-S) model, which captures the\ncomplex network structures of agents' connections. We analyze GGR-S dynamics\nand establish the convergence to dynamics of MP-MFG. Leveraging this result, we\npropose an efficient sample-based N-player Reinforcement Learning algorithm for\nGGR-S without population manipulation, and provide a rigorous convergence\nanalysis with finite sample guarantee.",
            "author": [
                "Peihan Huo",
                "Oscar Peralta",
                "Junyu Guo",
                "Qiaomin Xie",
                "Andreea Minca"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16326v1",
                "http://arxiv.org/pdf/2310.16326v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16324v1",
            "title": "Extracting Design Knowledge from Optimization Data: Enhancing\n  Engineering Design in Fluid Based Thermal Management Systems",
            "updated": "2023-10-25T03:13:52Z",
            "published": "2023-10-25T03:13:52Z",
            "summary": "As mechanical systems become more complex and technological advances\naccelerate, the traditional reliance on heritage designs for engineering\nendeavors is being diminished in its effectiveness. Considering the dynamic\nnature of the design industry where new challenges are continually emerging,\nalternative sources of knowledge need to be sought to guide future design\nefforts. One promising avenue lies in the analysis of design optimization data,\nwhich has the potential to offer valuable insights and overcome the limitations\nof heritage designs. This paper presents a step toward extracting knowledge\nfrom optimization data in multi-split fluid-based thermal management systems\nusing different classification machine learning methods, so that designers can\nuse it to guide decisions in future design efforts. This approach offers\nseveral advantages over traditional design heritage methods, including\napplicability in cases where there is no design heritage and the ability to\nderive optimal designs. We showcase our framework through four case studies\nwith varying levels of complexity. These studies demonstrate its effectiveness\nin enhancing the design of complex thermal management systems. Our results show\nthat the knowledge extracted from the configuration design optimization data\nprovides a good basis for more general design of complex thermal management\nsystems. It is shown that the objective value of the estimated optimal\nconfiguration closely approximates the true optimal configuration with less\nthan 1 percent error, achieved using basic features based on the system heat\nloads without involving the corresponding optimal open loop control (OLOC)\nfeatures. This eliminates the need to solve the OLOC problem, leading to\nreduced computation costs.",
            "author": [
                "Saeid Bayat",
                "Nastaran Shahmansouri",
                "Satya RT Peddada",
                "Alex Tessier",
                "Adrian Butscher",
                "James T Allison"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16324v1",
                "http://arxiv.org/pdf/2310.16324v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16323v1",
            "title": "Personalized Federated X -armed Bandit",
            "updated": "2023-10-25T03:11:32Z",
            "published": "2023-10-25T03:11:32Z",
            "summary": "In this work, we study the personalized federated $\\mathcal{X}$-armed bandit\nproblem, where the heterogeneous local objectives of the clients are optimized\nsimultaneously in the federated learning paradigm. We propose the\n\\texttt{PF-PNE} algorithm with a unique double elimination strategy, which\nsafely eliminates the non-optimal regions while encouraging federated\ncollaboration through biased but effective evaluations of the local objectives.\nThe proposed \\texttt{PF-PNE} algorithm is able to optimize local objectives\nwith arbitrary levels of heterogeneity, and its limited communications protects\nthe confidentiality of the client-wise reward data. Our theoretical analysis\nshows the benefit of the proposed algorithm over single-client algorithms.\nExperimentally, \\texttt{PF-PNE} outperforms multiple baselines on both\nsynthetic and real life datasets.",
            "author": [
                "Wenjie Li",
                "Qifan Song",
                "Jean Honorio"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16323v1",
                "http://arxiv.org/pdf/2310.16323v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16322v1",
            "title": "Samsung R&D Institute Philippines at WMT 2023",
            "updated": "2023-10-25T03:10:52Z",
            "published": "2023-10-25T03:10:52Z",
            "summary": "In this paper, we describe the constrained MT systems submitted by Samsung\nR&D Institute Philippines to the WMT 2023 General Translation Task for two\ndirections: en$\\rightarrow$he and he$\\rightarrow$en. Our systems comprise of\nTransformer-based sequence-to-sequence models that are trained with a mix of\nbest practices: comprehensive data preprocessing pipelines, synthetic\nbacktranslated data, and the use of noisy channel reranking during online\ndecoding. Our models perform comparably to, and sometimes outperform, strong\nbaseline unconstrained systems such as mBART50 M2M and NLLB 200 MoE despite\nhaving significantly fewer parameters on two public benchmarks: FLORES-200 and\nNTREX-128.",
            "author": [
                "Jan Christian Blaise Cruz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16322v1",
                "http://arxiv.org/pdf/2310.16322v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16321v1",
            "title": "Neuromorphic cameras for Atmospheric Cherenkov Telescopes and fast\n  optical astronomy: new paradigm, challenges and opportunities",
            "updated": "2023-10-25T03:10:44Z",
            "published": "2023-10-25T03:10:44Z",
            "summary": "The astronomy community has witnessed an explosive growth in the use of\ndeep-learning techniques based on neural networks since the mid-2010s. The\nwidespread adoption of these nature-inspired technologies has helped\nastronomers tackle previously insurmountable problems and provided an\nunprecedented opportunity for new discoveries. However, one of the primary\ntools of today's optical astronomy is neither natural nor efficient: their\nphoto-sensing devices. Specifically, the modern CCD camera - like that of the\ncutting-edge Rubin Observatory - requires an internal clock to regularly expose\nthe sensor to light, consumes a large amount of energy and information\nbandwidth, and has a limited dynamic range. On the contrary, biological eyes\nlack an internal clock and a shutter, have much higher pixel density but\nconsume significantly less energy and bandwidth, and can adapt to bright and\nlow light conditions. Inspired by the nature of the eyes, M. Mahowald and C.\nMead introduced the revolutionary concept of a silicon retina sensor in 1991.\nAlso known as event-based cameras (EBCs), these types of devices operate in a\nvastly different way compared to conventional CCD-based imaging sensors. EBCs\nmimic the operating principles of optic nerves and continuously produce a\nstream of events, with each event generated only when a pixel detects a change\nin light intensity. EBCs do not have fixed exposure times, have high dynamic\nrange, require low power for operation, and can capture high-speed phenomena.\nThese properties are important requirements for Cherenkov telescopes as well as\nother high-speed optical astronomy. This work presents the opportunities and\nchallenges of using EBCs in those cases, and proposes a low-cost approach to\nexperimentally assess the feasibility of this innovative technique.",
            "author": [
                "John Hoang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16321v1",
                "http://arxiv.org/pdf/2310.16321v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16320v1",
            "title": "Enhancing Low-Precision Sampling via Stochastic Gradient Hamiltonian\n  Monte Carlo",
            "updated": "2023-10-25T03:06:48Z",
            "published": "2023-10-25T03:06:48Z",
            "summary": "Low-precision training has emerged as a promising low-cost technique to\nenhance the training efficiency of deep neural networks without sacrificing\nmuch accuracy. Its Bayesian counterpart can further provide uncertainty\nquantification and improved generalization accuracy. This paper investigates\nlow-precision sampling via Stochastic Gradient Hamiltonian Monte Carlo (SGHMC)\nwith low-precision and full-precision gradient accumulators for both strongly\nlog-concave and non-log-concave distributions. Theoretically, our results show\nthat, to achieve $\\epsilon$-error in the 2-Wasserstein distance for\nnon-log-concave distributions, low-precision SGHMC achieves quadratic\nimprovement\n($\\widetilde{\\mathbf{O}}\\left({\\epsilon^{-2}{\\mu^*}^{-2}\\log^2\\left({\\epsilon^{-1}}\\right)}\\right)$)\ncompared to the state-of-the-art low-precision sampler, Stochastic Gradient\nLangevin Dynamics (SGLD)\n($\\widetilde{\\mathbf{O}}\\left({{\\epsilon}^{-4}{\\lambda^{*}}^{-1}\\log^5\\left({\\epsilon^{-1}}\\right)}\\right)$).\nMoreover, we prove that low-precision SGHMC is more robust to the quantization\nerror compared to low-precision SGLD due to the robustness of the\nmomentum-based update w.r.t. gradient noise. Empirically, we conduct\nexperiments on synthetic data, and {MNIST, CIFAR-10 \\& CIFAR-100} datasets,\nwhich validate our theoretical findings. Our study highlights the potential of\nlow-precision SGHMC as an efficient and accurate sampling method for\nlarge-scale and resource-limited machine learning.",
            "author": [
                "Ziyi Wang",
                "Yujie Chen",
                "Qifan Song",
                "Ruqi Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16320v1",
                "http://arxiv.org/pdf/2310.16320v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16318v1",
            "title": "Modality-Agnostic Self-Supervised Learning with Meta-Learned Masked\n  Auto-Encoder",
            "updated": "2023-10-25T03:03:34Z",
            "published": "2023-10-25T03:03:34Z",
            "summary": "Despite its practical importance across a wide range of modalities, recent\nadvances in self-supervised learning (SSL) have been primarily focused on a few\nwell-curated domains, e.g., vision and language, often relying on their\ndomain-specific knowledge. For example, Masked Auto-Encoder (MAE) has become\none of the popular architectures in these domains, but less has explored its\npotential in other modalities. In this paper, we develop MAE as a unified,\nmodality-agnostic SSL framework. In turn, we argue meta-learning as a key to\ninterpreting MAE as a modality-agnostic learner, and propose enhancements to\nMAE from the motivation to jointly improve its SSL across diverse modalities,\ncoined MetaMAE as a result. Our key idea is to view the mask reconstruction of\nMAE as a meta-learning task: masked tokens are predicted by adapting the\nTransformer meta-learner through the amortization of unmasked tokens. Based on\nthis novel interpretation, we propose to integrate two advanced meta-learning\ntechniques. First, we adapt the amortized latent of the Transformer encoder\nusing gradient-based meta-learning to enhance the reconstruction. Then, we\nmaximize the alignment between amortized and adapted latents through task\ncontrastive learning which guides the Transformer encoder to better encode the\ntask-specific knowledge. Our experiment demonstrates the superiority of MetaMAE\nin the modality-agnostic SSL benchmark (called DABS), significantly\noutperforming prior baselines. Code is available at\nhttps://github.com/alinlab/MetaMAE.",
            "author": [
                "Huiwon Jang",
                "Jihoon Tack",
                "Daewon Choi",
                "Jongheon Jeong",
                "Jinwoo Shin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16318v1",
                "http://arxiv.org/pdf/2310.16318v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16316v1",
            "title": "Sum-of-Parts Models: Faithful Attributions for Groups of Features",
            "updated": "2023-10-25T02:50:10Z",
            "published": "2023-10-25T02:50:10Z",
            "summary": "An explanation of a machine learning model is considered \"faithful\" if it\naccurately reflects the model's decision-making process. However, explanations\nsuch as feature attributions for deep learning are not guaranteed to be\nfaithful, and can produce potentially misleading interpretations. In this work,\nwe develop Sum-of-Parts (SOP), a class of models whose predictions come with\ngrouped feature attributions that are faithful-by-construction. This model\ndecomposes a prediction into an interpretable sum of scores, each of which is\ndirectly attributable to a sparse group of features. We evaluate SOP on\nbenchmarks with standard interpretability metrics, and in a case study, we use\nthe faithful explanations from SOP to help astrophysicists discover new\nknowledge about galaxy formation.",
            "author": [
                "Weiqiu You",
                "Helen Qu",
                "Marco Gatti",
                "Bhuvnesh Jain",
                "Eric Wong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16316v1",
                "http://arxiv.org/pdf/2310.16316v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16314v2",
            "title": "Understanding Code Semantics: An Evaluation of Transformer Models in\n  Summarization",
            "updated": "2023-10-27T01:22:52Z",
            "published": "2023-10-25T02:41:50Z",
            "summary": "This paper delves into the intricacies of code summarization using advanced\ntransformer-based language models. Through empirical studies, we evaluate the\nefficacy of code summarization by altering function and variable names to\nexplore whether models truly understand code semantics or merely rely on\ntextual cues. We have also introduced adversaries like dead code and commented\ncode across three programming languages (Python, Javascript, and Java) to\nfurther scrutinize the model's understanding. Ultimately, our research aims to\noffer valuable insights into the inner workings of transformer-based LMs,\nenhancing their ability to understand code and contributing to more efficient\nsoftware development practices and maintenance workflows.",
            "author": [
                "Debanjan Mondal",
                "Abhilasha Lodha",
                "Ankita Sahoo",
                "Beena Kumari"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16314v2",
                "http://arxiv.org/pdf/2310.16314v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16310v1",
            "title": "Score Matching-based Pseudolikelihood Estimation of Neural Marked\n  Spatio-Temporal Point Process with Uncertainty Quantification",
            "updated": "2023-10-25T02:37:51Z",
            "published": "2023-10-25T02:37:51Z",
            "summary": "Spatio-temporal point processes (STPPs) are potent mathematical tools for\nmodeling and predicting events with both temporal and spatial features. Despite\ntheir versatility, most existing methods for learning STPPs either assume a\nrestricted form of the spatio-temporal distribution, or suffer from inaccurate\napproximations of the intractable integral in the likelihood training\nobjective. These issues typically arise from the normalization term of the\nprobability density function. Moreover, current techniques fail to provide\nuncertainty quantification for model predictions, such as confidence intervals\nfor the predicted event's arrival time and confidence regions for the event's\nlocation, which is crucial given the considerable randomness of the data. To\ntackle these challenges, we introduce SMASH: a Score MAtching-based\npSeudolikeliHood estimator for learning marked STPPs with uncertainty\nquantification. Specifically, our framework adopts a normalization-free\nobjective by estimating the pseudolikelihood of marked STPPs through\nscore-matching and offers uncertainty quantification for the predicted event\ntime, location and mark by computing confidence regions over the generated\nsamples. The superior performance of our proposed framework is demonstrated\nthrough extensive experiments in both event prediction and uncertainty\nquantification.",
            "author": [
                "Zichong Li",
                "Qunzhi Xu",
                "Zhenghao Xu",
                "Yajun Mei",
                "Tuo Zhao",
                "Hongyuan Zha"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16310v1",
                "http://arxiv.org/pdf/2310.16310v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16308v1",
            "title": "Diffusion model approach to simulating electron-proton scattering events",
            "updated": "2023-10-25T02:29:06Z",
            "published": "2023-10-25T02:29:06Z",
            "summary": "Generative AI is a fast-growing area of research offering various avenues for\nexploration in high-energy nuclear physics. In this work, we explore the use of\ngenerative models for simulating electron-proton collisions relevant to\nexperiments like CEBAF and the future Electron-Ion Collider (EIC). These\nexperiments play a critical role in advancing our understanding of nucleons and\nnuclei in terms of quark and gluon degrees of freedom. The use of generative\nmodels for simulating collider events faces several challenges such as the\nsparsity of the data, the presence of global or event-wide constraints, and\nsteeply falling particle distributions. In this work, we focus on the\nimplementation of diffusion models for the simulation of electron-proton\nscattering events at EIC energies. Our results demonstrate that diffusion\nmodels can accurately reproduce relevant observables such as momentum\ndistributions and correlations of particles, momentum sum rules, and the\nleading electron kinematics, all of which are of particular interest in\nelectron-proton collisions. Although the sampling process is relatively slow\ncompared to other machine learning architectures, we find diffusion models can\ngenerate high-quality samples. We foresee various applications of our work\nincluding inference for nuclear structure, interpretable generative machine\nlearning, and searches of physics beyond the Standard Model.",
            "author": [
                "Peter Devlin",
                "Jian-Wei Qiu",
                "Felix Ringer",
                "Nobuo Sato"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16308v1",
                "http://arxiv.org/pdf/2310.16308v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-ex",
                "nucl-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16305v1",
            "title": "Dolfin: Diffusion Layout Transformers without Autoencoder",
            "updated": "2023-10-25T02:26:04Z",
            "published": "2023-10-25T02:26:04Z",
            "summary": "In this paper, we introduce a novel generative model, Diffusion Layout\nTransformers without Autoencoder (Dolfin), which significantly improves the\nmodeling capability with reduced complexity compared to existing methods.\nDolfin employs a Transformer-based diffusion process to model layout\ngeneration. In addition to an efficient bi-directional (non-causal joint)\nsequence representation, we further propose an autoregressive diffusion model\n(Dolfin-AR) that is especially adept at capturing rich semantic correlations\nfor the neighboring objects, such as alignment, size, and overlap. When\nevaluated against standard generative layout benchmarks, Dolfin notably\nimproves performance across various metrics (fid, alignment, overlap, MaxIoU\nand DocSim scores), enhancing transparency and interoperability in the process.\nMoreover, Dolfin's applications extend beyond layout generation, making it\nsuitable for modeling geometric structures, such as line segments. Our\nexperiments present both qualitative and quantitative results to demonstrate\nthe advantages of Dolfin.",
            "author": [
                "Yilin Wang",
                "Zeyuan Chen",
                "Liangjun Zhong",
                "Zheng Ding",
                "Zhizhou Sha",
                "Zhuowen Tu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16305v1",
                "http://arxiv.org/pdf/2310.16305v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16304v1",
            "title": "Deep Learning Approach to Photometric Redshift Estimation",
            "updated": "2023-10-25T02:24:37Z",
            "published": "2023-10-25T02:24:37Z",
            "summary": "Photometric redshift estimation, an essential process in astronomy for\ndistance estimation, obtains the redshift of celestial structures by utilizing\nthe magnitude of objects in varying wavelength filters. This research\ncapitalized on a dataset of 50,000 objects from the Sloan Digital Sky Survey,\ncomprising 5 bands of magnitudes and their corresponding redshift labels.\nTypically, studies use spectral distribution templates (SED) for redshift\nprediction. However, these templates are expensive and hard to obtain,\nespecially with larger datasets. The paper explores approaches for Data-Driven\nmethodology instead of template based prediction. Adopting both a decision tree\nregression model and a Fully Connected Neural Network (FCN) for analysis, the\nFCN significantly outperformed the decision tree regressor, achieving an\nimpressive root mean square error (RMSE) of 0.009 compared to the decision\ntree's RMSE above 0.16. The strong performance of the FCN highlights its\nability to capture intricate relationships in astronomical data, holding the\npotential for data-driven redshift estimation, which will help advance next\ngeneration surveys.",
            "author": [
                "Krishna Chunduri",
                "Mithun Mahesh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16304v1",
                "http://arxiv.org/pdf/2310.16304v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16303v1",
            "title": "URL-BERT: Training Webpage Representations via Social Media Engagements",
            "updated": "2023-10-25T02:22:50Z",
            "published": "2023-10-25T02:22:50Z",
            "summary": "Understanding and representing webpages is crucial to online social networks\nwhere users may share and engage with URLs. Common language model (LM) encoders\nsuch as BERT can be used to understand and represent the textual content of\nwebpages. However, these representations may not model thematic information of\nweb domains and URLs or accurately capture their appeal to social media users.\nIn this work, we introduce a new pre-training objective that can be used to\nadapt LMs to understand URLs and webpages. Our proposed framework consists of\ntwo steps: (1) scalable graph embeddings to learn shallow representations of\nURLs based on user engagement on social media and (2) a contrastive objective\nthat aligns LM representations with the aforementioned graph-based\nrepresentation. We apply our framework to the multilingual version of BERT to\nobtain the model URL-BERT. We experimentally demonstrate that our continued\npre-training approach improves webpage understanding on a variety of tasks and\nTwitter internal and external benchmarks.",
            "author": [
                "Ayesha Qamar",
                "Chetan Verma",
                "Ahmed El-Kishky",
                "Sumit Binnani",
                "Sneha Mehta",
                "Taylor Berg-Kirkpatrick"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16303v1",
                "http://arxiv.org/pdf/2310.16303v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16302v1",
            "title": "Imperfect Digital Twin Assisted Low Cost Reinforcement Training for\n  Multi-UAV Networks",
            "updated": "2023-10-25T02:19:19Z",
            "published": "2023-10-25T02:19:19Z",
            "summary": "Deep Reinforcement Learning (DRL) is widely used to optimize the performance\nof multi-UAV networks. However, the training of DRL relies on the frequent\ninteractions between the UAVs and the environment, which consumes lots of\nenergy due to the flying and communication of UAVs in practical experiments.\nInspired by the growing digital twin (DT) technology, which can simulate the\nperformance of algorithms in the digital space constructed by coping features\nof the physical space, the DT is introduced to reduce the costs of practical\ntraining, e.g., energy and hardware purchases. Different from previous\nDT-assisted works with an assumption of perfect reflecting real physics by\nvirtual digital, we consider an imperfect DT model with deviations for\nassisting the training of multi-UAV networks. Remarkably, to trade off the\ntraining cost, DT construction cost, and the impact of deviations of DT on\ntraining, the natural and virtually generated UAV mixing deployment method is\nproposed. Two cascade neural networks (NN) are used to optimize the joint\nnumber of virtually generated UAVs, the DT construction cost, and the\nperformance of multi-UAV networks. These two NNs are trained by unsupervised\nand reinforcement learning, both low-cost label-free training methods.\nSimulation results show the training cost can significantly decrease while\nguaranteeing the training performance. This implies that an efficient decision\ncan be made with imperfect DTs in multi-UAV networks.",
            "author": [
                "Xiucheng Wang",
                "Nan Cheng",
                "Longfei Ma",
                "Zhisheng Yin",
                "Tom. Luan",
                "Ning Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16302v1",
                "http://arxiv.org/pdf/2310.16302v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16301v1",
            "title": "Is ChatGPT a Good Multi-Party Conversation Solver?",
            "updated": "2023-10-25T02:18:40Z",
            "published": "2023-10-25T02:18:40Z",
            "summary": "Large Language Models (LLMs) have emerged as influential instruments within\nthe realm of natural language processing; nevertheless, their capacity to\nhandle multi-party conversations (MPCs) -- a scenario marked by the presence of\nmultiple interlocutors involved in intricate information exchanges -- remains\nuncharted. In this paper, we delve into the potential of generative LLMs such\nas ChatGPT and GPT-4 within the context of MPCs. An empirical analysis is\nconducted to assess the zero-shot learning capabilities of ChatGPT and GPT-4 by\nsubjecting them to evaluation across three MPC datasets that encompass five\nrepresentative tasks. The findings reveal that ChatGPT's performance on a\nnumber of evaluated MPC tasks leaves much to be desired, whilst GPT-4's results\nportend a promising future. Additionally, we endeavor to bolster performance\nthrough the incorporation of MPC structures, encompassing both speaker and\naddressee architecture. This study provides an exhaustive evaluation and\nanalysis of applying generative LLMs to MPCs, casting a light upon the\nconception and creation of increasingly effective and robust MPC agents.\nConcurrently, this work underscores the challenges implicit in the utilization\nof LLMs for MPCs, such as deciphering graphical information flows and\ngenerating stylistically consistent responses.",
            "author": [
                "Chao-Hong Tan",
                "Jia-Chen Gu",
                "Zhen-Hua Ling"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16301v1",
                "http://arxiv.org/pdf/2310.16301v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19822v1",
            "title": "FuXi-Extreme: Improving extreme rainfall and wind forecasts with\n  diffusion model",
            "updated": "2023-10-25T02:16:02Z",
            "published": "2023-10-25T02:16:02Z",
            "summary": "Significant advancements in the development of machine learning (ML) models\nfor weather forecasting have produced remarkable results. State-of-the-art\nML-based weather forecast models, such as FuXi, have demonstrated superior\nstatistical forecast performance in comparison to the high-resolution forecasts\n(HRES) of the European Centre for Medium-Range Weather Forecasts (ECMWF).\nHowever, ML models face a common challenge: as forecast lead times increase,\nthey tend to generate increasingly smooth predictions, leading to an\nunderestimation of the intensity of extreme weather events. To address this\nchallenge, we developed the FuXi-Extreme model, which employs a denoising\ndiffusion probabilistic model (DDPM) to restore finer-scale details in the\nsurface forecast data generated by the FuXi model in 5-day forecasts. An\nevaluation of extreme total precipitation ($\\textrm{TP}$), 10-meter wind speed\n($\\textrm{WS10}$), and 2-meter temperature ($\\textrm{T2M}$) illustrates the\nsuperior performance of FuXi-Extreme over both FuXi and HRES. Moreover, when\nevaluating tropical cyclone (TC) forecasts based on International Best Track\nArchive for Climate Stewardship (IBTrACS) dataset, both FuXi and FuXi-Extreme\nshows superior performance in TC track forecasts compared to HRES, but they\nshow inferior performance in TC intensity forecasts in comparison to HRES.",
            "author": [
                "Xiaohui Zhong",
                "Lei Chen",
                "Jun Liu",
                "Chensen Lin",
                "Yuan Qi",
                "Hao Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19822v1",
                "http://arxiv.org/pdf/2310.19822v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.ao-ph",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16295v1",
            "title": "Instance-wise Linearization of Neural Network for Model Interpretation",
            "updated": "2023-10-25T02:07:39Z",
            "published": "2023-10-25T02:07:39Z",
            "summary": "Neural network have achieved remarkable successes in many scientific fields.\nHowever, the interpretability of the neural network model is still a major\nbottlenecks to deploy such technique into our daily life. The challenge can\ndive into the non-linear behavior of the neural network, which rises a critical\nquestion that how a model use input feature to make a decision. The classical\napproach to address this challenge is feature attribution, which assigns an\nimportant score to each input feature and reveal its importance of current\nprediction. However, current feature attribution approaches often indicate the\nimportance of each input feature without detail of how they are actually\nprocessed by a model internally. These attribution approaches often raise a\nconcern that whether they highlight correct features for a model prediction.\n  For a neural network model, the non-linear behavior is often caused by\nnon-linear activation units of a model. However, the computation behavior of a\nprediction from a neural network model is locally linear, because one\nprediction has only one activation pattern. Base on the observation, we propose\nan instance-wise linearization approach to reformulates the forward computation\nprocess of a neural network prediction. This approach reformulates different\nlayers of convolution neural networks into linear matrix multiplication.\nAggregating all layers' computation, a prediction complex convolution neural\nnetwork operations can be described as a linear matrix multiplication $F(x) = W\n\\cdot x + b$. This equation can not only provides a feature attribution map\nthat highlights the important of the input features but also tells how each\ninput feature contributes to a prediction exactly. Furthermore, we discuss the\napplication of this technique in both supervise classification and unsupervised\nneural network learning parametric t-SNE dimension reduction.",
            "author": [
                "Zhimin Li",
                "Shusen Liu",
                "Kailkhura Bhavya",
                "Timo Bremer",
                "Valerio Pascucci"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16295v1",
                "http://arxiv.org/pdf/2310.16295v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16293v1",
            "title": "Crowd-Certain: Label Aggregation in Crowdsourced and Ensemble Learning\n  Classification",
            "updated": "2023-10-25T01:58:37Z",
            "published": "2023-10-25T01:58:37Z",
            "summary": "Crowdsourcing systems have been used to accumulate massive amounts of labeled\ndata for applications such as computer vision and natural language processing.\nHowever, because crowdsourced labeling is inherently dynamic and uncertain,\ndeveloping a technique that can work in most situations is extremely\nchallenging. In this paper, we introduce Crowd-Certain, a novel approach for\nlabel aggregation in crowdsourced and ensemble learning classification tasks\nthat offers improved performance and computational efficiency for different\nnumbers of annotators and a variety of datasets. The proposed method uses the\nconsistency of the annotators versus a trained classifier to determine a\nreliability score for each annotator. Furthermore, Crowd-Certain leverages\npredicted probabilities, enabling the reuse of trained classifiers on future\nsample data, thereby eliminating the need for recurrent simulation processes\ninherent in existing methods. We extensively evaluated our approach against ten\nexisting techniques across ten different datasets, each labeled by varying\nnumbers of annotators. The findings demonstrate that Crowd-Certain outperforms\nthe existing methods (Tao, Sheng, KOS, MACE, MajorityVote, MMSR, Wawa,\nZero-Based Skill, GLAD, and Dawid Skene), in nearly all scenarios, delivering\nhigher average accuracy, F1 scores, and AUC rates. Additionally, we introduce a\nvariation of two existing confidence score measurement techniques. Finally we\nevaluate these two confidence score techniques using two evaluation metrics:\nExpected Calibration Error (ECE) and Brier Score Loss. Our results show that\nCrowd-Certain achieves higher Brier Score, and lower ECE across the majority of\nthe examined datasets, suggesting better calibrated results.",
            "author": [
                "Mohammad S. Majdi",
                "Jeffrey J. Rodriguez"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16293v1",
                "http://arxiv.org/pdf/2310.16293v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16290v1",
            "title": "Fair Adaptive Experiments",
            "updated": "2023-10-25T01:52:41Z",
            "published": "2023-10-25T01:52:41Z",
            "summary": "Randomized experiments have been the gold standard for assessing the\neffectiveness of a treatment or policy. The classical complete randomization\napproach assigns treatments based on a prespecified probability and may lead to\ninefficient use of data. Adaptive experiments improve upon complete\nrandomization by sequentially learning and updating treatment assignment\nprobabilities. However, their application can also raise fairness and equity\nconcerns, as assignment probabilities may vary drastically across groups of\nparticipants. Furthermore, when treatment is expected to be extremely\nbeneficial to certain groups of participants, it is more appropriate to expose\nmany of these participants to favorable treatment. In response to these\nchallenges, we propose a fair adaptive experiment strategy that simultaneously\nenhances data use efficiency, achieves an envy-free treatment assignment\nguarantee, and improves the overall welfare of participants. An important\nfeature of our proposed strategy is that we do not impose parametric modeling\nassumptions on the outcome variables, making it more versatile and applicable\nto a wider array of applications. Through our theoretical investigation, we\ncharacterize the convergence rate of the estimated treatment effects and the\nassociated standard deviations at the group level and further prove that our\nadaptive treatment assignment algorithm, despite not having a closed-form\nexpression, approaches the optimal allocation rule asymptotically. Our proof\nstrategy takes into account the fact that the allocation decisions in our\ndesign depend on sequentially accumulated data, which poses a significant\nchallenge in characterizing the properties and conducting statistical inference\nof our method. We further provide simulation evidence to showcase the\nperformance of our fair adaptive experiment strategy.",
            "author": [
                "Waverly Wei",
                "Xinwei Ma",
                "Jingshen Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16290v1",
                "http://arxiv.org/pdf/2310.16290v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "econ.EM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12858v1",
            "title": "RAEDiff: Denoising Diffusion Probabilistic Models Based Reversible\n  Adversarial Examples Self-Generation and Self-Recovery",
            "updated": "2023-10-25T01:49:29Z",
            "published": "2023-10-25T01:49:29Z",
            "summary": "Collected and annotated datasets, which are obtained through extensive\nefforts, are effective for training Deep Neural Network (DNN) models. However,\nthese datasets are susceptible to be misused by unauthorized users, resulting\nin infringement of Intellectual Property (IP) rights owned by the dataset\ncreators. Reversible Adversarial Exsamples (RAE) can help to solve the issues\nof IP protection for datasets. RAEs are adversarial perturbed images that can\nbe restored to the original. As a cutting-edge approach, RAE scheme can serve\nthe purposes of preventing unauthorized users from engaging in malicious model\ntraining, as well as ensuring the legitimate usage of authorized users.\nNevertheless, in the existing work, RAEs still rely on the embedded auxiliary\ninformation for restoration, which may compromise their adversarial abilities.\nIn this paper, a novel self-generation and self-recovery method, named as\nRAEDiff, is introduced for generating RAEs based on a Denoising Diffusion\nProbabilistic Models (DDPM). It diffuses datasets into a Biased Gaussian\nDistribution (BGD) and utilizes the prior knowledge of the DDPM for generating\nand recovering RAEs. The experimental results demonstrate that RAEDiff\neffectively self-generates adversarial perturbations for DNN models, including\nArtificial Intelligence Generated Content (AIGC) models, while also exhibiting\nsignificant self-recovery capabilities.",
            "author": [
                "Fan Xing",
                "Xiaoyi Zhou",
                "Xuefeng Fan",
                "Zhuo Tian",
                "Yan Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12858v1",
                "http://arxiv.org/pdf/2311.12858v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.GR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16288v1",
            "title": "MotionAGFormer: Enhancing 3D Human Pose Estimation with a\n  Transformer-GCNFormer Network",
            "updated": "2023-10-25T01:46:35Z",
            "published": "2023-10-25T01:46:35Z",
            "summary": "Recent transformer-based approaches have demonstrated excellent performance\nin 3D human pose estimation. However, they have a holistic view and by encoding\nglobal relationships between all the joints, they do not capture the local\ndependencies precisely. In this paper, we present a novel Attention-GCNFormer\n(AGFormer) block that divides the number of channels by using two parallel\ntransformer and GCNFormer streams. Our proposed GCNFormer module exploits the\nlocal relationship between adjacent joints, outputting a new representation\nthat is complementary to the transformer output. By fusing these two\nrepresentation in an adaptive way, AGFormer exhibits the ability to better\nlearn the underlying 3D structure. By stacking multiple AGFormer blocks, we\npropose MotionAGFormer in four different variants, which can be chosen based on\nthe speed-accuracy trade-off. We evaluate our model on two popular benchmark\ndatasets: Human3.6M and MPI-INF-3DHP. MotionAGFormer-B achieves\nstate-of-the-art results, with P1 errors of 38.4mm and 16.2mm, respectively.\nRemarkably, it uses a quarter of the parameters and is three times more\ncomputationally efficient than the previous leading model on Human3.6M dataset.\nCode and models are available at https://github.com/TaatiTeam/MotionAGFormer.",
            "author": [
                "Soroush Mehraban",
                "Vida Adeli",
                "Babak Taati"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16288v1",
                "http://arxiv.org/pdf/2310.16288v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16285v1",
            "title": "Removing Dust from CMB Observations with Diffusion Models",
            "updated": "2023-10-25T01:36:48Z",
            "published": "2023-10-25T01:36:48Z",
            "summary": "In cosmology, the quest for primordial $B$-modes in cosmic microwave\nbackground (CMB) observations has highlighted the critical need for a refined\nmodel of the Galactic dust foreground. We investigate diffusion-based modeling\nof the dust foreground and its interest for component separation. Under the\nassumption of a Gaussian CMB with known cosmology (or covariance matrix), we\nshow that diffusion models can be trained on examples of dust emission maps\nsuch that their sampling process directly coincides with posterior sampling in\nthe context of component separation. We illustrate this on simulated mixtures\nof dust emission and CMB. We show that common summary statistics (power\nspectrum, Minkowski functionals) of the components are well recovered by this\nprocess. We also introduce a model conditioned by the CMB cosmology that\noutperforms models trained using a single cosmology on component separation.\nSuch a model will be used in future work for diffusion-based cosmological\ninference.",
            "author": [
                "David Heurtel-Depeiges",
                "Blakesley Burkhart",
                "Ruben Ohana",
                "Bruno R\u00e9galdo-Saint Blancard"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16285v1",
                "http://arxiv.org/pdf/2310.16285v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "astro-ph.GA",
                "astro-ph.IM",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16857v1",
            "title": "Improvement in Alzheimer's Disease MRI Images Analysis by Convolutional\n  Neural Networks Via Topological Optimization",
            "updated": "2023-10-25T01:36:00Z",
            "published": "2023-10-25T01:36:00Z",
            "summary": "This research underscores the efficacy of Fourier topological optimization in\nrefining MRI imagery, thereby bolstering the classification precision of\nAlzheimer's Disease through convolutional neural networks. Recognizing that MRI\nscans are indispensable for neurological assessments, but frequently grapple\nwith issues like blurriness and contrast irregularities, the deployment of\nFourier topological optimization offered enhanced delineation of brain\nstructures, ameliorated noise, and superior contrast. The applied techniques\nprioritized boundary enhancement, contrast and brightness adjustments, and\noverall image lucidity. Employing CNN architectures VGG16, ResNet50,\nInceptionV3, and Xception, the post-optimization analysis revealed a marked\nelevation in performance. Conclusively, the amalgamation of Fourier topological\noptimization with CNNs delineates a promising trajectory for the nuanced\nclassification of Alzheimer's Disease, portending a transformative impact on\nits diagnostic paradigms.",
            "author": [
                "Peiwen Tan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16857v1",
                "http://arxiv.org/pdf/2310.16857v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03707v1",
            "title": "Multi-label Text Classification using GloVe and Neural Network Models",
            "updated": "2023-10-25T01:30:26Z",
            "published": "2023-10-25T01:30:26Z",
            "summary": "This study addresses the challenges of multi-label text classification. The\ndifficulties arise from imbalanced data sets, varied text lengths, and numerous\nsubjective feature labels. Existing solutions include traditional machine\nlearning and deep neural networks for predictions. However, both approaches\nhave their limitations. Traditional machine learning often overlooks the\nassociations between words, while deep neural networks, despite their better\nclassification performance, come with increased training complexity and time.\nThis paper proposes a method utilizing the bag-of-words model approach based on\nthe GloVe model and the CNN-BiLSTM network. The principle is to use the word\nvector matrix trained by the GloVe model as the input for the text embedding\nlayer. Given that the GloVe model requires no further training, the neural\nnetwork model can be trained more efficiently. The method achieves an accuracy\nrate of 87.26% on the test set and an F1 score of 0.8737, showcasing promising\nresults.",
            "author": [
                "Hongren Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03707v1",
                "http://arxiv.org/pdf/2312.03707v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16279v1",
            "title": "TransPose: 6D Object Pose Estimation with Geometry-Aware Transformer",
            "updated": "2023-10-25T01:24:12Z",
            "published": "2023-10-25T01:24:12Z",
            "summary": "Estimating the 6D object pose is an essential task in many applications. Due\nto the lack of depth information, existing RGB-based methods are sensitive to\nocclusion and illumination changes. How to extract and utilize the geometry\nfeatures in depth information is crucial to achieve accurate predictions. To\nthis end, we propose TransPose, a novel 6D pose framework that exploits\nTransformer Encoder with geometry-aware module to develop better learning of\npoint cloud feature representations. Specifically, we first uniformly sample\npoint cloud and extract local geometry features with the designed local feature\nextractor base on graph convolution network. To improve robustness to\nocclusion, we adopt Transformer to perform the exchange of global information,\nmaking each local feature contains global information. Finally, we introduce\ngeometry-aware module in Transformer Encoder, which to form an effective\nconstrain for point cloud feature learning and makes the global information\nexchange more tightly coupled with point cloud tasks. Extensive experiments\nindicate the effectiveness of TransPose, our pose estimation pipeline achieves\ncompetitive results on three benchmark datasets.",
            "author": [
                "Xiao Lin",
                "Deming Wang",
                "Guangliang Zhou",
                "Chengju Liu",
                "Qijun Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16279v1",
                "http://arxiv.org/pdf/2310.16279v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16278v1",
            "title": "XFEVER: Exploring Fact Verification across Languages",
            "updated": "2023-10-25T01:20:17Z",
            "published": "2023-10-25T01:20:17Z",
            "summary": "This paper introduces the Cross-lingual Fact Extraction and VERification\n(XFEVER) dataset designed for benchmarking the fact verification models across\ndifferent languages. We constructed it by translating the claim and evidence\ntexts of the Fact Extraction and VERification (FEVER) dataset into six\nlanguages. The training and development sets were translated using machine\ntranslation, whereas the test set includes texts translated by professional\ntranslators and machine-translated texts. Using the XFEVER dataset, two\ncross-lingual fact verification scenarios, zero-shot learning and\ntranslate-train learning, are defined, and baseline models for each scenario\nare also proposed in this paper. Experimental results show that the\nmultilingual language model can be used to build fact verification models in\ndifferent languages efficiently. However, the performance varies by language\nand is somewhat inferior to the English case. We also found that we can\neffectively mitigate model miscalibration by considering the prediction\nsimilarity between the English and target languages. The XFEVER dataset, code,\nand model checkpoints are available at\nhttps://github.com/nii-yamagishilab/xfever.",
            "author": [
                "Yi-Chen Chang",
                "Canasai Kruengkrai",
                "Junichi Yamagishi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16278v1",
                "http://arxiv.org/pdf/2310.16278v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16277v1",
            "title": "Bayesian Domain Invariant Learning via Posterior Generalization of\n  Parameter Distributions",
            "updated": "2023-10-25T01:17:08Z",
            "published": "2023-10-25T01:17:08Z",
            "summary": "Domain invariant learning aims to learn models that extract invariant\nfeatures over various training domains, resulting in better generalization to\nunseen target domains. Recently, Bayesian Neural Networks have achieved\npromising results in domain invariant learning, but most works concentrate on\naligning features distributions rather than parameter distributions. Inspired\nby the principle of Bayesian Neural Network, we attempt to directly learn the\ndomain invariant posterior distribution of network parameters. We first propose\na theorem to show that the invariant posterior of parameters can be implicitly\ninferred by aggregating posteriors on different training domains. Our\nassumption is more relaxed and allows us to extract more domain invariant\ninformation. We also propose a simple yet effective method, named PosTerior\nGeneralization (PTG), that can be used to estimate the invariant parameter\ndistribution. PTG fully exploits variational inference to approximate parameter\ndistributions, including the invariant posterior and the posteriors on training\ndomains. Furthermore, we develop a lite version of PTG for widespread\napplications. PTG shows competitive performance on various domain\ngeneralization benchmarks on DomainBed. Additionally, PTG can use any existing\ndomain generalization methods as its prior, and combined with previous\nstate-of-the-art method the performance can be further improved. Code will be\nmade public.",
            "author": [
                "Shiyu Shen",
                "Bin Pan",
                "Tianyang Shi",
                "Tao Li",
                "Zhenwei Shi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16277v1",
                "http://arxiv.org/pdf/2310.16277v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12857v1",
            "title": "Adversarial sample generation and training using geometric masks for\n  accurate and resilient license plate character recognition",
            "updated": "2023-10-25T01:17:07Z",
            "published": "2023-10-25T01:17:07Z",
            "summary": "Reading dirty license plates accurately in moving vehicles is challenging for\nautomatic license plate recognition systems. Moreover, license plates are often\nintentionally tampered with a malicious intent to avoid police apprehension.\nUsually, such groups and individuals know how to fool the existing recognition\nsystems by making minor unnoticeable plate changes. Designing and developing\ndeep learning methods resilient to such real-world 'attack' practices remains\nan active research problem. As a solution, this work develops a resilient\nmethod to recognize license plate characters. Extracting 1057 character images\nfrom 160 Nepalese vehicles, as the first step, we trained several standard deep\nconvolutional neural networks to obtain 99.5% character classification\naccuracy. On adversarial images generated to simulate malicious tampering,\nhowever, our model's accuracy dropped to 25%. Next, we enriched our dataset by\ngenerating and adding geometrically masked images, retrained our models, and\ninvestigated the models' predictions. The proposed approach of training with\ngenerated adversarial images helped our adversarial attack-aware license plate\ncharacter recognition (AA-LPCR) model achieves an accuracy of 99.7%. This\nnear-perfect accuracy demonstrates that the proposed idea of random geometric\nmasking is highly effective for improving the accuracy of license plate\nrecognition models. Furthermore, by performing interpretability studies to\nunderstand why our models work, we identify and highlight attack-prone regions\nin the input character images. In sum, although Nepal's embossed license plate\ndetection systems are vulnerable to malicious attacks, our findings suggest\nthat these systems can be upgraded to close to 100% resilience.",
            "author": [
                "Bishal Shrestha",
                "Griwan Khakurel",
                "Kritika Simkhada",
                "Badri Adhikari"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12857v1",
                "http://arxiv.org/pdf/2311.12857v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18365v2",
            "title": "Using GPT-4 to Augment Unbalanced Data for Automatic Scoring",
            "updated": "2023-11-18T02:05:27Z",
            "published": "2023-10-25T01:07:50Z",
            "summary": "Machine learning-based automatic scoring can be challenging if students'\nresponses are unbalanced across scoring categories, as it introduces\nuncertainty in the machine training process. To meet this challenge, we\nintroduce a novel text data augmentation framework using GPT-4, a generative\nlarge language model, specifically tailored for unbalanced datasets in\nautomatic scoring. Our experimental dataset comprised student-written responses\nto two science items. We crafted prompts for GPT-4 to generate responses\nresembling student-written answers, particularly for the minority scoring\nclasses, to augment the data. We then finetuned DistillBERT for automatic\nscoring based on the augmented and original datasets. Model performance was\nassessed using accuracy, precision, recall, and F1 score. We incorporate varied\namounts of augmented data to examine scoring performance, and our findings\nrevealed remarkedly improved model performance. The average maximum increase\nobserved across two items is: 3.5% for accuracy, 30.6% for precision, 21.1% for\nrecall, and 24.2% for F1 score. Notably, using just 5% of the augmented data\nled to substantial improvements: 2.6%, 29.2%, 15.1%, and 19.6%. Interestingly,\nthe extent of improvement varied depending on specific datasets. Moreover, we\nfound that a varying amount of augmented data (5%-40%) was needed to obtain a\nstable improvement. We also compare models trained with GPT-4 augmented data\nand those trained with additional student-written responses. The findings\nindicate that former ones match or even exceed the performance of the latter.\nSpecifically, there is an average difference of 1.7%, 1.9%, 11.0%, and 7.8% for\nfour metrics separately. This research underscores the potential and\neffectiveness of data augmentation techniques utilizing GPT-4 in addressing\nunbalanced datasets within automated assessment.",
            "author": [
                "Luyang Fang",
                "Gyeong-Geon Lee",
                "Xiaoming Zhai"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18365v2",
                "http://arxiv.org/pdf/2310.18365v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16273v1",
            "title": "Deep Learning for Plant Identification and Disease Classification from\n  Leaf Images: Multi-prediction Approaches",
            "updated": "2023-10-25T01:06:18Z",
            "published": "2023-10-25T01:06:18Z",
            "summary": "Deep learning plays an important role in modern agriculture, especially in\nplant pathology using leaf images where convolutional neural networks (CNN) are\nattracting a lot of attention. While numerous reviews have explored the\napplications of deep learning within this research domain, there remains a\nnotable absence of an empirical study to offer insightful comparisons due to\nthe employment of varied datasets in the evaluation. Furthermore, a majority of\nthese approaches tend to address the problem as a singular prediction task,\noverlooking the multifaceted nature of predicting various aspects of plant\nspecies and disease types. Lastly, there is an evident need for a more profound\nconsideration of the semantic relationships that underlie plant species and\ndisease types. In this paper, we start our study by surveying current deep\nlearning approaches for plant identification and disease classification. We\ncategorise the approaches into multi-model, multi-label, multi-output, and\nmulti-task, in which different backbone CNNs can be employed. Furthermore,\nbased on the survey of existing approaches in plant pathology and the study of\navailable approaches in machine learning, we propose a new model named\nGeneralised Stacking Multi-output CNN (GSMo-CNN). To investigate the\neffectiveness of different backbone CNNs and learning approaches, we conduct an\nintensive experiment on three benchmark datasets Plant Village, Plant Leaves,\nand PlantDoc. The experimental results demonstrate that InceptionV3 can be a\ngood choice for a backbone CNN as its performance is better than AlexNet,\nVGG16, ResNet101, EfficientNet, MobileNet, and a custom CNN developed by us.\nInterestingly, empirical results support the hypothesis that using a single\nmodel can be comparable or better than using two models. Finally, we show that\nthe proposed GSMo-CNN achieves state-of-the-art performance on three benchmark\ndatasets.",
            "author": [
                "Jianping Yao",
                "Son N. Tran",
                "Saurabh Garg",
                "Samantha Sawyer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16273v1",
                "http://arxiv.org/pdf/2310.16273v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16271v1",
            "title": "CycleAlign: Iterative Distillation from Black-box LLM to White-box\n  Models for Better Human Alignment",
            "updated": "2023-10-25T01:05:03Z",
            "published": "2023-10-25T01:05:03Z",
            "summary": "Language models trained on large-scale corpus often generate content that is\nharmful, toxic, or contrary to human preferences, making their alignment with\nhuman values a critical concern. Reinforcement learning from human feedback\n(RLHF) with algorithms like PPO is a prevalent approach for alignment but is\noften complex, unstable, and resource-intensive. Recently, ranking-based\nalignment methods have emerged, offering stability and effectiveness by\nreplacing the RL framework with supervised fine-tuning, but they are costly due\nto the need for annotated data. Considering that existing large language models\n(LLMs) like ChatGPT are already relatively well-aligned and cost-friendly,\nresearchers have begun to align the language model with human preference from\nAI feedback. The common practices, which unidirectionally distill the\ninstruction-following responses from LLMs, are constrained by their bottleneck.\nThus we introduce CycleAlign to distill alignment capabilities from\nparameter-invisible LLMs (black-box) to a parameter-visible model (white-box)\nin an iterative manner. With in-context learning (ICL) as the core of the\ncycle, the black-box models are able to rank the model-generated responses\nguided by human-craft instruction and demonstrations about their preferences.\nDuring iterative interaction, the white-box models also have a judgment about\nresponses generated by them. Consequently, the agreement ranking could be\nviewed as a pseudo label to dynamically update the in-context demonstrations\nand improve the preference ranking ability of black-box models. Through\nmultiple interactions, the CycleAlign framework could align the white-box model\nwith the black-box model effectively in a low-resource way. Empirical results\nillustrate that the model fine-tuned by CycleAlign remarkably exceeds existing\nmethods, and achieves the state-of-the-art performance in alignment with human\nvalue.",
            "author": [
                "Jixiang Hong",
                "Quan Tu",
                "Changyu Chen",
                "Xing Gao",
                "Ji Zhang",
                "Rui Yan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16271v1",
                "http://arxiv.org/pdf/2310.16271v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16270v1",
            "title": "Attention Lens: A Tool for Mechanistically Interpreting the Attention\n  Head Information Retrieval Mechanism",
            "updated": "2023-10-25T01:03:35Z",
            "published": "2023-10-25T01:03:35Z",
            "summary": "Transformer-based Large Language Models (LLMs) are the state-of-the-art for\nnatural language tasks. Recent work has attempted to decode, by reverse\nengineering the role of linear layers, the internal mechanisms by which LLMs\narrive at their final predictions for text completion tasks. Yet little is\nknown about the specific role of attention heads in producing the final token\nprediction. We propose Attention Lens, a tool that enables researchers to\ntranslate the outputs of attention heads into vocabulary tokens via learned\nattention-head-specific transformations called lenses. Preliminary findings\nfrom our trained lenses indicate that attention heads play highly specialized\nroles in language models. The code for Attention Lens is available at\ngithub.com/msakarvadia/AttentionLens.",
            "author": [
                "Mansi Sakarvadia",
                "Arham Khan",
                "Aswathy Ajith",
                "Daniel Grzenda",
                "Nathaniel Hudson",
                "Andr\u00e9 Bauer",
                "Kyle Chard",
                "Ian Foster"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16270v1",
                "http://arxiv.org/pdf/2310.16270v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16267v3",
            "title": "Student Classroom Behavior Detection based on Spatio-Temporal Network\n  and Multi-Model Fusion",
            "updated": "2023-12-04T15:21:32Z",
            "published": "2023-10-25T00:46:26Z",
            "summary": "Using deep learning methods to detect students' classroom behavior\nautomatically is a promising approach for analyzing their class performance and\nimproving teaching effectiveness. However, the lack of publicly available\nspatio-temporal datasets on student behavior, as well as the high cost of\nmanually labeling such datasets, pose significant challenges for researchers in\nthis field. To address this issue, we proposed a method for extending the\nspatio-temporal behavior dataset in Student Classroom Scenarios\n(SCB-ST-Dataset4) through image dataset. Our SCB-ST-Dataset4 comprises 757265\nimages with 25810 labels, focusing on 3 behaviors: hand-raising, reading,\nwriting. Our proposed method can rapidly generate spatio-temporal behavior\ndatasets without requiring extra manual labeling. Furthermore, we proposed a\nBehavior Similarity Index (BSI) to explore the similarity of behaviors. We\nevaluated the dataset using the YOLOv5, YOLOv7, YOLOv8, and SlowFast\nalgorithms, achieving a mean average precision (map) of up to 82.3%. Last, we\nfused multiple models to generate student behavior-related data from various\nperspectives. The experiment further demonstrates the effectiveness of our\nmethod. And SCB-ST-Dataset4 provides a robust foundation for future research in\nstudent behavior detection, potentially contributing to advancements in this\nfield. The SCB-ST-Dataset4 is available for download at:\nhttps://github.com/Whiffe/SCB-dataset.",
            "author": [
                "Fan Yang",
                "Xiaofei Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16267v3",
                "http://arxiv.org/pdf/2310.16267v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16256v1",
            "title": "A Causal Disentangled Multi-Granularity Graph Classification Method",
            "updated": "2023-10-25T00:20:50Z",
            "published": "2023-10-25T00:20:50Z",
            "summary": "Graph data widely exists in real life, with large amounts of data and complex\nstructures. It is necessary to map graph data to low-dimensional embedding.\nGraph classification, a critical graph task, mainly relies on identifying the\nimportant substructures within the graph. At present, some graph classification\nmethods do not combine the multi-granularity characteristics of graph data.\nThis lack of granularity distinction in modeling leads to a conflation of key\ninformation and false correlations within the model. So, achieving the desired\ngoal of a credible and interpretable model becomes challenging. This paper\nproposes a causal disentangled multi-granularity graph representation learning\nmethod (CDM-GNN) to solve this challenge. The CDM-GNN model disentangles the\nimportant substructures and bias parts within the graph from a\nmulti-granularity perspective. The disentanglement of the CDM-GNN model reveals\nimportant and bias parts, forming the foundation for its classification task,\nspecifically, model interpretations. The CDM-GNN model exhibits strong\nclassification performance and generates explanatory outcomes aligning with\nhuman cognitive patterns. In order to verify the effectiveness of the model,\nthis paper compares the three real-world datasets MUTAG, PTC, and IMDM-M. Six\nstate-of-the-art models, namely GCN, GAT, Top-k, ASAPool, SUGAR, and SAT are\nemployed for comparison purposes. Additionally, a qualitative analysis of the\ninterpretation results is conducted.",
            "author": [
                "Yuan Li",
                "Li Liu",
                "Penggang Chen",
                "Youmin Zhang",
                "Guoyin Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16256v1",
                "http://arxiv.org/pdf/2310.16256v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16255v1",
            "title": "UAV-Sim: NeRF-based Synthetic Data Generation for UAV-based Perception",
            "updated": "2023-10-25T00:20:37Z",
            "published": "2023-10-25T00:20:37Z",
            "summary": "Tremendous variations coupled with large degrees of freedom in UAV-based\nimaging conditions lead to a significant lack of data in adequately learning\nUAV-based perception models. Using various synthetic renderers in conjunction\nwith perception models is prevalent to create synthetic data to augment the\nlearning in the ground-based imaging domain. However, severe challenges in the\naustere UAV-based domain require distinctive solutions to image synthesis for\ndata augmentation. In this work, we leverage recent advancements in neural\nrendering to improve static and dynamic novelview UAV-based image synthesis,\nespecially from high altitudes, capturing salient scene attributes. Finally, we\ndemonstrate a considerable performance boost is achieved when a state-ofthe-art\ndetection model is optimized primarily on hybrid sets of real and synthetic\ndata instead of the real or synthetic data separately.",
            "author": [
                "Christopher Maxey",
                "Jaehoon Choi",
                "Hyungtae Lee",
                "Dinesh Manocha",
                "Heesung Kwon"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16255v1",
                "http://arxiv.org/pdf/2310.16255v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16856v1",
            "title": "GraFT: Gradual Fusion Transformer for Multimodal Re-Identification",
            "updated": "2023-10-25T00:15:40Z",
            "published": "2023-10-25T00:15:40Z",
            "summary": "Object Re-Identification (ReID) is pivotal in computer vision, witnessing an\nescalating demand for adept multimodal representation learning. Current models,\nalthough promising, reveal scalability limitations with increasing modalities\nas they rely heavily on late fusion, which postpones the integration of\nspecific modality insights. Addressing this, we introduce the \\textbf{Gradual\nFusion Transformer (GraFT)} for multimodal ReID. At its core, GraFT employs\nlearnable fusion tokens that guide self-attention across encoders, adeptly\ncapturing both modality-specific and object-specific features. Further\nbolstering its efficacy, we introduce a novel training paradigm combined with\nan augmented triplet loss, optimizing the ReID feature embedding space. We\ndemonstrate these enhancements through extensive ablation studies and show that\nGraFT consistently surpasses established multimodal ReID benchmarks.\nAdditionally, aiming for deployment versatility, we've integrated neural\nnetwork pruning into GraFT, offering a balance between model size and\nperformance.",
            "author": [
                "Haoli Yin",
                "Jiayao Li",
                "Eva Schiller",
                "Luke McDermott",
                "Daniel Cummings"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16856v1",
                "http://arxiv.org/pdf/2310.16856v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16252v2",
            "title": "Near-Optimal Pure Exploration in Matrix Games: A Generalization of\n  Stochastic Bandits & Dueling Bandits",
            "updated": "2023-11-27T21:33:05Z",
            "published": "2023-10-25T00:05:37Z",
            "summary": "We study the sample complexity of identifying the pure strategy Nash\nequilibrium (PSNE) in a two-player zero-sum matrix game with noise. Formally,\nwe are given a stochastic model where any learner can sample an entry $(i,j)$\nof the input matrix $A\\in[-1,1]^{n\\times m}$ and observe $A_{i,j}+\\eta$ where\n$\\eta$ is a zero-mean 1-sub-Gaussian noise. The aim of the learner is to\nidentify the PSNE of $A$, whenever it exists, with high probability while\ntaking as few samples as possible. Zhou et al. (2017) presents an\ninstance-dependent sample complexity lower bound that depends only on the\nentries in the row and column in which the PSNE lies. We design a near-optimal\nalgorithm whose sample complexity matches the lower bound, up to log factors.\nThe problem of identifying the PSNE also generalizes the problem of pure\nexploration in stochastic multi-armed bandits and dueling bandits, and our\nresult matches the optimal bounds, up to log factors, in both the settings.",
            "author": [
                "Arnab Maiti",
                "Ross Boczar",
                "Kevin Jamieson",
                "Lillian J. Ratliff"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16252v2",
                "http://arxiv.org/pdf/2310.16252v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16249v1",
            "title": "A clustering tool for interrogating finite element models based on\n  eigenvectors of graph adjacency",
            "updated": "2023-10-24T23:49:27Z",
            "published": "2023-10-24T23:49:27Z",
            "summary": "This note introduces an unsupervised learning algorithm to debug errors in\nfinite element (FE) simulation models and details how it was productionised.\nThe algorithm clusters degrees of freedom in the FE model using numerical\nproperties of the adjacency of its stiffness matrix. The algorithm has been\ndeployed as a tool called `Model Stability Analysis' tool within the commercial\nstructural FE suite Oasys GSA (www.oasys-software.com/gsa). It has been used\nsuccessfully by end-users for debugging real world FE models and we present\nexamples of the tool in action.",
            "author": [
                "Ramaseshan Kannan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16249v1",
                "http://arxiv.org/pdf/2310.16249v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE",
                "cs.AI",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16246v1",
            "title": "Design of General Purpose Minimal-Auxiliary Ising Machines",
            "updated": "2023-10-24T23:33:26Z",
            "published": "2023-10-24T23:33:26Z",
            "summary": "Ising machines are a form of quantum-inspired processing-in-memory computer\nwhich has shown great promise for overcoming the limitations of traditional\ncomputing paradigms while operating at a fraction of the energy use. The\nprocess of designing Ising machines is known as the reverse Ising problem.\nUnfortunately, this problem is in general computationally intractable: it is a\nnonconvex mixed-integer linear programming problem which cannot be naively\nbrute-forced except in the simplest cases due to exponential scaling of runtime\nwith number of spins. We prove new theoretical results which allow us to reduce\nthe search space to one with quadratic scaling. We utilize this theory to\ndevelop general purpose algorithmic solutions to the reverse Ising problem. In\nparticular, we demonstrate Ising formulations of 3-bit and 4-bit integer\nmultiplication which use fewer total spins than previously known methods by a\nfactor of more than three. Our results increase the practicality of\nimplementing such circuits on modern Ising hardware, where spins are at a\npremium.",
            "author": [
                "Isaac K. Martin",
                "Andrew G. Moore",
                "John T. Daly",
                "Jess J. Meyer",
                "Teresa M. Ranadive"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16246v1",
                "http://arxiv.org/pdf/2310.16246v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.ET",
                "cs.NE",
                "94C11 (Primary), 90C05 68Q12 (Secondary)",
                "G.1.6; G.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16242v1",
            "title": "ZzzGPT: An Interactive GPT Approach to Enhance Sleep Quality",
            "updated": "2023-10-24T23:30:17Z",
            "published": "2023-10-24T23:30:17Z",
            "summary": "In today's world, sleep quality is pivotal for overall well-being. While\nwearable sensors offer real-time monitoring, they often lack actionable\ninsights, leading to user abandonment. This paper delves into the role of\ntechnology in understanding sleep patterns. We introduce a two-stage framework,\nutilizing Large Language Models (LLMs), aiming to provide accurate sleep\npredictions with actionable feedback. Leveraging the GLOBEM dataset and\nsynthetic data from LLMs, we highlight enhanced results with models like\nXGBoost. Our approach merges advanced machine learning with user-centric\ndesign, blending scientific accuracy with practicality.",
            "author": [
                "Yonchanok Khaokaew",
                "Thuc Hanh Nguyen",
                "Kaixin Ji",
                "Hiruni Kegalle",
                "Marwah Alaofi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16242v1",
                "http://arxiv.org/pdf/2310.16242v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16241v1",
            "title": "Task Grouping for Automated Multi-Task Machine Learning via Task\n  Affinity Prediction",
            "updated": "2023-10-24T23:29:46Z",
            "published": "2023-10-24T23:29:46Z",
            "summary": "When a number of similar tasks have to be learned simultaneously, multi-task\nlearning (MTL) models can attain significantly higher accuracy than single-task\nlearning (STL) models. However, the advantage of MTL depends on various\nfactors, such as the similarity of the tasks, the sizes of the datasets, and so\non; in fact, some tasks might not benefit from MTL and may even incur a loss of\naccuracy compared to STL. Hence, the question arises: which tasks should be\nlearned together? Domain experts can attempt to group tasks together following\nintuition, experience, and best practices, but manual grouping can be\nlabor-intensive and far from optimal. In this paper, we propose a novel\nautomated approach for task grouping. First, we study the affinity of tasks for\nMTL using four benchmark datasets that have been used extensively in the MTL\nliterature, focusing on neural network-based MTL models. We identify inherent\ntask features and STL characteristics that can help us to predict whether a\ngroup of tasks should be learned together using MTL or if they should be\nlearned independently using STL. Building on this predictor, we introduce a\nrandomized search algorithm, which employs the predictor to minimize the number\nof MTL trainings performed during the search for task groups. We demonstrate on\nthe four benchmark datasets that our predictor-driven search approach can find\nbetter task groupings than existing baseline approaches.",
            "author": [
                "Afiya Ayman",
                "Ayan Mukhopadhyay",
                "Aron Laszka"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16241v1",
                "http://arxiv.org/pdf/2310.16241v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16231v1",
            "title": "Attention-Based Ensemble Pooling for Time Series Forecasting",
            "updated": "2023-10-24T22:59:56Z",
            "published": "2023-10-24T22:59:56Z",
            "summary": "A common technique to reduce model bias in time-series forecasting is to use\nan ensemble of predictive models and pool their output into an ensemble\nforecast. In cases where each predictive model has different biases, however,\nit is not always clear exactly how each model forecast should be weighed during\nthis pooling. We propose a method for pooling that performs a weighted average\nover candidate model forecasts, where the weights are learned by an\nattention-based ensemble pooling model. We test this method on two time-series\nforecasting problems: multi-step forecasting of the dynamics of the\nnon-stationary Lorenz `63 equation, and one-step forecasting of the weekly\nincident deaths due to COVID-19. We find that while our model achieves\nexcellent valid times when forecasting the non-stationary Lorenz `63 equation,\nit does not consistently perform better than the existing ensemble pooling when\nforecasting COVID-19 weekly incident deaths.",
            "author": [
                "Dhruvit Patel",
                "Alexander Wikner"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16231v1",
                "http://arxiv.org/pdf/2310.16231v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "nlin.CD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16228v1",
            "title": "On the Foundations of Shortcut Learning",
            "updated": "2023-10-24T22:54:05Z",
            "published": "2023-10-24T22:54:05Z",
            "summary": "Deep-learning models can extract a rich assortment of features from data.\nWhich features a model uses depends not only on predictivity-how reliably a\nfeature indicates train-set labels-but also on availability-how easily the\nfeature can be extracted, or leveraged, from inputs. The literature on shortcut\nlearning has noted examples in which models privilege one feature over another,\nfor example texture over shape and image backgrounds over foreground objects.\nHere, we test hypotheses about which input properties are more available to a\nmodel, and systematically study how predictivity and availability interact to\nshape models' feature use. We construct a minimal, explicit generative\nframework for synthesizing classification datasets with two latent features\nthat vary in predictivity and in factors we hypothesize to relate to\navailability, and quantify a model's shortcut bias-its over-reliance on the\nshortcut (more available, less predictive) feature at the expense of the core\n(less available, more predictive) feature. We find that linear models are\nrelatively unbiased, but introducing a single hidden layer with ReLU or Tanh\nunits yields a bias. Our empirical findings are consistent with a theoretical\naccount based on Neural Tangent Kernels. Finally, we study how models used in\npractice trade off predictivity and availability in naturalistic datasets,\ndiscovering availability manipulations which increase models' degree of\nshortcut bias. Taken together, these findings suggest that the propensity to\nlearn shortcut features is a fundamental characteristic of deep nonlinear\narchitectures warranting systematic study given its role in shaping how models\nsolve tasks.",
            "author": [
                "Katherine L. Hermann",
                "Hossein Mobahi",
                "Thomas Fel",
                "Michael C. Mozer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16228v1",
                "http://arxiv.org/pdf/2310.16228v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16226v1",
            "title": "TiC-CLIP: Continual Training of CLIP Models",
            "updated": "2023-10-24T22:41:14Z",
            "published": "2023-10-24T22:41:14Z",
            "summary": "Keeping large foundation models up to date on latest data is inherently\nexpensive. To avoid the prohibitive costs of constantly retraining, it is\nimperative to continually train these models. This problem is exacerbated by\nthe lack of any large scale continual learning benchmarks or baselines. We\nintroduce the first set of web-scale Time-Continual (TiC) benchmarks for\ntraining vision-language models: TiC-DataCompt, TiC-YFCC, and TiC-RedCaps with\nover 12.7B timestamped image-text pairs spanning 9 years (2014--2022). We first\nuse our benchmarks to curate various dynamic evaluations to measure temporal\nrobustness of existing models. We show OpenAI's CLIP (trained on data up to\n2020) loses $\\approx 8\\%$ zero-shot accuracy on our curated retrieval task from\n2021--2022 compared with more recently trained models in OpenCLIP repository.\nWe then study how to efficiently train models on time-continuous data. We\ndemonstrate that a simple rehearsal-based approach that continues training from\nthe last checkpoint and replays old data reduces compute by $2.5\\times$ when\ncompared to the standard practice of retraining from scratch.",
            "author": [
                "Saurabh Garg",
                "Mehrdad Farajtabar",
                "Hadi Pouransari",
                "Raviteja Vemulapalli",
                "Sachin Mehta",
                "Oncel Tuzel",
                "Vaishaal Shankar",
                "Fartash Faghri"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16226v1",
                "http://arxiv.org/pdf/2310.16226v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16225v1",
            "title": "CleanCoNLL: A Nearly Noise-Free Named Entity Recognition Dataset",
            "updated": "2023-10-24T22:34:43Z",
            "published": "2023-10-24T22:34:43Z",
            "summary": "The CoNLL-03 corpus is arguably the most well-known and utilized benchmark\ndataset for named entity recognition (NER). However, prior works found\nsignificant numbers of annotation errors, incompleteness, and inconsistencies\nin the data. This poses challenges to objectively comparing NER approaches and\nanalyzing their errors, as current state-of-the-art models achieve F1-scores\nthat are comparable to or even exceed the estimated noise level in CoNLL-03. To\naddress this issue, we present a comprehensive relabeling effort assisted by\nautomatic consistency checking that corrects 7.0% of all labels in the English\nCoNLL-03. Our effort adds a layer of entity linking annotation both for better\nexplainability of NER labels and as additional safeguard of annotation quality.\nOur experimental evaluation finds not only that state-of-the-art approaches\nreach significantly higher F1-scores (97.1%) on our data, but crucially that\nthe share of correct predictions falsely counted as errors due to annotation\nnoise drops from 47% to 6%. This indicates that our resource is well suited to\nanalyze the remaining errors made by state-of-the-art models, and that the\ntheoretical upper bound even on high resource, coarse-grained NER is not yet\nreached. To facilitate such analysis, we make CleanCoNLL publicly available to\nthe research community.",
            "author": [
                "Susanna R\u00fccker",
                "Alan Akbik"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16225v1",
                "http://arxiv.org/pdf/2310.16225v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16224v1",
            "title": "Poison is Not Traceless: Fully-Agnostic Detection of Poisoning Attacks",
            "updated": "2023-10-24T22:27:44Z",
            "published": "2023-10-24T22:27:44Z",
            "summary": "The performance of machine learning models depends on the quality of the\nunderlying data. Malicious actors can attack the model by poisoning the\ntraining data. Current detectors are tied to either specific data types,\nmodels, or attacks, and therefore have limited applicability in real-world\nscenarios. This paper presents a novel fully-agnostic framework, DIVA\n(Detecting InVisible Attacks), that detects attacks solely relying on analyzing\nthe potentially poisoned data set. DIVA is based on the idea that poisoning\nattacks can be detected by comparing the classifier's accuracy on poisoned and\nclean data and pre-trains a meta-learner using Complexity Measures to estimate\nthe otherwise unknown accuracy on a hypothetical clean dataset. The framework\napplies to generic poisoning attacks. For evaluation purposes, in this paper,\nwe test DIVA on label-flipping attacks.",
            "author": [
                "Xinglong Chang",
                "Katharina Dost",
                "Gillian Dobbie",
                "J\u00f6rg Wicker"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16224v1",
                "http://arxiv.org/pdf/2310.16224v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG",
                "53-06"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16221v1",
            "title": "Hierarchical Randomized Smoothing",
            "updated": "2023-10-24T22:24:44Z",
            "published": "2023-10-24T22:24:44Z",
            "summary": "Real-world data is complex and often consists of objects that can be\ndecomposed into multiple entities (e.g. images into pixels, graphs into\ninterconnected nodes). Randomized smoothing is a powerful framework for making\nmodels provably robust against small changes to their inputs - by guaranteeing\nrobustness of the majority vote when randomly adding noise before\nclassification. Yet, certifying robustness on such complex data via randomized\nsmoothing is challenging when adversaries do not arbitrarily perturb entire\nobjects (e.g. images) but only a subset of their entities (e.g. pixels). As a\nsolution, we introduce hierarchical randomized smoothing: We partially smooth\nobjects by adding random noise only on a randomly selected subset of their\nentities. By adding noise in a more targeted manner than existing methods we\nobtain stronger robustness guarantees while maintaining high accuracy. We\ninitialize hierarchical smoothing using different noising distributions,\nyielding novel robustness certificates for discrete and continuous domains. We\nexperimentally demonstrate the importance of hierarchical smoothing in image\nand node classification, where it yields superior robustness-accuracy\ntrade-offs. Overall, hierarchical smoothing is an important contribution\ntowards models that are both - certifiably robust to perturbations and\naccurate.",
            "author": [
                "Yan Scholten",
                "Jan Schuchardt",
                "Aleksandar Bojchevski",
                "Stephan G\u00fcnnemann"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16221v1",
                "http://arxiv.org/pdf/2310.16221v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16214v1",
            "title": "Performance Tuning for GPU-Embedded Systems: Machine-Learning-based and\n  Analytical Model-driven Tuning Methodologies",
            "updated": "2023-10-24T22:09:03Z",
            "published": "2023-10-24T22:09:03Z",
            "summary": "GPU-embedded systems have gained popularity across various domains due to\ntheir efficient power consumption. However, in order to meet the demands of\nreal-time or time-consuming applications running on these systems, it is\ncrucial for them to be tuned to exhibit high performance. This paper addresses\nthe issue by developing and comparing two tuning methodologies on GPU-embedded\nsystems, and also provides performance insights for developers and researchers\nseeking to optimize applications running on these architectures. We focus on\nparallel prefix operations, such as FFT, scan primitives, and tridiagonal\nsystem solvers, which are performance-critical components in many applications.\nThe study introduces an analytical model-driven tuning methodology and a\nMachine Learning (ML)-based tuning methodology. We evaluate the performance of\nthe two tuning methodologies for different parallel prefix implementations of\nthe BPLG library in an NVIDIA Jetson system, and compare their performance to\nthe ones achieved through an exhaustive search. The findings shed light on the\nbest strategies for handling the open challenge of performance portability for\nmajor computational patterns among server and embedded devices, providing\npractical guidance for offline and online tuning. We also address the existing\ngap in performance studies for parallel computational patterns in GPU-embedded\nsystems by comparing the BPLG performance against other state-of-the-art\nlibraries, including CUSPARSE, CUB, and CUFFT.",
            "author": [
                "Adrian Perez Dieguez",
                "Margarita Amor Lopez"
            ],
            "link": [
                "http://dx.doi.org/10.1109/SBAC-PAD59825.2023.00022.",
                "http://arxiv.org/abs/2310.16214v1",
                "http://arxiv.org/pdf/2310.16214v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.LG",
                "cs.PF"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16210v1",
            "title": "Sea-Land-Cloud Segmentation in Satellite Hyperspectral Imagery by Deep\n  Learning",
            "updated": "2023-10-24T21:57:59Z",
            "published": "2023-10-24T21:57:59Z",
            "summary": "Satellites are increasingly adopting on-board Artificial Intelligence (AI)\ntechniques to enhance platforms' autonomy through edge inference. In this\ncontext, the utilization of deep learning (DL) techniques for segmentation in\nHS satellite imagery offers advantages for remote sensing applications, and\ntherefore, we train 16 different models, whose codes are made available through\nour study, which we consider to be relevant for on-board multi-class\nsegmentation of HS imagery, focusing on classifying oceanic (sea), terrestrial\n(land), and cloud formations. We employ the HYPSO-1 mission as an illustrative\ncase for sea-land-cloud segmentation, and to demonstrate the utility of the\nsegments, we introduce a novel sea-land-cloud ranking application scenario. Our\nsystem prioritizes HS image downlink based on sea, land, and cloud coverage\nlevels from the segmented images. We comparatively evaluate the models for\nin-orbit deployment, considering performance, parameter count, and inference\ntime. The models include both shallow and deep models, and after we propose\nfour new DL models, we demonstrate that segmenting single spectral signatures\n(1D) outperforms 3D data processing comprising both spectral (1D) and spatial\n(2D) contexts. We conclude that our lightweight DL model, called\n1D-Justo-LiuNet, consistently surpasses state-of-the-art models for\nsea-land-cloud segmentation, such as U-Net and its variations, in terms of\nperformance (0.93 accuracy) and parameter count (4,563). However, the 1D models\npresent longer inference time (15s) in the tested processing architecture,\nwhich is clearly suboptimal. Finally, after demonstrating that in-orbit image\nsegmentation should occur post L1b radiance calibration rather than on raw\ndata, we additionally show that reducing spectral channels down to 3 lowers\nmodels' parameters and inference time, at the cost of weaker segmentation\nperformance.",
            "author": [
                "Jon Alvarez Justo",
                "Joseph Landon Garrett",
                "Mariana-Iuliana Georgescu",
                "Jesus Gonzalez-Llorente",
                "Radu Tudor Ionescu",
                "Tor Arne Johansen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16210v1",
                "http://arxiv.org/pdf/2310.16210v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16209v1",
            "title": "ELM Ridge Regression Boosting",
            "updated": "2023-10-24T21:53:50Z",
            "published": "2023-10-24T21:53:50Z",
            "summary": "We discuss a boosting approach for the Ridge Regression (RR) method, with\napplications to the Extreme Learning Machine (ELM), and we show that the\nproposed method significantly improves the classification performance and\nrobustness of ELMs.",
            "author": [
                "M. Andrecut"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16209v1",
                "http://arxiv.org/pdf/2310.16209v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16203v1",
            "title": "Multivariate Dynamic Mediation Analysis under a Reinforcement Learning\n  Framework",
            "updated": "2023-10-24T21:43:31Z",
            "published": "2023-10-24T21:43:31Z",
            "summary": "Mediation analysis is an important analytic tool commonly used in a broad\nrange of scientific applications. In this article, we study the problem of\nmediation analysis when there are multivariate and conditionally dependent\nmediators, and when the variables are observed over multiple time points. The\nproblem is challenging, because the effect of a mediator involves not only the\npath from the treatment to this mediator itself at the current time point, but\nalso all possible paths pointed to this mediator from its upstream mediators,\nas well as the carryover effects from all previous time points. We propose a\nnovel multivariate dynamic mediation analysis approach. Drawing inspiration\nfrom the Markov decision process model that is frequently employed in\nreinforcement learning, we introduce a Markov mediation process paired with a\nsystem of time-varying linear structural equation models to formulate the\nproblem. We then formally define the individual mediation effect, built upon\nthe idea of simultaneous interventions and intervention calculus. We next\nderive the closed-form expression and propose an iterative estimation procedure\nunder the Markov mediation process model. We study both the asymptotic property\nand the empirical performance of the proposed estimator, and further illustrate\nour method with a mobile health application.",
            "author": [
                "Lan Luo",
                "Chengchun Shi",
                "Jitao Wang",
                "Zhenke Wu",
                "Lexin Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16203v1",
                "http://arxiv.org/pdf/2310.16203v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16194v1",
            "title": "Learning Low-Rank Latent Spaces with Simple Deterministic Autoencoder:\n  Theoretical and Empirical Insights",
            "updated": "2023-10-24T21:24:27Z",
            "published": "2023-10-24T21:24:27Z",
            "summary": "The autoencoder is an unsupervised learning paradigm that aims to create a\ncompact latent representation of data by minimizing the reconstruction loss.\nHowever, it tends to overlook the fact that most data (images) are embedded in\na lower-dimensional space, which is crucial for effective data representation.\nTo address this limitation, we propose a novel approach called Low-Rank\nAutoencoder (LoRAE). In LoRAE, we incorporated a low-rank regularizer to\nadaptively reconstruct a low-dimensional latent space while preserving the\nbasic objective of an autoencoder. This helps embed the data in a\nlower-dimensional space while preserving important information. It is a simple\nautoencoder extension that learns low-rank latent space. Theoretically, we\nestablish a tighter error bound for our model. Empirically, our model's\nsuperiority shines through various tasks such as image generation and\ndownstream classification. Both theoretical and practical outcomes highlight\nthe importance of acquiring low-dimensional embeddings.",
            "author": [
                "Alokendu Mazumder",
                "Tirthajit Baruah",
                "Bhartendu Kumar",
                "Rishab Sharma",
                "Vishwajeet Pattanaik",
                "Punit Rathore"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16194v1",
                "http://arxiv.org/pdf/2310.16194v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16193v1",
            "title": "Length is a Curse and a Blessing for Document-level Semantics",
            "updated": "2023-10-24T21:23:53Z",
            "published": "2023-10-24T21:23:53Z",
            "summary": "In recent years, contrastive learning (CL) has been extensively utilized to\nrecover sentence and document-level encoding capability from pre-trained\nlanguage models. In this work, we question the length generalizability of\nCL-based models, i.e., their vulnerability towards length-induced semantic\nshift. We verify not only that length vulnerability is a significant yet\noverlooked research gap, but we can devise unsupervised CL methods solely\ndepending on the semantic signal provided by document length. We first derive\nthe theoretical foundations underlying length attacks, showing that elongating\na document would intensify the high intra-document similarity that is already\nbrought by CL. Moreover, we found that isotropy promised by CL is highly\ndependent on the length range of text exposed in training. Inspired by these\nfindings, we introduce a simple yet universal document representation learning\nframework, LA(SER)$^{3}$: length-agnostic self-reference for semantically\nrobust sentence representation learning, achieving state-of-the-art\nunsupervised performance on the standard information retrieval benchmark.",
            "author": [
                "Chenghao Xiao",
                "Yizhi Li",
                "G Thomas Hudson",
                "Chenghua Lin",
                "Noura Al Moubayed"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16193v1",
                "http://arxiv.org/pdf/2310.16193v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16187v1",
            "title": "Efficient deep data assimilation with sparse observations and\n  time-varying sensors",
            "updated": "2023-10-24T21:13:59Z",
            "published": "2023-10-24T21:13:59Z",
            "summary": "Variational Data Assimilation (DA) has been broadly used in engineering\nproblems for field reconstruction and prediction by performing a weighted\ncombination of multiple sources of noisy data. In recent years, the integration\nof deep learning (DL) techniques in DA has shown promise in improving the\nefficiency and accuracy in high-dimensional dynamical systems. Nevertheless,\nexisting deep DA approaches face difficulties in dealing with unstructured\nobservation data, especially when the placement and number of sensors are\ndynamic over time. We introduce a novel variational DA scheme, named\nVoronoi-tessellation Inverse operator for VariatIonal Data assimilation\n(VIVID), that incorporates a DL inverse operator into the assimilation\nobjective function. By leveraging the capabilities of the Voronoi-tessellation\nand convolutional neural networks, VIVID is adept at handling sparse,\nunstructured, and time-varying sensor data. Furthermore, the incorporation of\nthe DL inverse operator establishes a direct link between observation and state\nspace, leading to a reduction in the number of minimization steps required for\nDA. Additionally, VIVID can be seamlessly integrated with Proper Orthogonal\nDecomposition (POD) to develop an end-to-end reduced-order DA scheme, which can\nfurther expedite field reconstruction. Numerical experiments in a fluid\ndynamics system demonstrate that VIVID can significantly outperform existing DA\nand DL algorithms. The robustness of VIVID is also accessed through the\napplication of various levels of prior error, the utilization of varying\nnumbers of sensors, and the misspecification of error covariance in DA.",
            "author": [
                "Sibo Cheng",
                "Che Liu",
                "Yike Guo",
                "Rossella Arcucci"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16187v1",
                "http://arxiv.org/pdf/2310.16187v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16186v1",
            "title": "Image Segmentation using U-Net Architecture for Powder X-ray Diffraction\n  Images",
            "updated": "2023-10-24T21:11:09Z",
            "published": "2023-10-24T21:11:09Z",
            "summary": "Scientific researchers frequently use the in situ synchrotron high-energy\npowder X-ray diffraction (XRD) technique to examine the crystallographic\nstructures of materials in functional devices such as rechargeable battery\nmaterials. We propose a method for identifying artifacts in experimental XRD\nimages. The proposed method uses deep learning convolutional neural network\narchitectures, such as tunable U-Nets to identify the artifacts. In particular,\nthe predicted artifacts are evaluated against the corresponding ground truth\n(manually implemented) using the overall true positive rate or recall. The\nresult demonstrates that the U-Nets can consistently produce great recall\nperformance at 92.4% on the test dataset, which is not included in the\ntraining, with a 34% reduction in average false positives in comparison to the\nconventional method. The U-Nets also reduce the time required to identify and\nseparate artifacts by more than 50%. Furthermore, the exclusion of the\nartifacts shows major changes in the integrated 1D XRD pattern, enhancing\nfurther analysis of the post-processing XRD data.",
            "author": [
                "Howard Yanxon",
                "Eric Roberts",
                "Hannah Parraga",
                "James Weng",
                "Wenqian Xu",
                "Uta Ruett",
                "Alexander Hexemer",
                "Petrus Zwart",
                "Nickolas Schwarz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16186v1",
                "http://arxiv.org/pdf/2310.16186v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16183v1",
            "title": "BLP 2023 Task 2: Sentiment Analysis",
            "updated": "2023-10-24T21:00:41Z",
            "published": "2023-10-24T21:00:41Z",
            "summary": "We present an overview of the BLP Sentiment Shared Task, organized as part of\nthe inaugural BLP 2023 workshop, co-located with EMNLP 2023. The task is\ndefined as the detection of sentiment in a given piece of social media text.\nThis task attracted interest from 71 participants, among whom 29 and 30 teams\nsubmitted systems during the development and evaluation phases, respectively.\nIn total, participants submitted 597 runs. However, a total of 15 teams\nsubmitted system description papers. The range of approaches in the submitted\nsystems spans from classical machine learning models, fine-tuning pre-trained\nmodels, to leveraging Large Language Model (LLMs) in zero- and few-shot\nsettings. In this paper, we provide a detailed account of the task setup,\nincluding dataset development and evaluation setup. Additionally, we provide a\nbrief overview of the systems submitted by the participants. All datasets and\nevaluation scripts from the shared task have been made publicly available for\nthe research community, to foster further research in this domain",
            "author": [
                "Md. Arid Hasan",
                "Firoj Alam",
                "Anika Anjum",
                "Shudipta Das",
                "Afiyat Anjum"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16183v1",
                "http://arxiv.org/pdf/2310.16183v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16181v1",
            "title": "Hidden Citations Obscure True Impact in Science",
            "updated": "2023-10-24T20:58:07Z",
            "published": "2023-10-24T20:58:07Z",
            "summary": "References, the mechanism scientists rely on to signal previous knowledge,\nlately have turned into widely used and misused measures of scientific impact.\nYet, when a discovery becomes common knowledge, citations suffer from\nobliteration by incorporation. This leads to the concept of hidden citation,\nrepresenting a clear textual credit to a discovery without a reference to the\npublication embodying it. Here, we rely on unsupervised interpretable machine\nlearning applied to the full text of each paper to systematically identify\nhidden citations. We find that for influential discoveries hidden citations\noutnumber citation counts, emerging regardless of publishing venue and\ndiscipline. We show that the prevalence of hidden citations is not driven by\ncitation counts, but rather by the degree of the discourse on the topic within\nthe text of the manuscripts, indicating that the more discussed is a discovery,\nthe less visible it is to standard bibliometric analysis. Hidden citations\nindicate that bibliometric measures offer a limited perspective on quantifying\nthe true impact of a discovery, raising the need to extract knowledge from the\nfull text of the scientific corpus.",
            "author": [
                "Xiangyi Meng",
                "Onur Varol",
                "Albert-L\u00e1szl\u00f3 Barab\u00e1si"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16181v1",
                "http://arxiv.org/pdf/2310.16181v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.DL",
                "cs.SI",
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16175v1",
            "title": "G-CASCADE: Efficient Cascaded Graph Convolutional Decoding for 2D\n  Medical Image Segmentation",
            "updated": "2023-10-24T20:41:04Z",
            "published": "2023-10-24T20:41:04Z",
            "summary": "In recent years, medical image segmentation has become an important\napplication in the field of computer-aided diagnosis. In this paper, we are the\nfirst to propose a new graph convolution-based decoder namely, Cascaded Graph\nConvolutional Attention Decoder (G-CASCADE), for 2D medical image segmentation.\nG-CASCADE progressively refines multi-stage feature maps generated by\nhierarchical transformer encoders with an efficient graph convolution block.\nThe encoder utilizes the self-attention mechanism to capture long-range\ndependencies, while the decoder refines the feature maps preserving long-range\ninformation due to the global receptive fields of the graph convolution block.\nRigorous evaluations of our decoder with multiple transformer encoders on five\nmedical image segmentation tasks (i.e., Abdomen organs, Cardiac organs, Polyp\nlesions, Skin lesions, and Retinal vessels) show that our model outperforms\nother state-of-the-art (SOTA) methods. We also demonstrate that our decoder\nachieves better DICE scores than the SOTA CASCADE decoder with 80.8% fewer\nparameters and 82.3% fewer FLOPs. Our decoder can easily be used with other\nhierarchical encoders for general-purpose semantic and medical image\nsegmentation tasks.",
            "author": [
                "Md Mostafijur Rahman",
                "Radu Marculescu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16175v1",
                "http://arxiv.org/pdf/2310.16175v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG",
                "I.4; J.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16173v1",
            "title": "On the Convergence and Sample Complexity Analysis of Deep Q-Networks\n  with $\u03b5$-Greedy Exploration",
            "updated": "2023-10-24T20:37:02Z",
            "published": "2023-10-24T20:37:02Z",
            "summary": "This paper provides a theoretical understanding of Deep Q-Network (DQN) with\nthe $\\varepsilon$-greedy exploration in deep reinforcement learning. Despite\nthe tremendous empirical achievement of the DQN, its theoretical\ncharacterization remains underexplored. First, the exploration strategy is\neither impractical or ignored in the existing analysis. Second, in contrast to\nconventional Q-learning algorithms, the DQN employs the target network and\nexperience replay to acquire an unbiased estimation of the mean-square Bellman\nerror (MSBE) utilized in training the Q-network. However, the existing\ntheoretical analysis of DQNs lacks convergence analysis or bypasses the\ntechnical challenges by deploying a significantly overparameterized neural\nnetwork, which is not computationally efficient. This paper provides the first\ntheoretical convergence and sample complexity analysis of the practical setting\nof DQNs with $\\epsilon$-greedy policy. We prove an iterative procedure with\ndecaying $\\epsilon$ converges to the optimal Q-value function geometrically.\nMoreover, a higher level of $\\epsilon$ values enlarges the region of\nconvergence but slows down the convergence, while the opposite holds for a\nlower level of $\\epsilon$ values. Experiments justify our established\ntheoretical insights on DQNs.",
            "author": [
                "Shuai Zhang",
                "Hongkang Li",
                "Meng Wang",
                "Miao Liu",
                "Pin-Yu Chen",
                "Songtao Lu",
                "Sijia Liu",
                "Keerthiram Murugesan",
                "Subhajit Chaudhury"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16173v1",
                "http://arxiv.org/pdf/2310.16173v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16168v1",
            "title": "Role of Multifidelity Data in Sequential Active Learning Materials\n  Discovery Campaigns: Case Study of Electronic Bandgap",
            "updated": "2023-10-24T20:33:44Z",
            "published": "2023-10-24T20:33:44Z",
            "summary": "Materials discovery and design typically proceeds through iterative\nevaluation (both experimental and computational) to obtain data, generally\ntargeting improvement of one or more properties under one or more constraints\n(e.g., time or budget). However, there can be great variation in the quality\nand cost of different data, and when they are mixed together in what we here\ncall multifidelity data the optimal approaches to their utilization are not\nestablished. It is therefore important to develop strategies to acquire and use\nmultifidelity data to realize the most efficient iterative materials\nexploration. In this work, we assess the impact of using multifidelity data\nthrough mock demonstration of designing solar cell materials, using the\nelectronic bandgap as the target property. We propose a new approach of using\nmultifidelity data through leveraging machine learning models of both low- and\nhigh-fidelity data, where using predicted low-fidelity data as an input feature\nin the high-fidelity model can improve the impact of a multifidelity data\napproach. We show how tradeoffs of low- versus high-fidelity measurement cost\nand acquisition can impact the materials discovery process, and find that the\nuse of multifidelity data has maximal impact on the materials discovery\ncampaign when approximately five low-fidelity measurements per high-fidelity\nmeasurement are performed, and when the cost of low-fidelity measurements is\napproximately 5% or less than that of high-fidelity measurements. This work\nprovides practical guidance and useful qualitative measures for improving\nmaterials discovery campaigns that involve multifidelity data.",
            "author": [
                "Ryan Jacobs",
                "Philip E. Goins",
                "Dane Morgan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16168v1",
                "http://arxiv.org/pdf/2310.16168v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16167v1",
            "title": "iNVS: Repurposing Diffusion Inpainters for Novel View Synthesis",
            "updated": "2023-10-24T20:33:19Z",
            "published": "2023-10-24T20:33:19Z",
            "summary": "We present a method for generating consistent novel views from a single\nsource image. Our approach focuses on maximizing the reuse of visible pixels\nfrom the source image. To achieve this, we use a monocular depth estimator that\ntransfers visible pixels from the source view to the target view. Starting from\na pre-trained 2D inpainting diffusion model, we train our method on the\nlarge-scale Objaverse dataset to learn 3D object priors. While training we use\na novel masking mechanism based on epipolar lines to further improve the\nquality of our approach. This allows our framework to perform zero-shot novel\nview synthesis on a variety of objects. We evaluate the zero-shot abilities of\nour framework on three challenging datasets: Google Scanned Objects, Ray Traced\nMultiview, and Common Objects in 3D. See our webpage for more details:\nhttps://yashkant.github.io/invs/",
            "author": [
                "Yash Kant",
                "Aliaksandr Siarohin",
                "Michael Vasilkovsky",
                "Riza Alp Guler",
                "Jian Ren",
                "Sergey Tulyakov",
                "Igor Gilitschenski"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16167v1",
                "http://arxiv.org/pdf/2310.16167v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17668v1",
            "title": "Fine tuning Pre trained Models for Robustness Under Noisy Labels",
            "updated": "2023-10-24T20:28:59Z",
            "published": "2023-10-24T20:28:59Z",
            "summary": "The presence of noisy labels in a training dataset can significantly impact\nthe performance of machine learning models. To tackle this issue, researchers\nhave explored methods for Learning with Noisy Labels to identify clean samples\nand reduce the influence of noisy labels. However, constraining the influence\nof a certain portion of the training dataset can result in a reduction in\noverall generalization performance. To alleviate this, recent studies have\nconsidered the careful utilization of noisy labels by leveraging huge\ncomputational resources. Therefore, the increasing training cost necessitates a\nreevaluation of efficiency. In other areas of research, there has been a focus\non developing fine-tuning techniques for large pre-trained models that aim to\nachieve both high generalization performance and efficiency. However, these\nmethods have mainly concentrated on clean datasets, and there has been limited\nexploration of the noisy label scenario. In this research, our aim is to find\nan appropriate way to fine-tune pre-trained models for noisy labeled datasets.\nTo achieve this goal, we investigate the characteristics of pre-trained models\nwhen they encounter noisy datasets. Through empirical analysis, we introduce a\nnovel algorithm called TURN, which robustly and efficiently transfers the prior\nknowledge of pre-trained models. The algorithm consists of two main steps: (1)\nindependently tuning the linear classifier to protect the feature extractor\nfrom being distorted by noisy labels, and (2) reducing the noisy label ratio\nand fine-tuning the entire model based on the noise-reduced dataset to adapt it\nto the target dataset. The proposed algorithm has been extensively tested and\ndemonstrates efficient yet improved denoising performance on various benchmarks\ncompared to previous methods.",
            "author": [
                "Sumyeong Ahn",
                "Sihyeon Kim",
                "Jongwoo Ko",
                "Se-Young Yun"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17668v1",
                "http://arxiv.org/pdf/2310.17668v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "Computer Science, Artificial Intelligence"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16162v1",
            "title": "Brainchop: Next Generation Web-Based Neuroimaging Application",
            "updated": "2023-10-24T20:17:06Z",
            "published": "2023-10-24T20:17:06Z",
            "summary": "Performing volumetric image processing directly within the browser,\nparticularly with medical data, presents unprecedented challenges compared to\nconventional backend tools. These challenges arise from limitations inherent in\nbrowser environments, such as constrained computational resources and the\navailability of frontend machine learning libraries. Consequently, there is a\nshortage of neuroimaging frontend tools capable of providing comprehensive\nend-to-end solutions for whole brain preprocessing and segmentation while\npreserving end-user data privacy and residency. In light of this context, we\nintroduce Brainchop (http://www.brainchop.org) as a groundbreaking in-browser\nneuroimaging tool that enables volumetric analysis of structural MRI using\npre-trained full-brain deep learning models, all without requiring technical\nexpertise or intricate setup procedures. Beyond its commitment to data privacy,\nthis frontend tool offers multiple features, including scalability, low\nlatency, user-friendly operation, cross-platform compatibility, and enhanced\naccessibility. This paper outlines the processing pipeline of Brainchop and\nevaluates the performance of models across various software and hardware\nconfigurations. The results demonstrate the practicality of client-side\nprocessing for volumetric data, owing to the robust MeshNet architecture, even\nwithin the resource-constrained environment of web browsers.",
            "author": [
                "Mohamed Masoud",
                "Pratyush Reddy",
                "Farfalla Hu",
                "Sergey Plis"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16162v1",
                "http://arxiv.org/pdf/2310.16162v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16161v1",
            "title": "MyriadAL: Active Few Shot Learning for Histopathology",
            "updated": "2023-10-24T20:08:15Z",
            "published": "2023-10-24T20:08:15Z",
            "summary": "Active Learning (AL) and Few Shot Learning (FSL) are two label-efficient\nmethods which have achieved excellent results recently. However, most prior\narts in both learning paradigms fail to explore the wealth of the vast\nunlabelled data. In this study, we address this issue in the scenario where the\nannotation budget is very limited, yet a large amount of unlabelled data for\nthe target task is available. We frame this work in the context of\nhistopathology where labelling is prohibitively expensive. To this end, we\nintroduce an active few shot learning framework, Myriad Active Learning (MAL),\nincluding a contrastive-learning encoder, pseudo-label generation, and novel\nquery sample selection in the loop. Specifically, we propose to massage\nunlabelled data in a self-supervised manner, where the obtained data\nrepresentations and clustering knowledge form the basis to activate the AL\nloop. With feedback from the oracle in each AL cycle, the pseudo-labels of the\nunlabelled data are refined by optimizing a shallow task-specific net on top of\nthe encoder. These updated pseudo-labels serve to inform and improve the active\nlearning query selection process. Furthermore, we introduce a novel recipe to\ncombine existing uncertainty measures and utilize the entire uncertainty list\nto reduce sample redundancy in AL. Extensive experiments on two public\nhistopathology datasets show that MAL has superior test accuracy, macro\nF1-score, and label efficiency compared to prior works, and can achieve a\ncomparable test accuracy to a fully supervised algorithm while labelling only\n5% of the dataset.",
            "author": [
                "Nico Schiavone",
                "Jingyi Wang",
                "Shuangzhi Li",
                "Roger Zemp",
                "Xingyu Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16161v1",
                "http://arxiv.org/pdf/2310.16161v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16157v1",
            "title": "Context-aware feature attribution through argumentation",
            "updated": "2023-10-24T20:02:02Z",
            "published": "2023-10-24T20:02:02Z",
            "summary": "Feature attribution is a fundamental task in both machine learning and data\nanalysis, which involves determining the contribution of individual features or\nvariables to a model's output. This process helps identify the most important\nfeatures for predicting an outcome. The history of feature attribution methods\ncan be traced back to General Additive Models (GAMs), which extend linear\nregression models by incorporating non-linear relationships between dependent\nand independent variables. In recent years, gradient-based methods and\nsurrogate models have been applied to unravel complex Artificial Intelligence\n(AI) systems, but these methods have limitations. GAMs tend to achieve lower\naccuracy, gradient-based methods can be difficult to interpret, and surrogate\nmodels often suffer from stability and fidelity issues. Furthermore, most\nexisting methods do not consider users' contexts, which can significantly\ninfluence their preferences. To address these limitations and advance the\ncurrent state-of-the-art, we define a novel feature attribution framework\ncalled Context-Aware Feature Attribution Through Argumentation (CA-FATA). Our\nframework harnesses the power of argumentation by treating each feature as an\nargument that can either support, attack or neutralize a prediction.\nAdditionally, CA-FATA formulates feature attribution as an argumentation\nprocedure, and each computation has explicit semantics, which makes it\ninherently interpretable. CA-FATA also easily integrates side information, such\nas users' contexts, resulting in more accurate predictions.",
            "author": [
                "Jinfeng Zhong",
                "Elsa Negre"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16157v1",
                "http://arxiv.org/pdf/2310.16157v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.IR",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16154v1",
            "title": "Breaking the Curse of Dimensionality in Deep Neural Networks by Learning\n  Invariant Representations",
            "updated": "2023-10-24T19:50:41Z",
            "published": "2023-10-24T19:50:41Z",
            "summary": "Artificial intelligence, particularly the subfield of machine learning, has\nseen a paradigm shift towards data-driven models that learn from and adapt to\ndata. This has resulted in unprecedented advancements in various domains such\nas natural language processing and computer vision, largely attributed to deep\nlearning, a special class of machine learning models. Deep learning arguably\nsurpasses traditional approaches by learning the relevant features from raw\ndata through a series of computational layers.\n  This thesis explores the theoretical foundations of deep learning by studying\nthe relationship between the architecture of these models and the inherent\nstructures found within the data they process. In particular, we ask What\ndrives the efficacy of deep learning algorithms and allows them to beat the\nso-called curse of dimensionality-i.e. the difficulty of generally learning\nfunctions in high dimensions due to the exponentially increasing need for data\npoints with increased dimensionality? Is it their ability to learn relevant\nrepresentations of the data by exploiting their structure? How do different\narchitectures exploit different data structures? In order to address these\nquestions, we push forward the idea that the structure of the data can be\neffectively characterized by its invariances-i.e. aspects that are irrelevant\nfor the task at hand.\n  Our methodology takes an empirical approach to deep learning, combining\nexperimental studies with physics-inspired toy models. These simplified models\nallow us to investigate and interpret the complex behaviors we observe in deep\nlearning systems, offering insights into their inner workings, with the\nfar-reaching goal of bridging the gap between theory and practice.",
            "author": [
                "Leonardo Petrini"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16154v1",
                "http://arxiv.org/pdf/2310.16154v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16152v1",
            "title": "FLTrojan: Privacy Leakage Attacks against Federated Language Models\n  Through Selective Weight Tampering",
            "updated": "2023-10-24T19:50:01Z",
            "published": "2023-10-24T19:50:01Z",
            "summary": "Federated learning (FL) is becoming a key component in many technology-based\napplications including language modeling -- where individual FL participants\noften have privacy-sensitive text data in their local datasets. However,\nrealizing the extent of privacy leakage in federated language models is not\nstraightforward and the existing attacks only intend to extract data regardless\nof how sensitive or naive it is. To fill this gap, in this paper, we introduce\ntwo novel findings with regard to leaking privacy-sensitive user data from\nfederated language models. Firstly, we make a key observation that model\nsnapshots from the intermediate rounds in FL can cause greater privacy leakage\nthan the final trained model. Secondly, we identify that privacy leakage can be\naggravated by tampering with a model's selective weights that are specifically\nresponsible for memorizing the sensitive training data. We show how a malicious\nclient can leak the privacy-sensitive data of some other user in FL even\nwithout any cooperation from the server. Our best-performing method improves\nthe membership inference recall by 29% and achieves up to 70% private data\nreconstruction, evidently outperforming existing attacks with stronger\nassumptions of adversary capabilities.",
            "author": [
                "Md Rafi Ur Rashid",
                "Vishnu Asutosh Dasu",
                "Kang Gu",
                "Najrin Sultana",
                "Shagufta Mehnaz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16152v1",
                "http://arxiv.org/pdf/2310.16152v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18364v1",
            "title": "From Heuristic to Analytic: Cognitively Motivated Strategies for\n  Coherent Physical Commonsense Reasoning",
            "updated": "2023-10-24T19:46:04Z",
            "published": "2023-10-24T19:46:04Z",
            "summary": "Pre-trained language models (PLMs) have shown impressive performance in\nvarious language tasks. However, they are prone to spurious correlations, and\noften generate illusory information. In real-world applications, PLMs should\njustify decisions with formalized, coherent reasoning chains, but this\nchallenge remains under-explored. Cognitive psychology theorizes that humans\nare capable of utilizing fast and intuitive heuristic thinking to make\ndecisions based on past experience, then rationalizing the decisions through\nslower and deliberative analytic reasoning. We incorporate these interlinked\ndual processes in fine-tuning and in-context learning with PLMs, applying them\nto two language understanding tasks that require coherent physical commonsense\nreasoning. We show that our proposed Heuristic-Analytic Reasoning (HAR)\nstrategies drastically improve the coherence of rationalizations for model\ndecisions, yielding state-of-the-art results on Tiered Reasoning for Intuitive\nPhysics (TRIP). We also find that this improved coherence is a direct result of\nmore faithful attention to relevant language context in each step of reasoning.\nOur findings suggest that human-like reasoning strategies can effectively\nimprove the coherence and reliability of PLM reasoning.",
            "author": [
                "Zheyuan Zhang",
                "Shane Storks",
                "Fengyuan Hu",
                "Sungryull Sohn",
                "Moontae Lee",
                "Honglak Lee",
                "Joyce Chai"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18364v1",
                "http://arxiv.org/pdf/2310.18364v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16142v1",
            "title": "A Language Model with Limited Memory Capacity Captures Interference in\n  Human Sentence Processing",
            "updated": "2023-10-24T19:33:27Z",
            "published": "2023-10-24T19:33:27Z",
            "summary": "Two of the central factors believed to underpin human sentence processing\ndifficulty are expectations and retrieval from working memory. A recent attempt\nto create a unified cognitive model integrating these two factors relied on the\nparallels between the self-attention mechanism of transformer language models\nand cue-based retrieval theories of working memory in human sentence processing\n(Ryu and Lewis 2021). While Ryu and Lewis show that attention patterns in\nspecialized attention heads of GPT-2 are consistent with similarity-based\ninterference, a key prediction of cue-based retrieval models, their method\nrequires identifying syntactically specialized attention heads, and makes the\ncognitively implausible assumption that hundreds of memory retrieval operations\ntake place in parallel. In the present work, we develop a recurrent neural\nlanguage model with a single self-attention head, which more closely parallels\nthe memory system assumed by cognitive theories. We show that our model's\nsingle attention head captures semantic and syntactic interference effects\nobserved in human experiments.",
            "author": [
                "William Timkey",
                "Tal Linzen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16142v1",
                "http://arxiv.org/pdf/2310.16142v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19821v1",
            "title": "A Risk-Averse Framework for Non-Stationary Stochastic Multi-Armed\n  Bandits",
            "updated": "2023-10-24T19:29:13Z",
            "published": "2023-10-24T19:29:13Z",
            "summary": "In a typical stochastic multi-armed bandit problem, the objective is often to\nmaximize the expected sum of rewards over some time horizon $T$. While the\nchoice of a strategy that accomplishes that is optimal with no additional\ninformation, it is no longer the case when provided additional\nenvironment-specific knowledge. In particular, in areas of high volatility like\nhealthcare or finance, a naive reward maximization approach often does not\naccurately capture the complexity of the learning problem and results in\nunreliable solutions. To tackle problems of this nature, we propose a framework\nof adaptive risk-aware strategies that operate in non-stationary environments.\nOur framework incorporates various risk measures prevalent in the literature to\nmap multiple families of multi-armed bandit algorithms into a risk-sensitive\nsetting. In addition, we equip the resulting algorithms with the Restarted\nBayesian Online Change-Point Detection (R-BOCPD) algorithm and impose a\n(tunable) forced exploration strategy to detect local (per-arm) switches. We\nprovide finite-time theoretical guarantees and an asymptotic regret bound of\norder $\\tilde O(\\sqrt{K_T T})$ up to time horizon $T$ with $K_T$ the total\nnumber of change-points. In practice, our framework compares favorably to the\nstate-of-the-art in both synthetic and real-world environments and manages to\nperform efficiently with respect to both risk-sensitivity and non-stationarity.",
            "author": [
                "Reda Alami",
                "Mohammed Mahfoud",
                "Mastane Achab"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19821v1",
                "http://arxiv.org/pdf/2310.19821v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16140v1",
            "title": "IA Para el Mantenimiento Predictivo en Canteras: Modelado",
            "updated": "2023-10-24T19:27:50Z",
            "published": "2023-10-24T19:27:50Z",
            "summary": "Dependence on raw materials, especially in the mining sector, is a key part\nof today's economy. Aggregates are vital, being the second most used raw\nmaterial after water. Digitally transforming this sector is key to optimizing\noperations. However, supervision and maintenance (predictive and corrective)\nare challenges little explored in this sector, due to the particularities of\nthe sector, machinery and environmental conditions. All this, despite the\nsuccesses achieved in other scenarios in monitoring with acoustic and contact\nsensors. We present an unsupervised learning scheme that trains a variational\nautoencoder model on a set of sound records. This is the first such dataset\ncollected during processing plant operations, containing information from\ndifferent points of the processing line. Our results demonstrate the model's\nability to reconstruct and represent in latent space the recorded sounds, the\ndifferences in operating conditions and between different equipment. In the\nfuture, this should facilitate the classification of sounds, as well as the\ndetection of anomalies and degradation patterns in the operation of the\nmachinery.",
            "author": [
                "Fernando Marcos",
                "Rodrigo Tamaki",
                "Mateo C\u00e1mara",
                "Virginia Yag\u00fce",
                "Jos\u00e9 Luis Blanco"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16140v1",
                "http://arxiv.org/pdf/2310.16140v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16139v1",
            "title": "Pix2HDR -- A pixel-wise acquisition and deep learning-based synthesis\n  approach for high-speed HDR videos",
            "updated": "2023-10-24T19:27:35Z",
            "published": "2023-10-24T19:27:35Z",
            "summary": "Accurately capturing dynamic scenes with wide-ranging motion and light\nintensity is crucial for many vision applications. However, acquiring\nhigh-speed high dynamic range (HDR) video is challenging because the camera's\nframe rate restricts its dynamic range. Existing methods sacrifice speed to\nacquire multi-exposure frames. Yet, misaligned motion in these frames can still\npose complications for HDR fusion algorithms, resulting in artifacts. Instead\nof frame-based exposures, we sample the videos using individual pixels at\nvarying exposures and phase offsets. Implemented on a pixel-wise programmable\nimage sensor, our sampling pattern simultaneously captures fast motion at a\nhigh dynamic range. We then transform pixel-wise outputs into an HDR video\nusing end-to-end learned weights from deep neural networks, achieving high\nspatiotemporal resolution with minimized motion blurring. We demonstrate\naliasing-free HDR video acquisition at 1000 FPS, resolving fast motion under\nlow-light conditions and against bright backgrounds - both challenging\nconditions for conventional cameras. By combining the versatility of pixel-wise\nsampling patterns with the strength of deep neural networks at decoding complex\nscenes, our method greatly enhances the vision system's adaptability and\nperformance in dynamic conditions.",
            "author": [
                "Caixin Wang",
                "Jie Zhang",
                "Matthew A. Wilson",
                "Ralph Etienne-Cummings"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16139v1",
                "http://arxiv.org/pdf/2310.16139v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16138v1",
            "title": "Subtle Signals: Video-based Detection of Infant Non-nutritive Sucking as\n  a Neurodevelopmental Cue",
            "updated": "2023-10-24T19:26:07Z",
            "published": "2023-10-24T19:26:07Z",
            "summary": "Non-nutritive sucking (NNS), which refers to the act of sucking on a\npacifier, finger, or similar object without nutrient intake, plays a crucial\nrole in assessing healthy early development. In the case of preterm infants,\nNNS behavior is a key component in determining their readiness for feeding. In\nolder infants, the characteristics of NNS behavior offer valuable insights into\nneural and motor development. Additionally, NNS activity has been proposed as a\npotential safeguard against sudden infant death syndrome (SIDS). However, the\nclinical application of NNS assessment is currently hindered by labor-intensive\nand subjective finger-in-mouth evaluations. Consequently, researchers often\nresort to expensive pressure transducers for objective NNS signal measurement.\nTo enhance the accessibility and reliability of NNS signal monitoring for both\nclinicians and researchers, we introduce a vision-based algorithm designed for\nnon-contact detection of NNS activity using baby monitor footage in natural\nsettings. Our approach involves a comprehensive exploration of optical flow and\ntemporal convolutional networks, enabling the detection and amplification of\nsubtle infant-sucking signals. We successfully classify short video clips of\nuniform length into NNS and non-NNS periods. Furthermore, we investigate manual\nand learning-based techniques to piece together local classification results,\nfacilitating the segmentation of longer mixed-activity videos into NNS and\nnon-NNS segments of varying duration. Our research introduces two novel\ndatasets of annotated infant videos, including one sourced from our clinical\nstudy featuring 19 infant subjects and 183 hours of overnight baby monitor\nfootage.",
            "author": [
                "Shaotong Zhu",
                "Michael Wan",
                "Sai Kumar Reddy Manne",
                "Emily Zimmerman",
                "Sarah Ostadabbas"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16138v1",
                "http://arxiv.org/pdf/2310.16138v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16125v2",
            "title": "Online Two-stage Thermal History Prediction Method for Metal Additive\n  Manufacturing of Thin Walls",
            "updated": "2023-11-17T19:46:15Z",
            "published": "2023-10-24T18:58:36Z",
            "summary": "This paper aims to propose an online two-stage thermal history prediction\nmethod, which could be integrated into a metal AM process for performance\ncontrol. Based on the similarity of temperature curves (curve segments of a\ntemperature profile of one point) between any two successive layers, the first\nstage of the proposed method designs a layer-to-layer prediction model to\nestimate the temperature curves of the yet-to-print layer from measured\ntemperatures of certain points on the previously printed layer. With\nmeasured/predicted temperature profiles of several points on the same layer,\nthe second stage proposes a reduced order model (ROM) (intra-layer prediction\nmodel) to decompose and construct the temperature profiles of all points on the\nsame layer, which could be used to build the temperature field of the entire\nlayer. The training of ROM is performed with an extreme learning machine (ELM)\nfor computational efficiency. Fifteen wire arc AM experiments and nine\nsimulations are designed for thin walls with a fixed length and unidirectional\nprinting of each layer. The test results indicate that the proposed prediction\nmethod could construct the thermal history of a yet-to-print layer within 0.1\nseconds on a low-cost desktop computer. Meanwhile, the method has acceptable\ngeneralization capability in most cases from lower layers to higher layers in\nthe same simulation, as well as from one simulation to a new simulation on\ndifferent AM process parameters. More importantly, after fine-tuning the\nproposed method with limited experimental data, the relative errors of all\npredicted temperature profiles on a new experiment are smaller than 0.09, which\ndemonstrates the applicability and generalization of the proposed two-stage\nthermal history prediction method in online applications for metal AM.",
            "author": [
                "Yifan Tang",
                "M. Rahmani Dehaghani",
                "Pouyan Sajadi",
                "Shahriar Bakrani Balani",
                "Akshay Dhalpe",
                "Suraj Panicker",
                "Di Wu",
                "Eric Coatanea",
                "G. Gary Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16125v2",
                "http://arxiv.org/pdf/2310.16125v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16123v1",
            "title": "Anchor Space Optimal Transport: Accelerating Batch Processing of\n  Multiple OT Problems",
            "updated": "2023-10-24T18:55:12Z",
            "published": "2023-10-24T18:55:12Z",
            "summary": "The optimal transport (OT) theory provides an effective way to compare\nprobability distributions on a defined metric space, but it suffers from cubic\ncomputational complexity. Although the Sinkhorn's algorithm greatly reduces the\ncomputational complexity of OT solutions, the solutions of multiple OT problems\nare still time-consuming and memory-comsuming in practice. However, many works\non the computational acceleration of OT are usually based on the premise of a\nsingle OT problem, ignoring the potential common characteristics of the\ndistributions in a mini-batch. Therefore, we propose a translated OT problem\ndesignated as the anchor space optimal transport (ASOT) problem, which is\nspecially designed for batch processing of multiple OT problem solutions. For\nthe proposed ASOT problem, the distributions will be mapped into a shared\nanchor point space, which learns the potential common characteristics and thus\nhelp accelerate OT batch processing. Based on the proposed ASOT, the\nWasserstein distance error to the original OT problem is proven to be bounded\nby ground cost errors. Building upon this, we propose three methods to learn an\nanchor space minimizing the distance error, each of which has its application\nbackground. Numerical experiments on real-world datasets show that our proposed\nmethods can greatly reduce computational time while maintaining reasonable\napproximation performance.",
            "author": [
                "Jianming Huang",
                "Xun Su",
                "Zhongxi Fang",
                "Hiroyuki Kasai"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16123v1",
                "http://arxiv.org/pdf/2310.16123v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16122v1",
            "title": "A Performance-Portable SYCL Implementation of CRK-HACC for Exascale",
            "updated": "2023-10-24T18:52:24Z",
            "published": "2023-10-24T18:52:24Z",
            "summary": "The first generation of exascale systems will include a variety of machine\narchitectures, featuring GPUs from multiple vendors. As a result, many\ndevelopers are interested in adopting portable programming models to avoid\nmaintaining multiple versions of their code. It is necessary to document\nexperiences with such programming models to assist developers in understanding\nthe advantages and disadvantages of different approaches.\n  To this end, this paper evaluates the performance portability of a SYCL\nimplementation of a large-scale cosmology application (CRK-HACC) running on\nGPUs from three different vendors: AMD, Intel, and NVIDIA. We detail the\nprocess of migrating the original code from CUDA to SYCL and show that\nspecializing kernels for specific targets can greatly improve performance\nportability without significantly impacting programmer productivity. The SYCL\nversion of CRK-HACC achieves a performance portability of 0.96 with a code\ndivergence of almost 0, demonstrating that SYCL is a viable programming model\nfor performance-portable applications.",
            "author": [
                "Esteban M. Rangel",
                "S. John Pennycook",
                "Adrian Pope",
                "Nicholas Frontiere",
                "Zhiqiang Ma",
                "Varsha Madananth"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16122v1",
                "http://arxiv.org/pdf/2310.16122v1"
            ],
            "primary_category": "cs.PF",
            "category": [
                "cs.PF",
                "astro-ph.CO",
                "cs.DC",
                "D.2.7; D.2.8; D.1.3; J.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16121v2",
            "title": "19 Parameters Is All You Need: Tiny Neural Networks for Particle Physics",
            "updated": "2023-11-29T22:13:24Z",
            "published": "2023-10-24T18:51:22Z",
            "summary": "As particle accelerators increase their collision rates, and deep learning\nsolutions prove their viability, there is a growing need for lightweight and\nfast neural network architectures for low-latency tasks such as triggering. We\nexamine the potential of one recent Lorentz- and permutation-symmetric\narchitecture, PELICAN, and present its instances with as few as 19 trainable\nparameters that outperform generic architectures with tens of thousands of\nparameters when compared on the binary classification task of top quark jet\ntagging.",
            "author": [
                "Alexander Bogatskiy",
                "Timothy Hoffman",
                "Jan T. Offermann"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16121v2",
                "http://arxiv.org/pdf/2310.16121v2"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "cs.LG",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16119v1",
            "title": "Alquist 5.0: Dialogue Trees Meet Generative Models. A Novel Approach for\n  Enhancing SocialBot Conversations",
            "updated": "2023-10-24T18:47:13Z",
            "published": "2023-10-24T18:47:13Z",
            "summary": "We present our SocialBot -- Alquist~5.0 -- developed for the Alexa Prize\nSocialBot Grand Challenge~5. Building upon previous versions of our system, we\nintroduce the NRG Barista and outline several innovative approaches for\nintegrating Barista into our SocialBot, improving the overall conversational\nexperience. Additionally, we extend our SocialBot to support multimodal\ndevices. This paper offers insights into the development of Alquist~5.0, which\nmeets evolving user expectations while maintaining empathetic and knowledgeable\nconversational abilities across diverse topics.",
            "author": [
                "Ond\u0159ej Kobza",
                "Jan \u010cuhel",
                "Tommaso Gargiani",
                "David Herel",
                "Petr Marek"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16119v1",
                "http://arxiv.org/pdf/2310.16119v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16117v1",
            "title": "NADI 2023: The Fourth Nuanced Arabic Dialect Identification Shared Task",
            "updated": "2023-10-24T18:41:24Z",
            "published": "2023-10-24T18:41:24Z",
            "summary": "We describe the findings of the fourth Nuanced Arabic Dialect Identification\nShared Task (NADI 2023). The objective of NADI is to help advance\nstate-of-the-art Arabic NLP by creating opportunities for teams of researchers\nto collaboratively compete under standardized conditions. It does so with a\nfocus on Arabic dialects, offering novel datasets and defining subtasks that\nallow for meaningful comparisons between different approaches. NADI 2023\ntargeted both dialect identification (Subtask 1) and dialect-to-MSA machine\ntranslation (Subtask 2 and Subtask 3). A total of 58 unique teams registered\nfor the shared task, of whom 18 teams have participated (with 76 valid\nsubmissions during test phase). Among these, 16 teams participated in Subtask\n1, 5 participated in Subtask 2, and 3 participated in Subtask 3. The winning\nteams achieved 87.27\n  F1 on Subtask 1, 14.76 Bleu in Subtask 2, and 21.10 Bleu in Subtask 3,\nrespectively. Results show that all three subtasks remain challenging, thereby\nmotivating future work in this area. We describe the methods employed by the\nparticipating teams and briefly offer an outlook for NADI.",
            "author": [
                "Muhammad Abdul-Mageed",
                "AbdelRahim Elmadany",
                "Chiyu Zhang",
                "El Moatez Billah Nagoudi",
                "Houda Bouamor",
                "Nizar Habash"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16117v1",
                "http://arxiv.org/pdf/2310.16117v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16115v1",
            "title": "Wakening Past Concepts without Past Data: Class-Incremental Learning\n  from Online Placebos",
            "updated": "2023-10-24T18:32:46Z",
            "published": "2023-10-24T18:32:46Z",
            "summary": "Not forgetting old class knowledge is a key challenge for class-incremental\nlearning (CIL) when the model continuously adapts to new classes. A common\ntechnique to address this is knowledge distillation (KD), which penalizes\nprediction inconsistencies between old and new models. Such prediction is made\nwith almost new class data, as old class data is extremely scarce due to the\nstrict memory limitation in CIL. In this paper, we take a deep dive into KD\nlosses and find that \"using new class data for KD\" not only hinders the model\nadaption (for learning new classes) but also results in low efficiency for\npreserving old class knowledge. We address this by \"using the placebos of old\nclasses for KD\", where the placebos are chosen from a free image stream, such\nas Google Images, in an automatical and economical fashion. To this end, we\ntrain an online placebo selection policy to quickly evaluate the quality of\nstreaming images (good or bad placebos) and use only good ones for one-time\nfeed-forward computation of KD. We formulate the policy training process as an\nonline Markov Decision Process (MDP), and introduce an online learning\nalgorithm to solve this MDP problem without causing much computation costs. In\nexperiments, we show that our method 1) is surprisingly effective even when\nthere is no class overlap between placebos and original old class data, 2) does\nnot require any additional supervision or memory budget, and 3) significantly\noutperforms a number of top-performing CIL methods, in particular when using\nlower memory budgets for old class exemplars, e.g., five exemplars per class.",
            "author": [
                "Yaoyao Liu",
                "Yingying Li",
                "Bernt Schiele",
                "Qianru Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16115v1",
                "http://arxiv.org/pdf/2310.16115v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16855v1",
            "title": "Stock Market Directional Bias Prediction Using ML Algorithms",
            "updated": "2023-10-24T18:26:57Z",
            "published": "2023-10-24T18:26:57Z",
            "summary": "The stock market has been established since the 13th century, but in the\ncurrent epoch of time, it is substantially more practicable to anticipate the\nstock market than it was at any other point in time due to the tools and data\nthat are available for both traditional and algorithmic trading. There are many\ndifferent machine learning models that can do time-series forecasting in the\ncontext of machine learning. These models can be used to anticipate the future\nprices of assets and/or the directional bias of assets. In this study, we\nexamine and contrast the effectiveness of three different machine learning\nalgorithms, namely, logistic regression, decision tree, and random forest to\nforecast the movement of the assets traded on the Japanese stock market. In\naddition, the models are compared to a feed forward deep neural network, and it\nis found that all of the models consistently reach above 50% in directional\nbias forecasting for the stock market. The results of our study contribute to a\nbetter understanding of the complexity involved in stock market forecasting and\ngive insight on the possible role that machine learning could play in this\ncontext.",
            "author": [
                "Ryan Chipwanya"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16855v1",
                "http://arxiv.org/pdf/2310.16855v1"
            ],
            "primary_category": "q-fin.ST",
            "category": [
                "q-fin.ST",
                "ACM-class: F.2.2, I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16113v1",
            "title": "Compressed representation of brain genetic transcription",
            "updated": "2023-10-24T18:26:43Z",
            "published": "2023-10-24T18:26:43Z",
            "summary": "The architecture of the brain is too complex to be intuitively surveyable\nwithout the use of compressed representations that project its variation into a\ncompact, navigable space. The task is especially challenging with\nhigh-dimensional data, such as gene expression, where the joint complexity of\nanatomical and transcriptional patterns demands maximum compression.\nEstablished practice is to use standard principal component analysis (PCA),\nwhose computational felicity is offset by limited expressivity, especially at\ngreat compression ratios. Employing whole-brain, voxel-wise Allen Brain Atlas\ntranscription data, here we systematically compare compressed representations\nbased on the most widely supported linear and non-linear methods-PCA, kernel\nPCA, non-negative matrix factorization (NMF), t-stochastic neighbour embedding\n(t-SNE), uniform manifold approximation and projection (UMAP), and deep\nauto-encoding-quantifying reconstruction fidelity, anatomical coherence, and\npredictive utility with respect to signalling, microstructural, and metabolic\ntargets. We show that deep auto-encoders yield superior representations across\nall metrics of performance and target domains, supporting their use as the\nreference standard for representing transcription patterns in the human brain.",
            "author": [
                "James K Ruffle",
                "Henry Watkins",
                "Robert J Gray",
                "Harpreet Hyare",
                "Michel Thiebaut de Schotten",
                "Parashkev Nachev"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16113v1",
                "http://arxiv.org/pdf/2310.16113v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.GN",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16112v1",
            "title": "Towards long-tailed, multi-label disease classification from chest\n  X-ray: Overview of the CXR-LT challenge",
            "updated": "2023-10-24T18:26:22Z",
            "published": "2023-10-24T18:26:22Z",
            "summary": "Many real-world image recognition problems, such as diagnostic medical\nimaging exams, are \"long-tailed\" $\\unicode{x2013}$ there are a few common\nfindings followed by many more relatively rare conditions. In chest\nradiography, diagnosis is both a long-tailed and multi-label problem, as\npatients often present with multiple findings simultaneously. While researchers\nhave begun to study the problem of long-tailed learning in medical image\nrecognition, few have studied the interaction of label imbalance and label\nco-occurrence posed by long-tailed, multi-label disease classification. To\nengage with the research community on this emerging topic, we conducted an open\nchallenge, CXR-LT, on long-tailed, multi-label thorax disease classification\nfrom chest X-rays (CXRs). We publicly release a large-scale benchmark dataset\nof over 350,000 CXRs, each labeled with at least one of 26 clinical findings\nfollowing a long-tailed distribution. We synthesize common themes of\ntop-performing solutions, providing practical recommendations for long-tailed,\nmulti-label medical image classification. Finally, we use these insights to\npropose a path forward involving vision-language foundation models for few- and\nzero-shot disease classification.",
            "author": [
                "Gregory Holste",
                "Yiliang Zhou",
                "Song Wang",
                "Ajay Jaiswal",
                "Mingquan Lin",
                "Sherry Zhuge",
                "Yuzhe Yang",
                "Dongkyun Kim",
                "Trong-Hieu Nguyen-Mau",
                "Minh-Triet Tran",
                "Jaehyup Jeong",
                "Wongi Park",
                "Jongbin Ryu",
                "Feng Hong",
                "Arsh Verma",
                "Yosuke Yamagishi",
                "Changhyun Kim",
                "Hyeryeong Seo",
                "Myungjoo Kang",
                "Leo Anthony Celi",
                "Zhiyong Lu",
                "Ronald M. Summers",
                "George Shih",
                "Zhangyang Wang",
                "Yifan Peng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16112v1",
                "http://arxiv.org/pdf/2310.16112v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16111v2",
            "title": "Locally Differentially Private Document Generation Using Zero Shot\n  Prompting",
            "updated": "2023-11-30T18:13:01Z",
            "published": "2023-10-24T18:25:13Z",
            "summary": "Numerous studies have highlighted the privacy risks associated with\npretrained large language models. In contrast, our research offers a unique\nperspective by demonstrating that pretrained large language models can\neffectively contribute to privacy preservation. We propose a locally\ndifferentially private mechanism called DP-Prompt, which leverages the power of\npretrained large language models and zero-shot prompting to counter author\nde-anonymization attacks while minimizing the impact on downstream utility.\nWhen DP-Prompt is used with a powerful language model like ChatGPT (gpt-3.5),\nwe observe a notable reduction in the success rate of de-anonymization attacks,\nshowing that it surpasses existing approaches by a considerable margin despite\nits simpler design. For instance, in the case of the IMDB dataset, DP-Prompt\n(with ChatGPT) perfectly recovers the clean sentiment F1 score while achieving\na 46\\% reduction in author identification F1 score against static attackers and\na 26\\% reduction against adaptive attackers. We conduct extensive experiments\nacross six open-source large language models, ranging up to 7 billion\nparameters, to analyze various effects of the privacy-utility tradeoff.",
            "author": [
                "Saiteja Utpala",
                "Sara Hooker",
                "Pin Yu Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16111v2",
                "http://arxiv.org/pdf/2310.16111v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16106v1",
            "title": "Decentralized Learning over Wireless Networks with Broadcast-Based\n  Subgraph Sampling",
            "updated": "2023-10-24T18:15:52Z",
            "published": "2023-10-24T18:15:52Z",
            "summary": "This work centers on the communication aspects of decentralized learning over\nwireless networks, using consensus-based decentralized stochastic gradient\ndescent (D-SGD). Considering the actual communication cost or delay caused by\nin-network information exchange in an iterative process, our goal is to achieve\nfast convergence of the algorithm measured by improvement per transmission\nslot. We propose BASS, an efficient communication framework for D-SGD over\nwireless networks with broadcast transmission and probabilistic subgraph\nsampling. In each iteration, we activate multiple subsets of non-interfering\nnodes to broadcast model updates to their neighbors. These subsets are randomly\nactivated over time, with probabilities reflecting their importance in network\nconnectivity and subject to a communication cost constraint (e.g., the average\nnumber of transmission slots per iteration). During the consensus update step,\nonly bi-directional links are effectively preserved to maintain communication\nsymmetry. In comparison to existing link-based scheduling methods, the inherent\nbroadcasting nature of wireless channels offers intrinsic advantages in\nspeeding up convergence of decentralized learning by creating more communicated\nlinks with the same number of transmission slots.",
            "author": [
                "Daniel P\u00e9rez Herrera",
                "Zheng Chen",
                "Erik G. Larsson"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16106v1",
                "http://arxiv.org/pdf/2310.16106v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC",
                "cs.IT",
                "cs.SY",
                "eess.SY",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16105v2",
            "title": "Locally Differentially Private Gradient Tracking for Distributed Online\n  Learning over Directed Graphs",
            "updated": "2023-10-29T17:34:15Z",
            "published": "2023-10-24T18:15:25Z",
            "summary": "Distributed online learning has been proven extremely effective in solving\nlarge-scale machine learning problems over streaming data. However, information\nsharing between learners in distributed learning also raises concerns about the\npotential leakage of individual learners' sensitive data. To mitigate this\nrisk, differential privacy, which is widely regarded as the \"gold standard\" for\nprivacy protection, has been widely employed in many existing results on\ndistributed online learning. However, these results often face a fundamental\ntradeoff between learning accuracy and privacy. In this paper, we propose a\nlocally differentially private gradient tracking based distributed online\nlearning algorithm that successfully circumvents this tradeoff. We prove that\nthe proposed algorithm converges in mean square to the exact optimal solution\nwhile ensuring rigorous local differential privacy, with the cumulative privacy\nbudget guaranteed to be finite even when the number of iterations tends to\ninfinity. The algorithm is applicable even when the communication graph among\nlearners is directed. To the best of our knowledge, this is the first result\nthat simultaneously ensures learning accuracy and rigorous local differential\nprivacy in distributed online learning over directed graphs. We evaluate our\nalgorithm's performance by using multiple benchmark machine-learning\napplications, including logistic regression of the \"Mushrooms\" dataset and\nCNN-based image classification of the \"MNIST\" and \"CIFAR-10\" datasets,\nrespectively. The experimental results confirm that the proposed algorithm\noutperforms existing counterparts in both training and testing accuracies.",
            "author": [
                "Ziqin Chen",
                "Yongqiang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16105v2",
                "http://arxiv.org/pdf/2310.16105v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16103v1",
            "title": "LaksNet: an end-to-end deep learning model for self-driving cars in\n  Udacity simulator",
            "updated": "2023-10-24T18:11:25Z",
            "published": "2023-10-24T18:11:25Z",
            "summary": "The majority of road accidents occur because of human errors, including\ndistraction, recklessness, and drunken driving. One of the effective ways to\novercome this dangerous situation is by implementing self-driving technologies\nin vehicles. In this paper, we focus on building an efficient deep-learning\nmodel for self-driving cars. We propose a new and effective convolutional\nneural network model called `LaksNet' consisting of four convolutional layers\nand two fully connected layers. We conduct extensive experiments using our\nLaksNet model with the training data generated from the Udacity simulator. Our\nmodel outperforms many existing pre-trained ImageNet and NVIDIA models in terms\nof the duration of the car for which it drives without going off the track on\nthe simulator.",
            "author": [
                "Lakshmikar R. Polamreddy",
                "Youshan Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16103v1",
                "http://arxiv.org/pdf/2310.16103v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16102v1",
            "title": "Learned, Uncertainty-driven Adaptive Acquisition for Photon-Efficient\n  Multiphoton Microscopy",
            "updated": "2023-10-24T18:06:03Z",
            "published": "2023-10-24T18:06:03Z",
            "summary": "Multiphoton microscopy (MPM) is a powerful imaging tool that has been a\ncritical enabler for live tissue imaging. However, since most multiphoton\nmicroscopy platforms rely on point scanning, there is an inherent trade-off\nbetween acquisition time, field of view (FOV), phototoxicity, and image\nquality, often resulting in noisy measurements when fast, large FOV, and/or\ngentle imaging is needed. Deep learning could be used to denoise multiphoton\nmicroscopy measurements, but these algorithms can be prone to hallucination,\nwhich can be disastrous for medical and scientific applications. We propose a\nmethod to simultaneously denoise and predict pixel-wise uncertainty for\nmultiphoton imaging measurements, improving algorithm trustworthiness and\nproviding statistical guarantees for the deep learning predictions.\nFurthermore, we propose to leverage this learned, pixel-wise uncertainty to\ndrive an adaptive acquisition technique that rescans only the most uncertain\nregions of a sample. We demonstrate our method on experimental noisy MPM\nmeasurements of human endometrium tissues, showing that we can maintain fine\nfeatures and outperform other denoising methods while predicting uncertainty at\neach pixel. Finally, with our adaptive acquisition technique, we demonstrate a\n120X reduction in acquisition time and total light dose while successfully\nrecovering fine features in the sample. We are the first to demonstrate\ndistribution-free uncertainty quantification for a denoising task with real\nexperimental data and the first to propose adaptive acquisition based on\nreconstruction uncertainty",
            "author": [
                "Cassandra Tong Ye",
                "Jiashu Han",
                "Kunzan Liu",
                "Anastasios Angelopoulos",
                "Linda Griffith",
                "Kristina Monakhova",
                "Sixian You"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16102v1",
                "http://arxiv.org/pdf/2310.16102v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16099v1",
            "title": "Anatomically-aware Uncertainty for Semi-supervised Image Segmentation",
            "updated": "2023-10-24T18:03:07Z",
            "published": "2023-10-24T18:03:07Z",
            "summary": "Semi-supervised learning relaxes the need of large pixel-wise labeled\ndatasets for image segmentation by leveraging unlabeled data. A prominent way\nto exploit unlabeled data is to regularize model predictions. Since the\npredictions of unlabeled data can be unreliable, uncertainty-aware schemes are\ntypically employed to gradually learn from meaningful and reliable predictions.\nUncertainty estimation methods, however, rely on multiple inferences from the\nmodel predictions that must be computed for each training step, which is\ncomputationally expensive. Moreover, these uncertainty maps capture pixel-wise\ndisparities and do not consider global information. This work proposes a novel\nmethod to estimate segmentation uncertainty by leveraging global information\nfrom the segmentation masks. More precisely, an anatomically-aware\nrepresentation is first learnt to model the available segmentation masks. The\nlearnt representation thereupon maps the prediction of a new segmentation into\nan anatomically-plausible segmentation. The deviation from the plausible\nsegmentation aids in estimating the underlying pixel-level uncertainty in order\nto further guide the segmentation network. The proposed method consequently\nestimates the uncertainty using a single inference from our representation,\nthereby reducing the total computation. We evaluate our method on two publicly\navailable segmentation datasets of left atria in cardiac MRIs and of multiple\norgans in abdominal CTs. Our anatomically-aware method improves the\nsegmentation accuracy over the state-of-the-art semi-supervised methods in\nterms of two commonly used evaluation metrics.",
            "author": [
                "Sukesh Adiga V",
                "Jose Dolz",
                "Herve Lombaert"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16099v1",
                "http://arxiv.org/pdf/2310.16099v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16095v1",
            "title": "CR-COPEC: Causal Rationale of Corporate Performance Changes to Learn\n  from Financial Reports",
            "updated": "2023-10-24T18:00:40Z",
            "published": "2023-10-24T18:00:40Z",
            "summary": "In this paper, we introduce CR-COPEC called Causal Rationale of Corporate\nPerformance Changes from financial reports. This is a comprehensive large-scale\ndomain-adaptation causal sentence dataset to detect financial performance\nchanges of corporate. CR-COPEC contributes to two major achievements. First, it\ndetects causal rationale from 10-K annual reports of the U.S. companies, which\ncontain experts' causal analysis following accounting standards in a formal\nmanner. This dataset can be widely used by both individual investors and\nanalysts as material information resources for investing and decision making\nwithout tremendous effort to read through all the documents. Second, it\ncarefully considers different characteristics which affect the financial\nperformance of companies in twelve industries. As a result, CR-COPEC can\ndistinguish causal sentences in various industries by taking unique narratives\nin each industry into consideration. We also provide an extensive analysis of\nhow well CR-COPEC dataset is constructed and suited for classifying target\nsentences as causal ones with respect to industry characteristics. Our dataset\nand experimental codes are publicly available.",
            "author": [
                "Ye Eun Chun",
                "Sunjae Kwon",
                "Kyunghwan Sohn",
                "Nakwon Sung",
                "Junyoup Lee",
                "Byungki Seo",
                "Kevin Compher",
                "Seung-won Hwang",
                "Jaesik Choi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16095v1",
                "http://arxiv.org/pdf/2310.16095v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16096v1",
            "title": "Contextual Bandits for Evaluating and Improving Inventory Control\n  Policies",
            "updated": "2023-10-24T18:00:40Z",
            "published": "2023-10-24T18:00:40Z",
            "summary": "Solutions to address the periodic review inventory control problem with\nnonstationary random demand, lost sales, and stochastic vendor lead times\ntypically involve making strong assumptions on the dynamics for either\napproximation or simulation, and applying methods such as optimization, dynamic\nprogramming, or reinforcement learning. Therefore, it is important to analyze\nand evaluate any inventory control policy, in particular to see if there is\nroom for improvement. We introduce the concept of an equilibrium policy, a\ndesirable property of a policy that intuitively means that, in hindsight,\nchanging only a small fraction of actions does not result in materially more\nreward. We provide a light-weight contextual bandit-based algorithm to evaluate\nand occasionally tweak policies, and show that this method achieves favorable\nguarantees, both theoretically and in empirical studies.",
            "author": [
                "Dean Foster",
                "Randy Jia",
                "Dhruv Madeka"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16096v1",
                "http://arxiv.org/pdf/2310.16096v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16088v1",
            "title": "Physical Properties of 5,000 Cool LMC Supergiants with Gaia XP Spectra:\n  A Detailed Portrait of the Upper HR Diagram Hints at Missing Supernova\n  Progenitors",
            "updated": "2023-10-24T18:00:02Z",
            "published": "2023-10-24T18:00:02Z",
            "summary": "Characterizing the physical properties of cool supergiants allows us to probe\nthe final stages of a massive star's evolution before it undergoes core\ncollapse. Despite their importance, the fundamental properties for these stars\n-- $T_{\\rm eff}$ and $\\log L/L_\\odot$ -- are only known for a limited number of\nobjects. The third data release of the Gaia mission contains precise photometry\nand low-resolution spectroscopy of hundreds of cool supergiants in the LMC with\nwell-constrained properties. Using these data, we train a simple and\neasily-interpretable machine learning model to regress effective temperatures\nand luminosities with high accuracy and precision comparable to the training\ndata. We then apply our model to 5000 cool supergiants, many of which have no\npreviously-published $T_{\\rm eff}$ or $L$ estimates. The resulting\nHertzprung-Russell diagram is well-populated, allowing us to study the\ndistribution of cool supergiants in great detail. Examining the luminosity\nfunctions of our sample, we find a notable flattening in the luminosity\nfunction of yellow supergiants above $\\log L/L_\\odot=5$, and a corresponding\nsteepening of the red supergiant luminosity function. We place this finding in\ncontext with previous results, and present its implications for the infamous\nred supergiant problem.",
            "author": [
                "Trevor Z. Dorn-Wallenstein",
                "Kathryn F. Neugent",
                "Emily M. Levesque"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16088v1",
                "http://arxiv.org/pdf/2310.16088v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16052v1",
            "title": "Synthetic Data as Validation",
            "updated": "2023-10-24T17:59:55Z",
            "published": "2023-10-24T17:59:55Z",
            "summary": "This study leverages synthetic data as a validation set to reduce overfitting\nand ease the selection of the best model in AI development. While synthetic\ndata have been used for augmenting the training set, we find that synthetic\ndata can also significantly diversify the validation set, offering marked\nadvantages in domains like healthcare, where data are typically limited,\nsensitive, and from out-domain sources (i.e., hospitals). In this study, we\nillustrate the effectiveness of synthetic data for early cancer detection in\ncomputed tomography (CT) volumes, where synthetic tumors are generated and\nsuperimposed onto healthy organs, thereby creating an extensive dataset for\nrigorous validation. Using synthetic data as validation can improve AI\nrobustness in both in-domain and out-domain test sets. Furthermore, we\nestablish a new continual learning framework that continuously trains AI models\non a stream of out-domain data with synthetic tumors. The AI model trained and\nvalidated in dynamically expanding synthetic data can consistently outperform\nmodels trained and validated exclusively on real-world data. Specifically, the\nDSC score for liver tumor segmentation improves from 26.7% (95% CI:\n22.6%-30.9%) to 34.5% (30.8%-38.2%) when evaluated on an in-domain dataset and\nfrom 31.1% (26.0%-36.2%) to 35.4% (32.1%-38.7%) on an out-domain dataset.\nImportantly, the performance gain is particularly significant in identifying\nvery tiny liver tumors (radius < 5mm) in CT volumes, with Sensitivity improving\nfrom 33.1% to 55.4% on an in-domain dataset and 33.9% to 52.3% on an out-domain\ndataset, justifying the efficacy in early detection of cancer. The application\nof synthetic data, from both training and validation perspectives, underlines a\npromising avenue to enhance AI robustness when dealing with data from varying\ndomains.",
            "author": [
                "Qixin Hu",
                "Alan Yuille",
                "Zongwei Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16052v1",
                "http://arxiv.org/pdf/2310.16052v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16050v1",
            "title": "EquivAct: SIM(3)-Equivariant Visuomotor Policies beyond Rigid Object\n  Manipulation",
            "updated": "2023-10-24T17:59:48Z",
            "published": "2023-10-24T17:59:48Z",
            "summary": "If a robot masters folding a kitchen towel, we would also expect it to master\nfolding a beach towel. However, existing works for policy learning that rely on\ndata set augmentations are still limited in achieving this level of\ngeneralization. Our insight is to add equivariance to both the visual object\nrepresentation and policy architecture. We propose EquivAct which utilizes\nSIM(3)-equivariant network structures that guarantee generalization across all\npossible object translations, 3D rotations, and scales by construction.\nTraining of EquivAct is done in two phases. We first pre-train a\nSIM(3)-equivariant visual representation on simulated scene point clouds. Then,\nwe learn a SIM(3)-equivariant visuomotor policy on top of the pre-trained\nvisual representation using a small amount of source task demonstrations. We\ndemonstrate that after training, the learned policy directly transfers to\nobjects that substantially differ in scale, position and orientation from the\nsource demonstrations. In simulation, we evaluate our method in three\nmanipulation tasks involving deformable and articulated objects thereby going\nbeyond the typical rigid object manipulation tasks that prior works considered.\nWe show that our method outperforms prior works that do not use equivariant\narchitectures or do not use our contrastive pre-training procedure. We also\nshow quantitative and qualitative experiments on three real robot tasks, where\nthe robot watches twenty demonstrations of a tabletop task and transfers\nzero-shot to a mobile manipulation task in a much larger setup. Project\nwebsite: https://equivact.github.io",
            "author": [
                "Jingyun Yang",
                "Congyue Deng",
                "Jimmy Wu",
                "Rika Antonova",
                "Leonidas Guibas",
                "Jeannette Bohg"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16050v1",
                "http://arxiv.org/pdf/2310.16050v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16048v1",
            "title": "AI Alignment and Social Choice: Fundamental Limitations and Policy\n  Implications",
            "updated": "2023-10-24T17:59:04Z",
            "published": "2023-10-24T17:59:04Z",
            "summary": "Aligning AI agents to human intentions and values is a key bottleneck in\nbuilding safe and deployable AI applications. But whose values should AI agents\nbe aligned with? Reinforcement learning with human feedback (RLHF) has emerged\nas the key framework for AI alignment. RLHF uses feedback from human\nreinforcers to fine-tune outputs; all widely deployed large language models\n(LLMs) use RLHF to align their outputs to human values. It is critical to\nunderstand the limitations of RLHF and consider policy challenges arising from\nthese limitations. In this paper, we investigate a specific challenge in\nbuilding RLHF systems that respect democratic norms. Building on impossibility\nresults in social choice theory, we show that, under fairly broad assumptions,\nthere is no unique voting protocol to universally align AI systems using RLHF\nthrough democratic processes. Further, we show that aligning AI agents with the\nvalues of all individuals will always violate certain private ethical\npreferences of an individual user i.e., universal AI alignment using RLHF is\nimpossible. We discuss policy implications for the governance of AI systems\nbuilt using RLHF: first, the need for mandating transparent voting rules to\nhold model builders accountable. Second, the need for model builders to focus\non developing AI agents that are narrowly aligned to specific user groups.",
            "author": [
                "Abhilash Mishra"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16048v1",
                "http://arxiv.org/pdf/2310.16048v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.CY",
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16047v1",
            "title": "From Posterior Sampling to Meaningful Diversity in Image Restoration",
            "updated": "2023-10-24T17:58:54Z",
            "published": "2023-10-24T17:58:54Z",
            "summary": "Image restoration problems are typically ill-posed in the sense that each\ndegraded image can be restored in infinitely many valid ways. To accommodate\nthis, many works generate a diverse set of outputs by attempting to randomly\nsample from the posterior distribution of natural images given the degraded\ninput. Here we argue that this strategy is commonly of limited practical value\nbecause of the heavy tail of the posterior distribution. Consider for example\ninpainting a missing region of the sky in an image. Since there is a high\nprobability that the missing region contains no object but clouds, any set of\nsamples from the posterior would be entirely dominated by (practically\nidentical) completions of sky. However, arguably, presenting users with only\none clear sky completion, along with several alternative solutions such as\nairships, birds, and balloons, would better outline the set of possibilities.\nIn this paper, we initiate the study of meaningfully diverse image restoration.\nWe explore several post-processing approaches that can be combined with any\ndiverse image restoration method to yield semantically meaningful diversity.\nMoreover, we propose a practical approach for allowing diffusion based image\nrestoration methods to generate meaningfully diverse outputs, while incurring\nonly negligent computational overhead. We conduct extensive user studies to\nanalyze the proposed techniques, and find the strategy of reducing similarity\nbetween outputs to be significantly favorable over posterior sampling. Code and\nexamples are available in https://noa-cohen.github.io/MeaningfulDiversityInIR",
            "author": [
                "Noa Cohen",
                "Hila Manor",
                "Yuval Bahat",
                "Tomer Michaeli"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16047v1",
                "http://arxiv.org/pdf/2310.16047v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16046v1",
            "title": "A Unified, Scalable Framework for Neural Population Decoding",
            "updated": "2023-10-24T17:58:26Z",
            "published": "2023-10-24T17:58:26Z",
            "summary": "Our ability to use deep learning approaches to decipher neural activity would\nlikely benefit from greater scale, in terms of both model size and datasets.\nHowever, the integration of many neural recordings into one unified model is\nchallenging, as each recording contains the activity of different neurons from\ndifferent individual animals. In this paper, we introduce a training framework\nand architecture designed to model the population dynamics of neural activity\nacross diverse, large-scale neural recordings. Our method first tokenizes\nindividual spikes within the dataset to build an efficient representation of\nneural events that captures the fine temporal structure of neural activity. We\nthen employ cross-attention and a PerceiverIO backbone to further construct a\nlatent tokenization of neural population activities. Utilizing this\narchitecture and training framework, we construct a large-scale multi-session\nmodel trained on large datasets from seven nonhuman primates, spanning over 158\ndifferent sessions of recording from over 27,373 neural units and over 100\nhours of recordings. In a number of different tasks, we demonstrate that our\npretrained model can be rapidly adapted to new, unseen sessions with\nunspecified neuron correspondence, enabling few-shot performance with minimal\nlabels. This work presents a powerful new approach for building deep learning\ntools to analyze neural data and stakes out a clear path to training at scale.",
            "author": [
                "Mehdi Azabou",
                "Vinam Arora",
                "Venkataramana Ganesh",
                "Ximeng Mao",
                "Santosh Nachimuthu",
                "Michael J. Mendelson",
                "Blake Richards",
                "Matthew G. Perich",
                "Guillaume Lajoie",
                "Eva L. Dyer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16046v1",
                "http://arxiv.org/pdf/2310.16046v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16045v1",
            "title": "Woodpecker: Hallucination Correction for Multimodal Large Language\n  Models",
            "updated": "2023-10-24T17:58:07Z",
            "published": "2023-10-24T17:58:07Z",
            "summary": "Hallucination is a big shadow hanging over the rapidly evolving Multimodal\nLarge Language Models (MLLMs), referring to the phenomenon that the generated\ntext is inconsistent with the image content. In order to mitigate\nhallucinations, existing studies mainly resort to an instruction-tuning manner\nthat requires retraining the models with specific data. In this paper, we pave\na different way, introducing a training-free method named Woodpecker. Like a\nwoodpecker heals trees, it picks out and corrects hallucinations from the\ngenerated text. Concretely, Woodpecker consists of five stages: key concept\nextraction, question formulation, visual knowledge validation, visual claim\ngeneration, and hallucination correction. Implemented in a post-remedy manner,\nWoodpecker can easily serve different MLLMs, while being interpretable by\naccessing intermediate outputs of the five stages. We evaluate Woodpecker both\nquantitatively and qualitatively and show the huge potential of this new\nparadigm. On the POPE benchmark, our method obtains a 30.66%/24.33% improvement\nin accuracy over the baseline MiniGPT-4/mPLUG-Owl. The source code is released\nat https://github.com/BradyFU/Woodpecker.",
            "author": [
                "Shukang Yin",
                "Chaoyou Fu",
                "Sirui Zhao",
                "Tong Xu",
                "Hao Wang",
                "Dianbo Sui",
                "Yunhang Shen",
                "Ke Li",
                "Xing Sun",
                "Enhong Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16045v1",
                "http://arxiv.org/pdf/2310.16045v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16042v2",
            "title": "WebWISE: Web Interface Control and Sequential Exploration with Large\n  Language Models",
            "updated": "2023-10-25T03:54:11Z",
            "published": "2023-10-24T17:57:03Z",
            "summary": "The paper investigates using a Large Language Model (LLM) to automatically\nperform web software tasks using click, scroll, and text input operations.\nPrevious approaches, such as reinforcement learning (RL) or imitation learning,\nare inefficient to train and task-specific. Our method uses filtered Document\nObject Model (DOM) elements as observations and performs tasks step-by-step,\nsequentially generating small programs based on the current observations. We\nuse in-context learning, either benefiting from a single manually provided\nexample, or an automatically generated example based on a successful zero-shot\ntrial. We evaluate the proposed method on the MiniWob++ benchmark. With only\none in-context example, our WebWISE method achieves similar or better\nperformance than other methods that require many demonstrations or trials.",
            "author": [
                "Heyi Tao",
                "Sethuraman T V",
                "Michal Shlapentokh-Rothman",
                "Derek Hoiem"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16042v2",
                "http://arxiv.org/pdf/2310.16042v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16035v1",
            "title": "What's Left? Concept Grounding with Logic-Enhanced Foundation Models",
            "updated": "2023-10-24T17:50:20Z",
            "published": "2023-10-24T17:50:20Z",
            "summary": "Recent works such as VisProg and ViperGPT have smartly composed foundation\nmodels for visual reasoning-using large language models (LLMs) to produce\nprograms that can be executed by pre-trained vision-language models. However,\nthey operate in limited domains, such as 2D images, not fully exploiting the\ngeneralization of language: abstract concepts like \"left\" can also be grounded\nin 3D, temporal, and action data, as in moving to your left. This limited\ngeneralization stems from these inference-only methods' inability to learn or\nadapt pre-trained models to a new domain. We propose the Logic-Enhanced\nFoundation Model (LEFT), a unified framework that learns to ground and reason\nwith concepts across domains with a differentiable, domain-independent,\nfirst-order logic-based program executor. LEFT has an LLM interpreter that\noutputs a program represented in a general, logic-based reasoning language,\nwhich is shared across all domains and tasks. LEFT's executor then executes the\nprogram with trainable domain-specific grounding modules. We show that LEFT\nflexibly learns concepts in four domains: 2D images, 3D scenes, human motions,\nand robotic manipulation. It exhibits strong reasoning ability in a wide\nvariety of tasks, including those that are complex and not seen during\ntraining, and can be easily applied to new domains.",
            "author": [
                "Joy Hsu",
                "Jiayuan Mao",
                "Joshua B. Tenenbaum",
                "Jiajun Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16035v1",
                "http://arxiv.org/pdf/2310.16035v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16029v1",
            "title": "Finetuning Offline World Models in the Real World",
            "updated": "2023-10-24T17:46:12Z",
            "published": "2023-10-24T17:46:12Z",
            "summary": "Reinforcement Learning (RL) is notoriously data-inefficient, which makes\ntraining on a real robot difficult. While model-based RL algorithms (world\nmodels) improve data-efficiency to some extent, they still require hours or\ndays of interaction to learn skills. Recently, offline RL has been proposed as\na framework for training RL policies on pre-existing datasets without any\nonline interaction. However, constraining an algorithm to a fixed dataset\ninduces a state-action distribution shift between training and inference, and\nlimits its applicability to new tasks. In this work, we seek to get the best of\nboth worlds: we consider the problem of pretraining a world model with offline\ndata collected on a real robot, and then finetuning the model on online data\ncollected by planning with the learned model. To mitigate extrapolation errors\nduring online interaction, we propose to regularize the planner at test-time by\nbalancing estimated returns and (epistemic) model uncertainty. We evaluate our\nmethod on a variety of visuo-motor control tasks in simulation and on a real\nrobot, and find that our method enables few-shot finetuning to seen and unseen\ntasks even when offline data is limited. Videos, code, and data are available\nat https://yunhaifeng.com/FOWM .",
            "author": [
                "Yunhai Feng",
                "Nicklas Hansen",
                "Ziyan Xiong",
                "Chandramouli Rajagopalan",
                "Xiaolong Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16029v1",
                "http://arxiv.org/pdf/2310.16029v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16028v1",
            "title": "What Algorithms can Transformers Learn? A Study in Length Generalization",
            "updated": "2023-10-24T17:43:29Z",
            "published": "2023-10-24T17:43:29Z",
            "summary": "Large language models exhibit surprising emergent generalization properties,\nyet also struggle on many simple reasoning tasks such as arithmetic and parity.\nThis raises the question of if and when Transformer models can learn the true\nalgorithm for solving a task. We study the scope of Transformers' abilities in\nthe specific setting of length generalization on algorithmic tasks. Here, we\npropose a unifying framework to understand when and how Transformers can\nexhibit strong length generalization on a given task. Specifically, we leverage\nRASP (Weiss et al., 2021) -- a programming language designed for the\ncomputational model of a Transformer -- and introduce the RASP-Generalization\nConjecture: Transformers tend to length generalize on a task if the task can be\nsolved by a short RASP program which works for all input lengths. This simple\nconjecture remarkably captures most known instances of length generalization on\nalgorithmic tasks. Moreover, we leverage our insights to drastically improve\ngeneralization performance on traditionally hard tasks (such as parity and\naddition). On the theoretical side, we give a simple example where the\n\"min-degree-interpolator\" model of learning from Abbe et al. (2023) does not\ncorrectly predict Transformers' out-of-distribution behavior, but our\nconjecture does. Overall, our work provides a novel perspective on the\nmechanisms of compositional generalization and the algorithmic capabilities of\nTransformers.",
            "author": [
                "Hattie Zhou",
                "Arwen Bradley",
                "Etai Littwin",
                "Noam Razin",
                "Omid Saremi",
                "Josh Susskind",
                "Samy Bengio",
                "Preetum Nakkiran"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16028v1",
                "http://arxiv.org/pdf/2310.16028v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16027v1",
            "title": "TimewarpVAE: Simultaneous Time-Warping and Representation Learning of\n  Trajectories",
            "updated": "2023-10-24T17:43:16Z",
            "published": "2023-10-24T17:43:16Z",
            "summary": "Human demonstrations of trajectories are an important source of training data\nfor many machine learning problems. However, the difficulty of collecting human\ndemonstration data for complex tasks makes learning efficient representations\nof those trajectories challenging. For many problems, such as for handwriting\nor for quasistatic dexterous manipulation, the exact timings of the\ntrajectories should be factored from their spatial path characteristics. In\nthis work, we propose TimewarpVAE, a fully differentiable manifold-learning\nalgorithm that incorporates Dynamic Time Warping (DTW) to simultaneously learn\nboth timing variations and latent factors of spatial variation. We show how the\nTimewarpVAE algorithm learns appropriate time alignments and meaningful\nrepresentations of spatial variations in small handwriting and fork\nmanipulation datasets. Our results have lower spatial reconstruction test error\nthan baseline approaches and the learned low-dimensional representations can be\nused to efficiently generate semantically meaningful novel trajectories.",
            "author": [
                "Travers Rhodes",
                "Daniel D. Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16027v1",
                "http://arxiv.org/pdf/2310.16027v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16020v2",
            "title": "ConvBKI: Real-Time Probabilistic Semantic Mapping Network with\n  Quantifiable Uncertainty",
            "updated": "2023-10-26T12:37:00Z",
            "published": "2023-10-24T17:30:26Z",
            "summary": "In this paper, we develop a modular neural network for real-time semantic\nmapping in uncertain environments, which explicitly updates per-voxel\nprobabilistic distributions within a neural network layer. Our approach\ncombines the reliability of classical probabilistic algorithms with the\nperformance and efficiency of modern neural networks. Although robotic\nperception is often divided between modern differentiable methods and classical\nexplicit methods, a union of both is necessary for real-time and trustworthy\nperformance. We introduce a novel Convolutional Bayesian Kernel Inference\n(ConvBKI) layer which incorporates semantic segmentation predictions online\ninto a 3D map through a depthwise convolution layer by leveraging conjugate\npriors. We compare ConvBKI against state-of-the-art deep learning approaches\nand probabilistic algorithms for mapping to evaluate reliability and\nperformance. We also create a Robot Operating System (ROS) package of ConvBKI\nand test it on real-world perceptually challenging off-road driving data.",
            "author": [
                "Joey Wilson",
                "Yuewei Fu",
                "Joshua Friesen",
                "Parker Ewen",
                "Andrew Capodieci",
                "Paramsothy Jayakumar",
                "Kira Barton",
                "Maani Ghaffari"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16020v2",
                "http://arxiv.org/pdf/2310.16020v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16015v1",
            "title": "Physically Explainable Deep Learning for Convective Initiation\n  Nowcasting Using GOES-16 Satellite Observations",
            "updated": "2023-10-24T17:18:44Z",
            "published": "2023-10-24T17:18:44Z",
            "summary": "Convection initiation (CI) nowcasting remains a challenging problem for both\nnumerical weather prediction models and existing nowcasting algorithms. In this\nstudy, object-based probabilistic deep learning models are developed to predict\nCI based on multichannel infrared GOES-R satellite observations. The data come\nfrom patches surrounding potential CI events identified in Multi-Radar\nMulti-Sensor Doppler weather radar products over the Great Plains region from\nJune and July 2020 and June 2021. An objective radar-based approach is used to\nidentify these events. The deep learning models significantly outperform the\nclassical logistic model at lead times up to 1 hour, especially on the false\nalarm ratio. Through case studies, the deep learning model exhibits the\ndependence on the characteristics of clouds and moisture at multiple levels.\nModel explanation further reveals the model's decision-making process with\ndifferent baselines. The explanation results highlight the importance of\nmoisture and cloud features at different levels depending on the choice of\nbaseline. Our study demonstrates the advantage of using different baselines in\nfurther understanding model behavior and gaining scientific insights.",
            "author": [
                "Da Fan",
                "Steven J. Greybush",
                "David John Gagne II",
                "Eugene E. Clothiaux"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16015v1",
                "http://arxiv.org/pdf/2310.16015v1"
            ],
            "primary_category": "physics.ao-ph",
            "category": [
                "physics.ao-ph",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16076v1",
            "title": "Practical Computational Power of Linear Transformers and Their Recurrent\n  and Self-Referential Extensions",
            "updated": "2023-10-24T17:17:01Z",
            "published": "2023-10-24T17:17:01Z",
            "summary": "Recent studies of the computational power of recurrent neural networks (RNNs)\nreveal a hierarchy of RNN architectures, given real-time and finite-precision\nassumptions. Here we study auto-regressive Transformers with linearised\nattention, a.k.a. linear Transformers (LTs) or Fast Weight Programmers (FWPs).\nLTs are special in the sense that they are equivalent to RNN-like sequence\nprocessors with a fixed-size state, while they can also be expressed as the\nnow-popular self-attention networks. We show that many well-known results for\nthe standard Transformer directly transfer to LTs/FWPs. Our formal language\nrecognition experiments demonstrate how recently proposed FWP extensions such\nas recurrent FWPs and self-referential weight matrices successfully overcome\ncertain limitations of the LT, e.g., allowing for generalisation on the parity\nproblem. Our code is public.",
            "author": [
                "Kazuki Irie",
                "R\u00f3bert Csord\u00e1s",
                "J\u00fcrgen Schmidhuber"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16076v1",
                "http://arxiv.org/pdf/2310.16076v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17817v1",
            "title": "Bayesian imaging inverse problem with SA-Roundtrip prior via HMC-pCN\n  sampler",
            "updated": "2023-10-24T17:16:45Z",
            "published": "2023-10-24T17:16:45Z",
            "summary": "Bayesian inference with deep generative prior has received considerable\ninterest for solving imaging inverse problems in many scientific and\nengineering fields. The selection of the prior distribution is learned from,\nand therefore an important representation learning of, available prior\nmeasurements. The SA-Roundtrip, a novel deep generative prior, is introduced to\nenable controlled sampling generation and identify the data's intrinsic\ndimension. This prior incorporates a self-attention structure within a\nbidirectional generative adversarial network. Subsequently, Bayesian inference\nis applied to the posterior distribution in the low-dimensional latent space\nusing the Hamiltonian Monte Carlo with preconditioned Crank-Nicolson (HMC-pCN)\nalgorithm, which is proven to be ergodic under specific conditions. Experiments\nconducted on computed tomography (CT) reconstruction with the MNIST and\nTomoPhantom datasets reveal that the proposed method outperforms\nstate-of-the-art comparisons, consistently yielding a robust and superior point\nestimator along with precise uncertainty quantification.",
            "author": [
                "Jiayu Qian",
                "Yuanyuan Liu",
                "Jingya Yang",
                "Qingping Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17817v1",
                "http://arxiv.org/pdf/2310.17817v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.AI",
                "cs.LG",
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16014v1",
            "title": "Human-in-the-Loop Task and Motion Planning for Imitation Learning",
            "updated": "2023-10-24T17:15:16Z",
            "published": "2023-10-24T17:15:16Z",
            "summary": "Imitation learning from human demonstrations can teach robots complex\nmanipulation skills, but is time-consuming and labor intensive. In contrast,\nTask and Motion Planning (TAMP) systems are automated and excel at solving\nlong-horizon tasks, but they are difficult to apply to contact-rich tasks. In\nthis paper, we present Human-in-the-Loop Task and Motion Planning (HITL-TAMP),\na novel system that leverages the benefits of both approaches. The system\nemploys a TAMP-gated control mechanism, which selectively gives and takes\ncontrol to and from a human teleoperator. This enables the human teleoperator\nto manage a fleet of robots, maximizing data collection efficiency. The\ncollected human data is then combined with an imitation learning framework to\ntrain a TAMP-gated policy, leading to superior performance compared to training\non full task demonstrations. We compared HITL-TAMP to a conventional\nteleoperation system -- users gathered more than 3x the number of demos given\nthe same time budget. Furthermore, proficient agents (75\\%+ success) could be\ntrained from just 10 minutes of non-expert teleoperation data. Finally, we\ncollected 2.1K demos with HITL-TAMP across 12 contact-rich, long-horizon tasks\nand show that the system often produces near-perfect agents. Videos and\nadditional results at https://hitltamp.github.io .",
            "author": [
                "Ajay Mandlekar",
                "Caelan Garrett",
                "Danfei Xu",
                "Dieter Fox"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16014v1",
                "http://arxiv.org/pdf/2310.16014v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16009v1",
            "title": "Spatio-temporal reconstruction of drop impact dynamics by means of\n  color-coded glare points and deep learning",
            "updated": "2023-10-24T17:03:42Z",
            "published": "2023-10-24T17:03:42Z",
            "summary": "The present work introduces a deep learning approach for the\nthree-dimensional reconstruction of the spatio-temporal dynamics of the\ngas-liquid interface in two-phase flows on the basis of monocular images\nobtained via optical measurement techniques. The dynamics of liquid droplets\nimpacting onto structured solid substrates are captured through high-speed\nimaging in an extended shadowgraphy setup with additional reflective glare\npoints from lateral light sources that encode further three-dimensional\ninformation of the gas-liquid interface in the images. A neural network is\nlearned for the physically correct reconstruction of the droplet dynamics on a\nlabelled dataset generated by synthetic image rendering on the basis of\ngas-liquid interface shapes obtained from direct numerical simulation. The\nemployment of synthetic image rendering allows for the efficient generation of\ntraining data and circumvents the introduction of errors resulting from the\ninherent discrepancy of the droplet shapes between experiment and simulation.\nThe accurate reconstruction of the gas-liquid interface during droplet\nimpingement on the basis of images obtained in the experiment demonstrates the\npracticality of the presented approach based on neural networks and synthetic\ntraining data generation. The introduction of glare points from lateral light\nsources in the experiments is shown to improve the reconstruction accuracy,\nwhich indicates that the neural network learns to leverage the additional\nthree-dimensional information encoded in the images for a more accurate depth\nestimation. Furthermore, the physically reasonable reconstruction of unknown\ngas-liquid interface shapes indicates that the neural network learned a\nversatile model of the involved two-phase flow phenomena during droplet\nimpingement.",
            "author": [
                "Maximilian Dreisbach",
                "Jochen Kriegseis",
                "Alexander Stroh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16009v1",
                "http://arxiv.org/pdf/2310.16009v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16006v1",
            "title": "Machine-learning the phase diagram of a strongly-interacting Fermi gas",
            "updated": "2023-10-24T17:00:05Z",
            "published": "2023-10-24T17:00:05Z",
            "summary": "We determine the phase diagram of strongly correlated fermions in the\ncrossover from Bose-Einstein condensates of molecules (BEC) to Cooper pairs of\nfermions (BCS) utilizing an artificial neural network. By applying advanced\nimage recognition techniques to the momentum distribution of the fermions, a\nquantity which has been widely considered as featureless for providing\ninformation about the condensed state, we measure the critical temperature and\nshow that it exhibits a maximum on the bosonic side of the crossover.\nAdditionally, we back-analyze the trained neural network and demonstrate that\nit interprets physically relevant quantities.",
            "author": [
                "M. Link",
                "K. Gao",
                "A. Kell",
                "M. Breyer",
                "D. Eberz",
                "B. Rauf",
                "M. K\u00f6hl"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16006v1",
                "http://arxiv.org/pdf/2310.16006v1"
            ],
            "primary_category": "cond-mat.quant-gas",
            "category": [
                "cond-mat.quant-gas"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16005v1",
            "title": "MLFMF: Data Sets for Machine Learning for Mathematical Formalization",
            "updated": "2023-10-24T17:00:00Z",
            "published": "2023-10-24T17:00:00Z",
            "summary": "We introduce MLFMF, a collection of data sets for benchmarking recommendation\nsystems used to support formalization of mathematics with proof assistants.\nThese systems help humans identify which previous entries (theorems,\nconstructions, datatypes, and postulates) are relevant in proving a new theorem\nor carrying out a new construction. Each data set is derived from a library of\nformalized mathematics written in proof assistants Agda or Lean. The collection\nincludes the largest Lean~4 library Mathlib, and some of the largest Agda\nlibraries: the standard library, the library of univalent mathematics\nAgda-unimath, and the TypeTopology library. Each data set represents the\ncorresponding library in two ways: as a heterogeneous network, and as a list of\ns-expressions representing the syntax trees of all the entries in the library.\nThe network contains the (modular) structure of the library and the references\nbetween entries, while the s-expressions give complete and easily parsed\ninformation about every entry. We report baseline results using standard graph\nand word embeddings, tree ensembles, and instance-based learning algorithms.\nThe MLFMF data sets provide solid benchmarking support for further\ninvestigation of the numerous machine learning approaches to formalized\nmathematics. The methodology used to extract the networks and the s-expressions\nreadily applies to other libraries, and is applicable to other proof\nassistants. With more than $250\\,000$ entries in total, this is currently the\nlargest collection of formalized mathematical knowledge in machine learnable\nformat.",
            "author": [
                "Andrej Bauer",
                "Matej Petkovi\u0107",
                "Ljup\u010do Todorovski"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16005v1",
                "http://arxiv.org/pdf/2310.16005v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15999v1",
            "title": "Transitivity Recovering Decompositions: Interpretable and Robust\n  Fine-Grained Relationships",
            "updated": "2023-10-24T16:48:56Z",
            "published": "2023-10-24T16:48:56Z",
            "summary": "Recent advances in fine-grained representation learning leverage\nlocal-to-global (emergent) relationships for achieving state-of-the-art\nresults. The relational representations relied upon by such methods, however,\nare abstract. We aim to deconstruct this abstraction by expressing them as\ninterpretable graphs over image views. We begin by theoretically showing that\nabstract relational representations are nothing but a way of recovering\ntransitive relationships among local views. Based on this, we design\nTransitivity Recovering Decompositions (TRD), a graph-space search algorithm\nthat identifies interpretable equivalents of abstract emergent relationships at\nboth instance and class levels, and with no post-hoc computations. We\nadditionally show that TRD is provably robust to noisy views, with empirical\nevidence also supporting this finding. The latter allows TRD to perform at par\nor even better than the state-of-the-art, while being fully interpretable.\nImplementation is available at https://github.com/abhrac/trd.",
            "author": [
                "Abhra Chaudhuri",
                "Massimiliano Mancini",
                "Zeynep Akata",
                "Anjan Dutta"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15999v1",
                "http://arxiv.org/pdf/2310.15999v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15994v1",
            "title": "Training models using forces computed by stochastic electronic structure\n  methods",
            "updated": "2023-10-24T16:40:43Z",
            "published": "2023-10-24T16:40:43Z",
            "summary": "Quantum Monte Carlo (QMC) can play a very important role in generating\naccurate data needed for constructing potential energy surfaces. We argue that\nQMC has advantages in terms of a smaller systematic bias and an ability to\ncover phase space more completely. The stochastic noise can ease the training\nof the machine learning model. We discuss how stochastic errors affect the\ngeneration of effective models by analyzing the errors within a linear least\nsquares procedure, finding that there is an advantage to having many relatively\nimprecise data points for constructing models. We then analyze the effect of\nnoise on a model of many-body silicon finding that noise in some situations\nimproves the resulting model. We then study the effect of QMC noise on two\nmachine learning models of dense hydrogen used in a recent study of its phase\ndiagram. The noise enable us to estimate the errors in the model. We conclude\nwith a discussion of future research problems.",
            "author": [
                "David M. Ceperley",
                "Scott Jensen",
                "Yubo Yang",
                "Hongwei Niu",
                "Carlo Pierleoni",
                "Markus Holzmann"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15994v1",
                "http://arxiv.org/pdf/2310.15994v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15991v1",
            "title": "White-box Compiler Fuzzing Empowered by Large Language Models",
            "updated": "2023-10-24T16:39:06Z",
            "published": "2023-10-24T16:39:06Z",
            "summary": "Compiler correctness is crucial, as miscompilation falsifying the program\nbehaviors can lead to serious consequences. In the literature, fuzzing has been\nextensively studied to uncover compiler defects. However, compiler fuzzing\nremains challenging: Existing arts focus on black- and grey-box fuzzing, which\ngenerates tests without sufficient understanding of internal compiler\nbehaviors. As such, they often fail to construct programs to exercise\nconditions of intricate optimizations. Meanwhile, traditional white-box\ntechniques are computationally inapplicable to the giant codebase of compilers.\nRecent advances demonstrate that Large Language Models (LLMs) excel in code\ngeneration/understanding tasks and have achieved state-of-the-art performance\nin black-box fuzzing. Nonetheless, prompting LLMs with compiler source-code\ninformation remains a missing piece of research in compiler testing.\n  To this end, we propose WhiteFox, the first white-box compiler fuzzer using\nLLMs with source-code information to test compiler optimization. WhiteFox\nadopts a dual-model framework: (i) an analysis LLM examines the low-level\noptimization source code and produces requirements on the high-level test\nprograms that can trigger the optimization; (ii) a generation LLM produces test\nprograms based on the summarized requirements. Additionally,\noptimization-triggering tests are used as feedback to further enhance the test\ngeneration on the fly. Our evaluation on four popular compilers shows that\nWhiteFox can generate high-quality tests to exercise deep optimizations\nrequiring intricate conditions, practicing up to 80 more optimizations than\nstate-of-the-art fuzzers. To date, WhiteFox has found in total 96 bugs, with 80\nconfirmed as previously unknown and 51 already fixed. Beyond compiler testing,\nWhiteFox can also be adapted for white-box fuzzing of other complex, real-world\nsoftware systems in general.",
            "author": [
                "Chenyuan Yang",
                "Yinlin Deng",
                "Runyu Lu",
                "Jiayi Yao",
                "Jiawei Liu",
                "Reyhaneh Jabbarvand",
                "Lingming Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15991v1",
                "http://arxiv.org/pdf/2310.15991v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.LG",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15989v1",
            "title": "Detecting the phase transition in a strongly-interacting Fermi gas by\n  unsupervised machine learning",
            "updated": "2023-10-24T16:38:09Z",
            "published": "2023-10-24T16:38:09Z",
            "summary": "We study the critical temperature of the superfluid phase transition of\nstrongly-interacting fermions in the crossover regime between a\nBardeen-Cooper-Schrieffer (BCS) superconductor and a Bose-Einstein condensate\n(BEC) of dimers. To this end, we employ the technique of unsupervised machine\nlearning using an autoencoder neural network which we directly apply to\ntime-of-flight images of the fermions. We extract the critical temperature of\nthe phase transition from trend changes in the data distribution revealed in\nthe latent space of the autoencoder bottleneck.",
            "author": [
                "D. Eberz",
                "M. Link",
                "A. Kell",
                "M. Breyer",
                "K. Gao",
                "M. K\u00f6hl"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15989v1",
                "http://arxiv.org/pdf/2310.15989v1"
            ],
            "primary_category": "cond-mat.quant-gas",
            "category": [
                "cond-mat.quant-gas"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15987v1",
            "title": "Dissecting In-Context Learning of Translations in GPTs",
            "updated": "2023-10-24T16:37:18Z",
            "published": "2023-10-24T16:37:18Z",
            "summary": "Most of the recent work in leveraging Large Language Models (LLMs) such as\nGPT-3 for Machine Translation (MT) has focused on selecting the few-shot\nsamples for prompting. In this work, we try to better understand the role of\ndemonstration attributes for the in-context learning of translations through\nperturbations of high-quality, in-domain demonstrations. We find that\nasymmetric perturbation of the source-target mappings yield vastly different\nresults. We show that the perturbation of the source side has surprisingly\nlittle impact, while target perturbation can drastically reduce translation\nquality, suggesting that it is the output text distribution that provides the\nmost important learning signal during in-context learning of translations. We\npropose a method named Zero-Shot-Context to add this signal automatically in\nZero-Shot prompting. We demonstrate that it improves upon the zero-shot\ntranslation performance of GPT-3, even making it competitive with few-shot\nprompted translations.",
            "author": [
                "Vikas Raunak",
                "Hany Hassan Awadalla",
                "Arul Menezes"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15987v1",
                "http://arxiv.org/pdf/2310.15987v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15985v1",
            "title": "Vision-Language Pseudo-Labels for Single-Positive Multi-Label Learning",
            "updated": "2023-10-24T16:36:51Z",
            "published": "2023-10-24T16:36:51Z",
            "summary": "This paper presents a novel approach to Single-Positive Multi-label Learning.\nIn general multi-label learning, a model learns to predict multiple labels or\ncategories for a single input image. This is in contrast with standard\nmulti-class image classification, where the task is predicting a single label\nfrom many possible labels for an image. Single-Positive Multi-label Learning\n(SPML) specifically considers learning to predict multiple labels when there is\nonly a single annotation per image in the training data. Multi-label learning\nis in many ways a more realistic task than single-label learning as real-world\ndata often involves instances belonging to multiple categories simultaneously;\nhowever, most common computer vision datasets predominantly contain single\nlabels due to the inherent complexity and cost of collecting multiple high\nquality annotations for each instance. We propose a novel approach called\nVision-Language Pseudo-Labeling (VLPL), which uses a vision-language model to\nsuggest strong positive and negative pseudo-labels, and outperforms the current\nSOTA methods by 5.5% on Pascal VOC, 18.4% on MS-COCO, 15.2% on NUS-WIDE, and\n8.4% on CUB-Birds. Our code and data are available at\nhttps://github.com/mvrl/VLPL.",
            "author": [
                "Xin Xing",
                "Zhexiao Xiong",
                "Abby Stylianou",
                "Srikumar Sastry",
                "Liyu Gong",
                "Nathan Jacobs"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15985v1",
                "http://arxiv.org/pdf/2310.15985v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15978v1",
            "title": "Graph Deep Learning for Time Series Forecasting",
            "updated": "2023-10-24T16:26:38Z",
            "published": "2023-10-24T16:26:38Z",
            "summary": "Graph-based deep learning methods have become popular tools to process\ncollections of correlated time series. Differently from traditional\nmultivariate forecasting methods, neural graph-based predictors take advantage\nof pairwise relationships by conditioning forecasts on a (possibly dynamic)\ngraph spanning the time series collection. The conditioning can take the form\nof an architectural inductive bias on the neural forecasting architecture,\nresulting in a family of deep learning models called spatiotemporal graph\nneural networks. Such relational inductive biases enable the training of global\nforecasting models on large time-series collections, while at the same time\nlocalizing predictions w.r.t. each element in the set (i.e., graph nodes) by\naccounting for local correlations among them (i.e., graph edges). Indeed,\nrecent theoretical and practical advances in graph neural networks and deep\nlearning for time series forecasting make the adoption of such processing\nframeworks appealing and timely. However, most of the studies in the literature\nfocus on proposing variations of existing neural architectures by taking\nadvantage of modern deep learning practices, while foundational and\nmethodological aspects have not been subject to systematic investigation. To\nfill the gap, this paper aims to introduce a comprehensive methodological\nframework that formalizes the forecasting problem and provides design\nprinciples for graph-based predictive models and methods to assess their\nperformance. At the same time, together with an overview of the field, we\nprovide design guidelines, recommendations, and best practices, as well as an\nin-depth discussion of open challenges and future research directions.",
            "author": [
                "Andrea Cini",
                "Ivan Marisca",
                "Daniele Zambon",
                "Cesare Alippi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15978v1",
                "http://arxiv.org/pdf/2310.15978v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15977v1",
            "title": "The Conspiracy Money Machine: Uncovering Telegram's Conspiracy Channels\n  and their Profit Model",
            "updated": "2023-10-24T16:25:52Z",
            "published": "2023-10-24T16:25:52Z",
            "summary": "In recent years, major social media platforms have implemented increasingly\nstrict moderation policies, resulting in bans and restrictions on conspiracy\ntheory-related content. To circumvent these restrictions, conspiracy theorists\nare turning to alternatives, such as Telegram, where they can express and\nspread their views with fewer limitations. Telegram offers channels -- virtual\nrooms where only administrators can broadcast messages -- and a more permissive\ncontent policy. These features have created the perfect breeding ground for a\ncomplex ecosystem of conspiracy channels.\n  In this paper, we illuminate this ecosystem. First, we propose an approach to\ndetect conspiracy channels. Then, we discover that conspiracy channels can be\nclustered into four distinct communities comprising over 17,000 channels.\nFinally, we uncover the \"Conspiracy Money Machine,\" revealing how most\nconspiracy channels actively seek to profit from their subscribers. We find\nconspiracy theorists leverage e-commerce platforms to sell questionable\nproducts or lucratively promote them through affiliate links. Moreover, we\nobserve that conspiracy channels use donation and crowdfunding platforms to\nraise funds for their campaigns. We determine that this business involves\nhundreds of donors and generates a turnover of over $90 million.",
            "author": [
                "Vincenzo Imperati",
                "Massimo La Morgia",
                "Alessandro Mei",
                "Alberto Maria Mongardini",
                "Francesco Sassi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15977v1",
                "http://arxiv.org/pdf/2310.15977v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15975v2",
            "title": "Data-driven Traffic Simulation: A Comprehensive Review",
            "updated": "2023-11-23T07:15:23Z",
            "published": "2023-10-24T16:25:13Z",
            "summary": "Autonomous vehicles (AVs) have the potential to significantly revolutionize\nsociety by providing a secure and efficient mode of transportation. Recent\nyears have witnessed notable advancements in autonomous driving perception and\nprediction, but the challenge of validating the performance of AVs remains\nlargely unresolved. Data-driven microscopic traffic simulation has become an\nimportant tool for autonomous driving testing due to 1) availability of\nhigh-fidelity traffic data; 2) its advantages of enabling large-scale testing\nand scenario reproducibility; and 3) its potential in reactive and realistic\ntraffic simulation. However, a comprehensive review of this topic is currently\nlacking. This paper aims to fill this gap by summarizing relevant studies. The\nprimary objective of this paper is to review current research efforts and\nprovide a futuristic perspective that will benefit future developments in the\nfield. It introduces the general issues of data-driven traffic simulation and\noutlines key concepts and terms. After overviewing traffic simulation, various\ndatasets and evaluation metrics commonly used are reviewed. The paper then\noffers a comprehensive evaluation of imitation learning, reinforcement\nlearning, deep generative and deep learning methods, summarizing each and\nanalyzing their advantages and disadvantages in detail. Moreover, it evaluates\nthe state-of-the-art, existing challenges, and future research directions.",
            "author": [
                "Di Chen",
                "Meixin Zhu",
                "Hao Yang",
                "Xuesong Wang",
                "Yinhai Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15975v2",
                "http://arxiv.org/pdf/2310.15975v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15976v1",
            "title": "Convergence of Sign-based Random Reshuffling Algorithms for Nonconvex\n  Optimization",
            "updated": "2023-10-24T16:25:13Z",
            "published": "2023-10-24T16:25:13Z",
            "summary": "signSGD is popular in nonconvex optimization due to its communication\nefficiency. Yet, existing analyses of signSGD rely on assuming that data are\nsampled with replacement in each iteration, contradicting the practical\nimplementation where data are randomly reshuffled and sequentially fed into the\nalgorithm. We bridge this gap by proving the first convergence result of\nsignSGD with random reshuffling (SignRR) for nonconvex optimization. Given the\ndataset size $n$, the number of epochs of data passes $T$, and the variance\nbound of a stochastic gradient $\\sigma^2$, we show that SignRR has the same\nconvergence rate $O(\\log(nT)/\\sqrt{nT} + \\|\\sigma\\|_1)$ as signSGD\n\\citep{bernstein2018signsgd}. We then present SignRVR and SignRVM, which\nleverage variance-reduced gradients and momentum updates respectively, both\nconverging at $O(\\log(nT)/\\sqrt{nT})$. In contrast with the analysis of\nsignSGD, our results do not require an extremely large batch size in each\niteration to be of the same order as the total number of iterations\n\\citep{bernstein2018signsgd} or the signs of stochastic and true gradients\nmatch element-wise with a minimum probability of 1/2\n\\citep{safaryan2021stochastic}. We also extend our algorithms to cases where\ndata are distributed across different machines, yielding dist-SignRVR and\ndist-SignRVM, both converging at $O(\\log(n_0T)/\\sqrt{n_0T})$, where $n_0$ is\nthe dataset size of a single machine. We back up our theoretical findings\nthrough experiments on simulated and real-world problems, verifying that\nrandomly reshuffled sign methods match or surpass existing baselines.",
            "author": [
                "Zhen Qin",
                "Zhishuai Liu",
                "Pan Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15976v1",
                "http://arxiv.org/pdf/2310.15976v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15974v1",
            "title": "Minimax Forward and Backward Learning of Evolving Tasks with Performance\n  Guarantees",
            "updated": "2023-10-24T16:21:41Z",
            "published": "2023-10-24T16:21:41Z",
            "summary": "For a sequence of classification tasks that arrive over time, it is common\nthat tasks are evolving in the sense that consecutive tasks often have a higher\nsimilarity. The incremental learning of a growing sequence of tasks holds\npromise to enable accurate classification even with few samples per task by\nleveraging information from all the tasks in the sequence (forward and backward\nlearning). However, existing techniques developed for continual learning and\nconcept drift adaptation are either designed for tasks with time-independent\nsimilarities or only aim to learn the last task in the sequence. This paper\npresents incremental minimax risk classifiers (IMRCs) that effectively exploit\nforward and backward learning and account for evolving tasks. In addition, we\nanalytically characterize the performance improvement provided by forward and\nbackward learning in terms of the tasks' expected quadratic change and the\nnumber of tasks. The experimental evaluation shows that IMRCs can result in a\nsignificant performance improvement, especially for reduced sample sizes.",
            "author": [
                "Ver\u00f3nica \u00c1lvarez",
                "Santiago Mazuelas",
                "Jose A. Lozano"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15974v1",
                "http://arxiv.org/pdf/2310.15974v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15970v3",
            "title": "Accented Speech Recognition With Accent-specific Codebooks",
            "updated": "2023-10-27T02:54:29Z",
            "published": "2023-10-24T16:10:58Z",
            "summary": "Speech accents pose a significant challenge to state-of-the-art automatic\nspeech recognition (ASR) systems. Degradation in performance across\nunderrepresented accents is a severe deterrent to the inclusive adoption of\nASR. In this work, we propose a novel accent adaptation approach for end-to-end\nASR systems using cross-attention with a trainable set of codebooks. These\nlearnable codebooks capture accent-specific information and are integrated\nwithin the ASR encoder layers. The model is trained on accented English speech,\nwhile the test data also contained accents which were not seen during training.\nOn the Mozilla Common Voice multi-accented dataset, we show that our proposed\napproach yields significant performance gains not only on the seen English\naccents (up to $37\\%$ relative improvement in word error rate) but also on the\nunseen accents (up to $5\\%$ relative improvement in WER). Further, we\nillustrate benefits for a zero-shot transfer setup on the L2Artic dataset. We\nalso compare the performance with other approaches based on accent adversarial\ntraining.",
            "author": [
                "Darshan Prabhu",
                "Preethi Jyothi",
                "Sriram Ganapathy",
                "Vinit Unni"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15970v3",
                "http://arxiv.org/pdf/2310.15970v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15966v1",
            "title": "Constructing and Machine Learning Calabi-Yau Five-folds",
            "updated": "2023-10-24T16:07:08Z",
            "published": "2023-10-24T16:07:08Z",
            "summary": "We construct all possible complete intersection Calabi-Yau five-folds in a\nproduct of four or less complex projective spaces, with up to four constraints.\nWe obtain $27068$ spaces, which are not related by permutations of rows and\ncolumns of the configuration matrix, and determine the Euler number for all of\nthem. Excluding the $3909$ product manifolds among those, we calculate the\ncohomological data for $12433$ cases, i.e. $53.7 \\%$ of the non-product spaces,\nobtaining $2375$ different Hodge diamonds. The dataset containing all the above\ninformation is available at\nhttps://www.dropbox.com/scl/fo/z7ii5idt6qxu36e0b8azq/h?rlkey=0qfhx3tykytduobpld510gsfy&dl=0\n. The distributions of the invariants are presented, and a comparison with the\nlower-dimensional analogues is discussed. Supervised machine learning is\nperformed on the cohomological data, via classifier and regressor (both fully\nconnected and convolutional) neural networks. We find that $h^{1,1}$ can be\nlearnt very efficiently, with very high $R^2$ score and an accuracy of $96\\%$,\ni.e. $96 \\%$ of the predictions exactly match the correct values. For\n$h^{1,4},h^{2,3}, \\eta$, we also find very high $R^2$ scores, but the accuracy\nis lower, due to the large ranges of possible values.",
            "author": [
                "R. Alawadhi",
                "D. Angella",
                "A. Leonardo",
                "T. Schettini Gherardini"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15966v1",
                "http://arxiv.org/pdf/2310.15966v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "cs.LG",
                "math.AG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15961v1",
            "title": "Mixture of Tokens: Efficient LLMs through Cross-Example Aggregation",
            "updated": "2023-10-24T16:03:57Z",
            "published": "2023-10-24T16:03:57Z",
            "summary": "Despite the promise of Mixture of Experts (MoE) models in increasing\nparameter counts of Transformer models while maintaining training and inference\ncosts, their application carries notable drawbacks. The key strategy of these\nmodels is to, for each processed token, activate at most a few experts -\nsubsets of an extensive feed-forward layer. But this approach is not without\nits challenges. The operation of matching experts and tokens is discrete, which\nmakes MoE models prone to issues like training instability and uneven expert\nutilization. Existing techniques designed to address these concerns, such as\nauxiliary losses or balance-aware matching, result either in lower model\nperformance or are more difficult to train. In response to these issues, we\npropose Mixture of Tokens, a fully-differentiable model that retains the\nbenefits of MoE architectures while avoiding the aforementioned difficulties.\nRather than routing tokens to experts, this approach mixes tokens from\ndifferent examples prior to feeding them to experts, enabling the model to\nlearn from all token-expert combinations. Importantly, this mixing can be\ndisabled to avoid mixing of different sequences during inference. Crucially,\nthis method is fully compatible with both masked and causal Large Language\nModel training and inference.",
            "author": [
                "Szymon Antoniak",
                "Sebastian Jaszczur",
                "Micha\u0142 Krutul",
                "Maciej Pi\u00f3ro",
                "Jakub Krajewski",
                "Jan Ludziejewski",
                "Tomasz Odrzyg\u00f3\u017ad\u017a",
                "Marek Cygan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15961v1",
                "http://arxiv.org/pdf/2310.15961v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02088v1",
            "title": "Combining Deep Learning on Order Books with Reinforcement Learning for\n  Profitable Trading",
            "updated": "2023-10-24T15:58:58Z",
            "published": "2023-10-24T15:58:58Z",
            "summary": "High-frequency trading is prevalent, where automated decisions must be made\nquickly to take advantage of price imbalances and patterns in price action that\nforecast near-future movements. While many algorithms have been explored and\ntested, analytical methods fail to harness the whole nature of the market\nenvironment by focusing on a limited domain. With the evergrowing machine\nlearning field, many large-scale end-to-end studies on raw data have been\nsuccessfully employed to increase the domain scope for profitable trading but\nare very difficult to replicate. Combining deep learning on the order books\nwith reinforcement learning is one way of breaking down large-scale end-to-end\nlearning into more manageable and lightweight components for reproducibility,\nsuitable for retail trading.\n  The following work focuses on forecasting returns across multiple horizons\nusing order flow imbalance and training three temporal-difference learning\nmodels for five financial instruments to provide trading signals. The\ninstruments used are two foreign exchange pairs (GBPUSD and EURUSD), two\nindices (DE40 and FTSE100), and one commodity (XAUUSD). The performances of\nthese 15 agents are evaluated through backtesting simulation, and successful\nmodels proceed through to forward testing on a retail trading platform. The\nresults prove potential but require further minimal modifications for\nconsistently profitable trading to fully handle retail trading costs, slippage,\nand spread fluctuation.",
            "author": [
                "Koti S. Jaddu",
                "Paul A. Bilokon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02088v1",
                "http://arxiv.org/pdf/2311.02088v1"
            ],
            "primary_category": "q-fin.CP",
            "category": [
                "q-fin.CP",
                "cs.AI",
                "cs.LG",
                "q-fin.PM",
                "q-fin.TR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15955v1",
            "title": "Decoupled DETR: Spatially Disentangling Localization and Classification\n  for Improved End-to-End Object Detection",
            "updated": "2023-10-24T15:54:11Z",
            "published": "2023-10-24T15:54:11Z",
            "summary": "The introduction of DETR represents a new paradigm for object detection.\nHowever, its decoder conducts classification and box localization using shared\nqueries and cross-attention layers, leading to suboptimal results. We observe\nthat different regions of interest in the visual feature map are suitable for\nperforming query classification and box localization tasks, even for the same\nobject. Salient regions provide vital information for classification, while the\nboundaries around them are more favorable for box regression. Unfortunately,\nsuch spatial misalignment between these two tasks greatly hinders DETR's\ntraining. Therefore, in this work, we focus on decoupling localization and\nclassification tasks in DETR. To achieve this, we introduce a new design scheme\ncalled spatially decoupled DETR (SD-DETR), which includes a task-aware query\ngeneration module and a disentangled feature learning process. We elaborately\ndesign the task-aware query initialization process and divide the\ncross-attention block in the decoder to allow the task-aware queries to match\ndifferent visual regions. Meanwhile, we also observe that the prediction\nmisalignment problem for high classification confidence and precise\nlocalization exists, so we propose an alignment loss to further guide the\nspatially decoupled DETR training. Through extensive experiments, we\ndemonstrate that our approach achieves a significant improvement in MSCOCO\ndatasets compared to previous work. For instance, we improve the performance of\nConditional DETR by 4.5 AP. By spatially disentangling the two tasks, our\nmethod overcomes the misalignment problem and greatly improves the performance\nof DETR for object detection.",
            "author": [
                "Manyuan Zhang",
                "Guanglu Song",
                "Yu Liu",
                "Hongsheng Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15955v1",
                "http://arxiv.org/pdf/2310.15955v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15952v3",
            "title": "Improving Robustness and Reliability in Medical Image Classification\n  with Latent-Guided Diffusion and Nested-Ensembles",
            "updated": "2023-11-10T09:52:03Z",
            "published": "2023-10-24T15:53:07Z",
            "summary": "While deep learning models have achieved remarkable success across a range of\nmedical image analysis tasks, deployment of these models in real clinical\ncontexts requires that they be robust to variability in the acquired images.\nWhile many methods apply predefined transformations to augment the training\ndata to enhance test-time robustness, these transformations may not ensure the\nmodel's robustness to the diverse variability seen in patient images. In this\npaper, we introduce a novel three-stage approach based on transformers coupled\nwith conditional diffusion models, with the goal of improving model robustness\nto the kinds of imaging variability commonly encountered in practice without\nthe need for pre-determined data augmentation strategies. To this end, multiple\nimage encoders first learn hierarchical feature representations to build\ndiscriminative latent spaces. Next, a reverse diffusion process, guided by the\nlatent code, acts on an informative prior and proposes prediction candidates in\na generative manner. Finally, several prediction candidates are aggregated in a\nbi-level aggregation protocol to produce the final output. Through extensive\nexperiments on medical imaging benchmark datasets, we show that our method\nimproves upon state-of-the-art methods in terms of robustness and confidence\ncalibration. Additionally, we introduce a strategy to quantify the prediction\nuncertainty at the instance level, increasing their trustworthiness to\nclinicians using them in clinical practice.",
            "author": [
                "Xing Shen",
                "Hengguan Huang",
                "Brennan Nichyporuk",
                "Tal Arbel"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15952v3",
                "http://arxiv.org/pdf/2310.15952v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15951v1",
            "title": "Weighted Distance Nearest Neighbor Condensing",
            "updated": "2023-10-24T15:51:20Z",
            "published": "2023-10-24T15:51:20Z",
            "summary": "The problem of nearest neighbor condensing has enjoyed a long history of\nstudy, both in its theoretical and practical aspects. In this paper, we\nintroduce the problem of weighted distance nearest neighbor condensing, where\none assigns weights to each point of the condensed set, and then new points are\nlabeled based on their weighted distance nearest neighbor in the condensed set.\n  We study the theoretical properties of this new model, and show that it can\nproduce dramatically better condensing than the standard nearest neighbor rule,\nyet is characterized by generalization bounds almost identical to the latter.\nWe then suggest a condensing heuristic for our new problem. We demonstrate\nBayes consistency for this heuristic, and also show promising empirical\nresults.",
            "author": [
                "Lee-Ad Gottlieb",
                "Timor Sharabi",
                "Roi Weiss"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15951v1",
                "http://arxiv.org/pdf/2310.15951v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15950v1",
            "title": "Representation Learning with Large Language Models for Recommendation",
            "updated": "2023-10-24T15:51:13Z",
            "published": "2023-10-24T15:51:13Z",
            "summary": "Recommender systems have seen significant advancements with the influence of\ndeep learning and graph neural networks, particularly in capturing complex\nuser-item relationships. However, these graph-based recommenders heavily depend\non ID-based data, potentially disregarding valuable textual information\nassociated with users and items, resulting in less informative learned\nrepresentations. Moreover, the utilization of implicit feedback data introduces\npotential noise and bias, posing challenges for the effectiveness of user\npreference learning. While the integration of large language models (LLMs) into\ntraditional ID-based recommenders has gained attention, challenges such as\nscalability issues, limitations in text-only reliance, and prompt input\nconstraints need to be addressed for effective implementation in practical\nrecommender systems. To address these challenges, we propose a model-agnostic\nframework RLMRec that aims to enhance existing recommenders with LLM-empowered\nrepresentation learning. It proposes a recommendation paradigm that integrates\nrepresentation learning with LLMs to capture intricate semantic aspects of user\nbehaviors and preferences. RLMRec incorporates auxiliary textual signals,\ndevelops a user/item profiling paradigm empowered by LLMs, and aligns the\nsemantic space of LLMs with the representation space of collaborative\nrelational signals through a cross-view alignment framework. This work further\nestablish a theoretical foundation demonstrating that incorporating textual\nsignals through mutual information maximization enhances the quality of\nrepresentations. In our evaluation, we integrate RLMRec with state-of-the-art\nrecommender models, while also analyzing its efficiency and robustness to noise\ndata. Our implementation codes are available at\nhttps://github.com/HKUDS/RLMRec.",
            "author": [
                "Xubin Ren",
                "Wei Wei",
                "Lianghao Xia",
                "Lixin Su",
                "Suqi Cheng",
                "Junfeng Wang",
                "Dawei Yin",
                "Chao Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15950v1",
                "http://arxiv.org/pdf/2310.15950v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15940v1",
            "title": "Combining Behaviors with the Successor Features Keyboard",
            "updated": "2023-10-24T15:35:54Z",
            "published": "2023-10-24T15:35:54Z",
            "summary": "The Option Keyboard (OK) was recently proposed as a method for transferring\nbehavioral knowledge across tasks. OK transfers knowledge by adaptively\ncombining subsets of known behaviors using Successor Features (SFs) and\nGeneralized Policy Improvement (GPI). However, it relies on hand-designed\nstate-features and task encodings which are cumbersome to design for every new\nenvironment. In this work, we propose the \"Successor Features Keyboard\" (SFK),\nwhich enables transfer with discovered state-features and task encodings. To\nenable discovery, we propose the \"Categorical Successor Feature Approximator\"\n(CSFA), a novel learning algorithm for estimating SFs while jointly discovering\nstate-features and task encodings. With SFK and CSFA, we achieve the first\ndemonstration of transfer with SFs in a challenging 3D environment where all\nthe necessary representations are discovered. We first compare CSFA against\nother methods for approximating SFs and show that only CSFA discovers\nrepresentations compatible with SF&GPI at this scale. We then compare SFK\nagainst transfer learning baselines and show that it transfers most quickly to\nlong-horizon tasks.",
            "author": [
                "Wilka Carvalho",
                "Andre Saraiva",
                "Angelos Filos",
                "Andrew Kyle Lampinen",
                "Loic Matthey",
                "Richard L. Lewis",
                "Honglak Lee",
                "Satinder Singh",
                "Danilo J. Rezende",
                "Daniel Zoran"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15940v1",
                "http://arxiv.org/pdf/2310.15940v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15939v1",
            "title": "Blip-Up Blip-Down Circular EPI (BUDA-cEPI) for Distortion-Free dMRI with\n  Rapid Unrolled Deep Learning Reconstruction",
            "updated": "2023-10-24T15:35:00Z",
            "published": "2023-10-24T15:35:00Z",
            "summary": "Purpose: We implemented the blip-up, blip-down circular echo planar imaging\n(BUDA-cEPI) sequence with readout and phase partial Fourier to reduced\noff-resonance effect and T2* blurring. BUDA-cEPI reconstruction with S-based\nlow-rank modeling of local k-space neighborhoods (S-LORAKS) is shown to be\neffective at reconstructing the highly under-sampled BUDA-cEPI data, but it is\ncomputationally intensive. Thus, we developed an ML-based reconstruction\ntechnique termed \"BUDA-cEPI RUN-UP\" to enable fast reconstruction.\n  Methods: BUDA-cEPI RUN-UP - a model-based framework that incorporates\noff-resonance and eddy current effects was unrolled through an artificial\nneural network with only six gradient updates. The unrolled network alternates\nbetween data consistency (i.e., forward BUDA-cEPI and its adjoint) and\nregularization steps where U-Net plays a role as the regularizer. To handle the\npartial Fourier effect, the virtual coil concept was also incorporated into the\nreconstruction to effectively take advantage of the smooth phase prior, and\ntrained to predict the ground-truth images obtained by BUDA-cEPI with S-LORAKS.\n  Results: BUDA-cEPI with S-LORAKS reconstruction enabled the management of\noff-resonance, partial Fourier, and residual aliasing artifacts. However, the\nreconstruction time is approximately 225 seconds per slice, which may not be\npractical in a clinical setting. In contrast, the proposed BUDA-cEPI RUN-UP\nyielded similar results to BUDA-cEPI with S-LORAKS, with less than a 5%\nnormalized root mean square error detected, while the reconstruction time is\napproximately 3 seconds.\n  Conclusion: BUDA-cEPI RUN-UP was shown to reduce the reconstruction time by\n~88x when compared to the state-of-the-art technique, while preserving imaging\ndetails as demonstrated through DTI application.",
            "author": [
                "Uten Yarach",
                "Itthi Chatnuntawech",
                "Congyu Liao",
                "Surat Teerapittayanon",
                "Siddharth Srinivasan Iyer",
                "Tae Hyung Kim",
                "Justin Haldar",
                "Jaejin Cho",
                "Berkin Bilgic",
                "Yuxin Hu",
                "Brian Hargreaves",
                "Kawin Setsompop"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15939v1",
                "http://arxiv.org/pdf/2310.15939v1"
            ],
            "primary_category": "physics.med-ph",
            "category": [
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15938v1",
            "title": "ABKD: Graph Neural Network Compression with Attention-Based Knowledge\n  Distillation",
            "updated": "2023-10-24T15:34:30Z",
            "published": "2023-10-24T15:34:30Z",
            "summary": "Graph Neural Networks (GNNs) have proven to be quite versatile for a variety\nof applications, including recommendation systems, fake news detection, drug\ndiscovery, and even computer vision. Due to the expanding size of\ngraph-structured data, GNN models have also increased in complexity, leading to\nsubstantial latency issues. This is primarily attributed to the irregular\nstructure of graph data and its access pattern into memory. The natural\nsolution to reduce latency is to compress large GNNs into small GNNs. One way\nto do this is via knowledge distillation (KD). However, most KD approaches for\nGNNs only consider the outputs of the last layers and do not consider the\noutputs of the intermediate layers of the GNNs; these layers may contain\nimportant inductive biases indicated by the graph structure. To address this\nshortcoming, we propose a novel KD approach to GNN compression that we call\nAttention-Based Knowledge Distillation (ABKD). ABKD is a KD approach that uses\nattention to identify important intermediate teacher-student layer pairs and\nfocuses on aligning their outputs. ABKD enables higher compression of GNNs with\na smaller accuracy dropoff compared to existing KD approaches. On average, we\nachieve a 1.79% increase in accuracy with a 32.3x compression ratio on\nOGBN-Mag, a large graph dataset, compared to state-of-the-art approaches.",
            "author": [
                "Anshul Ahluwalia",
                "Rohit Das",
                "Payman Behnam",
                "Alind Khare",
                "Pan Li",
                "Alexey Tumanov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15938v1",
                "http://arxiv.org/pdf/2310.15938v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15935v1",
            "title": "Mediator Interpretation and Faster Learning Algorithms for Linear\n  Correlated Equilibria in General Extensive-Form Games",
            "updated": "2023-10-24T15:32:54Z",
            "published": "2023-10-24T15:32:54Z",
            "summary": "A recent paper by Farina & Pipis (2023) established the existence of\nuncoupled no-linear-swap regret dynamics with polynomial-time iterations in\nextensive-form games. The equilibrium points reached by these dynamics, known\nas linear correlated equilibria, are currently the tightest known relaxation of\ncorrelated equilibrium that can be learned in polynomial time in any finite\nextensive-form game. However, their properties remain vastly unexplored, and\ntheir computation is onerous. In this paper, we provide several contributions\nshedding light on the fundamental nature of linear-swap regret. First, we show\na connection between linear deviations and a generalization of communication\ndeviations in which the player can make queries to a \"mediator\" who replies\nwith action recommendations, and, critically, the player is not constrained to\nmatch the timing of the game as would be the case for communication deviations.\nWe coin this latter set the untimed communication (UTC) deviations. We show\nthat the UTC deviations coincide precisely with the linear deviations, and\ntherefore that any player minimizing UTC regret also minimizes linear-swap\nregret. We then leverage this connection to develop state-of-the-art no-regret\nalgorithms for computing linear correlated equilibria, both in theory and in\npractice. In theory, our algorithms achieve polynomially better per-iteration\nruntimes; in practice, our algorithms represent the state of the art by several\norders of magnitude.",
            "author": [
                "Brian Hu Zhang",
                "Gabriele Farina",
                "Tuomas Sandholm"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15935v1",
                "http://arxiv.org/pdf/2310.15935v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15932v1",
            "title": "Online Robust Mean Estimation",
            "updated": "2023-10-24T15:28:43Z",
            "published": "2023-10-24T15:28:43Z",
            "summary": "We study the problem of high-dimensional robust mean estimation in an online\nsetting. Specifically, we consider a scenario where $n$ sensors are measuring\nsome common, ongoing phenomenon. At each time step $t=1,2,\\ldots,T$, the\n$i^{th}$ sensor reports its readings $x^{(i)}_t$ for that time step. The\nalgorithm must then commit to its estimate $\\mu_t$ for the true mean value of\nthe process at time $t$. We assume that most of the sensors observe independent\nsamples from some common distribution $X$, but an $\\epsilon$-fraction of them\nmay instead behave maliciously. The algorithm wishes to compute a good\napproximation $\\mu$ to the true mean $\\mu^\\ast := \\mathbf{E}[X]$. We note that\nif the algorithm is allowed to wait until time $T$ to report its estimate, this\nreduces to the well-studied problem of robust mean estimation. However, the\nrequirement that our algorithm produces partial estimates as the data is coming\nin substantially complicates the situation.\n  We prove two main results about online robust mean estimation in this model.\nFirst, if the uncorrupted samples satisfy the standard condition of\n$(\\epsilon,\\delta)$-stability, we give an efficient online algorithm that\noutputs estimates $\\mu_t$, $t \\in [T],$ such that with high probability it\nholds that $\\|\\mu-\\mu^\\ast\\|_2 = O(\\delta \\log(T))$, where $\\mu = (\\mu_t)_{t\n\\in [T]}$. We note that this error bound is nearly competitive with the best\noffline algorithms, which would achieve $\\ell_2$-error of $O(\\delta)$. Our\nsecond main result shows that with additional assumptions on the input (most\nnotably that $X$ is a product distribution) there are inefficient algorithms\nwhose error does not depend on $T$ at all.",
            "author": [
                "Daniel M. Kane",
                "Ilias Diakonikolas",
                "Hanshen Xiao",
                "Sihan Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15932v1",
                "http://arxiv.org/pdf/2310.15932v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DS",
                "math.ST",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15929v1",
            "title": "E-Sparse: Boosting the Large Language Model Inference through\n  Entropy-based N:M Sparsity",
            "updated": "2023-10-24T15:27:15Z",
            "published": "2023-10-24T15:27:15Z",
            "summary": "Traditional pruning methods are known to be challenging to work in Large\nLanguage Models (LLMs) for Generative AI because of their unaffordable training\nprocess and large computational demands. For the first time, we introduce the\ninformation entropy of hidden state features into a pruning metric design,\nnamely E-Sparse, to improve the accuracy of N:M sparsity on LLM. E-Sparse\nemploys the information richness to leverage the channel importance, and\nfurther incorporates several novel techniques to put it into effect: (1) it\nintroduces information entropy to enhance the significance of parameter weights\nand input feature norms as a novel pruning metric, and performs N:M sparsity\nwithout modifying the remaining weights. (2) it designs global naive shuffle\nand local block shuffle to quickly optimize the information distribution and\nadequately cope with the impact of N:M sparsity on LLMs' accuracy. E-Sparse is\nimplemented as a Sparse-GEMM on FasterTransformer and runs on NVIDIA Ampere\nGPUs. Extensive experiments on the LLaMA family and OPT models show that\nE-Sparse can significantly speed up the model inference over the dense model\n(up to 1.53X) and obtain significant memory saving (up to 43.52%), with\nacceptable accuracy loss.",
            "author": [
                "Yun Li",
                "Lin Niu",
                "Xipeng Zhang",
                "Kai Liu",
                "Jianchen Zhu",
                "Zhanhui Kang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15929v1",
                "http://arxiv.org/pdf/2310.15929v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15921v1",
            "title": "Contrastive Learning-based Sentence Encoders Implicitly Weight\n  Informative Words",
            "updated": "2023-10-24T15:22:04Z",
            "published": "2023-10-24T15:22:04Z",
            "summary": "The performance of sentence encoders can be significantly improved through\nthe simple practice of fine-tuning using contrastive loss. A natural question\narises: what characteristics do models acquire during contrastive learning?\nThis paper theoretically and experimentally shows that contrastive-based\nsentence encoders implicitly weight words based on information-theoretic\nquantities; that is, more informative words receive greater weight, while\nothers receive less. The theory states that, in the lower bound of the optimal\nvalue of the contrastive learning objective, the norm of word embedding\nreflects the information gain associated with the distribution of surrounding\nwords. We also conduct comprehensive experiments using various models, multiple\ndatasets, two methods to measure the implicit weighting of models (Integrated\nGradients and SHAP), and two information-theoretic quantities (information gain\nand self-information). The results provide empirical evidence that contrastive\nfine-tuning emphasizes informative words.",
            "author": [
                "Hiroto Kurita",
                "Goro Kobayashi",
                "Sho Yokoi",
                "Kentaro Inui"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15921v1",
                "http://arxiv.org/pdf/2310.15921v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15916v1",
            "title": "In-Context Learning Creates Task Vectors",
            "updated": "2023-10-24T15:17:14Z",
            "published": "2023-10-24T15:17:14Z",
            "summary": "In-context learning (ICL) in Large Language Models (LLMs) has emerged as a\npowerful new learning paradigm. However, its underlying mechanism is still not\nwell understood. In particular, it is challenging to map it to the \"standard\"\nmachine learning framework, where one uses a training set $S$ to find a\nbest-fitting function $f(x)$ in some hypothesis class. Here we make progress on\nthis problem by showing that the functions learned by ICL often have a very\nsimple structure: they correspond to the transformer LLM whose only inputs are\nthe query $x$ and a single \"task vector\" calculated from the training set.\nThus, ICL can be seen as compressing $S$ into a single task vector\n$\\boldsymbol{\\theta}(S)$ and then using this task vector to modulate the\ntransformer to produce the output. We support the above claim via comprehensive\nexperiments across a range of models and tasks.",
            "author": [
                "Roee Hendel",
                "Mor Geva",
                "Amir Globerson"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15916v1",
                "http://arxiv.org/pdf/2310.15916v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16074v1",
            "title": "RePoseDM: Recurrent Pose Alignment and Gradient Guidance for Pose Guided\n  Image Synthesis",
            "updated": "2023-10-24T15:16:19Z",
            "published": "2023-10-24T15:16:19Z",
            "summary": "Pose-guided person image synthesis task requires re-rendering a reference\nimage, which should have a photorealistic appearance and flawless pose\ntransfer. Since person images are highly structured, existing approaches\nrequire dense connections for complex deformations and occlusions because these\nare generally handled through multi-level warping and masking in latent space.\nBut the feature maps generated by convolutional neural networks do not have\nequivariance, and hence even the multi-level warping does not have a perfect\npose alignment. Inspired by the ability of the diffusion model to generate\nphotorealistic images from the given conditional guidance, we propose recurrent\npose alignment to provide pose-aligned texture features as conditional\nguidance. Moreover, we propose gradient guidance from pose interaction fields,\nwhich output the distance from the valid pose manifold given a target pose as\ninput. This helps in learning plausible pose transfer trajectories that result\nin photorealism and undistorted texture details. Extensive results on two\nlarge-scale benchmarks and a user study demonstrate the ability of our proposed\napproach to generate photorealistic pose transfer under challenging scenarios.\nAdditionally, we prove the efficiency of gradient guidance in pose-guided image\ngeneration on the HumanArt dataset with fine-tuned stable diffusion.",
            "author": [
                "Anant Khandelwal"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16074v1",
                "http://arxiv.org/pdf/2310.16074v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15913v1",
            "title": "Mitigate Domain Shift by Primary-Auxiliary Objectives Association for\n  Generalizing Person ReID",
            "updated": "2023-10-24T15:15:57Z",
            "published": "2023-10-24T15:15:57Z",
            "summary": "While deep learning has significantly improved ReID model accuracy under the\nindependent and identical distribution (IID) assumption, it has also become\nclear that such models degrade notably when applied to an unseen novel domain\ndue to unpredictable/unknown domain shift. Contemporary domain generalization\n(DG) ReID models struggle in learning domain-invariant representation solely\nthrough training on an instance classification objective. We consider that a\ndeep learning model is heavily influenced and therefore biased towards\ndomain-specific characteristics, e.g., background clutter, scale and viewpoint\nvariations, limiting the generalizability of the learned model, and hypothesize\nthat the pedestrians are domain invariant owning they share the same structural\ncharacteristics. To enable the ReID model to be less domain-specific from these\npure pedestrians, we introduce a method that guides model learning of the\nprimary ReID instance classification objective by a concurrent auxiliary\nlearning objective on weakly labeled pedestrian saliency detection. To solve\nthe problem of conflicting optimization criteria in the model parameter space\nbetween the two learning objectives, we introduce a Primary-Auxiliary\nObjectives Association (PAOA) mechanism to calibrate the loss gradients of the\nauxiliary task towards the primary learning task gradients. Benefiting from the\nharmonious multitask learning design, our model can be extended with the recent\ntest-time diagram to form the PAOA+, which performs on-the-fly optimization\nagainst the auxiliary objective in order to maximize the model's generative\ncapacity in the test target domain. Experiments demonstrate the superiority of\nthe proposed PAOA model.",
            "author": [
                "Qilei Li",
                "Shaogang Gong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15913v1",
                "http://arxiv.org/pdf/2310.15913v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15912v1",
            "title": "Climate Change Impact on Agricultural Land Suitability: An Interpretable\n  Machine Learning-Based Eurasia Case Study",
            "updated": "2023-10-24T15:15:28Z",
            "published": "2023-10-24T15:15:28Z",
            "summary": "The United Nations has identified improving food security and reducing hunger\nas essential components of its sustainable development goals. As of 2021,\napproximately 828 million people worldwide are experiencing hunger and\nmalnutrition, with numerous fatalities reported. Climate change significantly\nimpacts agricultural land suitability, potentially leading to severe food\nshortages and subsequent social and political conflicts. To address this\npressing issue, we have developed a machine learning-based approach to predict\nthe risk of substantial land suitability degradation and changes in irrigation\npatterns. Our study focuses on Central Eurasia, a region burdened with economic\nand social challenges.\n  This study represents a pioneering effort in utilizing machine learning\nmethods to assess the impact of climate change on agricultural land suitability\nunder various carbon emissions scenarios. Through comprehensive feature\nimportance analysis, we unveil specific climate and terrain characteristics\nthat exert influence on land suitability. Our approach achieves remarkable\naccuracy, offering policymakers invaluable insights to facilitate informed\ndecisions aimed at averting a humanitarian crisis, including strategies such as\nthe provision of additional water and fertilizers. This research underscores\nthe tremendous potential of machine learning in addressing global challenges,\nwith a particular emphasis on mitigating hunger and malnutrition.",
            "author": [
                "Valeriy Shevchenko",
                "Daria Taniushkina",
                "Aleksander Lukashevich",
                "Aleksandr Bulkin",
                "Roland Grinis",
                "Kirill Kovalev",
                "Veronika Narozhnaia",
                "Nazar Sotiriadi",
                "Alexander Krenke",
                "Yury Maximov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15912v1",
                "http://arxiv.org/pdf/2310.15912v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15910v1",
            "title": "Characterizing Mechanisms for Factual Recall in Language Models",
            "updated": "2023-10-24T15:15:18Z",
            "published": "2023-10-24T15:15:18Z",
            "summary": "Language Models (LMs) often must integrate facts they memorized in\npretraining with new information that appears in a given context. These two\nsources can disagree, causing competition within the model, and it is unclear\nhow an LM will resolve the conflict. On a dataset that queries for knowledge of\nworld capitals, we investigate both distributional and mechanistic determinants\nof LM behavior in such situations. Specifically, we measure the proportion of\nthe time an LM will use a counterfactual prefix (e.g., \"The capital of Poland\nis London\") to overwrite what it learned in pretraining (\"Warsaw\"). On Pythia\nand GPT2, the training frequency of both the query country (\"Poland\") and the\nin-context city (\"London\") highly affect the models' likelihood of using the\ncounterfactual. We then use head attribution to identify individual attention\nheads that either promote the memorized answer or the in-context answer in the\nlogits. By scaling up or down the value vector of these heads, we can control\nthe likelihood of using the in-context answer on new data. This method can\nincrease the rate of generating the in-context answer to 88\\% of the time\nsimply by scaling a single head at runtime. Our work contributes to a body of\nevidence showing that we can often localize model behaviors to specific\ncomponents and provides a proof of concept for how future methods might control\nmodel behavior dynamically at runtime.",
            "author": [
                "Qinan Yu",
                "Jack Merullo",
                "Ellie Pavlick"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15910v1",
                "http://arxiv.org/pdf/2310.15910v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15905v1",
            "title": "Is Probing All You Need? Indicator Tasks as an Alternative to Probing\n  Embedding Spaces",
            "updated": "2023-10-24T15:08:12Z",
            "published": "2023-10-24T15:08:12Z",
            "summary": "The ability to identify and control different kinds of linguistic information\nencoded in vector representations of words has many use cases, especially for\nexplainability and bias removal. This is usually done via a set of simple\nclassification tasks, termed probes, to evaluate the information encoded in the\nembedding space. However, the involvement of a trainable classifier leads to\nentanglement between the probe's results and the classifier's nature. As a\nresult, contemporary works on probing include tasks that do not involve\ntraining of auxiliary models. In this work we introduce the term indicator\ntasks for non-trainable tasks which are used to query embedding spaces for the\nexistence of certain properties, and claim that this kind of tasks may point to\na direction opposite to probes, and that this contradiction complicates the\ndecision on whether a property exists in an embedding space. We demonstrate our\nclaims with two test cases, one dealing with gender debiasing and another with\nthe erasure of morphological information from embedding spaces. We show that\nthe application of a suitable indicator provides a more accurate picture of the\ninformation captured and removed compared to probes. We thus conclude that\nindicator tasks should be implemented and taken into consideration when\neliciting information from embedded representations.",
            "author": [
                "Tal Levy",
                "Omer Goldman",
                "Reut Tsarfaty"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15905v1",
                "http://arxiv.org/pdf/2310.15905v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15904v1",
            "title": "Do Stochastic Parrots have Feelings Too? Improving Neural Detection of\n  Synthetic Text via Emotion Recognition",
            "updated": "2023-10-24T15:07:35Z",
            "published": "2023-10-24T15:07:35Z",
            "summary": "Recent developments in generative AI have shone a spotlight on\nhigh-performance synthetic text generation technologies. The now wide\navailability and ease of use of such models highlights the urgent need to\nprovide equally powerful technologies capable of identifying synthetic text.\nWith this in mind, we draw inspiration from psychological studies which suggest\nthat people can be driven by emotion and encode emotion in the text they\ncompose. We hypothesize that pretrained language models (PLMs) have an\naffective deficit because they lack such an emotional driver when generating\ntext and consequently may generate synthetic text which has affective\nincoherence i.e. lacking the kind of emotional coherence present in\nhuman-authored text. We subsequently develop an emotionally aware detector by\nfine-tuning a PLM on emotion. Experiment results indicate that our\nemotionally-aware detector achieves improvements across a range of synthetic\ntext generators, various sized models, datasets, and domains. Finally, we\ncompare our emotionally-aware synthetic text detector to ChatGPT in the task of\nidentification of its own output and show substantial gains, reinforcing the\npotential of emotion as a signal to identify synthetic text. Code, models, and\ndatasets are available at https: //github.com/alanagiasi/emoPLMsynth",
            "author": [
                "Alan Cowap",
                "Yvette Graham",
                "Jennifer Foster"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15904v1",
                "http://arxiv.org/pdf/2310.15904v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15903v2",
            "title": "Neural Collapse in Multi-label Learning with Pick-all-label Loss",
            "updated": "2023-11-01T03:59:09Z",
            "published": "2023-10-24T15:07:16Z",
            "summary": "We study deep neural networks for the multi-label classification (MLab) task\nthrough the lens of neural collapse (NC). Previous works have been restricted\nto the multi-class classification setting and discovered a prevalent NC\nphenomenon comprising of the following properties for the last-layer features:\n(i) the variability of features within every class collapses to zero, (ii) the\nset of feature means form an equi-angular tight frame (ETF), and (iii) the last\nlayer classifiers collapse to the feature mean upon some scaling. We generalize\nthe study to multi-label learning, and prove for the first time that a\ngeneralized NC phenomenon holds with the \"pick-all-label\" formulation. Under\nthe natural analog of the unconstrained feature model (UFM), we establish that\nthe only global classifier of the pick-all-label cross entropy loss display the\nsame ETF geometry which further collapse to multiplicity-1 feature class means.\nBesides, we discover a combinatorial property in generalized NC which is unique\nfor multi-label learning that we call \"tag-wise average\" property, where the\nfeature class-means of samples with multiple labels are scaled average of the\nfeature class-means of single label tags. Theoretically, we establish global\noptimality result for the pick-all-label cross-entropy risk for the UFM.\nAdditionally, We also provide empirical evidence to support our investigation\ninto training deep neural networks on multi-label datasets, resulting in\nimproved training efficiency.",
            "author": [
                "Pengyu Li",
                "Yutong Wang",
                "Xiao Li",
                "Qing Qu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15903v2",
                "http://arxiv.org/pdf/2310.15903v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16073v1",
            "title": "Correlation Debiasing for Unbiased Scene Graph Generation in Videos",
            "updated": "2023-10-24T14:59:51Z",
            "published": "2023-10-24T14:59:51Z",
            "summary": "Dynamic scene graph generation (SGG) from videos requires not only\ncomprehensive understanding of objects across the scenes that are prone to\ntemporal fluctuations but also a model the temporal motions and interactions\nwith different objects. Moreover, the long-tailed distribution of visual\nrelationships is the crucial bottleneck of most dynamic SGG methods, since most\nof them focus on capturing spatio-temporal context using complex architectures,\nwhich leads to the generation of biased scene graphs. To address these\nchallenges, we propose FloCoDe: Flow-aware temporal consistency and Correlation\nDebiasing with uncertainty attenuation for unbiased dynamic scene graphs.\nFloCoDe employs feature warping using flow to detect temporally consistent\nobjects across the frames. In addition, it uses correlation debiasing to learn\nthe unbiased relation representation for long-tailed classes. Moreover, to\nattenuate the predictive uncertainties, it uses a mixture of sigmoidal\ncross-entropy loss and contrastive loss to incorporate label correlations to\nidentify the commonly co-occurring relations and help debias the long-tailed\nones. Extensive experimental evaluation shows a performance gain as high as\n4.1% showing the superiority of generating more unbiased scene graphs.",
            "author": [
                "Anant Khandelwal"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16073v1",
                "http://arxiv.org/pdf/2310.16073v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15890v3",
            "title": "Cross-feature Contrastive Loss for Decentralized Deep Learning on\n  Heterogeneous Data",
            "updated": "2023-12-05T20:31:51Z",
            "published": "2023-10-24T14:48:23Z",
            "summary": "The current state-of-the-art decentralized learning algorithms mostly assume\nthe data distribution to be Independent and Identically Distributed (IID).\nHowever, in practical scenarios, the distributed datasets can have\nsignificantly heterogeneous data distributions across the agents. In this work,\nwe present a novel approach for decentralized learning on heterogeneous data,\nwhere data-free knowledge distillation through contrastive loss on\ncross-features is utilized to improve performance. Cross-features for a pair of\nneighboring agents are the features (i.e., last hidden layer activations)\nobtained from the data of an agent with respect to the model parameters of the\nother agent. We demonstrate the effectiveness of the proposed technique through\nan exhaustive set of experiments on various Computer Vision datasets (CIFAR-10,\nCIFAR-100, Fashion MNIST, Imagenette, and ImageNet), model architectures, and\nnetwork topologies. Our experiments show that the proposed method achieves\nsuperior performance (0.2-4% improvement in test accuracy) compared to other\nexisting techniques for decentralized learning on heterogeneous data.",
            "author": [
                "Sai Aparna Aketi",
                "Kaushik Roy"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15890v3",
                "http://arxiv.org/pdf/2310.15890v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15888v1",
            "title": "State Sequences Prediction via Fourier Transform for Representation\n  Learning",
            "updated": "2023-10-24T14:47:02Z",
            "published": "2023-10-24T14:47:02Z",
            "summary": "While deep reinforcement learning (RL) has been demonstrated effective in\nsolving complex control tasks, sample efficiency remains a key challenge due to\nthe large amounts of data required for remarkable performance. Existing\nresearch explores the application of representation learning for data-efficient\nRL, e.g., learning predictive representations by predicting long-term future\nstates. However, many existing methods do not fully exploit the structural\ninformation inherent in sequential state signals, which can potentially improve\nthe quality of long-term decision-making but is difficult to discern in the\ntime domain. To tackle this problem, we propose State Sequences Prediction via\nFourier Transform (SPF), a novel method that exploits the frequency domain of\nstate sequences to extract the underlying patterns in time series data for\nlearning expressive representations efficiently. Specifically, we theoretically\nanalyze the existence of structural information in state sequences, which is\nclosely related to policy performance and signal regularity, and then propose\nto predict the Fourier transform of infinite-step future state sequences to\nextract such information. One of the appealing features of SPF is that it is\nsimple to implement while not requiring storage of infinite-step future states\nas prediction targets. Experiments demonstrate that the proposed method\noutperforms several state-of-the-art algorithms in terms of both sample\nefficiency and performance.",
            "author": [
                "Mingxuan Ye",
                "Yufei Kuang",
                "Jie Wang",
                "Rui Yang",
                "Wengang Zhou",
                "Houqiang Li",
                "Feng Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15888v1",
                "http://arxiv.org/pdf/2310.15888v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02087v1",
            "title": "Design Of Rubble Analyzer Probe Using ML For Earthquake",
            "updated": "2023-10-24T14:43:42Z",
            "published": "2023-10-24T14:43:42Z",
            "summary": "The earthquake rubble analyzer uses machine learning to detect human presence\nvia ambient sounds, achieving 97.45% accuracy. It also provides real-time\nenvironmental data, aiding in assessing survival prospects for trapped\nindividuals, crucial for post-earthquake rescue efforts",
            "author": [
                "Abhishek Sebastian",
                "R Pragna",
                "K Vishal Vythianathan",
                "Dasaraju Sohan Sai",
                "U Shiva Sri Hari Al",
                "R Anirudh",
                "Apurv Choudhary"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02087v1",
                "http://arxiv.org/pdf/2311.02087v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.AI",
                "cs.LG",
                "eess.AS",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15883v1",
            "title": "Attitude Takeover Control for Noncooperative Space Targets Based on\n  Gaussian Processes with Online Model Learning",
            "updated": "2023-10-24T14:38:11Z",
            "published": "2023-10-24T14:38:11Z",
            "summary": "One major challenge for autonomous attitude takeover control for on-orbit\nservicing of spacecraft is that an accurate dynamic motion model of the\ncombined vehicles is highly nonlinear, complex and often costly to identify\nonline, which makes traditional model-based control impractical for this task.\nTo address this issue, a recursive online sparse Gaussian Process (GP)-based\nlearning strategy for attitude takeover control of noncooperative targets with\nmaneuverability is proposed, where the unknown dynamics are online compensated\nbased on the learnt GP model in a semi-feedforward manner. The method enables\nthe continuous use of on-orbit data to successively improve the learnt model\nduring online operation and has reduced computational load compared to standard\nGP regression. Next to the GP-based feedforward, a feedback controller is\nproposed that varies its gains based on the predicted model confidence,\nensuring robustness of the overall scheme. Moreover, rigorous theoretical\nproofs of Lyapunov stability and boundedness guarantees of the proposed\nmethod-driven closed-loop system are provided in the probabilistic sense. A\nsimulation study based on a high-fidelity simulator is used to show the\neffectiveness of the proposed strategy and demonstrate its high performance.",
            "author": [
                "Yuhan Liu",
                "Pengyu Wang",
                "Chang-Hun Lee",
                "Roland T\u00f3th"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15883v1",
                "http://arxiv.org/pdf/2310.15883v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18363v1",
            "title": "A Contextualized Real-Time Multimodal Emotion Recognition for\n  Conversational Agents using Graph Convolutional Networks in Reinforcement\n  Learning",
            "updated": "2023-10-24T14:31:17Z",
            "published": "2023-10-24T14:31:17Z",
            "summary": "Owing to the recent developments in Generative Artificial Intelligence\n(GenAI) and Large Language Models (LLM), conversational agents are becoming\nincreasingly popular and accepted. They provide a human touch by interacting in\nways familiar to us and by providing support as virtual companions. Therefore,\nit is important to understand the user's emotions in order to respond\nconsiderately. Compared to the standard problem of emotion recognition,\nconversational agents face an additional constraint in that recognition must be\nreal-time. Studies on model architectures using audio, visual, and textual\nmodalities have mainly focused on emotion classification using full video\nsequences that do not provide online features. In this work, we present a novel\nparadigm for contextualized Emotion Recognition using Graph Convolutional\nNetwork with Reinforcement Learning (conER-GRL). Conversations are partitioned\ninto smaller groups of utterances for effective extraction of contextual\ninformation. The system uses Gated Recurrent Units (GRU) to extract multimodal\nfeatures from these groups of utterances. More importantly, Graph Convolutional\nNetworks (GCN) and Reinforcement Learning (RL) agents are cascade trained to\ncapture the complex dependencies of emotion features in interactive scenarios.\nComparing the results of the conER-GRL model with other state-of-the-art models\non the benchmark dataset IEMOCAP demonstrates the advantageous capabilities of\nthe conER-GRL architecture in recognizing emotions in real-time from multimodal\nconversational signals.",
            "author": [
                "Fathima Abdul Rahman",
                "Guang Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18363v1",
                "http://arxiv.org/pdf/2310.18363v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.HC",
                "cs.LG",
                "I.2.10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15872v1",
            "title": "KirchhoffNet: A Circuit Bridging Message Passing and Continuous-Depth\n  Models",
            "updated": "2023-10-24T14:28:00Z",
            "published": "2023-10-24T14:28:00Z",
            "summary": "In this paper, we exploit a fundamental principle of analog electronic\ncircuitry, Kirchhoff's current law, to introduce a unique class of neural\nnetwork models that we refer to as KirchhoffNet. KirchhoffNet establishes close\nconnections with message passing neural networks and continuous-depth networks.\nWe demonstrate that even in the absence of any traditional layers (such as\nconvolution, pooling, or linear layers), KirchhoffNet attains 98.86% test\naccuracy on the MNIST dataset, comparable with state of the art (SOTA) results.\nWhat makes KirchhoffNet more intriguing is its potential in the realm of\nhardware. Contemporary deep neural networks are conventionally deployed on\nGPUs. In contrast, KirchhoffNet can be physically realized by an analog\nelectronic circuit. Moreover, we justify that irrespective of the number of\nparameters within a KirchhoffNet, its forward calculation can always be\ncompleted within 1/f seconds, with f representing the hardware's clock\nfrequency. This characteristic introduces a promising technology for\nimplementing ultra-large-scale neural networks.",
            "author": [
                "Zhengqi Gao",
                "Fan-Keng Sun",
                "Duane S. Boning"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15872v1",
                "http://arxiv.org/pdf/2310.15872v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18362v1",
            "title": "SoK: Memorization in General-Purpose Large Language Models",
            "updated": "2023-10-24T14:25:53Z",
            "published": "2023-10-24T14:25:53Z",
            "summary": "Large Language Models (LLMs) are advancing at a remarkable pace, with myriad\napplications under development. Unlike most earlier machine learning models,\nthey are no longer built for one specific application but are designed to excel\nin a wide range of tasks. A major part of this success is due to their huge\ntraining datasets and the unprecedented number of model parameters, which allow\nthem to memorize large amounts of information contained in the training data.\nThis memorization goes beyond mere language, and encompasses information only\npresent in a few documents. This is often desirable since it is necessary for\nperforming tasks such as question answering, and therefore an important part of\nlearning, but also brings a whole array of issues, from privacy and security to\ncopyright and beyond. LLMs can memorize short secrets in the training data, but\ncan also memorize concepts like facts or writing styles that can be expressed\nin text in many different ways. We propose a taxonomy for memorization in LLMs\nthat covers verbatim text, facts, ideas and algorithms, writing styles,\ndistributional properties, and alignment goals. We describe the implications of\neach type of memorization - both positive and negative - for model performance,\nprivacy, security and confidentiality, copyright, and auditing, and ways to\ndetect and prevent memorization. We further highlight the challenges that arise\nfrom the predominant way of defining memorization with respect to model\nbehavior instead of model weights, due to LLM-specific phenomena such as\nreasoning capabilities or differences between decoding algorithms. Throughout\nthe paper, we describe potential risks and opportunities arising from\nmemorization in LLMs that we hope will motivate new research directions.",
            "author": [
                "Valentin Hartmann",
                "Anshuman Suri",
                "Vincent Bindschaedler",
                "David Evans",
                "Shruti Tople",
                "Robert West"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18362v1",
                "http://arxiv.org/pdf/2310.18362v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15865v1",
            "title": "Using Causality-Aware Graph Neural Networks to Predict Temporal\n  Centralities in Dynamic Graphs",
            "updated": "2023-10-24T14:23:10Z",
            "published": "2023-10-24T14:23:10Z",
            "summary": "Node centralities play a pivotal role in network science, social network\nanalysis, and recommender systems. In temporal data, static path-based\ncentralities like closeness or betweenness can give misleading results about\nthe true importance of nodes in a temporal graph. To address this issue,\ntemporal generalizations of betweenness and closeness have been defined that\nare based on the shortest time-respecting paths between pairs of nodes.\nHowever, a major issue of those generalizations is that the calculation of such\npaths is computationally expensive. Addressing this issue, we study the\napplication of De Bruijn Graph Neural Networks (DBGNN), a causality-aware graph\nneural network architecture, to predict temporal path-based centralities in\ntime series data. We experimentally evaluate our approach in 13 temporal graphs\nfrom biological and social systems and show that it considerably improves the\nprediction of both betweenness and closeness centrality compared to a static\nGraph Convolutional Neural Network.",
            "author": [
                "Franziska Heeg",
                "Ingo Scholtes"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15865v1",
                "http://arxiv.org/pdf/2310.15865v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15861v1",
            "title": "Social Learning of General Rules",
            "updated": "2023-10-24T14:21:52Z",
            "published": "2023-10-24T14:21:52Z",
            "summary": "Why do agents adopt a particular general behavioral rule among a collection\nof possible alternatives? To address this question, we introduce a dynamic\nsocial learning framework, where agents rely on general rules of thumb and\nimitate the behavioral rules of successful peers. We find the social learning\noutcome can be characterized independent of the initial rule distribution. When\none dominant general rule consistently yields superior problem-specific\noutcomes, social learning almost surely leads all agents to adopt this dominant\nrule; otherwise, provided the population is sufficiently large, the better rule\nfor the more frequent problem becomes the consensus rule with arbitrarily high\nprobability. As a result, the behavioral rule selected by the social learning\nprocess need not maximize social welfare. We complement our theoretical\nanalysis with an application to the market sentiment selection in a stochastic\nproduction market.",
            "author": [
                "Enrique Urbano Arellano",
                "Xinyang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15861v1",
                "http://arxiv.org/pdf/2310.15861v1"
            ],
            "primary_category": "econ.TH",
            "category": [
                "econ.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16853v1",
            "title": "CP-BCS: Binary Code Summarization Guided by Control Flow Graph and\n  Pseudo Code",
            "updated": "2023-10-24T14:20:39Z",
            "published": "2023-10-24T14:20:39Z",
            "summary": "Automatically generating function summaries for binaries is an extremely\nvaluable but challenging task, since it involves translating the execution\nbehavior and semantics of the low-level language (assembly code) into\nhuman-readable natural language. However, most current works on understanding\nassembly code are oriented towards generating function names, which involve\nnumerous abbreviations that make them still confusing. To bridge this gap, we\nfocus on generating complete summaries for binary functions, especially for\nstripped binary (no symbol table and debug information in reality). To fully\nexploit the semantics of assembly code, we present a control flow graph and\npseudo code guided binary code summarization framework called CP-BCS. CP-BCS\nutilizes a bidirectional instruction-level control flow graph and pseudo code\nthat incorporates expert knowledge to learn the comprehensive binary function\nexecution behavior and logic semantics. We evaluate CP-BCS on 3 different\nbinary optimization levels (O1, O2, and O3) for 3 different computer\narchitectures (X86, X64, and ARM). The evaluation results demonstrate CP-BCS is\nsuperior and significantly improves the efficiency of reverse engineering.",
            "author": [
                "Tong Ye",
                "Lingfei Wu",
                "Tengfei Ma",
                "Xuhong Zhang",
                "Yangkai Du",
                "Peiyu Liu",
                "Shouling Ji",
                "Wenhai Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16853v1",
                "http://arxiv.org/pdf/2310.16853v1"
            ],
            "primary_category": "cs.PL",
            "category": [
                "cs.PL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15858v1",
            "title": "Topology-aware Debiased Self-supervised Graph Learning for\n  Recommendation",
            "updated": "2023-10-24T14:16:19Z",
            "published": "2023-10-24T14:16:19Z",
            "summary": "In recommendation, graph-based Collaborative Filtering (CF) methods mitigate\nthe data sparsity by introducing Graph Contrastive Learning (GCL). However, the\nrandom negative sampling strategy in these GCL-based CF models neglects the\nsemantic structure of users (items), which not only introduces false negatives\n(negatives that are similar to anchor user (item)) but also ignores the\npotential positive samples. To tackle the above issues, we propose\nTopology-aware Debiased Self-supervised Graph Learning (TDSGL) for\nrecommendation, which constructs contrastive pairs according to the semantic\nsimilarity between users (items). Specifically, since the original user-item\ninteraction data commendably reflects the purchasing intent of users and\ncertain characteristics of items, we calculate the semantic similarity between\nusers (items) on interaction data. Then, given a user (item), we construct its\nnegative pairs by selecting users (items) which embed different semantic\nstructures to ensure the semantic difference between the given user (item) and\nits negatives. Moreover, for a user (item), we design a feature extraction\nmodule that converts other semantically similar users (items) into an auxiliary\npositive sample to acquire a more informative representation. Experimental\nresults show that the proposed model outperforms the state-of-the-art models\nsignificantly on three public datasets. Our model implementation codes are\navailable at https://github.com/malajikuai/TDSGL.",
            "author": [
                "Lei Han",
                "Hui Yan",
                "Zhicheng Qiao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15858v1",
                "http://arxiv.org/pdf/2310.15858v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15853v1",
            "title": "Improving Event Time Prediction by Learning to Partition the Event Time\n  Space",
            "updated": "2023-10-24T14:11:40Z",
            "published": "2023-10-24T14:11:40Z",
            "summary": "Recently developed survival analysis methods improve upon existing approaches\nby predicting the probability of event occurrence in each of a number\npre-specified (discrete) time intervals. By avoiding placing strong parametric\nassumptions on the event density, this approach tends to improve prediction\nperformance, particularly when data are plentiful. However, in clinical\nsettings with limited available data, it is often preferable to judiciously\npartition the event time space into a limited number of intervals well suited\nto the prediction task at hand. In this work, we develop a method to learn from\ndata a set of cut points defining such a partition. We show that in two\nsimulated datasets, we are able to recover intervals that match the underlying\ngenerative model. We then demonstrate improved prediction performance on three\nreal-world observational datasets, including a large, newly harmonized stroke\nrisk prediction dataset. Finally, we argue that our approach facilitates\nclinical decision-making by suggesting time intervals that are most appropriate\nfor each task, in the sense that they facilitate more accurate risk prediction.",
            "author": [
                "Jimmy Hickey",
                "Ricardo Henao",
                "Daniel Wojdyla",
                "Michael Pencina",
                "Matthew M. Engelhard"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15853v1",
                "http://arxiv.org/pdf/2310.15853v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15852v1",
            "title": "Using Artificial French Data to Understand the Emergence of Gender Bias\n  in Transformer Language Models",
            "updated": "2023-10-24T14:08:37Z",
            "published": "2023-10-24T14:08:37Z",
            "summary": "Numerous studies have demonstrated the ability of neural language models to\nlearn various linguistic properties without direct supervision. This work takes\nan initial step towards exploring the less researched topic of how neural\nmodels discover linguistic properties of words, such as gender, as well as the\nrules governing their usage. We propose to use an artificial corpus generated\nby a PCFG based on French to precisely control the gender distribution in the\ntraining data and determine under which conditions a model correctly captures\ngender information or, on the contrary, appears gender-biased.",
            "author": [
                "Lina Conti",
                "Guillaume Wisniewski"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15852v1",
                "http://arxiv.org/pdf/2310.15852v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15850v1",
            "title": "Posterior Estimation for Dynamic PET imaging using Conditional\n  Variational Inference",
            "updated": "2023-10-24T14:05:30Z",
            "published": "2023-10-24T14:05:30Z",
            "summary": "This work aims efficiently estimating the posterior distribution of kinetic\nparameters for dynamic positron emission tomography (PET) imaging given a\nmeasurement of time of activity curve. Considering the inherent information\nloss from parametric imaging to measurement space with the forward kinetic\nmodel, the inverse mapping is ambiguous. The conventional (but expensive)\nsolution can be the Markov Chain Monte Carlo (MCMC) sampling, which is known to\nproduce unbiased asymptotical estimation. We propose a deep-learning-based\nframework for efficient posterior estimation. Specifically, we counteract the\ninformation loss in the forward process by introducing latent variables. Then,\nwe use a conditional variational autoencoder (CVAE) and optimize its evidence\nlower bound. The well-trained decoder is able to infer the posterior with a\ngiven measurement and the sampled latent variables following a simple\nmultivariate Gaussian distribution. We validate our CVAE-based method using\nunbiased MCMC as the reference for low-dimensional data (a single brain region)\nwith the simplified reference tissue model.",
            "author": [
                "Xiaofeng Liu",
                "Thibault Marin",
                "Tiss Amal",
                "Jonghye Woo",
                "Georges El Fakhri",
                "Jinsong Ouyang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15850v1",
                "http://arxiv.org/pdf/2310.15850v1"
            ],
            "primary_category": "physics.med-ph",
            "category": [
                "physics.med-ph",
                "cs.AI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15848v3",
            "title": "On Responsible Machine Learning Datasets with Fairness, Privacy, and\n  Regulatory Norms",
            "updated": "2023-11-25T04:02:29Z",
            "published": "2023-10-24T14:01:53Z",
            "summary": "Artificial Intelligence (AI) has made its way into various scientific fields,\nproviding astonishing improvements over existing algorithms for a wide variety\nof tasks. In recent years, there have been severe concerns over the\ntrustworthiness of AI technologies. The scientific community has focused on the\ndevelopment of trustworthy AI algorithms. However, machine and deep learning\nalgorithms, popular in the AI community today, depend heavily on the data used\nduring their development. These learning algorithms identify patterns in the\ndata, learning the behavioral objective. Any flaws in the data have the\npotential to translate directly into algorithms. In this study, we discuss the\nimportance of Responsible Machine Learning Datasets and propose a framework to\nevaluate the datasets through a responsible rubric. While existing work focuses\non the post-hoc evaluation of algorithms for their trustworthiness, we provide\na framework that considers the data component separately to understand its role\nin the algorithm. We discuss responsible datasets through the lens of fairness,\nprivacy, and regulatory compliance and provide recommendations for constructing\nfuture datasets. After surveying over 100 datasets, we use 60 datasets for\nanalysis and demonstrate that none of these datasets is immune to issues of\nfairness, privacy preservation, and regulatory compliance. We provide\nmodifications to the ``datasheets for datasets\" with important additions for\nimproved dataset documentation. With governments around the world regularizing\ndata protection laws, the method for the creation of datasets in the scientific\ncommunity requires revision. We believe this study is timely and relevant in\ntoday's era of AI.",
            "author": [
                "Surbhi Mittal",
                "Kartik Thakral",
                "Richa Singh",
                "Mayank Vatsa",
                "Tamar Glaser",
                "Cristian Canton Ferrer",
                "Tal Hassner"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15848v3",
                "http://arxiv.org/pdf/2310.15848v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15845v1",
            "title": "Pre-training Music Classification Models via Music Source Separation",
            "updated": "2023-10-24T13:57:55Z",
            "published": "2023-10-24T13:57:55Z",
            "summary": "In this paper, we study whether music source separation can be used as a\npre-training strategy for music representation learning, targeted at music\nclassification tasks. To this end, we first pre-train U-Net networks under\nvarious music source separation objectives, such as the isolation of vocal or\ninstrumental sources from a musical piece; afterwards, we attach a\nconvolutional tail network to the pre-trained U-Net and jointly finetune the\nwhole network. The features learned by the separation network are also\npropagated to the tail network through skip connections. Experimental results\nin two widely used and publicly available datasets indicate that pre-training\nthe U-Nets with a music source separation objective can improve performance\ncompared to both training the whole network from scratch and using the tail\nnetwork as a standalone in two music classification tasks: music auto-tagging,\nwhen vocal separation is used, and music genre classification for the case of\nmulti-source separation.",
            "author": [
                "Christos Garoufis",
                "Athanasia Zlatintsi",
                "Petros Maragos"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15845v1",
                "http://arxiv.org/pdf/2310.15845v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16071v1",
            "title": "Grid Frequency Forecasting in University Campuses using Convolutional\n  LSTM",
            "updated": "2023-10-24T13:53:51Z",
            "published": "2023-10-24T13:53:51Z",
            "summary": "The modern power grid is facing increasing complexities, primarily stemming\nfrom the integration of renewable energy sources and evolving consumption\npatterns. This paper introduces an innovative methodology that harnesses\nConvolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) networks\nto establish robust time series forecasting models for grid frequency. These\nmodels effectively capture the spatiotemporal intricacies inherent in grid\nfrequency data, significantly enhancing prediction accuracy and bolstering\npower grid reliability. The research explores the potential and development of\nindividualized Convolutional LSTM (ConvLSTM) models for buildings within a\nuniversity campus, enabling them to be independently trained and evaluated for\neach building. Individual ConvLSTM models are trained on power consumption data\nfor each campus building and forecast the grid frequency based on historical\ntrends. The results convincingly demonstrate the superiority of the proposed\nmodels over traditional forecasting techniques, as evidenced by performance\nmetrics such as Mean Square Error (MSE), Mean Absolute Error (MAE), and Mean\nAbsolute Percentage Error (MAPE). Additionally, an Ensemble Model is formulated\nto aggregate insights from the building-specific models, delivering\ncomprehensive forecasts for the entire campus. This approach ensures the\nprivacy and security of power consumption data specific to each building.",
            "author": [
                "Aneesh Sathe",
                "Wen Ren Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16071v1",
                "http://arxiv.org/pdf/2310.16071v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18361v1",
            "title": "Clinical Decision Support System for Unani Medicine Practitioners",
            "updated": "2023-10-24T13:49:18Z",
            "published": "2023-10-24T13:49:18Z",
            "summary": "Like other fields of Traditional Medicines, Unani Medicines have been found\nas an effective medical practice for ages. It is still widely used in the\nsubcontinent, particularly in Pakistan and India. However, Unani Medicines\nPractitioners are lacking modern IT applications in their everyday clinical\npractices. An Online Clinical Decision Support System may address this\nchallenge to assist apprentice Unani Medicines practitioners in their\ndiagnostic processes. The proposed system provides a web-based interface to\nenter the patient's symptoms, which are then automatically analyzed by our\nsystem to generate a list of probable diseases. The system allows practitioners\nto choose the most likely disease and inform patients about the associated\ntreatment options remotely. The system consists of three modules: an Online\nClinical Decision Support System, an Artificial Intelligence Inference Engine,\nand a comprehensive Unani Medicines Database. The system employs advanced AI\ntechniques such as Decision Trees, Deep Learning, and Natural Language\nProcessing. For system development, the project team used a technology stack\nthat includes React, FastAPI, and MySQL. Data and functionality of the\napplication is exposed using APIs for integration and extension with similar\ndomain applications. The novelty of the project is that it addresses the\nchallenge of diagnosing diseases accurately and efficiently in the context of\nUnani Medicines principles. By leveraging the power of technology, the proposed\nClinical Decision Support System has the potential to ease access to healthcare\nservices and information, reduce cost, boost practitioner and patient\nsatisfaction, improve speed and accuracy of the diagnostic process, and provide\neffective treatments remotely. The application will be useful for Unani\nMedicines Practitioners, Patients, Government Drug Regulators, Software\nDevelopers, and Medical Researchers.",
            "author": [
                "Haider Sultan",
                "Hafiza Farwa Mahmood",
                "Noor Fatima",
                "Marriyam Nadeem",
                "Talha Waheed"
            ],
            "link": [
                "http://dx.doi.org/10.13140/RG.2.2.15161.54887/1",
                "http://arxiv.org/abs/2310.18361v1",
                "http://arxiv.org/pdf/2310.18361v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16070v1",
            "title": "Spatial-Temporal Hypergraph Neural Network for Traffic Forecasting",
            "updated": "2023-10-24T13:49:13Z",
            "published": "2023-10-24T13:49:13Z",
            "summary": "Traffic forecasting, which benefits from mobile Internet development and\nposition technologies, plays a critical role in Intelligent Transportation\nSystems. It helps to implement rich and varied transportation applications and\nbring convenient transportation services to people based on collected traffic\ndata. Most existing methods usually leverage graph-based deep learning networks\nto model the complex road network for traffic forecasting shallowly. Despite\ntheir effectiveness, these methods are generally limited in fully capturing\nhigh-order spatial dependencies caused by road network topology and high-order\ntemporal dependencies caused by traffic dynamics. To tackle the above issues,\nwe focus on the essence of traffic system and propose STHODE: Spatio-Temporal\nHypergraph Neural Ordinary Differential Equation Network, which combines road\nnetwork topology and traffic dynamics to capture high-order spatio-temporal\ndependencies in traffic data. Technically, STHODE consists of a spatial module\nand a temporal module. On the one hand, we construct a spatial hypergraph and\nleverage an adaptive MixHop hypergraph ODE network to capture high-order\nspatial dependencies. On the other hand, we utilize a temporal hypergraph and\nemploy a hyperedge evolving ODE network to capture high-order temporal\ndependencies. Finally, we aggregate the outputs of stacked STHODE layers to\nmutually enhance the prediction performance. Extensive experiments conducted on\nfour real-world traffic datasets demonstrate the superior performance of our\nproposed model compared to various baselines.",
            "author": [
                "Chengzhi Yao",
                "Zhi Li",
                "Junbo Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16070v1",
                "http://arxiv.org/pdf/2310.16070v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12856v2",
            "title": "Density of States Prediction of Crystalline Materials via Prompt-guided\n  Multi-Modal Transformer",
            "updated": "2023-11-23T02:00:09Z",
            "published": "2023-10-24T13:43:17Z",
            "summary": "The density of states (DOS) is a spectral property of crystalline materials,\nwhich provides fundamental insights into various characteristics of the\nmaterials. While previous works mainly focus on obtaining high-quality\nrepresentations of crystalline materials for DOS prediction, we focus on\npredicting the DOS from the obtained representations by reflecting the nature\nof DOS: DOS determines the general distribution of states as a function of\nenergy. That is, DOS is not solely determined by the crystalline material but\nalso by the energy levels, which has been neglected in previous works. In this\npaper, we propose to integrate heterogeneous information obtained from the\ncrystalline materials and the energies via a multi-modal transformer, thereby\nmodeling the complex relationships between the atoms in the crystalline\nmaterials and various energy levels for DOS prediction. Moreover, we propose to\nutilize prompts to guide the model to learn the crystal structural\nsystem-specific interactions between crystalline materials and energies.\nExtensive experiments on two types of DOS, i.e., Phonon DOS and Electron DOS,\nwith various real-world scenarios demonstrate the superiority of\nDOSTransformer. The source code for DOSTransformer is available at\nhttps://github.com/HeewoongNoh/DOSTransformer.",
            "author": [
                "Namkyeong Lee",
                "Heewoong Noh",
                "Sungwon Kim",
                "Dongmin Hyun",
                "Gyoung S. Na",
                "Chanyoung Park"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12856v2",
                "http://arxiv.org/pdf/2311.12856v2"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15836v1",
            "title": "A Diffusion Weighted Graph Framework for New Intent Discovery",
            "updated": "2023-10-24T13:43:01Z",
            "published": "2023-10-24T13:43:01Z",
            "summary": "New Intent Discovery (NID) aims to recognize both new and known intents from\nunlabeled data with the aid of limited labeled data containing only known\nintents. Without considering structure relationships between samples, previous\nmethods generate noisy supervisory signals which cannot strike a balance\nbetween quantity and quality, hindering the formation of new intent clusters\nand effective transfer of the pre-training knowledge. To mitigate this\nlimitation, we propose a novel Diffusion Weighted Graph Framework (DWGF) to\ncapture both semantic similarities and structure relationships inherent in\ndata, enabling more sufficient and reliable supervisory signals. Specifically,\nfor each sample, we diffuse neighborhood relationships along semantic paths\nguided by the nearest neighbors for multiple hops to characterize its local\nstructure discriminately. Then, we sample its positive keys and weigh them\nbased on semantic similarities and local structures for contrastive learning.\nDuring inference, we further propose Graph Smoothing Filter (GSF) to explicitly\nutilize the structure relationships to filter high-frequency noise embodied in\nsemantically ambiguous samples on the cluster boundary. Extensive experiments\nshow that our method outperforms state-of-the-art models on all evaluation\nmetrics across multiple benchmark datasets. Code and data are available at\nhttps://github.com/yibai-shi/DWGF.",
            "author": [
                "Wenkai Shi",
                "Wenbin An",
                "Feng Tian",
                "Qinghua Zheng",
                "QianYing Wang",
                "Ping Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15836v1",
                "http://arxiv.org/pdf/2310.15836v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15831v2",
            "title": "A Comparative Study of Variational Autoencoders, Normalizing Flows, and\n  Score-based Diffusion Models for Electrical Impedance Tomography",
            "updated": "2023-11-29T11:39:34Z",
            "published": "2023-10-24T13:36:44Z",
            "summary": "Electrical Impedance Tomography (EIT) is a widely employed imaging technique\nin industrial inspection, geophysical prospecting, and medical imaging.\nHowever, the inherent nonlinearity and ill-posedness of EIT image\nreconstruction present challenges for classical regularization techniques, such\nas the critical selection of regularization terms and the lack of prior\nknowledge. Deep generative models (DGMs) have been shown to play a crucial role\nin learning implicit regularizers and prior knowledge. This study aims to\ninvestigate the potential of three DGMs-variational autoencoder networks,\nnormalizing flow, and score-based diffusion model-to learn implicit\nregularizers in learning-based EIT imaging. We first introduce background\ninformation on EIT imaging and its inverse problem formulation. Next, we\npropose three algorithms for performing EIT inverse problems based on\ncorresponding DGMs. Finally, we present numerical and visual experiments, which\nreveal that (1) no single method consistently outperforms the others across all\nsettings, and (2) when reconstructing an object with 2 anomalies using a\nwell-trained model based on a training dataset containing 4 anomalies, the\nconditional normalizing flow model (CNF) exhibits the best generalization in\nlow-level noise, while the conditional score-based diffusion model (CSD*)\ndemonstrates the best generalization in high-level noise settings. We hope our\npreliminary efforts will encourage other researchers to assess their DGMs in\nEIT and other nonlinear inverse problems.",
            "author": [
                "Huihui Wang",
                "Guixian Xu",
                "Qingping Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15831v2",
                "http://arxiv.org/pdf/2310.15831v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15830v1",
            "title": "Localization of Small Leakages in Water Distribution Networks using\n  Concept Drift Explanation Methods",
            "updated": "2023-10-24T13:33:19Z",
            "published": "2023-10-24T13:33:19Z",
            "summary": "Facing climate change the already limited availability of drinking water will\ndecrease in the future rendering drinking water an increasingly scarce\nresource. Considerable amounts of it are lost through leakages in water\ntransportation and distribution networks. Leakage detection and localization\nare challenging problems due to the complex interactions and changing demands\nin water distribution networks. Especially small leakages are hard to pinpoint\nyet their localization is vital to avoid water loss over long periods of time.\nWhile there exist different approaches to solving the tasks of leakage\ndetection and localization, they are relying on various information about the\nsystem, e.g. real-time demand measurements and the precise network topology,\nwhich is an unrealistic assumption in many real-world scenarios. In contrast,\nthis work attempts leakage localization using pressure measurements only. For\nthis purpose, first, leakages in the water distribution network are modeled\nemploying Bayesian networks, and the system dynamics are analyzed. We then show\nhow the problem is connected to and can be considered through the lens of\nconcept drift. In particular, we argue that model-based explanations of concept\ndrift are a promising tool for localizing leakages given limited information\nabout the network. The methodology is experimentally evaluated using realistic\nbenchmark scenarios.",
            "author": [
                "Valerie Vaquet",
                "Fabian Hinder",
                "Kathrin Lammers",
                "Jonas Vaquet",
                "Barbara Hammer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15830v1",
                "http://arxiv.org/pdf/2310.15830v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15829v1",
            "title": "Unnatural language processing: How do language models handle\n  machine-generated prompts?",
            "updated": "2023-10-24T13:32:20Z",
            "published": "2023-10-24T13:32:20Z",
            "summary": "Language model prompt optimization research has shown that semantically and\ngrammatically well-formed manually crafted prompts are routinely outperformed\nby automatically generated token sequences with no apparent meaning or\nsyntactic structure, including sequences of vectors from a model's embedding\nspace. We use machine-generated prompts to probe how models respond to input\nthat is not composed of natural language expressions. We study the behavior of\nmodels of different sizes in multiple semantic tasks in response to both\ncontinuous and discrete machine-generated prompts, and compare it to the\nbehavior in response to human-generated natural-language prompts. Even when\nproducing a similar output, machine-generated and human prompts trigger\ndifferent response patterns through the network processing pathways, including\ndifferent perplexities, different attention and output entropy distributions,\nand different unit activation profiles. We provide preliminary insight into the\nnature of the units activated by different prompt types, suggesting that only\nnatural language prompts recruit a genuinely linguistic circuit.",
            "author": [
                "Corentin Kervadec",
                "Francesca Franzon",
                "Marco Baroni"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15829v1",
                "http://arxiv.org/pdf/2310.15829v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15827v1",
            "title": "Automatic Aorta Segmentation with Heavily Augmented, High-Resolution 3-D\n  ResUNet: Contribution to the SEG.A Challenge",
            "updated": "2023-10-24T13:28:46Z",
            "published": "2023-10-24T13:28:46Z",
            "summary": "Automatic aorta segmentation from 3-D medical volumes is an important yet\ndifficult task. Several factors make the problem challenging, e.g. the\npossibility of aortic dissection or the difficulty with segmenting and\nannotating the small branches. This work presents a contribution by the MedGIFT\nteam to the SEG.A challenge organized during the MICCAI 2023 conference. We\npropose a fully automated algorithm based on deep encoder-decoder architecture.\nThe main assumption behind our work is that data preprocessing and augmentation\nare much more important than the deep architecture, especially in low data\nregimes. Therefore, the solution is based on a variant of traditional\nconvolutional U-Net. The proposed solution achieved a Dice score above 0.9 for\nall testing cases with the highest stability among all participants. The method\nscored 1st, 4th, and 3rd in terms of the clinical evaluation, quantitative\nresults, and volumetric meshing quality, respectively. We freely release the\nsource code, pretrained model, and provide access to the algorithm on the\nGrand-Challenge platform.",
            "author": [
                "Marek Wodzinski",
                "Henning M\u00fcller"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15827v1",
                "http://arxiv.org/pdf/2310.15827v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15826v1",
            "title": "One or Two Things We know about Concept Drift -- A Survey on Monitoring\n  Evolving Environments",
            "updated": "2023-10-24T13:25:19Z",
            "published": "2023-10-24T13:25:19Z",
            "summary": "The world surrounding us is subject to constant change. These changes,\nfrequently described as concept drift, influence many industrial and technical\nprocesses. As they can lead to malfunctions and other anomalous behavior, which\nmay be safety-critical in many scenarios, detecting and analyzing concept drift\nis crucial. In this paper, we provide a literature review focusing on concept\ndrift in unsupervised data streams. While many surveys focus on supervised data\nstreams, so far, there is no work reviewing the unsupervised setting. However,\nthis setting is of particular relevance for monitoring and anomaly detection\nwhich are directly applicable to many tasks and challenges in engineering. This\nsurvey provides a taxonomy of existing work on drift detection. Besides, it\ncovers the current state of research on drift localization in a systematic way.\nIn addition to providing a systematic literature review, this work provides\nprecise mathematical definitions of the considered problems and contains\nstandardized experiments on parametric artificial datasets allowing for a\ndirect comparison of different strategies for detection and localization.\nThereby, the suitability of different schemes can be analyzed systematically\nand guidelines for their usage in real-world scenarios can be provided.\nFinally, there is a section on the emerging topic of explaining concept drift.",
            "author": [
                "Fabian Hinder",
                "Valerie Vaquet",
                "Barbara Hammer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15826v1",
                "http://arxiv.org/pdf/2310.15826v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03370v1",
            "title": "CMIP X-MOS: Improving Climate Models with Extreme Model Output\n  Statistics",
            "updated": "2023-10-24T13:18:53Z",
            "published": "2023-10-24T13:18:53Z",
            "summary": "Climate models are essential for assessing the impact of greenhouse gas\nemissions on our changing climate and the resulting increase in the frequency\nand severity of natural disasters. Despite the widespread acceptance of climate\nmodels produced by the Coupled Model Intercomparison Project (CMIP), they still\nface challenges in accurately predicting climate extremes, which pose most\nsignificant threats to both people and the environment. To address this\nlimitation and improve predictions of natural disaster risks, we introduce\nExtreme Model Output Statistics (X-MOS). This approach utilizes deep regression\ntechniques to precisely map CMIP model outputs to real measurements obtained\nfrom weather stations, which results in a more accurate analysis of the XXI\nclimate extremes. In contrast to previous research, our study places a strong\nemphasis on enhancing the estimation of the tails of future climate parameter\ndistributions. The latter supports decision-makers, enabling them to better\nassess climate-related risks across the globe.",
            "author": [
                "Vsevolod Morozov",
                "Artem Galliamov",
                "Aleksandr Lukashevich",
                "Antonina Kurdukova",
                "Yury Maximov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03370v1",
                "http://arxiv.org/pdf/2311.03370v1"
            ],
            "primary_category": "physics.ao-ph",
            "category": [
                "physics.ao-ph",
                "cs.LG",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15819v1",
            "title": "Generative Language Models Exhibit Social Identity Biases",
            "updated": "2023-10-24T13:17:40Z",
            "published": "2023-10-24T13:17:40Z",
            "summary": "The surge in popularity of large language models has given rise to concerns\nabout biases that these models could learn from humans. In this study, we\ninvestigate whether ingroup solidarity and outgroup hostility, fundamental\nsocial biases known from social science, are present in 51 large language\nmodels. We find that almost all foundational language models and some\ninstruction fine-tuned models exhibit clear ingroup-positive and\noutgroup-negative biases when prompted to complete sentences (e.g., \"We\nare...\"). A comparison of LLM-generated sentences with human-written sentences\non the internet reveals that these models exhibit similar level, if not\ngreater, levels of bias than human text. To investigate where these biases stem\nfrom, we experimentally varied the amount of ingroup-positive or\noutgroup-negative sentences the model was exposed to during fine-tuning in the\ncontext of the United States Democrat-Republican divide. Doing so resulted in\nthe models exhibiting a marked increase in ingroup solidarity and an even\ngreater increase in outgroup hostility. Furthermore, removing either\ningroup-positive or outgroup-negative sentences (or both) from the fine-tuning\ndata leads to a significant reduction in both ingroup solidarity and outgroup\nhostility, suggesting that biases can be reduced by removing biased training\ndata. Our findings suggest that modern language models exhibit fundamental\nsocial identity biases and that such biases can be mitigated by curating\ntraining data. Our results have practical implications for creating less biased\nlarge-language models and further underscore the need for more research into\nuser interactions with LLMs to prevent potential bias reinforcement in humans.",
            "author": [
                "Tiancheng Hu",
                "Yara Kyrychenko",
                "Steve Rathje",
                "Nigel Collier",
                "Sander van der Linden",
                "Jon Roozenbeek"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15819v1",
                "http://arxiv.org/pdf/2310.15819v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15817v1",
            "title": "Discriminator Guidance for Autoregressive Diffusion Models",
            "updated": "2023-10-24T13:14:22Z",
            "published": "2023-10-24T13:14:22Z",
            "summary": "We introduce discriminator guidance in the setting of Autoregressive\nDiffusion Models. The use of a discriminator to guide a diffusion process has\npreviously been used for continuous diffusion models, and in this work we\nderive ways of using a discriminator together with a pretrained generative\nmodel in the discrete case. First, we show that using an optimal discriminator\nwill correct the pretrained model and enable exact sampling from the underlying\ndata distribution. Second, to account for the realistic scenario of using a\nsub-optimal discriminator, we derive a sequential Monte Carlo algorithm which\niteratively takes the predictions from the discrimiator into account during the\ngeneration process. We test these approaches on the task of generating\nmolecular graphs and show how the discriminator improves the generative\nperformance over using only the pretrained model.",
            "author": [
                "Filip Ekstr\u00f6m Kelvinius",
                "Fredrik Lindsten"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15817v1",
                "http://arxiv.org/pdf/2310.15817v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15816v1",
            "title": "Nonlinear dimensionality reduction then and now: AIMs for dissipative\n  PDEs in the ML era",
            "updated": "2023-10-24T13:10:43Z",
            "published": "2023-10-24T13:10:43Z",
            "summary": "This study presents a collection of purely data-driven workflows for\nconstructing reduced-order models (ROMs) for distributed dynamical systems. The\nROMs we focus on, are data-assisted models inspired by, and templated upon, the\ntheory of Approximate Inertial Manifolds (AIMs); the particular motivation is\nthe so-called post-processing Galerkin method of Garcia-Archilla, Novo and\nTiti. Its applicability can be extended: the need for accurate truncated\nGalerkin projections and for deriving closed-formed corrections can be\ncircumvented using machine learning tools. When the right latent variables are\nnot a priori known, we illustrate how autoencoders as well as Diffusion Maps (a\nmanifold learning scheme) can be used to discover good sets of latent variables\nand test their explainability. The proposed methodology can express the ROMs in\nterms of (a) theoretical (Fourier coefficients), (b) linear data-driven (POD\nmodes) and/or (c) nonlinear data-driven (Diffusion Maps) coordinates. Both\nBlack-Box and (theoretically-informed and data-corrected) Gray-Box models are\ndescribed; the necessity for the latter arises when truncated Galerkin\nprojections are so inaccurate as to not be amenable to post-processing. We use\nthe Chafee-Infante reaction-diffusion and the Kuramoto-Sivashinsky dissipative\npartial differential equations to illustrate and successfully test the overall\nframework.",
            "author": [
                "Eleni D. Koronaki",
                "Nikolaos Evangelou",
                "Cristina P. Martin-Linares",
                "Edriss S. Titi",
                "Ioannis G. Kevrekidis"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15816v1",
                "http://arxiv.org/pdf/2310.15816v1"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15815v1",
            "title": "Good Better Best: Self-Motivated Imitation Learning for noisy\n  Demonstrations",
            "updated": "2023-10-24T13:09:56Z",
            "published": "2023-10-24T13:09:56Z",
            "summary": "Imitation Learning (IL) aims to discover a policy by minimizing the\ndiscrepancy between the agent's behavior and expert demonstrations. However, IL\nis susceptible to limitations imposed by noisy demonstrations from non-expert\nbehaviors, presenting a significant challenge due to the lack of supplementary\ninformation to assess their expertise. In this paper, we introduce\nSelf-Motivated Imitation LEarning (SMILE), a method capable of progressively\nfiltering out demonstrations collected by policies deemed inferior to the\ncurrent policy, eliminating the need for additional information. We utilize the\nforward and reverse processes of Diffusion Models to emulate the shift in\ndemonstration expertise from low to high and vice versa, thereby extracting the\nnoise information that diffuses expertise. Then, the noise information is\nleveraged to predict the diffusion steps between the current policy and\ndemonstrators, which we theoretically demonstrate its equivalence to their\nexpertise gap. We further explain in detail how the predicted diffusion steps\nare applied to filter out noisy demonstrations in a self-motivated manner and\nprovide its theoretical grounds. Through empirical evaluations on MuJoCo tasks,\nwe demonstrate that our method is proficient in learning the expert policy\namidst noisy demonstrations, and effectively filters out demonstrations with\nexpertise inferior to the current policy.",
            "author": [
                "Ye Yuan",
                "Xin Li",
                "Yong Heng",
                "Leiji Zhang",
                "MingZhong Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15815v1",
                "http://arxiv.org/pdf/2310.15815v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15797v1",
            "title": "Random Entity Quantization for Parameter-Efficient Compositional\n  Knowledge Graph Representation",
            "updated": "2023-10-24T12:48:52Z",
            "published": "2023-10-24T12:48:52Z",
            "summary": "Representation Learning on Knowledge Graphs (KGs) is essential for downstream\ntasks. The dominant approach, KG Embedding (KGE), represents entities with\nindependent vectors and faces the scalability challenge. Recent studies propose\nan alternative way for parameter efficiency, which represents entities by\ncomposing entity-corresponding codewords matched from predefined small-scale\ncodebooks. We refer to the process of obtaining corresponding codewords of each\nentity as entity quantization, for which previous works have designed\ncomplicated strategies. Surprisingly, this paper shows that simple random\nentity quantization can achieve similar results to current strategies. We\nanalyze this phenomenon and reveal that entity codes, the quantization outcomes\nfor expressing entities, have higher entropy at the code level and Jaccard\ndistance at the codeword level under random entity quantization. Therefore,\ndifferent entities become more easily distinguished, facilitating effective KG\nrepresentation. The above results show that current quantization strategies are\nnot critical for KG representation, and there is still room for improvement in\nentity distinguishability beyond current strategies. The code to reproduce our\nresults is available at https://github.com/JiaangL/RandomQuantization.",
            "author": [
                "Jiaang Li",
                "Quan Wang",
                "Yi Liu",
                "Licheng Zhang",
                "Zhendong Mao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15797v1",
                "http://arxiv.org/pdf/2310.15797v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15793v1",
            "title": "Improving generalization in large language models by learning prefix\n  subspaces",
            "updated": "2023-10-24T12:44:09Z",
            "published": "2023-10-24T12:44:09Z",
            "summary": "This article focuses on large language models (LLMs) fine-tuning in the\nscarce data regime (also known as the \"few-shot\" learning setting). We propose\na method to increase the generalization capabilities of LLMs based on neural\nnetwork subspaces. This optimization method, recently introduced in computer\nvision, aims to improve model generalization by identifying wider local optima\nthrough the joint optimization of an entire simplex of models in parameter\nspace. Its adaptation to massive, pretrained transformers, however, poses some\nchallenges. First, their considerable number of parameters makes it difficult\nto train several models jointly, and second, their deterministic parameter\ninitialization schemes make them unfit for the subspace method as originally\nproposed. We show in this paper that \"Parameter Efficient Fine-Tuning\" (PEFT)\nmethods, however, are perfectly compatible with this original approach, and\npropose to learn entire simplex of continuous prefixes. We test our method on a\nvariant of the GLUE benchmark adapted to the few-shot learning setting, and\nshow that both our contributions jointly lead to a gain in average performances\ncompared to sota methods. The implementation can be found at the following\nlink: https://github.com/Liloulou/prefix_subspace",
            "author": [
                "Louis Falissard",
                "Vincent Guigue",
                "Laure Soulier"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15793v1",
                "http://arxiv.org/pdf/2310.15793v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18360v1",
            "title": "Guiding LLM to Fool Itself: Automatically Manipulating Machine Reading\n  Comprehension Shortcut Triggers",
            "updated": "2023-10-24T12:37:06Z",
            "published": "2023-10-24T12:37:06Z",
            "summary": "Recent applications of LLMs in Machine Reading Comprehension (MRC) systems\nhave shown impressive results, but the use of shortcuts, mechanisms triggered\nby features spuriously correlated to the true label, has emerged as a potential\nthreat to their reliability. We analyze the problem from two angles: LLMs as\neditors, guided to edit text to mislead LLMs; and LLMs as readers, who answer\nquestions based on the edited text. We introduce a framework that guides an\neditor to add potential shortcuts-triggers to samples. Using GPT4 as the\neditor, we find it can successfully edit trigger shortcut in samples that fool\nLLMs. Analysing LLMs as readers, we observe that even capable LLMs can be\ndeceived using shortcut knowledge. Strikingly, we discover that GPT4 can be\ndeceived by its own edits (15% drop in F1). Our findings highlight inherent\nvulnerabilities of LLMs to shortcut manipulations. We publish ShortcutQA, a\ncurated dataset generated by our framework for future research.",
            "author": [
                "Mosh Levy",
                "Shauli Ravfogel",
                "Yoav Goldberg"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18360v1",
                "http://arxiv.org/pdf/2310.18360v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15788v1",
            "title": "qPOTS: Efficient batch multiobjective Bayesian optimization via Pareto\n  optimal Thompson sampling",
            "updated": "2023-10-24T12:35:15Z",
            "published": "2023-10-24T12:35:15Z",
            "summary": "Classical evolutionary approaches for multiobjective optimization are quite\neffective but incur a lot of queries to the objectives; this can be prohibitive\nwhen objectives are expensive oracles. A sample-efficient approach to solving\nmultiobjective optimization is via Gaussian process (GP) surrogates and\nBayesian optimization (BO). Multiobjective Bayesian optimization (MOBO)\ninvolves the construction of an acquisition function which is optimized to\nacquire new observation candidates. This ``inner'' optimization can be hard due\nto various reasons: acquisition functions being nonconvex, nondifferentiable\nand/or unavailable in analytical form; the success of MOBO heavily relies on\nthis inner optimization. We do away with this hard acquisition function\noptimization step and propose a simple, but effective, Thompson sampling based\napproach ($q\\texttt{POTS}$) where new candidate(s) are chosen from the Pareto\nfrontier of random GP posterior sample paths obtained by solving a much cheaper\nmultiobjective optimization problem. To further improve computational\ntractability in higher dimensions we propose an automated active set of\ncandidates selection combined with a Nystr\\\"{o}m approximation. Our approach\napplies to arbitrary GP prior assumptions and demonstrates strong empirical\nperformance over the state of the art, both in terms of accuracy and\ncomputational efficiency, on synthetic as well as real-world experiments.",
            "author": [
                "S. Ashwin Renganathan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15788v1",
                "http://arxiv.org/pdf/2310.15788v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15787v1",
            "title": "SequenceMatch: Revisiting the design of weak-strong augmentations for\n  Semi-supervised learning",
            "updated": "2023-10-24T12:34:58Z",
            "published": "2023-10-24T12:34:58Z",
            "summary": "Semi-supervised learning (SSL) has become popular in recent years because it\nallows the training of a model using a large amount of unlabeled data. However,\none issue that many SSL methods face is the confirmation bias, which occurs\nwhen the model is overfitted to the small labeled training dataset and produces\noverconfident, incorrect predictions. To address this issue, we propose\nSequenceMatch, an efficient SSL method that utilizes multiple data\naugmentations. The key element of SequenceMatch is the inclusion of a medium\naugmentation for unlabeled data. By taking advantage of different augmentations\nand the consistency constraints between each pair of augmented examples,\nSequenceMatch helps reduce the divergence between the prediction distribution\nof the model for weakly and strongly augmented examples. In addition,\nSequenceMatch defines two different consistency constraints for high and\nlow-confidence predictions. As a result, SequenceMatch is more data-efficient\nthan ReMixMatch, and more time-efficient than both ReMixMatch ($\\times4$) and\nCoMatch ($\\times2$) while having higher accuracy. Despite its simplicity,\nSequenceMatch consistently outperforms prior methods on standard benchmarks,\nsuch as CIFAR-10/100, SVHN, and STL-10. It also surpasses prior\nstate-of-the-art methods by a large margin on large-scale datasets such as\nImageNet, with a 38.46\\% error rate. Code is available at\nhttps://github.com/beandkay/SequenceMatch.",
            "author": [
                "Khanh-Binh Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15787v1",
                "http://arxiv.org/pdf/2310.15787v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15786v1",
            "title": "Amortised Inference in Neural Networks for Small-Scale Probabilistic\n  Meta-Learning",
            "updated": "2023-10-24T12:34:25Z",
            "published": "2023-10-24T12:34:25Z",
            "summary": "The global inducing point variational approximation for BNNs is based on\nusing a set of inducing inputs to construct a series of conditional\ndistributions that accurately approximate the conditionals of the true\nposterior distribution. Our key insight is that these inducing inputs can be\nreplaced by the actual data, such that the variational distribution consists of\na set of approximate likelihoods for each datapoint. This structure lends\nitself to amortised inference, in which the parameters of each approximate\nlikelihood are obtained by passing each datapoint through a meta-model known as\nthe inference network. By training this inference network across related\ndatasets, we can meta-learn Bayesian inference over task-specific BNNs.",
            "author": [
                "Matthew Ashman",
                "Tommy Rochussen",
                "Adrian Weller"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15786v1",
                "http://arxiv.org/pdf/2310.15786v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15780v1",
            "title": "Make LLM a Testing Expert: Bringing Human-like Interaction to Mobile GUI\n  Testing via Functionality-aware Decisions",
            "updated": "2023-10-24T12:30:26Z",
            "published": "2023-10-24T12:30:26Z",
            "summary": "Automated Graphical User Interface (GUI) testing plays a crucial role in\nensuring app quality, especially as mobile applications have become an integral\npart of our daily lives. Despite the growing popularity of learning-based\ntechniques in automated GUI testing due to their ability to generate human-like\ninteractions, they still suffer from several limitations, such as low testing\ncoverage, inadequate generalization capabilities, and heavy reliance on\ntraining data. Inspired by the success of Large Language Models (LLMs) like\nChatGPT in natural language understanding and question answering, we formulate\nthe mobile GUI testing problem as a Q&A task. We propose GPTDroid, asking LLM\nto chat with the mobile apps by passing the GUI page information to LLM to\nelicit testing scripts, and executing them to keep passing the app feedback to\nLLM, iterating the whole process. Within this framework, we have also\nintroduced a functionality-aware memory prompting mechanism that equips the LLM\nwith the ability to retain testing knowledge of the whole process and conduct\nlong-term, functionality-based reasoning to guide exploration. We evaluate it\non 93 apps from Google Play and demonstrate that it outperforms the best\nbaseline by 32% in activity coverage, and detects 31% more bugs at a faster\nrate. Moreover, GPTDroid identify 53 new bugs on Google Play, of which 35 have\nbeen confirmed and fixed.",
            "author": [
                "Zhe Liu",
                "Chunyang Chen",
                "Junjie Wang",
                "Mengzhuo Chen",
                "Boyu Wu",
                "Xing Che",
                "Dandan Wang",
                "Qing Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15780v1",
                "http://arxiv.org/pdf/2310.15780v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15771v1",
            "title": "Control problems on infinite horizon subject to time-dependent pure\n  state constraints",
            "updated": "2023-10-24T12:17:23Z",
            "published": "2023-10-24T12:17:23Z",
            "summary": "In the last decades, control problems with infinite horizons and discount\nfactors have become increasingly central not only for economics but also for\napplications in artificial intelligence and machine learning. The strong links\nbetween reinforcement learning and control theory have led to major efforts\ntowards the development of algorithms to learn how to solve constrained control\nproblems. In particular, discount plays a role in addressing the challenges\nthat come with models that have unbounded disturbances. Although algorithms\nhave been extensively explored, few results take into account time-dependent\nstate constraints, which are imposed in most real-world control applications.\nFor this purpose, here we investigate feasibility and sufficient conditions for\nLipschitz regularity of the value function for a class of discounted infinite\nhorizon optimal control problems subject to time-dependent constraints. We\nfocus on problems with data that allow nonautonomous dynamics, and Lagrangian\nand state constraints that can be unbounded with possibly nonsmooth boundaries.",
            "author": [
                "Vincenzo Basco"
            ],
            "link": [
                "http://dx.doi.org/10.1007/s00498-023-00372-3",
                "http://arxiv.org/abs/2310.15771v1",
                "http://arxiv.org/pdf/2310.15771v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15767v2",
            "title": "Unpaired MRI Super Resolution with Self-Supervised Contrastive Learning",
            "updated": "2023-11-09T10:40:54Z",
            "published": "2023-10-24T12:13:51Z",
            "summary": "High-resolution (HR) magnetic resonance imaging (MRI) is crucial for\nenhancing diagnostic accuracy in clinical settings. Nonetheless, the inherent\nlimitation of MRI resolution restricts its widespread applicability. Deep\nlearning-based image super-resolution (SR) methods exhibit promise in improving\nMRI resolution without additional cost. However, these methods frequently\nrequire a substantial number of HR MRI images for training, which can be\nchallenging to acquire. In this paper, we propose an unpaired MRI SR approach\nthat employs self-supervised contrastive learning to enhance SR performance\nwith limited training data. Our approach leverages both authentic HR images and\nsynthetically generated SR images to construct positive and negative sample\npairs, thus facilitating the learning of discriminative features. Empirical\nresults presented in this study underscore significant enhancements in the peak\nsignal-to-noise ratio and structural similarity index, even when a paucity of\nHR images is available. These findings accentuate the potential of our approach\nin addressing the challenge of limited training data, thereby contributing to\nthe advancement of high-resolution MRI in clinical applications.",
            "author": [
                "Hao Li",
                "Quanwei Liu",
                "Jianan Liu",
                "Xiling Liu",
                "Yanni Dong",
                "Tao Huang",
                "Zhihan Lv"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15767v2",
                "http://arxiv.org/pdf/2310.15767v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15766v1",
            "title": "Robust Learning via Conditional Prevalence Adjustment",
            "updated": "2023-10-24T12:13:49Z",
            "published": "2023-10-24T12:13:49Z",
            "summary": "Healthcare data often come from multiple sites in which the correlations\nbetween confounding variables can vary widely. If deep learning models exploit\nthese unstable correlations, they might fail catastrophically in unseen sites.\nAlthough many methods have been proposed to tackle unstable correlations, each\nhas its limitations. For example, adversarial training forces models to\ncompletely ignore unstable correlations, but doing so may lead to poor\npredictive performance. Other methods (e.g. Invariant risk minimization [4])\ntry to learn domain-invariant representations that rely only on stable\nassociations by assuming a causal data-generating process (input X causes class\nlabel Y ). Thus, they may be ineffective for anti-causal tasks (Y causes X),\nwhich are common in computer vision. We propose a method called CoPA\n(Conditional Prevalence-Adjustment) for anti-causal tasks. CoPA assumes that\n(1) generation mechanism is stable, i.e. label Y and confounding variable(s) Z\ngenerate X, and (2) the unstable conditional prevalence in each site E fully\naccounts for the unstable correlations between X and Y . Our crucial\nobservation is that confounding variables are routinely recorded in healthcare\nsettings and the prevalence can be readily estimated, for example, from a set\nof (Y, Z) samples (no need for corresponding samples of X). CoPA can work even\nif there is a single training site, a scenario which is often overlooked by\nexisting methods. Our experiments on synthetic and real data show CoPA beating\ncompetitive baselines.",
            "author": [
                "Minh Nguyen",
                "Alan Q. Wang",
                "Heejong Kim",
                "Mert R. Sabuncu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15766v1",
                "http://arxiv.org/pdf/2310.15766v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15764v1",
            "title": "Debiasing, calibrating, and improving Semi-supervised Learning\n  performance via simple Ensemble Projector",
            "updated": "2023-10-24T12:11:19Z",
            "published": "2023-10-24T12:11:19Z",
            "summary": "Recent studies on semi-supervised learning (SSL) have achieved great success.\nDespite their promising performance, current state-of-the-art methods tend\ntoward increasingly complex designs at the cost of introducing more network\ncomponents and additional training procedures. In this paper, we propose a\nsimple method named Ensemble Projectors Aided for Semi-supervised Learning\n(EPASS), which focuses mainly on improving the learned embeddings to boost the\nperformance of the existing contrastive joint-training semi-supervised learning\nframeworks. Unlike standard methods, where the learned embeddings from one\nprojector are stored in memory banks to be used with contrastive learning,\nEPASS stores the ensemble embeddings from multiple projectors in memory banks.\nAs a result, EPASS improves generalization, strengthens feature representation,\nand boosts performance. For instance, EPASS improves strong baselines for\nsemi-supervised learning by 39.47\\%/31.39\\%/24.70\\% top-1 error rate, while\nusing only 100k/1\\%/10\\% of labeled data for SimMatch, and achieves\n40.24\\%/32.64\\%/25.90\\% top-1 error rate for CoMatch on the ImageNet dataset.\nThese improvements are consistent across methods, network architectures, and\ndatasets, proving the general effectiveness of the proposed methods. Code is\navailable at https://github.com/beandkay/EPASS.",
            "author": [
                "Khanh-Binh Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15764v1",
                "http://arxiv.org/pdf/2310.15764v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15758v1",
            "title": "Learning From Free-Text Human Feedback -- Collect New Datasets Or Extend\n  Existing Ones?",
            "updated": "2023-10-24T12:01:11Z",
            "published": "2023-10-24T12:01:11Z",
            "summary": "Learning from free-text human feedback is essential for dialog systems, but\nannotated data is scarce and usually covers only a small fraction of error\ntypes known in conversational AI. Instead of collecting and annotating new\ndatasets from scratch, recent advances in synthetic dialog generation could be\nused to augment existing dialog datasets with the necessary annotations.\nHowever, to assess the feasibility of such an effort, it is important to know\nthe types and frequency of free-text human feedback included in these datasets.\nIn this work, we investigate this question for a variety of commonly used\ndialog datasets, including MultiWoZ, SGD, BABI, PersonaChat,\nWizards-of-Wikipedia, and the human-bot split of the Self-Feeding Chatbot.\nUsing our observations, we derive new taxonomies for the annotation of\nfree-text human feedback in dialogs and investigate the impact of including\nsuch data in response generation for three SOTA language generation models,\nincluding GPT-2, LLAMA, and Flan-T5. Our findings provide new insights into the\ncomposition of the datasets examined, including error types, user response\ntypes, and the relations between them.",
            "author": [
                "Dominic Petrak",
                "Nafise Sadat Moosavi",
                "Ye Tian",
                "Nikolai Rozanov",
                "Iryna Gurevych"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15758v1",
                "http://arxiv.org/pdf/2310.15758v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15753v1",
            "title": "Efficient CPU-Optimized Parameter Estimation for Modeling Fish Schooling\n  Behavior in Large Particle Systems",
            "updated": "2023-10-24T11:56:13Z",
            "published": "2023-10-24T11:56:13Z",
            "summary": "The schooling behavior of fish can be studied through simulations involving a\nlarge number of interacting particles. In such systems, each individual\nparticle is guided by behavior rules, which include aggregation towards a\ncentroid, collision avoidance, and direction alignment. The movement vector of\neach particle may be expressed as a linear combination of behaviors, with\nunknown parameters that define a trade-off among several behavioral\nconstraints. A fitness function for collective schooling behavior encompasses\nall individual particle parameters.\n  For a large number of interacting particles in a complex environment,\nheuristic methods, such as evolutionary algorithms, are used to optimize the\nfitness function, ensuring that the resulting decision rule preserves\ncollective behavior. However, these algorithms exhibit slow convergence, making\nthem inefficient in terms of CPU time cost.\n  This paper proposes a CPU-efficient iterative (Cluster, Partition, Refine --\nCPR) algorithm for estimating decision rule parameters for a large number of\ninteracting particles. In the first step, we employ the K-Means (unsupervised\nlearning) algorithm to cluster candidate solutions. Then, we partition the\nsearch space using Voronoi tessellation over the defined clusters. We assess\nthe quality of each cluster based on the fitness function, with the centroid of\ntheir Voronoi cells representing the clusters. Subsequently, we refine the\nsearch space by introducing new cells into a number of identified well-fitting\nVoronoi cells. This process is repeated until convergence.\n  A comparison of the performance of the CPR algorithm with a standard Genetic\nAlgorithm reveals that the former converges faster than the latter. We also\ndemonstrate that the application of the CPR algorithm results in a schooling\nbehavior consistent with empirical observations.",
            "author": [
                "S. Arabeei",
                "S. Subbey"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15753v1",
                "http://arxiv.org/pdf/2310.15753v1"
            ],
            "primary_category": "q-bio.PE",
            "category": [
                "q-bio.PE",
                "92D40, 92C20, 65K05, 68T05",
                "G.1.6; G.4; I.2.8; I.6.5; J.3; D.2.8"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15752v1",
            "title": "Integrating Language Models into Direct Speech Translation: An\n  Inference-Time Solution to Control Gender Inflection",
            "updated": "2023-10-24T11:55:16Z",
            "published": "2023-10-24T11:55:16Z",
            "summary": "When translating words referring to the speaker, speech translation (ST)\nsystems should not resort to default masculine generics nor rely on potentially\nmisleading vocal traits. Rather, they should assign gender according to the\nspeakers' preference. The existing solutions to do so, though effective, are\nhardly feasible in practice as they involve dedicated model re-training on\ngender-labeled ST data. To overcome these limitations, we propose the first\ninference-time solution to control speaker-related gender inflections in ST.\nOur approach partially replaces the (biased) internal language model (LM)\nimplicitly learned by the ST decoder with gender-specific external LMs.\nExperiments on en->es/fr/it show that our solution outperforms the base models\nand the best training-time mitigation strategy by up to 31.0 and 1.6 points in\ngender accuracy, respectively, for feminine forms. The gains are even larger\n(up to 32.0 and 3.4) in the challenging condition where speakers' vocal traits\nconflict with their gender.",
            "author": [
                "Dennis Fucci",
                "Marco Gaido",
                "Sara Papi",
                "Mauro Cettolo",
                "Matteo Negri",
                "Luisa Bentivogli"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15752v1",
                "http://arxiv.org/pdf/2310.15752v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16851v1",
            "title": "Deep Learning Models for Classification of COVID-19 Cases by Medical\n  Images",
            "updated": "2023-10-24T11:48:40Z",
            "published": "2023-10-24T11:48:40Z",
            "summary": "In recent times, the use of chest Computed Tomography (CT) images for\ndetecting coronavirus infections has gained significant attention, owing to\ntheir ability to reveal bilateral changes in affected individuals. However,\nclassifying patients from medical images presents a formidable challenge,\nparticularly in identifying such bilateral changes. To tackle this challenge,\nour study harnesses the power of deep learning models for the precise\nclassification of infected patients. Our research involves a comparative\nanalysis of deep transfer learning-based classification models, including\nDenseNet201, GoogleNet, and AlexNet, against carefully chosen supervised\nlearning models. Additionally, our work encompasses Covid-19 classification,\nwhich involves the identification and differentiation of medical images, such\nas X-rays and electrocardiograms, that exhibit telltale signs of Covid-19\ninfection. This comprehensive approach ensures that our models can handle a\nwide range of medical image types and effectively identify characteristic\npatterns indicative of Covid-19. By conducting meticulous research and\nemploying advanced deep learning techniques, we have made significant strides\nin enhancing the accuracy and speed of Covid-19 diagnosis. Our results\ndemonstrate the effectiveness of these models and their potential to make\nsubstantial contributions to the global effort to combat COVID-19.",
            "author": [
                "Amir Ali"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16851v1",
                "http://arxiv.org/pdf/2310.16851v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15746v1",
            "title": "Failures Pave the Way: Enhancing Large Language Models through\n  Tuning-free Rule Accumulation",
            "updated": "2023-10-24T11:40:34Z",
            "published": "2023-10-24T11:40:34Z",
            "summary": "Large Language Models (LLMs) have showcased impressive performance. However,\ndue to their inability to capture relationships among samples, these frozen\nLLMs inevitably keep repeating similar mistakes. In this work, we propose our\nTuning-free Rule Accumulation (TRAN) framework, which guides LLMs in improving\ntheir performance by learning from previous mistakes. Considering data arrives\nsequentially, LLMs gradually accumulate rules from incorrect cases, forming a\nrule collection. These rules are then utilized by the LLMs to avoid making\nsimilar mistakes when processing subsequent inputs. Moreover, the rules remain\nindependent of the primary prompts, seamlessly complementing prompt design\nstrategies. Experimentally, we show that TRAN improves over recent baselines by\na large margin.",
            "author": [
                "Zeyuan Yang",
                "Peng Li",
                "Yang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15746v1",
                "http://arxiv.org/pdf/2310.15746v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15744v1",
            "title": "Analyzing Single Cell RNA Sequencing with Topological Nonnegative Matrix\n  Factorization",
            "updated": "2023-10-24T11:36:41Z",
            "published": "2023-10-24T11:36:41Z",
            "summary": "Single-cell RNA sequencing (scRNA-seq) is a relatively new technology that\nhas stimulated enormous interest in statistics, data science, and computational\nbiology due to the high dimensionality, complexity, and large scale associated\nwith scRNA-seq data. Nonnegative matrix factorization (NMF) offers a unique\napproach due to its meta-gene interpretation of resulting low-dimensional\ncomponents. However, NMF approaches suffer from the lack of multiscale\nanalysis. This work introduces two persistent Laplacian regularized NMF\nmethods, namely, topological NMF (TNMF) and robust topological NMF (rTNMF). By\nemploying a total of 12 datasets, we demonstrate that the proposed TNMF and\nrTNMF significantly outperform all other NMF-based methods. We have also\nutilized TNMF and rTNMF for the visualization of popular Uniform Manifold\nApproximation and Projection (UMAP) and t-distributed stochastic neighbor\nembedding (t-SNE).",
            "author": [
                "Yuta Hozumi",
                "Guo-Wei Wei"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15744v1",
                "http://arxiv.org/pdf/2310.15744v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "math.AT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15743v1",
            "title": "RAPL: A Relation-Aware Prototype Learning Approach for Few-Shot\n  Document-Level Relation Extraction",
            "updated": "2023-10-24T11:35:23Z",
            "published": "2023-10-24T11:35:23Z",
            "summary": "How to identify semantic relations among entities in a document when only a\nfew labeled documents are available? Few-shot document-level relation\nextraction (FSDLRE) is crucial for addressing the pervasive data scarcity\nproblem in real-world scenarios. Metric-based meta-learning is an effective\nframework widely adopted for FSDLRE, which constructs class prototypes for\nclassification. However, existing works often struggle to obtain class\nprototypes with accurate relational semantics: 1) To build prototype for a\ntarget relation type, they aggregate the representations of all entity pairs\nholding that relation, while these entity pairs may also hold other relations,\nthus disturbing the prototype. 2) They use a set of generic NOTA\n(none-of-the-above) prototypes across all tasks, neglecting that the NOTA\nsemantics differs in tasks with different target relation types. In this paper,\nwe propose a relation-aware prototype learning method for FSDLRE to strengthen\nthe relational semantics of prototype representations. By judiciously\nleveraging the relation descriptions and realistic NOTA instances as guidance,\nour method effectively refines the relation prototypes and generates\ntask-specific NOTA prototypes. Extensive experiments demonstrate that our\nmethod outperforms state-of-the-art approaches by average 2.61% $F_1$ across\nvarious settings of two FSDLRE benchmarks.",
            "author": [
                "Shiao Meng",
                "Xuming Hu",
                "Aiwei Liu",
                "Shu'ang Li",
                "Fukun Ma",
                "Yawen Yang",
                "Lijie Wen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15743v1",
                "http://arxiv.org/pdf/2310.15743v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "68T50",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15742v2",
            "title": "Improving Diffusion Models for ECG Imputation with an Augmented Template\n  Prior",
            "updated": "2023-11-14T12:02:43Z",
            "published": "2023-10-24T11:34:15Z",
            "summary": "Pulsative signals such as the electrocardiogram (ECG) are extensively\ncollected as part of routine clinical care. However, noisy and poor-quality\nrecordings are a major issue for signals collected using mobile health systems,\ndecreasing the signal quality, leading to missing values, and affecting\nautomated downstream tasks. Recent studies have explored the imputation of\nmissing values in ECG with probabilistic time-series models. Nevertheless, in\ncomparison with the deterministic models, their performance is still limited,\nas the variations across subjects and heart-beat relationships are not\nexplicitly considered in the training objective. In this work, to improve the\nimputation and forecasting accuracy for ECG with probabilistic models, we\npresent a template-guided denoising diffusion probabilistic model (DDPM),\nPulseDiff, which is conditioned on an informative prior for a range of health\nconditions. Specifically, 1) we first extract a subject-level pulsative\ntemplate from the observed values to use as an informative prior of the missing\nvalues, which personalises the prior; 2) we then add beat-level stochastic\nshift terms to augment the prior, which considers variations in the position\nand amplitude of the prior at each beat; 3) we finally design a confidence\nscore to consider the health condition of the subject, which ensures our prior\nis provided safely. Experiments with the PTBXL dataset reveal that PulseDiff\nimproves the performance of two strong DDPM baseline models, CSDI and\nSSSD$^{S4}$, verifying that our method guides the generation of DDPMs while\nmanaging the uncertainty. When combined with SSSD$^{S4}$, PulseDiff outperforms\nthe leading deterministic model for short-interval missing data and is\ncomparable for long-interval data loss.",
            "author": [
                "Alexander Jenkins",
                "Zehua Chen",
                "Fu Siong Ng",
                "Danilo Mandic"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15742v2",
                "http://arxiv.org/pdf/2310.15742v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16065v1",
            "title": "The Hyperdimensional Transform: a Holographic Representation of\n  Functions",
            "updated": "2023-10-24T11:33:39Z",
            "published": "2023-10-24T11:33:39Z",
            "summary": "Integral transforms are invaluable mathematical tools to map functions into\nspaces where they are easier to characterize. We introduce the hyperdimensional\ntransform as a new kind of integral transform. It converts square-integrable\nfunctions into noise-robust, holographic, high-dimensional representations\ncalled hyperdimensional vectors. The central idea is to approximate a function\nby a linear combination of random functions. We formally introduce a set of\nstochastic, orthogonal basis functions and define the hyperdimensional\ntransform and its inverse. We discuss general transform-related properties such\nas its uniqueness, approximation properties of the inverse transform, and the\nrepresentation of integrals and derivatives. The hyperdimensional transform\noffers a powerful, flexible framework that connects closely with other integral\ntransforms, such as the Fourier, Laplace, and fuzzy transforms. Moreover, it\nprovides theoretical foundations and new insights for the field of\nhyperdimensional computing, a computing paradigm that is rapidly gaining\nattention for efficient and explainable machine learning algorithms, with\npotential applications in statistical modelling and machine learning. In\naddition, we provide straightforward and easily understandable code, which can\nfunction as a tutorial and allows for the reproduction of the demonstrated\nexamples, from computing the transform to solving differential equations.",
            "author": [
                "Pieter Dewulf",
                "Michiel Stock",
                "Bernard De Baets"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16065v1",
                "http://arxiv.org/pdf/2310.16065v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15741v1",
            "title": "Interpretable Medical Image Classification using Prototype Learning and\n  Privileged Information",
            "updated": "2023-10-24T11:28:59Z",
            "published": "2023-10-24T11:28:59Z",
            "summary": "Interpretability is often an essential requirement in medical imaging.\nAdvanced deep learning methods are required to address this need for\nexplainability and high performance. In this work, we investigate whether\nadditional information available during the training process can be used to\ncreate an understandable and powerful model. We propose an innovative solution\ncalled Proto-Caps that leverages the benefits of capsule networks, prototype\nlearning and the use of privileged information. Evaluating the proposed\nsolution on the LIDC-IDRI dataset shows that it combines increased\ninterpretability with above state-of-the-art prediction performance. Compared\nto the explainable baseline model, our method achieves more than 6 % higher\naccuracy in predicting both malignancy (93.0 %) and mean characteristic\nfeatures of lung nodules. Simultaneously, the model provides case-based\nreasoning with prototype representations that allow visual validation of\nradiologist-defined attributes.",
            "author": [
                "Luisa Gallee",
                "Meinrad Beer",
                "Michael Goetz"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-031-43895-0_41",
                "http://arxiv.org/abs/2310.15741v1",
                "http://arxiv.org/pdf/2310.15741v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15723v1",
            "title": "Data Processing Engine (DPE): Data Analysis Tool for Particle Tracking\n  and Mixed Radiation Field Characterization with Pixel Detectors Timepix",
            "updated": "2023-10-24T10:59:43Z",
            "published": "2023-10-24T10:59:43Z",
            "summary": "Hybrid semiconductor pixelated detectors from the Timepix family are advanced\ndetectors for online particle tracking, offering energy measurement and precise\ntime stamping capabilities for particles of various types and energies. This\ninherent capability makes them highly suitable for various applications,\nincluding imaging, medical fields such as radiotherapy and particle therapy,\nspace-based applications aboard satellites and the International Space Station,\nand industrial applications. The data generated by these detectors is complex,\nnecessitating the development and deployment of various analytical techniques\nto extract essential information. For this purpose, and to aid the Timepix user\ncommunity, it was designed and developed the \"Data Processing Engine\" (DPE) as\nan advanced tool for data processing designed explicitly for Timepix detectors.\nThe functionality of the DPE is structured into three distinct processing\nlevels: i) Pre-processing: This phase involves clusterization and the\napplication of necessary calibrations and corrections. ii) Processing: This\nstage includes particle classification, employing machine learning algorithms,\nand the recognition of radiation fields. iii) Post-processing: Involves various\nanalyses, such as directional analysis, coincidence analysis, frame analysis,\nCompton directional analysis, and the generation of physics products, are\nperformed. The core of the DPE is supported by an extensive experimental\ndatabase containing calibrations and referential radiation fields of typical\nenvironments, including protons, ions, electrons, gamma rays and X-rays, as\nwell as thermal and fast neutrons. To enhance accessibility, the DPE is\nimplemented into various user interface platforms such as a command-line tool,\nan application programming interface, and as a graphical user interface in the\nform of a web portal.",
            "author": [
                "Marek Lukas",
                "Granja Carlos",
                "Jakubek Jan",
                "Ingerle Jan",
                "Turecek Daniel",
                "Vuolo Marco",
                "Oancea Cristina"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15723v1",
                "http://arxiv.org/pdf/2310.15723v1"
            ],
            "primary_category": "physics.med-ph",
            "category": [
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15722v1",
            "title": "Re-Temp: Relation-Aware Temporal Representation Learning for Temporal\n  Knowledge Graph Completion",
            "updated": "2023-10-24T10:58:33Z",
            "published": "2023-10-24T10:58:33Z",
            "summary": "Temporal Knowledge Graph Completion (TKGC) under the extrapolation setting\naims to predict the missing entity from a fact in the future, posing a\nchallenge that aligns more closely with real-world prediction problems.\nExisting research mostly encodes entities and relations using sequential graph\nneural networks applied to recent snapshots. However, these approaches tend to\noverlook the ability to skip irrelevant snapshots according to entity-related\nrelations in the query and disregard the importance of explicit temporal\ninformation. To address this, we propose our model, Re-Temp (Relation-Aware\nTemporal Representation Learning), which leverages explicit temporal embedding\nas input and incorporates skip information flow after each timestamp to skip\nunnecessary information for prediction. Additionally, we introduce a two-phase\nforward propagation method to prevent information leakage. Through the\nevaluation on six TKGC (extrapolation) datasets, we demonstrate that our model\noutperforms all eight recent state-of-the-art models by a significant margin.",
            "author": [
                "Kunze Wang",
                "Soyeon Caren Han",
                "Josiah Poon"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15722v1",
                "http://arxiv.org/pdf/2310.15722v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15720v2",
            "title": "Ensemble of Task-Specific Language Models for Brain Encoding",
            "updated": "2023-11-09T07:03:54Z",
            "published": "2023-10-24T10:52:41Z",
            "summary": "Language models have been shown to be rich enough to encode fMRI activations\nof certain Regions of Interest in our Brains. Previous works have explored\ntransfer learning from representations learned for popular natural language\nprocessing tasks for predicting brain responses. In our work, we improve the\nperformance of such encoders by creating an ensemble model out of 10 popular\nLanguage Models (2 syntactic and 8 semantic). We beat the current baselines by\n10% on average across all ROIs through our ensembling methods.",
            "author": [
                "Arvindh Arun",
                "Jerrin John",
                "Sanjai Kumaran"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15720v2",
                "http://arxiv.org/pdf/2310.15720v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15719v1",
            "title": "Recurrent Linear Transformers",
            "updated": "2023-10-24T10:51:50Z",
            "published": "2023-10-24T10:51:50Z",
            "summary": "The self-attention mechanism in the transformer architecture is capable of\ncapturing long-range dependencies and it is the main reason behind its\neffectiveness in processing sequential data. Nevertheless, despite their\nsuccess, transformers have two significant drawbacks that still limit their\nbroader applicability: (1) In order to remember past information, the\nself-attention mechanism requires access to the whole history to be provided as\ncontext. (2) The inference cost in transformers is expensive. In this paper we\nintroduce recurrent alternatives to the transformer self-attention mechanism\nthat offer a context-independent inference cost, leverage long-range\ndependencies effectively, and perform well in practice. We evaluate our\napproaches in reinforcement learning problems where the aforementioned\ncomputational limitations make the application of transformers nearly\ninfeasible. We quantify the impact of the different components of our\narchitecture in a diagnostic environment and assess performance gains in 2D and\n3D pixel-based partially-observable environments. When compared to a\nstate-of-the-art architecture, GTrXL, inference in our approach is at least 40%\ncheaper while reducing memory use in more than 50%. Our approach either\nperforms similarly or better than GTrXL, improving more than 37% upon GTrXL\nperformance on harder tasks.",
            "author": [
                "Subhojeet Pramanik",
                "Esraa Elelimy",
                "Marlos C. Machado",
                "Adam White"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15719v1",
                "http://arxiv.org/pdf/2310.15719v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    }
]