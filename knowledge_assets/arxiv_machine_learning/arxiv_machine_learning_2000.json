[
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15955v1",
            "title": "NN bundle method applied to cosmology: an improvement in computational\n  times",
            "updated": "2023-11-27T15:58:37Z",
            "published": "2023-11-27T15:58:37Z",
            "summary": "In the last few years, there has been significant progress in the development\nof machine learning methods tailored to astrophysics and cosmology. Among the\nvarious methods that have been developed, there is one that allows to obtain a\nbundle of solutions of differential systems without the need of using\ntraditional numerical solvers. We have recently applied this to the\ncosmological scenario and showed that in some cases the computational times of\nthe inference process can be reduced. In this paper, we present an improvement\nto the neural network bundle method that results in a significant reduction of\nthe computational times of the statistical analysis. The novelty of the method\nconsists in the use of the neural network bundle method to calculate the\nluminosity distance of type Ia supernovae, which is usually computed through an\nintegral with numerical methods. In this work, we have applied this improvement\nto the Starobinsky $f(R)$ model, which is more difficult to integrate than the\n$f(R)$ models analyzed in our previous work. We performed a statistical\nanalysis with data from type Ia supernovae of the Pantheon+ compilation and\ncosmic chronometers to estimate the values of the free parameters of the\nStarobinsky model. We show that the statistical analyses carried out with our\nnew method require lower computational times than the ones performed with both\nthe numerical and the neural network method from our previous work. This\nreduction in time is more significant in the case of a difficult computational\nproblem such as the one we address in this work.",
            "author": [
                "Augusto T. Chantada",
                "Susana J. Landau",
                "Pavlos Protopapas",
                "Claudia G. Sc\u00f3ccola",
                "Cecilia Garraffo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15955v1",
                "http://arxiv.org/pdf/2311.15955v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "gr-qc",
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15954v1",
            "title": "A Quantitative Approach to Understand Self-Supervised Models as\n  Cross-lingual Feature Extractors",
            "updated": "2023-11-27T15:58:28Z",
            "published": "2023-11-27T15:58:28Z",
            "summary": "In this work, we study the features extracted by English self-supervised\nlearning (SSL) models in cross-lingual contexts and propose a new metric to\npredict the quality of feature representations. Using automatic speech\nrecognition (ASR) as a downstream task, we analyze the effect of model size,\ntraining objectives, and model architecture on the models' performance as a\nfeature extractor for a set of topologically diverse corpora. We develop a\nnovel metric, the Phonetic-Syntax Ratio (PSR), to measure the phonetic and\nsynthetic information in the extracted representations using deep generalized\ncanonical correlation analysis. Results show the contrastive loss in the\nwav2vec2.0 objective facilitates more effective cross-lingual feature\nextraction. There is a positive correlation between PSR scores and ASR\nperformance, suggesting that phonetic information extracted by monolingual SSL\nmodels can be used for downstream tasks in cross-lingual settings. The proposed\nmetric is an effective indicator of the quality of the representations and can\nbe useful for model selection.",
            "author": [
                "Shuyue Stella Li",
                "Beining Xu",
                "Xiangyu Zhang",
                "Hexin Liu",
                "Wenhan Chao",
                "Leibny Paola Garcia"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15954v1",
                "http://arxiv.org/pdf/2311.15954v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15951v2",
            "title": "Replay across Experiments: A Natural Extension of Off-Policy RL",
            "updated": "2023-11-28T15:18:43Z",
            "published": "2023-11-27T15:57:11Z",
            "summary": "Replaying data is a principal mechanism underlying the stability and data\nefficiency of off-policy reinforcement learning (RL). We present an effective\nyet simple framework to extend the use of replays across multiple experiments,\nminimally adapting the RL workflow for sizeable improvements in controller\nperformance and research iteration times. At its core, Replay Across\nExperiments (RaE) involves reusing experience from previous experiments to\nimprove exploration and bootstrap learning while reducing required changes to a\nminimum in comparison to prior work. We empirically show benefits across a\nnumber of RL algorithms and challenging control domains spanning both\nlocomotion and manipulation, including hard exploration tasks from egocentric\nvision. Through comprehensive ablations, we demonstrate robustness to the\nquality and amount of data available and various hyperparameter choices.\nFinally, we discuss how our approach can be applied more broadly across\nresearch life cycles and can increase resilience by reloading data across\nrandom seeds or hyperparameter variations.",
            "author": [
                "Dhruva Tirumala",
                "Thomas Lampe",
                "Jose Enrique Chen",
                "Tuomas Haarnoja",
                "Sandy Huang",
                "Guy Lever",
                "Ben Moran",
                "Tim Hertweck",
                "Leonard Hasenclever",
                "Martin Riedmiller",
                "Nicolas Heess",
                "Markus Wulfmeier"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15951v2",
                "http://arxiv.org/pdf/2311.15951v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15950v1",
            "title": "Auto-CsiNet: Scenario-customized Automatic Neural Network Architecture\n  Generation for Massive MIMO CSI Feedback",
            "updated": "2023-11-27T15:56:58Z",
            "published": "2023-11-27T15:56:58Z",
            "summary": "Deep learning has revolutionized the design of the channel state information\n(CSI) feedback module in wireless communications. However, designing the\noptimal neural network (NN) architecture for CSI feedback can be a laborious\nand time-consuming process. Manual design can be prohibitively expensive for\ncustomizing NNs to different scenarios. This paper proposes using neural\narchitecture search (NAS) to automate the generation of scenario-customized CSI\nfeedback NN architectures, thereby maximizing the potential of deep learning in\nexclusive environments. By employing automated machine learning and\ngradient-descent-based NAS, an efficient and cost-effective architecture design\nprocess is achieved. The proposed approach leverages implicit scene knowledge,\nintegrating it into the scenario customization process in a data-driven manner,\nand fully exploits the potential of deep learning for each specific scenario.\nTo address the issue of excessive search, early stopping and elastic selection\nmechanisms are employed, enhancing the efficiency of the proposed scheme. The\nexperimental results demonstrate that the automatically generated architecture,\nknown as Auto-CsiNet, outperforms manually-designed models in both\nreconstruction performance (achieving approximately a 14% improvement) and\ncomplexity (reducing it by approximately 50%). Furthermore, the paper analyzes\nthe impact of the scenario on the NN architecture and its capacity.",
            "author": [
                "Xiangyi Li",
                "Jiajia Guo",
                "Chao-Kai Wen",
                "Shi Jin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15950v1",
                "http://arxiv.org/pdf/2311.15950v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.AI",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15947v1",
            "title": "GloNets: Globally Connected Neural Networks",
            "updated": "2023-11-27T15:54:20Z",
            "published": "2023-11-27T15:54:20Z",
            "summary": "Deep learning architectures suffer from depth-related performance\ndegradation, limiting the effective depth of neural networks. Approaches like\nResNet are able to mitigate this, but they do not completely eliminate the\nproblem. We introduce Globally Connected Neural Networks (GloNet), a novel\narchitecture overcoming depth-related issues, designed to be superimposed on\nany model, enhancing its depth without increasing complexity or reducing\nperformance. With GloNet, the network's head uniformly receives information\nfrom all parts of the network, regardless of their level of abstraction. This\nenables GloNet to self-regulate information flow during training, reducing the\ninfluence of less effective deeper layers, and allowing for stable training\nirrespective of network depth. This paper details GloNet's design, its\ntheoretical basis, and a comparison with existing similar architectures.\nExperiments show GloNet's self-regulation ability and resilience to\ndepth-related learning challenges, like performance degradation. Our findings\nsuggest GloNet as a strong alternative to traditional architectures like\nResNets.",
            "author": [
                "Antonio Di Cecco",
                "Carlo Metta",
                "Marco Fantozzi",
                "Francesco Morandin",
                "Maurizio Parton"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15947v1",
                "http://arxiv.org/pdf/2311.15947v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15946v1",
            "title": "Leveraging deep active learning to identify low-resource mobility\n  functioning information in public clinical notes",
            "updated": "2023-11-27T15:53:11Z",
            "published": "2023-11-27T15:53:11Z",
            "summary": "Function is increasingly recognized as an important indicator of whole-person\nhealth, although it receives little attention in clinical natural language\nprocessing research. We introduce the first public annotated dataset\nspecifically on the Mobility domain of the International Classification of\nFunctioning, Disability and Health (ICF), aiming to facilitate automatic\nextraction and analysis of functioning information from free-text clinical\nnotes. We utilize the National NLP Clinical Challenges (n2c2) research dataset\nto construct a pool of candidate sentences using keyword expansion. Our active\nlearning approach, using query-by-committee sampling weighted by density\nrepresentativeness, selects informative sentences for human annotation. We\ntrain BERT and CRF models, and use predictions from these models to guide the\nselection of new sentences for subsequent annotation iterations. Our final\ndataset consists of 4,265 sentences with a total of 11,784 entities, including\n5,511 Action entities, 5,328 Mobility entities, 306 Assistance entities, and\n639 Quantification entities. The inter-annotator agreement (IAA), averaged over\nall entity types, is 0.72 for exact matching and 0.91 for partial matching. We\nalso train and evaluate common BERT models and state-of-the-art Nested NER\nmodels. The best F1 scores are 0.84 for Action, 0.7 for Mobility, 0.62 for\nAssistance, and 0.71 for Quantification. Empirical results demonstrate\npromising potential of NER models to accurately extract mobility functioning\ninformation from clinical text. The public availability of our annotated\ndataset will facilitate further research to comprehensively capture functioning\ninformation in electronic health records (EHRs).",
            "author": [
                "Tuan-Dung Le",
                "Zhuqi Miao",
                "Samuel Alvarado",
                "Brittany Smith",
                "William Paiva",
                "Thanh Thieu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15946v1",
                "http://arxiv.org/pdf/2311.15946v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15945v1",
            "title": "Over-Squashing in Riemannian Graph Neural Networks",
            "updated": "2023-11-27T15:51:07Z",
            "published": "2023-11-27T15:51:07Z",
            "summary": "Most graph neural networks (GNNs) are prone to the phenomenon of\nover-squashing in which node features become insensitive to information from\ndistant nodes in the graph. Recent works have shown that the topology of the\ngraph has the greatest impact on over-squashing, suggesting graph rewiring\napproaches as a suitable solution. In this work, we explore whether\nover-squashing can be mitigated through the embedding space of the GNN. In\nparticular, we consider the generalization of Hyperbolic GNNs (HGNNs) to\nRiemannian manifolds of variable curvature in which the geometry of the\nembedding space is faithful to the graph's topology. We derive bounds on the\nsensitivity of the node features in these Riemannian GNNs as the number of\nlayers increases, which yield promising theoretical and empirical results for\nalleviating over-squashing in graphs with negative curvature.",
            "author": [
                "Julia Balla"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15945v1",
                "http://arxiv.org/pdf/2311.15945v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15940v2",
            "title": "Physics-informed neural networks for transformed geometries and\n  manifolds",
            "updated": "2023-11-29T15:46:23Z",
            "published": "2023-11-27T15:47:33Z",
            "summary": "Physics-informed neural networks (PINNs) effectively embed physical\nprinciples into machine learning, but often struggle with complex or\nalternating geometries. We propose a novel method for integrating geometric\ntransformations within PINNs to robustly accommodate geometric variations. Our\nmethod incorporates a diffeomorphism as a mapping of a reference domain and\nadapts the derivative computation of the physics-informed loss function. This\ngeneralizes the applicability of PINNs not only to smoothly deformed domains,\nbut also to lower-dimensional manifolds and allows for direct shape\noptimization while training the network. We demonstrate the effectivity of our\napproach on several problems: (i) Eikonal equation on Archimedean spiral, (ii)\nPoisson problem on surface manifold, (iii) Incompressible Stokes flow in\ndeformed tube, and (iv) Shape optimization with Laplace operator. Through these\nexamples, we demonstrate the enhanced flexibility over traditional PINNs,\nespecially under geometric variations. The proposed framework presents an\noutlook for training deep neural operators over parametrized geometries, paving\nthe way for advanced modeling with PDEs on complex geometries in science and\nengineering.",
            "author": [
                "Samuel Burbulla"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15940v2",
                "http://arxiv.org/pdf/2311.15940v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15939v1",
            "title": "Unleashing the Power of Prompt-driven Nucleus Instance Segmentation",
            "updated": "2023-11-27T15:46:47Z",
            "published": "2023-11-27T15:46:47Z",
            "summary": "Nuclear instance segmentation in histology images is crucial for a broad\nspectrum of clinical applications. Current prevailing nuclear instance\nsegmentation algorithms rely on regression of nuclei contours, distance maps,\nwatershed markers or a proxy nuclear representation of star-convex polygons.\nConsequently, these methods necessitate sophisticated post-processing\noperations to distinguish nuclei instances, which are commonly acknowledged to\nbe error-prone and parameter-sensitive. Recently, the segment anything model\n(SAM) has earned attracted huge attention within the domain of medical image\nsegmentation due to its impressive generalization ability and promptable\nproperty. Nevertheless, its potential on nuclear instance segmentation remains\nlargely underexplored. In this paper, we present a novel prompt-driven\nframework that consists of a point prompter and a SAM for automatic nuclei\ninstance segmentation. Specifically, the prompter learns to generate a unique\npoint prompt for each nucleus while the SAM is fine tuned to output the\ncorresponding mask of the cued nucleus. Furthermore, we propose to add adjacent\nnuclei as negative prompts to promote the model's ability to recognize\noverlapping nuclei. Without bells and whistles, our proposed method sets a new\nstate-of-the-art performance on three challenging benchmarks. Our code is\navailable at\n\\textcolor{magenta}{\\url{https://github.com/windygoo/PromptNucSeg}} .",
            "author": [
                "Zhongyi Shui",
                "Yunlong Zhang",
                "Kai Yao",
                "Chenglu Zhu",
                "Yuxuan Sun",
                "Lin Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15939v1",
                "http://arxiv.org/pdf/2311.15939v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15936v3",
            "title": "Towards Responsible Governance of Biological Design Tools",
            "updated": "2023-11-30T11:54:38Z",
            "published": "2023-11-27T15:45:02Z",
            "summary": "Recent advancements in generative machine learning have enabled rapid\nprogress in biological design tools (BDTs) such as protein structure and\nsequence prediction models. The unprecedented predictive accuracy and novel\ndesign capabilities of BDTs present new and significant dual-use risks. For\nexample, their predictive accuracy allows biological agents, whether vaccines\nor pathogens, to be developed more quickly, while the design capabilities could\nbe used to discover drugs or evade DNA screening techniques. Similar to other\ndual-use AI systems, BDTs present a wicked problem: how can regulators uphold\npublic safety without stifling innovation? We highlight how current regulatory\nproposals that are primarily tailored toward large language models may be less\neffective for BDTs, which require fewer computational resources to train and\nare often developed in an open-source manner. We propose a range of measures to\nmitigate the risk that BDTs are misused, across the areas of responsible\ndevelopment, risk assessment, transparency, access management, cybersecurity,\nand investing in resilience. Implementing such measures will require close\ncoordination between developers and governments.",
            "author": [
                "Richard Moulange",
                "Max Langenkamp",
                "Tessa Alexanian",
                "Samuel Curtis",
                "Morgan Livingston"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15936v3",
                "http://arxiv.org/pdf/2311.15936v3"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15930v1",
            "title": "WorldSense: A Synthetic Benchmark for Grounded Reasoning in Large\n  Language Models",
            "updated": "2023-11-27T15:38:17Z",
            "published": "2023-11-27T15:38:17Z",
            "summary": "We propose WorldSense, a benchmark designed to assess the extent to which\nLLMs are consistently able to sustain tacit world models, by testing how they\ndraw simple inferences from descriptions of simple arrangements of entities.\nWorldsense is a synthetic benchmark with three problem types, each with their\nown trivial control, which explicitly avoids bias by decorrelating the abstract\nstructure of problems from the vocabulary and expressions, and by decorrelating\nall problem subparts with the correct response. We run our benchmark on three\nstate-of-the-art chat-LLMs (GPT3.5, GPT4 and Llama2-chat) and show that these\nmodels make errors even with as few as three objects. Furthermore, they have\nquite heavy response biases, preferring certain responses irrespective of the\nquestion. Errors persist even with chain-of-thought prompting and in-context\nlearning. Lastly, we show that while finetuning on similar problems does result\nin substantial improvements -- within- and out-of-distribution -- the finetuned\nmodels do not generalise beyond a constraint problem space.",
            "author": [
                "Youssef Benchekroun",
                "Megi Dervishi",
                "Mark Ibrahim",
                "Jean-Baptiste Gaya",
                "Xavier Martinet",
                "Gr\u00e9goire Mialon",
                "Thomas Scialom",
                "Emmanuel Dupoux",
                "Dieuwke Hupkes",
                "Pascal Vincent"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15930v1",
                "http://arxiv.org/pdf/2311.15930v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.03727v1",
            "title": "Content-Localization based System for Analyzing Sentiment and Hate\n  Behaviors in Low-Resource Dialectal Arabic: English to Levantine and Gulf",
            "updated": "2023-11-27T15:37:33Z",
            "published": "2023-11-27T15:37:33Z",
            "summary": "Even though online social movements can quickly become viral on social media,\nlanguages can be a barrier to timely monitoring and analyzing the underlying\nonline social behaviors (OSB). This is especially true for under-resourced\nlanguages on social media like dialectal Arabic; the primary language used by\nArabs on social media. Therefore, it is crucial to provide solutions to\nefficiently exploit resources from high-resourced languages to solve\nlanguage-dependent OSB analysis in under-resourced languages. This paper\nproposes to localize content of resources in high-resourced languages into\nunder-resourced Arabic dialects. Content localization goes beyond content\ntranslation that converts text from one language to another; content\nlocalization adapts culture, language nuances and regional preferences from one\nlanguage to a specific language/dialect. Automating understanding of the\nnatural and familiar day-to-day expressions in different regions, is the key to\nachieve a wider analysis of OSB especially for smart cities. In this paper, we\nutilize content-localization based neural machine translation to develop\nsentiment and hate classifiers for two low-resourced Arabic dialects: Levantine\nand Gulf. Not only this but we also leverage unsupervised learning to\nfacilitate the analysis of sentiment and hate predictions by inferring hidden\ntopics from the corresponding data and providing coherent interpretations of\nthose topics in their native language/dialects. The experimental evaluations\nand proof-of-concept COVID-19 case study on real data have validated the\neffectiveness of our proposed system in precisely distinguishing sentiments and\naccurately identifying hate content in both Levantine and Gulf Arabic dialects.\nOur findings shed light on the importance of considering the unique nature of\ndialects within the same language and ignoring the dialectal aspect would lead\nto misleading analysis.",
            "author": [
                "Fatimah Alzamzami",
                "Abdulmotaleb El Saddik"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03727v1",
                "http://arxiv.org/pdf/2312.03727v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15925v1",
            "title": "Reinforcement Learning for Wildfire Mitigation in Simulated Disaster\n  Environments",
            "updated": "2023-11-27T15:37:05Z",
            "published": "2023-11-27T15:37:05Z",
            "summary": "Climate change has resulted in a year over year increase in adverse weather\nand weather conditions which contribute to increasingly severe fire seasons.\nWithout effective mitigation, these fires pose a threat to life, property,\necology, cultural heritage, and critical infrastructure. To better prepare for\nand react to the increasing threat of wildfires, more accurate fire modelers\nand mitigation responses are necessary. In this paper, we introduce SimFire, a\nversatile wildland fire projection simulator designed to generate realistic\nwildfire scenarios, and SimHarness, a modular agent-based machine learning\nwrapper capable of automatically generating land management strategies within\nSimFire to reduce the overall damage to the area. Together, this publicly\navailable system allows researchers and practitioners the ability to emulate\nand assess the effectiveness of firefighter interventions and formulate\nstrategic plans that prioritize value preservation and resource allocation\noptimization. The repositories are available for download at\nhttps://github.com/mitrefireline.",
            "author": [
                "Alexander Tapley",
                "Marissa Dotter",
                "Michael Doyle",
                "Aidan Fennelly",
                "Dhanuj Gandikota",
                "Savanna Smith",
                "Michael Threet",
                "Tim Welsh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15925v1",
                "http://arxiv.org/pdf/2311.15925v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.MA",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15924v1",
            "title": "Diagnosis driven Anomaly Detection for CPS",
            "updated": "2023-11-27T15:34:40Z",
            "published": "2023-11-27T15:34:40Z",
            "summary": "In Cyber-Physical Systems (CPS) research, anomaly detection (detecting\nabnormal behavior) and diagnosis (identifying the underlying root cause) are\noften treated as distinct, isolated tasks. However, diagnosis algorithms\nrequire symptoms, i.e. temporally and spatially isolated anomalies, as input.\nThus, anomaly detection and diagnosis must be developed together to provide a\nholistic solution for diagnosis in CPS. We therefore propose a method for\nutilizing deep learning-based anomaly detection to generate inputs for\nConsistency-Based Diagnosis (CBD). We evaluate our approach on a simulated and\na real-world CPS dataset, where our model demonstrates strong performance\nrelative to other state-of-the-art models.",
            "author": [
                "Henrik S. Steude",
                "Lukas Moddemann",
                "Alexander Diedrich",
                "Jonas Ehrhardt",
                "Oliver Niggemann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15924v1",
                "http://arxiv.org/pdf/2311.15924v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16207v1",
            "title": "The Graph Convolutional Network with Multi-representation Alignment for\n  Drug Synergy Prediction",
            "updated": "2023-11-27T15:34:14Z",
            "published": "2023-11-27T15:34:14Z",
            "summary": "Drug combination refers to the use of two or more drugs to treat a specific\ndisease at the same time. It is currently the mainstream way to treat complex\ndiseases. Compared with single drugs, drug combinations have better efficacy\nand can better inhibit toxicity and drug resistance. The computational model\nbased on deep learning concatenates the representation of multiple drugs and\nthe corresponding cell line feature as input, and the output is whether the\ndrug combination can have an inhibitory effect on the cell line. However, this\nstrategy of concatenating multiple representations has the following defects:\nthe alignment of drug representation and cell line representation is ignored,\nresulting in the synergistic relationship not being reflected positionally in\nthe embedding space. Moreover, the alignment measurement function in deep\nlearning cannot be suitable for drug synergy prediction tasks due to\ndifferences in input types. Therefore, in this work, we propose a graph\nconvolutional network with multi-representation alignment (GCNMRA) for\npredicting drug synergy. In the GCNMRA model, we designed a\nmulti-representation alignment function suitable for the drug synergy\nprediction task so that the positional relationship between drug\nrepresentations and cell line representation is reflected in the embedding\nspace. In addition, the vector modulus of drug representations and cell line\nrepresentation is considered to improve the accuracy of calculation results and\naccelerate model convergence. Finally, many relevant experiments were run on\nmultiple drug synergy datasets to verify the effectiveness of the above\ninnovative elements and the excellence of the GCNMRA model.",
            "author": [
                "Xinxing Yang",
                "Genke Yang",
                "Jian Chu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16207v1",
                "http://arxiv.org/pdf/2311.16207v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15923v1",
            "title": "SEINE: SEgment-based Indexing for NEural information retrieval",
            "updated": "2023-11-27T15:32:52Z",
            "published": "2023-11-27T15:32:52Z",
            "summary": "Many early neural Information Retrieval (NeurIR) methods are re-rankers that\nrely on a traditional first-stage retriever due to expensive query time\ncomputations. Recently, representation-based retrievers have gained much\nattention, which learns query representation and document representation\nseparately, making it possible to pre-compute document representations offline\nand reduce the workload at query time. Both dense and sparse\nrepresentation-based retrievers have been explored. However, these methods\nfocus on finding the representation that best represents a text (aka metric\nlearning) and the actual retrieval function that is responsible for similarity\nmatching between query and document is kept at a minimum by using dot product.\nOne drawback is that unlike traditional term-level inverted index, the index\nformed by these embeddings cannot be easily re-used by another retrieval\nmethod. Another drawback is that keeping the interaction at minimum hurts\nretrieval effectiveness. On the contrary, interaction-based retrievers are\nknown for their better retrieval effectiveness. In this paper, we propose a\nnovel SEgment-based Neural Indexing method, SEINE, which provides a general\nindexing framework that can flexibly support a variety of interaction-based\nneural retrieval methods. We emphasize on a careful decomposition of common\ncomponents in existing neural retrieval methods and propose to use\nsegment-level inverted index to store the atomic query-document interaction\nvalues. Experiments on LETOR MQ2007 and MQ2008 datasets show that our indexing\nmethod can accelerate multiple neural retrieval methods up to 28-times faster\nwithout sacrificing much effectiveness.",
            "author": [
                "Sibo Dong",
                "Justin Goldstein",
                "Grace Hui Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15923v1",
                "http://arxiv.org/pdf/2311.15923v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15921v1",
            "title": "Measurement of associated $J/\u03c8$-$\u03c8(2S)$ production cross-section\n  in $pp$ collisions at $\\sqrt{s}=13$ TeV",
            "updated": "2023-11-27T15:30:38Z",
            "published": "2023-11-27T15:30:38Z",
            "summary": "The cross-section of associated $J/\\psi$-$\\psi(2S)$ production in\nproton-proton collisions at a centre-of-mass energy of $\\sqrt{s}=13$ TeV is\nmeasured using a data sample corresponding to an integrated luminosity of 4.2\nfb$^{-1}$, collected by the LHCb experiment. The measurement is performed for\nboth $J/\\psi$ and $\\psi(2S)$ mesons having transverse momentum\n$p_{\\text{T}}<14$ GeV/$c$ and rapidity $2.0<y<4.5$, assuming negligible\npolarisation of the $J/\\psi$ and $\\psi(2S)$ mesons. The production\ncross-section is measured to be $4.5\\pm0.7\\pm0.3$ nb, where the first\nuncertainty is statistical and the second systematic. The differential\ncross-sections are measured as functions of several kinematic variables of the\n$J/\\psi$-$\\psi(2S)$ candidates. The results are combined with a measurement of\n$J/\\psi$-$J/\\psi$ production, giving a cross-section ratio between\n$J/\\psi$-$\\psi(2S)$ and $J/\\psi$-$J/\\psi$ production of\n$0.274\\pm0.044\\pm0.008$, where the first uncertainty is statistical and the\nsecond systematic.",
            "author": [
                "LHCb collaboration",
                "R. Aaij",
                "A. S. W. Abdelmotteleb",
                "C. Abellan Beteta",
                "F. Abudin\u00e9n",
                "T. Ackernley",
                "B. Adeva",
                "M. Adinolfi",
                "P. Adlarson",
                "H. Afsharnia",
                "C. Agapopoulou",
                "C. A. Aidala",
                "Z. Ajaltouni",
                "S. Akar",
                "K. Akiba",
                "P. Albicocco",
                "J. Albrecht",
                "F. Alessio",
                "M. Alexander",
                "A. Alfonso Albero",
                "Z. Aliouche",
                "P. Alvarez Cartelle",
                "R. Amalric",
                "S. Amato",
                "J. L. Amey",
                "Y. Amhis",
                "L. An",
                "L. Anderlini",
                "M. Andersson",
                "A. Andreianov",
                "P. Andreola",
                "M. Andreotti",
                "D. Andreou",
                "A. Anelli",
                "D. Ao",
                "F. Archilli",
                "S. Arguedas Cuendis",
                "A. Artamonov",
                "M. Artuso",
                "E. Aslanides",
                "M. Atzeni",
                "B. Audurier",
                "D. Bacher",
                "I. Bachiller Perea",
                "S. Bachmann",
                "M. Bachmayer",
                "J. J. Back",
                "A. Bailly-reyre",
                "P. Baladron Rodriguez",
                "V. Balagura",
                "W. Baldini",
                "J. Baptista de Souza Leite",
                "M. Barbetti",
                "I. R. Barbosa",
                "R. J. Barlow",
                "S. Barsuk",
                "W. Barter",
                "M. Bartolini",
                "F. Baryshnikov",
                "J. M. Basels",
                "G. Bassi",
                "B. Batsukh",
                "A. Battig",
                "A. Bay",
                "A. Beck",
                "M. Becker",
                "F. Bedeschi",
                "I. B. Bediaga",
                "A. Beiter",
                "S. Belin",
                "V. Bellee",
                "K. Belous",
                "I. Belov",
                "I. Belyaev",
                "G. Benane",
                "G. Bencivenni",
                "E. Ben-Haim",
                "A. Berezhnoy",
                "R. Bernet",
                "S. Bernet Andres",
                "H. C. Bernstein",
                "C. Bertella",
                "A. Bertolin",
                "C. Betancourt",
                "F. Betti",
                "J. Bex",
                "Ia. Bezshyiko",
                "J. Bhom",
                "M. S. Bieker",
                "N. V. Biesuz",
                "P. Billoir",
                "A. Biolchini",
                "M. Birch",
                "F. C. R. Bishop",
                "A. Bitadze",
                "A. Bizzeti",
                "M. P. Blago",
                "T. Blake",
                "F. Blanc",
                "J. E. Blank",
                "S. Blusk",
                "D. Bobulska",
                "V. Bocharnikov",
                "J. A. Boelhauve",
                "O. Boente Garcia",
                "T. Boettcher",
                "A. Bohare",
                "A. Boldyrev",
                "C. S. Bolognani",
                "R. Bolzonella",
                "N. Bondar",
                "F. Borgato",
                "S. Borghi",
                "M. Borsato",
                "J. T. Borsuk",
                "S. A. Bouchiba",
                "T. J. V. Bowcock",
                "A. Boyer",
                "C. Bozzi",
                "M. J. Bradley",
                "S. Braun",
                "A. Brea Rodriguez",
                "N. Breer",
                "J. Brodzicka",
                "A. Brossa Gonzalo",
                "J. Brown",
                "D. Brundu",
                "A. Buonaura",
                "L. Buonincontri",
                "A. T. Burke",
                "C. Burr",
                "A. Bursche",
                "A. Butkevich",
                "J. S. Butter",
                "J. Buytaert",
                "W. Byczynski",
                "S. Cadeddu",
                "H. Cai",
                "R. Calabrese",
                "L. Calefice",
                "S. Cali",
                "M. Calvi",
                "M. Calvo Gomez",
                "J. Cambon Bouzas",
                "P. Campana",
                "D. H. Campora Perez",
                "A. F. Campoverde Quezada",
                "S. Capelli",
                "L. Capriotti",
                "A. Carbone",
                "L. Carcedo Salgado",
                "R. Cardinale",
                "A. Cardini",
                "P. Carniti",
                "L. Carus",
                "A. Casais Vidal",
                "R. Caspary",
                "G. Casse",
                "J. Castro Godinez",
                "M. Cattaneo",
                "G. Cavallero",
                "V. Cavallini",
                "S. Celani",
                "J. Cerasoli",
                "D. Cervenkov",
                "S. Cesare",
                "A. J. Chadwick",
                "I. Chahrour",
                "M. Charles",
                "Ph. Charpentier",
                "C. A. Chavez Barajas",
                "M. Chefdeville",
                "C. Chen",
                "S. Chen",
                "A. Chernov",
                "S. Chernyshenko",
                "V. Chobanova",
                "S. Cholak",
                "M. Chrzaszcz",
                "A. Chubykin",
                "V. Chulikov",
                "P. Ciambrone",
                "M. F. Cicala",
                "X. Cid Vidal",
                "G. Ciezarek",
                "P. Cifra",
                "P. E. L. Clarke",
                "M. Clemencic",
                "H. V. Cliff",
                "J. Closier",
                "J. L. Cobbledick",
                "C. Cocha Toapaxi",
                "V. Coco",
                "J. Cogan",
                "E. Cogneras",
                "L. Cojocariu",
                "P. Collins",
                "T. Colombo",
                "A. Comerma-Montells",
                "L. Congedo",
                "A. Contu",
                "N. Cooke",
                "I. Corredoira",
                "A. Correia",
                "G. Corti",
                "J. J. Cottee Meldrum",
                "B. Couturier",
                "D. C. Craik",
                "M. Cruz Torres",
                "R. Currie",
                "C. L. Da Silva",
                "S. Dadabaev",
                "L. Dai",
                "X. Dai",
                "E. Dall'Occo",
                "J. Dalseno",
                "C. D'Ambrosio",
                "J. Daniel",
                "A. Danilina",
                "P. d'Argent",
                "A. Davidson",
                "J. E. Davies",
                "A. Davis",
                "O. De Aguiar Francisco",
                "C. De Angelis",
                "J. de Boer",
                "K. De Bruyn",
                "S. De Capua",
                "M. De Cian",
                "U. De Freitas Carneiro Da Graca",
                "E. De Lucia",
                "J. M. De Miranda",
                "L. De Paula",
                "M. De Serio",
                "D. De Simone",
                "P. De Simone",
                "F. De Vellis",
                "J. A. de Vries",
                "F. Debernardis",
                "D. Decamp",
                "V. Dedu",
                "L. Del Buono",
                "B. Delaney",
                "H. -P. Dembinski",
                "J. Deng",
                "V. Denysenko",
                "O. Deschamps",
                "F. Dettori",
                "B. Dey",
                "P. Di Nezza",
                "I. Diachkov",
                "S. Didenko",
                "S. Ding",
                "V. Dobishuk",
                "A. D. Docheva",
                "A. Dolmatov",
                "C. Dong",
                "A. M. Donohoe",
                "F. Dordei",
                "A. C. dos Reis",
                "L. Douglas",
                "A. G. Downes",
                "W. Duan",
                "P. Duda",
                "M. W. Dudek",
                "L. Dufour",
                "V. Duk",
                "P. Durante",
                "M. M. Duras",
                "J. M. Durham",
                "D. Dutta",
                "A. Dziurda",
                "A. Dzyuba",
                "S. Easo",
                "E. Eckstein",
                "U. Egede",
                "A. Egorychev",
                "V. Egorychev",
                "C. Eirea Orro",
                "S. Eisenhardt",
                "E. Ejopu",
                "S. Ek-In",
                "L. Eklund",
                "M. Elashri",
                "J. Ellbracht",
                "S. Ely",
                "A. Ene",
                "E. Epple",
                "S. Escher",
                "J. Eschle",
                "S. Esen",
                "T. Evans",
                "F. Fabiano",
                "L. N. Falcao",
                "Y. Fan",
                "B. Fang",
                "L. Fantini",
                "M. Faria",
                "K. Farmer",
                "D. Fazzini",
                "L. Felkowski",
                "M. Feng",
                "M. Feo",
                "M. Fernandez Gomez",
                "A. D. Fernez",
                "F. Ferrari",
                "F. Ferreira Rodrigues",
                "S. Ferreres Sole",
                "M. Ferrillo",
                "M. Ferro-Luzzi",
                "S. Filippov",
                "R. A. Fini",
                "M. Fiorini",
                "M. Firlej",
                "K. M. Fischer",
                "D. S. Fitzgerald",
                "C. Fitzpatrick",
                "T. Fiutowski",
                "F. Fleuret",
                "M. Fontana",
                "F. Fontanelli",
                "L. F. Foreman",
                "R. Forty",
                "D. Foulds-Holt",
                "M. Franco Sevilla",
                "M. Frank",
                "E. Franzoso",
                "G. Frau",
                "C. Frei",
                "D. A. Friday",
                "L. Frontini",
                "J. Fu",
                "Q. Fuehring",
                "Y. Fujii",
                "T. Fulghesu",
                "E. Gabriel",
                "G. Galati",
                "M. D. Galati",
                "A. Gallas Torreira",
                "D. Galli",
                "S. Gambetta",
                "M. Gandelman",
                "P. Gandini",
                "H. Gao",
                "R. Gao",
                "Y. Gao",
                "Y. Gao",
                "Y. Gao",
                "M. Garau",
                "L. M. Garcia Martin",
                "P. Garcia Moreno",
                "J. Garc\u00eda Pardi\u00f1as",
                "B. Garcia Plana",
                "K. G. Garg",
                "L. Garrido",
                "C. Gaspar",
                "R. E. Geertsema",
                "L. L. Gerken",
                "E. Gersabeck",
                "M. Gersabeck",
                "T. Gershon",
                "Z. Ghorbanimoghaddam",
                "L. Giambastiani",
                "F. I. Giasemis",
                "V. Gibson",
                "H. K. Giemza",
                "A. L. Gilman",
                "M. Giovannetti",
                "A. Giovent\u00f9",
                "P. Gironella Gironell",
                "C. Giugliano",
                "M. A. Giza",
                "E. L. Gkougkousis",
                "F. C. Glaser",
                "V. V. Gligorov",
                "C. G\u00f6bel",
                "E. Golobardes",
                "D. Golubkov",
                "A. Golutvin",
                "A. Gomes",
                "S. Gomez Fernandez",
                "F. Goncalves Abrantes",
                "M. Goncerz",
                "G. Gong",
                "J. A. Gooding",
                "I. V. Gorelov",
                "C. Gotti",
                "J. P. Grabowski",
                "L. A. Granado Cardoso",
                "E. Graug\u00e9s",
                "E. Graverini",
                "L. Grazette",
                "G. Graziani",
                "A. T. Grecu",
                "L. M. Greeven",
                "N. A. Grieser",
                "L. Grillo",
                "S. Gromov",
                "C. Gu",
                "M. Guarise",
                "M. Guittiere",
                "V. Guliaeva",
                "P. A. G\u00fcnther",
                "A. -K. Guseinov",
                "E. Gushchin",
                "Y. Guz",
                "T. Gys",
                "T. Hadavizadeh",
                "C. Hadjivasiliou",
                "G. Haefeli",
                "C. Haen",
                "J. Haimberger",
                "M. Hajheidari",
                "T. Halewood-leagas",
                "M. M. Halvorsen",
                "P. M. Hamilton",
                "J. Hammerich",
                "Q. Han",
                "X. Han",
                "S. Hansmann-Menzemer",
                "L. Hao",
                "N. Harnew",
                "T. Harrison",
                "M. Hartmann",
                "C. Hasse",
                "J. He",
                "K. Heijhoff",
                "F. Hemmer",
                "C. Henderson",
                "R. D. L. Henderson",
                "A. M. Hennequin",
                "K. Hennessy",
                "L. Henry",
                "J. Herd",
                "J. Heuel",
                "A. Hicheur",
                "D. Hill",
                "S. E. Hollitt",
                "J. Horswill",
                "R. Hou",
                "Y. Hou",
                "N. Howarth",
                "J. Hu",
                "J. Hu",
                "W. Hu",
                "X. Hu",
                "W. Huang",
                "W. Hulsbergen",
                "R. J. Hunter",
                "M. Hushchyn",
                "D. Hutchcroft",
                "M. Idzik",
                "D. Ilin",
                "P. Ilten",
                "A. Inglessi",
                "A. Iniukhin",
                "A. Ishteev",
                "K. Ivshin",
                "R. Jacobsson",
                "H. Jage",
                "S. J. Jaimes Elles",
                "S. Jakobsen",
                "E. Jans",
                "B. K. Jashal",
                "A. Jawahery",
                "V. Jevtic",
                "E. Jiang",
                "X. Jiang",
                "Y. Jiang",
                "Y. J. Jiang",
                "M. John",
                "D. Johnson",
                "C. R. Jones",
                "T. P. Jones",
                "S. Joshi",
                "B. Jost",
                "N. Jurik",
                "I. Juszczak",
                "D. Kaminaris",
                "S. Kandybei",
                "Y. Kang",
                "M. Karacson",
                "D. Karpenkov",
                "M. Karpov",
                "A. M. Kauniskangas",
                "J. W. Kautz",
                "F. Keizer",
                "D. M. Keller",
                "M. Kenzie",
                "T. Ketel",
                "B. Khanji",
                "A. Kharisova",
                "S. Kholodenko",
                "G. Khreich",
                "T. Kirn",
                "V. S. Kirsebom",
                "O. Kitouni",
                "S. Klaver",
                "N. Kleijne",
                "K. Klimaszewski",
                "M. R. Kmiec",
                "S. Koliiev",
                "L. Kolk",
                "A. Konoplyannikov",
                "P. Kopciewicz",
                "P. Koppenburg",
                "M. Korolev",
                "I. Kostiuk",
                "O. Kot",
                "S. Kotriakhova",
                "A. Kozachuk",
                "P. Kravchenko",
                "L. Kravchuk",
                "M. Kreps",
                "S. Kretzschmar",
                "P. Krokovny",
                "W. Krupa",
                "W. Krzemien",
                "J. Kubat",
                "S. Kubis",
                "W. Kucewicz",
                "M. Kucharczyk",
                "V. Kudryavtsev",
                "E. Kulikova",
                "A. Kupsc",
                "B. K. Kutsenko",
                "D. Lacarrere",
                "G. Lafferty",
                "A. Lai",
                "A. Lampis",
                "D. Lancierini",
                "C. Landesa Gomez",
                "J. J. Lane",
                "R. Lane",
                "C. Langenbruch",
                "J. Langer",
                "O. Lantwin",
                "T. Latham",
                "F. Lazzari",
                "C. Lazzeroni",
                "R. Le Gac",
                "S. H. Lee",
                "R. Lef\u00e8vre",
                "A. Leflat",
                "S. Legotin",
                "M. Lehuraux",
                "O. Leroy",
                "T. Lesiak",
                "B. Leverington",
                "A. Li",
                "H. Li",
                "K. Li",
                "L. Li",
                "P. Li",
                "P. -R. Li",
                "S. Li",
                "T. Li",
                "T. Li",
                "Y. Li",
                "Y. Li",
                "Z. Li",
                "Z. Lian",
                "X. Liang",
                "C. Lin",
                "T. Lin",
                "R. Lindner",
                "V. Lisovskyi",
                "R. Litvinov",
                "G. Liu",
                "H. Liu",
                "K. Liu",
                "Q. Liu",
                "S. Liu",
                "Y. Liu",
                "Y. Liu",
                "Y. L. Liu",
                "A. Lobo Salvia",
                "A. Loi",
                "J. Lomba Castro",
                "T. Long",
                "J. H. Lopes",
                "A. Lopez Huertas",
                "S. L\u00f3pez Soli\u00f1o",
                "G. H. Lovell",
                "C. Lucarelli",
                "D. Lucchesi",
                "S. Luchuk",
                "M. Lucio Martinez",
                "V. Lukashenko",
                "Y. Luo",
                "A. Lupato",
                "E. Luppi",
                "K. Lynch",
                "X. -R. Lyu",
                "G. M. Ma",
                "R. Ma",
                "S. Maccolini",
                "F. Machefert",
                "F. Maciuc",
                "I. Mackay",
                "L. R. Madhan Mohan",
                "M. M. Madurai",
                "A. Maevskiy",
                "D. Magdalinski",
                "D. Maisuzenko",
                "M. W. Majewski",
                "J. J. Malczewski",
                "S. Malde",
                "B. Malecki",
                "L. Malentacca",
                "A. Malinin",
                "T. Maltsev",
                "G. Manca",
                "G. Mancinelli",
                "C. Mancuso",
                "R. Manera Escalero",
                "D. Manuzzi",
                "D. Marangotto",
                "J. F. Marchand",
                "R. Marchevski",
                "U. Marconi",
                "S. Mariani",
                "C. Marin Benito",
                "J. Marks",
                "A. M. Marshall",
                "P. J. Marshall",
                "G. Martelli",
                "G. Martellotti",
                "L. Martinazzoli",
                "M. Martinelli",
                "D. Martinez Santos",
                "F. Martinez Vidal",
                "A. Massafferri",
                "M. Materok",
                "R. Matev",
                "A. Mathad",
                "V. Matiunin",
                "C. Matteuzzi",
                "K. R. Mattioli",
                "A. Mauri",
                "E. Maurice",
                "J. Mauricio",
                "M. Mazurek",
                "M. McCann",
                "L. Mcconnell",
                "T. H. McGrath",
                "N. T. McHugh",
                "A. McNab",
                "R. McNulty",
                "B. Meadows",
                "G. Meier",
                "D. Melnychuk",
                "M. Merk",
                "A. Merli",
                "L. Meyer Garcia",
                "D. Miao",
                "H. Miao",
                "M. Mikhasenko",
                "D. A. Milanes",
                "A. Minotti",
                "E. Minucci",
                "T. Miralles",
                "S. E. Mitchell",
                "B. Mitreska",
                "D. S. Mitzel",
                "A. Modak",
                "A. M\u00f6dden",
                "R. A. Mohammed",
                "R. D. Moise",
                "S. Mokhnenko",
                "T. Momb\u00e4cher",
                "M. Monk",
                "I. A. Monroy",
                "S. Monteil",
                "A. Morcillo Gomez",
                "G. Morello",
                "M. J. Morello",
                "M. P. Morgenthaler",
                "J. Moron",
                "A. B. Morris",
                "A. G. Morris",
                "R. Mountain",
                "H. Mu",
                "Z. M. Mu",
                "E. Muhammad",
                "F. Muheim",
                "M. Mulder",
                "K. M\u00fcller",
                "F. M{\u0169}noz-Rojas",
                "R. Murta",
                "P. Naik",
                "T. Nakada",
                "R. Nandakumar",
                "T. Nanut",
                "I. Nasteva",
                "M. Needham",
                "N. Neri",
                "S. Neubert",
                "N. Neufeld",
                "P. Neustroev",
                "R. Newcombe",
                "J. Nicolini",
                "D. Nicotra",
                "E. M. Niel",
                "N. Nikitin",
                "P. Nogga",
                "N. S. Nolte",
                "C. Normand",
                "J. Novoa Fernandez",
                "G. Nowak",
                "C. Nunez",
                "H. N. Nur",
                "A. Oblakowska-Mucha",
                "V. Obraztsov",
                "T. Oeser",
                "S. Okamura",
                "R. Oldeman",
                "F. Oliva",
                "M. Olocco",
                "C. J. G. Onderwater",
                "R. H. O'Neil",
                "J. M. Otalora Goicochea",
                "T. Ovsiannikova",
                "P. Owen",
                "A. Oyanguren",
                "O. Ozcelik",
                "K. O. Padeken",
                "B. Pagare",
                "P. R. Pais",
                "T. Pajero",
                "A. Palano",
                "M. Palutan",
                "G. Panshin",
                "L. Paolucci",
                "A. Papanestis",
                "M. Pappagallo",
                "L. L. Pappalardo",
                "C. Pappenheimer",
                "C. Parkes",
                "B. Passalacqua",
                "G. Passaleva",
                "D. Passaro",
                "A. Pastore",
                "M. Patel",
                "J. Patoc",
                "C. Patrignani",
                "C. J. Pawley",
                "A. Pellegrino",
                "M. Pepe Altarelli",
                "S. Perazzini",
                "D. Pereima",
                "A. Pereiro Castro",
                "P. Perret",
                "A. Perro",
                "K. Petridis",
                "A. Petrolini",
                "S. Petrucci",
                "H. Pham",
                "L. Pica",
                "M. Piccini",
                "B. Pietrzyk",
                "G. Pietrzyk",
                "D. Pinci",
                "F. Pisani",
                "M. Pizzichemi",
                "V. Placinta",
                "M. Plo Casasus",
                "F. Polci",
                "M. Poli Lener",
                "A. Poluektov",
                "N. Polukhina",
                "I. Polyakov",
                "E. Polycarpo",
                "S. Ponce",
                "D. Popov",
                "S. Poslavskii",
                "K. Prasanth",
                "L. Promberger",
                "C. Prouve",
                "V. Pugatch",
                "V. Puill",
                "G. Punzi",
                "H. R. Qi",
                "W. Qian",
                "N. Qin",
                "S. Qu",
                "R. Quagliani",
                "B. Rachwal",
                "J. H. Rademacker",
                "M. Rama",
                "M. Ram\u00edrez Garc\u00eda",
                "M. Ramos Pernas",
                "M. S. Rangel",
                "F. Ratnikov",
                "G. Raven",
                "M. Rebollo De Miguel",
                "F. Redi",
                "J. Reich",
                "F. Reiss",
                "Z. Ren",
                "P. K. Resmi",
                "R. Ribatti",
                "G. R. Ricart",
                "D. Riccardi",
                "S. Ricciardi",
                "K. Richardson",
                "M. Richardson-Slipper",
                "K. Rinnert",
                "P. Robbe",
                "G. Robertson",
                "E. Rodrigues",
                "E. Rodriguez Fernandez",
                "J. A. Rodriguez Lopez",
                "E. Rodriguez Rodriguez",
                "A. Rogovskiy",
                "D. L. Rolf",
                "A. Rollings",
                "P. Roloff",
                "V. Romanovskiy",
                "M. Romero Lamas",
                "A. Romero Vidal",
                "G. Romolini",
                "F. Ronchetti",
                "M. Rotondo",
                "S. R. Roy",
                "M. S. Rudolph",
                "T. Ruf",
                "M. Ruiz Diaz",
                "R. A. Ruiz Fernandez",
                "J. Ruiz Vidal",
                "A. Ryzhikov",
                "J. Ryzka",
                "J. J. Saborido Silva",
                "R. Sadek",
                "N. Sagidova",
                "N. Sahoo",
                "B. Saitta",
                "M. Salomoni",
                "C. Sanchez Gras",
                "I. Sanderswood",
                "R. Santacesaria",
                "C. Santamarina Rios",
                "M. Santimaria",
                "L. Santoro",
                "E. Santovetti",
                "A. Saputi",
                "D. Saranin",
                "G. Sarpis",
                "M. Sarpis",
                "A. Sarti",
                "C. Satriano",
                "A. Satta",
                "M. Saur",
                "D. Savrina",
                "H. Sazak",
                "L. G. Scantlebury Smead",
                "A. Scarabotto",
                "S. Schael",
                "S. Scherl",
                "A. M. Schertz",
                "M. Schiller",
                "H. Schindler",
                "M. Schmelling",
                "B. Schmidt",
                "S. Schmitt",
                "H. Schmitz",
                "O. Schneider",
                "A. Schopper",
                "N. Schulte",
                "S. Schulte",
                "M. H. Schune",
                "R. Schwemmer",
                "G. Schwering",
                "B. Sciascia",
                "A. Sciuccati",
                "S. Sellam",
                "A. Semennikov",
                "M. Senghi Soares",
                "A. Sergi",
                "N. Serra",
                "L. Sestini",
                "A. Seuthe",
                "Y. Shang",
                "D. M. Shangase",
                "M. Shapkin",
                "I. Shchemerov",
                "L. Shchutska",
                "T. Shears",
                "L. Shekhtman",
                "Z. Shen",
                "S. Sheng",
                "V. Shevchenko",
                "B. Shi",
                "E. B. Shields",
                "Y. Shimizu",
                "E. Shmanin",
                "R. Shorkin",
                "J. D. Shupperd",
                "R. Silva Coutinho",
                "G. Simi",
                "S. Simone",
                "N. Skidmore",
                "R. Skuza",
                "T. Skwarnicki",
                "M. W. Slater",
                "J. C. Smallwood",
                "E. Smith",
                "K. Smith",
                "M. Smith",
                "A. Snoch",
                "L. Soares Lavra",
                "M. D. Sokoloff",
                "F. J. P. Soler",
                "A. Solomin",
                "A. Solovev",
                "I. Solovyev",
                "R. Song",
                "Y. Song",
                "Y. Song",
                "Y. S. Song",
                "F. L. Souza De Almeida",
                "B. Souza De Paula",
                "E. Spadaro Norella",
                "E. Spedicato",
                "J. G. Speer",
                "E. Spiridenkov",
                "P. Spradlin",
                "V. Sriskaran",
                "F. Stagni",
                "M. Stahl",
                "S. Stahl",
                "S. Stanislaus",
                "E. N. Stein",
                "O. Steinkamp",
                "O. Stenyakin",
                "H. Stevens",
                "D. Strekalina",
                "Y. Su",
                "F. Suljik",
                "J. Sun",
                "L. Sun",
                "Y. Sun",
                "P. N. Swallow",
                "K. Swientek",
                "F. Swystun",
                "A. Szabelski",
                "T. Szumlak",
                "M. Szymanski",
                "Y. Tan",
                "S. Taneja",
                "M. D. Tat",
                "A. Terentev",
                "F. Terzuoli",
                "F. Teubert",
                "E. Thomas",
                "D. J. D. Thompson",
                "H. Tilquin",
                "V. Tisserand",
                "S. T'Jampens",
                "M. Tobin",
                "L. Tomassetti",
                "G. Tonani",
                "X. Tong",
                "D. Torres Machado",
                "L. Toscano",
                "D. Y. Tou",
                "C. Trippl",
                "G. Tuci",
                "N. Tuning",
                "L. H. Uecker",
                "A. Ukleja",
                "D. J. Unverzagt",
                "E. Ursov",
                "A. Usachov",
                "A. Ustyuzhanin",
                "U. Uwer",
                "V. Vagnoni",
                "A. Valassi",
                "G. Valenti",
                "N. Valls Canudas",
                "H. Van Hecke",
                "E. van Herwijnen",
                "C. B. Van Hulse",
                "R. Van Laak",
                "M. van Veghel",
                "R. Vazquez Gomez",
                "P. Vazquez Regueiro",
                "C. V\u00e1zquez Sierra",
                "S. Vecchi",
                "J. J. Velthuis",
                "M. Veltri",
                "A. Venkateswaran",
                "M. Vesterinen",
                "D. Vieira",
                "M. Vieites Diaz",
                "X. Vilasis-Cardona",
                "E. Vilella Figueras",
                "A. Villa",
                "P. Vincent",
                "F. C. Volle",
                "D. vom Bruch",
                "V. Vorobyev",
                "N. Voropaev",
                "K. Vos",
                "C. Vrahas",
                "J. Walsh",
                "E. J. Walton",
                "G. Wan",
                "C. Wang",
                "G. Wang",
                "J. Wang",
                "J. Wang",
                "J. Wang",
                "J. Wang",
                "M. Wang",
                "N. W. Wang",
                "R. Wang",
                "X. Wang",
                "X. W. Wang",
                "Y. Wang",
                "Z. Wang",
                "Z. Wang",
                "Z. Wang",
                "J. A. Ward",
                "N. K. Watson",
                "D. Websdale",
                "Y. Wei",
                "B. D. C. Westhenry",
                "D. J. White",
                "M. Whitehead",
                "A. R. Wiederhold",
                "D. Wiedner",
                "G. Wilkinson",
                "M. K. Wilkinson",
                "M. Williams",
                "M. R. J. Williams",
                "R. Williams",
                "F. F. Wilson",
                "W. Wislicki",
                "M. Witek",
                "L. Witola",
                "C. P. Wong",
                "G. Wormser",
                "S. A. Wotton",
                "H. Wu",
                "J. Wu",
                "Y. Wu",
                "K. Wyllie",
                "S. Xian",
                "Z. Xiang",
                "Y. Xie",
                "A. Xu",
                "J. Xu",
                "L. Xu",
                "L. Xu",
                "M. Xu",
                "Z. Xu",
                "Z. Xu",
                "Z. Xu",
                "D. Yang",
                "S. Yang",
                "X. Yang",
                "Y. Yang",
                "Z. Yang",
                "Z. Yang",
                "V. Yeroshenko",
                "H. Yeung",
                "H. Yin",
                "C. Y. Yu",
                "J. Yu",
                "X. Yuan",
                "E. Zaffaroni",
                "M. Zavertyaev",
                "M. Zdybal",
                "M. Zeng",
                "C. Zhang",
                "D. Zhang",
                "J. Zhang",
                "L. Zhang",
                "S. Zhang",
                "S. Zhang",
                "Y. Zhang",
                "Y. Zhang",
                "Y. Z. Zhang",
                "Y. Zhao",
                "A. Zharkova",
                "A. Zhelezov",
                "X. Z. Zheng",
                "Y. Zheng",
                "T. Zhou",
                "X. Zhou",
                "Y. Zhou",
                "V. Zhovkovska",
                "L. Z. Zhu",
                "X. Zhu",
                "X. Zhu",
                "Z. Zhu",
                "V. Zhukov",
                "J. Zhuo",
                "Q. Zou",
                "D. Zuliani",
                "G. Zunica"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15921v1",
                "http://arxiv.org/pdf/2311.15921v1"
            ],
            "primary_category": "hep-ex",
            "category": [
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15920v1",
            "title": "A Fully Data-Driven Approach for Realistic Traffic Signal Control Using\n  Offline Reinforcement Learning",
            "updated": "2023-11-27T15:29:21Z",
            "published": "2023-11-27T15:29:21Z",
            "summary": "The optimization of traffic signal control (TSC) is critical for an efficient\ntransportation system. In recent years, reinforcement learning (RL) techniques\nhave emerged as a popular approach for TSC and show promising results for\nhighly adaptive control. However, existing RL-based methods suffer from notably\npoor real-world applicability and hardly have any successful deployments. The\nreasons for such failures are mostly due to the reliance on over-idealized\ntraffic simulators for policy optimization, as well as using unrealistic\nfine-grained state observations and reward signals that are not directly\nobtainable from real-world sensors. In this paper, we propose a fully\nData-Driven and simulator-free framework for realistic Traffic Signal Control\n(D2TSC). Specifically, we combine well-established traffic flow theory with\nmachine learning to construct a reward inference model to infer the reward\nsignals from coarse-grained traffic data. With the inferred rewards, we further\npropose a sample-efficient offline RL method to enable direct signal control\npolicy learning from historical offline datasets of real-world intersections.\nTo evaluate our approach, we collect historical traffic data from a real-world\nintersection, and develop a highly customized simulation environment that\nstrictly follows real data characteristics. We demonstrate through extensive\nexperiments that our approach achieves superior performance over conventional\nand offline RL baselines, and also enjoys much better real-world applicability.",
            "author": [
                "Jianxiong Li",
                "Shichao Lin",
                "Tianyu Shi",
                "Chujie Tian",
                "Yu Mei",
                "Jian Song",
                "Xianyuan Zhan",
                "Ruimin Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15920v1",
                "http://arxiv.org/pdf/2311.15920v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15912v1",
            "title": "LIFT OFF: LoRaWAN Installation and Fiducial Tracking Operations for the\n  Flightline of the Future",
            "updated": "2023-11-27T15:22:17Z",
            "published": "2023-11-27T15:22:17Z",
            "summary": "Real-time situational awareness for the location of assets is critical to\nensure missions are completed efficiently and requirements are satisfied. In\nmany commercial settings, the application of global positioning system (GPS)\nsensors is appropriate to achieve timely knowledge of the position of people\nand equipment. However, GPS sensors are not appropriate for all situations due\nto flight clearance and operations security concerns. LIFT OFF: LoRaWAN\nInstallation and Fiducial Tracking Operations for the Flightline of the Future\nproposes a hybrid framework solution to achieve real-time situational awareness\nfor people, support equipment, and aircraft positions regardless of the\nenvironment. This framework included a machine-vision component, which involved\nsetting up cameras to detect AprilTag decals that were installed on the sides\nof aircraft. The framework included a geolocation sensor component, which\ninvolved installing GPS sensors on support equipment and helmets. The framework\nalso included creating a long-range wide area network (LoRaWAN) to transfer\ndata and developing a user interface to display the data. The framework was\ntested at Naval Air Station Oceana Flightline, the United States Naval Test\nPilot School, and at Naval Air Warfare Center Aircraft Division Lakehurst. LIFT\nOFF successfully provided a real-time updating map of all tracked assets using\nGPS sensors for people and support equipment and with visual fiducials for\naircraft. The trajectories of the assets were recorded for logistical analysis\nand playback. Future follow-on work is anticipated to apply the technology to\nother environments including carriers and amphibious assault ships in addition\nto the flightline.",
            "author": [
                "Ari Goodman",
                "Ryan O'Shea"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15912v1",
                "http://arxiv.org/pdf/2311.15912v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15906v1",
            "title": "MetaDefa: Meta-learning based on Domain Enhancement and Feature\n  Alignment for Single Domain Generalization",
            "updated": "2023-11-27T15:13:02Z",
            "published": "2023-11-27T15:13:02Z",
            "summary": "The single domain generalization(SDG) based on meta-learning has emerged as\nan effective technique for solving the domain-shift problem. However, the\ninadequate match of data distribution between source and augmented domains and\ndifficult separation of domain-invariant features from domain-related features\nmake SDG model hard to achieve great generalization. Therefore, a novel\nmeta-learning method based on domain enhancement and feature alignment\n(MetaDefa) is proposed to improve the model generalization performance. First,\nthe background substitution and visual corruptions techniques are used to\ngenerate diverse and effective augmented domains. Then, the multi-channel\nfeature alignment module based on class activation maps and class agnostic\nactivation maps is designed to effectively extract adequate transferability\nknowledge. In this module, domain-invariant features can be fully explored by\nfocusing on similar target regions between source and augmented domains feature\nspace and suppressing the feature representation of non-similar target regions.\nExtensive experiments on two publicly available datasets show that MetaDefa has\nsignificant generalization performance advantages in unknown multiple target\ndomains.",
            "author": [
                "Can Sun",
                "Hao Zheng",
                "Zhigang Hu",
                "Liu Yang",
                "Meiguang Zheng",
                "Bo Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15906v1",
                "http://arxiv.org/pdf/2311.15906v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15903v1",
            "title": "Mass reconstruction and noise reduction with cosmic-web environments",
            "updated": "2023-11-27T15:05:55Z",
            "published": "2023-11-27T15:05:55Z",
            "summary": "The clustering of galaxies and their connections to their initial conditions\nis a major means by which we learn about cosmology. However, the stochasticity\nbetween galaxies and their underlying matter field is a major limitation for\nprecise measurements of galaxy clustering. It also hinders accurate mass\nreconstruction for retrieving cosmological information from observations.\nEfforts have been made with an optimal weighting scheme to reduce this\nstochasticity using the mass-dependent clustering of dark matter halos, but its\napplication to observation is challenging due to the difficulties in measuring\nthe mass of halos precisely. Here, we show that this is not optimal. We\ndemonstrate that the cosmic-web environments (voids, sheets, filaments \\&\nknots) of halos provide extra information for reducing stochasticity. Using the\nenvironmental information alone can increase the signal-to-noise of clustering\nby approximately a factor of 3, better than the Poisson level at the scales of\nthe baryon acoustic oscillations. This improvement is comparable to using halo\nmass information alone. The information about the environment and halo mass are\ncomplementary. Their combination increases the signal-to-noise by another\nfactor of 2-3. The information about the cosmic web correlates with other\nproperties of halos, including halo concentrations and tidal forces, thus,\nthese are among the most dominant factors that can help improve the\nreconstruction. We attribute the extra information from the environment and\nsecondary properties of halos primarily to the assembly bias of halos. Our\nfindings open a new avenue for mass reconstruction and noise reduction using\ninformation beyond the halo mass.",
            "author": [
                "Feng Fang",
                "Yan-Chuan Cai",
                "Zhuoyang Li",
                "Shiyu Yue",
                "Weishan Zhu",
                "Longlong Feng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15903v1",
                "http://arxiv.org/pdf/2311.15903v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16206v1",
            "title": "Continual Instruction Tuning for Large Multimodal Models",
            "updated": "2023-11-27T15:04:48Z",
            "published": "2023-11-27T15:04:48Z",
            "summary": "Instruction tuning is now a widely adopted approach to aligning large\nmultimodal models (LMMs) to follow human intent. It unifies the data format of\nvision-language tasks, enabling multi-task joint training. However,\nvision-language tasks are constantly being created in practice. Instead of\nalways re-training LMMs when new tasks arrive, continual learning offers\nflexibility for models to continually and efficiently exploit the evolving\ndata. This work aims to explore the following two questions: 1) Do LMMs still\nsuffer from catastrophic forgetting in continual instruction tuning? 2) Are the\nexisting three classes of continual learning methods still applicable to the\ncontinual instruction tuning of LMMs? An extensive study is conducted to\naddress the above questions. First, we establish the first benchmark in this\nsetting and reveal that catastrophic forgetting is still observed when\ncontinually instruction-tuning LMMs. However, the multi-task joint instruction\ntuning can facilitate the model's continual learning ability and mitigate\nforgetting. Second, we integrate and adapt classic continual learning methods\nto our context, demonstrating the efficacy of data replay and model expansion\nstrategies across diverse scenarios. In contrast, regularization-based methods\nonly perform well on models that have been jointly instruction-tuned on\nmultiple tasks. Third, we delve into the correlation and forgetting dynamics\nbetween vision-language task pairs and propose task-similarity-informed\nregularization and model expansion methods for continual instruction tuning of\nLMMs. Experimental results show that our approach consistently boosts the\nmodel's performance.",
            "author": [
                "Jinghan He",
                "Haiyun Guo",
                "Ming Tang",
                "Jinqiao Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16206v1",
                "http://arxiv.org/pdf/2311.16206v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15894v1",
            "title": "Distributed Attacks over Federated Reinforcement Learning-enabled Cell\n  Sleep Control",
            "updated": "2023-11-27T14:59:43Z",
            "published": "2023-11-27T14:59:43Z",
            "summary": "Federated learning (FL) is particularly useful in wireless networks due to\nits distributed implementation and privacy-preserving features. However, as a\ndistributed learning system, FL can be vulnerable to malicious attacks from\nboth internal and external sources. Our work aims to investigate the attack\nmodels in a FL-enabled wireless networks. Specifically, we consider a cell\nsleep control scenario, and apply federated reinforcement learning to improve\nenergy-efficiency. We design three attacks, namely free rider attacks,\nByzantine data poisoning attacks and backdoor attacks. The simulation results\nshow that the designed attacks can degrade the network performance and lead to\nlower energy-efficiency. Moreover, we also explore possible ways to mitigate\nthe above attacks. We design a defense model called refined-Krum to defend\nagainst attacks by enabling a secure aggregation on the global server. The\nproposed refined- Krum scheme outperforms the existing Krum scheme and can\neffectively prevent wireless networks from malicious attacks, improving the\nsystem energy-efficiency performance.",
            "author": [
                "Han Zhang",
                "Hao Zhou",
                "Medhat Elsayed",
                "Majid Bavand",
                "Raimundas Gaigalas",
                "Yigit Ozcan",
                "Melike Erol-Kantarci"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15894v1",
                "http://arxiv.org/pdf/2311.15894v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15891v1",
            "title": "Sampling a rare protein transition with a hybrid classical-quantum\n  computing algorithm",
            "updated": "2023-11-27T14:58:29Z",
            "published": "2023-11-27T14:58:29Z",
            "summary": "Simulating spontaneous structural rearrangements in macromolecules with\nclassical Molecular Dynamics (MD) is an outstanding challenge. Conventional\nsupercomputers can access time intervals up to tens of $\\mu$s, while many key\nevents occur on exponentially longer time scales. Transition path sampling\ntechniques have the advantage of focusing the computational power on\nbarrier-crossing trajectories, but generating uncorrelated transition paths\nthat explore diverse conformational regions remains an unsolved problem. We\nemploy a path-sampling paradigm combining machine learning (ML) with quantum\ncomputing (QC) to address this issue. We use ML on a classical computer to\nperform a preliminary uncharted exploration of the conformational space. The\ndata set generated in this exploration is then post-processed to obtain a\nnetwork representation of the reactive kinetics.\n  Quantum annealing machines can exploit quantum superposition to encode all\nthe transition pathways in this network in the initial quantum state and ensure\nthe generation of completely uncorrelated transition paths. In particular, we\nresort to the DWAVE quantum computer to perform an all-atom simulation of a\nprotein conformational transition that occurs on the ms timescale. Our results\nmatch those of a special purpose supercomputer designed to perform MD\nsimulations. These results highlight the role of biomolecular simulation as a\nground for applying, testing, and advancing quantum technologies.",
            "author": [
                "Danial Ghamari",
                "Roberto Covino",
                "Pietro Faccioli"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15891v1",
                "http://arxiv.org/pdf/2311.15891v1"
            ],
            "primary_category": "physics.bio-ph",
            "category": [
                "physics.bio-ph",
                "cond-mat.stat-mech",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15890v2",
            "title": "Stability-Informed Initialization of Neural Ordinary Differential\n  Equations",
            "updated": "2023-12-01T07:39:02Z",
            "published": "2023-11-27T14:56:47Z",
            "summary": "This paper addresses the training of Neural Ordinary Differential Equations\n(neural ODEs), and in particular explores the interplay between numerical\nintegration techniques, stability regions, step size, and initialization\ntechniques. It is shown how the choice of integration technique implicitly\nregularizes the learned model, and how the solver's corresponding stability\nregion affects training and prediction performance. From this analysis, a\nstability-informed parameter initialization technique is introduced. The\neffectiveness of the initialization method is displayed across several learning\nbenchmarks and industrial applications.",
            "author": [
                "Theodor Westny",
                "Arman Mohammadi",
                "Daniel Jung",
                "Erik Frisk"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15890v2",
                "http://arxiv.org/pdf/2311.15890v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15887v1",
            "title": "FLASC: A Flare-Sensitive Clustering Algorithm: Extending HDBSCAN* for\n  Detecting Branches in Clusters",
            "updated": "2023-11-27T14:55:16Z",
            "published": "2023-11-27T14:55:16Z",
            "summary": "We present FLASC, an algorithm for flare-sensitive clustering. Our algorithm\nbuilds upon HDBSCAN* -- which provides high-quality density-based clustering\nperformance -- through a post-processing step that differentiates branches\nwithin the detected clusters' manifold, adding a type of pattern that can be\ndiscovered. Two variants of the algorithm are presented, which trade\ncomputational cost for noise robustness. We show that both variants scale\nsimilarly to HDBSCAN* in terms of computational cost and provide stable outputs\nusing synthetic data sets, resulting in an efficient flare-sensitive clustering\nalgorithm. In addition, we demonstrate the algorithm's benefit in data\nexploration over HDBSCAN* clustering on two real-world data sets.",
            "author": [
                "D. M. Bot",
                "J. Peeters",
                "J. Liesenborgs",
                "J. Aerts"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15887v1",
                "http://arxiv.org/pdf/2311.15887v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DB",
                "I.5.3; H.3.3"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15884v1",
            "title": "Elementary Quantum Recursion Schemes That Capture Quantum\n  Polylogarithmic Time Computability of Quantum Functions",
            "updated": "2023-11-27T14:53:45Z",
            "published": "2023-11-27T14:53:45Z",
            "summary": "Quantum computing has been studied over the past four decades based on two\ncomputational models of quantum circuits and quantum Turing machines. To\ncapture quantum polynomial-time computability, a new recursion-theoretic\napproach was taken lately by Yamakami [J. Symb. Logic 80, pp. 1546--1587, 2020]\nby way of recursion schematic definitions, which constitute six initial quantum\nfunctions and three construction schemes of composition, branching, and\nmulti-qubit quantum recursion. By taking a similar approach, we look into\nquantum logarithmic-time computability and further explore the expressing power\nof elementary schemes designed for such quantum computation. In particular, we\nintroduce an elementary form of the quantum recursion, called the fast quantum\nrecursion and formulate EQS (elementary quantum schemes) of \"elementary\"\nquantum functions. This class EQS captures exactly quantum logarithmic-time\ncomputability, represented by BQPOLYLOGTIME. We also demonstrate the separation\nof BQPOLYLOGTIME from NLOGTIME and PPOLYLOGTIME. As a natural extension of EQS,\nwe further consider an algorithmic procedural scheme that implements the\nwell-known divide-and-conquer strategy. This divide-and-conquer scheme helps\ncompute the parity function but the scheme cannot be realized within our system\nEQS.",
            "author": [
                "Tomoyuki Yamakami"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15884v1",
                "http://arxiv.org/pdf/2311.15884v1"
            ],
            "primary_category": "cs.CC",
            "category": [
                "cs.CC",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15878v1",
            "title": "Individualized Treatment Allocations with Distributional Welfare",
            "updated": "2023-11-27T14:51:30Z",
            "published": "2023-11-27T14:51:30Z",
            "summary": "In this paper, we explore optimal treatment allocation policies that target\ndistributional welfare. Most literature on treatment choice has considered\nutilitarian welfare based on the conditional average treatment effect (ATE).\nWhile average welfare is intuitive, it may yield undesirable allocations\nespecially when individuals are heterogeneous (e.g., with outliers) - the very\nreason individualized treatments were introduced in the first place. This\nobservation motivates us to propose an optimal policy that allocates the\ntreatment based on the conditional \\emph{quantile of individual treatment\neffects} (QoTE). Depending on the choice of the quantile probability, this\ncriterion can accommodate a policymaker who is either prudent or negligent. The\nchallenge of identifying the QoTE lies in its requirement for knowledge of the\njoint distribution of the counterfactual outcomes, which is generally hard to\nrecover even with experimental data. Therefore, we introduce minimax optimal\npolicies that are robust to model uncertainty. We then propose a range of\nidentifying assumptions under which we can point or partially identify the\nQoTE. We establish the asymptotic bound on the regret of implementing the\nproposed policies. We consider both stochastic and deterministic rules. In\nsimulations and two empirical applications, we compare optimal decisions based\non the QoTE with decisions based on other criteria.",
            "author": [
                "Yifan Cui",
                "Sukjin Han"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15878v1",
                "http://arxiv.org/pdf/2311.15878v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "econ.EM",
                "math.ST",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15876v1",
            "title": "RO-LLaMA: Generalist LLM for Radiation Oncology via Noise Augmentation\n  and Consistency Regularization",
            "updated": "2023-11-27T14:49:06Z",
            "published": "2023-11-27T14:49:06Z",
            "summary": "Recent advancements in Artificial Intelligence (AI) have profoundly\ninfluenced medical fields, by providing tools to reduce clinical workloads.\nHowever, most AI models are constrained to execute uni-modal tasks, in stark\ncontrast to the comprehensive approaches utilized by medical professionals. To\naddress this, here we present RO-LLaMA, a versatile generalist large language\nmodel (LLM) tailored for the field of radiation oncology. This model seamlessly\ncovers a wide range of the workflow of radiation oncologists, adept at various\ntasks such as clinical report summarization, radiation therapy plan suggestion,\nand plan-guided therapy target volume segmentation. In particular, to maximize\nthe end-to-end performance, we further present a novel Consistency Embedding\nFine-Tuning (CEFTune) technique, which boosts LLM's robustness to additional\nerrors at the intermediates while preserving the capability of handling clean\ninputs, and creatively transform this concept into LLM-driven segmentation\nframework as Consistency Embedding Segmentation (CESEG). Experimental results\non multi-centre cohort sets demonstrate our proposed RO-LLaMA's promising\nperformance for diverse tasks with generalization capabilities.",
            "author": [
                "Kwanyoung Kim",
                "Yujin Oh",
                "Sangjoon Park",
                "Hwa Kyung Byun",
                "Jin Sung Kim",
                "Yong Bae Kim",
                "Jong Chul Ye"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15876v1",
                "http://arxiv.org/pdf/2311.15876v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15875v1",
            "title": "Nodal Hydraulic Head Estimation through Unscented Kalman Filter for\n  Data-driven Leak Localization in Water Networks",
            "updated": "2023-11-27T14:48:37Z",
            "published": "2023-11-27T14:48:37Z",
            "summary": "In this paper, we present a nodal hydraulic head estimation methodology for\nwater distribution networks (WDN) based on an Unscented Kalman Filter (UKF)\nscheme with application to leak localization. The UKF refines an initial\nestimation of the hydraulic state by considering the prediction model, as well\nas available pressure and demand measurements. To this end, it provides\ncustomized prediction and data assimilation steps. Additionally, the method is\nenhanced by dynamically updating the prediction function weight matrices.\nPerformance testing on the Modena benchmark under realistic conditions\ndemonstrates the method's effectiveness in enhancing state estimation and\ndata-driven leak localization.",
            "author": [
                "Luis Romero-Ben",
                "Paul Irofti",
                "Florin Stoican",
                "Vicen\u00e7 Puig"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15875v1",
                "http://arxiv.org/pdf/2311.15875v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.NA",
                "cs.SY",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15868v2",
            "title": "Learning with Errors over Group Rings Constructed by Semi-direct Product",
            "updated": "2023-12-01T15:33:09Z",
            "published": "2023-11-27T14:38:36Z",
            "summary": "The Learning with Errors (LWE) problem has been widely utilized as a\nfoundation for numerous cryptographic tools over the years. In this study, we\nfocus on an algebraic variant of the LWE problem called Group ring LWE\n(GR-LWE). We select group rings (or their direct summands) that underlie\nspecific families of finite groups constructed by taking the semi-direct\nproduct of two cyclic groups. Unlike the Ring-LWE problem described in\n\\cite{lyubashevsky2010ideal}, the multiplication operation in the group rings\nconsidered here is non-commutative. As an extension of Ring-LWE, it maintains\ncomputational hardness and can be potentially applied in many cryptographic\nscenarios. In this paper, we present two polynomial-time quantum reductions.\nFirstly, we provide a quantum reduction from the worst-case shortest\nindependent vectors problem (SIVP) in ideal lattices with polynomial\napproximate factor to the search version of GR-LWE. This reduction requires\nthat the underlying group ring possesses certain mild properties; Secondly, we\npresent another quantum reduction for two types of group rings, where the\nworst-case SIVP problem is directly reduced to the (average-case) decision\nGR-LWE problem. The pseudorandomness of GR-LWE samples guaranteed by this\nreduction can be consequently leveraged to construct semantically secure\npublic-key cryptosystems.",
            "author": [
                "Jiaqi Liu",
                "Fang-Wei Fu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15868v2",
                "http://arxiv.org/pdf/2311.15868v2"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15865v1",
            "title": "A precise symbolic emulator of the linear matter power spectrum",
            "updated": "2023-11-27T14:33:21Z",
            "published": "2023-11-27T14:33:21Z",
            "summary": "Computing the matter power spectrum, $P(k)$, as a function of cosmological\nparameters can be prohibitively slow in cosmological analyses, hence emulating\nthis calculation is desirable. Previous analytic approximations are\ninsufficiently accurate for modern applications, so black-box, uninterpretable\nemulators are often used. We utilise an efficient genetic programming based\nsymbolic regression framework to explore the space of potential mathematical\nexpressions which can approximate the power spectrum and $\\sigma_8$. We learn\nthe ratio between an existing low-accuracy fitting function for $P(k)$ and that\nobtained by solving the Boltzmann equations and thus still incorporate the\nphysics which motivated this earlier approximation. We obtain an analytic\napproximation to the linear power spectrum with a root mean squared fractional\nerror of 0.2% between $k = 9\\times10^{-3} - 9 \\, h{\\rm \\, Mpc^{-1}}$ and across\na wide range of cosmological parameters, and we provide physical\ninterpretations for various terms in the expression. We also provide a simple\nanalytic approximation for $\\sigma_8$ with a similar accuracy, with a root mean\nsquared fractional error of just 0.4% when evaluated across the same range of\ncosmologies. This function is easily invertible to obtain $A_{\\rm s}$ as a\nfunction of $\\sigma_8$ and the other cosmological parameters, if preferred. It\nis possible to obtain symbolic approximations to a seemingly complex function\nat a precision required for current and future cosmological analyses without\nresorting to deep-learning techniques, thus avoiding their black-box nature and\nlarge number of parameters. Our emulator will be usable long after the codes on\nwhich numerical approximations are built become outdated.",
            "author": [
                "Deaglan J. Bartlett",
                "Lukas Kammerer",
                "Gabriel Kronberger",
                "Harry Desmond",
                "Pedro G. Ferreira",
                "Benjamin D. Wandelt",
                "Bogdan Burlacu",
                "David Alonso",
                "Matteo Zennaro"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15865v1",
                "http://arxiv.org/pdf/2311.15865v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "astro-ph.IM",
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15858v1",
            "title": "Multi-Agent Reinforcement Learning for Power Control in Wireless\n  Networks via Adaptive Graphs",
            "updated": "2023-11-27T14:25:40Z",
            "published": "2023-11-27T14:25:40Z",
            "summary": "The ever-increasing demand for high-quality and heterogeneous wireless\ncommunication services has driven extensive research on dynamic optimization\nstrategies in wireless networks. Among several possible approaches, multi-agent\ndeep reinforcement learning (MADRL) has emerged as a promising method to\naddress a wide range of complex optimization problems like power control.\nHowever, the seamless application of MADRL to a variety of network optimization\nproblems faces several challenges related to convergence. In this paper, we\npresent the use of graphs as communication-inducing structures among\ndistributed agents as an effective means to mitigate these challenges.\nSpecifically, we harness graph neural networks (GNNs) as neural architectures\nfor policy parameterization to introduce a relational inductive bias in the\ncollective decision-making process. Most importantly, we focus on modeling the\ndynamic interactions among sets of neighboring agents through the introduction\nof innovative methods for defining a graph-induced framework for integrated\ncommunication and learning. Finally, the superior generalization capabilities\nof the proposed methodology to larger networks and to networks with different\nuser categories is verified through simulations.",
            "author": [
                "Lorenzo Mario Amorosa",
                "Marco Skocaj",
                "Roberto Verdone",
                "Deniz G\u00fcnd\u00fcz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15858v1",
                "http://arxiv.org/pdf/2311.15858v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.LG",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15856v1",
            "title": "JSSL: Joint Supervised and Self-supervised Learning for MRI\n  Reconstruction",
            "updated": "2023-11-27T14:23:36Z",
            "published": "2023-11-27T14:23:36Z",
            "summary": "Magnetic Resonance Imaging represents an important diagnostic modality;\nhowever, its inherently slow acquisition process poses challenges in obtaining\nfully sampled k-space data under motion in clinical scenarios such as\nabdominal, cardiac, and prostate imaging. In the absence of fully sampled\nacquisitions, which can serve as ground truth data, training deep learning\nalgorithms in a supervised manner to predict the underlying ground truth image\nbecomes an impossible task. To address this limitation, self-supervised methods\nhave emerged as a viable alternative, leveraging available subsampled k-space\ndata to train deep learning networks for MRI reconstruction. Nevertheless,\nthese self-supervised approaches often fall short when compared to supervised\nmethodologies. In this paper, we introduce JSSL (Joint Supervised and\nSelf-supervised Learning), a novel training approach for deep learning-based\nMRI reconstruction algorithms aimed at enhancing reconstruction quality in\nscenarios where target dataset(s) containing fully sampled k-space measurements\nare unavailable. Our proposed method operates by simultaneously training a\nmodel in a self-supervised learning setting, using subsampled data from the\ntarget dataset(s), and in a supervised learning manner, utilizing data from\nother datasets, referred to as proxy datasets, where fully sampled k-space data\nis accessible. To demonstrate the efficacy of JSSL, we utilized subsampled\nprostate parallel MRI measurements as the target dataset, while employing fully\nsampled brain and knee k-space acquisitions as proxy datasets. Our results\nshowcase a substantial improvement over conventional self-supervised training\nmethods, thereby underscoring the effectiveness of our joint approach. We\nprovide a theoretical motivation for JSSL and establish a practical\n\"rule-of-thumb\" for selecting the most appropriate training approach for deep\nMRI reconstruction.",
            "author": [
                "George Yiasemis",
                "Nikita Moriakov",
                "Clara I. S\u00e1nchez",
                "Jan-Jakob Sonke",
                "Jonas Teuwen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15856v1",
                "http://arxiv.org/pdf/2311.15856v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15854v1",
            "title": "A systematic study comparing hyperparameter optimization engines on\n  tabular data",
            "updated": "2023-11-27T14:21:47Z",
            "published": "2023-11-27T14:21:47Z",
            "summary": "We run an independent comparison of all hyperparameter optimization\n(hyperopt) engines available in the Ray Tune library. We introduce two ways to\nnormalize and aggregate statistics across data sets and models, one rank-based,\nand another one sandwiching the score between the random search score and the\nfull grid search score. This affords us i) to rank the hyperopt engines, ii) to\nmake generalized and statistically significant statements on how much they\nimprove over random search, and iii) to make recommendations on which engine\nshould be used to hyperopt a given learning algorithm. We find that most\nengines beat random search, but that only three of them (HEBO, AX, and\nBlendSearch) clearly stand out. We also found that some engines seem to\nspecialize in hyperopting certain learning algorithms, which makes it tricky to\nuse hyperopt in comparison studies, since the choice of the hyperopt technique\nmay favor some of the models in the comparison.",
            "author": [
                "Balazs Kegl"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15854v1",
                "http://arxiv.org/pdf/2311.15854v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15851v1",
            "title": "Single-Model and Any-Modality for Video Object Tracking",
            "updated": "2023-11-27T14:17:41Z",
            "published": "2023-11-27T14:17:41Z",
            "summary": "In the realm of video object tracking, auxiliary modalities such as depth,\nthermal, or event data have emerged as valuable assets to complement the RGB\ntrackers. In practice, most existing RGB trackers learn a single set of\nparameters to use them across datasets and applications. However, a similar\nsingle-model unification for multi-modality tracking presents several\nchallenges. These challenges stem from the inherent heterogeneity of inputs --\neach with modality-specific representations, the scarcity of multi-modal\ndatasets, and the absence of all the modalities at all times. In this work, we\nintroduce Un-Track, a \\underline{Un}ified Tracker of a single set of parameters\nfor any modality. To handle any modality, our method learns their common latent\nspace through low-rank factorization and reconstruction techniques. More\nimportantly, we use only the RGB-X pairs to learn the common latent space. This\nunique shared representation seamlessly binds all modalities together, enabling\neffective unification and accommodating any missing modality, all within a\nsingle transformer-based architecture and without the need for\nmodality-specific fine-tuning. Our Un-Track achieves +8.1 absolute F-score\ngain, on the DepthTrack dataset, by introducing only +2.14 (over 21.50) GFLOPs\nwith +6.6M (over 93M) parameters, through a simple yet efficient prompting\nstrategy. Extensive comparisons on five benchmark datasets with different\nmodalities show that Un-Track surpasses both SOTA unified trackers and\nmodality-specific finetuned counterparts, validating our effectiveness and\npracticality.",
            "author": [
                "Zongwei Wu",
                "Jilai Zheng",
                "Xiangxuan Ren",
                "Florin-Alexandru Vasluianu",
                "Chao Ma",
                "Danda Pani Paudel",
                "Luc Van Gool",
                "Radu Timofte"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15851v1",
                "http://arxiv.org/pdf/2311.15851v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15847v1",
            "title": "Cell Maps Representation For Lung Adenocarcinoma Growth Patterns\n  Classification In Whole Slide Images",
            "updated": "2023-11-27T14:12:51Z",
            "published": "2023-11-27T14:12:51Z",
            "summary": "Lung adenocarcinoma is a morphologically heterogeneous disease, characterized\nby five primary histologic growth patterns. The quantity of these patterns can\nbe related to tumor behavior and has a significant impact on patient prognosis.\nIn this work, we propose a novel machine learning pipeline capable of\nclassifying tissue tiles into one of the five patterns or as non-tumor, with an\nArea Under the Receiver Operating Characteristic Curve (AUCROC) score of 0.97.\nOur model's strength lies in its comprehensive consideration of cellular\nspatial patterns, where it first generates cell maps from Hematoxylin and Eosin\n(H&E) whole slide images (WSIs), which are then fed into a convolutional neural\nnetwork classification model. Exploiting these cell maps provides the model\nwith robust generalizability to new data, achieving approximately 30% higher\naccuracy on unseen test-sets compared to current state of the art approaches.\nThe insights derived from our model can be used to predict prognosis, enhancing\npatient outcomes.",
            "author": [
                "Arwa Al-Rubaian",
                "Gozde N. Gunesli",
                "Wajd A. Althakfi",
                "Ayesha Azam",
                "Nasir Rajpoot",
                "Shan E Ahmed Raza"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15847v1",
                "http://arxiv.org/pdf/2311.15847v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15846v1",
            "title": "Learning with Noisy Low-Cost MOS for Image Quality Assessment via\n  Dual-Bias Calibration",
            "updated": "2023-11-27T14:11:54Z",
            "published": "2023-11-27T14:11:54Z",
            "summary": "Learning based image quality assessment (IQA) models have obtained impressive\nperformance with the help of reliable subjective quality labels, where mean\nopinion score (MOS) is the most popular choice. However, in view of the\nsubjective bias of individual annotators, the labor-abundant MOS (LA-MOS)\ntypically requires a large collection of opinion scores from multiple\nannotators for each image, which significantly increases the learning cost. In\nthis paper, we aim to learn robust IQA models from low-cost MOS (LC-MOS), which\nonly requires very few opinion scores or even a single opinion score for each\nimage. More specifically, we consider the LC-MOS as the noisy observation of\nLA-MOS and enforce the IQA model learned from LC-MOS to approach the unbiased\nestimation of LA-MOS. In this way, we represent the subjective bias between\nLC-MOS and LA-MOS, and the model bias between IQA predictions learned from\nLC-MOS and LA-MOS (i.e., dual-bias) as two latent variables with unknown\nparameters. By means of the expectation-maximization based alternating\noptimization, we can jointly estimate the parameters of the dual-bias, which\nsuppresses the misleading of LC-MOS via a gated dual-bias calibration (GDBC)\nmodule. To the best of our knowledge, this is the first exploration of robust\nIQA model learning from noisy low-cost labels. Theoretical analysis and\nextensive experiments on four popular IQA datasets show that the proposed\nmethod is robust toward different bias rates and annotation numbers and\nsignificantly outperforms the other learning based IQA models when only LC-MOS\nis available. Furthermore, we also achieve comparable performance with respect\nto the other models learned with LA-MOS.",
            "author": [
                "Lei Wang",
                "Qingbo Wu",
                "Desen Yuan",
                "King Ngi Ngan",
                "Hongliang Li",
                "Fanman Meng",
                "Linfeng Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15846v1",
                "http://arxiv.org/pdf/2311.15846v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15845v3",
            "title": "On Learning the Optimal Regularization Parameter in Inverse Problems",
            "updated": "2023-12-01T15:14:52Z",
            "published": "2023-11-27T14:10:28Z",
            "summary": "Selecting the best regularization parameter in inverse problems is a\nclassical and yet challenging problem. Recently, data-driven approaches have\nbecome popular to tackle this challenge. These approaches are appealing since\nthey do require less a priori knowledge, but their theoretical analysis is\nlimited. In this paper, we propose and study a statistical machine learning\napproach, based on empirical risk minimization. Our main contribution is a\ntheoretical analysis, showing that, provided with enough data, this approach\ncan reach sharp rates while being essentially adaptive to the noise and\nsmoothness of the problem. Numerical simulations corroborate and illustrate the\ntheoretical findings. Our results are a step towards grounding theoretically\ndata-driven approaches to inverse problems.",
            "author": [
                "Jonathan Chirinos Rodriguez",
                "Ernesto De Vito",
                "Cesare Molinari",
                "Lorenzo Rosasco",
                "Silvia Villa"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15845v3",
                "http://arxiv.org/pdf/2311.15845v3"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "math.OC",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15841v2",
            "title": "Learning Disentangled Identifiers for Action-Customized Text-to-Image\n  Generation",
            "updated": "2023-11-30T17:51:47Z",
            "published": "2023-11-27T14:07:13Z",
            "summary": "This study focuses on a novel task in text-to-image (T2I) generation, namely\naction customization. The objective of this task is to learn the co-existing\naction from limited data and generalize it to unseen humans or even animals.\nExperimental results show that existing subject-driven customization methods\nfail to learn the representative characteristics of actions and struggle in\ndecoupling actions from context features, including appearance. To overcome the\npreference for low-level features and the entanglement of high-level features,\nwe propose an inversion-based method Action-Disentangled Identifier (ADI) to\nlearn action-specific identifiers from the exemplar images. ADI first expands\nthe semantic conditioning space by introducing layer-wise identifier tokens,\nthereby increasing the representational richness while distributing the\ninversion across different features. Then, to block the inversion of\naction-agnostic features, ADI extracts the gradient invariance from the\nconstructed sample triples and masks the updates of irrelevant channels. To\ncomprehensively evaluate the task, we present an ActionBench that includes a\nvariety of actions, each accompanied by meticulously selected samples. Both\nquantitative and qualitative results show that our ADI outperforms existing\nbaselines in action-customized T2I generation. Our project page is at\nhttps://adi-t2i.github.io/ADI.",
            "author": [
                "Siteng Huang",
                "Biao Gong",
                "Yutong Feng",
                "Xi Chen",
                "Yuqian Fu",
                "Yu Liu",
                "Donglin Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15841v2",
                "http://arxiv.org/pdf/2311.15841v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15839v1",
            "title": "Ontologising Trustworthy in the Telecommunications Domain",
            "updated": "2023-11-27T14:04:46Z",
            "published": "2023-11-27T14:04:46Z",
            "summary": "Based upon trusted and confidential computing platforms, telecommunications\nsystems must provide guaranteed security for the processes and data running\natop them. This in turn requires us to provide trustworthy systems. The term\ntrustworthy is poorly defined with corresponding misunderstanding and\nmisapplication. We present a definition of this term, as well as others,\ndemonstrate its application against certain telecommunications use cases and\naddress how the learnings from ontologising these structures contribute to\nstandardisation and the necessity for FAIR ontologies across telecommunications\nstandards and hosting organisations.",
            "author": [
                "Ian Oliver",
                "Pekka Kuure",
                "Wiktor Sedkowski",
                "Thore Sommer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15839v1",
                "http://arxiv.org/pdf/2311.15839v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.SE",
                "D.2.1"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15838v1",
            "title": "Utilizing Explainability Techniques for Reinforcement Learning Model\n  Assurance",
            "updated": "2023-11-27T14:02:47Z",
            "published": "2023-11-27T14:02:47Z",
            "summary": "Explainable Reinforcement Learning (XRL) can provide transparency into the\ndecision-making process of a Deep Reinforcement Learning (DRL) model and\nincrease user trust and adoption in real-world use cases. By utilizing XRL\ntechniques, researchers can identify potential vulnerabilities within a trained\nDRL model prior to deployment, therefore limiting the potential for mission\nfailure or mistakes by the system. This paper introduces the ARLIN (Assured RL\nModel Interrogation) Toolkit, an open-source Python library that identifies\npotential vulnerabilities and critical points within trained DRL models through\ndetailed, human-interpretable explainability outputs. To illustrate ARLIN's\neffectiveness, we provide explainability visualizations and vulnerability\nanalysis for a publicly available DRL model. The open-source code repository is\navailable for download at https://github.com/mitre/arlin.",
            "author": [
                "Alexander Tapley",
                "Kyle Gatesman",
                "Luis Robaina",
                "Brett Bissey",
                "Joseph Weissman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15838v1",
                "http://arxiv.org/pdf/2311.15838v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15836v1",
            "title": "Syn3DWound: A Synthetic Dataset for 3D Wound Bed Analysis",
            "updated": "2023-11-27T13:59:53Z",
            "published": "2023-11-27T13:59:53Z",
            "summary": "Wound management poses a significant challenge, particularly for bedridden\npatients and the elderly. Accurate diagnostic and healing monitoring can\nsignificantly benefit from modern image analysis, providing accurate and\nprecise measurements of wounds. Despite several existing techniques, the\nshortage of expansive and diverse training datasets remains a significant\nobstacle to constructing machine learning-based frameworks. This paper\nintroduces Syn3DWound, an open-source dataset of high-fidelity simulated wounds\nwith 2D and 3D annotations. We propose baseline methods and a benchmarking\nframework for automated 3D morphometry analysis and 2D/3D wound segmentation.",
            "author": [
                "L\u00e9o Lebrat",
                "Rodrigo Santa Cruz",
                "Remi Chierchia",
                "Yulia Arzhaeva",
                "Mohammad Ali Armin",
                "Joshua Goldsmith",
                "Jeremy Oorloff",
                "Prithvi Reddy",
                "Chuong Nguyen",
                "Lars Petersson",
                "Michelle Barakat-Johnson",
                "Georgina Luscombe",
                "Clinton Fookes",
                "Olivier Salvado",
                "David Ahmedt-Aristizabal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15836v1",
                "http://arxiv.org/pdf/2311.15836v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15831v1",
            "title": "Temporal Action Localization for Inertial-based Human Activity\n  Recognition",
            "updated": "2023-11-27T13:55:21Z",
            "published": "2023-11-27T13:55:21Z",
            "summary": "A persistent trend in Deep Learning has been the applicability of machine\nlearning concepts to other areas than originally introduced for. As of today,\nstate-of-the-art activity recognition from wearable sensors relies on\nclassifiers being trained on fixed windows of data. Contrarily, video-based\nHuman Activity Recognition has followed a segment-based prediction approach,\nlocalizing activity occurrences from start to end. This paper is the first to\nsystematically demonstrate the applicability of state-of-the-art TAL models for\nwearable Human Activity Recongition (HAR) using raw inertial data as input. Our\nresults show that state-of-the-art TAL models are able to outperform popular\ninertial models on 4 out of 6 wearable activity recognition benchmark datasets,\nwith improvements ranging as much as 25% in F1-score. Introducing the TAL\ncommunity's most popular metric to inertial-based HAR, namely mean Average\nPrecision, our analysis shows that TAL models are able to produce more coherent\nsegments along with an overall higher NULL-class accuracy across all datasets.\nBeing the first to provide such an analysis, the TAL community offers an\ninteresting new perspective to inertial-based HAR with yet to be explored\ndesign choices and training concepts, which could be of significant value for\nthe inertial-based HAR community.",
            "author": [
                "Marius Bock",
                "Michael Moeller",
                "Kristof Van Laerhoven"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15831v1",
                "http://arxiv.org/pdf/2311.15831v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.HC",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15830v2",
            "title": "A-JEPA: Joint-Embedding Predictive Architecture Can Listen",
            "updated": "2023-11-28T03:15:50Z",
            "published": "2023-11-27T13:53:53Z",
            "summary": "This paper presents that the masked-modeling principle driving the success of\nlarge foundational vision models can be effectively applied to audio by making\npredictions in a latent space. We introduce Audio-based Joint-Embedding\nPredictive Architecture (A-JEPA), a simple extension method for self-supervised\nlearning from the audio spectrum. Following the design of I-JEPA, our A-JEPA\nencodes visible audio spectrogram patches with a curriculum masking strategy\nvia context encoder, and predicts the representations of regions sampled at\nwell-designed locations. The target representations of those regions are\nextracted by the exponential moving average of context encoder, \\emph{i.e.},\ntarget encoder, on the whole spectrogram. We find it beneficial to transfer\nrandom block masking into time-frequency aware masking in a curriculum manner,\nconsidering the complexity of highly correlated in local time and frequency in\naudio spectrograms. To enhance contextual semantic understanding and\nrobustness, we fine-tune the encoder with a regularized masking on target\ndatasets, instead of input dropping or zero. Empirically, when built with\nVision Transformers structure, we find A-JEPA to be highly scalable and sets\nnew state-of-the-art performance on multiple audio and speech classification\ntasks, outperforming other recent models that use externally supervised\npre-training.",
            "author": [
                "Zhengcong Fei",
                "Mingyuan Fan",
                "Junshi Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15830v2",
                "http://arxiv.org/pdf/2311.15830v2"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CV",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15822v1",
            "title": "Data reconstruction for complex flows using AI: recent progress,\n  obstacles, and perspectives",
            "updated": "2023-11-27T13:47:05Z",
            "published": "2023-11-27T13:47:05Z",
            "summary": "In recent years the fluid mechanics community has been intensely focused on\npursuing solutions to its long-standing open problems by exploiting the new\nmachine learning, (ML), approaches. The exchange between ML and fluid mechanics\nis bringing important paybacks in both directions. The first is benefiting from\nnew physics-inspired ML methods and a scientific playground to perform\nquantitative benchmarks, whilst the latter has been open to a large set of new\ntools inherently well suited to deal with big data, flexible in scope, and\ncapable of revealing unknown correlations. A special case is the problem of\nmodeling missing information of partially observable systems. The aim of this\npaper is to review some of the ML algorithms that are playing an important role\nin the current developments in this field, to uncover potential avenues, and to\ndiscuss the open challenges for applications to fluid mechanics.",
            "author": [
                "Michele Buzzicotti"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15822v1",
                "http://arxiv.org/pdf/2311.15822v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15816v1",
            "title": "Scale-Dropout: Estimating Uncertainty in Deep Neural Networks Using\n  Stochastic Scale",
            "updated": "2023-11-27T13:41:20Z",
            "published": "2023-11-27T13:41:20Z",
            "summary": "Uncertainty estimation in Neural Networks (NNs) is vital in improving\nreliability and confidence in predictions, particularly in safety-critical\napplications. Bayesian Neural Networks (BayNNs) with Dropout as an\napproximation offer a systematic approach to quantifying uncertainty, but they\ninherently suffer from high hardware overhead in terms of power, memory, and\ncomputation. Thus, the applicability of BayNNs to edge devices with limited\nresources or to high-performance applications is challenging. Some of the\ninherent costs of BayNNs can be reduced by accelerating them in hardware on a\nComputation-In-Memory (CIM) architecture with spintronic memories and\nbinarizing their parameters. However, numerous stochastic units are required to\nimplement conventional dropout-based BayNN. In this paper, we propose the Scale\nDropout, a novel regularization technique for Binary Neural Networks (BNNs),\nand Monte Carlo-Scale Dropout (MC-Scale Dropout)-based BayNNs for efficient\nuncertainty estimation. Our approach requires only one stochastic unit for the\nentire model, irrespective of the model size, leading to a highly scalable\nBayesian NN. Furthermore, we introduce a novel Spintronic memory-based CIM\narchitecture for the proposed BayNN that achieves more than $100\\times$ energy\nsavings compared to the state-of-the-art. We validated our method to show up to\na $1\\%$ improvement in predictive performance and superior uncertainty\nestimates compared to related works.",
            "author": [
                "Soyed Tuhin Ahmed",
                "Kamal Danouchi",
                "Michael Hefenbrock",
                "Guillaume Prenat",
                "Lorena Anghel",
                "Mehdi B. Tahoori"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15816v1",
                "http://arxiv.org/pdf/2311.15816v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.ET"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15812v1",
            "title": "C-SAW: Self-Supervised Prompt Learning for Image Generalization in\n  Remote Sensing",
            "updated": "2023-11-27T13:35:20Z",
            "published": "2023-11-27T13:35:20Z",
            "summary": "We focus on domain and class generalization problems in analyzing optical\nremote sensing images, using the large-scale pre-trained vision-language model\n(VLM), CLIP. While contrastively trained VLMs show impressive zero-shot\ngeneralization performance, their effectiveness is limited when dealing with\ndiverse domains during training and testing. Existing prompt learning\ntechniques overlook the importance of incorporating domain and content\ninformation into the prompts, which results in a drop in performance while\ndealing with such multi-domain data. To address these challenges, we propose a\nsolution that ensures domain-invariant prompt learning while enhancing the\nexpressiveness of visual features. We observe that CLIP's vision encoder\nstruggles to identify contextual image information, particularly when image\npatches are jumbled up. This issue is especially severe in optical remote\nsensing images, where land-cover classes exhibit well-defined contextual\nappearances. To this end, we introduce C-SAW, a method that complements CLIP\nwith a self-supervised loss in the visual space and a novel prompt learning\ntechnique that emphasizes both visual domain and content-specific features. We\nkeep the CLIP backbone frozen and introduce a small set of projectors for both\nthe CLIP encoders to train C-SAW contrastively. Experimental results\ndemonstrate the superiority of C-SAW across multiple remote sensing benchmarks\nand different generalization tasks.",
            "author": [
                "Avigyan Bhattacharya",
                "Mainak Singha",
                "Ankit Jha",
                "Biplab Banerjee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15812v1",
                "http://arxiv.org/pdf/2311.15812v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15810v1",
            "title": "Tascade: Hardware Support for Atomic-free, Asynchronous and Efficient\n  Reduction Trees",
            "updated": "2023-11-27T13:32:33Z",
            "published": "2023-11-27T13:32:33Z",
            "summary": "As system parallelism at chip- and server-level increases, challenges that\narose with network-level systems a decade ago, are now being encountered with\nthese massively parallel systems that have become an important workhorse for\nMachine Learning workloads as well as Graph and Sparse workloads. To tackle the\ncommunication bottlenecks, recent works have introduced task-based\nparallelization schemes to accelerate graph search and sparse data-structure\ntraversal, where some solutions scale up to thousands of processing units (PUs)\non a single chip. However, existing communication schemes do not scale to\nlarger than thousands of processing tiles. To address these challenges we\npropose Tascade, a system that offers hardware-supported, efficient and\nbalanced reduction trees to reduce communication overheads in task-based\nparallelization schemes and scales up to a million PUs. Tascade achieves this\nby implementing an execution model utilizing proxy regions and cascading\nupdates, along with a supporting hardware design that enables the execution of\nthe reduction tree at the chip level. The Tascade approach reduces overall\ncommunication and improves load balancing. We evaluate six applications and\nfour datasets to provide a detailed analysis of Tascade's performance, power,\nand traffic-reduction gains over prior work. Our parallelization of\nBreadth-First-Search with RMAT-26 across a million PUs, the largest of the\nliterature, reaches 5305 GTEPS.",
            "author": [
                "Marcelo Orenes-Vera",
                "Esin Tureci",
                "David Wentzlaff",
                "Margaret Martonosi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15810v1",
                "http://arxiv.org/pdf/2311.15810v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15809v1",
            "title": "From deepfake to deep useful: risks and opportunities through a\n  systematic literature review",
            "updated": "2023-11-27T13:31:40Z",
            "published": "2023-11-27T13:31:40Z",
            "summary": "Deepfake videos are defined as a resulting media from the synthesis of\ndifferent persons images and videos, mostly faces, replacing a real one. The\neasy spread of such videos leads to elevated misinformation and represents a\nthreat to society and democracy today. The present study aims to collect and\nanalyze the relevant literature through a systematic procedure. We present 27\narticles from scientific databases revealing threats to society, democracies,\nthe political life but present as well advantages of this technology in\nentertainment, gaming, education, and public life. The research indicates high\nscientific interest in deepfake detection algorithms as well as the ethical\naspect of such technology. This article covers the scientific gap since, to the\nbest of our knowledge, this is the first systematic literature review in the\nfield. A discussion has already started among academics and practitioners\nconcerning the spread of fake news. The next step of fake news considers the\nuse of artificial intelligence and machine learning algorithms that create\nhyper-realistic videos, called deepfake. Deepfake technology has continuously\nattracted the attention of scholars over the last 3 years more and more. The\nimportance of conducting research in this field derives from the necessity to\nunderstand the theory. The first contextual approach is related to the\nepistemological points of view of the concept. The second one is related to the\nphenomenological disadvantages of the field. Despite that, the authors will try\nto focus not only on the disadvantages of the field but also on the positive\naspects of the technology.",
            "author": [
                "Nikolaos Misirlis",
                "Harris Bin Munawar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15809v1",
                "http://arxiv.org/pdf/2311.15809v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15807v1",
            "title": "Exploring Artificial Intelligence Methods for Energy Prediction in\n  Healthcare Facilities: An In-Depth Extended Systematic Review",
            "updated": "2023-11-27T13:30:20Z",
            "published": "2023-11-27T13:30:20Z",
            "summary": "Hospitals, due to their complexity and unique requirements, play a pivotal\nrole in global energy consumption patterns. This study conducted a\ncomprehensive literature review, utilizing the PRISMA framework, of articles\nthat employed machine learning and artificial intelligence techniques for\npredicting energy consumption in hospital buildings. Of the 1884 publications\nidentified, 17 were found to address this specific domain and have been\nthoroughly reviewed to establish the state-of-the-art and identify gaps where\nfuture research is needed. This review revealed a diverse range of data inputs\ninfluencing energy prediction, with occupancy and meteorological data emerging\nas significant predictors. However, many studies failed to delve deep into the\nimplications of their data choices, and gaps were evident regarding the\nunderstanding of time dynamics, operational status, and preprocessing methods.\nMachine learning, especially deep learning models like ANNs, have shown\npotential in this domain, yet they come with challenges, including\ninterpretability and computational demands. The findings underscore the immense\npotential of AI in optimizing hospital energy consumption but also highlight\nthe need for more comprehensive and granular research. Key areas for future\nresearch include the optimization of ANN approaches, new optimization and data\nintegration techniques, the integration of real-time data into Intelligent\nEnergy Management Systems, and increasing focus on long-term energy\nforecasting.",
            "author": [
                "Marjan FatehiJananloo",
                "Helen Stopps",
                "J. J. McArthur"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15807v1",
                "http://arxiv.org/pdf/2311.15807v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SY",
                "eess.SY",
                "A.1; I.2; J.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15800v1",
            "title": "Public sentiment analysis and topic modeling regarding ChatGPT in mental\n  health on Reddit: Negative sentiments increase over time",
            "updated": "2023-11-27T13:23:11Z",
            "published": "2023-11-27T13:23:11Z",
            "summary": "In order to uncover users' attitudes towards ChatGPT in mental health, this\nstudy examines public opinions about ChatGPT in mental health discussions on\nReddit. Researchers used the bert-base-multilingual-uncased-sentiment\ntechniques for sentiment analysis and the BERTopic model for topic modeling. It\nwas found that overall, negative sentiments prevail, followed by positive ones,\nwith neutral sentiments being the least common. The prevalence of negative\nemotions has increased over time. Negative emotions encompass discussions on\nChatGPT providing bad mental health advice, debates on machine vs. human value,\nthe fear of AI, and concerns about Universal Basic Income (UBI). In contrast,\npositive emotions highlight ChatGPT's effectiveness in counseling, with\nmentions of keywords like \"time\" and \"wallet.\" Neutral discussions center\naround private data concerns. These findings shed light on public attitudes\ntoward ChatGPT in mental health, potentially contributing to the development of\ntrustworthy AI in mental health from the public perspective.",
            "author": [
                "Yunna Cai",
                "Fan Wang",
                "Haowei Wang",
                "Qianwen Qian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15800v1",
                "http://arxiv.org/pdf/2311.15800v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15792v1",
            "title": "Rethinking Privacy in Machine Learning Pipelines from an Information\n  Flow Control Perspective",
            "updated": "2023-11-27T13:14:39Z",
            "published": "2023-11-27T13:14:39Z",
            "summary": "Modern machine learning systems use models trained on ever-growing corpora.\nTypically, metadata such as ownership, access control, or licensing information\nis ignored during training. Instead, to mitigate privacy risks, we rely on\ngeneric techniques such as dataset sanitization and differentially private\nmodel training, with inherent privacy/utility trade-offs that hurt model\nperformance. Moreover, these techniques have limitations in scenarios where\nsensitive information is shared across multiple participants and fine-grained\naccess control is required. By ignoring metadata, we therefore miss an\nopportunity to better address security, privacy, and confidentiality\nchallenges. In this paper, we take an information flow control perspective to\ndescribe machine learning systems, which allows us to leverage metadata such as\naccess control policies and define clear-cut privacy and confidentiality\nguarantees with interpretable information flows. Under this perspective, we\ncontrast two different approaches to achieve user-level non-interference: 1)\nfine-tuning per-user models, and 2) retrieval augmented models that access\nuser-specific datasets at inference time. We compare these two approaches to a\ntrivially non-interfering zero-shot baseline using a public model and to a\nbaseline that fine-tunes this model on the whole corpus. We evaluate trained\nmodels on two datasets of scientific articles and demonstrate that retrieval\naugmented architectures deliver the best utility, scalability, and flexibility\nwhile satisfying strict non-interference guarantees.",
            "author": [
                "Lukas Wutschitz",
                "Boris K\u00f6pf",
                "Andrew Paverd",
                "Saravan Rajmohan",
                "Ahmed Salem",
                "Shruti Tople",
                "Santiago Zanella-B\u00e9guelin",
                "Menglin Xia",
                "Victor R\u00fchle"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15792v1",
                "http://arxiv.org/pdf/2311.15792v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16514v1",
            "title": "Video Anomaly Detection via Spatio-Temporal Pseudo-Anomaly Generation :\n  A Unified Approach",
            "updated": "2023-11-27T13:14:06Z",
            "published": "2023-11-27T13:14:06Z",
            "summary": "Video Anomaly Detection (VAD) is an open-set recognition task, which is\nusually formulated as a one-class classification (OCC) problem, where training\ndata is comprised of videos with normal instances while test data contains both\nnormal and anomalous instances. Recent works have investigated the creation of\npseudo-anomalies (PAs) using only the normal data and making strong assumptions\nabout real-world anomalies with regards to abnormality of objects and speed of\nmotion to inject prior information about anomalies in an autoencoder (AE) based\nreconstruction model during training. This work proposes a novel method for\ngenerating generic spatio-temporal PAs by inpainting a masked out region of an\nimage using a pre-trained Latent Diffusion Model and further perturbing the\noptical flow using mixup to emulate spatio-temporal distortions in the data. In\naddition, we present a simple unified framework to detect real-world anomalies\nunder the OCC setting by learning three types of anomaly indicators, namely\nreconstruction quality, temporal irregularity and semantic inconsistency.\nExtensive experiments on four VAD benchmark datasets namely Ped2, Avenue,\nShanghaiTech and UBnormal demonstrate that our method performs on par with\nother existing state-of-the-art PAs generation and reconstruction based methods\nunder the OCC setting. Our analysis also examines the transferability and\ngeneralisation of PAs across these datasets, offering valuable insights by\nidentifying real-world anomalies through PAs.",
            "author": [
                "Ayush K. Rai",
                "Tarun Krishna",
                "Feiyan Hu",
                "Alexandru Drimbarean",
                "Kevin McGuinness",
                "Alan F. Smeaton",
                "Noel E. O'Connor"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16514v1",
                "http://arxiv.org/pdf/2311.16514v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15790v1",
            "title": "A Social-aware Gaussian Pre-trained Model for Effective Cold-start\n  Recommendation",
            "updated": "2023-11-27T13:04:33Z",
            "published": "2023-11-27T13:04:33Z",
            "summary": "The use of pre-training is an emerging technique to enhance a neural model's\nperformance, which has been shown to be effective for many neural language\nmodels such as BERT. This technique has also been used to enhance the\nperformance of recommender systems. In such recommender systems, pre-training\nmodels are used to learn a better initialisation for both users and items.\nHowever, recent existing pre-trained recommender systems tend to only\nincorporate the user interaction data at the pre-training stage, making it\ndifficult to deliver good recommendations, especially when the interaction data\nis sparse. To alleviate this common data sparsity issue, we propose to\npre-train the recommendation model not only with the interaction data but also\nwith other available information such as the social relations among users,\nthereby providing the recommender system with a better initialisation compared\nwith solely relying on the user interaction data. We propose a novel\nrecommendation model, the Social-aware Gaussian Pre-trained model (SGP), which\nencodes the user social relations and interaction data at the pre-training\nstage in a Graph Neural Network (GNN). Afterwards, in the subsequent\nfine-tuning stage, our SGP model adopts a Gaussian Mixture Model (GMM) to\nfactorise these pre-trained embeddings for further training, thereby benefiting\nthe cold-start users from these pre-built social relations. Our extensive\nexperiments on three public datasets show that, in comparison to 16 competitive\nbaselines, our SGP model significantly outperforms the best baseline by upto\n7.7% in terms of NDCG@10. In addition, we show that SGP permits to effectively\nalleviate the cold-start problem, especially when users newly register to the\nsystem through their friends' suggestions.",
            "author": [
                "Siwei Liu",
                "Xi Wang",
                "Craig Macdonald",
                "Iadh Ounis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15790v1",
                "http://arxiv.org/pdf/2311.15790v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI",
                "68P20",
                "H.3.3"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16503v1",
            "title": "TFMQ-DM: Temporal Feature Maintenance Quantization for Diffusion Models",
            "updated": "2023-11-27T12:59:52Z",
            "published": "2023-11-27T12:59:52Z",
            "summary": "The Diffusion model, a prevalent framework for image generation, encounters\nsignificant challenges in terms of broad applicability due to its extended\ninference times and substantial memory requirements. Efficient Post-training\nQuantization (PTQ) is pivotal for addressing these issues in traditional\nmodels. Different from traditional models, diffusion models heavily depend on\nthe time-step $t$ to achieve satisfactory multi-round denoising. Usually, $t$\nfrom the finite set $\\{1, \\ldots, T\\}$ is encoded to a temporal feature by a\nfew modules totally irrespective of the sampling data. However, existing PTQ\nmethods do not optimize these modules separately. They adopt inappropriate\nreconstruction targets and complex calibration methods, resulting in a severe\ndisturbance of the temporal feature and denoising trajectory, as well as a low\ncompression efficiency. To solve these, we propose a Temporal Feature\nMaintenance Quantization (TFMQ) framework building upon a Temporal Information\nBlock which is just related to the time-step $t$ and unrelated to the sampling\ndata. Powered by the pioneering block design, we devise temporal information\naware reconstruction (TIAR) and finite set calibration (FSC) to align the\nfull-precision temporal features in a limited time. Equipped with the\nframework, we can maintain the most temporal information and ensure the\nend-to-end generation quality. Extensive experiments on various datasets and\ndiffusion models prove our state-of-the-art results. Remarkably, our\nquantization approach, for the first time, achieves model performance nearly on\npar with the full-precision model under 4-bit weight quantization.\nAdditionally, our method incurs almost no extra computational cost and\naccelerates quantization time by $2.0 \\times$ on LSUN-Bedrooms $256 \\times 256$\ncompared to previous works.",
            "author": [
                "Yushi Huang",
                "Ruihao Gong",
                "Jing Liu",
                "Tianlong Chen",
                "Xianglong Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16503v1",
                "http://arxiv.org/pdf/2311.16503v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16510v1",
            "title": "Source-Free Domain Adaptation with Frozen Multimodal Foundation Model",
            "updated": "2023-11-27T12:58:02Z",
            "published": "2023-11-27T12:58:02Z",
            "summary": "Source-Free Domain Adaptation (SFDA) aims to adapt a source model for a\ntarget domain, with only access to unlabeled target training data and the\nsource model pre-trained on a supervised source domain. Relying on pseudo\nlabeling and/or auxiliary supervision, conventional methods are inevitably\nerror-prone. To mitigate this limitation, in this work we for the first time\nexplore the potentials of off-the-shelf vision-language (ViL) multimodal models\n(e.g.,CLIP) with rich whilst heterogeneous knowledge. We find that directly\napplying the ViL model to the target domain in a zero-shot fashion is\nunsatisfactory, as it is not specialized for this particular task but largely\ngeneric. To make it task specific, we propose a novel Distilling multimodal\nFoundation model(DIFO)approach. Specifically, DIFO alternates between two steps\nduring adaptation: (i) Customizing the ViL model by maximizing the mutual\ninformation with the target model in a prompt learning manner, (ii) Distilling\nthe knowledge of this customized ViL model to the target model. For more\nfine-grained and reliable distillation, we further introduce two effective\nregularization terms, namely most-likely category encouragement and predictive\nconsistency. Extensive experiments show that DIFO significantly outperforms the\nstate-of-the-art alternatives. Our source code will be released.",
            "author": [
                "Song Tang",
                "Wenxin Su",
                "Mao Ye",
                "Xiatian Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16510v1",
                "http://arxiv.org/pdf/2311.16510v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15782v1",
            "title": "Relationship between Model Compression and Adversarial Robustness: A\n  Review of Current Evidence",
            "updated": "2023-11-27T12:55:39Z",
            "published": "2023-11-27T12:55:39Z",
            "summary": "Increasing the model capacity is a known approach to enhance the adversarial\nrobustness of deep learning networks. On the other hand, various model\ncompression techniques, including pruning and quantization, can reduce the size\nof the network while preserving its accuracy. Several recent studies have\naddressed the relationship between model compression and adversarial\nrobustness, while some experiments have reported contradictory results. This\nwork summarizes available evidence and discusses possible explanations for the\nobserved effects.",
            "author": [
                "Svetlana Pavlitska",
                "Hannes Grolig",
                "J. Marius Z\u00f6llner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15782v1",
                "http://arxiv.org/pdf/2311.15782v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15781v1",
            "title": "Increasing Coverage and Precision of Textual Information in Multilingual\n  Knowledge Graphs",
            "updated": "2023-11-27T12:54:47Z",
            "published": "2023-11-27T12:54:47Z",
            "summary": "Recent work in Natural Language Processing and Computer Vision has been using\ntextual information -- e.g., entity names and descriptions -- available in\nknowledge graphs to ground neural models to high-quality structured data.\nHowever, when it comes to non-English languages, the quantity and quality of\ntextual information are comparatively scarce. To address this issue, we\nintroduce the novel task of automatic Knowledge Graph Enhancement (KGE) and\nperform a thorough investigation on bridging the gap in both the quantity and\nquality of textual information between English and non-English languages. More\nspecifically, we: i) bring to light the problem of increasing multilingual\ncoverage and precision of entity names and descriptions in Wikidata; ii)\ndemonstrate that state-of-the-art methods, namely, Machine Translation (MT),\nWeb Search (WS), and Large Language Models (LLMs), struggle with this task;\niii) present M-NTA, a novel unsupervised approach that combines MT, WS, and\nLLMs to generate high-quality textual information; and, iv) study the impact of\nincreasing multilingual coverage and precision of non-English textual\ninformation in Entity Linking, Knowledge Graph Completion, and Question\nAnswering. As part of our effort towards better multilingual knowledge graphs,\nwe also introduce WikiKGE-10, the first human-curated benchmark to evaluate KGE\napproaches in 10 languages across 7 language families.",
            "author": [
                "Simone Conia",
                "Min Li",
                "Daniel Lee",
                "Umar Farooq Minhas",
                "Ihab Ilyas",
                "Yunyao Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15781v1",
                "http://arxiv.org/pdf/2311.15781v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15772v1",
            "title": "Attend Who is Weak: Enhancing Graph Condensation via Cross-Free\n  Adversarial Training",
            "updated": "2023-11-27T12:44:42Z",
            "published": "2023-11-27T12:44:42Z",
            "summary": "In this paper, we study the \\textit{graph condensation} problem by\ncompressing the large, complex graph into a concise, synthetic representation\nthat preserves the most essential and discriminative information of structure\nand features. We seminally propose the concept of Shock Absorber (a type of\nperturbation) that enhances the robustness and stability of the original graphs\nagainst changes in an adversarial training fashion. Concretely, (I) we forcibly\nmatch the gradients between pre-selected graph neural networks (GNNs) trained\non a synthetic, simplified graph and the original training graph at regularly\nspaced intervals. (II) Before each update synthetic graph point, a Shock\nAbsorber serves as a gradient attacker to maximize the distance between the\nsynthetic dataset and the original graph by selectively perturbing the parts\nthat are underrepresented or insufficiently informative. We iteratively repeat\nthe above two processes (I and II) in an adversarial training fashion to\nmaintain the highly-informative context without losing correlation with the\noriginal dataset. More importantly, our shock absorber and the synthesized\ngraph parallelly share the backward process in a free training manner. Compared\nto the original adversarial training, it introduces almost no additional time\noverhead.\n  We validate our framework across 8 datasets (3 graph and 5 node\nclassification datasets) and achieve prominent results: for example, on Cora,\nCiteseer and Ogbn-Arxiv, we can gain nearly 1.13% to 5.03% improvements compare\nwith SOTA models. Moreover, our algorithm adds only about 0.2% to 2.2%\nadditional time overhead over Flicker, Citeseer and Ogbn-Arxiv. Compared to the\ngeneral adversarial training, our approach improves time efficiency by nearly\n4-fold.",
            "author": [
                "Xinglin Li",
                "Kun Wang",
                "Hanhui Deng",
                "Yuxuan Liang",
                "Di Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15772v1",
                "http://arxiv.org/pdf/2311.15772v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15769v1",
            "title": "Side4Video: Spatial-Temporal Side Network for Memory-Efficient\n  Image-to-Video Transfer Learning",
            "updated": "2023-11-27T12:39:42Z",
            "published": "2023-11-27T12:39:42Z",
            "summary": "Large pre-trained vision models achieve impressive success in computer\nvision. However, fully fine-tuning large models for downstream tasks,\nparticularly in video understanding, can be prohibitively computationally\nexpensive. Recent studies turn their focus towards efficient image-to-video\ntransfer learning. Nevertheless, existing efficient fine-tuning methods lack\nattention to training memory usage and exploration of transferring a larger\nmodel to the video domain. In this paper, we present a novel Spatial-Temporal\nSide Network for memory-efficient fine-tuning large image models to video\nunderstanding, named Side4Video. Specifically, we introduce a lightweight\nspatial-temporal side network attached to the frozen vision model, which avoids\nthe backpropagation through the heavy pre-trained model and utilizes\nmulti-level spatial features from the original image model. Extremely\nmemory-efficient architecture enables our method to reduce 75% memory usage\nthan previous adapter-based methods. In this way, we can transfer a huge ViT-E\n(4.4B) for video understanding tasks which is 14x larger than ViT-L (304M). Our\napproach achieves remarkable performance on various video datasets across\nunimodal and cross-modal tasks (i.e., action recognition and text-video\nretrieval), especially in Something-Something V1&V2 (67.3% & 74.6%),\nKinetics-400 (88.6%), MSR-VTT (52.3%), MSVD (56.1%) and VATEX (68.8%). We\nrelease our code at https://github.com/HJYao00/Side4Video.",
            "author": [
                "Huanjin Yao",
                "Wenhao Wu",
                "Zhiheng Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15769v1",
                "http://arxiv.org/pdf/2311.15769v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15766v1",
            "title": "Knowledge Unlearning for LLMs: Tasks, Methods, and Challenges",
            "updated": "2023-11-27T12:37:51Z",
            "published": "2023-11-27T12:37:51Z",
            "summary": "In recent years, large language models (LLMs) have spurred a new research\nparadigm in natural language processing. Despite their excellent capability in\nknowledge-based question answering and reasoning, their potential to retain\nfaulty or even harmful knowledge poses risks of malicious application. The\nchallenge of mitigating this issue and transforming these models into purer\nassistants is crucial for their widespread applicability. Unfortunately,\nRetraining LLMs repeatedly to eliminate undesirable knowledge is impractical\ndue to their immense parameters. Knowledge unlearning, derived from analogous\nstudies on machine unlearning, presents a promising avenue to address this\nconcern and is notably advantageous in the context of LLMs. It allows for the\nremoval of harmful knowledge in an efficient manner, without affecting\nunrelated knowledge in the model. To this end, we provide a survey of knowledge\nunlearning in the era of LLMs. Firstly, we formally define the knowledge\nunlearning problem and distinguish it from related works. Subsequently, we\ncategorize existing knowledge unlearning methods into three classes: those\nbased on parameter optimization, parameter merging, and in-context learning,\nand introduce details of these unlearning methods. We further present\nevaluation datasets used in existing methods, and finally conclude this survey\nby presenting the ongoing challenges and future directions.",
            "author": [
                "Nianwen Si",
                "Hao Zhang",
                "Heyu Chang",
                "Wenlin Zhang",
                "Dan Qu",
                "Weiqiang Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15766v1",
                "http://arxiv.org/pdf/2311.15766v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15756v1",
            "title": "Learning Multi-Frequency Partial Correlation Graphs",
            "updated": "2023-11-27T12:22:44Z",
            "published": "2023-11-27T12:22:44Z",
            "summary": "Despite the large research effort devoted to learning dependencies between\ntime series, the state of the art still faces a major limitation: existing\nmethods learn partial correlations but fail to discriminate across distinct\nfrequency bands. Motivated by many applications in which this differentiation\nis pivotal, we overcome this limitation by learning a block-sparse,\nfrequency-dependent, partial correlation graph, in which layers correspond to\ndifferent frequency bands, and partial correlations can occur over just a few\nlayers. To this aim, we formulate and solve two nonconvex learning problems:\nthe first has a closed-form solution and is suitable when there is prior\nknowledge about the number of partial correlations; the second hinges on an\niterative solution based on successive convex approximation, and is effective\nfor the general case where no prior knowledge is available. Numerical results\non synthetic data show that the proposed methods outperform the current state\nof the art. Finally, the analysis of financial time series confirms that\npartial correlations exist only within a few frequency bands, underscoring how\nour methods enable the gaining of valuable insights that would be undetected\nwithout discriminating along the frequency domain.",
            "author": [
                "Gabriele D'Acunto",
                "Paolo Di Lorenzo",
                "Francesco Bonchi",
                "Stefania Sardellitti",
                "Sergio Barbarossa"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15756v1",
                "http://arxiv.org/pdf/2311.15756v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16490v1",
            "title": "SIRAN: Sinkhorn Distance Regularized Adversarial Network for DEM\n  Super-resolution using Discriminative Spatial Self-attention",
            "updated": "2023-11-27T12:03:22Z",
            "published": "2023-11-27T12:03:22Z",
            "summary": "Digital Elevation Model (DEM) is an essential aspect in the remote sensing\ndomain to analyze and explore different applications related to surface\nelevation information. In this study, we intend to address the generation of\nhigh-resolution DEMs using high-resolution multi-spectral (MX) satellite\nimagery by incorporating adversarial learning. To promptly regulate this\nprocess, we utilize the notion of polarized self-attention of discriminator\nspatial maps as well as introduce a Densely connected Multi-Residual Block\n(DMRB) module to assist in efficient gradient flow. Further, we present an\nobjective function related to optimizing Sinkhorn distance with traditional GAN\nto improve the stability of adversarial learning. In this regard, we provide\nboth theoretical and empirical substantiation of better performance in terms of\nvanishing gradient issues and numerical convergence. We demonstrate both\nqualitative and quantitative outcomes with available state-of-the-art methods.\nBased on our experiments on DEM datasets of Shuttle Radar Topographic Mission\n(SRTM) and Cartosat-1, we show that the proposed model performs preferably\nagainst other learning-based state-of-the-art methods. We also generate and\nvisualize several high-resolution DEMs covering terrains with diverse\nsignatures to show the performance of our model.",
            "author": [
                "Subhajit Paul",
                "Ashutosh Gupta"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16490v1",
                "http://arxiv.org/pdf/2311.16490v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15743v1",
            "title": "Review for Dynamic Prediction in Clinical Survival Analysis",
            "updated": "2023-11-27T11:58:25Z",
            "published": "2023-11-27T11:58:25Z",
            "summary": "The accurate prediction of patient prognosis is a critical challenge in\nclinical practice. With the availability of various patient information,\nphysicians can optimize medical care by closely monitoring disease progression\nand therapy responses. To enable better individualized treatment, dynamic\nprediction models are required to continuously update survival probability\npredictions as new information becomes available. This article aims to offer a\ncomprehensive survey of current methods in dynamic survival analysis,\nencompassing both classical statistical approaches and deep learning\ntechniques. Additionally, it will also discuss the limitations of existing\nmethods and the prospects for future advancements in this field.",
            "author": [
                "He Weiyi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15743v1",
                "http://arxiv.org/pdf/2311.15743v1"
            ],
            "primary_category": "stat.AP",
            "category": [
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15741v1",
            "title": "Machine Learning-Based Jamun Leaf Disease Detection: A Comprehensive\n  Review",
            "updated": "2023-11-27T11:46:30Z",
            "published": "2023-11-27T11:46:30Z",
            "summary": "Jamun leaf diseases pose a significant threat to agricultural productivity,\nnegatively impacting both yield and quality in the jamun industry. The advent\nof machine learning has opened up new avenues for tackling these diseases\neffectively. Early detection and diagnosis are essential for successful crop\nmanagement. While no automated systems have yet been developed specifically for\njamun leaf disease detection, various automated systems have been implemented\nfor similar types of disease detection using image processing techniques. This\npaper presents a comprehensive review of machine learning methodologies\nemployed for diagnosing plant leaf diseases through image classification, which\ncan be adapted for jamun leaf disease detection. It meticulously assesses the\nstrengths and limitations of various Vision Transformer models, including\nTransfer learning model and vision transformer (TLMViT), SLViT, SE-ViT,\nIterationViT, Tiny-LeViT, IEM-ViT, GreenViT, and PMViT. Additionally, the paper\nreviews models such as Dense Convolutional Network (DenseNet), Residual Neural\nNetwork (ResNet)-50V2, EfficientNet, Ensemble model, Convolutional Neural\nNetwork (CNN), and Locally Reversible Transformer. These machine-learning\nmodels have been evaluated on various datasets, demonstrating their real-world\napplicability. This review not only sheds light on current advancements in the\nfield but also provides valuable insights for future research directions in\nmachine learning-based jamun leaf disease detection and classification.",
            "author": [
                "Auvick Chandra Bhowmik",
                "Dr. Md. Taimur Ahad",
                "Yousuf Rayhan Emon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15741v1",
                "http://arxiv.org/pdf/2311.15741v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15740v1",
            "title": "Optimization of Image Processing Algorithms for Character Recognition in\n  Cultural Typewritten Documents",
            "updated": "2023-11-27T11:44:46Z",
            "published": "2023-11-27T11:44:46Z",
            "summary": "Linked Data is used in various fields as a new way of structuring and\nconnecting data. Cultural heritage institutions have been using linked data to\nimprove archival descriptions and facilitate the discovery of information. Most\narchival records have digital representations of physical artifacts in the form\nof scanned images that are non-machine-readable. Optical Character Recognition\n(OCR) recognizes text in images and translates it into machine-encoded text.\nThis paper evaluates the impact of image processing methods and parameter\ntuning in OCR applied to typewritten cultural heritage documents. The approach\nuses a multi-objective problem formulation to minimize Levenshtein edit\ndistance and maximize the number of words correctly identified with a\nnon-dominated sorting genetic algorithm (NSGA-II) to tune the methods'\nparameters. Evaluation results show that parameterization by digital\nrepresentation typology benefits the performance of image pre-processing\nalgorithms in OCR. Furthermore, our findings suggest that employing image\npre-processing algorithms in OCR might be more suitable for typologies where\nthe text recognition task without pre-processing does not produce good results.\nIn particular, Adaptive Thresholding, Bilateral Filter, and Opening are the\nbest-performing algorithms for the theatre plays' covers, letters, and overall\ndataset, respectively, and should be applied before OCR to improve its\nperformance.",
            "author": [
                "Mariana Dias",
                "Carla Teixeira Lopes"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3606705",
                "http://arxiv.org/abs/2311.15740v1",
                "http://arxiv.org/pdf/2311.15740v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.DL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15728v1",
            "title": "Adinkra Symbol Recognition using Classical Machine Learning and Deep\n  Learning",
            "updated": "2023-11-27T11:26:41Z",
            "published": "2023-11-27T11:26:41Z",
            "summary": "Artificial intelligence (AI) has emerged as a transformative influence,\nengendering paradigm shifts in global societies, spanning academia and\nindustry. However, in light of these rapid advances, addressing the\nunderrepresentation of black communities and African countries in AI is\ncrucial. Boosting enthusiasm for AI can be effectively accomplished by\nshowcasing straightforward applications around tasks like identifying and\ncategorizing traditional symbols, such as Adinkra symbols, or familiar objects\nwithin the community. In this research endeavor, we dived into classical\nmachine learning and harnessed the power of deep learning models to tackle the\nintricate task of classifying and recognizing Adinkra symbols. The idea led to\na newly constructed ADINKRA dataset comprising 174,338 images meticulously\norganized into 62 distinct classes, each representing a singular and emblematic\nsymbol. We constructed a CNN model for classification and recognition using six\nconvolutional layers, three fully connected (FC) layers, and optional dropout\nregularization. The model is a simpler and smaller version of VGG, with fewer\nlayers, smaller channel sizes, and a fixed kernel size. Additionally, we tap\ninto the transfer learning capabilities provided by pre-trained models like VGG\nand ResNet. These models assist us in both classifying images and extracting\nfeatures that can be used with classical machine learning models. We assess the\nmodel's performance by measuring its accuracy and convergence rate and\nvisualizing the areas that significantly influence its predictions. These\nevaluations serve as a foundational benchmark for future assessments of the\nADINKRA dataset. We hope this application exemplar inspires ideas on the\nvarious uses of AI in organizing our traditional and modern lives.",
            "author": [
                "Michael Adjeisah",
                "Kwame Omono Asamoah",
                "Martha Asamoah Yeboah",
                "Raji Rafiu King",
                "Godwin Ferguson Achaab",
                "Kingsley Adjei"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15728v1",
                "http://arxiv.org/pdf/2311.15728v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15723v1",
            "title": "Italian Crossword Generator: Enhancing Education through Interactive\n  Word Puzzles",
            "updated": "2023-11-27T11:17:29Z",
            "published": "2023-11-27T11:17:29Z",
            "summary": "Educational crosswords offer numerous benefits for students, including\nincreased engagement, improved understanding, critical thinking, and memory\nretention. Creating high-quality educational crosswords can be challenging, but\nrecent advances in natural language processing and machine learning have made\nit possible to use language models to generate nice wordplays. The exploitation\nof cutting-edge language models like GPT3-DaVinci, GPT3-Curie, GPT3-Babbage,\nGPT3-Ada, and BERT-uncased has led to the development of a comprehensive system\nfor generating and verifying crossword clues. A large dataset of clue-answer\npairs was compiled to fine-tune the models in a supervised manner to generate\noriginal and challenging clues from a given keyword. On the other hand, for\ngenerating crossword clues from a given text, Zero/Few-shot learning techniques\nwere used to extract clues from the input text, adding variety and creativity\nto the puzzles. We employed the fine-tuned model to generate data and labeled\nthe acceptability of clue-answer parts with human supervision. To ensure\nquality, we developed a classifier by fine-tuning existing language models on\nthe labeled dataset. Conversely, to assess the quality of clues generated from\nthe given text using zero/few-shot learning, we employed a zero-shot learning\napproach to check the quality of generated clues. The results of the evaluation\nhave been very promising, demonstrating the effectiveness of the approach in\ncreating high-standard educational crosswords that offer students engaging and\nrewarding learning experiences.",
            "author": [
                "Kamyar Zeinalipour",
                "Tommaso laquinta",
                "Asya Zanollo",
                "Giovanni Angelini",
                "Leonardo Rigutini",
                "Marco Maggini",
                "Marco Gori"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15723v1",
                "http://arxiv.org/pdf/2311.15723v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15722v1",
            "title": "GLIME: General, Stable and Local LIME Explanation",
            "updated": "2023-11-27T11:17:20Z",
            "published": "2023-11-27T11:17:20Z",
            "summary": "As black-box machine learning models grow in complexity and find applications\nin high-stakes scenarios, it is imperative to provide explanations for their\npredictions. Although Local Interpretable Model-agnostic Explanations (LIME)\n[22] is a widely adpoted method for understanding model behaviors, it is\nunstable with respect to random seeds [35,24,3] and exhibits low local fidelity\n(i.e., how well the explanation approximates the model's local behaviors)\n[21,16]. Our study shows that this instability problem stems from small sample\nweights, leading to the dominance of regularization and slow convergence.\nAdditionally, LIME's sampling neighborhood is non-local and biased towards the\nreference, resulting in poor local fidelity and sensitivity to reference\nchoice. To tackle these challenges, we introduce GLIME, an enhanced framework\nextending LIME and unifying several prior methods. Within the GLIME framework,\nwe derive an equivalent formulation of LIME that achieves significantly faster\nconvergence and improved stability. By employing a local and unbiased sampling\ndistribution, GLIME generates explanations with higher local fidelity compared\nto LIME. GLIME explanations are independent of reference choice. Moreover,\nGLIME offers users the flexibility to choose a sampling distribution based on\ntheir specific scenarios.",
            "author": [
                "Zeren Tan",
                "Yang Tian",
                "Jian Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15722v1",
                "http://arxiv.org/pdf/2311.15722v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "cs.HC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15719v1",
            "title": "Variational Autoencoders for Feature Exploration and Malignancy\n  Prediction of Lung Lesions",
            "updated": "2023-11-27T11:12:33Z",
            "published": "2023-11-27T11:12:33Z",
            "summary": "Lung cancer is responsible for 21% of cancer deaths in the UK and five-year\nsurvival rates are heavily influenced by the stage the cancer was identified\nat. Recent studies have demonstrated the capability of AI methods for accurate\nand early diagnosis of lung cancer from routine scans. However, this evidence\nhas not translated into clinical practice with one barrier being a lack of\ninterpretable models. This study investigates the application Variational\nAutoencoders (VAEs), a type of generative AI model, to lung cancer lesions.\nProposed models were trained on lesions extracted from 3D CT scans in the\nLIDC-IDRI public dataset. Latent vector representations of 2D slices produced\nby the VAEs were explored through clustering to justify their quality and used\nin an MLP classifier model for lung cancer diagnosis, the best model achieved\nstate-of-the-art metrics of AUC 0.98 and 93.1% accuracy. Cluster analysis shows\nthe VAE latent space separates the dataset of malignant and benign lesions\nbased on meaningful feature components including tumour size, shape, patient\nand malignancy class. We also include a comparative analysis of the standard\nGaussian VAE (GVAE) and the more recent Dirichlet VAE (DirVAE), which replaces\nthe prior with a Dirichlet distribution to encourage a more explainable latent\nspace with disentangled feature representation. Finally, we demonstrate the\npotential for latent space traversals corresponding to clinically meaningful\nfeature changes.",
            "author": [
                "Benjamin Keel",
                "Aaron Quyn",
                "David Jayne",
                "Samuel D. Relton"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15719v1",
                "http://arxiv.org/pdf/2311.15719v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15703v1",
            "title": "Tabular Two-Dimensional Correlation Analysis for Multifaceted\n  Characterization Data",
            "updated": "2023-11-27T10:41:28Z",
            "published": "2023-11-27T10:41:28Z",
            "summary": "We propose tabular two-dimensional correlation analysis for extracting\nfeatures from multifaceted characterization data, essential for understanding\nmaterial properties. This method visualizes similarities and phase lags in\nstructural parameter changes through heatmaps, combining hierarchical\nclustering and asynchronous correlations. We applied the proposed method to\ndatasets of carbon nanotube (CNTs) films annealed at various temperatures and\nrevealed the complexity of their hierarchical structures, which include\nelements like voids, bundles, and amorphous carbon. Our analysis addresses the\nchallenge of attempting to understand the sequence of structural changes,\nespecially in multifaceted characterization data where 11 structural parameters\nderived from 8 characterization methods interact with complex behavior. The\nresults show how phase lags (asynchronous changes from stimuli) and parameter\nsimilarities can illuminate the sequence of structural changes in materials,\nproviding insights into phenomena like the removal of amorphous carbon and\ngraphitization in annealed CNTs. This approach is beneficial even with limited\ndata and holds promise for a wide range of material analyses, demonstrating its\npotential in elucidating complex material behaviors and properties.",
            "author": [
                "Shun Muroga",
                "Satoshi Yamazaki",
                "Koji Michishio",
                "Hideaki Nakajima",
                "Takahiro Morimoto",
                "Nagayasu Oshima",
                "Kazufumi Kobashi",
                "Toshiya Okazaki"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15703v1",
                "http://arxiv.org/pdf/2311.15703v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cond-mat.soft",
                "cs.LG",
                "physics.app-ph",
                "physics.data-an"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15696v1",
            "title": "Peptide Binding Classification on Quantum Computers",
            "updated": "2023-11-27T10:32:31Z",
            "published": "2023-11-27T10:32:31Z",
            "summary": "We conduct an extensive study on using near-term quantum computers for a task\nin the domain of computational biology. By constructing quantum models based on\nparameterised quantum circuits we perform sequence classification on a task\nrelevant to the design of therapeutic proteins, and find competitive\nperformance with classical baselines of similar scale. To study the effect of\nnoise, we run some of the best-performing quantum models with favourable\nresource requirements on emulators of state-of-the-art noisy quantum\nprocessors. We then apply error mitigation methods to improve the signal. We\nfurther execute these quantum models on the Quantinuum H1-1 trapped-ion quantum\nprocessor and observe very close agreement with noiseless exact simulation.\nFinally, we perform feature attribution methods and find that the quantum\nmodels indeed identify sensible relationships, at least as well as the\nclassical baselines. This work constitutes the first proof-of-concept\napplication of near-term quantum computing to a task critical to the design of\ntherapeutic proteins, opening the route toward larger-scale applications in\nthis and related fields, in line with the hardware development roadmaps of\nnear-term quantum technologies.",
            "author": [
                "Charles London",
                "Douglas Brown",
                "Wenduan Xu",
                "Sezen Vatansever",
                "Christopher James Langmead",
                "Dimitri Kartsaklis",
                "Stephen Clark",
                "Konstantinos Meichanetzidis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15696v1",
                "http://arxiv.org/pdf/2311.15696v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15691v1",
            "title": "Automated discovery of trade-off between utility, privacy and fairness\n  in machine learning models",
            "updated": "2023-11-27T10:28:44Z",
            "published": "2023-11-27T10:28:44Z",
            "summary": "Machine learning models are deployed as a central component in decision\nmaking and policy operations with direct impact on individuals' lives. In order\nto act ethically and comply with government regulations, these models need to\nmake fair decisions and protect the users' privacy. However, such requirements\ncan come with decrease in models' performance compared to their potentially\nbiased, privacy-leaking counterparts. Thus the trade-off between fairness,\nprivacy and performance of ML models emerges, and practitioners need a way of\nquantifying this trade-off to enable deployment decisions. In this work we\ninterpret this trade-off as a multi-objective optimization problem, and propose\nPFairDP, a pipeline that uses Bayesian optimization for discovery of\nPareto-optimal points between fairness, privacy and utility of ML models. We\nshow how PFairDP can be used to replicate known results that were achieved\nthrough manual constraint setting process. We further demonstrate effectiveness\nof PFairDP with experiments on multiple models and datasets.",
            "author": [
                "Bogdan Ficiu",
                "Neil D. Lawrence",
                "Andrei Paleyes"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15691v1",
                "http://arxiv.org/pdf/2311.15691v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15685v1",
            "title": "The Battleship Approach to the Low Resource Entity Matching Problem",
            "updated": "2023-11-27T10:18:17Z",
            "published": "2023-11-27T10:18:17Z",
            "summary": "Entity matching, a core data integration problem, is the task of deciding\nwhether two data tuples refer to the same real-world entity. Recent advances in\ndeep learning methods, using pre-trained language models, were proposed for\nresolving entity matching. Although demonstrating unprecedented results, these\nsolutions suffer from a major drawback as they require large amounts of labeled\ndata for training, and, as such, are inadequate to be applied to low resource\nentity matching problems. To overcome the challenge of obtaining sufficient\nlabeled data we offer a new active learning approach, focusing on a selection\nmechanism that exploits unique properties of entity matching. We argue that a\ndistributed representation of a tuple pair indicates its informativeness when\nconsidered among other pairs. This is used consequently in our approach that\niteratively utilizes space-aware considerations. Bringing it all together, we\ntreat the low resource entity matching problem as a Battleship game, hunting\nindicative samples, focusing on positive ones, through awareness of the latent\nspace along with careful planning of next sampling iterations. An extensive\nexperimental analysis shows that the proposed algorithm outperforms\nstate-of-the-art active learning solutions to low resource entity matching, and\nalthough using less samples, can be as successful as state-of-the-art fully\ntrained known algorithms.",
            "author": [
                "Bar Genossar",
                "Avigdor Gal",
                "Roee Shraga"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3626711",
                "http://arxiv.org/abs/2311.15685v1",
                "http://arxiv.org/pdf/2311.15685v1"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15683v2",
            "title": "Ultrasensitive Textile Strain Sensors Redefine Wearable Silent Speech\n  Interfaces with High Machine Learning Efficiency",
            "updated": "2023-12-07T09:16:20Z",
            "published": "2023-11-27T10:17:00Z",
            "summary": "Our research presents a wearable Silent Speech Interface (SSI) technology\nthat excels in device comfort, time-energy efficiency, and speech decoding\naccuracy for real-world use. We developed a biocompatible, durable textile\nchoker with an embedded graphene-based strain sensor, capable of accurately\ndetecting subtle throat movements. This sensor, surpassing other strain sensors\nin sensitivity by 420%, simplifies signal processing compared to traditional\nvoice recognition methods. Our system uses a computationally efficient neural\nnetwork, specifically a one-dimensional convolutional neural network with\nresidual structures, to decode speech signals. This network is energy and\ntime-efficient, reducing computational load by 90% while achieving 95.25%\naccuracy for a 20-word lexicon and swiftly adapting to new users and words with\nminimal samples. This innovation demonstrates a practical, sensitive, and\nprecise wearable SSI suitable for daily communication applications.",
            "author": [
                "Chenyu Tang",
                "Muzi Xu",
                "Wentian Yi",
                "Zibo Zhang",
                "Edoardo Occhipinti",
                "Chaoqun Dong",
                "Dafydd Ravenscroft",
                "Sung-Min Jung",
                "Sanghyo Lee",
                "Shuo Gao",
                "Jong Min Kim",
                "Luigi G. Occhipinti"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15683v2",
                "http://arxiv.org/pdf/2311.15683v2"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.SD",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15682v1",
            "title": "Information theoretic study of the neural geometry induced by category\n  learning",
            "updated": "2023-11-27T10:16:22Z",
            "published": "2023-11-27T10:16:22Z",
            "summary": "Categorization is an important topic both for biological and artificial\nneural networks. Here, we take an information theoretic approach to assess the\nefficiency of the representations induced by category learning. We show that\none can decompose the relevant Bayesian cost into two components, one for the\ncoding part and one for the decoding part. Minimizing the coding cost implies\nmaximizing the mutual information between the set of categories and the neural\nactivities. We analytically show that this mutual information can be written as\nthe sum of two terms that can be interpreted as (i) finding an appropriate\nrepresentation space, and, (ii) building a representation with the appropriate\nmetrics, based on the neural Fisher information on this space. One main\nconsequence is that category learning induces an expansion of neural space near\ndecision boundaries. Finally, we provide numerical illustrations that show how\nFisher information of the coding neural population aligns with the boundaries\nbetween categories.",
            "author": [
                "Laurent Bonnasse-Gahot",
                "Jean-Pierre Nadal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15682v1",
                "http://arxiv.org/pdf/2311.15682v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IT",
                "math.IT",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15679v1",
            "title": "Model-agnostic Body Part Relevance Assessment for Pedestrian Detection",
            "updated": "2023-11-27T10:10:25Z",
            "published": "2023-11-27T10:10:25Z",
            "summary": "Model-agnostic explanation methods for deep learning models are flexible\nregarding usability and availability. However, due to the fact that they can\nonly manipulate input to see changes in output, they suffer from weak\nperformance when used with complex model architectures. For models with large\ninputs as, for instance, in object detection, sampling-based methods like\nKernelSHAP are inefficient due to many computation-heavy forward passes through\nthe model. In this work, we present a framework for using sampling-based\nexplanation models in a computer vision context by body part relevance\nassessment for pedestrian detection. Furthermore, we introduce a novel\nsampling-based method similar to KernelSHAP that shows more robustness for\nlower sampling sizes and, thus, is more efficient for explainability analyses\non large-scale datasets.",
            "author": [
                "Maurice G\u00fcnder",
                "Sneha Banerjee",
                "Rafet Sifa",
                "Christian Bauckhage"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15679v1",
                "http://arxiv.org/pdf/2311.15679v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15673v1",
            "title": "Accelerating Hierarchical Associative Memory: A Deep Equilibrium\n  Approach",
            "updated": "2023-11-27T10:02:12Z",
            "published": "2023-11-27T10:02:12Z",
            "summary": "Hierarchical Associative Memory models have recently been proposed as a\nversatile extension of continuous Hopfield networks. In order to facilitate\nfuture research on such models, especially at scale, we focus on increasing\ntheir simulation efficiency on digital hardware. In particular, we propose two\nstrategies to speed up memory retrieval in these models, which corresponds to\ntheir use at inference, but is equally important during training. First, we\nshow how they can be cast as Deep Equilibrium Models, which allows using faster\nand more stable solvers. Second, inspired by earlier work, we show that\nalternating optimization of the even and odd layers accelerates memory\nretrieval by a factor close to two. Combined, these two techniques allow for a\nmuch faster energy minimization, as shown in our proof-of-concept experimental\nresults. The code is available at https://github.com/cgoemaere/hamdeq",
            "author": [
                "C\u00e9dric Goemaere",
                "Johannes Deleu",
                "Thomas Demeester"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15673v1",
                "http://arxiv.org/pdf/2311.15673v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15668v1",
            "title": "Deformation-Guided Unsupervised Non-Rigid Shape Matching",
            "updated": "2023-11-27T09:55:55Z",
            "published": "2023-11-27T09:55:55Z",
            "summary": "We present an unsupervised data-driven approach for non-rigid shape matching.\nShape matching identifies correspondences between two shapes and is a\nfundamental step in many computer vision and graphics applications. Our\napproach is designed to be particularly robust when matching shapes digitized\nusing 3D scanners that contain fine geometric detail and suffer from different\ntypes of noise including topological noise caused by the coalescence of\nspatially close surface regions. We build on two strategies. First, using a\nhierarchical patch based shape representation we match shapes consistently in a\ncoarse to fine manner, allowing for robustness to noise. This multi-scale\nrepresentation drastically reduces the dimensionality of the problem when\nmatching at the coarsest scale, rendering unsupervised learning feasible.\nSecond, we constrain this hierarchical matching to be reflected in 3D by\nfitting a patch-wise near-rigid deformation model. Using this constraint, we\nleverage spatial continuity at different scales to capture global shape\nproperties, resulting in matchings that generalize well to data with different\ndeformations and noise characteristics. Experiments demonstrate that our\napproach obtains significantly better results on raw 3D scans than\nstate-of-the-art methods, while performing on-par on standard test scenarios.",
            "author": [
                "Aymen Merrouche",
                "Joao Regateiro",
                "Stefanie Wuhrer",
                "Edmond Boyer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15668v1",
                "http://arxiv.org/pdf/2311.15668v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15663v1",
            "title": "Comparison between Tensor Networks and Variational Quantum Classifier",
            "updated": "2023-11-27T09:49:05Z",
            "published": "2023-11-27T09:49:05Z",
            "summary": "The primary objective of this paper is to conduct a comparative analysis\nbetween two Machine Learning approaches: Tensor Networks (TN) and Variational\nQuantum Classifiers (VQC). While both approaches share similarities in their\nrepresentation of the Hilbert space using a logarithmic number of parameters,\nthey diverge in the manifolds they cover. Thus, the aim is to evaluate and\ncompare the expressibility and trainability of these approaches. By conducting\nthis comparison, we can gain insights into potential areas where quantum\nadvantage may be found. Our findings indicate that VQC exhibits advantages in\nterms of speed and accuracy when dealing with data, characterized by a small\nnumber of features. However, for high-dimensional data, TN surpasses VQC in\noverall classification accuracy. We believe that this disparity is primarily\nattributed to challenges encountered during the training of quantum circuits.\nWe want to stress that in this article, we focus on only one particular task\nand do not conduct thorough averaging of the results. Consequently, we\nrecommend considering the results of this article as a unique case without\nexcessive generalization.",
            "author": [
                "Georgios Laskaris",
                "Artem A. Melnikov",
                "Michael R. Perelshtein",
                "Reuben Brasher",
                "Thomas Baeck",
                "Florian Neukart"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15663v1",
                "http://arxiv.org/pdf/2311.15663v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15658v1",
            "title": "Regularization by Texts for Latent Diffusion Inverse Solvers",
            "updated": "2023-11-27T09:40:14Z",
            "published": "2023-11-27T09:40:14Z",
            "summary": "The recent advent of diffusion models has led to significant progress in\nsolving inverse problems, leveraging these models as effective generative\npriors. Nonetheless, challenges related to the ill-posed nature of such\nproblems remain, often due to inherent ambiguities in measurements. Drawing\ninspiration from the human ability to resolve visual ambiguities through\nperceptual biases, here we introduce a novel latent diffusion inverse solver by\nincorporating regularization by texts (TReg). Specifically, TReg applies the\ntextual description of the preconception of the solution during the reverse\nsampling phase, of which description isndynamically reinforced through\nnull-text optimization for adaptive negation. Our comprehensive experimental\nresults demonstrate that TReg successfully mitigates ambiguity in latent\ndiffusion inverse solvers, enhancing their effectiveness and accuracy.",
            "author": [
                "Jeongsol Kim",
                "Geon Yeong Park",
                "Hyungjin Chung",
                "Jong Chul Ye"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15658v1",
                "http://arxiv.org/pdf/2311.15658v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15657v1",
            "title": "Enhancing Diffusion Models with Text-Encoder Reinforcement Learning",
            "updated": "2023-11-27T09:39:45Z",
            "published": "2023-11-27T09:39:45Z",
            "summary": "Text-to-image diffusion models are typically trained to optimize the\nlog-likelihood objective, which presents challenges in meeting specific\nrequirements for downstream tasks, such as image aesthetics and image-text\nalignment. Recent research addresses this issue by refining the diffusion U-Net\nusing human rewards through reinforcement learning or direct backpropagation.\nHowever, many of them overlook the importance of the text encoder, which is\ntypically pretrained and fixed during training. In this paper, we demonstrate\nthat by finetuning the text encoder through reinforcement learning, we can\nenhance the text-image alignment of the results, thereby improving the visual\nquality. Our primary motivation comes from the observation that the current\ntext encoder is suboptimal, often requiring careful prompt adjustment. While\nfine-tuning the U-Net can partially improve performance, it remains suffering\nfrom the suboptimal text encoder. Therefore, we propose to use reinforcement\nlearning with low-rank adaptation to finetune the text encoder based on\ntask-specific rewards, referred as \\textbf{TexForce}. We first show that\nfinetuning the text encoder can improve the performance of diffusion models.\nThen, we illustrate that TexForce can be simply combined with existing U-Net\nfinetuned models to get much better results without additional training.\nFinally, we showcase the adaptability of our method in diverse applications,\nincluding the generation of high-quality face and hand images.",
            "author": [
                "Chaofeng Chen",
                "Annan Wang",
                "Haoning Wu",
                "Liang Liao",
                "Wenxiu Sun",
                "Qiong Yan",
                "Weisi Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15657v1",
                "http://arxiv.org/pdf/2311.15657v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15654v1",
            "title": "Universal Event Detection in Time Series",
            "updated": "2023-11-27T09:33:56Z",
            "published": "2023-11-27T09:33:56Z",
            "summary": "In our previously published work, we introduced a supervised deep learning\nmethod for event detection in multivariate time series data, employing\nregression instead of binary classification. This simplification avoids the\nneed for point-wise labels throughout the entire dataset, relying solely on\nground truth events defined as time points or intervals. In this paper, we\nestablish mathematically that our method is universal, and capable of detecting\nany type of event with arbitrary precision under mild continuity assumptions on\nthe time series. These events may encompass change points, frauds, anomalies,\nphysical occurrences, and more. We substantiate our theoretical results using\nthe universal approximation theorem for feed-forward neural networks (FFN).\nAdditionally, we provide empirical validations that confirm our claims,\ndemonstrating that our method, with a limited number of parameters, outperforms\nother deep learning approaches, particularly for rare events and imbalanced\ndatasets from different domains.",
            "author": [
                "Menouar Azib",
                "Benjamin Renard",
                "Philippe Garnier",
                "Vincent G\u00e9not",
                "Nicolas Andr\u00e9"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15654v1",
                "http://arxiv.org/pdf/2311.15654v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15650v1",
            "title": "SimSIMS: Simulation-based Supernova Ia Model Selection with thousands of\n  latent variables",
            "updated": "2023-11-27T09:22:39Z",
            "published": "2023-11-27T09:22:39Z",
            "summary": "We present principled Bayesian model comparison through simulation-based\nneural classification applied to SN Ia analysis. We validate our approach on\nrealistically simulated SN Ia light curve data, demonstrating its ability to\nrecover posterior model probabilities while marginalizing over >4000 latent\nvariables. The amortized nature of our technique allows us to explore the\ndependence of Bayes factors on the true parameters of simulated data,\ndemonstrating Occam's razor for nested models. When applied to a sample of 86\nlow-redshift SNae Ia from the Carnegie Supernova Project, our method prefers a\nmodel with a single dust law and no magnitude step with host mass, disfavouring\ndifferent dust laws for low- and high-mass hosts with odds in excess of 100:1.",
            "author": [
                "Konstantin Karchev",
                "Roberto Trotta",
                "Christoph Weniger"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15650v1",
                "http://arxiv.org/pdf/2311.15650v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15649v1",
            "title": "RoboGPT: an intelligent agent of making embodied long-term decisions for\n  daily instruction tasks",
            "updated": "2023-11-27T09:20:23Z",
            "published": "2023-11-27T09:20:23Z",
            "summary": "Robotic agents must master common sense and long-term sequential decisions to\nsolve daily tasks through natural language instruction. The developments in\nLarge Language Models (LLMs) in natural language processing have inspired\nefforts to use LLMs in complex robot planning. Despite LLMs' great\ngeneralization and comprehension of instruction tasks, LLMs-generated task\nplans sometimes lack feasibility and correctness. To address the problem, we\npropose a RoboGPT agent\\footnote{our code and dataset will be released soon}\nfor making embodied long-term decisions for daily tasks, with two modules: 1)\nLLMs-based planning with re-plan to break the task into multiple sub-goals; 2)\nRoboSkill individually designed for sub-goals to learn better navigation and\nmanipulation skills. The LLMs-based planning is enhanced with a new robotic\ndataset and re-plan, called RoboGPT. The new robotic dataset of 67k daily\ninstruction tasks is gathered for fine-tuning the Llama model and obtaining\nRoboGPT. RoboGPT planner with strong generalization can plan hundreds of daily\ninstruction tasks. Additionally, a low-computational Re-Plan module is designed\nto allow plans to flexibly adapt to the environment, thereby addressing the\nnomenclature diversity challenge. The proposed RoboGPT agent outperforms SOTA\nmethods on the ALFRED daily tasks. Moreover, RoboGPT planner exceeds SOTA\nLLM-based planners like ChatGPT in task-planning rationality for hundreds of\nunseen daily tasks, and even other domain tasks, while keeping the large\nmodel's original broad application and generality.",
            "author": [
                "Yaran Chen",
                "Wenbo Cui",
                "Yuanwen Chen",
                "Mining Tan",
                "Xinyao Zhang",
                "Dongbin Zhao",
                "He Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15649v1",
                "http://arxiv.org/pdf/2311.15649v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15648v1",
            "title": "Reinforcement Learning from Diffusion Feedback: Q* for Image Search",
            "updated": "2023-11-27T09:20:12Z",
            "published": "2023-11-27T09:20:12Z",
            "summary": "Large vision-language models are steadily gaining personalization\ncapabilities at the cost of fine-tuning or data augmentation. We present two\nmodels for image generation using model-agnostic learning that align semantic\npriors with generative capabilities. RLDF, or Reinforcement Learning from\nDiffusion Feedback, is a singular approach for visual imitation through\nprior-preserving reward function guidance. This employs Q-learning (with\nstandard Q*) for generation and follows a semantic-rewarded trajectory for\nimage search through finite encoding-tailored actions. The second proposed\nmethod, noisy diffusion gradient, is optimization driven. At the root of both\nmethods is a special CFG encoding that we propose for continual semantic\nguidance. Using only a single input image and no text input, RLDF generates\nhigh-quality images over varied domains including retail, sports and\nagriculture showcasing class-consistency and strong visual diversity. Project\nwebsite is available at https://infernolia.github.io/RLDF.",
            "author": [
                "Aboli Marathe"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15648v1",
                "http://arxiv.org/pdf/2311.15648v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15647v1",
            "title": "Bandits Meet Mechanism Design to Combat Clickbait in Online\n  Recommendation",
            "updated": "2023-11-27T09:19:01Z",
            "published": "2023-11-27T09:19:01Z",
            "summary": "We study a strategic variant of the multi-armed bandit problem, which we coin\nthe strategic click-bandit. This model is motivated by applications in online\nrecommendation where the choice of recommended items depends on both the\nclick-through rates and the post-click rewards. Like in classical bandits,\nrewards follow a fixed unknown distribution. However, we assume that the\nclick-rate of each arm is chosen strategically by the arm (e.g., a host on\nAirbnb) in order to maximize the number of times it gets clicked. The algorithm\ndesigner does not know the post-click rewards nor the arms' actions (i.e.,\nstrategically chosen click-rates) in advance, and must learn both values over\ntime. To solve this problem, we design an incentive-aware learning algorithm,\nUCB-S, which achieves two goals simultaneously: (a) incentivizing desirable arm\nbehavior under uncertainty; (b) minimizing regret by learning unknown\nparameters. We characterize all approximate Nash equilibria among arms under\nUCB-S and show a $\\tilde{\\mathcal{O}} (\\sqrt{KT})$ regret bound uniformly in\nevery equilibrium. We also show that incentive-unaware algorithms generally\nfail to achieve low regret in the strategic click-bandit. Finally, we support\nour theoretical results by simulations of strategic arm behavior which confirm\nthe effectiveness and robustness of our proposed incentive design.",
            "author": [
                "Thomas Kleine Buening",
                "Aadirupa Saha",
                "Christos Dimitrakakis",
                "Haifeng Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15647v1",
                "http://arxiv.org/pdf/2311.15647v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.00048v1",
            "title": "Tokenized Model: A Blockchain-Empowered Decentralized Model Ownership\n  Verification Platform",
            "updated": "2023-11-27T09:02:57Z",
            "published": "2023-11-27T09:02:57Z",
            "summary": "With the development of practical deep learning models like generative AI,\ntheir excellent performance has brought huge economic value. For instance,\nChatGPT has attracted more than 100 million users in three months. Since the\nmodel training requires a lot of data and computing power, a well-performing\ndeep learning model is behind a huge effort and cost. Facing various model\nattacks, unauthorized use and abuse from the network that threaten the\ninterests of model owners, in addition to considering legal and other\nadministrative measures, it is equally important to protect the model's\ncopyright from the technical means. By using the model watermarking technology,\nwe point out the possibility of building a unified platform for model ownership\nverification. Given the application history of blockchain in copyright\nverification and the drawbacks of a centralized third-party, this paper\nconsiders combining model watermarking technology and blockchain to build a\nunified model copyright protection platform. By a new solution we called\nTokenized Model, it protects the model's copyright by reliable ownership record\nand verification mechanism. It also promotes the financial value of model by\nconstructing the model's transaction process and contribution shares of a\nmodel. In the typical case study, we also study the various performance under\nusual scenario to verify the effectiveness of this platform.",
            "author": [
                "Yihao Li",
                "Yanyi Lai",
                "Tianchi Liao",
                "Chuan Chen",
                "Zibin Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00048v1",
                "http://arxiv.org/pdf/2312.00048v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15632v1",
            "title": "Application of Long-short Term Memory (LSTM) Model for Forecasting NOx\n  Emission in Pohang Area",
            "updated": "2023-11-27T08:53:21Z",
            "published": "2023-11-27T08:53:21Z",
            "summary": "Emissions of nitric oxide and nitrogen dioxide, which are named as NOx, are a\nmajor environmental and health concern.To react to the climate crisis, the\nSouth Korean government has strengthened NOx emission regulations. An accurate\nNOx prediction model can help companies to meet their NOx emission quotas and\nachieve cost savings. This study focuses on developing a model which forecasts\nthe amount of NOx emissions in Pohang, a heavy industrial city in South Korea\nwith serious air pollution problems.In this study, the Long-short term memory\n(LSTM) modeling is applied to predict the amount of NOx emissions, with missing\ndata imputation using stochastic regression. Two parameters (i.e., time windows\nand learning rates) necessary to run the LSTM model are tested and selected\nusing the Adam optimizer, one of the popular optimization methods in LSTM. I\nfound that the model that I applied achieved the acceptable prediction\nperformance since its Mean Absolute Scaled Error (MASE), the most important\nevaluation criterion, is less than 1. This means that applying the model that I\ndeveloped in predicting future NOx emissions will perform better than a naive\nprediction, a model that simply predicts them based on the last observed data\npoint.",
            "author": [
                "Sangdeok Lee",
                "MinChung Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15632v1",
                "http://arxiv.org/pdf/2311.15632v1"
            ],
            "primary_category": "stat.AP",
            "category": [
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16203v2",
            "title": "ChatTraffic: Text-to-Traffic Generation via Diffusion Model",
            "updated": "2023-11-29T01:53:46Z",
            "published": "2023-11-27T08:52:10Z",
            "summary": "Traffic prediction is one of the most significant foundations in Intelligent\nTransportation Systems (ITS). Traditional traffic prediction methods rely only\non historical traffic data to predict traffic trends and face two main\nchallenges. 1) insensitivity to unusual events. 2) poor performance in\nlong-term prediction. In this work, we explore how generative models combined\nwith text describing the traffic system can be applied for traffic generation\nand name the task Text-to-Traffic Generation (TTG). The key challenge of the\nTTG task is how to associate text with the spatial structure of the road\nnetwork and traffic data for generating traffic situations. To this end, we\npropose ChatTraffic, the first diffusion model for text-to-traffic generation.\nTo guarantee the consistency between synthetic and real data, we augment a\ndiffusion model with the Graph Convolutional Network (GCN) to extract spatial\ncorrelations of traffic data. In addition, we construct a large dataset\ncontaining text-traffic pairs for the TTG task. We benchmarked our model\nqualitatively and quantitatively on the released dataset. The experimental\nresults indicate that ChatTraffic can generate realistic traffic situations\nfrom the text. Our code and dataset are available at\nhttps://github.com/ChyaZhang/ChatTraffic.",
            "author": [
                "Chengyang Zhang",
                "Yong Zhang",
                "Qitan Shao",
                "Bo Li",
                "Yisheng Lv",
                "Xinglin Piao",
                "Baocai Yin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16203v2",
                "http://arxiv.org/pdf/2311.16203v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16496v1",
            "title": "Leveraging Out-of-Domain Data for Domain-Specific Prompt Tuning in\n  Multi-Modal Fake News Detection",
            "updated": "2023-11-27T08:49:26Z",
            "published": "2023-11-27T08:49:26Z",
            "summary": "The spread of fake news using out-of-context images has become widespread and\nis a challenging task in this era of information overload. Since annotating\nhuge amounts of such data requires significant time of domain experts, it is\nimperative to develop methods which can work in limited annotated data\nscenarios. In this work, we explore whether out-of-domain data can help to\nimprove out-of-context misinformation detection (termed here as multi-modal\nfake news detection) of a desired domain, eg. politics, healthcare, etc.\nTowards this goal, we propose a novel framework termed DPOD (Domain-specific\nPrompt-tuning using Out-of-Domain data). First, to compute generalizable\nfeatures, we modify the Vision-Language Model, CLIP to extract features that\nhelps to align the representations of the images and corresponding text\ncaptions of both the in-domain and out-of-domain data in a label-aware manner.\nFurther, we propose a domain-specific prompt learning technique which leverages\nthe training samples of all the available domains based on the the extent they\ncan be useful to the desired domain. Extensive experiments on a large-scale\nbenchmark dataset, namely NewsClippings demonstrate that the proposed framework\nachieves state of-the-art performance, significantly surpassing the existing\napproaches for this challenging task.",
            "author": [
                "Debarshi Brahma",
                "Amartya Bhattacharya",
                "Suraj Nagaje Mahadev",
                "Anmol Asati",
                "Vikas Verma",
                "Soma Biswas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16496v1",
                "http://arxiv.org/pdf/2311.16496v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15627v1",
            "title": "Phonetic-aware speaker embedding for far-field speaker verification",
            "updated": "2023-11-27T08:45:35Z",
            "published": "2023-11-27T08:45:35Z",
            "summary": "When a speaker verification (SV) system operates far from the sound sourced,\nsignificant challenges arise due to the interference of noise and\nreverberation. Studies have shown that incorporating phonetic information into\nspeaker embedding can improve the performance of text-independent SV. Inspired\nby this observation, we propose a joint-training speech recognition and speaker\nrecognition (JTSS) framework to exploit phonetic content for far-field SV. The\nframework encourages speaker embeddings to preserve phonetic information by\nmatching the frame-based feature maps of a speaker embedding network with\nwav2vec's vectors. The intuition is that phonetic information can preserve\nlow-level acoustic dynamics with speaker information and thus partly compensate\nfor the degradation due to noise and reverberation. Results show that the\nproposed framework outperforms the standard speaker embedding on the VOiCES\nChallenge 2019 evaluation set and the VoxCeleb1 test set. This indicates that\nleveraging phonetic information under far-field conditions is effective for\nlearning robust speaker representations.",
            "author": [
                "Zezhong Jin",
                "Youzhi Tu",
                "Man-Wai Mak"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15627v1",
                "http://arxiv.org/pdf/2311.15627v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.AI",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15625v1",
            "title": "Only Positive Cases: 5-fold High-order Attention Interaction Model for\n  Skin Segmentation Derived Classification",
            "updated": "2023-11-27T08:44:00Z",
            "published": "2023-11-27T08:44:00Z",
            "summary": "Computer-aided diagnosis of skin diseases is an important tool. However, the\ninterpretability of computer-aided diagnosis is currently poor. Dermatologists\nand patients cannot intuitively understand the learning and prediction process\nof neural networks, which will lead to a decrease in the credibility of\ncomputer-aided diagnosis. In addition, traditional methods need to be trained\nusing negative samples in order to predict the presence or absence of a lesion,\nbut medical data is often in short supply. In this paper, we propose a multiple\nhigh-order attention interaction model (MHA-UNet) for use in a highly\nexplainable skin lesion segmentation task. MHA-UNet is able to obtain the\npresence or absence of a lesion by explainable reasoning without the need for\ntraining on negative samples. Specifically, we propose a high-order attention\ninteraction mechanism that introduces squeeze attention to a higher level for\nfeature attention. In addition, a multiple high-order attention interaction\n(MHAblock) module is proposed by combining the different features of different\norders. For classifying the presence or absence of lesions, we conducted\nclassification experiments on several publicly available datasets in the\nabsence of negative samples, based on explainable reasoning about the\ninteraction of 5 attention orders of MHAblock. The highest positive detection\nrate obtained from the experiments was 81.0% and the highest negative detection\nrate was 83.5%. For segmentation experiments, comparison experiments of the\nproposed method with 13 medical segmentation models and external validation\nexperiments with 8 state-of-the-art models in three public datasets and our\nclinical dataset demonstrate the state-of-the-art performance of our model. The\ncode is available from https://github.com/wurenkai/MHA-UNet.",
            "author": [
                "Renkai Wu",
                "Yinghao Liu",
                "Pengchen Liang",
                "Qing Chang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15625v1",
                "http://arxiv.org/pdf/2311.15625v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15623v1",
            "title": "Injecting linguistic knowledge into BERT for Dialogue State Tracking",
            "updated": "2023-11-27T08:38:42Z",
            "published": "2023-11-27T08:38:42Z",
            "summary": "Dialogue State Tracking (DST) models often employ intricate neural network\narchitectures, necessitating substantial training data, and their inference\nprocesses lack transparency. This paper proposes a method that extracts\nlinguistic knowledge via an unsupervised framework and subsequently utilizes\nthis knowledge to augment BERT's performance and interpretability in DST tasks.\nThe knowledge extraction procedure is computationally economical and does not\nnecessitate annotations or additional training data. The injection of the\nextracted knowledge necessitates the addition of only simple neural modules. We\nemploy the Convex Polytopic Model (CPM) as a feature extraction tool for DST\ntasks and illustrate that the acquired features correlate with the syntactic\nand semantic patterns in the dialogues. This correlation facilitates a\ncomprehensive understanding of the linguistic features influencing the DST\nmodel's decision-making process. We benchmark this framework on various DST\ntasks and observe a notable improvement in accuracy.",
            "author": [
                "Xiaohan Feng",
                "Xixin Wu",
                "Helen Meng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15623v1",
                "http://arxiv.org/pdf/2311.15623v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15619v1",
            "title": "Align before Adapt: Leveraging Entity-to-Region Alignments for\n  Generalizable Video Action Recognition",
            "updated": "2023-11-27T08:32:28Z",
            "published": "2023-11-27T08:32:28Z",
            "summary": "Large-scale visual-language pre-trained models have achieved significant\nsuccess in various video tasks. However, most existing methods follow an \"adapt\nthen align\" paradigm, which adapts pre-trained image encoders to model\nvideo-level representations and utilizes one-hot or text embedding of the\naction labels for supervision. This paradigm overlooks the challenge of mapping\nfrom static images to complicated activity concepts. In this paper, we propose\na novel \"Align before Adapt\" (ALT) paradigm. Prior to adapting to video\nrepresentation learning, we exploit the entity-to-region alignments for each\nframe. The alignments are fulfilled by matching the region-aware image\nembeddings to an offline-constructed text corpus. With the aligned entities, we\nfeed their text embeddings to a transformer-based video adapter as the queries,\nwhich can help extract the semantics of the most important entities from a\nvideo to a vector. This paradigm reuses the visual-language alignment of VLP\nduring adaptation and tries to explain an action by the underlying entities.\nThis helps understand actions by bridging the gap with complex activity\nsemantics, particularly when facing unfamiliar or unseen categories. ALT\nachieves competitive performance and superior generalizability while requiring\nsignificantly low computational costs. In fully supervised scenarios, it\nachieves 88.1% top-1 accuracy on Kinetics-400 with only 4947 GFLOPs. In 2-shot\nexperiments, ALT outperforms the previous state-of-the-art by 7.1% and 9.2% on\nHMDB-51 and UCF-101, respectively.",
            "author": [
                "Yifei Chen",
                "Dapeng Chen",
                "Ruijin Liu",
                "Sai Zhou",
                "Wenyuan Xue",
                "Wei Peng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15619v1",
                "http://arxiv.org/pdf/2311.15619v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15617v1",
            "title": "VeryFL: A Verify Federated Learning Framework Embedded with Blockchain",
            "updated": "2023-11-27T08:28:08Z",
            "published": "2023-11-27T08:28:08Z",
            "summary": "Blockchain-empowered federated learning (FL) has provoked extensive research\nrecently. Various blockchain-based federated learning algorithm, architecture\nand mechanism have been designed to solve issues like single point failure and\ndata falsification brought by centralized FL paradigm. Moreover, it is easier\nto allocate incentives to nodes with the help of the blockchain. Various\ncentralized federated learning frameworks like FedML, have emerged in the\ncommunity to help boost the research on FL. However, decentralized\nblockchain-based federated learning framework is still missing, which cause\ninconvenience for researcher to reproduce or verify the algorithm performance\nbased on blockchain. Inspired by the above issues, we have designed and\ndeveloped a blockchain-based federated learning framework by embedding Ethereum\nnetwork. This report will present the overall structure of this framework,\nwhich proposes a code practice paradigm for the combination of FL with\nblockchain and, at the same time, compatible with normal FL training task. In\naddition to implement some blockchain federated learning algorithms on smart\ncontract to help execute a FL training, we also propose a model ownership\nauthentication architecture based on blockchain and model watermarking to\nprotect the intellectual property rights of models. These mechanism on\nblockchain shows an underlying support of blockchain for federated learning to\nprovide a verifiable training, aggregation and incentive distribution procedure\nand thus we named this framework VeryFL (A Verify Federated Learninig Framework\nEmbedded with Blockchain). The source code is avaliable on\nhttps://github.com/GTMLLab/VeryFL.",
            "author": [
                "Yihao Li",
                "Yanyi Lai",
                "Chuan Chen",
                "Zibin Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15617v1",
                "http://arxiv.org/pdf/2311.15617v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15614v1",
            "title": "FreeAL: Towards Human-Free Active Learning in the Era of Large Language\n  Models",
            "updated": "2023-11-27T08:23:08Z",
            "published": "2023-11-27T08:23:08Z",
            "summary": "Collecting high-quality labeled data for model training is notoriously\ntime-consuming and labor-intensive for various NLP tasks. While copious\nsolutions, such as active learning for small language models (SLMs) and\nprevalent in-context learning in the era of large language models (LLMs), have\nbeen proposed and alleviate the labeling burden to some extent, their\nperformances are still subject to human intervention. It is still underexplored\nhow to reduce the annotation cost in the LLMs era. To bridge this, we\nrevolutionize traditional active learning and propose an innovative\ncollaborative learning framework FreeAL to interactively distill and filter the\ntask-specific knowledge from LLMs. During collaborative training, an LLM serves\nas an active annotator inculcating its coarse-grained knowledge, while a\ndownstream SLM is incurred as a student to filter out high-quality in-context\nsamples to feedback LLM for the subsequent label refinery. Extensive\nexperiments on eight benchmark datasets demonstrate that FreeAL largely\nenhances the zero-shot performances for both SLM and LLM without any human\nsupervision. The code is available at https://github.com/Justherozen/FreeAL .",
            "author": [
                "Ruixuan Xiao",
                "Yiwen Dong",
                "Junbo Zhao",
                "Runze Wu",
                "Minmin Lin",
                "Gang Chen",
                "Haobo Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15614v1",
                "http://arxiv.org/pdf/2311.15614v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16482v2",
            "title": "Animatable 3D Gaussian: Fast and High-Quality Reconstruction of Multiple\n  Human Avatars",
            "updated": "2023-11-29T11:02:47Z",
            "published": "2023-11-27T08:17:09Z",
            "summary": "Neural radiance fields are capable of reconstructing high-quality drivable\nhuman avatars but are expensive to train and render. To reduce consumption, we\npropose Animatable 3D Gaussian, which learns human avatars from input images\nand poses. We extend 3D Gaussians to dynamic human scenes by modeling a set of\nskinned 3D Gaussians and a corresponding skeleton in canonical space and\ndeforming 3D Gaussians to posed space according to the input poses. We\nintroduce hash-encoded shape and appearance to speed up training and propose\ntime-dependent ambient occlusion to achieve high-quality reconstructions in\nscenes containing complex motions and dynamic shadows. On both novel view\nsynthesis and novel pose synthesis tasks, our method outperforms existing\nmethods in terms of training time, rendering speed, and reconstruction quality.\nOur method can be easily extended to multi-human scenes and achieve comparable\nnovel view synthesis results on a scene with ten people in only 25 seconds of\ntraining.",
            "author": [
                "Yang Liu",
                "Xiang Huang",
                "Minghan Qin",
                "Qinwei Lin",
                "Haoqian Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16482v2",
                "http://arxiv.org/pdf/2311.16482v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15610v1",
            "title": "Bayesian Approach to Linear Bayesian Networks",
            "updated": "2023-11-27T08:10:53Z",
            "published": "2023-11-27T08:10:53Z",
            "summary": "This study proposes the first Bayesian approach for learning high-dimensional\nlinear Bayesian networks. The proposed approach iteratively estimates each\nelement of the topological ordering from backward and its parent using the\ninverse of a partial covariance matrix. The proposed method successfully\nrecovers the underlying structure when Bayesian regularization for the inverse\ncovariance matrix with unequal shrinkage is applied. Specifically, it shows\nthat the number of samples $n = \\Omega( d_M^2 \\log p)$ and $n = \\Omega(d_M^2\np^{2/m})$ are sufficient for the proposed algorithm to learn linear Bayesian\nnetworks with sub-Gaussian and 4m-th bounded-moment error distributions,\nrespectively, where $p$ is the number of nodes and $d_M$ is the maximum degree\nof the moralized graph. The theoretical findings are supported by extensive\nsimulation studies including real data analysis. Furthermore the proposed\nmethod is demonstrated to outperform state-of-the-art frequentist approaches,\nsuch as the BHLSM, LISTEN, and TD algorithms in synthetic data.",
            "author": [
                "Seyong Hwang",
                "Kyoungjae Lee",
                "Sunmin Oh",
                "Gunwoong Park"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15610v1",
                "http://arxiv.org/pdf/2311.15610v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "math.ST",
                "stat.ME",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15609v1",
            "title": "A manometric feature descriptor with linear-SVM to distinguish\n  esophageal contraction vigor",
            "updated": "2023-11-27T08:06:56Z",
            "published": "2023-11-27T08:06:56Z",
            "summary": "n clinical, if a patient presents with nonmechanical obstructive dysphagia,\nesophageal chest pain, and gastro esophageal reflux symptoms, the physician\nwill usually assess the esophageal dynamic function. High-resolution manometry\n(HRM) is a clinically commonly used technique for detection of esophageal\ndynamic function comprehensively and objectively. However, after the results of\nHRM are obtained, doctors still need to evaluate by a variety of parameters.\nThis work is burdensome, and the process is complex. We conducted image\nprocessing of HRM to predict the esophageal contraction vigor for assisting the\nevaluation of esophageal dynamic function. Firstly, we used Feature-Extraction\nand Histogram of Gradients (FE-HOG) to analyses feature of proposal of swallow\n(PoS) to further extract higher-order features. Then we determine the\nclassification of esophageal contraction vigor normal, weak and failed by using\nlinear-SVM according to these features. Our data set includes 3000 training\nsets, 500 validation sets and 411 test sets. After verification our accuracy\nreaches 86.83%, which is higher than other common machine learning methods.",
            "author": [
                "Jialin Liu",
                "Lu Yan",
                "Xiaowei Liu",
                "Yuzhuo Dai",
                "Fanggen Lu",
                "Yuanting Ma",
                "Muzhou Hou",
                "Zheng Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15609v1",
                "http://arxiv.org/pdf/2311.15609v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15605v1",
            "title": "2D Feature Distillation for Weakly- and Semi-Supervised 3D Semantic\n  Segmentation",
            "updated": "2023-11-27T07:57:29Z",
            "published": "2023-11-27T07:57:29Z",
            "summary": "As 3D perception problems grow in popularity and the need for large-scale\nlabeled datasets for LiDAR semantic segmentation increase, new methods arise\nthat aim to reduce the necessity for dense annotations by employing\nweakly-supervised training. However these methods continue to show weak\nboundary estimation and high false negative rates for small objects and distant\nsparse regions. We argue that such weaknesses can be compensated by using RGB\nimages which provide a denser representation of the scene. We propose an\nimage-guidance network (IGNet) which builds upon the idea of distilling high\nlevel feature information from a domain adapted synthetically trained 2D\nsemantic segmentation network. We further utilize a one-way contrastive\nlearning scheme alongside a novel mixing strategy called FOVMix, to combat the\nhorizontal field-of-view mismatch between the two sensors and enhance the\neffects of image guidance. IGNet achieves state-of-the-art results for\nweakly-supervised LiDAR semantic segmentation on ScribbleKITTI, boasting up to\n98% relative performance to fully supervised training with only 8% labeled\npoints, while introducing no additional annotation burden or\ncomputational/memory cost during inference. Furthermore, we show that our\ncontributions also prove effective for semi-supervised training, where IGNet\nclaims state-of-the-art results on both ScribbleKITTI and SemanticKITTI.",
            "author": [
                "Ozan Unal",
                "Dengxin Dai",
                "Lukas Hoyer",
                "Yigit Baran Can",
                "Luc Van Gool"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15605v1",
                "http://arxiv.org/pdf/2311.15605v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15603v1",
            "title": "QuickDrop: Efficient Federated Unlearning by Integrated Dataset\n  Distillation",
            "updated": "2023-11-27T07:53:44Z",
            "published": "2023-11-27T07:53:44Z",
            "summary": "Federated Unlearning (FU) aims to delete specific training data from an ML\nmodel trained using Federated Learning (FL). We introduce QuickDrop, an\nefficient and original FU method that utilizes dataset distillation (DD) to\naccelerate unlearning and drastically reduces computational overhead compared\nto existing approaches. In QuickDrop, each client uses DD to generate a compact\ndataset representative of the original training dataset, called a distilled\ndataset, and uses this compact dataset during unlearning. To unlearn specific\nknowledge from the global model, QuickDrop has clients execute Stochastic\nGradient Ascent with samples from the distilled datasets, thus significantly\nreducing computational overhead compared to conventional FU methods. We further\nincrease the efficiency of QuickDrop by ingeniously integrating DD into the FL\ntraining process. By reusing the gradient updates produced during FL training\nfor DD, the overhead of creating distilled datasets becomes close to\nnegligible. Evaluations on three standard datasets show that, with comparable\naccuracy guarantees, QuickDrop reduces the duration of unlearning by 463.8x\ncompared to model retraining from scratch and 65.1x compared to existing FU\napproaches. We also demonstrate the scalability of QuickDrop with 100 clients\nand show its effectiveness while handling multiple unlearning operations.",
            "author": [
                "Akash Dhasade",
                "Yaohong Ding",
                "Song Guo",
                "Anne-marie Kermarrec",
                "Martijn De Vos",
                "Leijie Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15603v1",
                "http://arxiv.org/pdf/2311.15603v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15600v1",
            "title": "Non-intrusive, transferable model for coupled turbulent channel-porous\n  media flow based upon neural networks",
            "updated": "2023-11-27T07:49:25Z",
            "published": "2023-11-27T07:49:25Z",
            "summary": "Turbulent flow over permeable interface is omnipresent featuring complex flow\ntopology. In this work, a data driven, end to end machine learning model has\nbeen developed to model the turbulent flow in porous media. For the same, we\nhave derived a non linear reduced order model with a deep convolution\nautoencoder network. This model can reduce highly resolved spatial dimensions,\nwhich is a prerequisite for direct numerical simulation. A downstream recurrent\nneural network has been trained to capture the temporal trend of reduced modes,\nthus it is able to provide future evolution of modes. We further evaluate the\ntrained model s capability on a newer dataset with a different porosity. In\nsuch cases, fine tuning could reduce the efforts (up to two order of magnitude)\nto train a model with limited dataset and knowledge and still show a good\nagreement on the mean velocity profile. Leveraging the current model, we find\nthat even quick fine tuning achieving an impressive order of magnitude\nreduction in training time by approximately still results in effective flow\npredictions. This promising discovery encourages the fast development of a\nsubstantial amount of data-driven models tailored for various types of porous\nmedia. The diminished training time substantially lowers the computational cost\nwhen dealing with changing porous topologies, making it feasible to\nsystematically explore interface engineering with different types of porous\nmedia. Overall, the data driven model shows a good agreement, especially for\nthe porous media which can aid the DNS and reduce the burden to resolve this\ncomplex domain during the simulations. The fine tuning is able to reduce the\ntraining cost significantly and maintain an acceptable accuracy when a new flow\ncondition comes into play.",
            "author": [
                "Xu Chu",
                "Sandeep Pandey"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15600v1",
                "http://arxiv.org/pdf/2311.15600v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15598v1",
            "title": "Optimal Clustering of Discrete Mixtures: Binomial, Poisson, Block\n  Models, and Multi-layer Networks",
            "updated": "2023-11-27T07:48:50Z",
            "published": "2023-11-27T07:48:50Z",
            "summary": "In this paper, we first study the fundamental limit of clustering networks\nwhen a multi-layer network is present. Under the mixture multi-layer stochastic\nblock model (MMSBM), we show that the minimax optimal network clustering error\nrate, which takes an exponential form and is characterized by the Renyi\ndivergence between the edge probability distributions of the component\nnetworks. We propose a novel two-stage network clustering method including a\ntensor-based initialization algorithm involving both node and sample splitting\nand a refinement procedure by likelihood-based Lloyd algorithm. Network\nclustering must be accompanied by node community detection. Our proposed\nalgorithm achieves the minimax optimal network clustering error rate and allows\nextreme network sparsity under MMSBM. Numerical simulations and real data\nexperiments both validate that our method outperforms existing methods.\nOftentimes, the edges of networks carry count-type weights. We then extend our\nmethodology and analysis framework to study the minimax optimal clustering\nerror rate for mixture of discrete distributions including Binomial, Poisson,\nand multi-layer Poisson networks. The minimax optimal clustering error rates in\nthese discrete mixtures all take the same exponential form characterized by the\nRenyi divergences. These optimal clustering error rates in discrete mixtures\ncan also be achieved by our proposed two-stage clustering algorithm.",
            "author": [
                "Zhongyuan Lyu",
                "Ting Li",
                "Dong Xia"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15598v1",
                "http://arxiv.org/pdf/2311.15598v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "cs.LG",
                "cs.SI",
                "stat.ME",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15599v1",
            "title": "UniRepLKNet: A Universal Perception Large-Kernel ConvNet for Audio,\n  Video, Point Cloud, Time-Series and Image Recognition",
            "updated": "2023-11-27T07:48:50Z",
            "published": "2023-11-27T07:48:50Z",
            "summary": "Large-kernel convolutional neural networks (ConvNets) have recently received\nextensive research attention, but there are two unresolved and critical issues\nthat demand further investigation. 1) The architectures of existing\nlarge-kernel ConvNets largely follow the design principles of conventional\nConvNets or transformers, while the architectural design for large-kernel\nConvNets remains under-addressed. 2) As transformers have dominated multiple\nmodalities, it remains to be investigated whether ConvNets also have a strong\nuniversal perception ability in domains beyond vision. In this paper, we\ncontribute from two aspects. 1) We propose four architectural guidelines for\ndesigning large-kernel ConvNets, the core of which is to exploit the essential\ncharacteristics of large kernels that distinguish them from small kernels -\nthey can see wide without going deep. Following such guidelines, our proposed\nlarge-kernel ConvNet shows leading performance in image recognition. For\nexample, our models achieve an ImageNet accuracy of 88.0%, ADE20K mIoU of\n55.6%, and COCO box AP of 56.4%, demonstrating better performance and higher\nspeed than a number of recently proposed powerful competitors. 2) We discover\nthat large kernels are the key to unlocking the exceptional performance of\nConvNets in domains where they were originally not proficient. With certain\nmodality-related preprocessing approaches, the proposed model achieves\nstate-of-the-art performance on time-series forecasting and audio recognition\ntasks even without modality-specific customization to the architecture. Code\nand all the models at https://github.com/AILab-CVC/UniRepLKNet.",
            "author": [
                "Xiaohan Ding",
                "Yiyuan Zhang",
                "Yixiao Ge",
                "Sijie Zhao",
                "Lin Song",
                "Xiangyu Yue",
                "Ying Shan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15599v1",
                "http://arxiv.org/pdf/2311.15599v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15594v1",
            "title": "Networked Multiagent Safe Reinforcement Learning for Low-carbon Demand\n  Management in Distribution Network",
            "updated": "2023-11-27T07:41:28Z",
            "published": "2023-11-27T07:41:28Z",
            "summary": "This paper proposes a multiagent based bi-level operation framework for the\nlow-carbon demand management in distribution networks considering the carbon\nemission allowance on the demand side. In the upper level, the aggregate load\nagents optimize the control signals for various types of loads to maximize the\nprofits; in the lower level, the distribution network operator makes optimal\ndispatching decisions to minimize the operational costs and calculates the\ndistribution locational marginal price and carbon intensity. The distributed\nflexible load agent has only incomplete information of the distribution network\nand cooperates with other agents using networked communication. Finally, the\nproblem is formulated into a networked multi-agent constrained Markov decision\nprocess, which is solved using a safe reinforcement learning algorithm called\nconsensus multi-agent constrained policy optimization considering the carbon\nemission allowance for each agent. Case studies with the IEEE 33-bus and\n123-bus distribution network systems demonstrate the effectiveness of the\nproposed approach, in terms of satisfying the carbon emission constraint on\ndemand side, ensuring the safe operation of the distribution network and\npreserving privacy of both sides.",
            "author": [
                "Jichen Zhang",
                "Linwei Sang",
                "Yinliang Xu",
                "Hongbin Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15594v1",
                "http://arxiv.org/pdf/2311.15594v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.AI",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16474v1",
            "title": "Progressive Target-Styled Feature Augmentation for Unsupervised Domain\n  Adaptation on Point Clouds",
            "updated": "2023-11-27T07:33:15Z",
            "published": "2023-11-27T07:33:15Z",
            "summary": "Unsupervised domain adaptation is a critical challenge in the field of point\ncloud analysis, as models trained on one set of data often struggle to perform\nwell in new scenarios due to domain shifts. Previous works tackle the problem\nby using adversarial training or self-supervised learning for feature extractor\nadaptation, but ensuring that features extracted from the target domain can be\ndistinguished by the source-supervised classifier remains challenging. In this\nwork, we propose a novel approach called progressive target-styled feature\naugmentation (PTSFA). Unlike previous works that focus on feature extractor\nadaptation, our PTSFA approach focuses on classifier adaptation. It aims to\nempower the classifier to recognize target-styled source features and\nprogressively adapt to the target domain. To enhance the reliability of\npredictions within the PTSFA framework and encourage discriminative feature\nextraction, we further introduce a new intermediate domain approaching (IDA)\nstrategy. We validate our method on the benchmark datasets, where our method\nachieves new state-of-the-art performance. Our code is available at\nhttps://github.com/xiaoyao3302/PTSFA.",
            "author": [
                "Zicheng Wang",
                "Zhen Zhao",
                "Yiming Wu",
                "Luping Zhou",
                "Dong Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16474v1",
                "http://arxiv.org/pdf/2311.16474v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15587v1",
            "title": "Quantum Langevin Dynamics for Optimization",
            "updated": "2023-11-27T07:25:47Z",
            "published": "2023-11-27T07:25:47Z",
            "summary": "We initiate the study of utilizing Quantum Langevin Dynamics (QLD) to solve\noptimization problems, particularly those non-convex objective functions that\npresent substantial obstacles for traditional gradient descent algorithms.\nSpecifically, we examine the dynamics of a system coupled with an infinite heat\nbath. This interaction induces both random quantum noise and a deterministic\ndamping effect to the system, which nudge the system towards a steady state\nthat hovers near the global minimum of objective functions. We theoretically\nprove the convergence of QLD in convex landscapes, demonstrating that the\naverage energy of the system can approach zero in the low temperature limit\nwith an exponential decay rate correlated with the evolution time. Numerically,\nwe first show the energy dissipation capability of QLD by retracing its origins\nto spontaneous emission. Furthermore, we conduct detailed discussion of the\nimpact of each parameter. Finally, based on the observations when comparing QLD\nwith classical Fokker-Plank-Smoluchowski equation, we propose a time-dependent\nQLD by making temperature and $\\hbar$ time-dependent parameters, which can be\ntheoretically proven to converge better than the time-independent case and also\noutperforms a series of state-of-the-art quantum and classical optimization\nalgorithms in many non-convex landscapes.",
            "author": [
                "Zherui Chen",
                "Yuchen Lu",
                "Hao Wang",
                "Yizhou Liu",
                "Tongyang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15587v1",
                "http://arxiv.org/pdf/2311.15587v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.DS",
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15585v1",
            "title": "Dawning of a New Era in Gravitational Wave Data Analysis: Unveiling\n  Cosmic Mysteries via Artificial Intelligence -- A Systematic Review",
            "updated": "2023-11-27T07:21:24Z",
            "published": "2023-11-27T07:21:24Z",
            "summary": "Background: Artificial intelligence (AI), with its vast capabilities, has\nbecome an integral part of our daily interactions, particularly with the rise\nof sophisticated models like Large Language Models. These advancements have not\nonly transformed human-machine interactions but have also paved the way for\nsignificant breakthroughs in various scientific domains. Aim of review: This\nreview is centered on elucidating the profound impact of AI, especially deep\nlearning, in the field of gravitational wave data analysis (GWDA). We aim to\nhighlight the challenges faced by traditional GWDA methodologies and how AI\nemerges as a beacon of hope, promising enhanced accuracy, real-time processing,\nand adaptability. Key scientific concepts of review: Gravitational wave (GW)\nwaveform modeling stands as a cornerstone in the realm of GW research, serving\nas a sophisticated method to simulate and interpret the intricate patterns and\nsignatures of these cosmic phenomena. This modeling provides a deep\nunderstanding of the astrophysical events that produce gravitational waves.\nNext in line is GW signal detection, a refined technique that meticulously\ncombs through extensive datasets, distinguishing genuine gravitational wave\nsignals from the cacophony of background noise. This detection process is\npivotal in ensuring the authenticity of observed events. Complementing this is\nthe GW parameter estimation, a method intricately designed to decode the\ndetected signals, extracting crucial parameters that offer insights into the\nproperties and origins of the waves. Lastly, the integration of AI for GW\nscience has emerged as a transformative force. AI methodologies harness vast\ncomputational power and advanced algorithms to enhance the efficiency,\naccuracy, and adaptability of data analysis in GW research, heralding a new era\nof innovation and discovery in the field.",
            "author": [
                "Tianyu Zhao",
                "Ruijun Shi",
                "Yue Zhou",
                "Zhoujian Cao",
                "Zhixiang Ren"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15585v1",
                "http://arxiv.org/pdf/2311.15585v1"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc",
                "astro-ph.HE",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15584v1",
            "title": "A deep learning approach for marine snow synthesis and removal",
            "updated": "2023-11-27T07:19:41Z",
            "published": "2023-11-27T07:19:41Z",
            "summary": "Marine snow, the floating particles in underwater images, severely degrades\nthe visibility and performance of human and machine vision systems. This paper\nproposes a novel method to reduce the marine snow interference using deep\nlearning techniques. We first synthesize realistic marine snow samples by\ntraining a Generative Adversarial Network (GAN) model and combine them with\nnatural underwater images to create a paired dataset. We then train a U-Net\nmodel to perform marine snow removal as an image to image translation task. Our\nexperiments show that the U-Net model can effectively remove both synthetic and\nnatural marine snow with high accuracy, outperforming state-of-the-art methods\nsuch as the Median filter and its adaptive variant. We also demonstrate the\nrobustness of our method by testing it on the MSRB dataset, which contains\nsynthetic artifacts that our model has not seen during training. Our method is\na practical and efficient solution for enhancing underwater images affected by\nmarine snow.",
            "author": [
                "Fernando Galetto",
                "Guang Deng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15584v1",
                "http://arxiv.org/pdf/2311.15584v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16201v1",
            "title": "Pre-trained Language Models Do Not Help Auto-regressive Text-to-Image\n  Generation",
            "updated": "2023-11-27T07:19:26Z",
            "published": "2023-11-27T07:19:26Z",
            "summary": "Recent advances in image tokenizers, such as VQ-VAE, have enabled\ntext-to-image generation using auto-regressive methods, similar to language\nmodeling. However, these methods have yet to leverage pre-trained language\nmodels, despite their adaptability to various downstream tasks. In this work,\nwe explore this gap by adapting a pre-trained language model for\nauto-regressive text-to-image generation, and find that pre-trained language\nmodels offer limited help. We provide a two-fold explanation by analyzing\ntokens from each modality. First, we demonstrate that image tokens possess\nsignificantly different semantics compared to text tokens, rendering\npre-trained language models no more effective in modeling them than randomly\ninitialized ones. Second, the text tokens in the image-text datasets are too\nsimple compared to normal language model pre-training data, which causes the\ncatastrophic degradation of language models' capability.",
            "author": [
                "Yuhui Zhang",
                "Brandon McKinzie",
                "Zhe Gan",
                "Vaishaal Shankar",
                "Alexander Toshev"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16201v1",
                "http://arxiv.org/pdf/2311.16201v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15583v1",
            "title": "A Simple Geometric-Aware Indoor Positioning Interpolation Algorithm\n  Based on Manifold Learning",
            "updated": "2023-11-27T07:19:23Z",
            "published": "2023-11-27T07:19:23Z",
            "summary": "Interpolation methodologies have been widely used within the domain of indoor\npositioning systems. However, existing indoor positioning interpolation\nalgorithms exhibit several inherent limitations, including reliance on complex\nmathematical models, limited flexibility, and relatively low precision. To\nenhance the accuracy and efficiency of indoor positioning interpolation\ntechniques, this paper proposes a simple yet powerful geometric-aware\ninterpolation algorithm for indoor positioning tasks. The key to our algorithm\nis to exploit the geometric attributes of the local topological manifold using\nmanifold learning principles. Therefore, instead of constructing complicated\nmathematical models, the proposed algorithm facilitates the more precise and\nefficient estimation of points grounded in the local topological manifold.\nMoreover, our proposed method can be effortlessly integrated into any indoor\npositioning system, thereby bolstering its adaptability. Through a systematic\narray of experiments and comprehensive performance analyses conducted on both\nsimulated and real-world datasets, we demonstrate that the proposed algorithm\nconsistently outperforms the most commonly used and representative\ninterpolation approaches regarding interpolation accuracy and efficiency.\nFurthermore, the experimental results also underscore the substantial practical\nutility of our method and its potential applicability in real-time indoor\npositioning scenarios.",
            "author": [
                "Suorong Yang",
                "Geng Zhang",
                "Jian Zhao",
                "Furao Shen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15583v1",
                "http://arxiv.org/pdf/2311.15583v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15582v1",
            "title": "Lightly Weighted Automatic Audio Parameter Extraction for the Quality\n  Assessment of Consensus Auditory-Perceptual Evaluation of Voice",
            "updated": "2023-11-27T07:19:22Z",
            "published": "2023-11-27T07:19:22Z",
            "summary": "The Consensus Auditory-Perceptual Evaluation of Voice is a widely employed\ntool in clinical voice quality assessment that is significant for streaming\ncommunication among clinical professionals and benchmarking for the\ndetermination of further treatment. Currently, because the assessment relies on\nexperienced clinicians, it tends to be inconsistent, and thus, difficult to\nstandardize. To address this problem, we propose to leverage lightly weighted\nautomatic audio parameter extraction, to increase the clinical relevance,\nreduce the complexity, and enhance the interpretability of voice quality\nassessment. The proposed method utilizes age, sex, and five audio parameters:\njitter, absolute jitter, shimmer, harmonic-to-noise ratio (HNR), and zero\ncrossing. A classical machine learning approach is employed. The result reveals\nthat our approach performs similar to state-of-the-art (SOTA) methods, and\noutperforms the latent representation obtained by using popular audio\npre-trained models. This approach provide insights into the feasibility of\ndifferent feature extraction approaches for voice evaluation. Audio parameters\nsuch as jitter and the HNR are proven to be suitable for characterizing voice\nquality attributes, such as roughness and strain. Conversely, pre-trained\nmodels exhibit limitations in effectively addressing noise-related scorings.\nThis study contributes toward more comprehensive and precise voice quality\nevaluations, achieved by a comprehensively exploring diverse assessment\nmethodologies.",
            "author": [
                "Yi-Heng Lin",
                "Wen-Hsuan Tseng",
                "Li-Chin Chen",
                "Ching-Ting Tan",
                "Yu Tsao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15582v1",
                "http://arxiv.org/pdf/2311.15582v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16200v1",
            "title": "Streaming Lossless Volumetric Compression of Medical Images Using Gated\n  Recurrent Convolutional Neural Network",
            "updated": "2023-11-27T07:19:09Z",
            "published": "2023-11-27T07:19:09Z",
            "summary": "Deep learning-based lossless compression methods offer substantial advantages\nin compressing medical volumetric images. Nevertheless, many learning-based\nalgorithms encounter a trade-off between practicality and compression\nperformance. This paper introduces a hardware-friendly streaming lossless\nvolumetric compression framework, utilizing merely one-thousandth of the model\nweights compared to other learning-based compression frameworks. We propose a\ngated recurrent convolutional neural network that combines diverse\nconvolutional structures and fusion gate mechanisms to capture the inter-slice\ndependencies in volumetric images. Based on such contextual information, we can\npredict the pixel-by-pixel distribution for entropy coding. Guided by\nhardware/software co-design principles, we implement the proposed framework on\nField Programmable Gate Array to achieve enhanced real-time performance.\nExtensive experimental results indicate that our method outperforms traditional\nlossless volumetric compressors and state-of-the-art learning-based lossless\ncompression methods across various medical image benchmarks. Additionally, our\nmethod exhibits robust generalization ability and competitive compression speed",
            "author": [
                "Qianhao Chen",
                "Jietao Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16200v1",
                "http://arxiv.org/pdf/2311.16200v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.AR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15578v1",
            "title": "Experimental Analysis of Large-scale Learnable Vector Storage\n  Compression",
            "updated": "2023-11-27T07:11:47Z",
            "published": "2023-11-27T07:11:47Z",
            "summary": "Learnable embedding vector is one of the most important applications in\nmachine learning, and is widely used in various database-related domains.\nHowever, the high dimensionality of sparse data in recommendation tasks and the\nhuge volume of corpus in retrieval-related tasks lead to a large memory\nconsumption of the embedding table, which poses a great challenge to the\ntraining and deployment of models. Recent research has proposed various methods\nto compress the embeddings at the cost of a slight decrease in model quality or\nthe introduction of other overheads. Nevertheless, the relative performance of\nthese methods remains unclear. Existing experimental comparisons only cover a\nsubset of these methods and focus on limited metrics. In this paper, we perform\na comprehensive comparative analysis and experimental evaluation of embedding\ncompression. We introduce a new taxonomy that categorizes these techniques\nbased on their characteristics and methodologies, and further develop a modular\nbenchmarking framework that integrates 14 representative methods. Under a\nuniform test environment, our benchmark fairly evaluates each approach,\npresents their strengths and weaknesses under different memory budgets, and\nrecommends the best method based on the use case. In addition to providing\nuseful guidelines, our study also uncovers the limitations of current methods\nand suggests potential directions for future research.",
            "author": [
                "Hailin Zhang",
                "Penghao Zhao",
                "Xupeng Miao",
                "Yingxia Shao",
                "Zirui Liu",
                "Tong Yang",
                "Bin Cui"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15578v1",
                "http://arxiv.org/pdf/2311.15578v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DB",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15571v1",
            "title": "Video-based Visible-Infrared Person Re-Identification with Auxiliary\n  Samples",
            "updated": "2023-11-27T06:45:22Z",
            "published": "2023-11-27T06:45:22Z",
            "summary": "Visible-infrared person re-identification (VI-ReID) aims to match persons\ncaptured by visible and infrared cameras, allowing person retrieval and\ntracking in 24-hour surveillance systems. Previous methods focus on learning\nfrom cross-modality person images in different cameras. However, temporal\ninformation and single-camera samples tend to be neglected. To crack this nut,\nin this paper, we first contribute a large-scale VI-ReID dataset named\nBUPTCampus. Different from most existing VI-ReID datasets, it 1) collects\ntracklets instead of images to introduce rich temporal information, 2) contains\npixel-aligned cross-modality sample pairs for better modality-invariant\nlearning, 3) provides one auxiliary set to help enhance the optimization, in\nwhich each identity only appears in a single camera. Based on our constructed\ndataset, we present a two-stream framework as baseline and apply Generative\nAdversarial Network (GAN) to narrow the gap between the two modalities. To\nexploit the advantages introduced by the auxiliary set, we propose a curriculum\nlearning based strategy to jointly learn from both primary and auxiliary sets.\nMoreover, we design a novel temporal k-reciprocal re-ranking method to refine\nthe ranking list with fine-grained temporal correlation cues. Experimental\nresults demonstrate the effectiveness of the proposed methods. We also\nreproduce 9 state-of-the-art image-based and video-based VI-ReID methods on\nBUPTCampus and our methods show substantial superiority to them. The codes and\ndataset are available at: https://github.com/dyhBUPT/BUPTCampus.",
            "author": [
                "Yunhao Du",
                "Cheng Lei",
                "Zhicheng Zhao",
                "Yuan Dong",
                "Fei Su"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15571v1",
                "http://arxiv.org/pdf/2311.15571v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15570v1",
            "title": "UFDA: Universal Federated Domain Adaptation with Practical Assumptions",
            "updated": "2023-11-27T06:38:07Z",
            "published": "2023-11-27T06:38:07Z",
            "summary": "Conventional Federated Domain Adaptation (FDA) approaches usually demand an\nabundance of assumptions, such as label set consistency, which makes them\nsignificantly less feasible for real-world situations and introduces security\nhazards. In this work, we propose a more practical scenario named Universal\nFederated Domain Adaptation (UFDA). It only requires the black-box model and\nthe label set information of each source domain, while the label sets of\ndifferent source domains could be inconsistent and the target-domain label set\nis totally blind. This relaxes the assumptions made by FDA, which are often\nchallenging to meet in real-world cases and diminish model security. To address\nthe UFDA scenario, we propose a corresponding framework called Hot-Learning\nwith Contrastive Label Disambiguation (HCLD), which tackles UFDA's domain\nshifts and category gaps problem by using one-hot outputs from the black-box\nmodels of various source domains. Moreover, to better distinguish the shared\nand unknown classes, we further present a cluster-level strategy named\nMutual-Voting Decision (MVD) to extract robust consensus knowledge across peer\nclasses from both source and target domains. The extensive experiments on three\nbenchmarks demonstrate that our HCLD achieves comparable performance for our\nUFDA scenario with much fewer assumptions, compared to the previous\nmethodologies with many additional assumptions.",
            "author": [
                "Xinhui Liu",
                "Zhenghao Chen",
                "Luping Zhou",
                "Dong Xu",
                "Wei Xi",
                "Gairui Bai",
                "Yihan Zhao",
                "Jizhong Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15570v1",
                "http://arxiv.org/pdf/2311.15570v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15569v1",
            "title": "Improving Adaptability and Generalizability of Efficient Transfer\n  Learning for Vision-Language Models",
            "updated": "2023-11-27T06:37:05Z",
            "published": "2023-11-27T06:37:05Z",
            "summary": "Vision-Language Models (VLMs) like CLIP have demonstrated remarkable\napplicability across a variety of downstream tasks, including zero-shot image\nclassification. Recently, the use of prompts or adapters for efficient transfer\nlearning has gained significant attention for effectively adapting to\ndownstream tasks. However, the roles of vision and text prompts, as well as\nadapters in terms of generalization and transfer difficulty, have been\noverlooked, limiting performance on unseen tasks. In this paper, we empirically\nanalyze how VLMs behave when using vision and text prompts, adapters, and a\ncombination of these components, marking a novel exploration by our study. Our\nobservations find that utilizing vision prompts for class separability and text\nadapters for task adaptation is crucial for adaptability and generalizability.\nMoreover, to improve generalization across every domain, we propose an adaptive\nensemble method that effectively combines the general knowledge of VLMs with\ntask-specific knowledge according to transfer difficulty. Upon experimenting\nwith extensive benchmarks, our method consistently outperforms all baselines,\nparticularly on unseen tasks, demonstrating the effectiveness of our proposed\napproach.",
            "author": [
                "Yongjin Yang",
                "Jongwoo Ko",
                "Se-Young Yun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15569v1",
                "http://arxiv.org/pdf/2311.15569v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15566v1",
            "title": "SpotServe: Serving Generative Large Language Models on Preemptible\n  Instances",
            "updated": "2023-11-27T06:31:17Z",
            "published": "2023-11-27T06:31:17Z",
            "summary": "The high computational and memory requirements of generative large language\nmodels (LLMs) make it challenging to serve them cheaply. This paper aims to\nreduce the monetary cost for serving LLMs by leveraging preemptible GPU\ninstances on modern clouds, which offer accesses to spare GPUs at a much\ncheaper price than regular instances but may be preempted by the cloud at any\ntime. Serving LLMs on preemptible instances requires addressing challenges\ninduced by frequent instance preemptions and the necessity of migrating\ninstances to handle these preemptions.\n  This paper presents SpotServe, the first distributed LLM serving system on\npreemptible instances. Several key techniques in SpotServe realize fast and\nreliable serving of generative LLMs on cheap preemptible instances. First,\nSpotServe dynamically adapts the LLM parallelization configuration for dynamic\ninstance availability and fluctuating workload, while balancing the trade-off\namong the overall throughput, inference latency and monetary costs. Second, to\nminimize the cost of migrating instances for dynamic reparallelization, the\ntask of migrating instances is formulated as a bipartite graph matching\nproblem, which uses the Kuhn-Munkres algorithm to identify an optimal migration\nplan that minimizes communications. Finally, to take advantage of the grace\nperiod offered by modern clouds, we introduce stateful inference recovery, a\nnew inference mechanism that commits inference progress at a much finer\ngranularity and allows SpotServe to cheaply resume inference upon preemption.\nWe evaluate on real spot instance preemption traces and various popular LLMs\nand show that SpotServe can reduce the P99 tail latency by 2.4 - 9.1x compared\nwith the best existing LLM serving systems. We also show that SpotServe can\nleverage the price advantage of preemptive instances, saving 54% monetary cost\ncompared with only using on-demand instances.",
            "author": [
                "Xupeng Miao",
                "Chunan Shi",
                "Jiangfei Duan",
                "Xiaoli Xi",
                "Dahua Lin",
                "Bin Cui",
                "Zhihao Jia"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15566v1",
                "http://arxiv.org/pdf/2311.15566v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15565v2",
            "title": "Evaluating the Efficacy of Hybrid Deep Learning Models in Distinguishing\n  AI-Generated Text",
            "updated": "2023-12-02T21:06:50Z",
            "published": "2023-11-27T06:26:53Z",
            "summary": "My research investigates the use of cutting-edge hybrid deep learning models\nto accurately differentiate between AI-generated text and human writing. I\napplied a robust methodology, utilising a carefully selected dataset comprising\nAI and human texts from various sources, each tagged with instructions.\nAdvanced natural language processing techniques facilitated the analysis of\ntextual features. Combining sophisticated neural networks, the custom model\nenabled it to detect nuanced differences between AI and human content.",
            "author": [
                "Finbarrs Oketunji"
            ],
            "link": [
                "http://dx.doi.org/10.5281/zenodo.10251778",
                "http://arxiv.org/abs/2311.15565v2",
                "http://arxiv.org/pdf/2311.15565v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15564v1",
            "title": "Boot and Switch: Alternating Distillation for Zero-Shot Dense Retrieval",
            "updated": "2023-11-27T06:22:57Z",
            "published": "2023-11-27T06:22:57Z",
            "summary": "Neural 'dense' retrieval models are state of the art for many datasets,\nhowever these models often exhibit limited domain transfer ability. Existing\napproaches to adaptation are unwieldy, such as requiring explicit supervision,\ncomplex model architectures, or massive external models. We present\n$\\texttt{ABEL}$, a simple but effective unsupervised method to enhance passage\nretrieval in zero-shot settings. Our technique follows a straightforward loop:\na dense retriever learns from supervision signals provided by a reranker, and\nsubsequently, the reranker is updated based on feedback from the improved\nretriever. By iterating this loop, the two components mutually enhance one\nanother's performance. Experimental results demonstrate that our unsupervised\n$\\texttt{ABEL}$ model outperforms both leading supervised and unsupervised\nretrievers on the BEIR benchmark. Meanwhile, it exhibits strong adaptation\nabilities to tasks and domains that were unseen during training. By either\nfine-tuning $\\texttt{ABEL}$ on labelled data or integrating it with existing\nsupervised dense retrievers, we achieve state-of-the-art\nresults.\\footnote{Source code is available at\n\\url{https://github.com/Fantabulous-J/BootSwitch}.}",
            "author": [
                "Fan Jiang",
                "Qiongkai Xu",
                "Tom Drummond",
                "Trevor Cohn"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15564v1",
                "http://arxiv.org/pdf/2311.15564v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15551v1",
            "title": "Instruct2Attack: Language-Guided Semantic Adversarial Attacks",
            "updated": "2023-11-27T05:35:49Z",
            "published": "2023-11-27T05:35:49Z",
            "summary": "We propose Instruct2Attack (I2A), a language-guided semantic attack that\ngenerates semantically meaningful perturbations according to free-form language\ninstructions. We make use of state-of-the-art latent diffusion models, where we\nadversarially guide the reverse diffusion process to search for an adversarial\nlatent code conditioned on the input image and text instruction. Compared to\nexisting noise-based and semantic attacks, I2A generates more natural and\ndiverse adversarial examples while providing better controllability and\ninterpretability. We further automate the attack process with GPT-4 to generate\ndiverse image-specific text instructions. We show that I2A can successfully\nbreak state-of-the-art deep neural networks even under strong adversarial\ndefenses, and demonstrate great transferability among a variety of network\narchitectures.",
            "author": [
                "Jiang Liu",
                "Chen Wei",
                "Yuxiang Guo",
                "Heng Yu",
                "Alan Yuille",
                "Soheil Feizi",
                "Chun Pong Lau",
                "Rama Chellappa"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15551v1",
                "http://arxiv.org/pdf/2311.15551v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CR",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16199v1",
            "title": "Symphony: Symmetry-Equivariant Point-Centered Spherical Harmonics for\n  Molecule Generation",
            "updated": "2023-11-27T05:32:21Z",
            "published": "2023-11-27T05:32:21Z",
            "summary": "We present Symphony, an $E(3)$-equivariant autoregressive generative model\nfor 3D molecular geometries that iteratively builds a molecule from molecular\nfragments. Existing autoregressive models such as G-SchNet and G-SphereNet for\nmolecules utilize rotationally invariant features to respect the 3D symmetries\nof molecules. In contrast, Symphony uses message-passing with higher-degree\n$E(3)$-equivariant features. This allows a novel representation of probability\ndistributions via spherical harmonic signals to efficiently model the 3D\ngeometry of molecules. We show that Symphony is able to accurately generate\nsmall molecules from the QM9 dataset, outperforming existing autoregressive\nmodels and approaching the performance of diffusion models.",
            "author": [
                "Ameya Daigavane",
                "Song Kim",
                "Mario Geiger",
                "Tess Smidt"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16199v1",
                "http://arxiv.org/pdf/2311.16199v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.BM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15549v2",
            "title": "From Prediction to Action: Critical Role of Performance Estimation for\n  Machine-Learning-Driven Materials Discovery",
            "updated": "2023-12-07T02:08:13Z",
            "published": "2023-11-27T05:29:43Z",
            "summary": "Materials discovery driven by statistical property models is an iterative\ndecision process, during which an initial data collection is extended with new\ndata proposed by a model-informed acquisition function--with the goal to\nmaximize a certain \"reward\" over time, such as the maximum property value\ndiscovered so far. While the materials science community achieved much progress\nin developing property models that predict well on average with respect to the\ntraining distribution, this form of in-distribution performance measurement is\nnot directly coupled with the discovery reward. This is because an iterative\ndiscovery process has a shifting reward distribution that is\nover-proportionally determined by the model performance for exceptional\nmaterials. We demonstrate this problem using the example of bulk modulus\nmaximization among double perovskite oxides. We find that the in-distribution\npredictive performance suggests random forests as superior to Gaussian process\nregression, while the results are inverse in terms of the discovery rewards. We\nargue that the lack of proper performance estimation methods from pre-computed\ndata collections is a fundamental problem for improving data-driven materials\ndiscovery, and we propose a novel such estimator that, in contrast to na\\\"ive\nreward estimation, successfully predicts Gaussian processes with the \"expected\nimprovement\" acquisition function as the best out of four options in our\ndemonstrational study for double perovskites. Importantly, it does so without\nrequiring the over thousand ab initio computations that were needed to confirm\nthis prediction.",
            "author": [
                "Mario Boley",
                "Felix Luong",
                "Simon Teshuva",
                "Daniel F Schmidt",
                "Lucas Foppa",
                "Matthias Scheffler"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15549v2",
                "http://arxiv.org/pdf/2311.15549v2"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15548v1",
            "title": "Deficiency of Large Language Models in Finance: An Empirical Examination\n  of Hallucination",
            "updated": "2023-11-27T05:27:13Z",
            "published": "2023-11-27T05:27:13Z",
            "summary": "The hallucination issue is recognized as a fundamental deficiency of large\nlanguage models (LLMs), especially when applied to fields such as finance,\neducation, and law. Despite the growing concerns, there has been a lack of\nempirical investigation. In this paper, we provide an empirical examination of\nLLMs' hallucination behaviors in financial tasks. First, we empirically\ninvestigate LLM model's ability of explaining financial concepts and\nterminologies. Second, we assess LLM models' capacity of querying historical\nstock prices. Third, to alleviate the hallucination issue, we evaluate the\nefficacy of four practical methods, including few-shot learning, Decoding by\nContrasting Layers (DoLa), the Retrieval Augmentation Generation (RAG) method\nand the prompt-based tool learning method for a function to generate a query\ncommand. Finally, our major finding is that off-the-shelf LLMs experience\nserious hallucination behaviors in financial tasks. Therefore, there is an\nurgent need to call for research efforts in mitigating LLMs' hallucination.",
            "author": [
                "Haoqiang Kang",
                "Xiao-Yang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15548v1",
                "http://arxiv.org/pdf/2311.15548v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "q-fin.ST"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15547v1",
            "title": "Dataset Distillation in Latent Space",
            "updated": "2023-11-27T05:23:01Z",
            "published": "2023-11-27T05:23:01Z",
            "summary": "Dataset distillation (DD) is a newly emerging research area aiming at\nalleviating the heavy computational load in training models on large datasets.\nIt tries to distill a large dataset into a small and condensed one so that\nmodels trained on the distilled dataset can perform comparably with those\ntrained on the full dataset when performing downstream tasks. Among the\nprevious works in this area, there are three key problems that hinder the\nperformance and availability of the existing DD methods: high time complexity,\nhigh space complexity, and low info-compactness. In this work, we\nsimultaneously attempt to settle these three problems by moving the DD\nprocesses from conventionally used pixel space to latent space. Encoded by a\npretrained generic autoencoder, latent codes in the latent space are naturally\ninfo-compact representations of the original images in much smaller sizes.\nAfter transferring three mainstream DD algorithms to latent space, we\nsignificantly reduce time and space consumption while achieving similar\nperformance, allowing us to distill high-resolution datasets or target at\ngreater data ratio that previous methods have failed. Besides, within the same\nstorage budget, we can also quantitatively deliver more latent codes than\npixel-level images, which further boosts the performance of our methods.",
            "author": [
                "Yuxuan Duan",
                "Jianfu Zhang",
                "Liqing Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15547v1",
                "http://arxiv.org/pdf/2311.15547v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15545v1",
            "title": "Out-of-Distribution Generalized Dynamic Graph Neural Network for Human\n  Albumin Prediction",
            "updated": "2023-11-27T05:21:08Z",
            "published": "2023-11-27T05:21:08Z",
            "summary": "Human albumin is essential for indicating the body's overall health.\nAccurately predicting plasma albumin levels and determining appropriate doses\nare urgent clinical challenges, particularly in critically ill patients, to\nmaintain optimal blood levels. However, human albumin prediction is non-trivial\nthat has to leverage the dynamics of biochemical markers as well as the\nexperience of treating patients. Moreover, the problem of distribution shift is\noften encountered in real clinical data, which may lead to a decline in the\nmodel prediction performance and reduce the reliability of the model's\napplication. In this paper, we propose a framework named Out-of-Distribution\nGeneralized Dynamic Graph Neural Network for Human Albumin Prediction\n(DyG-HAP), which is able to provide accurate albumin predictions for Intensity\nCare Unit (ICU) patients during hospitalization. We first model human albumin\nprediction as a dynamic graph regression problem to model the dynamics and\npatient relationship. Then, we propose a disentangled dynamic graph attention\nmechanism to capture and disentangle the patterns whose relationship to labels\nunder distribution shifts is invariant and variant respectively. Last, we\npropose an invariant dynamic graph regression method to encourage the model to\nrely on invariant patterns to make predictions. Moreover, we propose a dataset\nnamed Albumin level testing and nutritional dosing data for Intensive Care\n(ANIC) for evaluation. Extensive experiments demonstrate the superiority of our\nmethod compared to several baseline methods in human albumin prediction.",
            "author": [
                "Zeyang Zhang",
                "Xingwang Li",
                "Fei Teng",
                "Ning Lin",
                "Xueling Zhu",
                "Xin Wang",
                "Wenwu Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15545v1",
                "http://arxiv.org/pdf/2311.15545v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15544v2",
            "title": "The effect of source disclosure on evaluation of AI-generated messages:\n  A two-part study",
            "updated": "2023-11-28T02:04:58Z",
            "published": "2023-11-27T05:20:47Z",
            "summary": "Advancements in artificial intelligence (AI) over the last decade demonstrate\nthat machines can exhibit communicative behavior and influence how humans\nthink, feel, and behave. In fact, the recent development of ChatGPT has shown\nthat large language models (LLMs) can be leveraged to generate high-quality\ncommunication content at scale and across domains, suggesting that they will be\nincreasingly used in practice. However, many questions remain about how knowing\nthe source of the messages influences recipients' evaluation of and preference\nfor AI-generated messages compared to human-generated messages. This paper\ninvestigated this topic in the context of vaping prevention messaging. In Study\n1, which was pre-registered, we examined the influence of source disclosure on\npeople's evaluation of AI-generated health prevention messages compared to\nhuman-generated messages. We found that source disclosure (i.e., labeling the\nsource of a message as AI vs. human) significantly impacted the evaluation of\nthe messages but did not significantly alter message rankings. In a follow-up\nstudy (Study 2), we examined how the influence of source disclosure may vary by\nthe participants' negative attitudes towards AI. We found a significant\nmoderating effect of negative attitudes towards AI on message evaluation, but\nnot for message selection. However, for those with moderate levels of negative\nattitudes towards AI, source disclosure decreased the preference for\nAI-generated messages. Overall, the results of this series of studies showed a\nslight bias against AI-generated messages once the source was disclosed, adding\nto the emerging area of study that lies at the intersection of AI and\ncommunication.",
            "author": [
                "Sue Lim",
                "Ralf Schm\u00e4lzle"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15544v2",
                "http://arxiv.org/pdf/2311.15544v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15543v1",
            "title": "Beyond Pixels: Exploring Human-Readable SVG Generation for Simple Images\n  with Vision Language Models",
            "updated": "2023-11-27T05:20:11Z",
            "published": "2023-11-27T05:20:11Z",
            "summary": "In the field of computer graphics, the use of vector graphics, particularly\nScalable Vector Graphics (SVG), represents a notable development from\ntraditional pixel-based imagery. SVGs, with their XML-based format, are\ndistinct in their ability to directly and explicitly represent visual elements\nsuch as shape, color, and path. This direct representation facilitates a more\naccurate and logical depiction of graphical elements, enhancing reasoning and\ninterpretability. Recognizing the potential of SVGs, the machine learning\ncommunity has introduced multiple methods for image vectorization. However,\ntransforming images into SVG format while retaining the relational properties\nand context of the original scene remains a key challenge. Most vectorization\nmethods often yield SVGs that are overly complex and not easily interpretable.\nIn response to this challenge, we introduce our method, Simple-SVG-Generation\n(S\\textsuperscript{2}VG\\textsuperscript{2}). Our method focuses on producing\nSVGs that are both accurate and simple, aligning with human readability and\nunderstanding. With simple images, we evaluate our method with reasoning tasks\ntogether with advanced language models, the results show a clear improvement\nover previous SVG generation methods. We also conducted surveys for human\nevaluation on the readability of our generated SVGs, the results also favor our\nmethods.",
            "author": [
                "Tong Zhang",
                "Haoyang Liu",
                "Peiyan Zhang",
                "Yuxuan Cheng",
                "Haohan Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15543v1",
                "http://arxiv.org/pdf/2311.15543v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.03725v1",
            "title": "SCStory: Self-supervised and Continual Online Story Discovery",
            "updated": "2023-11-27T04:50:01Z",
            "published": "2023-11-27T04:50:01Z",
            "summary": "We present a framework SCStory for online story discovery, that helps people\ndigest rapidly published news article streams in real-time without human\nannotations. To organize news article streams into stories, existing approaches\ndirectly encode the articles and cluster them based on representation\nsimilarity. However, these methods yield noisy and inaccurate story discovery\nresults because the generic article embeddings do not effectively reflect the\nstory-indicative semantics in an article and cannot adapt to the rapidly\nevolving news article streams. SCStory employs self-supervised and continual\nlearning with a novel idea of story-indicative adaptive modeling of news\narticle streams. With a lightweight hierarchical embedding module that first\nlearns sentence representations and then article representations, SCStory\nidentifies story-relevant information of news articles and uses them to\ndiscover stories. The embedding module is continuously updated to adapt to\nevolving news streams with a contrastive learning objective, backed up by two\nunique techniques, confidence-aware memory replay and prioritized-augmentation,\nemployed for label absence and data scarcity problems. Thorough experiments on\nreal and the latest news data sets demonstrate that SCStory outperforms\nexisting state-of-the-art algorithms for unsupervised online story discovery.",
            "author": [
                "Susik Yoon",
                "Yu Meng",
                "Dongha Lee",
                "Jiawei Han"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03725v1",
                "http://arxiv.org/pdf/2312.03725v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15536v1",
            "title": "SVRDA: A Web-based Dataset Annotation Tool for Slice-to-Volume\n  Registration",
            "updated": "2023-11-27T04:49:24Z",
            "published": "2023-11-27T04:49:24Z",
            "summary": "Background and Objective: The lack of benchmark datasets has impeded the\ndevelopment of slice-to-volume registration algorithms. Such datasets are\ndifficult to annotate, primarily due to the dimensional difference within data\nand the dearth of task-specific software. We aim to develop a user-friendly\ntool to streamline dataset annotation for slice-to-volume registration.\n  Methods: The proposed tool, named SVRDA, is an installation-free web\napplication for platform-agnostic collaborative dataset annotation. It enables\nefficient transformation manipulation via keyboard shortcuts and smooth case\ntransitions with auto-saving. SVRDA supports configuration-based data loading\nand adheres to the separation of concerns, offering great flexibility and\nextensibility for future research. Various supplementary features have been\nimplemented to facilitate slice-to-volume registration.\n  Results: We validated the effectiveness of SVRDA by indirectly evaluating the\npost-registration segmentation quality on UK Biobank data, observing a dramatic\noverall improvement (24.02% in the Dice Similarity Coefficient and 48.93% in\nthe 95th percentile Hausdorff distance, respectively) supported by highly\nstatistically significant evidence ($p<0.001$).We further showcased the\nclinical usage of SVRDA by integrating it into test-retest T1 quantification on\nin-house magnetic resonance images, leading to more consistent results after\nregistration.\n  Conclusions: SVRDA can facilitate collaborative annotation of benchmark\ndatasets while being potentially applicable to other pipelines incorporating\nslice-to-volume registration. Full source code and documentation are available\nat https://github.com/Roldbach/SVRDA",
            "author": [
                "Weixun Luo",
                "Alexandre Triay Bagur",
                "Paul Aljabar",
                "George Ralli",
                "Sir Michael Brady"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15536v1",
                "http://arxiv.org/pdf/2311.15536v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15530v1",
            "title": "SSIN: Self-Supervised Learning for Rainfall Spatial Interpolation",
            "updated": "2023-11-27T04:23:47Z",
            "published": "2023-11-27T04:23:47Z",
            "summary": "The acquisition of accurate rainfall distribution in space is an important\ntask in hydrological analysis and natural disaster pre-warning. However, it is\nimpossible to install rain gauges on every corner. Spatial interpolation is a\ncommon way to infer rainfall distribution based on available raingauge data.\nHowever, the existing works rely on some unrealistic pre-settings to capture\nspatial correlations, which limits their performance in real scenarios. To\ntackle this issue, we propose the SSIN, which is a novel data-driven\nself-supervised learning framework for rainfall spatial interpolation by mining\nlatent spatial patterns from historical observation data. Inspired by the Cloze\ntask and BERT, we fully consider the characteristics of spatial interpolation\nand design the SpaFormer model based on the Transformer architecture as the\ncore of SSIN. Our main idea is: by constructing rich self-supervision signals\nvia random masking, SpaFormer can learn informative embeddings for raw data and\nthen adaptively model spatial correlations based on rainfall spatial context.\nExtensive experiments on two real-world raingauge datasets show that our method\noutperforms the state-of-the-art solutions. In addition, we take traffic\nspatial interpolation as another use case to further explore the performance of\nour method, and SpaFormer achieves the best performance on one large real-world\ntraffic dataset, which further confirms the effectiveness and generality of our\nmethod.",
            "author": [
                "Jia Li",
                "Yanyan Shen",
                "Lei Chen",
                "Charles Wang Wai NG"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3589321",
                "http://arxiv.org/abs/2311.15530v1",
                "http://arxiv.org/pdf/2311.15530v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "physics.ao-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16198v1",
            "title": "Ultra-short-term multi-step wind speed prediction for wind farms based\n  on adaptive noise reduction technology and temporal convolutional network",
            "updated": "2023-11-27T03:53:19Z",
            "published": "2023-11-27T03:53:19Z",
            "summary": "As an important clean and renewable kind of energy, wind power plays an\nimportant role in coping with energy crisis and environmental pollution.\nHowever, the volatility and intermittency of wind speed restrict the\ndevelopment of wind power. To improve the utilization of wind power, this study\nproposes a new wind speed prediction model based on data noise reduction\ntechnology, temporal convolutional network (TCN), and gated recurrent unit\n(GRU). Firstly, an adaptive data noise reduction algorithm P-SSA is proposed\nbased on singular spectrum analysis (SSA) and Pearson correlation coefficient.\nThe original wind speed is decomposed into multiple subsequences by SSA and\nthen reconstructed. When the Pearson correlation coefficient between the\nreconstructed sequence and the original sequence is greater than 0.99, other\nnoise subsequences are deleted to complete the data denoising. Then, the\nreceptive field of the samples is expanded through the causal convolution and\ndilated convolution of TCN, and the characteristics of wind speed change are\nextracted. Then, the time feature information of the sequence is extracted by\nGRU, and then the wind speed is predicted to form the wind speed sequence\nprediction model of P-SSA-TCN-GRU. The proposed model was validated on three\nwind farms in Shandong Province. The experimental results show that the\nprediction performance of the proposed model is better than that of the\ntraditional model and other models based on TCN, and the wind speed prediction\nof wind farms with high precision and strong stability is realized. The wind\nspeed predictions of this model have the potential to become the data that\nsupport the operation and management of wind farms. The code is available at\nlink.",
            "author": [
                "Haojian Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16198v1",
                "http://arxiv.org/pdf/2311.16198v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16197v1",
            "title": "Generation of patient specific cardiac chamber models using generative\n  neural networks under a Bayesian framework for electroanatomical mapping",
            "updated": "2023-11-27T03:47:33Z",
            "published": "2023-11-27T03:47:33Z",
            "summary": "Electroanatomical mapping is a technique used in cardiology to create a\ndetailed 3D map of the electrical activity in the heart. It is useful for\ndiagnosis, treatment planning and real time guidance in cardiac ablation\nprocedures to treat arrhythmias like atrial fibrillation. A probabilistic\nmachine learning model trained on a library of CT/MRI scans of the heart can be\nused during electroanatomical mapping to generate a patient-specific 3D model\nof the chamber being mapped. The use of probabilistic machine learning models\nunder a Bayesian framework provides a way to quantify uncertainty in results\nand provide a natural framework of interpretability of the model. Here we\nintroduce a Bayesian approach to surface reconstruction of cardiac chamber\nmodels from a sparse 3D point cloud data acquired during electroanatomical\nmapping. We show how probabilistic graphical models trained on segmented CT/MRI\ndata can be used to generate cardiac chamber models from few acquired locations\nthereby reducing procedure time and x-ray exposure. We show how they provide\ninsight into what the neural network learns from the segmented CT/MRI images\nused to train the network, which provides explainability to the resulting\ncardiac chamber models generated by the model.",
            "author": [
                "Sunil Mathew",
                "Jasbir Sra",
                "Daniel B. Rowe"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16197v1",
                "http://arxiv.org/pdf/2311.16197v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15516v1",
            "title": "Active Foundational Models for Fault Diagnosis of Electrical Motors",
            "updated": "2023-11-27T03:25:12Z",
            "published": "2023-11-27T03:25:12Z",
            "summary": "Fault detection and diagnosis of electrical motors are of utmost importance\nin ensuring the safe and reliable operation of several industrial systems.\nDetection and diagnosis of faults at the incipient stage allows corrective\nactions to be taken in order to reduce the severity of faults. The existing\ndata-driven deep learning approaches for machine fault diagnosis rely\nextensively on huge amounts of labeled samples, where annotations are expensive\nand time-consuming. However, a major portion of unlabeled condition monitoring\ndata is not exploited in the training process. To overcome this limitation, we\npropose a foundational model-based Active Learning framework that utilizes less\namount of labeled samples, which are most informative and harnesses a large\namount of available unlabeled data by effectively combining Active Learning and\nContrastive Self-Supervised Learning techniques. It consists of a transformer\nnetwork-based backbone model trained using an advanced nearest-neighbor\ncontrastive self-supervised learning method. This approach empowers the\nbackbone to learn improved representations of samples derived from raw,\nunlabeled vibration data. Subsequently, the backbone can undergo fine-tuning to\naddress a range of downstream tasks, both within the same machines and across\ndifferent machines. The effectiveness of the proposed methodology has been\nassessed through the fine-tuning of the backbone for multiple target tasks\nusing three distinct machine-bearing fault datasets. The experimental\nevaluation demonstrates a superior performance as compared to existing\nstate-of-the-art fault diagnosis methods with less amount of labeled data.",
            "author": [
                "Sriram Anbalagan",
                "Sai Shashank GP",
                "Deepesh Agarwal",
                "Balasubramaniam Natarajan",
                "Babji Srinivasan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15516v1",
                "http://arxiv.org/pdf/2311.15516v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.AI",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15513v1",
            "title": "A Comparative and Experimental Study on Automatic Question Answering\n  Systems and its Robustness against Word Jumbling",
            "updated": "2023-11-27T03:17:09Z",
            "published": "2023-11-27T03:17:09Z",
            "summary": "Question answer generation using Natural Language Processing models is\nubiquitous in the world around us. It is used in many use cases such as the\nbuilding of chat bots, suggestive prompts in google search and also as a way of\nnavigating information in banking mobile applications etc. It is highly\nrelevant because a frequently asked questions (FAQ) list can only have a finite\namount of questions but a model which can perform question answer generation\ncould be able to answer completely new questions that are within the scope of\nthe data. This helps us to be able to answer new questions accurately as long\nas it is a relevant question. In commercial applications, it can be used to\nincrease customer satisfaction and ease of usage. However a lot of data is\ngenerated by humans so it is susceptible to human error and this can adversely\naffect the model's performance and we are investigating this through our work",
            "author": [
                "Shashidhar Reddy Javaji",
                "Haoran Hu",
                "Sai Sameer Vennam",
                "Vijaya Gajanan Buddhavarapu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15513v1",
                "http://arxiv.org/pdf/2311.15513v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15512v1",
            "title": "Sparse Pedestrian Character Learning for Trajectory Prediction",
            "updated": "2023-11-27T03:15:48Z",
            "published": "2023-11-27T03:15:48Z",
            "summary": "Pedestrian trajectory prediction in a first-person view has recently\nattracted much attention due to its importance in autonomous driving. Recent\nwork utilizes pedestrian character information, \\textit{i.e.}, action and\nappearance, to improve the learned trajectory embedding and achieves\nstate-of-the-art performance. However, it neglects the invalid and negative\npedestrian character information, which is harmful to trajectory representation\nand thus leads to performance degradation. To address this issue, we present a\ntwo-stream sparse-character-based network~(TSNet) for pedestrian trajectory\nprediction. Specifically, TSNet learns the negative-removed characters in the\nsparse character representation stream to improve the trajectory embedding\nobtained in the trajectory representation stream. Moreover, to model the\nnegative-removed characters, we propose a novel sparse character graph,\nincluding the sparse category and sparse temporal character graphs, to learn\nthe different effects of various characters in category and temporal\ndimensions, respectively. Extensive experiments on two first-person view\ndatasets, PIE and JAAD, show that our method outperforms existing\nstate-of-the-art methods. In addition, ablation studies demonstrate different\neffects of various characters and prove that TSNet outperforms approaches\nwithout eliminating negative characters.",
            "author": [
                "Yonghao Dong",
                "Le Wang",
                "Sanpin Zhou",
                "Gang Hua",
                "Changyin Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15512v1",
                "http://arxiv.org/pdf/2311.15512v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15510v1",
            "title": "CaesarNeRF: Calibrated Semantic Representation for Few-shot\n  Generalizable Neural Rendering",
            "updated": "2023-11-27T03:09:58Z",
            "published": "2023-11-27T03:09:58Z",
            "summary": "Generalizability and few-shot learning are key challenges in Neural Radiance\nFields (NeRF), often due to the lack of a holistic understanding in pixel-level\nrendering. We introduce CaesarNeRF, an end-to-end approach that leverages\nscene-level CAlibratEd SemAntic Representation along with pixel-level\nrepresentations to advance few-shot, generalizable neural rendering,\nfacilitating a holistic understanding without compromising high-quality\ndetails. CaesarNeRF explicitly models pose differences of reference views to\ncombine scene-level semantic representations, providing a calibrated holistic\nunderstanding. This calibration process aligns various viewpoints with precise\nlocation and is further enhanced by sequential refinement to capture varying\ndetails. Extensive experiments on public datasets, including LLFF, Shiny,\nmip-NeRF 360, and MVImgNet, show that CaesarNeRF delivers state-of-the-art\nperformance across varying numbers of reference views, proving effective even\nwith a single reference image. The project page of this work can be found at\nhttps://haidongz-usc.github.io/project/caesarnerf.",
            "author": [
                "Haidong Zhu",
                "Tianyu Ding",
                "Tianyi Chen",
                "Ilya Zharkov",
                "Ram Nevatia",
                "Luming Liang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15510v1",
                "http://arxiv.org/pdf/2311.15510v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15507v1",
            "title": "Improving Word Sense Disambiguation in Neural Machine Translation with\n  Salient Document Context",
            "updated": "2023-11-27T03:05:48Z",
            "published": "2023-11-27T03:05:48Z",
            "summary": "Lexical ambiguity is a challenging and pervasive problem in machine\ntranslation (\\mt). We introduce a simple and scalable approach to resolve\ntranslation ambiguity by incorporating a small amount of extra-sentential\ncontext in neural \\mt. Our approach requires no sense annotation and no change\nto standard model architectures. Since actual document context is not available\nfor the vast majority of \\mt training data, we collect related sentences for\neach input to construct pseudo-documents. Salient words from pseudo-documents\nare then encoded as a prefix to each source sentence to condition the\ngeneration of the translation. To evaluate, we release \\docmucow, a challenge\nset for translation disambiguation based on the English-German \\mucow\n\\cite{raganato-etal-2020-evaluation} augmented with document IDs. Extensive\nexperiments show that our method translates ambiguous source words better than\nstrong sentence-level baselines and comparable document-level baselines while\nreducing training costs.",
            "author": [
                "Elijah Rippeth",
                "Marine Carpuat",
                "Kevin Duh",
                "Matt Post"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15507v1",
                "http://arxiv.org/pdf/2311.15507v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15502v1",
            "title": "Learning with Complementary Labels Revisited: A Consistent Approach via\n  Negative-Unlabeled Learning",
            "updated": "2023-11-27T02:59:17Z",
            "published": "2023-11-27T02:59:17Z",
            "summary": "Complementary-label learning is a weakly supervised learning problem in which\neach training example is associated with one or multiple complementary labels\nindicating the classes to which it does not belong. Existing consistent\napproaches have relied on the uniform distribution assumption to model the\ngeneration of complementary labels, or on an ordinary-label training set to\nestimate the transition matrix. However, both conditions may not be satisfied\nin real-world scenarios. In this paper, we propose a novel complementary-label\nlearning approach that does not rely on these conditions. We find that\ncomplementary-label learning can be expressed as a set of negative-unlabeled\nbinary classification problems when using the one-versus-rest strategy. This\nobservation allows us to propose a risk-consistent approach with theoretical\nguarantees. Furthermore, we introduce a risk correction approach to address\noverfitting problems when using complex models. We also prove the statistical\nconsistency and convergence rate of the corrected risk estimator. Extensive\nexperimental results on both synthetic and real-world benchmark datasets\nvalidate the superiority of our proposed approach over state-of-the-art\nmethods.",
            "author": [
                "Wei Wang",
                "Takashi Ishida",
                "Yu-Jie Zhang",
                "Gang Niu",
                "Masashi Sugiyama"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15502v1",
                "http://arxiv.org/pdf/2311.15502v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15500v2",
            "title": "Function-constrained Program Synthesis",
            "updated": "2023-12-04T06:24:02Z",
            "published": "2023-11-27T02:55:34Z",
            "summary": "This work introduces (1) a technique that allows large language models (LLMs)\nto leverage user-provided code when solving programming tasks and (2) a method\nto iteratively generate modular sub-functions that can aid future code\ngeneration attempts when the initial code generated by the LLM is inadequate.\nGenerating computer programs in general-purpose programming languages like\nPython poses a challenge for LLMs when instructed to use code provided in the\nprompt. Code-specific LLMs (e.g., GitHub Copilot, CodeLlama2) can generate code\ncompletions in real-time by drawing on all code available in a development\nenvironment. However, restricting code-specific LLMs to use only in-context\ncode is not straightforward, as the model is not explicitly instructed to use\nthe user-provided code and users cannot highlight precisely which snippets of\ncode the model should incorporate into its context. Moreover, current systems\nlack effective recovery methods, forcing users to iteratively re-prompt the\nmodel with modified prompts until a sufficient solution is reached. Our method\ndiffers from traditional LLM-powered code-generation by constraining\ncode-generation to an explicit function set and enabling recovery from failed\nattempts through automatically generated sub-functions. When the LLM cannot\nproduce working code, we generate modular sub-functions to aid subsequent\nattempts at generating functional code. A by-product of our method is a library\nof reusable sub-functions that can solve related tasks, imitating a software\nteam where efficiency scales with experience. We also introduce a new\n\"half-shot\" evaluation paradigm that provides tighter estimates of LLMs' coding\nabilities compared to traditional zero-shot evaluation. Our proposed evaluation\nmethod encourages models to output solutions in a structured format, decreasing\nsyntax errors that can be mistaken for poor coding ability.",
            "author": [
                "Patrick Hajali",
                "Ignas Budvytis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15500v2",
                "http://arxiv.org/pdf/2311.15500v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15497v1",
            "title": "Adaptive Image Registration: A Hybrid Approach Integrating Deep Learning\n  and Optimization Functions for Enhanced Precision",
            "updated": "2023-11-27T02:48:06Z",
            "published": "2023-11-27T02:48:06Z",
            "summary": "Image registration has traditionally been done using two distinct approaches:\nlearning based methods, relying on robust deep neural networks, and\noptimization-based methods, applying complex mathematical transformations to\nwarp images accordingly. Of course, both paradigms offer advantages and\ndisadvantages, and, in this work, we seek to combine their respective strengths\ninto a single streamlined framework, using the outputs of the learning based\nmethod as initial parameters for optimization while prioritizing computational\npower for the image pairs that offer the greatest loss. Our investigations\nshowed that an improvement of 0.3\\% in testing when utilizing the best\nperforming state-of-the-art model as the backbone of the framework, while\nmaintaining the same inference time and with only a 0.8\\% loss in deformation\nfield smoothness.",
            "author": [
                "Gabriel De Araujo",
                "Shanlin Sun",
                "Xiaohui Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15497v1",
                "http://arxiv.org/pdf/2311.15497v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15493v1",
            "title": "UFIN: Universal Feature Interaction Network for Multi-Domain\n  Click-Through Rate Prediction",
            "updated": "2023-11-27T02:30:39Z",
            "published": "2023-11-27T02:30:39Z",
            "summary": "Click-Through Rate (CTR) prediction, which aims to estimate the probability\nof a user clicking on an item, is a key task in online advertising. Numerous\nexisting CTR models concentrate on modeling the feature interactions within a\nsolitary domain, thereby rendering them inadequate for fulfilling the\nrequisites of multi-domain recommendations in real industrial scenarios. Some\nrecent approaches propose intricate architectures to enhance knowledge sharing\nand augment model training across multiple domains. However, these approaches\nencounter difficulties when being transferred to new recommendation domains,\nowing to their reliance on the modeling of ID features (e.g., item id). To\naddress the above issue, we propose the Universal Feature Interaction Network\n(UFIN) approach for CTR prediction. UFIN exploits textual data to learn\nuniversal feature interactions that can be effectively transferred across\ndiverse domains. For learning universal feature representations, we regard the\ntext and feature as two different modalities and propose an encoder-decoder\nnetwork founded on a Large Language Model (LLM) to enforce the transfer of data\nfrom the text modality to the feature modality. Building upon the above\nfoundation, we further develop a mixtureof-experts (MoE) enhanced adaptive\nfeature interaction model to learn transferable collaborative patterns across\nmultiple domains. Furthermore, we propose a multi-domain knowledge distillation\nframework to enhance feature interaction learning. Based on the above methods,\nUFIN can effectively bridge the semantic gap to learn common knowledge across\nvarious domains, surpassing the constraints of ID-based models. Extensive\nexperiments conducted on eight datasets show the effectiveness of UFIN, in both\nmultidomain and cross-platform settings. Our code is available at\nhttps://github.com/RUCAIBox/UFIN.",
            "author": [
                "Zhen Tian",
                "Changwang Zhang",
                "Wayne Xin Zhao",
                "Xin Zhao",
                "Ji-Rong Wen",
                "Zhao Cao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15493v1",
                "http://arxiv.org/pdf/2311.15493v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16485v1",
            "title": "Class-Adaptive Sampling Policy for Efficient Continual Learning",
            "updated": "2023-11-27T02:17:14Z",
            "published": "2023-11-27T02:17:14Z",
            "summary": "Continual learning (CL) aims to acquire new knowledge while preserving\ninformation from previous experiences without forgetting. Though buffer-based\nmethods (i.e., retaining samples from previous tasks) have achieved acceptable\nperformance, determining how to allocate the buffer remains a critical\nchallenge. Most recent research focuses on refining these methods but often\nfails to sufficiently consider the varying influence of samples on the learning\nprocess, and frequently overlooks the complexity of the classes/concepts being\nlearned. Generally, these methods do not directly take into account the\ncontribution of individual classes. However, our investigation indicates that\nmore challenging classes necessitate preserving a larger number of samples\ncompared to less challenging ones. To address this issue, we propose a novel\nmethod and policy named 'Class-Adaptive Sampling Policy' (CASP), which\ndynamically allocates storage space within the buffer. By utilizing concepts of\nclass contribution and difficulty, CASP adaptively manages buffer space,\nallowing certain classes to occupy a larger portion of the buffer while\nreducing storage for others. This approach significantly improves the\nefficiency of knowledge retention and utilization. CASP provides a versatile\nsolution to boost the performance and efficiency of CL. It meets the demand for\ndynamic buffer allocation, accommodating the varying contributions of different\nclasses and their learning complexities over time.",
            "author": [
                "Hossein Rezaei",
                "Mohammad Sabokrou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16485v1",
                "http://arxiv.org/pdf/2311.16485v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15487v1",
            "title": "Global $\\mathcal{L}^2$ minimization with certainty via geometrically\n  adapted gradient descent in Deep Learning",
            "updated": "2023-11-27T02:12:02Z",
            "published": "2023-11-27T02:12:02Z",
            "summary": "We consider the gradient descent flow widely used for the minimization of the\n$\\mathcal{L}^2$ cost function in Deep Learning networks, and introduce two\nmodified versions; one adapted for the overparametrized setting, and the other\nfor the underparametrized setting. Both have a clear and natural invariant\ngeometric meaning, taking into account the pullback vector bundle structure in\nthe overparametrized, and the pushforward vector bundle structure in the\nunderparametrized setting. In the overparametrized case, we prove that,\nprovided that a rank condition holds, all orbits of the modified gradient\ndescent drive the $\\mathcal{L}^2$ cost to its global minimum at a uniform\nexponential convergence rate. We point out relations of the latter to\nsub-Riemannian geometry.",
            "author": [
                "Thomas Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15487v1",
                "http://arxiv.org/pdf/2311.15487v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "math-ph",
                "math.MP",
                "math.OC",
                "stat.ML",
                "57R70, 62M45"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.03724v1",
            "title": "DP-OPT: Make Large Language Model Your Privacy-Preserving Prompt\n  Engineer",
            "updated": "2023-11-27T02:01:10Z",
            "published": "2023-11-27T02:01:10Z",
            "summary": "Large Language Models (LLMs) have emerged as dominant tools for various\ntasks, particularly when tailored for a specific target by prompt tuning.\nNevertheless, concerns surrounding data privacy present obstacles due to the\ntuned prompts' dependency on sensitive private information. A practical\nsolution is to host a local LLM and optimize a soft prompt privately using\ndata. Yet, hosting a local model becomes problematic when model ownership is\nprotected. Alternative methods, like sending data to the model's provider for\ntraining, intensify these privacy issues facing an untrusted provider. In this\npaper, we present a novel solution called Differentially-Private Offsite Prompt\nTuning (DP-OPT) to address this challenge. Our approach involves tuning a\ndiscrete prompt on the client side and then applying it to the desired cloud\nmodels. We demonstrate that prompts suggested by LLMs themselves can be\ntransferred without compromising performance significantly. To ensure that the\nprompts do not leak private information, we introduce the first private prompt\ngeneration mechanism, by a differentially-private (DP) ensemble of in-context\nlearning with private demonstrations. With DP-OPT, generating\nprivacy-preserving prompts by Vicuna-7b can yield competitive performance\ncompared to non-private in-context learning on GPT3.5 or local private prompt\ntuning. Codes are available at https://github.com/VITA-Group/DP-OPT .",
            "author": [
                "Junyuan Hong",
                "Jiachen T. Wang",
                "Chenhui Zhang",
                "Zhangheng Li",
                "Bo Li",
                "Zhangyang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03724v1",
                "http://arxiv.org/pdf/2312.03724v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15480v1",
            "title": "Automatic Time Signature Determination for New Scores Using Lyrics for\n  Latent Rhythmic Structure",
            "updated": "2023-11-27T01:44:02Z",
            "published": "2023-11-27T01:44:02Z",
            "summary": "There has recently been a sharp increase in interest in Artificial\nIntelligence-Generated Content (AIGC). Despite this, musical components such as\ntime signatures have not been studied sufficiently to form an algorithmic\ndetermination approach for new compositions, especially lyrical songs. This is\nlikely because of the neglect of musical details, which is critical for\nconstructing a robust framework. Specifically, time signatures establish the\nfundamental rhythmic structure for almost all aspects of a song, including the\nphrases and notes. In this paper, we propose a novel approach that only uses\nlyrics as input to automatically generate a fitting time signature for lyrical\nsongs and uncover the latent rhythmic structure utilizing explainable machine\nlearning models. In particular, we devise multiple methods that are associated\nwith discovering lyrical patterns and creating new features that simultaneously\ncontain lyrical, rhythmic, and statistical information. In this approach, the\nbest of our experimental results reveal a 97.6% F1 score and a 0.996 Area Under\nthe Curve (AUC) of the Receiver Operating Characteristic (ROC) score. In\nconclusion, our research directly generates time signatures from lyrics\nautomatically for new scores utilizing machine learning, which is an innovative\nidea that approaches an understudied component of musicology and therefore\ncontributes significantly to the future of Artificial Intelligence (AI) music\ngeneration.",
            "author": [
                "Callie C. Liao",
                "Duoduo Liao",
                "Jesse Guessford"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15480v1",
                "http://arxiv.org/pdf/2311.15480v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL",
                "cs.MM",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15477v1",
            "title": "DreamCreature: Crafting Photorealistic Virtual Creatures from\n  Imagination",
            "updated": "2023-11-27T01:24:31Z",
            "published": "2023-11-27T01:24:31Z",
            "summary": "Recent text-to-image (T2I) generative models allow for high-quality synthesis\nfollowing either text instructions or visual examples. Despite their\ncapabilities, these models face limitations in creating new, detailed creatures\nwithin specific categories (e.g., virtual dog or bird species), which are\nvaluable in digital asset creation and biodiversity analysis. To bridge this\ngap, we introduce a novel task, Virtual Creatures Generation: Given a set of\nunlabeled images of the target concepts (e.g., 200 bird species), we aim to\ntrain a T2I model capable of creating new, hybrid concepts within diverse\nbackgrounds and contexts. We propose a new method called DreamCreature, which\nidentifies and extracts the underlying sub-concepts (e.g., body parts of a\nspecific species) in an unsupervised manner. The T2I thus adapts to generate\nnovel concepts (e.g., new bird species) with faithful structures and\nphotorealistic appearance by seamlessly and flexibly composing learned\nsub-concepts. To enhance sub-concept fidelity and disentanglement, we extend\nthe textual inversion technique by incorporating an additional projector and\ntailored attention loss regularization. Extensive experiments on two\nfine-grained image benchmarks demonstrate the superiority of DreamCreature over\nprior methods in both qualitative and quantitative evaluation. Ultimately, the\nlearned sub-concepts facilitate diverse creative applications, including\ninnovative consumer product designs and nuanced property modifications.",
            "author": [
                "Kam Woh Ng",
                "Xiatian Zhu",
                "Yi-Zhe Song",
                "Tao Xiang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15477v1",
                "http://arxiv.org/pdf/2311.15477v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15475v1",
            "title": "MeshGPT: Generating Triangle Meshes with Decoder-Only Transformers",
            "updated": "2023-11-27T01:20:11Z",
            "published": "2023-11-27T01:20:11Z",
            "summary": "We introduce MeshGPT, a new approach for generating triangle meshes that\nreflects the compactness typical of artist-created meshes, in contrast to dense\ntriangle meshes extracted by iso-surfacing methods from neural fields. Inspired\nby recent advances in powerful large language models, we adopt a sequence-based\napproach to autoregressively generate triangle meshes as sequences of\ntriangles. We first learn a vocabulary of latent quantized embeddings, using\ngraph convolutions, which inform these embeddings of the local mesh geometry\nand topology. These embeddings are sequenced and decoded into triangles by a\ndecoder, ensuring that they can effectively reconstruct the mesh. A transformer\nis then trained on this learned vocabulary to predict the index of the next\nembedding given previous embeddings. Once trained, our model can be\nautoregressively sampled to generate new triangle meshes, directly generating\ncompact meshes with sharp edges, more closely imitating the efficient\ntriangulation patterns of human-crafted meshes. MeshGPT demonstrates a notable\nimprovement over state of the art mesh generation methods, with a 9% increase\nin shape coverage and a 30-point enhancement in FID scores across various\ncategories.",
            "author": [
                "Yawar Siddiqui",
                "Antonio Alliegro",
                "Alexey Artemov",
                "Tatiana Tommasi",
                "Daniele Sirigatti",
                "Vladislav Rosov",
                "Angela Dai",
                "Matthias Nie\u00dfner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15475v1",
                "http://arxiv.org/pdf/2311.15475v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15465v1",
            "title": "Quantum Carnot thermal machines revisited: Definition of efficiency and\n  the effects of strong coupling",
            "updated": "2023-11-27T00:35:05Z",
            "published": "2023-11-27T00:35:05Z",
            "summary": "Whether the strong coupling to thermal baths can improve the performance of\nquantum thermal machines remains an open issue under active debate. Here, we\nrevisit quantum thermal machines operating with the quasi-static Carnot cycle\nand aim to unveil the role of strong coupling in maximum efficiency. Our\nanalysis builds upon definitions of excess work and heat derived from an exact\nformulation of the first law of thermodynamics for the working substance, which\ncaptures the non-Gibbsian thermal equilibrium state that emerges at strong\ncouplings during quasi-static isothermal processes. These excess definitions\ndiffer from conventional ones by an energetic cost for maintaining the\nnon-Gibbsian characteristics. With this distinction, we point out that one can\nintroduce two different yet thermodynamically allowed definitions for\nefficiency of both the heat engine and refrigerator modes. We dub them inside\nand outside definitions which differ in the way of defining the gain for the\nthermal machines at strong couplings by either just analyzing the energetics of\nthe working substance or instead evaluating the performance from an external\nsystem upon which the thermal machine acts, respectively. We analytically\ndemonstrate that the inside definition predicts that the Carnot limit remains\nthe upper bound for both operation modes at strong couplings, whereas the\noutside one reveals that strong coupling can suppress the maximum efficiency\nrendering the Carnot limit unattainable. These seemingly incompatible\npredictions thus indicate that it is imperative to first gauge the definition\nfor efficiency before elucidating the exact role of strong coupling, thereby\nshedding light on the on-going investigation on strong-coupling quantum thermal\nmachines.",
            "author": [
                "Junjie Liu",
                "Kenneth A. Jung"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15465v1",
                "http://arxiv.org/pdf/2311.15465v1"
            ],
            "primary_category": "cond-mat.stat-mech",
            "category": [
                "cond-mat.stat-mech"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15463v1",
            "title": "Where to Begin? From Random to Foundation Model Instructed\n  Initialization in Federated Learning for Medical Image Segmentation",
            "updated": "2023-11-27T00:29:10Z",
            "published": "2023-11-27T00:29:10Z",
            "summary": "In medical image analysis, Federated Learning (FL) stands out as a key\ntechnology that enables privacy-preserved, decentralized data processing,\ncrucial for handling sensitive medical data. Currently, most FL models employ\nrandom initialization, which has been proven effective in various instances.\nHowever, given the unique challenges posed by non-IID (independently and\nidentically distributed) data in FL, we propose a novel perspective: exploring\nthe impact of using the foundation model with enormous pre-trained knowledge,\nsuch as the Segment Anything Model (SAM), as an instructive teacher for FL\nmodel initialization in medical image segmentation task. This work for the\nfirst time attempts to utilize the foundation model as an instructive teacher\nfor initialization in FL, assessing its impact on the performance of FL models,\nespecially in non-IID data scenarios. Our empirical evaluation on chest x-ray\nlung segmentation showcases that FL with foundation model instructed\ninitialization not only achieves faster convergence but also improves\nperformance in complex data contexts. These findings offer a new perspective\nfor model initialization in FL.",
            "author": [
                "Ming Li",
                "Guang Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15463v1",
                "http://arxiv.org/pdf/2311.15463v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15460v1",
            "title": "Privacy-Preserving Data Sharing in Agriculture: Enforcing Policy Rules\n  for Secure and Confidential Data Synthesis",
            "updated": "2023-11-27T00:12:47Z",
            "published": "2023-11-27T00:12:47Z",
            "summary": "Big Data empowers the farming community with the information needed to\noptimize resource usage, increase productivity, and enhance the sustainability\nof agricultural practices. The use of Big Data in farming requires the\ncollection and analysis of data from various sources such as sensors,\nsatellites, and farmer surveys. While Big Data can provide the farming\ncommunity with valuable insights and improve efficiency, there is significant\nconcern regarding the security of this data as well as the privacy of the\nparticipants. Privacy regulations, such as the EU GDPR, the EU Code of Conduct\non agricultural data sharing by contractual agreement, and the proposed EU AI\nlaw, have been created to address the issue of data privacy and provide\nspecific guidelines on when and how data can be shared between organizations.\nTo make confidential agricultural data widely available for Big Data analysis\nwithout violating the privacy of the data subjects, we consider\nprivacy-preserving methods of data sharing in agriculture. Deep learning-based\nsynthetic data generation has been proposed for privacy-preserving data\nsharing. However, there is a lack of compliance with documented data privacy\npolicies in such privacy-preserving efforts. In this study, we propose a novel\nframework for enforcing privacy policy rules in privacy-preserving data\ngeneration algorithms. We explore several available agricultural codes of\nconduct, extract knowledge related to the privacy constraints in data, and use\nthe extracted knowledge to define privacy bounds in a privacy-preserving\ngenerative model. We use our framework to generate synthetic agricultural data\nand present experimental results that demonstrate the utility of the synthetic\ndataset in downstream tasks. We also show that our framework can evade\npotential threats and secure data based on applicable regulatory policy rules.",
            "author": [
                "Anantaa Kotal",
                "Lavanya Elluri",
                "Deepti Gupta",
                "Varun Mandalapu",
                "Anupam Joshi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15460v1",
                "http://arxiv.org/pdf/2311.15460v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15459v1",
            "title": "HyperKon: A Self-Supervised Contrastive Network for Hyperspectral Image\n  Analysis",
            "updated": "2023-11-26T23:50:05Z",
            "published": "2023-11-26T23:50:05Z",
            "summary": "The exceptional spectral resolution of hyperspectral imagery enables material\ninsights that are not possible with RGB or multispectral images. Yet, the full\npotential of this data is often underutilized by deep learning techniques due\nto the scarcity of hyperspectral-native CNN backbones. To bridge this gap, we\nintroduce HyperKon, a self-supervised contrastive learning network designed and\ntrained on hyperspectral data from the EnMAP Hyperspectral\nSatellite\\cite{kaufmann2012environmental}. HyperKon uniquely leverages the high\nspectral continuity, range, and resolution of hyperspectral data through a\nspectral attention mechanism and specialized convolutional layers. We also\nperform a thorough ablation study on different kinds of layers, showing their\nperformance in understanding hyperspectral layers. It achieves an outstanding\n98% Top-1 retrieval accuracy and outperforms traditional RGB-trained backbones\nin hyperspectral pan-sharpening tasks. Additionally, in hyperspectral image\nclassification, HyperKon surpasses state-of-the-art methods, indicating a\nparadigm shift in hyperspectral image analysis and underscoring the importance\nof hyperspectral-native backbones.",
            "author": [
                "Daniel L Ayuba",
                "Belen Marti-Cardona",
                "Jean-Yves Guillemaut",
                "Oscar Mendez Maldonado"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15459v1",
                "http://arxiv.org/pdf/2311.15459v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.03723v1",
            "title": "ChatGPT Application In Summarizing An Evolution Of Deep Learning\n  Techniques In Imaging: A Qualitative Study",
            "updated": "2023-11-26T23:22:37Z",
            "published": "2023-11-26T23:22:37Z",
            "summary": "The pursuit of article or text summarization has captured the attention of\nnatural language processing (NLP) practitioners, presenting itself as a\nformidable challenge. ChatGPT 3.5 exhibits the capacity to condense the content\nof up to 3000 tokens into a single page, aiming to retain pivotal information\nfrom a given text across diverse themes. In a conducted qualitative research\nendeavor, we selected seven scientific articles and employed the publicly\navailable ChatGPT service to generate summaries of these articles.\nSubsequently, we engaged six co-authors of the articles in a survey, presenting\nfive questions to evaluate the quality of the summaries compared to the\noriginal content. The findings revealed that the summaries produced by ChatGPT\neffectively encapsulated the crucial information present in the articles,\npreserving the principal message of each manuscript. Nonetheless, there was a\nslight diminishment in the technical depth of the summaries as opposed to the\noriginal articles. As a result, our conclusion underscores ChatGPT's text\nsummarization capability as a potent tool for extracting essential insights in\na manner more aligned with reporting than purely scientific discourse.",
            "author": [
                "Arman Sarraf",
                "Amirabbas Abbaspour"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03723v1",
                "http://arxiv.org/pdf/2312.03723v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15453v1",
            "title": "DISYRE: Diffusion-Inspired SYnthetic REstoration for Unsupervised\n  Anomaly Detection",
            "updated": "2023-11-26T23:07:19Z",
            "published": "2023-11-26T23:07:19Z",
            "summary": "Unsupervised Anomaly Detection (UAD) techniques aim to identify and localize\nanomalies without relying on annotations, only leveraging a model trained on a\ndataset known to be free of anomalies. Diffusion models learn to modify inputs\n$x$ to increase the probability of it belonging to a desired distribution,\ni.e., they model the score function $\\nabla_x \\log p(x)$. Such a score function\nis potentially relevant for UAD, since $\\nabla_x \\log p(x)$ is itself a\npixel-wise anomaly score. However, diffusion models are trained to invert a\ncorruption process based on Gaussian noise and the learned score function is\nunlikely to generalize to medical anomalies. This work addresses the problem of\nhow to learn a score function relevant for UAD and proposes DISYRE:\nDiffusion-Inspired SYnthetic REstoration. We retain the diffusion-like pipeline\nbut replace the Gaussian noise corruption with a gradual, synthetic anomaly\ncorruption so the learned score function generalizes to medical, naturally\noccurring anomalies. We evaluate DISYRE on three common Brain MRI UAD\nbenchmarks and substantially outperform other methods in two out of the three\ntasks.",
            "author": [
                "Sergio Naval Marimont",
                "Matthew Baugh",
                "Vasilis Siomos",
                "Christos Tzelepis",
                "Bernhard Kainz",
                "Giacomo Tarroni"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15453v1",
                "http://arxiv.org/pdf/2311.15453v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16196v1",
            "title": "Variational Exploration Module VEM: A Cloud-Native Optimization and\n  Validation Tool for Geospatial Modeling and AI Workflows",
            "updated": "2023-11-26T23:07:00Z",
            "published": "2023-11-26T23:07:00Z",
            "summary": "Geospatial observations combined with computational models have become key to\nunderstanding the physical systems of our environment and enable the design of\nbest practices to reduce societal harm. Cloud-based deployments help to scale\nup these modeling and AI workflows. Yet, for practitioners to make robust\nconclusions, model tuning and testing is crucial, a resource intensive process\nwhich involves the variation of model input variables. We have developed the\nVariational Exploration Module which facilitates the optimization and\nvalidation of modeling workflows deployed in the cloud by orchestrating\nworkflow executions and using Bayesian and machine learning-based methods to\nanalyze model behavior. User configurations allow the combination of diverse\nsampling strategies in multi-agent environments. The flexibility and robustness\nof the model-agnostic module is demonstrated using real-world applications.",
            "author": [
                "Julian Kuehnert",
                "Hiwot Tadesse",
                "Chris Dearden",
                "Rosie Lickorish",
                "Paolo Fraccaro",
                "Anne Jones",
                "Blair Edwards",
                "Sekou L. Remy",
                "Peter Melling",
                "Tim Culmer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16196v1",
                "http://arxiv.org/pdf/2311.16196v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.03722v1",
            "title": "Leveraging AI-derived Data for Carbon Accounting: Information Extraction\n  from Alternative Sources",
            "updated": "2023-11-26T22:49:41Z",
            "published": "2023-11-26T22:49:41Z",
            "summary": "Carbon accounting is a fundamental building block in our global path to\nemissions reduction and decarbonization, yet many challenges exist in achieving\nreliable and trusted carbon accounting measures. We motivate that carbon\naccounting not only needs to be more data-driven, but also more\nmethodologically sound. We discuss the need for alternative, more diverse data\nsources that can play a significant role on our path to trusted carbon\naccounting procedures and elaborate on not only why, but how Artificial\nIntelligence (AI) in general and Natural Language Processing (NLP) in\nparticular can unlock reasonable access to a treasure trove of alternative data\nsets in light of the recent advances in the field that better enable the\nutilization of unstructured data in this process. We present a case study of\nthe recent developments on real-world data via an NLP-powered analysis using\nOpenAI's GPT API on financial and shipping data. We conclude the paper with a\ndiscussion on how these methods and approaches can be integrated into a broader\nframework for AI-enabled integrative carbon accounting.",
            "author": [
                "Olamide Oladeji",
                "Seyed Shahabeddin Mousavi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03722v1",
                "http://arxiv.org/pdf/2312.03722v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15451v1",
            "title": "Uncertainty-aware Language Modeling for Selective Question Answering",
            "updated": "2023-11-26T22:47:54Z",
            "published": "2023-11-26T22:47:54Z",
            "summary": "We present an automatic large language model (LLM) conversion approach that\nproduces uncertainty-aware LLMs capable of estimating uncertainty with every\nprediction. Our approach is model- and data-agnostic, is\ncomputationally-efficient, and does not rely on external models or systems. We\nevaluate converted models on the selective question answering setting -- to\nanswer as many questions as possible while maintaining a given accuracy,\nforgoing providing predictions when necessary. As part of our results, we test\nBERT and Llama 2 model variants on the SQuAD extractive QA task and the\nTruthfulQA generative QA task. We show that using the uncertainty estimates\nprovided by our approach to selectively answer questions leads to significantly\nhigher accuracy over directly using model probabilities.",
            "author": [
                "Qi Yang",
                "Shreya Ravikumar",
                "Fynn Schmitt-Ulms",
                "Satvik Lolla",
                "Ege Demir",
                "Iaroslav Elistratov",
                "Alex Lavaee",
                "Sadhana Lolla",
                "Elaheh Ahmadi",
                "Daniela Rus",
                "Alexander Amini",
                "Alejandro Perez"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15451v1",
                "http://arxiv.org/pdf/2311.15451v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15448v1",
            "title": "GGNNs : Generalizing GNNs using Residual Connections and Weighted\n  Message Passing",
            "updated": "2023-11-26T22:22:38Z",
            "published": "2023-11-26T22:22:38Z",
            "summary": "Many real-world phenomena can be modeled as a graph, making them extremely\nvaluable due to their ubiquitous presence. GNNs excel at capturing those\nrelationships and patterns within these graphs, enabling effective learning and\nprediction tasks. GNNs are constructed using Multi-Layer Perceptrons (MLPs) and\nincorporate additional layers for message passing to facilitate the flow of\nfeatures among nodes. It is commonly believed that the generalizing power of\nGNNs is attributed to the message-passing mechanism between layers, where nodes\nexchange information with their neighbors, enabling them to effectively capture\nand propagate information across the nodes of a graph. Our technique builds on\nthese results, modifying the message-passing mechanism further: one by weighing\nthe messages before accumulating at each node and another by adding Residual\nconnections. These two mechanisms show significant improvements in learning and\nfaster convergence",
            "author": [
                "Abhinav Raghuvanshi",
                "Kushal Sokke Malleshappa"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15448v1",
                "http://arxiv.org/pdf/2311.15448v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15438v1",
            "title": "ProtoArgNet: Interpretable Image Classification with Super-Prototypes\n  and Argumentation [Technical Report]",
            "updated": "2023-11-26T21:52:47Z",
            "published": "2023-11-26T21:52:47Z",
            "summary": "We propose ProtoArgNet, a novel interpretable deep neural architecture for\nimage classification in the spirit of prototypical-part-learning as found, e.g.\nin ProtoPNet. While earlier approaches associate every class with multiple\nprototypical-parts, ProtoArgNet uses super-prototypes that combine\nprototypical-parts into single prototypical class representations. Furthermore,\nwhile earlier approaches use interpretable classification layers, e.g. logistic\nregression in ProtoPNet, ProtoArgNet improves accuracy with multi-layer\nperceptrons while relying upon an interpretable reading thereof based on a form\nof argumentation. ProtoArgNet is customisable to user cognitive requirements by\na process of sparsification of the multi-layer perceptron/argumentation\ncomponent. Also, as opposed to other prototypical-part-learning approaches,\nProtoArgNet can recognise spatial relations between different\nprototypical-parts that are from different regions in images, similar to how\nCNNs capture relations between patterns recognized in earlier layers.",
            "author": [
                "Hamed Ayoobi",
                "Nico Potyka",
                "Francesca Toni"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15438v1",
                "http://arxiv.org/pdf/2311.15438v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15436v1",
            "title": "Learning to Skip for Language Modeling",
            "updated": "2023-11-26T21:45:53Z",
            "published": "2023-11-26T21:45:53Z",
            "summary": "Overparameterized large-scale language models have impressive generalization\nperformance of in-context few-shot learning. However, most language models\nallocate the same amount of parameters or computation to each token,\ndisregarding the complexity or importance of the input data. We argue that in\nlanguage model pretraining, a variable amount of computation should be assigned\nto different tokens, and this can be efficiently achieved via a simple routing\nmechanism. Different from conventional early stopping techniques where tokens\ncan early exit at only early layers, we propose a more general method that\ndynamically skips the execution of a layer (or module) for any input token with\na binary router. In our extensive evaluation across 24 NLP tasks, we\ndemonstrate that the proposed method can significantly improve the 1-shot\nperformance compared to other competitive baselines only at mild extra cost for\ninference.",
            "author": [
                "Dewen Zeng",
                "Nan Du",
                "Tao Wang",
                "Yuanzhong Xu",
                "Tao Lei",
                "Zhifeng Chen",
                "Claire Cui"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15436v1",
                "http://arxiv.org/pdf/2311.15436v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15435v1",
            "title": "Functional Diffusion",
            "updated": "2023-11-26T21:35:34Z",
            "published": "2023-11-26T21:35:34Z",
            "summary": "We propose a new class of generative diffusion models, called functional\ndiffusion. In contrast to previous work, functional diffusion works on samples\nthat are represented by functions with a continuous domain. Functional\ndiffusion can be seen as an extension of classical diffusion models to an\ninfinite-dimensional domain. Functional diffusion is very versatile as images,\nvideos, audio, 3D shapes, deformations, \\etc, can be handled by the same\nframework with minimal changes. In addition, functional diffusion is especially\nsuited for irregular data or data defined in non-standard domains. In our work,\nwe derive the necessary foundations for functional diffusion and propose a\nfirst implementation based on the transformer architecture. We show generative\nresults on complicated signed distance functions and deformation functions\ndefined on 3D surfaces.",
            "author": [
                "Biao Zhang",
                "Peter Wonka"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15435v1",
                "http://arxiv.org/pdf/2311.15435v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15430v1",
            "title": "Application of batch learning for boosting high-throughput ab initio\n  success rates and reducing computational effort required using data-driven\n  processes",
            "updated": "2023-11-26T21:22:17Z",
            "published": "2023-11-26T21:22:17Z",
            "summary": "The increased availability of computing time, in recent years, allows for\nsystematic high-throughput studies of material classes with the purpose of both\nscreening for materials with remarkable properties and understanding how\nstructural configuration and material composition affect macroscopic attributes\nmanifestation. However, when conducting systematic high-throughput studies, the\nindividual ab initio calculations' success depends on the quality of the chosen\ninput quantities. On a large scale, improving input parameters by trial and\nerror is neither efficient nor systematic. We present a systematic,\nhigh-throughput compatible, and machine learning-based approach to improve the\ninput parameters optimized during a DFT computation or workflow. This approach\nof integrating machine learning into a typical high-throughput workflow\ndemonstrates the advantages and necessary considerations for a systematic study\nof magnetic multilayers of 3$d$ transition metal layers on FCC noble metal\nsubstrates. For 6660 film systems, we were able to improve the overall success\nrate of our high-throughput FLAPW-based structural relaxations from $64.8 \\%$\nto $94.3\\ \\%$ while at the same time requiring $17\\ \\%$ less computational time\nfor each successful relaxation.",
            "author": [
                "Robin Hilgers",
                "Daniel Wortmann",
                "Stefan Bl\u00fcgel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15430v1",
                "http://arxiv.org/pdf/2311.15430v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15426v1",
            "title": "Data Augmentation for Sample Efficient and Robust Document Ranking",
            "updated": "2023-11-26T21:16:12Z",
            "published": "2023-11-26T21:16:12Z",
            "summary": "Contextual ranking models have delivered impressive performance improvements\nover classical models in the document ranking task. However, these highly\nover-parameterized models tend to be data-hungry and require large amounts of\ndata even for fine-tuning. In this paper, we propose data-augmentation methods\nfor effective and robust ranking performance. One of the key benefits of using\ndata augmentation is in achieving sample efficiency or learning effectively\nwhen we have only a small amount of training data. We propose supervised and\nunsupervised data augmentation schemes by creating training data using parts of\nthe relevant documents in the query-document pairs. We then adapt a family of\ncontrastive losses for the document ranking task that can exploit the augmented\ndata to learn an effective ranking model. Our extensive experiments on subsets\nof the MS MARCO and TREC-DL test sets show that data augmentation, along with\nthe ranking-adapted contrastive losses, results in performance improvements\nunder most dataset sizes. Apart from sample efficiency, we conclusively show\nthat data augmentation results in robust models when transferred to\nout-of-domain benchmarks. Our performance improvements in in-domain and more\nprominently in out-of-domain benchmarks show that augmentation regularizes the\nranking model and improves its robustness and generalization capability.",
            "author": [
                "Abhijit Anand",
                "Jurek Leonhardt",
                "Jaspreet Singh",
                "Koustav Rudra",
                "Avishek Anand"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15426v1",
                "http://arxiv.org/pdf/2311.15426v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15425v1",
            "title": "Machine-Generated Text Detection using Deep Learning",
            "updated": "2023-11-26T21:16:01Z",
            "published": "2023-11-26T21:16:01Z",
            "summary": "Our research focuses on the crucial challenge of discerning text produced by\nLarge Language Models (LLMs) from human-generated text, which holds\nsignificance for various applications. With ongoing discussions about attaining\na model with such functionality, we present supporting evidence regarding the\nfeasibility of such models. We evaluated our models on multiple datasets,\nincluding Twitter Sentiment, Football Commentary, Project Gutenberg, PubMedQA,\nand SQuAD, confirming the efficacy of the enhanced detection approaches. These\ndatasets were sampled with intricate constraints encompassing every\npossibility, laying the foundation for future research. We evaluate\nGPT-3.5-Turbo against various detectors such as SVM, RoBERTa-base, and\nRoBERTa-large. Based on the research findings, the results predominantly relied\non the sequence length of the sentence.",
            "author": [
                "Raghav Gaggar",
                "Ashish Bhagchandani",
                "Harsh Oza"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15425v1",
                "http://arxiv.org/pdf/2311.15425v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "I.2.7; I.5.4; I.2.6"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15423v1",
            "title": "Machine Learning-based estimation and explainable artificial\n  intelligence-supported interpretation of the critical temperature from\n  magnetic ab initio Heusler alloys data",
            "updated": "2023-11-26T21:11:12Z",
            "published": "2023-11-26T21:11:12Z",
            "summary": "Machine Learning (ML) has impacted numerous areas of materials science, most\nprominently improving molecular simulations, where force fields were trained on\npreviously relaxed structures. One natural next step is to predict material\nproperties beyond structure. In this work, we investigate the applicability and\nexplainability of ML methods in the use case of estimating the critical\ntemperature for magnetic Heusler alloys calculated using ab initio methods\ndetermined materials-specific magnetic interactions and a subsequent Monte\nCarlo (MC) approach. We compare the performance of regression and\nclassification models to predict the range of the critical temperature of given\ncompounds without performing the MC calculations. Since the MC calculation\nrequires computational resources in the same order of magnitude as the\ndensity-functional theory (DFT) calculation, it would be advantageous to\nreplace either step with a less computationally intensive method such as ML. We\ndiscuss the necessity to generate the magnetic ab initio results to make a\nquantitative prediction of the critical temperature. We used state-of-the-art\nexplainable artificial intelligence (XAI) methods to extract physical relations\nand deepen our understanding of patterns learned by our models from the\nexamined data.",
            "author": [
                "Robin Hilgers",
                "Daniel Wortmann",
                "Stefan Bl\u00fcgel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15423v1",
                "http://arxiv.org/pdf/2311.15423v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15419v1",
            "title": "Frobenius-Type Norms and Inner Products of Matrices and Linear Maps with\n  Applications to Neural Network Training",
            "updated": "2023-11-26T21:03:25Z",
            "published": "2023-11-26T21:03:25Z",
            "summary": "The Frobenius norm is a frequent choice of norm for matrices. In particular,\nthe underlying Frobenius inner product is typically used to evaluate the\ngradient of an objective with respect to matrix variable, such as those\noccuring in the training of neural networks. We provide a broader view on the\nFrobenius norm and inner product for linear maps or matrices, and establish\ntheir dependence on inner products in the domain and co-domain spaces. This\nshows that the classical Frobenius norm is merely one special element of a\nfamily of more general Frobenius-type norms. The significant extra freedom\nfurnished by this realization can be used, among other things, to precondition\nneural network training.",
            "author": [
                "Roland Herzog",
                "Frederik K\u00f6hne",
                "Leonie Kreis",
                "Anton Schiela"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15419v1",
                "http://arxiv.org/pdf/2311.15419v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15415v1",
            "title": "GAN-Based LiDAR Intensity Simulation",
            "updated": "2023-11-26T20:44:09Z",
            "published": "2023-11-26T20:44:09Z",
            "summary": "Realistic vehicle sensor simulation is an important element in developing\nautonomous driving. As physics-based implementations of visual sensors like\nLiDAR are complex in practice, data-based approaches promise solutions. Using\npairs of camera images and LiDAR scans from real test drives, GANs can be\ntrained to translate between them. For this process, we contribute two\nadditions. First, we exploit the camera images, acquiring segmentation data and\ndense depth maps as additional input for training. Second, we test the\nperformance of the LiDAR simulation by testing how well an object detection\nnetwork generalizes between real and synthetic point clouds to enable\nevaluation without ground truth point clouds. Combining both, we simulate LiDAR\npoint clouds and demonstrate their realism.",
            "author": [
                "Richard Marcus",
                "Felix Gabel",
                "Niklas Knoop",
                "Marc Stamminger"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-031-39059-3_28",
                "http://arxiv.org/abs/2311.15415v1",
                "http://arxiv.org/pdf/2311.15415v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15414v2",
            "title": "KOPPA: Improving Prompt-based Continual Learning with Key-Query\n  Orthogonal Projection and Prototype-based One-Versus-All",
            "updated": "2023-11-30T15:26:20Z",
            "published": "2023-11-26T20:35:19Z",
            "summary": "Drawing inspiration from prompt tuning techniques applied to Large Language\nModels, recent methods based on pre-trained ViT networks have achieved\nremarkable results in the field of Continual Learning. Specifically, these\napproaches propose to maintain a set of prompts and allocate a subset of them\nto learn each task using a key-query matching strategy. However, they may\nencounter limitations when lacking control over the correlations between old\ntask queries and keys of future tasks, the shift of features in the latent\nspace, and the relative separation of latent vectors learned in independent\ntasks. In this work, we introduce a novel key-query learning strategy based on\northogonal projection, inspired by model-agnostic meta-learning, to enhance\nprompt matching efficiency and address the challenge of shifting features.\nFurthermore, we introduce a One-Versus-All (OVA) prototype-based component that\nenhances the classification head distinction. Experimental results on benchmark\ndatasets demonstrate that our method empowers the model to achieve results\nsurpassing those of current state-of-the-art approaches by a large margin of up\nto 20%.",
            "author": [
                "Quyen Tran",
                "Lam Tran",
                "Khoat Than",
                "Toan Tran",
                "Dinh Phung",
                "Trung Le"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15414v2",
                "http://arxiv.org/pdf/2311.15414v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15408v1",
            "title": "Techniques for learning sparse Pauli-Lindblad noise models",
            "updated": "2023-11-26T20:17:20Z",
            "published": "2023-11-26T20:17:20Z",
            "summary": "Error-mitigation techniques such as probabilistic error cancellation and\nzero-noise extrapolation benefit from accurate noise models. The sparse\nPauli-Lindblad noise model is one of the most successful models for those\napplications. In existing implementations, the model decomposes into a series\nof simple Pauli channels with one- and two-local terms that follow the qubit\ntopology. While the model has been shown to accurately capture the noise in\ncontemporary superconducting quantum processors for error mitigation, it is\nimportant to consider higher-weight terms and effects beyond nearest-neighbor\ninteractions. For such extended models to remain practical, however, we need to\nensure that they can be learned efficiently. In this work we present new\ntechniques that accomplish exactly this. We introduce twirling based on Pauli\nrotations, which enables us to automatically generate single-qubit learning\ncorrection sequences and reduce the number of unique fidelities that need to be\nlearned. In addition, we propose a basis-selection strategy that leverages\ngraph coloring and uniform covering arrays to minimize the number of learning\nbases. Taken together, these techniques ensure that the learning of the\nextended noise models remains efficient, despite their increased complexity.",
            "author": [
                "Ewout van den Berg",
                "Pawel Wocjan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15408v1",
                "http://arxiv.org/pdf/2311.15408v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15404v1",
            "title": "Applying statistical learning theory to deep learning",
            "updated": "2023-11-26T20:00:53Z",
            "published": "2023-11-26T20:00:53Z",
            "summary": "Although statistical learning theory provides a robust framework to\nunderstand supervised learning, many theoretical aspects of deep learning\nremain unclear, in particular how different architectures may lead to inductive\nbias when trained using gradient based methods. The goal of these lectures is\nto provide an overview of some of the main questions that arise when attempting\nto understand deep learning from a learning theory perspective. After a brief\nreminder on statistical learning theory and stochastic optimization, we discuss\nimplicit bias in the context of benign overfitting. We then move to a general\ndescription of the mirror descent algorithm, showing how we may go back and\nforth between a parameter space and the corresponding function space for a\ngiven learning problem, as well as how the geometry of the learning problem may\nbe represented by a metric tensor. Building on this framework, we provide a\ndetailed study of the implicit bias of gradient descent on linear diagonal\nnetworks for various regression tasks, showing how the loss function, scale of\nparameters at initialization and depth of the network may lead to various forms\nof implicit bias, in particular transitioning between kernel or feature\nlearning.",
            "author": [
                "C\u00e9dric Gerbelot",
                "Avetik Karagulyan",
                "Stefani Karp",
                "Kavya Ravichandran",
                "Menachem Stern",
                "Nathan Srebro"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15404v1",
                "http://arxiv.org/pdf/2311.15404v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cond-mat.dis-nn",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15402v1",
            "title": "Learning Section Weights for Multi-Label Document Classification",
            "updated": "2023-11-26T19:56:19Z",
            "published": "2023-11-26T19:56:19Z",
            "summary": "Multi-label document classification is a traditional task in NLP. Compared to\nsingle-label classification, each document can be assigned multiple classes.\nThis problem is crucially important in various domains, such as tagging\nscientific articles. Documents are often structured into several sections such\nas abstract and title. Current approaches treat different sections equally for\nmulti-label classification. We argue that this is not a realistic assumption,\nleading to sub-optimal results. Instead, we propose a new method called\nLearning Section Weights (LSW), leveraging the contribution of each distinct\nsection for multi-label classification. Via multiple feed-forward layers, LSW\nlearns to assign weights to each section of, and incorporate the weights in the\nprediction. We demonstrate our approach on scientific articles. Experimental\nresults on public (arXiv) and private (Elsevier) datasets confirm the\nsuperiority of LSW, compared to state-of-the-art multi-label document\nclassification methods. In particular, LSW achieves a 1.3% improvement in terms\nof macro averaged F1-score while it achieves 1.3% in terms of macro averaged\nrecall on the publicly available arXiv dataset.",
            "author": [
                "Maziar Moradi Fard",
                "Paula Sorrolla Bayod",
                "Kiomars Motarjem",
                "Mohammad Alian Nejadi",
                "Saber Akhondi",
                "Camilo Thorne"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15402v1",
                "http://arxiv.org/pdf/2311.15402v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15401v1",
            "title": "Advanced Techniques in Mortality Trend Estimation: Integrating\n  Generalized Additive Models and Machine Learning to Evaluate the COVID-19\n  Impact",
            "updated": "2023-11-26T19:51:40Z",
            "published": "2023-11-26T19:51:40Z",
            "summary": "The last two centuries have seen a significant increase in life expectancy.\nAlthough past trends suggest that mortality will continue to decline in the\nfuture, uncertainty and instability about the development is greatly increased\ndue to the ongoing COVID-19 pandemic. It is therefore of essential interest,\nparticularly to annuity and life insurers, to predict the mortality of their\nmembers or policyholders with reliable accuracy. The goal of this study is to\nimprove the state-of-the-art stochastic mortality models using machine learning\ntechniques and generalize them to a multi-population model. Detailed\ncross-country results conducted for Finland, Germany, Italy, the Netherlands,\nand the United States show that the best forecasting performance is achieved by\na generalized additive model that uses the framework of APC analysis. Based on\nthis finding, trend forecasts of mortality rates as a measure of longevity are\nfulfilled for the future, given a range of COVID-19 scenarios, from mild to\nsevere. Discussing and evaluating the plausibility of these scenarios, this\nstudy is useful for preparation, planning, and informed decision-making.",
            "author": [
                "Asmik Nalmpatian",
                "Christian Heumann",
                "Stefan Pilz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15401v1",
                "http://arxiv.org/pdf/2311.15401v1"
            ],
            "primary_category": "stat.AP",
            "category": [
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15399v1",
            "title": "Optimally Teaching a Linear Behavior Cloning Agent",
            "updated": "2023-11-26T19:47:39Z",
            "published": "2023-11-26T19:47:39Z",
            "summary": "We study optimal teaching of Linear Behavior Cloning (LBC) learners. In this\nsetup, the teacher can select which states to demonstrate to an LBC learner.\nThe learner maintains a version space of infinite linear hypotheses consistent\nwith the demonstration. The goal of the teacher is to teach a realizable target\npolicy to the learner using minimum number of state demonstrations. This number\nis known as the Teaching Dimension(TD). We present a teaching algorithm called\n``Teach using Iterative Elimination(TIE)\" that achieves instance optimal TD.\nHowever, we also show that finding optimal teaching set computationally is\nNP-hard. We further provide an approximation algorithm that guarantees an\napproximation ratio of $\\log(|A|-1)$ on the teaching dimension. Finally, we\nprovide experimental results to validate the efficiency and effectiveness of\nour algorithm.",
            "author": [
                "Shubham Kumar Bharti",
                "Stephen Wright",
                "Adish Singla",
                "Xiaojin Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15399v1",
                "http://arxiv.org/pdf/2311.15399v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15398v1",
            "title": "On the Convergence of Learning Algorithms in Bayesian Auction Games",
            "updated": "2023-11-26T19:44:15Z",
            "published": "2023-11-26T19:44:15Z",
            "summary": "Equilibrium problems in Bayesian auction games can be described as systems of\ndifferential equations. Depending on the model assumptions, these equations\nmight be such that we do not have a rigorous mathematical solution theory. The\nlack of analytical or numerical techniques with guaranteed convergence for the\nequilibrium problem has plagued the field and limited equilibrium analysis to\nrather simple auction models such as single-object auctions. Recent advances in\nequilibrium learning led to algorithms that find equilibrium under a wide\nvariety of model assumptions. We analyze first- and second-price auctions where\nsimple learning algorithms converge to an equilibrium. The equilibrium problem\nin auctions is equivalent to solving an infinite-dimensional variational\ninequality (VI). Monotonicity and the Minty condition are the central\nsufficient conditions for learning algorithms to converge to an equilibrium in\nsuch VIs. We show that neither monotonicity nor pseudo- or quasi-monotonicity\nholds for the respective VIs. The second-price auction's equilibrium is a\nMinty-type solution, but the first-price auction is not. However, the\nBayes--Nash equilibrium is the unique solution to the VI within the class of\nuniformly increasing bid functions, which ensures that gradient-based\nalgorithms attain the {equilibrium} in case of convergence, as also observed in\nnumerical experiments.",
            "author": [
                "Martin Bichler",
                "Stephan B. Lunowa",
                "Matthias Oberlechner",
                "Fabian R. Pieroth",
                "Barbara Wohlmuth"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15398v1",
                "http://arxiv.org/pdf/2311.15398v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15395v1",
            "title": "ConstraintMatch for Semi-constrained Clustering",
            "updated": "2023-11-26T19:31:52Z",
            "published": "2023-11-26T19:31:52Z",
            "summary": "Constrained clustering allows the training of classification models using\npairwise constraints only, which are weak and relatively easy to mine, while\nstill yielding full-supervision-level model performance. While they perform\nwell even in the absence of the true underlying class labels, constrained\nclustering models still require large amounts of binary constraint annotations\nfor training. In this paper, we propose a semi-supervised context whereby a\nlarge amount of \\textit{unconstrained} data is available alongside a smaller\nset of constraints, and propose \\textit{ConstraintMatch} to leverage such\nunconstrained data. While a great deal of progress has been made in\nsemi-supervised learning using full labels, there are a number of challenges\nthat prevent a naive application of the resulting methods in the\nconstraint-based label setting. Therefore, we reason about and analyze these\nchallenges, specifically 1) proposing a \\textit{pseudo-constraining} mechanism\nto overcome the confirmation bias, a major weakness of pseudo-labeling, 2)\ndeveloping new methods for pseudo-labeling towards the selection of\n\\textit{informative} unconstrained samples, 3) showing that this also allows\nthe use of pairwise loss functions for the initial and auxiliary losses which\nfacilitates semi-constrained model training. In extensive experiments, we\ndemonstrate the effectiveness of ConstraintMatch over relevant baselines in\nboth the regular clustering and overclustering scenarios on five challenging\nbenchmarks and provide analyses of its several components.",
            "author": [
                "Jann Goschenhofer",
                "Bernd Bischl",
                "Zsolt Kira"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15395v1",
                "http://arxiv.org/pdf/2311.15395v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15390v1",
            "title": "Local Convergence of Approximate Newton Method for Two Layer Nonlinear\n  Regression",
            "updated": "2023-11-26T19:19:02Z",
            "published": "2023-11-26T19:19:02Z",
            "summary": "There have been significant advancements made by large language models (LLMs)\nin various aspects of our daily lives. LLMs serve as a transformative force in\nnatural language processing, finding applications in text generation,\ntranslation, sentiment analysis, and question-answering. The accomplishments of\nLLMs have led to a substantial increase in research efforts in this domain. One\nspecific two-layer regression problem has been well-studied in prior works,\nwhere the first layer is activated by a ReLU unit, and the second layer is\nactivated by a softmax unit. While previous works provide a solid analysis of\nbuilding a two-layer regression, there is still a gap in the analysis of\nconstructing regression problems with more than two layers.\n  In this paper, we take a crucial step toward addressing this problem: we\nprovide an analysis of a two-layer regression problem. In contrast to previous\nworks, our first layer is activated by a softmax unit. This sets the stage for\nfuture analyses of creating more activation functions based on the softmax\nfunction. Rearranging the softmax function leads to significantly different\nanalyses. Our main results involve analyzing the convergence properties of an\napproximate Newton method used to minimize the regularized training loss. We\nprove that the loss function for the Hessian matrix is positive definite and\nLipschitz continuous under certain assumptions. This enables us to establish\nlocal convergence guarantees for the proposed training algorithm. Specifically,\nwith an appropriate initialization and after $O(\\log(1/\\epsilon))$ iterations,\nour algorithm can find an $\\epsilon$-approximate minimizer of the training loss\nwith high probability. Each iteration requires approximately $O(\\mathrm{nnz}(C)\n+ d^\\omega)$ time, where $d$ is the model size, $C$ is the input matrix, and\n$\\omega < 2.374$ is the matrix multiplication exponent.",
            "author": [
                "Zhihang Li",
                "Zhao Song",
                "Zifan Wang",
                "Junze Yin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15390v1",
                "http://arxiv.org/pdf/2311.15390v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15386v1",
            "title": "Spectro-ViT: A Vision Transformer Model for GABA-edited MRS\n  Reconstruction Using Spectrograms",
            "updated": "2023-11-26T19:09:28Z",
            "published": "2023-11-26T19:09:28Z",
            "summary": "Purpose: To investigate the use of a Vision Transformer (ViT) to\nreconstruct/denoise GABA-edited magnetic resonance spectroscopy (MRS) from a\nquarter of the typically acquired number of transients using spectrograms.\n  Theory and Methods: A quarter of the typically acquired number of transients\ncollected in GABA-edited MRS scans are pre-processed and converted to a\nspectrogram image representation using the Short-Time Fourier Transform (STFT).\nThe image representation of the data allows the adaptation of a pre-trained ViT\nfor reconstructing GABA-edited MRS spectra (Spectro-ViT). The Spectro-ViT is\nfine-tuned and then tested using \\textit{in vivo} GABA-edited MRS data. The\nSpectro-ViT performance is compared against other models in the literature\nusing spectral quality metrics and estimated metabolite concentration values.\n  Results: The Spectro-ViT model significantly outperformed all other models in\nfour out of five quantitative metrics (mean squared error, shape score,\nGABA+/water fit error, and full width at half maximum). The metabolite\nconcentrations estimated (GABA+/water, GABA+/Cr, and Glx/water) were consistent\nwith the metabolite concentrations estimated using typical GABA-edited MRS\nscans reconstructed with the full amount of typically collected transients.\n  Conclusion: The proposed Spectro-ViT model achieved state-of-the-art results\nin reconstructing GABA-edited MRS, and the results indicate these scans could\nbe up to four times faster.",
            "author": [
                "Gabriel Dias",
                "Rodrigo Pommot Berto",
                "Mateus Oliveira",
                "Lucas Ueda",
                "Sergio Dertkigil",
                "Paula D. P. Costa",
                "Amirmohammad Shamaei",
                "Roberto Souza",
                "Ashley Harris",
                "Leticia Rittner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15386v1",
                "http://arxiv.org/pdf/2311.15386v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.LG",
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15384v1",
            "title": "Robust and Automatic Data Clustering: Dirichlet Process meets\n  Median-of-Means",
            "updated": "2023-11-26T19:01:15Z",
            "published": "2023-11-26T19:01:15Z",
            "summary": "Clustering stands as one of the most prominent challenges within the realm of\nunsupervised machine learning. Among the array of centroid-based clustering\nalgorithms, the classic $k$-means algorithm, rooted in Lloyd's heuristic, takes\ncenter stage as one of the extensively employed techniques in the literature.\nNonetheless, both $k$-means and its variants grapple with noteworthy\nlimitations. These encompass a heavy reliance on initial cluster centroids,\nsusceptibility to converging into local minima of the objective function, and\nsensitivity to outliers and noise in the data. When confronted with data\ncontaining noisy or outlier-laden observations, the Median-of-Means (MoM)\nestimator emerges as a stabilizing force for any centroid-based clustering\nframework. On a different note, a prevalent constraint among existing\nclustering methodologies resides in the prerequisite knowledge of the number of\nclusters prior to analysis. Utilizing model-based methodologies, such as\nBayesian nonparametric models, offers the advantage of infinite mixture models,\nthereby circumventing the need for such requirements. Motivated by these facts,\nin this article, we present an efficient and automatic clustering technique by\nintegrating the principles of model-based and centroid-based methodologies that\nmitigates the effect of noise on the quality of clustering while ensuring that\nthe number of clusters need not be specified in advance. Statistical guarantees\non the upper bound of clustering error, and rigorous assessment through\nsimulated and real datasets suggest the advantages of our proposed method over\nexisting state-of-the-art clustering algorithms.",
            "author": [
                "Supratik Basu",
                "Jyotishka Ray Choudhury",
                "Debolina Paul",
                "Swagatam Das"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15384v1",
                "http://arxiv.org/pdf/2311.15384v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15382v1",
            "title": "Evaluating Multi-Global Server Architecture for Federated Learning",
            "updated": "2023-11-26T18:55:46Z",
            "published": "2023-11-26T18:55:46Z",
            "summary": "Federated learning (FL) with a single global server framework is currently a\npopular approach for training machine learning models on decentralized\nenvironment, such as mobile devices and edge devices. However, the centralized\nserver architecture poses a risk as any challenge on the central/global server\nwould result in the failure of the entire system. To minimize this risk, we\npropose a novel federated learning framework that leverages the deployment of\nmultiple global servers. We posit that implementing multiple global servers in\nfederated learning can enhance efficiency by capitalizing on local\ncollaborations and aggregating knowledge, and the error tolerance in regard to\ncommunication failure in the single server framework would be handled. We\ntherefore propose a novel framework that leverages the deployment of multiple\nglobal servers. We conducted a series of experiments using a dataset containing\nthe event history of electric vehicle (EV) charging at numerous stations. We\ndeployed a federated learning setup with multiple global servers and client\nservers, where each client-server strategically represented a different region\nand a global server was responsible for aggregating local updates from those\ndevices. Our preliminary results of the global models demonstrate that the\ndifference in performance attributed to multiple servers is less than 1%. While\nthe hypothesis of enhanced model efficiency was not as expected, the rule for\nhandling communication challenges added to the algorithm could resolve the\nerror tolerance issue. Future research can focus on identifying specific uses\nfor the deployment of multiple global servers.",
            "author": [
                "Asfia Kawnine",
                "Hung Cao",
                "Atah Nuh Mih",
                "Monica Wachowicz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15382v1",
                "http://arxiv.org/pdf/2311.15382v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15373v1",
            "title": "Confidence Is All You Need for MI Attacks",
            "updated": "2023-11-26T18:09:24Z",
            "published": "2023-11-26T18:09:24Z",
            "summary": "In this evolving era of machine learning security, membership inference\nattacks have emerged as a potent threat to the confidentiality of sensitive\ndata. In this attack, adversaries aim to determine whether a particular point\nwas used during the training of a target model. This paper proposes a new\nmethod to gauge a data point's membership in a model's training set. Instead of\ncorrelating loss with membership, as is traditionally done, we have leveraged\nthe fact that training examples generally exhibit higher confidence values when\nclassified into their actual class. During training, the model is essentially\nbeing 'fit' to the training data and might face particular difficulties in\ngeneralization to unseen data. This asymmetry leads to the model achieving\nhigher confidence on the training data as it exploits the specific patterns and\nnoise present in the training data. Our proposed approach leverages the\nconfidence values generated by the machine learning model. These confidence\nvalues provide a probabilistic measure of the model's certainty in its\npredictions and can further be used to infer the membership of a given data\npoint. Additionally, we also introduce another variant of our method that\nallows us to carry out this attack without knowing the ground truth(true class)\nof a given data point, thus offering an edge over existing label-dependent\nattack methods.",
            "author": [
                "Abhishek Sinha",
                "Himanshi Tibrewal",
                "Mansi Gupta",
                "Nikhar Waghela",
                "Shivank Garg"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15373v1",
                "http://arxiv.org/pdf/2311.15373v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15369v1",
            "title": "TD-Net: A Tri-domain network for sparse-view CT reconstruction",
            "updated": "2023-11-26T17:48:53Z",
            "published": "2023-11-26T17:48:53Z",
            "summary": "Sparse-view CT reconstruction, aimed at reducing X-ray radiation risks,\nfrequently suffers from image quality degradation, manifested as noise and\nartifacts. Existing post-processing and dual-domain techniques, although\neffective in radiation reduction, often lead to over-smoothed results,\ncompromising diagnostic clarity. Addressing this, we introduce TD-Net, a\npioneering tri-domain approach that unifies sinogram, image, and frequency\ndomain optimizations. By incorporating Frequency Supervision Module(FSM),\nTD-Net adeptly preserves intricate details, overcoming the prevalent\nover-smoothing issue. Extensive evaluations demonstrate TD-Net's superior\nperformance in reconstructing high-quality CT images from sparse views,\nefficiently balancing radiation safety and image fidelity. The enhanced\ncapabilities of TD-Net in varied noise scenarios highlight its potential as a\nbreakthrough in medical imaging.",
            "author": [
                "Xinyuan Wang",
                "Changqing Su",
                "Bo Xiong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15369v1",
                "http://arxiv.org/pdf/2311.15369v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.AI",
                "cs.CV",
                "cs.LG",
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15366v1",
            "title": "Untargeted Code Authorship Evasion with Seq2Seq Transformation",
            "updated": "2023-11-26T17:45:57Z",
            "published": "2023-11-26T17:45:57Z",
            "summary": "Code authorship attribution is the problem of identifying authors of\nprogramming language codes through the stylistic features in their codes, a\ntopic that recently witnessed significant interest with outstanding\nperformance. In this work, we present SCAE, a code authorship obfuscation\ntechnique that leverages a Seq2Seq code transformer called StructCoder. SCAE\ncustomizes StructCoder, a system designed initially for function-level code\ntranslation from one language to another (e.g., Java to C#), using transfer\nlearning. SCAE improved the efficiency at a slight accuracy degradation\ncompared to existing work. We also reduced the processing time by about 68%\nwhile maintaining an 85% transformation success rate and up to 95.77% evasion\nsuccess rate in the untargeted setting.",
            "author": [
                "Soohyeon Choi",
                "Rhongho Jang",
                "DaeHun Nyang",
                "David Mohaisen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15366v1",
                "http://arxiv.org/pdf/2311.15366v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15365v1",
            "title": "A Convergence result of a continuous model of deep learning via\n  \u0141ojasiewicz--Simon inequality",
            "updated": "2023-11-26T17:44:29Z",
            "published": "2023-11-26T17:44:29Z",
            "summary": "This study focuses on a Wasserstein-type gradient flow, which represents an\noptimization process of a continuous model of a Deep Neural Network (DNN).\nFirst, we establish the existence of a minimizer for an average loss of the\nmodel under $L^2$-regularization. Subsequently, we show the existence of a\ncurve of maximal slope of the loss. Our main result is the convergence of flow\nto a critical point of the loss as time goes to infinity. An essential aspect\nof proving this result involves the establishment of the \\L{}ojasiewicz--Simon\ngradient inequality for the loss. We derive this inequality by assuming the\nanalyticity of NNs and loss functions. Our proofs offer a new approach for\nanalyzing the asymptotic behavior of Wasserstein-type gradient flows for\nnonconvex functionals.",
            "author": [
                "Noboru Isobe"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15365v1",
                "http://arxiv.org/pdf/2311.15365v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.AP",
                "math.FA",
                "math.PR",
                "35B40, 49J20, 49Q22, 68T07"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15362v1",
            "title": "Application of Process Mining and Sequence Clustering in Recognizing an\n  Industrial Issue",
            "updated": "2023-11-26T17:31:55Z",
            "published": "2023-11-26T17:31:55Z",
            "summary": "Process mining has become one of the best programs that can outline the event\nlogs of production processes in visualized detail. We have addressed the\nimportant problem that easily occurs in the industrial process called\nBottleneck. The analysis process was focused on extracting the bottlenecks in\nthe production line to improve the flow of production. Given enough stored\nhistory logs, the field of process mining can provide a suitable answer to\noptimize production flow by mitigating bottlenecks in the production stream.\nProcess mining diagnoses the productivity processes by mining event logs, this\ncan help to expose the opportunities to optimize critical production processes.\nWe found that there is a considerable bottleneck in the process because of the\nweaving activities. Through discussions with specialists, it was agreed that\nthe main problem in the weaving processes, especially machines that were\nexhausted in overloading processes. The improvement in the system has measured\nby teamwork; the cycle time for process has improved to 91%, the worker's\nperformance has improved to 96%,product quality has improved by 85%, and lead\ntime has optimized from days and weeks to hours.",
            "author": [
                "Hamza Saad"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15362v1",
                "http://arxiv.org/pdf/2311.15362v1"
            ],
            "primary_category": "econ.GN",
            "category": [
                "econ.GN",
                "q-fin.EC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15361v1",
            "title": "Ultra-Range Gesture Recognition using an RGB Camera in Human-Robot\n  Interaction",
            "updated": "2023-11-26T17:27:26Z",
            "published": "2023-11-26T17:27:26Z",
            "summary": "Hand gestures play a significant role in human interactions where non-verbal\nintentions, thoughts and commands are conveyed. In Human-Robot Interaction\n(HRI), hand gestures offer a similar and efficient medium for conveying clear\nand rapid directives to a robotic agent. However, state-of-the-art vision-based\nmethods for gesture recognition have been shown to be effective only up to a\nuser-camera distance of seven meters. Such a short distance range limits\npractical HRI with, for example, service robots, search and rescue robots and\ndrones. In this work, we address the Ultra-Range Gesture Recognition (URGR)\nproblem by aiming for a recognition distance of up to 25 meters and in the\ncontext of HRI. We propose a novel deep-learning framework for URGR using\nsolely a simple RGB camera. First, a novel super-resolution model termed HQ-Net\nis used to enhance the low-resolution image of the user. Then, we propose a\nnovel URGR classifier termed Graph Vision Transformer (GViT) which takes the\nenhanced image as input. GViT combines the benefits of a Graph Convolutional\nNetwork (GCN) and a modified Vision Transformer (ViT). Evaluation of the\nproposed framework over diverse test data yields a high recognition rate of\n98.1%. The framework has also exhibited superior performance compared to human\nrecognition in ultra-range distances. With the framework, we analyze and\ndemonstrate the performance of an autonomous quadruped robot directed by human\ngestures in complex ultra-range indoor and outdoor environments.",
            "author": [
                "Eran Bamani",
                "Eden Nissinman",
                "Inbar Meir",
                "Lisa Koenigsberg",
                "Avishai Sintov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15361v1",
                "http://arxiv.org/pdf/2311.15361v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15358v1",
            "title": "An optimised cuckoo-based discrete symbiotic organisms search strategy\n  for tasks scheduling in cloud computing environment",
            "updated": "2023-11-26T17:20:21Z",
            "published": "2023-11-26T17:20:21Z",
            "summary": "Currently, the cloud computing paradigm is experiencing rapid growth as there\nis a shift from other distributed computing methods and traditional IT\ninfrastructure towards it. Consequently, optimised task scheduling techniques\nhave become crucial in managing the expanding cloud computing environment. In\ncloud computing, numerous tasks need to be scheduled on a limited number of\ndiverse virtual machines to minimise the imbalance between the local and global\nsearch space; and optimise system utilisation. Task scheduling is a challenging\nproblem known as NP-complete, which means that there is no exact solution, and\nwe can only achieve near-optimal results, particularly when using large-scale\ntasks in the context of cloud computing. This paper proposes an optimised\nstrategy, Cuckoo-based Discrete Symbiotic Organisms Search (C-DSOS) that\nincorporated with Levy-Flight for optimal task scheduling in the cloud\ncomputing environment to minimise degree of imbalance. The strategy is based on\nthe Standard Symbiotic Organism Search (SOS), which is a nature-inspired\nmetaheuristic optimisation algorithm designed for numerical optimisation\nproblems. SOS simulates the symbiotic relationships observed in ecosystems,\nsuch as mutualism, commensalism, and parasitism. To evaluate the proposed\ntechnique, the CloudSim toolkit simulator was used to conduct experiments. The\nresults demonstrated that C-DSOS outperforms the Simulated Annealing Symbiotic\nOrganism Search (SASOS) algorithm, which is a benchmarked algorithm commonly\nused in task scheduling problems. C-DSOS exhibits a favourable convergence\nrate, especially when using larger search spaces, making it suitable for task\nscheduling problems in the cloud. For the analysis, a t-test was employed,\nreveals that C-DSOS is statistically significant compared to the benchmarked\nSASOS algorithm, particularly for scenarios involving a large search space.",
            "author": [
                "Suleiman Sa'ad",
                "Abdullah Muhammed",
                "Mohammed Abdullahi",
                "Azizol Abdullah"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15358v1",
                "http://arxiv.org/pdf/2311.15358v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15356v1",
            "title": "Having Second Thoughts? Let's hear it",
            "updated": "2023-11-26T17:17:28Z",
            "published": "2023-11-26T17:17:28Z",
            "summary": "Deep learning models loosely mimic bottom-up signal pathways from low-order\nsensory areas to high-order cognitive areas. After training, DL models can\noutperform humans on some domain-specific tasks, but their decision-making\nprocess has been known to be easily disrupted. Since the human brain consists\nof multiple functional areas highly connected to one another and relies on\nintricate interplays between bottom-up and top-down (from high-order to\nlow-order areas) processing, we hypothesize that incorporating top-down signal\nprocessing may make DL models more robust. To address this hypothesis, we\npropose a certification process mimicking selective attention and test if it\ncould make DL models more robust. Our empirical evaluations suggest that this\nnewly proposed certification can improve DL models' accuracy and help us build\nsafety measures to alleviate their vulnerabilities with both artificial and\nnatural adversarial examples.",
            "author": [
                "Jung H. Lee",
                "Sujith Vijayan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15356v1",
                "http://arxiv.org/pdf/2311.15356v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15341v1",
            "title": "Generative Modelling of Stochastic Actions with Arbitrary Constraints in\n  Reinforcement Learning",
            "updated": "2023-11-26T15:57:20Z",
            "published": "2023-11-26T15:57:20Z",
            "summary": "Many problems in Reinforcement Learning (RL) seek an optimal policy with\nlarge discrete multidimensional yet unordered action spaces; these include\nproblems in randomized allocation of resources such as placements of multiple\nsecurity resources and emergency response units, etc. A challenge in this\nsetting is that the underlying action space is categorical (discrete and\nunordered) and large, for which existing RL methods do not perform well.\nMoreover, these problems require validity of the realized action (allocation);\nthis validity constraint is often difficult to express compactly in a closed\nmathematical form. The allocation nature of the problem also prefers stochastic\noptimal policies, if one exists. In this work, we address these challenges by\n(1) applying a (state) conditional normalizing flow to compactly represent the\nstochastic policy -- the compactness arises due to the network only producing\none sampled action and the corresponding log probability of the action, which\nis then used by an actor-critic method; and (2) employing an invalid action\nrejection method (via a valid action oracle) to update the base policy. The\naction rejection is enabled by a modified policy gradient that we derive.\nFinally, we conduct extensive experiments to show the scalability of our\napproach compared to prior methods and the ability to enforce arbitrary\nstate-conditional constraints on the support of the distribution of actions in\nany state.",
            "author": [
                "Changyu Chen",
                "Ramesha Karunasena",
                "Thanh Hong Nguyen",
                "Arunesh Sinha",
                "Pradeep Varakantham"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15341v1",
                "http://arxiv.org/pdf/2311.15341v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15339v1",
            "title": "Adversarial Purification of Information Masking",
            "updated": "2023-11-26T15:50:19Z",
            "published": "2023-11-26T15:50:19Z",
            "summary": "Adversarial attacks meticulously generate minuscule, imperceptible\nperturbations to images to deceive neural networks. Counteracting these,\nadversarial purification methods seek to transform adversarial input samples\ninto clean output images to defend against adversarial attacks. Nonetheless,\nextent generative models fail to effectively eliminate adversarial\nperturbations, yielding less-than-ideal purification results. We emphasize the\npotential threat of residual adversarial perturbations to target models,\nquantitatively establishing a relationship between perturbation scale and\nattack capability. Notably, the residual perturbations on the purified image\nprimarily stem from the same-position patch and similar patches of the\nadversarial sample. We propose a novel adversarial purification approach named\nInformation Mask Purification (IMPure), aims to extensively eliminate\nadversarial perturbations. To obtain an adversarial sample, we first mask part\nof the patches information, then reconstruct the patches to resist adversarial\nperturbations from the patches. We reconstruct all patches in parallel to\nobtain a cohesive image. Then, in order to protect the purified samples against\npotential similar regional perturbations, we simulate this risk by randomly\nmixing the purified samples with the input samples before inputting them into\nthe feature extraction network. Finally, we establish a combined constraint of\npixel loss and perceptual loss to augment the model's reconstruction\nadaptability. Extensive experiments on the ImageNet dataset with three\nclassifier models demonstrate that our approach achieves state-of-the-art\nresults against nine adversarial attack methods. Implementation code and\npre-trained weights can be accessed at\n\\textcolor{blue}{https://github.com/NoWindButRain/IMPure}.",
            "author": [
                "Sitong Liu",
                "Zhichao Lian",
                "Shuangquan Zhang",
                "Liang Xiao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15339v1",
                "http://arxiv.org/pdf/2311.15339v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CR",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15335v1",
            "title": "Token Recycling for Efficient Sequential Inference with Vision\n  Transformers",
            "updated": "2023-11-26T15:39:57Z",
            "published": "2023-11-26T15:39:57Z",
            "summary": "Vision Transformers (ViTs) overpass Convolutional Neural Networks in\nprocessing incomplete inputs because they do not require the imputation of\nmissing values. Therefore, ViTs are well suited for sequential decision-making,\ne.g. in the Active Visual Exploration problem. However, they are\ncomputationally inefficient because they perform a full forward pass each time\na piece of new sequential information arrives.\n  To reduce this computational inefficiency, we introduce the TOken REcycling\n(TORE) modification for the ViT inference, which can be used with any\narchitecture. TORE divides ViT into two parts, iterator and aggregator. An\niterator processes sequential information separately into midway tokens, which\nare cached. The aggregator processes midway tokens jointly to obtain the\nprediction. This way, we can reuse the results of computations made by\niterator.\n  Except for efficient sequential inference, we propose a complementary\ntraining policy, which significantly reduces the computational burden\nassociated with sequential decision-making while achieving state-of-the-art\naccuracy.",
            "author": [
                "Jan Olszewski",
                "Dawid Rymarczyk",
                "Piotr W\u00f3jcik",
                "Mateusz Pach",
                "Bartosz Zieli\u0144ski"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15335v1",
                "http://arxiv.org/pdf/2311.15335v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15332v1",
            "title": "ASI: Accuracy-Stability Index for Evaluating Deep Learning Models",
            "updated": "2023-11-26T15:34:36Z",
            "published": "2023-11-26T15:34:36Z",
            "summary": "In the context of deep learning research, where model introductions\ncontinually occur, the need for effective and efficient evaluation remains\nparamount. Existing methods often emphasize accuracy metrics, overlooking\nstability. To address this, the paper introduces the Accuracy-Stability Index\n(ASI), a quantitative measure incorporating both accuracy and stability for\nassessing deep learning models. Experimental results demonstrate the\napplication of ASI, and a 3D surface model is presented for visualizing ASI,\nmean accuracy, and coefficient of variation. This paper addresses the important\nissue of quantitative benchmarking metrics for deep learning models, providing\na new approach for accurately evaluating accuracy and stability of deep\nlearning models. The paper concludes with discussions on potential weaknesses\nand outlines future research directions.",
            "author": [
                "Wei Dai",
                "Daniel Berleant"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15332v1",
                "http://arxiv.org/pdf/2311.15332v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "cs.IT",
                "cs.PF",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15331v1",
            "title": "How much data do I need? A case study on medical data",
            "updated": "2023-11-26T15:31:51Z",
            "published": "2023-11-26T15:31:51Z",
            "summary": "The collection of data to train a Deep Learning network is costly in terms of\neffort and resources. In many cases, especially in a medical context, it may\nhave detrimental impacts. Such as requiring invasive medical procedures or\nprocesses which could in themselves cause medical harm. However, Deep Learning\nis seen as a data hungry method. Here, we look at two commonly held adages i)\nmore data gives better results and ii) transfer learning will aid you when you\ndon't have enough data. These are widely assumed to be true and used as\nevidence for choosing how to solve a problem when Deep Learning is involved. We\nevaluate six medical datasets and six general datasets. Training a ResNet18\nnetwork on varying subsets of these datasets to evaluate `more data gives\nbetter results'. We take eleven of these datasets as the sources for Transfer\nLearning on subsets of the twelfth dataset -- Chest -- in order to determine\nwhether Transfer Learning is universally beneficial. We go further to see\nwhether multi-stage Transfer Learning provides a consistent benefit. Our\nanalysis shows that the real situation is more complex than these simple adages\n-- more data could lead to a case of diminishing returns and an incorrect\nchoice of dataset for transfer learning can lead to worse performance, with\ndatasets which we would consider highly similar to the Chest dataset giving\nworse results than datasets which are more dissimilar. Multi-stage transfer\nlearning likewise reveals complex relationships between datasets.",
            "author": [
                "Ayse Betul Cengiz",
                "A. Stephen McGough"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15331v1",
                "http://arxiv.org/pdf/2311.15331v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15328v1",
            "title": "BS-Diff: Effective Bone Suppression Using Conditional Diffusion Models\n  from Chest X-Ray Images",
            "updated": "2023-11-26T15:13:13Z",
            "published": "2023-11-26T15:13:13Z",
            "summary": "Chest X-rays (CXRs) are commonly utilized as a low-dose modality for lung\nscreening. Nonetheless, the efficacy of CXRs is somewhat impeded, given that\napproximately 75% of the lung area overlaps with bone, which in turn hampers\nthe detection and diagnosis of diseases. As a remedial measure, bone\nsuppression techniques have been introduced. The current dual-energy\nsubtraction imaging technique in the clinic requires costly equipment and\nsubjects being exposed to high radiation. To circumvent these issues, deep\nlearning-based image generation algorithms have been proposed. However,\nexisting methods fall short in terms of producing high-quality images and\ncapturing texture details, particularly with pulmonary vessels. To address\nthese issues, this paper proposes a new bone suppression framework, termed\nBS-Diff, that comprises a conditional diffusion model equipped with a U-Net\narchitecture and a simple enhancement module to incorporate an autoencoder. Our\nproposed network cannot only generate soft tissue images with a high bone\nsuppression rate but also possesses the capability to capture fine image\ndetails. Additionally, we compiled the largest dataset since 2010, including\ndata from 120 patients with high-definition, high-resolution paired CXRs and\nsoft tissue images collected by our affiliated hospital. Extensive experiments,\ncomparative analyses, ablation studies, and clinical evaluations indicate that\nthe proposed BS-Diff outperforms several bone-suppression models across\nmultiple metrics.",
            "author": [
                "Zhanghao Chen",
                "Yifei Sun",
                "Wenjian Qin",
                "Ruiquan Ge",
                "Cheng Pan",
                "Wenming Deng",
                "Zhou Liu",
                "Wenwen Min",
                "Ahmed Elazab",
                "Xiang Wan",
                "Changmiao Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15328v1",
                "http://arxiv.org/pdf/2311.15328v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15327v2",
            "title": "FRAC-Q-Learning: A Reinforcement Learning with Boredom Avoidance\n  Processes for Social Robots",
            "updated": "2023-12-07T03:21:06Z",
            "published": "2023-11-26T15:11:17Z",
            "summary": "The reinforcement learning algorithms have often been applied to social\nrobots. However, most reinforcement learning algorithms were not optimized for\nthe use of social robots, and consequently they may bore users. We proposed a\nnew reinforcement learning method specialized for the social robot, the\nFRAC-Q-learning, that can avoid user boredom. The proposed algorithm consists\nof a forgetting process in addition to randomizing and categorizing processes.\nThis study evaluated interest and boredom hardness scores of the\nFRAC-Q-learning by a comparison with the traditional Q-learning. The\nFRAC-Q-learning showed significantly higher trend of interest score, and\nindicated significantly harder to bore users compared to the traditional\nQ-learning. Therefore, the FRAC-Q-learning can contribute to develop a social\nrobot that will not bore users. The proposed algorithm can also find\napplications in Web-based communication and educational systems. This paper\npresents the entire process, detailed implementation and a detailed evaluation\nmethod of the of the FRAC-Q-learning for the first time.",
            "author": [
                "Akinari Onishi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15327v2",
                "http://arxiv.org/pdf/2311.15327v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15322v1",
            "title": "False Discovery Rate Control For Structured Multiple Testing: Asymmetric\n  Rules And Conformal Q-values",
            "updated": "2023-11-26T14:48:07Z",
            "published": "2023-11-26T14:48:07Z",
            "summary": "The effective utilization of structural information in data while ensuring\nstatistical validity poses a significant challenge in false discovery rate\n(FDR) analyses. Conformal inference provides rigorous theory for grounding\ncomplex machine learning methods without relying on strong assumptions or\nhighly idealized models. However, existing conformal methods have limitations\nin handling structured multiple testing. This is because their validity\nrequires the deployment of symmetric rules, which assume the exchangeability of\ndata points and permutation-invariance of fitting algorithms. To overcome these\nlimitations, we introduce the pseudo local index of significance (PLIS)\nprocedure, which is capable of accommodating asymmetric rules and requires only\npairwise exchangeability between the null conformity scores. We demonstrate\nthat PLIS offers finite-sample guarantees in FDR control and the ability to\nassign higher weights to relevant data points. Numerical results confirm the\neffectiveness and robustness of PLIS and show improvements in power compared to\nexisting model-free methods in various scenarios.",
            "author": [
                "Zinan Zhao",
                "Wenguang Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15322v1",
                "http://arxiv.org/pdf/2311.15322v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15320v1",
            "title": "Learning Coarse Propagators in Parareal Algorithm",
            "updated": "2023-11-26T14:43:13Z",
            "published": "2023-11-26T14:43:13Z",
            "summary": "The parareal algorithm represents an important class of parallel-in-time\nalgorithms for solving evolution equations and has been widely applied in\npractice. To achieve effective speedup, the choice of the coarse propagator in\nthe algorithm is vital. In this work, we investigate the use of learned coarse\npropagators. Building upon the error estimation framework, we present a\nsystematic procedure for constructing coarse propagators that enjoy desirable\nstability and consistent order. Additionally, we provide preliminary\nmathematical guarantees for the resulting parareal algorithm. Numerical\nexperiments on a variety of settings, e.g., linear diffusion model, Allen-Cahn\nmodel, and viscous Burgers model, show that learning can significantly improve\nparallel efficiency when compared with the more ad hoc choice of some\nconventional and widely used coarse propagators.",
            "author": [
                "Bangti Jin",
                "Qingle Lin",
                "Zhi Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15320v1",
                "http://arxiv.org/pdf/2311.15320v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16195v1",
            "title": "A Foundational Framework and Methodology for Personalized Early and\n  Timely Diagnosis",
            "updated": "2023-11-26T14:42:31Z",
            "published": "2023-11-26T14:42:31Z",
            "summary": "Early diagnosis of diseases holds the potential for deep transformation in\nhealthcare by enabling better treatment options, improving long-term survival\nand quality of life, and reducing overall cost. With the advent of medical big\ndata, advances in diagnostic tests as well as in machine learning and\nstatistics, early or timely diagnosis seems within reach. Early diagnosis\nresearch often neglects the potential for optimizing individual diagnostic\npaths. To enable personalized early diagnosis, a foundational framework is\nneeded that delineates the diagnosis process and systematically identifies the\ntime-dependent value of various diagnostic tests for an individual patient\ngiven their unique characteristics. Here, we propose the first foundational\nframework for early and timely diagnosis. It builds on decision-theoretic\napproaches to outline the diagnosis process and integrates machine learning and\nstatistical methodology for estimating the optimal personalized diagnostic\npath. To describe the proposed framework as well as possibly other frameworks,\nwe provide essential definitions.\n  The development of a foundational framework is necessary for several reasons:\n1) formalism provides clarity for the development of decision support tools; 2)\nobserved information can be complemented with estimates of the future patient\ntrajectory; 3) the net benefit of counterfactual diagnostic paths and\nassociated uncertainties can be modeled for individuals 4) 'early' and 'timely'\ndiagnosis can be clearly defined; 5) a mechanism emerges for assessing the\nvalue of technologies in terms of their impact on personalized early diagnosis,\nresulting health outcomes and incurred costs.\n  Finally, we hope that this foundational framework will unlock the\nlong-awaited potential of timely diagnosis and intervention, leading to\nimproved outcomes for patients and higher cost-effectiveness for healthcare\nsystems.",
            "author": [
                "Tim Schubert",
                "Richard W Peck",
                "Alexander Gimson",
                "Camelia Davtyan",
                "Mihaela van der Schaar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16195v1",
                "http://arxiv.org/pdf/2311.16195v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15317v1",
            "title": "Generalized Graph Prompt: Toward a Unification of Pre-Training and\n  Downstream Tasks on Graphs",
            "updated": "2023-11-26T14:35:28Z",
            "published": "2023-11-26T14:35:28Z",
            "summary": "Graph neural networks have emerged as a powerful tool for graph\nrepresentation learning, but their performance heavily relies on abundant\ntask-specific supervision. To reduce labeling requirement, the \"pre-train,\nprompt\" paradigms have become increasingly common. However, existing study of\nprompting on graphs is limited, lacking a universal treatment to appeal to\ndifferent downstream tasks. In this paper, we propose GraphPrompt, a novel\npre-training and prompting framework on graphs. GraphPrompt not only unifies\npre-training and downstream tasks into a common task template but also employs\na learnable prompt to assist a downstream task in locating the most relevant\nknowledge from the pre-trained model in a task-specific manner. To further\nenhance GraphPrompt in these two stages, we extend it into GraphPrompt+ with\ntwo major enhancements. First, we generalize several popular graph pre-training\ntasks beyond simple link prediction to broaden the compatibility with our task\ntemplate. Second, we propose a more generalized prompt design that incorporates\na series of prompt vectors within every layer of the pre-trained graph encoder,\nin order to capitalize on the hierarchical information across different layers\nbeyond just the readout layer. Finally, we conduct extensive experiments on\nfive public datasets to evaluate and analyze GraphPrompt and GraphPrompt+.",
            "author": [
                "Xingtong Yu",
                "Zhenghao Liu",
                "Yuan Fang",
                "Zemin Liu",
                "Sihong Chen",
                "Xinming Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15317v1",
                "http://arxiv.org/pdf/2311.15317v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15313v1",
            "title": "Low-Complexity Joint Beamforming for RIS-Assisted MU-MISO Systems Based\n  on Model-Driven Deep Learning",
            "updated": "2023-11-26T14:24:26Z",
            "published": "2023-11-26T14:24:26Z",
            "summary": "Reconfigurable intelligent surfaces (RIS) can improve signal propagation\nenvironments by adjusting the phase of the incident signal. However, optimizing\nthe phase shifts jointly with the beamforming vector at the access point is\nchallenging due to the non-convex objective function and constraints. In this\nstudy, we propose an algorithm based on weighted minimum mean square error\noptimization and power iteration to maximize the weighted sum rate (WSR) of a\nRIS-assisted downlink multi-user multiple-input single-output system. To\nfurther improve performance, a model-driven deep learning (DL) approach is\ndesigned, where trainable variables and graph neural networks are introduced to\naccelerate the convergence of the proposed algorithm. We also extend the\nproposed method to include beamforming with imperfect channel state information\nand derive a two-timescale stochastic optimization algorithm. Simulation\nresults show that the proposed algorithm outperforms state-of-the-art\nalgorithms in terms of complexity and WSR. Specifically, the model-driven DL\napproach has a runtime that is approximately 3% of the state-of-the-art\nalgorithm to achieve the same performance. Additionally, the proposed algorithm\nwith 2-bit phase shifters outperforms the compared algorithm with continuous\nphase shift.",
            "author": [
                "Weijie Jin",
                "Jing Zhang",
                "Chao-Kai Wen",
                "Shi Jin",
                "Xiao Li",
                "Shuangfeng Han"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15313v1",
                "http://arxiv.org/pdf/2311.15313v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16194v1",
            "title": "BadCLIP: Trigger-Aware Prompt Learning for Backdoor Attacks on CLIP",
            "updated": "2023-11-26T14:24:13Z",
            "published": "2023-11-26T14:24:13Z",
            "summary": "Contrastive Vision-Language Pre-training, known as CLIP, has shown promising\neffectiveness in addressing downstream image recognition tasks. However, recent\nworks revealed that the CLIP model can be implanted with a downstream-oriented\nbackdoor. On downstream tasks, one victim model performs well on clean samples\nbut predicts a specific target class whenever a specific trigger is present.\nFor injecting a backdoor, existing attacks depend on a large amount of\nadditional data to maliciously fine-tune the entire pre-trained CLIP model,\nwhich makes them inapplicable to data-limited scenarios. In this work,\nmotivated by the recent success of learnable prompts, we address this problem\nby injecting a backdoor into the CLIP model in the prompt learning stage. Our\nmethod named BadCLIP is built on a novel and effective mechanism in backdoor\nattacks on CLIP, i.e., influencing both the image and text encoders with the\ntrigger. It consists of a learnable trigger applied to images and a\ntrigger-aware context generator, such that the trigger can change text features\nvia trigger-aware prompts, resulting in a powerful and generalizable attack.\nExtensive experiments conducted on 11 datasets verify that the clean accuracy\nof BadCLIP is similar to those of advanced prompt learning methods and the\nattack success rate is higher than 99% in most cases. BadCLIP is also\ngeneralizable to unseen classes, and shows a strong generalization capability\nunder cross-dataset and cross-domain settings.",
            "author": [
                "Jiawang Bai",
                "Kuofeng Gao",
                "Shaobo Min",
                "Shu-Tao Xia",
                "Zhifeng Li",
                "Wei Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16194v1",
                "http://arxiv.org/pdf/2311.16194v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15312v1",
            "title": "A Low-cost and Portable Active Noise Control Unit",
            "updated": "2023-11-26T14:20:58Z",
            "published": "2023-11-26T14:20:58Z",
            "summary": "The objective of this research is to employ cutting-edge active noise control\nmethodologies in order to mitigate the noise emissions produced by electrical\nappliances, such as a coffee machine. The algorithm utilized in this study is\nthe modified Filtered-X Least Mean Square (FXLMS) algorithm. This algorithm\naims to generate an anti-noise waveform by utilizing measurements from both the\nreference microphone and the error microphone. The desired outcome of this\napproach is to achieve a residual noise level of zero. The primary difficulty\nlies in conducting the experiment in an open space setting, as conventional\nactive noise control systems are designed to function within enclosed\nenvironments, such as closed rooms or relatively confined spaces like the\nvolume inside headphones. A validation test bench is established, employing the\nSigma Studio software to oversee the entire system, with the ADAU1452 digital\nsignal processor being chosen. This study presents an introduction to different\nActive Noise Control systems and algorithms, followed by the execution of\nsimulations for representative techniques. Subsequently, this section provides\na comprehensive account of the procedures involved in executing the\nexperiments, followed by an exploration of potential avenues for further\nresearch.",
            "author": [
                "Wang Zhaohan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15312v1",
                "http://arxiv.org/pdf/2311.15312v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15310v1",
            "title": "Secure and Verifiable Data Collaboration with Low-Cost Zero-Knowledge\n  Proofs",
            "updated": "2023-11-26T14:19:46Z",
            "published": "2023-11-26T14:19:46Z",
            "summary": "Organizations are increasingly recognizing the value of data collaboration\nfor data analytics purposes. Yet, stringent data protection laws prohibit the\ndirect exchange of raw data. To facilitate data collaboration, federated\nLearning (FL) emerges as a viable solution, which enables multiple clients to\ncollaboratively train a machine learning (ML) model under the supervision of a\ncentral server while ensuring the confidentiality of their raw data. However,\nexisting studies have unveiled two main risks: (i) the potential for the server\nto infer sensitive information from the client's uploaded updates (i.e., model\ngradients), compromising client input privacy, and (ii) the risk of malicious\nclients uploading malformed updates to poison the FL model, compromising input\nintegrity. Recent works utilize secure aggregation with zero-knowledge proofs\n(ZKP) to guarantee input privacy and integrity in FL. Nevertheless, they suffer\nfrom extremely low efficiency and, thus, are impractical for real deployment.\nIn this paper, we propose a novel and highly efficient solution RiseFL for\nsecure and verifiable data collaboration, ensuring input privacy and integrity\nsimultaneously.Firstly, we devise a probabilistic integrity check method that\nsignificantly reduces the cost of ZKP generation and verification. Secondly, we\ndesign a hybrid commitment scheme to satisfy Byzantine robustness with improved\nperformance. Thirdly, we theoretically prove the security guarantee of the\nproposed solution. Extensive experiments on synthetic and real-world datasets\nsuggest that our solution is effective and is highly efficient in both client\ncomputation and communication. For instance, RiseFL is up to 28x, 53x and 164x\nfaster than three state-of-the-art baselines ACORN, RoFL and EIFFeL for the\nclient computation.",
            "author": [
                "Yizheng Zhu",
                "Yuncheng Wu",
                "Zhaojing Luo",
                "Beng Chin Ooi",
                "Xiaokui Xiao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15310v1",
                "http://arxiv.org/pdf/2311.15310v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.DB",
                "cs.DC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15309v1",
            "title": "Deep Refinement-Based Joint Source Channel Coding over Time-Varying\n  Channels",
            "updated": "2023-11-26T14:18:50Z",
            "published": "2023-11-26T14:18:50Z",
            "summary": "In recent developments, deep learning (DL)-based joint source-channel coding\n(JSCC) for wireless image transmission has made significant strides in\nperformance enhancement. Nonetheless, the majority of existing DL-based JSCC\nmethods are tailored for scenarios featuring stable channel conditions, notably\na fixed signal-to-noise ratio (SNR). This specialization poses a limitation, as\ntheir performance tends to wane in practical scenarios marked by highly dynamic\nchannels, given that a fixed SNR inadequately represents the dynamic nature of\nsuch channels. In response to this challenge, we introduce a novel solution,\nnamely deep refinement-based JSCC (DRJSCC). This innovative method is designed\nto seamlessly adapt to channels exhibiting temporal variations. By leveraging\ninstantaneous channel state information (CSI), we dynamically optimize the\nencoding strategy through re-encoding the channel symbols. This dynamic\nadjustment ensures that the encoding strategy consistently aligns with the\nvarying channel conditions during the transmission process. Specifically, our\napproach begins with the division of encoded symbols into multiple blocks,\nwhich are transmitted progressively to the receiver. In the event of changing\nchannel conditions, we propose a mechanism to re-encode the remaining blocks,\nallowing them to adapt to the current channel conditions. Experimental results\nshow that the DRJSCC scheme achieves comparable performance to the other\nmainstream DL-based JSCC models in stable channel conditions, and also exhibits\ngreat robustness against time-varying channels.",
            "author": [
                "Junyu Pan",
                "Hanlei Li",
                "Guangyi Zhang",
                "Yunlong Cai",
                "Guanding Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15309v1",
                "http://arxiv.org/pdf/2311.15309v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15303v1",
            "title": "Concept Distillation: Leveraging Human-Centered Explanations for Model\n  Improvement",
            "updated": "2023-11-26T14:00:14Z",
            "published": "2023-11-26T14:00:14Z",
            "summary": "Humans use abstract concepts for understanding instead of hard features.\nRecent interpretability research has focused on human-centered concept\nexplanations of neural networks. Concept Activation Vectors (CAVs) estimate a\nmodel's sensitivity and possible biases to a given concept. In this paper, we\nextend CAVs from post-hoc analysis to ante-hoc training in order to reduce\nmodel bias through fine-tuning using an additional Concept Loss. Concepts were\ndefined on the final layer of the network in the past. We generalize it to\nintermediate layers using class prototypes. This facilitates class learning in\nthe last convolution layer, which is known to be most informative. We also\nintroduce Concept Distillation to create richer concepts using a pre-trained\nknowledgeable model as the teacher. Our method can sensitize or desensitize a\nmodel towards concepts. We show applications of concept-sensitive training to\ndebias several classification problems. We also use concepts to induce prior\nknowledge into IID, a reconstruction problem. Concept-sensitive training can\nimprove model interpretability, reduce biases, and induce prior knowledge.\nPlease visit https://avani17101.github.io/Concept-Distilllation/ for code and\nmore details.",
            "author": [
                "Avani Gupta",
                "Saurabh Saini",
                "P J Narayanan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15303v1",
                "http://arxiv.org/pdf/2311.15303v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15301v1",
            "title": "Eye Disease Prediction using Ensemble Learning and Attention on OCT\n  Scans",
            "updated": "2023-11-26T13:55:24Z",
            "published": "2023-11-26T13:55:24Z",
            "summary": "Eye diseases have posed significant challenges for decades, but advancements\nin technology have opened new avenues for their detection and treatment.\nMachine learning and deep learning algorithms have become instrumental in this\ndomain, particularly when combined with Optical Coherent Technology (OCT)\nimaging. We propose a novel method for efficient detection of eye diseases from\nOCT images. Our technique enables the classification of patients into disease\nfree (normal eyes) or affected by specific conditions such as Choroidal\nNeovascularization (CNV), Diabetic Macular Edema (DME), or Drusen. In this\nwork, we introduce an end to end web application that utilizes machine learning\nand deep learning techniques for efficient eye disease prediction. The\napplication allows patients to submit their raw OCT scanned images, which\nundergo segmentation using a trained custom UNet model. The segmented images\nare then fed into an ensemble model, comprising InceptionV3 and Xception\nnetworks, enhanced with a self attention layer. This self attention approach\nleverages the feature maps of individual models to achieve improved\nclassification accuracy. The ensemble model's output is aggregated to predict\nand classify various eye diseases. Extensive experimentation and optimization\nhave been conducted to ensure the application's efficiency and optimal\nperformance. Our results demonstrate the effectiveness of the proposed approach\nin accurate eye disease prediction. The developed web application holds\nsignificant potential for early detection and timely intervention, thereby\ncontributing to improved eye healthcare outcomes.",
            "author": [
                "Gauri Naik",
                "Nandini Narvekar",
                "Dimple Agarwal",
                "Nishita Nandanwar",
                "Himangi Pande"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15301v1",
                "http://arxiv.org/pdf/2311.15301v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15298v1",
            "title": "A Data-driven and multi-agent decision support system for time slot\n  management at container terminals: A case study for the Port of Rotterdam",
            "updated": "2023-11-26T13:46:20Z",
            "published": "2023-11-26T13:46:20Z",
            "summary": "Controlling the departure time of the trucks from a container hub is\nimportant to both the traffic and the logistics systems. This, however,\nrequires an intelligent decision support system that can control and manage\ntruck arrival times at terminal gates. This paper introduces an integrated\nmodel that can be used to understand, predict, and control logistics and\ntraffic interactions in the port-hinterland ecosystem. This approach is\ncontext-aware and makes use of big historical data to predict system states and\napply control policies accordingly, on truck inflow and outflow. The control\npolicies ensure multiple stakeholders satisfaction including those of trucking\ncompanies, terminal operators, and road traffic agencies. The proposed method\nconsists of five integrated modules orchestrated to systematically steer\ntruckers toward choosing those time slots that are expected to result in lower\ngate waiting times and more cost-effective schedules. The simulation is\nsupported by real-world data and shows that significant gains can be obtained\nin the system.",
            "author": [
                "Ali Nadi",
                "Maaike Snelder",
                "J. W. C. van Lint",
                "L\u00f3r\u00e1nt Tavasszy"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15298v1",
                "http://arxiv.org/pdf/2311.15298v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15297v1",
            "title": "Controllable Expensive Multi-objective Optimization with Warm-starting\n  Gaussian Processes",
            "updated": "2023-11-26T13:45:21Z",
            "published": "2023-11-26T13:45:21Z",
            "summary": "Pareto Set Learning (PSL) is a promising approach for approximating the\nentire Pareto front in multi-objective optimization (MOO) problems. However,\nexisting derivative-free PSL methods are often unstable and inefficient,\nespecially for expensive black-box MOO problems where objective function\nevaluations are costly. In this work, we propose to address the instability and\ninefficiency of existing PSL methods with a novel controllable PSL method,\ncalled Co-PSL. Particularly, Co-PSL consists of two stages: (1) warm-starting\nBayesian optimization to obtain quality Gaussian Processes priors and (2)\ncontrollable Pareto set learning to accurately acquire a parametric mapping\nfrom preferences to the corresponding Pareto solutions. The former is to help\nstabilize the PSL process and reduce the number of expensive function\nevaluations. The latter is to support real-time trade-off control between\nconflicting objectives. Performances across synthesis and real-world MOO\nproblems showcase the effectiveness of our Co-PSL for expensive multi-objective\noptimization tasks.",
            "author": [
                "Quang-Huy Nguyen",
                "Long P. Hoang",
                "Hoang V. Viet",
                "Dung D. Le"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15297v1",
                "http://arxiv.org/pdf/2311.15297v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15293v1",
            "title": "Student's Interests Related to Web and Mobile Technologies Study",
            "updated": "2023-11-26T13:24:30Z",
            "published": "2023-11-26T13:24:30Z",
            "summary": "We explore in this paper the interests and challenges of students regarding\nweb and mobile technologies. Our study is based on a survey among undergraduate\nstudents, students that attend a Web Programming course. In particular, we\nstudy the challenges students have in following a successful career in web or\nmobile development and we have found that the most important one is the large\neffort required for keeping up to date with the fast changing web and mobile\ntechnologies. Overall, the attitude of the surveyed undergraduate students\ntowards web development and mobile development is rather positive, as more than\n60% of them said that they are interested in a career in web or mobile\ndevelopment. We also found out that most of them prefer working on back-end web\ntechnologies. As for the specific web technologies students are interested on,\nthey are highly varied. Overall, our study provides valuable insights into the\ninterests and challenges of students regarding web and mobile technologies,\nwhich can guide the development of effective teaching and learning approaches\nin this area.",
            "author": [
                "Manuela Petrescu",
                "Adrian Sterca",
                "Ioan Badarinza"
            ],
            "link": [
                "http://dx.doi.org/10.5220/0012174900003584",
                "http://arxiv.org/abs/2311.15293v1",
                "http://arxiv.org/pdf/2311.15293v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.SE",
                "D.3.2; D.2.3"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15292v1",
            "title": "Active-Sensing-Based Beam Alignment for Near Field MIMO Communications",
            "updated": "2023-11-26T13:23:27Z",
            "published": "2023-11-26T13:23:27Z",
            "summary": "An active-sensing-based learning algorithm is proposed to solve the\nnear-field beam alignment problem with the aid of wavenumber-domain transform\nmatrices (WTMs). Specifically, WTMs can transform the antenna-domain channel\ninto a sparse representation in the wavenumber domain. The dimensions of WTMs\ncan be further reduced by exploiting the dominance of line-of-sight (LoS)\nlinks. By employing these lower-dimensional WTMs as mapping functions, the\nactive-sensing-based algorithm is executed in the wavenumber domain, resulting\nin an acceleration of convergence. Compared with the codebook-based beam\nalignment methods, the proposed method finds the optimal beam pair in a\nping-pong fashion, thus avoiding high training overheads caused by beam\nsweeping. Finally, the numerical results validate the effectiveness of the\nproposed method.",
            "author": [
                "Hao Jiang",
                "Zhaolin Wang",
                "Yuanwei Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15292v1",
                "http://arxiv.org/pdf/2311.15292v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15288v1",
            "title": "U-DeepONet: U-Net Enhanced Deep Operator Network for Geologic Carbon\n  Sequestration",
            "updated": "2023-11-26T13:02:27Z",
            "published": "2023-11-26T13:02:27Z",
            "summary": "FNO and DeepONet are by far the most popular neural operator learning\nalgorithms. FNO seems to enjoy an edge in popularity due to its ease of use,\nespecially with high dimensional data. However, a lesser-acknowledged feature\nof DeepONet is its modularity. This feature allows the user the flexibility of\nchoosing the kind of neural network to be used in the trunk and/or branch of\nthe DeepONet. This is beneficial because it has been shown many times that\ndifferent types of problems require different kinds of network architectures\nfor effective learning. In this work, we will take advantage of this feature by\ncarefully designing a more efficient neural operator based on the DeepONet\narchitecture. We introduce U-Net enhanced DeepONet (U-DeepONet) for learning\nthe solution operator of highly complex CO2-water two-phase flow in\nheterogeneous porous media. The U-DeepONet is more accurate in predicting gas\nsaturation and pressure buildup than the state-of-the-art U-Net based Fourier\nNeural Operator (U-FNO) and the Fourier-enhanced Multiple-Input Operator\n(Fourier-MIONet) trained on the same dataset. In addition, the proposed\nU-DeepONet is significantly more efficient in training times than both the\nU-FNO (more than 18 times faster) and the Fourier-MIONet (more than 5 times\nfaster), while consuming less computational resources. We also show that the\nU-DeepONet is more data efficient and better at generalization than both the\nU-FNO and the Fourier-MIONet.",
            "author": [
                "Waleed Diab",
                "Mohammed Al-Kobaisi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15288v1",
                "http://arxiv.org/pdf/2311.15288v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15287v1",
            "title": "Spatial and Temporal Characteristics of Freight Tours: A Data-Driven\n  Exploratory Analysis",
            "updated": "2023-11-26T13:02:24Z",
            "published": "2023-11-26T13:02:24Z",
            "summary": "This paper presents a modeling approach to infer scheduling and routing\npatterns from digital freight transport activity data for different freight\nmarkets. We provide a complete modeling framework including a new\ndiscrete-continuous decision tree approach for extracting rules from the\nfreight transport data. We apply these models to collected tour data for the\nNetherlands to understand departure time patterns and tour strategies, also\nallowing us to evaluate the effectiveness of the proposed algorithm. We find\nthat spatial and temporal characteristics are important to capture the types of\ntours and time-of-day patterns of freight activities. Also, the empirical\nevidence indicates that carriers in most of the transport markets are sensitive\nto the level of congestion. Many of them adjust the type of tour, departure\ntime, and the number of stops per tour when facing a congested zone. The\nresults can be used by practitioners to get more grip on transport markets and\ndevelop freight and traffic management measures.",
            "author": [
                "Ali Nadi",
                "L\u00f3r\u00e1nt Tavasszy",
                "J. W. C. van Lint",
                "Maaike Snelder"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15287v1",
                "http://arxiv.org/pdf/2311.15287v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15283v1",
            "title": "Bias-Variance Trade-off in Physics-Informed Neural Networks with\n  Randomized Smoothing for High-Dimensional PDEs",
            "updated": "2023-11-26T12:50:28Z",
            "published": "2023-11-26T12:50:28Z",
            "summary": "While physics-informed neural networks (PINNs) have been proven effective for\nlow-dimensional partial differential equations (PDEs), the computational cost\nremains a hurdle in high-dimensional scenarios. This is particularly pronounced\nwhen computing high-order and high-dimensional derivatives in the\nphysics-informed loss. Randomized Smoothing PINN (RS-PINN) introduces Gaussian\nnoise for stochastic smoothing of the original neural net model, enabling Monte\nCarlo methods for derivative approximation, eliminating the need for costly\nauto-differentiation. Despite its computational efficiency in high dimensions,\nRS-PINN introduces biases in both loss and gradients, negatively impacting\nconvergence, especially when coupled with stochastic gradient descent (SGD). We\npresent a comprehensive analysis of biases in RS-PINN, attributing them to the\nnonlinearity of the Mean Squared Error (MSE) loss and the PDE nonlinearity. We\npropose tailored bias correction techniques based on the order of PDE\nnonlinearity. The unbiased RS-PINN allows for a detailed examination of its\npros and cons compared to the biased version. Specifically, the biased version\nhas a lower variance and runs faster than the unbiased version, but it is less\naccurate due to the bias. To optimize the bias-variance trade-off, we combine\nthe two approaches in a hybrid method that balances the rapid convergence of\nthe biased version with the high accuracy of the unbiased version. In addition,\nwe present an enhanced implementation of RS-PINN. Extensive experiments on\ndiverse high-dimensional PDEs, including Fokker-Planck, HJB, viscous Burgers',\nAllen-Cahn, and Sine-Gordon equations, illustrate the bias-variance trade-off\nand highlight the effectiveness of the hybrid RS-PINN. Empirical guidelines are\nprovided for selecting biased, unbiased, or hybrid versions, depending on the\ndimensionality and nonlinearity of the specific PDE problem.",
            "author": [
                "Zheyuan Hu",
                "Zhouhao Yang",
                "Yezhen Wang",
                "George Em Karniadakis",
                "Kenji Kawaguchi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15283v1",
                "http://arxiv.org/pdf/2311.15283v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.NA",
                "math.DS",
                "math.NA",
                "stat.ML",
                "14J60"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15280v1",
            "title": "Optimize the event selection strategy the study the anomalous quartic\n  gauge couplings at muon colliders using the support vector machine",
            "updated": "2023-11-26T12:48:15Z",
            "published": "2023-11-26T12:48:15Z",
            "summary": "The search of the new physics~(NP) beyond the Standard Model is one of the\nmost important topics in current high energy physics research. With the\nincreasing luminosities at the colliders, the search for NP signals requires\nthe analysis of more and more data, and the efficiency in data processing\nbecomes particularly important. As a machine learning algorithm, the support\nvector machine~(SVM) is expected to be useful in the search of NP, meanwhile,\nhas the potential to be accelerated with the help of quantum computing. How to\nuse the SVM to optimize an event selection strategy to search for NP signals is\nstudied in this paper. Taking the tri-photon process at a muon collider as an\nexample, it can be shown that the event selection strategy optimized by the SVM\nis effective in the search of the dimension-8 operators contributing to the\nanomalous quartic gauge couplings.",
            "author": [
                "Shuai Zhang",
                "Yu-Chen Guo",
                "Ji-Chong Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15280v1",
                "http://arxiv.org/pdf/2311.15280v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15276v1",
            "title": "Efficient Rehearsal Free Zero Forgetting Continual Learning using\n  Adaptive Weight Modulation",
            "updated": "2023-11-26T12:36:05Z",
            "published": "2023-11-26T12:36:05Z",
            "summary": "Artificial neural networks encounter a notable challenge known as continual\nlearning, which involves acquiring knowledge of multiple tasks over an extended\nperiod. This challenge arises due to the tendency of previously learned weights\nto be adjusted to suit the objectives of new tasks, resulting in a phenomenon\ncalled catastrophic forgetting. Most approaches to this problem seek a balance\nbetween maximizing performance on the new tasks and minimizing the forgetting\nof previous tasks. In contrast, our approach attempts to maximize the\nperformance of the new task, while ensuring zero forgetting. This is\naccomplished by creating a task-specific modulation parameters for each task.\nOnly these would be learnable parameters during learning of consecutive tasks.\nThrough comprehensive experimental evaluations, our model demonstrates superior\nperformance in acquiring and retaining novel tasks that pose difficulties for\nother multi-task models. This emphasizes the efficacy of our approach in\npreventing catastrophic forgetting while accommodating the acquisition of new\ntasks",
            "author": [
                "Yonatan Sverdlov",
                "Shimon Ullman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15276v1",
                "http://arxiv.org/pdf/2311.15276v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15268v1",
            "title": "Unlearning via Sparse Representations",
            "updated": "2023-11-26T11:12:30Z",
            "published": "2023-11-26T11:12:30Z",
            "summary": "Machine \\emph{unlearning}, which involves erasing knowledge about a\n\\emph{forget set} from a trained model, can prove to be costly and infeasible\nby existing techniques. We propose a nearly compute-free zero-shot unlearning\ntechnique based on a discrete representational bottleneck. We show that the\nproposed technique efficiently unlearns the forget set and incurs negligible\ndamage to the model's performance on the rest of the data set. We evaluate the\nproposed technique on the problem of \\textit{class unlearning} using three\ndatasets: CIFAR-10, CIFAR-100, and LACUNA-100. We compare the proposed\ntechnique to SCRUB, a state-of-the-art approach which uses knowledge\ndistillation for unlearning. Across all three datasets, the proposed technique\nperforms as well as, if not better than SCRUB while incurring almost no\ncomputational cost.",
            "author": [
                "Vedant Shah",
                "Frederik Tr\u00e4uble",
                "Ashish Malik",
                "Hugo Larochelle",
                "Michael Mozer",
                "Sanjeev Arora",
                "Yoshua Bengio",
                "Anirudh Goyal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15268v1",
                "http://arxiv.org/pdf/2311.15268v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15264v1",
            "title": "ChAda-ViT : Channel Adaptive Attention for Joint Representation Learning\n  of Heterogeneous Microscopy Images",
            "updated": "2023-11-26T10:38:47Z",
            "published": "2023-11-26T10:38:47Z",
            "summary": "Unlike color photography images, which are consistently encoded into RGB\nchannels, biological images encompass various modalities, where the type of\nmicroscopy and the meaning of each channel varies with each experiment.\nImportantly, the number of channels can range from one to a dozen and their\ncorrelation is often comparatively much lower than RGB, as each of them brings\nspecific information content. This aspect is largely overlooked by methods\ndesigned out of the bioimage field, and current solutions mostly focus on\nintra-channel spatial attention, often ignoring the relationship between\nchannels, yet crucial in most biological applications. Importantly, the\nvariable channel type and count prevent the projection of several experiments\nto a unified representation for large scale pre-training. In this study, we\npropose ChAda-ViT, a novel Channel Adaptive Vision Transformer architecture\nemploying an Inter-Channel Attention mechanism on images with an arbitrary\nnumber, order and type of channels. We also introduce IDRCell100k, a bioimage\ndataset with a rich set of 79 experiments covering 7 microscope modalities,\nwith a multitude of channel types, and channel counts varying from 1 to 10 per\nexperiment. Our proposed architecture, trained in a self-supervised manner,\noutperforms existing approaches in several biologically relevant downstream\ntasks. Additionally, it can be used to bridge the gap for the first time\nbetween assays with different microscopes, channel numbers or types by\nembedding various image and experimental modalities into a unified biological\nimage representation. The latter should facilitate interdisciplinary studies\nand pave the way for better adoption of deep learning in biological image-based\nanalyses. Code and Data to be released soon.",
            "author": [
                "Nicolas Bourriez",
                "Ihab Bendidi",
                "Ethan Cohen",
                "Gabriel Watkinson",
                "Maxime Sanchez",
                "Guillaume Bollot",
                "Auguste Genovesio"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15264v1",
                "http://arxiv.org/pdf/2311.15264v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15262v1",
            "title": "Revealing Cortical Layers In Histological Brain Images With\n  Self-Supervised Graph Convolutional Networks Applied To Cell-Graphs",
            "updated": "2023-11-26T10:33:36Z",
            "published": "2023-11-26T10:33:36Z",
            "summary": "Identifying cerebral cortex layers is crucial for comparative studies of the\ncytoarchitecture aiming at providing insights into the relations between brain\nstructure and function across species. The absence of extensive annotated\ndatasets typically limits the adoption of machine learning approaches, leading\nto the manual delineation of cortical layers by neuroanatomists. We introduce a\nself-supervised approach to detect layers in 2D Nissl-stained histological\nslices of the cerebral cortex. It starts with the segmentation of individual\ncells and the creation of an attributed cell-graph. A self-supervised graph\nconvolutional network generates cell embeddings that encode morphological and\nstructural traits of the cellular environment and are exploited by a community\ndetection algorithm for the final layering. Our method, the first\nself-supervised of its kind with no spatial transcriptomics data involved,\nholds the potential to accelerate cytoarchitecture analyses, sidestepping\nannotation needs and advancing cross-species investigation.",
            "author": [
                "Valentina Vadori",
                "Antonella Peruffo",
                "Jean-Marie Gra\u00efc",
                "Giulia Vadori",
                "Livio Finos",
                "Enrico Grisan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15262v1",
                "http://arxiv.org/pdf/2311.15262v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16192v1",
            "title": "Utilizing Multiple Inputs Autoregressive Models for Bearing Remaining\n  Useful Life Prediction",
            "updated": "2023-11-26T09:50:32Z",
            "published": "2023-11-26T09:50:32Z",
            "summary": "Accurate prediction of the Remaining Useful Life (RUL) of rolling bearings is\ncrucial in industrial production, yet existing models often struggle with\nlimited generalization capabilities due to their inability to fully process all\nvibration signal patterns. We introduce a novel multi-input autoregressive\nmodel to address this challenge in RUL prediction for bearings. Our approach\nuniquely integrates vibration signals with previously predicted Health\nIndicator (HI) values, employing feature fusion to output current window HI\nvalues. Through autoregressive iterations, the model attains a global receptive\nfield, effectively overcoming the limitations in generalization. Furthermore,\nwe innovatively incorporate a segmentation method and multiple training\niterations to mitigate error accumulation in autoregressive models. Empirical\nevaluation on the PMH2012 dataset demonstrates that our model, compared to\nother backbone networks using similar autoregressive approaches, achieves\nsignificantly lower Root Mean Square Error (RMSE) and Score. Notably, it\noutperforms traditional autoregressive models that use label values as inputs\nand non-autoregressive networks, showing superior generalization abilities with\na marked lead in RMSE and Score metrics.",
            "author": [
                "Junliang Wang",
                "Qinghua Zhang",
                "Guanhua Zhu",
                "Guoxi Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16192v1",
                "http://arxiv.org/pdf/2311.16192v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.00808v1",
            "title": "Transforming organic chemistry research paradigms: moving from manual\n  efforts to the intersection of automation and artificial intelligence",
            "updated": "2023-11-26T09:46:03Z",
            "published": "2023-11-26T09:46:03Z",
            "summary": "Organic chemistry is undergoing a major paradigm shift, moving from a\nlabor-intensive approach to a new era dominated by automation and artificial\nintelligence (AI). This transformative shift is being driven by technological\nadvances, the ever-increasing demand for greater research efficiency and\naccuracy, and the burgeoning growth of interdisciplinary research. AI models,\nsupported by computational power and algorithms, are drastically reshaping\nsynthetic planning and introducing groundbreaking ways to tackle complex\nmolecular synthesis. In addition, autonomous robotic systems are rapidly\naccelerating the pace of discovery by performing tedious tasks with\nunprecedented speed and precision. This article examines the multiple\nopportunities and challenges presented by this paradigm shift and explores its\nfar-reaching implications. It provides valuable insights into the future\ntrajectory of organic chemistry research, which is increasingly defined by the\nsynergistic interaction of automation and AI.",
            "author": [
                "Chengchun Liu",
                "Yuntian Chen",
                "Fanyang Mo"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00808v1",
                "http://arxiv.org/pdf/2312.00808v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15251v1",
            "title": "Should I use metaverse or not? An investigation of university students\n  behavioral intention to use MetaEducation technology",
            "updated": "2023-11-26T09:45:34Z",
            "published": "2023-11-26T09:45:34Z",
            "summary": "Metaverse, a burgeoning technological trend that combines virtual and\naugmented reality, provides users with a fully digital environment where they\ncan assume a virtual identity through a digital avatar and interact with others\nas they were in the real world. Its applications span diverse domains such as\neconomy (with its entry into the cryptocurrency field), finance, social life,\nworking environment, healthcare, real estate, and education. During the\nCOVID-19 and post-COVID-19 era, universities have rapidly adopted e-learning\ntechnologies to provide students with online access to learning content and\nplatforms, rendering previous considerations on integrating such technologies\nor preparing institutional infrastructures virtually obsolete. In light of this\ncontext, the present study proposes a framework for analyzing university\nstudents' acceptance and intention to use metaverse technologies in education,\ndrawing upon the Technology Acceptance Model (TAM). The study aims to\ninvestigate the relationship between students' intention to use metaverse\ntechnologies in education, hereafter referred to as MetaEducation, and selected\nTAM constructs, including Attitude, Perceived Usefulness, Perceived Ease of\nUse, Self-efficacy of metaverse technologies in education, and Subjective Norm.\nNotably, Self-efficacy and Subjective Norm have a positive influence on\nAttitude and Perceived Usefulness, whereas Perceived Ease of Use does not\nexhibit a strong correlation with Attitude or Perceived Usefulness. The authors\npostulate that the weak associations between the study's constructs may be\nattributed to limited knowledge regarding MetaEducation and its potential\nbenefits. Further investigation and analysis of the study's proposed model are\nwarranted to comprehensively understand the complex dynamics involved in the\nacceptance and utilization of MetaEducation technologies in the realm of higher\neducation",
            "author": [
                "Nikolaos Misirlis",
                "Yiannis Nikolaidis",
                "Anna Sabidussi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15251v1",
                "http://arxiv.org/pdf/2311.15251v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15249v1",
            "title": "Algorithm Evolution Using Large Language Model",
            "updated": "2023-11-26T09:38:44Z",
            "published": "2023-11-26T09:38:44Z",
            "summary": "Optimization can be found in many real-life applications. Designing an\neffective algorithm for a specific optimization problem typically requires a\ntedious amount of effort from human experts with domain knowledge and algorithm\ndesign skills. In this paper, we propose a novel approach called Algorithm\nEvolution using Large Language Model (AEL). It utilizes a large language model\n(LLM) to automatically generate optimization algorithms via an evolutionary\nframework. AEL does algorithm-level evolution without model training. Human\neffort and requirements for domain knowledge can be significantly reduced. We\ntake constructive methods for the salesman traveling problem as a test example,\nwe show that the constructive algorithm obtained by AEL outperforms simple\nhand-crafted and LLM-generated heuristics. Compared with other domain deep\nlearning model-based algorithms, these methods exhibit excellent scalability\nacross different problem sizes. AEL is also very different from previous\nattempts that utilize LLMs as search operators in algorithms.",
            "author": [
                "Fei Liu",
                "Xialiang Tong",
                "Mingxuan Yuan",
                "Qingfu Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15249v1",
                "http://arxiv.org/pdf/2311.15249v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15243v2",
            "title": "ID-like Prompt Learning for Few-Shot Out-of-Distribution Detection",
            "updated": "2023-11-28T13:06:43Z",
            "published": "2023-11-26T09:06:40Z",
            "summary": "Out-of-distribution (OOD) detection methods often exploit auxiliary outliers\nto train model identifying OOD samples, especially discovering challenging\noutliers from auxiliary outliers dataset to improve OOD detection. However,\nthey may still face limitations in effectively distinguishing between the most\nchallenging OOD samples that are much like in-distribution (ID) data, i.e.,\nID-like samples. To this end, we propose a novel OOD detection framework that\ndiscovers ID-like outliers using CLIP from the vicinity space of the ID\nsamples, thus helping to identify these most challenging OOD samples. Then a\nprompt learning framework is proposed that utilizes the identified ID-like\noutliers to further leverage the capabilities of CLIP for OOD detection.\nBenefiting from the powerful CLIP, we only need a small number of ID samples to\nlearn the prompts of the model without exposing other auxiliary outlier\ndatasets. By focusing on the most challenging ID-like OOD samples and elegantly\nexploiting the capabilities of CLIP, our method achieves superior few-shot\nlearning performance on various real-world image datasets (e.g., in 4-shot OOD\ndetection on the ImageNet-1k dataset, our method reduces the average FPR95 by\n12.16% and improves the average AUROC by 2.76%, compared to state-of-the-art\nmethods).",
            "author": [
                "Yichen Bai",
                "Zongbo Han",
                "Changqing Zhang",
                "Bing Cao",
                "Xiaoheng Jiang",
                "Qinghua Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15243v2",
                "http://arxiv.org/pdf/2311.15243v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15241v1",
            "title": "CalibFormer: A Transformer-based Automatic LiDAR-Camera Calibration\n  Network",
            "updated": "2023-11-26T08:59:30Z",
            "published": "2023-11-26T08:59:30Z",
            "summary": "The fusion of LiDARs and cameras has been increasingly adopted in autonomous\ndriving for perception tasks. The performance of such fusion-based algorithms\nlargely depends on the accuracy of sensor calibration, which is challenging due\nto the difficulty of identifying common features across different data\nmodalities. Previously, many calibration methods involved specific targets\nand/or manual intervention, which has proven to be cumbersome and costly.\nLearning-based online calibration methods have been proposed, but their\nperformance is barely satisfactory in most cases. These methods usually suffer\nfrom issues such as sparse feature maps, unreliable cross-modality association,\ninaccurate calibration parameter regression, etc. In this paper, to address\nthese issues, we propose CalibFormer, an end-to-end network for automatic\nLiDAR-camera calibration. We aggregate multiple layers of camera and LiDAR\nimage features to achieve high-resolution representations. A multi-head\ncorrelation module is utilized to identify correlations between features more\naccurately. Lastly, we employ transformer architectures to estimate accurate\ncalibration parameters from the correlation information. Our method achieved a\nmean translation error of $0.8751 \\mathrm{cm}$ and a mean rotation error of\n$0.0562 ^{\\circ}$ on the KITTI dataset, surpassing existing state-of-the-art\nmethods and demonstrating strong robustness, accuracy, and generalization\ncapabilities.",
            "author": [
                "Yuxuan Xiao",
                "Yao Li",
                "Chengzhen Meng",
                "Xingchen Li",
                "Yanyong Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15241v1",
                "http://arxiv.org/pdf/2311.15241v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15238v1",
            "title": "A Nearly Optimal and Low-Switching Algorithm for Reinforcement Learning\n  with General Function Approximation",
            "updated": "2023-11-26T08:31:57Z",
            "published": "2023-11-26T08:31:57Z",
            "summary": "The exploration-exploitation dilemma has been a central challenge in\nreinforcement learning (RL) with complex model classes. In this paper, we\npropose a new algorithm, Monotonic Q-Learning with Upper Confidence Bound\n(MQL-UCB) for RL with general function approximation. Our key algorithmic\ndesign includes (1) a general deterministic policy-switching strategy that\nachieves low switching cost, (2) a monotonic value function structure with\ncarefully controlled function class complexity, and (3) a variance-weighted\nregression scheme that exploits historical trajectories with high data\nefficiency. MQL-UCB achieves minimax optimal regret of $\\tilde{O}(d\\sqrt{HK})$\nwhen $K$ is sufficiently large and near-optimal policy switching cost of\n$\\tilde{O}(dH)$, with $d$ being the eluder dimension of the function class, $H$\nbeing the planning horizon, and $K$ being the number of episodes.\n  Our work sheds light on designing provably sample-efficient and\ndeployment-efficient Q-learning with nonlinear function approximation.",
            "author": [
                "Heyang Zhao",
                "Jiafan He",
                "Quanquan Gu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15238v1",
                "http://arxiv.org/pdf/2311.15238v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15232v1",
            "title": "Self-supervised learning based on Transformer for flow reconstruction\n  and prediction",
            "updated": "2023-11-26T08:14:09Z",
            "published": "2023-11-26T08:14:09Z",
            "summary": "Machine learning has great potential for efficient reconstruction and\nprediction of flow fields. However, existing datasets may have highly\ndiversified labels for different flow scenarios, which are not applicable for\ntraining a model. To this end, we make a first attempt to apply the\nself-supervised learning (SSL) technique to fluid dynamics, which disregards\ndata labels for pre-training the model. The SSL technique embraces a large\namount of data ($8000$ snapshots) at Reynolds numbers of $Re=200$, $300$,\n$400$, $500$ without discriminating between them, which improves the\ngeneralization of the model. The Transformer model is pre-trained via a\nspecially designed pretext task, where it reconstructs the complete flow fields\nafter randomly masking $20\\%$ data points in each snapshot. For the downstream\ntask of flow reconstruction, the pre-trained model is fine-tuned separately\nwith $256$ snapshots for each Reynolds number. The fine-tuned models accurately\nreconstruct the complete flow fields based on less than $5\\%$ random data\npoints within a limited window even for $Re=250$ and $600$, whose data were not\nseen in the pre-trained phase. For the other downstream task of flow\nprediction, the pre-training model is fine-tuned separately with $128$\nconsecutive snapshot pairs for each corresponding Reynolds number. The\nfine-tuned models then correctly predict the evolution of the flow fields over\nmany periods of cycles. We compare all results generated by models trained via\nSSL and models trained via supervised learning, where the former has\nunequivocally superior performance. We expect that the methodology presented\nhere will have wider applications in fluid mechanics",
            "author": [
                "Bonan Xu",
                "Yuanye Zhou",
                "Xin Bian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15232v1",
                "http://arxiv.org/pdf/2311.15232v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15231v1",
            "title": "Double Reverse Regularization Network Based on Self-Knowledge\n  Distillation for SAR Object Classification",
            "updated": "2023-11-26T08:09:43Z",
            "published": "2023-11-26T08:09:43Z",
            "summary": "In current synthetic aperture radar (SAR) object classification, one of the\nmajor challenges is the severe overfitting issue due to the limited dataset\n(few-shot) and noisy data. Considering the advantages of knowledge distillation\nas a learned label smoothing regularization, this paper proposes a novel Double\nReverse Regularization Network based on Self-Knowledge Distillation\n(DRRNet-SKD). Specifically, through exploring the effect of distillation weight\non the process of distillation, we are inspired to adopt the double reverse\nthought to implement an effective regularization network by combining offline\nand online distillation in a complementary way. Then, the Adaptive Weight\nAssignment (AWA) module is designed to adaptively assign two reverse-changing\nweights based on the network performance, allowing the student network to\nbetter benefit from both teachers. The experimental results on OpenSARShip and\nFUSAR-Ship demonstrate that DRRNet-SKD exhibits remarkable performance\nimprovement on classical CNNs, outperforming state-of-the-art self-knowledge\ndistillation methods.",
            "author": [
                "Bo Xu",
                "Hao Zheng",
                "Zhigang Hu",
                "Liu Yang",
                "Meiguang Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15231v1",
                "http://arxiv.org/pdf/2311.15231v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15225v1",
            "title": "One-bit Supervision for Image Classification: Problem, Solution, and\n  Beyond",
            "updated": "2023-11-26T07:39:00Z",
            "published": "2023-11-26T07:39:00Z",
            "summary": "This paper presents one-bit supervision, a novel setting of learning with\nfewer labels, for image classification. Instead of training model using the\naccurate label of each sample, our setting requires the model to interact with\nthe system by predicting the class label of each sample and learn from the\nanswer whether the guess is correct, which provides one bit (yes or no) of\ninformation. An intriguing property of the setting is that the burden of\nannotation largely alleviates in comparison to offering the accurate label.\nThere are two keys to one-bit supervision, which are (i) improving the guess\naccuracy and (ii) making good use of the incorrect guesses. To achieve these\ngoals, we propose a multi-stage training paradigm and incorporate negative\nlabel suppression into an off-the-shelf semi-supervised learning algorithm.\nTheoretical analysis shows that one-bit annotation is more efficient than\nfull-bit annotation in most cases and gives the conditions of combining our\napproach with active learning. Inspired by this, we further integrate the\none-bit supervision framework into the self-supervised learning algorithm which\nyields an even more efficient training schedule. Different from training from\nscratch, when self-supervised learning is used for initialization, both hard\nexample mining and class balance are verified effective in boosting the\nlearning performance. However, these two frameworks still need full-bit labels\nin the initial stage. To cast off this burden, we utilize unsupervised domain\nadaptation to train the initial model and conduct pure one-bit annotations on\nthe target dataset. In multiple benchmarks, the learning efficiency of the\nproposed approach surpasses that using full-bit, semi-supervised supervision.",
            "author": [
                "Hengtong Hu",
                "Lingxi Xie",
                "Xinyue Hue",
                "Richang Hong",
                "Qi Tian"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3633779",
                "http://arxiv.org/abs/2311.15225v1",
                "http://arxiv.org/pdf/2311.15225v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14742v1",
            "title": "Query-LIFE: Query-aware Language Image Fusion Embedding for E-Commerce\n  Relevance",
            "updated": "2023-11-26T07:34:18Z",
            "published": "2023-11-26T07:34:18Z",
            "summary": "Relevance module plays a fundamental role in e-commerce search as they are\nresponsible for selecting relevant products from thousands of items based on\nuser queries, thereby enhancing users experience and efficiency. The\ntraditional approach models the relevance based product titles and queries, but\nthe information in titles alone maybe insufficient to describe the products\ncompletely. A more general optimization approach is to further leverage product\nimage information. In recent years, vision-language pre-training models have\nachieved impressive results in many scenarios, which leverage contrastive\nlearning to map both textual and visual features into a joint embedding space.\nIn e-commerce, a common practice is to fine-tune on the pre-trained model based\non e-commerce data. However, the performance is sub-optimal because the\nvision-language pre-training models lack of alignment specifically designed for\nqueries. In this paper, we propose a method called Query-LIFE (Query-aware\nLanguage Image Fusion Embedding) to address these challenges. Query-LIFE\nutilizes a query-based multimodal fusion to effectively incorporate the image\nand title based on the product types. Additionally, it employs query-aware\nmodal alignment to enhance the accuracy of the comprehensive representation of\nproducts. Furthermore, we design GenFilt, which utilizes the generation\ncapability of large models to filter out false negative samples and further\nimprove the overall performance of the contrastive learning task in the model.\nExperiments have demonstrated that Query-LIFE outperforms existing baselines.\nWe have conducted ablation studies and human evaluations to validate the\neffectiveness of each module within Query-LIFE. Moreover, Query-LIFE has been\ndeployed on Miravia Search, resulting in improved both relevance and conversion\nefficiency.",
            "author": [
                "Hai Zhu",
                "Yuankai Guo",
                "Ronggang Dou",
                "Kai Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14742v1",
                "http://arxiv.org/pdf/2311.14742v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15222v2",
            "title": "Decision Tree Psychological Risk Assessment in Currency Trading",
            "updated": "2023-12-01T08:43:14Z",
            "published": "2023-11-26T07:23:37Z",
            "summary": "This research paper focuses on the integration of Artificial Intelligence\n(AI) into the currency trading landscape, positing the development of\npersonalized AI models, essentially functioning as intelligent personal\nassistants tailored to the idiosyncrasies of individual traders. The paper\nposits that AI models are capable of identifying nuanced patterns within the\ntrader's historical data, facilitating a more accurate and insightful\nassessment of psychological risk dynamics in currency trading. The PRI is a\ndynamic metric that experiences fluctuations in response to market conditions\nthat foster psychological fragility among traders. By employing sophisticated\ntechniques, a classifying decision tree is crafted, enabling clearer\ndecision-making boundaries within the tree structure. By incorporating the\nuser's chronological trade entries, the model becomes adept at identifying\ncritical junctures when psychological risks are heightened. The real-time\nnature of the calculations enhances the model's utility as a proactive tool,\noffering timely alerts to traders about impending moments of psychological\nrisks. The implications of this research extend beyond the confines of currency\ntrading, reaching into the realms of other industries where the judicious\napplication of personalized modeling emerges as an efficient and strategic\napproach. This paper positions itself at the intersection of cutting-edge\ntechnology and the intricate nuances of human psychology, offering a\ntransformative paradigm for decision making support in dynamic and\nhigh-pressure environments.",
            "author": [
                "Jai Pal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15222v2",
                "http://arxiv.org/pdf/2311.15222v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CE",
                "q-fin.GN"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15221v1",
            "title": "The Local Landscape of Phase Retrieval Under Limited Samples",
            "updated": "2023-11-26T07:22:35Z",
            "published": "2023-11-26T07:22:35Z",
            "summary": "In this paper, we provide a fine-grained analysis of the local landscape of\nphase retrieval under the regime with limited samples. Our aim is to ascertain\nthe minimal sample size necessary to guarantee a benign local landscape\nsurrounding global minima in high dimensions. Let $n$ and $d$ denote the sample\nsize and input dimension, respectively. We first explore the local convexity\nand establish that when $n=o(d\\log d)$, for almost every fixed point in the\nlocal ball, the Hessian matrix must have negative eigenvalues as long as $d$ is\nsufficiently large. Consequently, the local landscape is highly non-convex. We\nnext consider the one-point strong convexity and show that as long as\n$n=\\omega(d)$, with high probability, the landscape is one-point strongly\nconvex in the local annulus: $\\{w\\in\\mathbb{R}^d: o_d(1)\\leqslant\n\\|w-w^*\\|\\leqslant c\\}$, where $w^*$ is the ground truth and $c$ is an absolute\nconstant. This implies that gradient descent initialized from any point in this\ndomain can converge to an $o_d(1)$-loss solution exponentially fast.\nFurthermore, we show that when $n=o(d\\log d)$, there is a radius of\n$\\widetilde\\Theta\\left(\\sqrt{1/d}\\right)$ such that one-point convexity breaks\nin the corresponding smaller local ball. This indicates an impossibility to\nestablish a convergence to exact $w^*$ for gradient descent under limited\nsamples by relying solely on one-point convexity.",
            "author": [
                "Kaizhao Liu",
                "Zihao Wang",
                "Lei Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15221v1",
                "http://arxiv.org/pdf/2311.15221v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.LG",
                "eess.SP",
                "math.IT",
                "math.OC",
                "math.ST",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15218v2",
            "title": "Real-Time Online Stock Forecasting Utilizing Integrated Quantitative and\n  Qualitative Analysis",
            "updated": "2023-12-05T14:49:36Z",
            "published": "2023-11-26T07:19:10Z",
            "summary": "The application of Machine learning to finance has become a familiar\napproach, even more so in stock market forecasting. The stock market is highly\nvolatile and huge amounts of data are generated every minute globally. The\nextraction of effective intelligence from this data is of critical importance.\nHowever, a collaboration of numerical stock data with qualitative text data can\nbe a challenging task. In this work, we accomplish this and provide an\nunprecedented, publicly available dataset with technical and fundamental data,\nsentiment that we gathered from News Archives, TV news captions, Radio\nTranscripts, Tweets, Daily financial newspapers, etc. The text data entries\nused for sentiment extraction total more than 1.4 Million. The dataset consists\nof daily entries from January 2018 to December 2022 for 8 companies\nrepresenting diverse industrial sectors and the Dow Jones Industrial Average\n(DJIA) as a whole. Holistic Fundamental and Technical data is provided training\nready for Model learning and deployment. The data generated could be used for\nIncremental online learning with real-time data points retrieved daily, since\nthere was no stagnant data utilized, all the data was retired from APIs or\nself-designed scripts. Moreover, the utilization of Spearman's rank correlation\nover real-time data, linking stock returns with sentiment analysis has produced\nnoteworthy results for the DJIA achieving accuracy levels surpassing 60\\%. The\ndataset is made available at https://github.com/batking24/Huge-Stock-Dataset",
            "author": [
                "Sai Akash Bathini",
                "Dagli Cihan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15218v2",
                "http://arxiv.org/pdf/2311.15218v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15216v1",
            "title": "Solve Large-scale Unit Commitment Problems by Physics-informed Graph\n  Learning",
            "updated": "2023-11-26T07:17:45Z",
            "published": "2023-11-26T07:17:45Z",
            "summary": "Unit commitment (UC) problems are typically formulated as mixed-integer\nprograms (MIP) and solved by the branch-and-bound (B&B) scheme. The recent\nadvances in graph neural networks (GNN) enable it to enhance the B&B algorithm\nin modern MIP solvers by learning to dive and branch. Existing GNN models that\ntackle MIP problems are mostly constructed from mathematical formulation, which\nis computationally expensive when dealing with large-scale UC problems. In this\npaper, we propose a physics-informed hierarchical graph convolutional network\n(PI-GCN) for neural diving that leverages the underlying features of various\ncomponents of power systems to find high-quality variable assignments.\nFurthermore, we adopt the MIP model-based graph convolutional network (MB-GCN)\nfor neural branching to select the optimal variables for branching at each node\nof the B&B tree. Finally, we integrate neural diving and neural branching into\na modern MIP solver to establish a novel neural MIP solver designed for\nlarge-scale UC problems. Numeral studies show that PI-GCN has better\nperformance and scalability than the baseline MB-GCN on neural diving.\nMoreover, the neural MIP solver yields the lowest operational cost and\noutperforms a modern MIP solver for all testing days after combining it with\nour proposed neural diving model and the baseline neural branching model.",
            "author": [
                "Jingtao Qin",
                "Nanpeng Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15216v1",
                "http://arxiv.org/pdf/2311.15216v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15214v1",
            "title": "A Novel Normalized-Cut Solver with Nearest Neighbor Hierarchical\n  Initialization",
            "updated": "2023-11-26T07:11:58Z",
            "published": "2023-11-26T07:11:58Z",
            "summary": "Normalized-Cut (N-Cut) is a famous model of spectral clustering. The\ntraditional N-Cut solvers are two-stage: 1) calculating the continuous spectral\nembedding of normalized Laplacian matrix; 2) discretization via $K$-means or\nspectral rotation. However, this paradigm brings two vital problems: 1)\ntwo-stage methods solve a relaxed version of the original problem, so they\ncannot obtain good solutions for the original N-Cut problem; 2) solving the\nrelaxed problem requires eigenvalue decomposition, which has $\\mathcal{O}(n^3)$\ntime complexity ($n$ is the number of nodes). To address the problems, we\npropose a novel N-Cut solver designed based on the famous coordinate descent\nmethod. Since the vanilla coordinate descent method also has $\\mathcal{O}(n^3)$\ntime complexity, we design various accelerating strategies to reduce the time\ncomplexity to $\\mathcal{O}(|E|)$ ($|E|$ is the number of edges). To avoid\nreliance on random initialization which brings uncertainties to clustering, we\npropose an efficient initialization method that gives deterministic outputs.\nExtensive experiments on several benchmark datasets demonstrate that the\nproposed solver can obtain larger objective values of N-Cut, meanwhile\nachieving better clustering performance compared to traditional solvers.",
            "author": [
                "Feiping Nie",
                "Jitao Lu",
                "Danyang Wu",
                "Rong Wang",
                "Xuelong Li"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TPAMI.2023.3279394",
                "http://arxiv.org/abs/2311.15214v1",
                "http://arxiv.org/pdf/2311.15214v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15213v1",
            "title": "Leveraging Anatomical Constraints with Uncertainty for Pneumothorax\n  Segmentation",
            "updated": "2023-11-26T07:03:17Z",
            "published": "2023-11-26T07:03:17Z",
            "summary": "Pneumothorax is a medical emergency caused by abnormal accumulation of air in\nthe pleural space - the potential space between the lungs and chest wall. On 2D\nchest radiographs, pneumothorax occurs within the thoracic cavity and outside\nof the mediastinum and we refer to this area as \"lung+ space\". While deep\nlearning (DL) has increasingly been utilized to segment pneumothorax lesions in\nchest radiographs, many existing DL models employ an end-to-end approach. These\nmodels directly map chest radiographs to clinician-annotated lesion areas,\noften neglecting the vital domain knowledge that pneumothorax is inherently\nlocation-sensitive.\n  We propose a novel approach that incorporates the lung+ space as a constraint\nduring DL model training for pneumothorax segmentation on 2D chest radiographs.\nTo circumvent the need for additional annotations and to prevent potential\nlabel leakage on the target task, our method utilizes external datasets and an\nauxiliary task of lung segmentation. This approach generates a specific\nconstraint of lung+ space for each chest radiograph. Furthermore, we have\nincorporated a discriminator to eliminate unreliable constraints caused by the\ndomain shift between the auxiliary and target datasets.\n  Our results demonstrated significant improvements, with average performance\ngains of 4.6%, 3.6%, and 3.3% regarding Intersection over Union (IoU), Dice\nSimilarity Coefficient (DSC), and Hausdorff Distance (HD). Our research\nunderscores the significance of incorporating medical domain knowledge about\nthe location-specific nature of pneumothorax to enhance DL-based lesion\nsegmentation.",
            "author": [
                "Han Yuan",
                "Chuan Hong",
                "Nguyen Tuan Anh Tran",
                "Xinxing Xu",
                "Nan Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15213v1",
                "http://arxiv.org/pdf/2311.15213v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15211v1",
            "title": "Probabilistic Transformer: A Probabilistic Dependency Model for\n  Contextual Word Representation",
            "updated": "2023-11-26T06:56:02Z",
            "published": "2023-11-26T06:56:02Z",
            "summary": "Syntactic structures used to play a vital role in natural language processing\n(NLP), but since the deep learning revolution, NLP has been gradually dominated\nby neural models that do not consider syntactic structures in their design. One\nvastly successful class of neural models is transformers. When used as an\nencoder, a transformer produces contextual representation of words in the input\nsentence. In this work, we propose a new model of contextual word\nrepresentation, not from a neural perspective, but from a purely syntactic and\nprobabilistic perspective. Specifically, we design a conditional random field\nthat models discrete latent representations of all words in a sentence as well\nas dependency arcs between them; and we use mean field variational inference\nfor approximate inference. Strikingly, we find that the computation graph of\nour model resembles transformers, with correspondences between dependencies and\nself-attention and between distributions over latent representations and\ncontextual embeddings of words. Experiments show that our model performs\ncompetitively to transformers on small to medium sized datasets. We hope that\nour work could help bridge the gap between traditional syntactic and\nprobabilistic approaches and cutting-edge neural approaches to NLP, and inspire\nmore linguistically-principled neural approaches in the future.",
            "author": [
                "Haoyi Wu",
                "Kewei Tu"
            ],
            "link": [
                "http://dx.doi.org/10.18653/v1/2023.findings-acl.482",
                "http://arxiv.org/abs/2311.15211v1",
                "http://arxiv.org/pdf/2311.15211v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15210v1",
            "title": "Topology combined machine learning for consonant recognition",
            "updated": "2023-11-26T06:53:56Z",
            "published": "2023-11-26T06:53:56Z",
            "summary": "In artificial-intelligence-aided signal processing, existing deep learning\nmodels often exhibit a black-box structure, and their validity and\ncomprehensibility remain elusive. The integration of topological methods,\ndespite its relatively nascent application, serves a dual purpose of making\nmodels more interpretable as well as extracting structural information from\ntime-dependent data for smarter learning. Here, we provide a transparent and\nbroadly applicable methodology, TopCap, to capture the most salient topological\nfeatures inherent in time series for machine learning. Rooted in\nhigh-dimensional ambient spaces, TopCap is capable of capturing features rarely\ndetected in datasets with low intrinsic dimensionality. Applying time-delay\nembedding and persistent homology, we obtain descriptors which encapsulate\ninformation such as the vibration of a time series, in terms of its variability\nof frequency, amplitude, and average line, demonstrated with simulated data.\nThis information is then vectorised and fed into multiple machine learning\nalgorithms such as k-nearest neighbours and support vector machine. Notably, in\nclassifying voiced and voiceless consonants, TopCap achieves an accuracy\nexceeding 96% and is geared towards designing topological convolutional layers\nfor deep learning of speech and audio signals.",
            "author": [
                "Pingyao Feng",
                "Siheng Yi",
                "Qingrui Qu",
                "Zhiwang Yu",
                "Yifei Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15210v1",
                "http://arxiv.org/pdf/2311.15210v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15207v1",
            "title": "Efficient interpolation of molecular properties across chemical compound\n  space with low-dimensional descriptors",
            "updated": "2023-11-26T06:22:13Z",
            "published": "2023-11-26T06:22:13Z",
            "summary": "We demonstrate accurate data-starved models of molecular properties for\ninterpolation in chemical compound spaces with low-dimensional descriptors.\n  Our starting point is based on three-dimensional, universal, physical\ndescriptors derived from the properties of the distributions of the eigenvalues\nof Coulomb matrices. To account for the shape and composition of molecules, we\ncombine these descriptors with six-dimensional features informed by the\nGershgorin circle theorem. We use the nine-dimensional descriptors thus\nobtained for Gaussian process regression based on kernels with variable\nfunctional form, leading to extremely efficient, low-dimensional interpolation\nmodels. The resulting models trained with 100 molecules are able to predict the\nproduct of entropy and temperature ($S \\times T$) and zero point vibrational\nenergy (ZPVE) with the absolute error under 1 kcal mol$^{-1}$ for $> 78$ \\% and\nunder 1.3 kcal mol$^{-1}$ for $> 92$ \\% of molecules in the test data. The test\ndata comprises 20,000 molecules with complexity varying from three atoms to 29\natoms and the ranges of $S \\times T$ and ZPVE covering 36 kcal mol$^{-1}$ and\n161 kcal mol$^{-1}$, respectively. We also illustrate that the descriptors\nbased on the Gershgorin circle theorem yield more accurate models of molecular\nentropy than those based on graph neural networks that explicitly account for\nthe atomic connectivity of molecules.",
            "author": [
                "Yun-Wen Mao",
                "Roman V. Krems"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15207v1",
                "http://arxiv.org/pdf/2311.15207v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15206v1",
            "title": "Insect-Foundation: A Foundation Model and Large-scale 1M Dataset for\n  Visual Insect Understanding",
            "updated": "2023-11-26T06:17:29Z",
            "published": "2023-11-26T06:17:29Z",
            "summary": "In precision agriculture, the detection and recognition of insects play an\nessential role in the ability of crops to grow healthy and produce a\nhigh-quality yield. The current machine vision model requires a large volume of\ndata to achieve high performance. However, there are approximately 5.5 million\ndifferent insect species in the world. None of the existing insect datasets can\ncover even a fraction of them due to varying geographic locations and\nacquisition costs. In this paper, we introduce a novel ``Insect-1M'' dataset, a\ngame-changing resource poised to revolutionize insect-related foundation model\ntraining. Covering a vast spectrum of insect species, our dataset, including 1\nmillion images with dense identification labels of taxonomy hierarchy and\ninsect descriptions, offers a panoramic view of entomology, enabling foundation\nmodels to comprehend visual and semantic information about insects like never\nbefore. Then, to efficiently establish an Insect Foundation Model, we develop a\nmicro-feature self-supervised learning method with a Patch-wise Relevant\nAttention mechanism capable of discerning the subtle differences among insect\nimages. In addition, we introduce Description Consistency loss to improve\nmicro-feature modeling via insect descriptions. Through our experiments, we\nillustrate the effectiveness of our proposed approach in insect modeling and\nachieve State-of-the-Art performance on standard benchmarks of insect-related\ntasks. Our Insect Foundation Model and Dataset promise to empower the next\ngeneration of insect-related vision models, bringing them closer to the\nultimate goal of precision agriculture.",
            "author": [
                "Hoang-Quan Nguyen",
                "Thanh-Dat Truong",
                "Xuan Bac Nguyen",
                "Ashley Dowling",
                "Xin Li",
                "Khoa Luu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15206v1",
                "http://arxiv.org/pdf/2311.15206v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15203v1",
            "title": "Learning against Non-credible Auctions",
            "updated": "2023-11-26T05:50:59Z",
            "published": "2023-11-26T05:50:59Z",
            "summary": "The standard framework of online bidding algorithm design assumes that the\nseller commits himself to faithfully implementing the rules of the adopted\nauction. However, the seller may attempt to cheat in execution to increase his\nrevenue if the auction belongs to the class of non-credible auctions. For\nexample, in a second-price auction, the seller could create a fake bid between\nthe highest bid and the second highest bid. This paper focuses on one such case\nof online bidding in repeated second-price auctions. At each time $t$, the\nwinner with bid $b_t$ is charged not the highest competing bid $d_t$ but a\nmanipulated price $p_t = \\alpha_0 d_t + (1-\\alpha_0) b_t$, where the parameter\n$\\alpha_0 \\in [0, 1]$ in essence measures the seller's credibility. Unlike\nclassic repeated-auction settings where the bidder has access to samples\n$(d_s)_{s=1}^{t-1}$, she can only receive mixed signals of $(b_s)_{s=1}^{t-1}$,\n$(d_s)_{s=1}^{t-1}$ and $\\alpha_0$ in this problem. The task for the bidder is\nto learn not only the bid distributions of her competitors but also the\nseller's credibility. We establish regret lower bounds in various information\nmodels and provide corresponding online bidding algorithms that can achieve\nnear-optimal performance. Specifically, we consider three cases of prior\ninformation based on whether the credibility $\\alpha_0$ and the distribution of\nthe highest competing bids are known. Our goal is to characterize the landscape\nof online bidding in non-credible auctions and understand the impact of the\nseller's credibility on online bidding algorithm design under different\ninformation structures.",
            "author": [
                "Qian Wang",
                "Xuanzhi Xia",
                "Zongjun Yang",
                "Xiaotie Deng",
                "Yuqing Kong",
                "Zhilin Zhang",
                "Liang Wang",
                "Chuan Yu",
                "Jian Xu",
                "Bo Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15203v1",
                "http://arxiv.org/pdf/2311.15203v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15202v2",
            "title": "Dual-stream contrastive predictive network with joint handcrafted\n  feature view for SAR ship classification",
            "updated": "2023-11-30T10:45:11Z",
            "published": "2023-11-26T05:47:01Z",
            "summary": "Most existing synthetic aperture radar (SAR) ship classification technologies\nheavily rely on correctly labeled data, ignoring the discriminative features of\nunlabeled SAR ship images. Even though researchers try to enrich CNN-based\nfeatures by introducing traditional handcrafted features, existing methods\neasily cause information redundancy and fail to capture the interaction between\nthem. To address these issues, we propose a novel dual-stream contrastive\npredictive network (DCPNet), which consists of two asymmetric task designs and\nthe false negative sample elimination module. The first task is to construct\npositive sample pairs, guiding the core encoder to learn more general\nrepresentations. The second task is to encourage adaptive capture of the\ncorrespondence between deep features and handcrated features, achieving\nknowledge transfer within the model, and effectively improving the redundancy\ncaused by the feature fusion. To increase the separability between clusters, we\nalso design a cluster-level tasks. The experimental results on OpenSARShip and\nFUSAR-Ship datasets demonstrate the improvement in classification accuracy of\nsupervised models and confirm the capability of learning effective\nrepresentations of DCPNet.",
            "author": [
                "Xianting Feng",
                "Hao zheng",
                "Zhigang Hu",
                "Liu Yang",
                "Meiguang Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15202v2",
                "http://arxiv.org/pdf/2311.15202v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15201v1",
            "title": "DiffBind: A SE(3) Equivariant Network for Accurate Full-Atom\n  Semi-Flexible Protein-Ligand Docking",
            "updated": "2023-11-26T05:46:19Z",
            "published": "2023-11-26T05:46:19Z",
            "summary": "Molecular docking, a key technique in structure-based drug design (SBDD),\nplays a pivotal role in hit identification for specific targets. Accurate\nprediction of protein-ligand binding mode is important for precise scoring and\nrational molecular optimization. Notwithstanding its significance, modelling\nprecise and physically plausible binding conformations is a largely unsolved\nproblem in the real-world docking scenario. Flexible docking is a daunting task\nas modeling protein conformation changes upon ligand binding is extremely\ncomputationally expensive and inaccurate. Currently available deep learning\ndocking methods ignore protein flexibility and fail to ensure the physical\nplausibility and detailed interactions. In this study, we present DiffBind, a\ncomprehensive full-atom diffusion-based semi-flexible docking model that\noperates over the product space of ligand movements (translation, rotation, and\ntorsion) and pocket side chain torsion changes. Evaluations reveal that\nDiffBind has considerably higher accuracy in producing native-like binding\nstructures with physically plausible and detailed interactions than traditional\ndocking methods and other deep learning-based approaches. Even in the\nAlphaFold2 modeled structures, DiffBind still demonstrates superior advantages\nin accurate pose prediction and structure refinement. DiffBind should be useful\nfor modeling the pocket-ligand binding structure with significant side chain\nflexibility and virtual screening.",
            "author": [
                "Jintao Zhu",
                "Zhonghui Gu",
                "Jianfeng Pei",
                "Luhua Lai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15201v1",
                "http://arxiv.org/pdf/2311.15201v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15200v1",
            "title": "SpliceMix: A Cross-scale and Semantic Blending Augmentation Strategy for\n  Multi-label Image Classification",
            "updated": "2023-11-26T05:45:27Z",
            "published": "2023-11-26T05:45:27Z",
            "summary": "Recently, Mix-style data augmentation methods (e.g., Mixup and CutMix) have\nshown promising performance in various visual tasks. However, these methods are\nprimarily designed for single-label images, ignoring the considerable\ndiscrepancies between single- and multi-label images, i.e., a multi-label image\ninvolves multiple co-occurred categories and fickle object scales. On the other\nhand, previous multi-label image classification (MLIC) methods tend to design\nelaborate models, bringing expensive computation. In this paper, we introduce a\nsimple but effective augmentation strategy for multi-label image\nclassification, namely SpliceMix. The \"splice\" in our method is two-fold: 1)\nEach mixed image is a splice of several downsampled images in the form of a\ngrid, where the semantics of images attending to mixing are blended without\nobject deficiencies for alleviating co-occurred bias; 2) We splice mixed images\nand the original mini-batch to form a new SpliceMixed mini-batch, which allows\nan image with different scales to contribute to training together. Furthermore,\nsuch splice in our SpliceMixed mini-batch enables interactions between mixed\nimages and original regular images. We also offer a simple and non-parametric\nextension based on consistency learning (SpliceMix-CL) to show the flexible\nextensibility of our SpliceMix. Extensive experiments on various tasks\ndemonstrate that only using SpliceMix with a baseline model (e.g., ResNet)\nachieves better performance than state-of-the-art methods. Moreover, the\ngeneralizability of our SpliceMix is further validated by the improvements in\ncurrent MLIC methods when married with our SpliceMix. The code is available at\nhttps://github.com/zuiran/SpliceMix.",
            "author": [
                "Lei Wang",
                "Yibing Zhan",
                "Leilei Ma",
                "Dapeng Tao",
                "Liang Ding",
                "Chen Gong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15200v1",
                "http://arxiv.org/pdf/2311.15200v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15198v1",
            "title": "ChatGPT and Beyond: The Generative AI Revolution in Education",
            "updated": "2023-11-26T05:34:22Z",
            "published": "2023-11-26T05:34:22Z",
            "summary": "The wide adoption and usage of generative artificial intelligence (AI)\nmodels, particularly ChatGPT, has sparked a surge in research exploring their\npotential applications in the educational landscape. This survey examines\nacademic literature published between November, 2022, and July, 2023,\nspecifically targeting high-impact research from Scopus-indexed Q1 and Q2\njournals. This survey delves into the practical applications and implications\nof generative AI models across a diverse range of educational contexts. Through\na comprehensive and rigorous evaluation of recent academic literature, this\nsurvey seeks to illuminate the evolving role of generative AI models,\nparticularly ChatGPT, in education. By shedding light on the potential\nbenefits, challenges, and emerging trends in this dynamic field, the survey\nendeavors to contribute to the understanding of the nexus between artificial\nintelligence and education. The findings of this review will empower educators,\nresearchers, and policymakers to make informed decisions about the integration\nof AI technologies into learning environments.",
            "author": [
                "Mohammad AL-Smadi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15198v1",
                "http://arxiv.org/pdf/2311.15198v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15194v1",
            "title": "Neural Network Models of Becoming a Cardinal Principle Knower",
            "updated": "2023-11-26T05:17:45Z",
            "published": "2023-11-26T05:17:45Z",
            "summary": "As children enter elementary school, their understanding of the ordinal\nstructure of numbers transitions from a memorized count list of the first\n50-100 numbers to knowing the successor function and understanding the\ncountably infinite. We investigate this developmental change in two neural\nnetwork models that learn the successor function on the pairs (N, N+1) for N in\n(0, 98). The first uses a one-hot encoding of the input and output values and\ncorresponds to children memorizing a count list, while the second model uses a\nplace-value encoding and corresponds to children learning the language rules\nfor naming numbers. The place-value model showed a predicted drop in\nrepresentational similarity across tens boundaries. Counting across a tens\nboundary can be understood as a vector operation in 2D space, where the numbers\nwith the same tens place are organized in a linearly separable manner, whereas\nthose with the same ones place are grouped together. A curriculum learning\nsimulation shows that, in the expanding numerical environment of the developing\nchild, representations of smaller numbers continue to be sharpened even as\nlarger numbers begin to be learned. These models set the stage for future work\nusing recurrent architectures to move beyond learning the successor function to\nsimulating the counting process more generally, and point towards a deeper\nunderstanding of what it means to understand the countably infinite.",
            "author": [
                "Vima Gupta",
                "Sashank Varma"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15194v1",
                "http://arxiv.org/pdf/2311.15194v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16191v1",
            "title": "MACE: A Multi-pattern Accommodated and Efficient Anomaly Detection\n  Method in the Frequency Domain",
            "updated": "2023-11-26T03:31:43Z",
            "published": "2023-11-26T03:31:43Z",
            "summary": "Anomaly detection significantly enhances the robustness of cloud systems.\nWhile neural network-based methods have recently demonstrated strong\nadvantages, they encounter practical challenges in cloud environments: the\ncontradiction between the impracticality of maintaining a unique model for each\nservice and the limited ability of dealing with diverse normal patterns by a\nunified model, as well as issues with handling heavy traffic in real time and\nshort-term anomaly detection sensitivity. Thus, we propose MACE, a\nMulti-pattern Accommodated and efficient Anomaly detection method in the\nfrequency domain for time series anomaly detection. There are three novel\ncharacteristics of it: (i) a pattern extraction mechanism excelling at handling\ndiverse normal patterns, which enables the model to identify anomalies by\nexamining the correlation between the data sample and its service normal\npattern, instead of solely focusing on the data sample itself; (ii) a dualistic\nconvolution mechanism that amplifies short-term anomalies in the time domain\nand hinders the reconstruction of anomalies in the frequency domain, which\nenlarges the reconstruction error disparity between anomaly and normality and\nfacilitates anomaly detection; (iii) leveraging the sparsity and parallelism of\nfrequency domain to enhance model efficiency. We theoretically and\nexperimentally prove that using a strategically selected subset of Fourier\nbases can not only reduce computational overhead but is also profit to\ndistinguish anomalies, compared to using the complete spectrum. Moreover,\nextensive experiments demonstrate MACE's effectiveness in handling diverse\nnormal patterns with a unified model and it achieves state-of-the-art\nperformance with high efficiency. \\end{abstract}",
            "author": [
                "Feiyi Chen",
                "Yingying zhang",
                "Zhen Qin",
                "Lunting Fan",
                "Renhe Jiang",
                "Yuxuan Liang",
                "Qingsong Wen",
                "Shuiguang Deng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16191v1",
                "http://arxiv.org/pdf/2311.16191v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15171v1",
            "title": "HumanRecon: Neural Reconstruction of Dynamic Human Using Geometric Cues\n  and Physical Priors",
            "updated": "2023-11-26T03:06:59Z",
            "published": "2023-11-26T03:06:59Z",
            "summary": "Recent methods for dynamic human reconstruction have attained promising\nreconstruction results. Most of these methods rely only on RGB color\nsupervision without considering explicit geometric constraints. This leads to\nexisting human reconstruction techniques being more prone to overfitting to\ncolor and causes geometrically inherent ambiguities, especially in the sparse\nmulti-view setup.\n  Motivated by recent advances in the field of monocular geometry prediction,\nwe consider the geometric constraints of estimated depth and normals in the\nlearning of neural implicit representation for dynamic human reconstruction. As\na geometric regularization, this provides reliable yet explicit supervision\ninformation, and improves reconstruction quality. We also exploit several\nbeneficial physical priors, such as adding noise into view direction and\nmaximizing the density on the human surface. These priors ensure the color\nrendered along rays to be robust to view direction and reduce the inherent\nambiguities of density estimated along rays. Experimental results demonstrate\nthat depth and normal cues, predicted by human-specific monocular estimators,\ncan provide effective supervision signals and render more accurate images.\nFinally, we also show that the proposed physical priors significantly reduce\noverfitting and improve the overall quality of novel view synthesis. Our code\nis available\nat:~\\href{https://github.com/PRIS-CV/HumanRecon}{https://github.com/PRIS-CV/HumanRecon}.",
            "author": [
                "Junhui Yin",
                "Wei Yin",
                "Hao Chen",
                "Xuqian Ren",
                "Zhanyu Ma",
                "Jun Guo",
                "Yifan Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15171v1",
                "http://arxiv.org/pdf/2311.15171v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15170v1",
            "title": "A unified moment tensor potential for silicon, oxygen, and silica",
            "updated": "2023-11-26T03:05:56Z",
            "published": "2023-11-26T03:05:56Z",
            "summary": "Si and its oxides have been extensively explored in theoretical research due\nto their technological and industrial importance. Simultaneously describing\ninteratomic interactions within both Si and SiO$_2$ without the use of\n\\textit{ab initio} methods is considered challenging, given the charge\ntransfers involved. Herein, this challenge is overcome by developing a unified\nmachine learning interatomic potentials describing the Si/ SiO$_2$/ O system,\nbased on the moment tensor potential (MTP) framework. This MTP is trained using\na comprehensive database generated using density functional theory simulations,\nencompassing a wide range of crystal structures, point defects, extended\ndefects, and disordered structure. Extensive testing of the MTP is performed,\nindicating it can describe static and dynamic features of very diverse Si, O,\nand SiO$_2$ atomic structures with a degree of fidelity approaching that of DFT",
            "author": [
                "Karim Zongo",
                "Hao Sun",
                "Claudiane Ouellet-Plamondon",
                "Laurent Karim B\u00e9land"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15170v1",
                "http://arxiv.org/pdf/2311.15170v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15168v1",
            "title": "A Data-Driven Approach for High-Impedance Fault Localization in\n  Distribution Systems",
            "updated": "2023-11-26T02:52:37Z",
            "published": "2023-11-26T02:52:37Z",
            "summary": "Accurate and quick identification of high-impedance faults is critical for\nthe reliable operation of distribution systems. Unlike other faults in power\ngrids, HIFs are very difficult to detect by conventional overcurrent relays due\nto the low fault current. Although HIFs can be affected by various factors, the\nvoltage current characteristics can substantially imply how the system responds\nto the disturbance and thus provides opportunities to effectively localize\nHIFs. In this work, we propose a data-driven approach for the identification of\nHIF events. To tackle the nonlinearity of the voltage current trajectory,\nfirst, we formulate optimization problems to approximate the trajectory with\npiecewise functions. Then we collect the function features of all segments as\ninputs and use the support vector machine approach to efficiently identify HIFs\nat different locations. Numerical studies on the IEEE 123-node test feeder\ndemonstrate the validity and accuracy of the proposed approach for real-time\nHIF identification.",
            "author": [
                "Yuqi Zhou",
                "Yuqing Dong",
                "Rui Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15168v1",
                "http://arxiv.org/pdf/2311.15168v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15167v1",
            "title": "Self-supervised OCT Image Denoising with Slice-to-Slice Registration and\n  Reconstruction",
            "updated": "2023-11-26T02:45:16Z",
            "published": "2023-11-26T02:45:16Z",
            "summary": "Strong speckle noise is inherent to optical coherence tomography (OCT)\nimaging and represents a significant obstacle for accurate quantitative\nanalysis of retinal structures which is key for advances in clinical diagnosis\nand monitoring of disease. Learning-based self-supervised methods for\nstructure-preserving noise reduction have demonstrated superior performance\nover traditional methods but face unique challenges in OCT imaging. The high\ncorrelation of voxels generated by coherent A-scan beams undermines the\nefficacy of self-supervised learning methods as it violates the assumption of\nindependent pixel noise. We conduct experiments demonstrating limitations of\nexisting models due to this independence assumption. We then introduce a new\nend-to-end self-supervised learning framework specifically tailored for OCT\nimage denoising, integrating slice-by-slice training and registration modules\ninto one network. An extensive ablation study is conducted for the proposed\napproach. Comparison to previously published self-supervised denoising models\ndemonstrates improved performance of the proposed framework, potentially\nserving as a preprocessing step towards superior segmentation performance and\nquantitative analysis.",
            "author": [
                "Shijie Li",
                "Palaiologos Alexopoulos",
                "Anse Vellappally",
                "Ronald Zambrano",
                "Wollstein Gadi",
                "Guido Gerig"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15167v1",
                "http://arxiv.org/pdf/2311.15167v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15165v1",
            "title": "Mixing Classifiers to Alleviate the Accuracy-Robustness Trade-Off",
            "updated": "2023-11-26T02:25:30Z",
            "published": "2023-11-26T02:25:30Z",
            "summary": "Machine learning models have recently found tremendous success in data-driven\ncontrol systems. However, standard learning models often suffer from an\naccuracy-robustness trade-off, which is a limitation that must be overcome in\nthe control of safety-critical systems that require both high performance and\nrigorous robustness guarantees. In this work, we build upon the recent \"locally\nbiased smoothing\" method to develop classifiers that simultaneously inherit\nhigh accuracy from standard models and high robustness from robust models.\nSpecifically, we extend locally biased smoothing to the multi-class setting,\nand then overcome its performance bottleneck by generalizing the formulation to\n\"mix\" the outputs of a standard neural network and a robust neural network. We\nprove that when the robustness of the robust base model is certifiable, within\na closed-form $\\ell_p$ radius, no alteration or attack on an input can result\nin misclassification of the mixed classifier; the proposed model inherits the\ncertified robustness. Moreover, we use numerical experiments on the CIFAR-10\nbenchmark dataset to verify that the mixed model noticeably improves the\naccuracy-robustness trade-off.",
            "author": [
                "Yatong Bai",
                "Brendon G. Anderson",
                "Somayeh Sojoudi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15165v1",
                "http://arxiv.org/pdf/2311.15165v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "68T07"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15163v1",
            "title": "Deep Learning-Based Approaches for Contactless Fingerprints Segmentation\n  and Extraction",
            "updated": "2023-11-26T01:56:10Z",
            "published": "2023-11-26T01:56:10Z",
            "summary": "Fingerprints are widely recognized as one of the most unique and reliable\ncharacteristics of human identity. Most modern fingerprint authentication\nsystems rely on contact-based fingerprints, which require the use of\nfingerprint scanners or fingerprint sensors for capturing fingerprints during\nthe authentication process. Various types of fingerprint sensors, such as\noptical, capacitive, and ultrasonic sensors, employ distinct techniques to\ngather and analyze fingerprint data. This dependency on specific hardware or\nsensors creates a barrier or challenge for the broader adoption of fingerprint\nbased biometric systems. This limitation hinders the widespread adoption of\nfingerprint authentication in various applications and scenarios. Border\ncontrol, healthcare systems, educational institutions, financial transactions,\nand airport security face challenges when fingerprint sensors are not\nuniversally available. To mitigate the dependence on additional hardware, the\nuse of contactless fingerprints has emerged as an alternative. Developing\nprecise fingerprint segmentation methods, accurate fingerprint extraction\ntools, and reliable fingerprint matchers are crucial for the successful\nimplementation of a robust contactless fingerprint authentication system. This\npaper focuses on the development of a deep learning-based segmentation tool for\ncontactless fingerprint localization and segmentation. Our system leverages\ndeep learning techniques to achieve high segmentation accuracy and reliable\nextraction of fingerprints from contactless fingerprint images. In our\nevaluation, our segmentation method demonstrated an average mean absolute error\n(MAE) of 30 pixels, an error in angle prediction (EAP) of 5.92 degrees, and a\nlabeling accuracy of 97.46%. These results demonstrate the effectiveness of our\nnovel contactless fingerprint segmentation and extraction tools.",
            "author": [
                "M. G. Sarwar Murshed",
                "Syed Konain Abbas",
                "Sandip Purnapatra",
                "Daqing Hou",
                "Faraz Hussain"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15163v1",
                "http://arxiv.org/pdf/2311.15163v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15161v1",
            "title": "Hessian Aware Low-Rank Weight Perturbation for Continual Learning",
            "updated": "2023-11-26T01:44:01Z",
            "published": "2023-11-26T01:44:01Z",
            "summary": "Continual learning aims to learn a series of tasks sequentially without\nforgetting the knowledge acquired from the previous ones. In this work, we\npropose the Hessian Aware Low-Rank Perturbation algorithm for continual\nlearning. By modeling the parameter transitions along the sequential tasks with\nthe weight matrix transformation, we propose to apply the low-rank\napproximation on the task-adaptive parameters in each layer of the neural\nnetworks. Specifically, we theoretically demonstrate the quantitative\nrelationship between the Hessian and the proposed low-rank approximation. The\napproximation ranks are then globally determined according to the marginal\nincrement of the empirical loss estimated by the layer-specific gradient and\nlow-rank approximation error. Furthermore, we control the model capacity by\npruning less important parameters to diminish the parameter growth. We conduct\nextensive experiments on various benchmarks, including a dataset with\nlarge-scale tasks, and compare our method against some recent state-of-the-art\nmethods to demonstrate the effectiveness and scalability of our proposed\nmethod. Empirical results show that our method performs better on different\nbenchmarks, especially in achieving task order robustness and handling the\nforgetting issue. A demo code can be found at https://github.com/lijiaqi/HALRP.",
            "author": [
                "Jiaqi Li",
                "Rui Wang",
                "Yuanhao Lai",
                "Changjian Shui",
                "Sabyasachi Sahoo",
                "Charles X. Ling",
                "Shichun Yang",
                "Boyu Wang",
                "Christian Gagn\u00e9",
                "Fan Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15161v1",
                "http://arxiv.org/pdf/2311.15161v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15156v1",
            "title": "xTrimoGene: An Efficient and Scalable Representation Learner for\n  Single-Cell RNA-Seq Data",
            "updated": "2023-11-26T01:23:01Z",
            "published": "2023-11-26T01:23:01Z",
            "summary": "Advances in high-throughput sequencing technology have led to significant\nprogress in measuring gene expressions at the single-cell level. The amount of\npublicly available single-cell RNA-seq (scRNA-seq) data is already surpassing\n50M records for humans with each record measuring 20,000 genes. This highlights\nthe need for unsupervised representation learning to fully ingest these data,\nyet classical transformer architectures are prohibitive to train on such data\nin terms of both computation and memory. To address this challenge, we propose\na novel asymmetric encoder-decoder transformer for scRNA-seq data, called\nxTrimoGene$^\\alpha$ (or xTrimoGene for short), which leverages the sparse\ncharacteristic of the data to scale up the pre-training. This scalable design\nof xTrimoGene reduces FLOPs by one to two orders of magnitude compared to\nclassical transformers while maintaining high accuracy, enabling us to train\nthe largest transformer models over the largest scRNA-seq dataset today. Our\nexperiments also show that the performance of xTrimoGene improves as we scale\nup the model sizes, and it also leads to SOTA performance over various\ndownstream tasks, such as cell type annotation, perturb-seq effect prediction,\nand drug combination prediction. xTrimoGene model is now available for use as a\nservice via the following link: https://api.biomap.com/xTrimoGene/apply.",
            "author": [
                "Jing Gong",
                "Minsheng Hao",
                "Xingyi Cheng",
                "Xin Zeng",
                "Chiming Liu",
                "Jianzhu Ma",
                "Xuegong Zhang",
                "Taifeng Wang",
                "Le Song"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15156v1",
                "http://arxiv.org/pdf/2311.15156v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "q-bio.GN"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15153v1",
            "title": "Self-Supervised Learning for SAR ATR with a Knowledge-Guided Predictive\n  Architecture",
            "updated": "2023-11-26T01:05:55Z",
            "published": "2023-11-26T01:05:55Z",
            "summary": "Recently, the emergence of a large number of Synthetic Aperture Radar (SAR)\nsensors and target datasets has made it possible to unify downstream tasks with\nself-supervised learning techniques, which can pave the way for building the\nfoundation model in the SAR target recognition field. The major challenge of\nself-supervised learning for SAR target recognition lies in the generalizable\nrepresentation learning in low data quality and noise.To address the\naforementioned problem, we propose a knowledge-guided predictive architecture\nthat uses local masked patches to predict the multiscale SAR feature\nrepresentations of unseen context. The core of the proposed architecture lies\nin combining traditional SAR domain feature extraction with state-of-the-art\nscalable self-supervised learning for accurate generalized feature\nrepresentations. The proposed framework is validated on various downstream\ndatasets (MSTAR, FUSAR-Ship, SAR-ACD and SSDD), and can bring consistent\nperformance improvement for SAR target recognition. The experimental results\nstrongly demonstrate the unified performance improvement of the self-supervised\nlearning technique for SAR target recognition across diverse targets, scenes\nand sensors.",
            "author": [
                "Weijie Li",
                "Yang Wei",
                "Tianpeng Liu",
                "Yuenan Hou",
                "Yongxiang Liu",
                "Li Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15153v1",
                "http://arxiv.org/pdf/2311.15153v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15147v1",
            "title": "Optimal operation of cryogenic calorimeters through deep reinforcement\n  learning",
            "updated": "2023-11-26T00:15:31Z",
            "published": "2023-11-26T00:15:31Z",
            "summary": "Cryogenic phonon detectors with transition-edge sensors achieve the best\nsensitivity to light dark matter-nucleus scattering in current direct detection\ndark matter searches. In such devices, the temperature of the thermometer and\nthe bias current in its readout circuit need careful optimization to achieve\noptimal detector performance. This task is not trivial and is typically done\nmanually by an expert. In our work, we automated the procedure with\nreinforcement learning in two settings. First, we trained on a simulation of\nthe response of three CRESST detectors used as a virtual reinforcement learning\nenvironment. Second, we trained live on the same detectors operated in the\nCRESST underground setup. In both cases, we were able to optimize a standard\ndetector as fast and with comparable results as human experts. Our method\nenables the tuning of large-scale cryogenic detector setups with minimal manual\ninterventions.",
            "author": [
                "G. Angloher",
                "S. Banik",
                "G. Benato",
                "A. Bento",
                "A. Bertolini",
                "R. Breier",
                "C. Bucci",
                "J. Burkhart",
                "L. Canonica",
                "A. D'Addabbo",
                "S. Di Lorenzo",
                "L. Einfalt",
                "A. Erb",
                "F. v. Feilitzsch",
                "S. Fichtinger",
                "D. Fuchs",
                "A. Garai",
                "V. M. Ghete",
                "P. Gorla",
                "P. V. Guillaumon",
                "S. Gupta",
                "D. Hauff",
                "M. Je\u0161kovsk\u00fd",
                "J. Jochum",
                "M. Kaznacheeva",
                "A. Kinast",
                "S. Kuckuk",
                "H. Kluck",
                "H. Kraus",
                "A. Langenk\u00e4mper",
                "M. Mancuso",
                "L. Marini",
                "B. Mauri",
                "L. Meyer",
                "V. Mokina",
                "K. Niedermayer",
                "M. Olmi",
                "T. Ortmann",
                "C. Pagliarone",
                "L. Pattavina",
                "F. Petricca",
                "W. Potzel",
                "P. Povinec",
                "F. Pr\u00f6bst",
                "F. Pucci",
                "F. Reindl",
                "J. Rothe",
                "K. Sch\u00e4ffner",
                "J. Schieck",
                "S. Sch\u00f6nert",
                "C. Schwertner",
                "M. Stahlberg",
                "L. Stodolsky",
                "C. Strandhagen",
                "R. Strauss",
                "I. Usherov",
                "F. Wagner",
                "V. Wagner",
                "M. Willers",
                "V. Zema",
                "C. Heitzinger",
                "W. Waltenberger"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15147v1",
                "http://arxiv.org/pdf/2311.15147v1"
            ],
            "primary_category": "physics.ins-det",
            "category": [
                "physics.ins-det"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15146v1",
            "title": "Artificial Neural Network Syndrome Decoding on IBM Quantum Processors",
            "updated": "2023-11-26T00:14:22Z",
            "published": "2023-11-26T00:14:22Z",
            "summary": "Syndrome decoding is an integral but computationally demanding step in the\nimplementation of quantum error correction for fault-tolerant quantum\ncomputing. Here, we report the development and benchmarking of Artificial\nNeural Network (ANN) decoding on IBM Quantum Processors. We demonstrate that\nANNs can efficiently decode syndrome measurement data from heavy-hexagonal code\narchitecture and apply appropriate corrections to facilitate error protection.\nThe current physical error rates of IBM devices are above the code's threshold\nand restrict the scope of our ANN decoder for logical error rate suppression.\nHowever, our work confirms the applicability of ANN decoding methods of\nsyndrome data retrieved from experimental devices and establishes machine\nlearning as a promising pathway for quantum error correction when quantum\ndevices with below threshold error rates become available in the near future.",
            "author": [
                "Brhyeton Hall",
                "Spiro Gicev",
                "Muhammad Usman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15146v1",
                "http://arxiv.org/pdf/2311.15146v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15145v1",
            "title": "Choosing Wisely and Learning Deeply: Selective Cross-Modality\n  Distillation via CLIP for Domain Generalization",
            "updated": "2023-11-26T00:06:12Z",
            "published": "2023-11-26T00:06:12Z",
            "summary": "Domain Generalization (DG), a crucial research area, seeks to train models\nacross multiple domains and test them on unseen ones. In this paper, we\nintroduce a novel approach, namely, Selective Cross-Modality Distillation for\nDomain Generalization (SCMD). SCMD leverages the capabilities of large\nvision-language models, specifically the CLIP model, to train a more efficient\nmodel, ensuring it acquires robust generalization capabilities across unseen\ndomains. Our primary contribution is a unique selection framework strategically\ndesigned to identify hard-to-learn samples for distillation. In parallel, we\nintroduce a novel cross-modality module. This module seamlessly combines the\nprojected features of the student model with the text embeddings from CLIP,\nensuring the alignment of similarity distributions. We assess SCMD's\nperformance on various benchmarks, where it empowers a ResNet50 to deliver\nstate-of-the-art performance, surpassing existing domain generalization\nmethods. Furthermore, we provide a theoretical analysis of our selection\nstrategy, offering deeper insight into its effectiveness and potential in the\nfield of DG.",
            "author": [
                "Jixuan Leng",
                "Yijiang Li",
                "Haohan Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15145v1",
                "http://arxiv.org/pdf/2311.15145v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15142v1",
            "title": "Testable Learning with Distribution Shift",
            "updated": "2023-11-25T23:57:45Z",
            "published": "2023-11-25T23:57:45Z",
            "summary": "We revisit the fundamental problem of learning with distribution shift, in\nwhich a learner is given labeled samples from training distribution $D$,\nunlabeled samples from test distribution $D'$ and is asked to output a\nclassifier with low test error. The standard approach in this setting is to\nbound the loss of a classifier in terms of some notion of distance between $D$\nand $D'$. These distances, however, seem difficult to compute and do not lead\nto efficient algorithms.\n  We depart from this paradigm and define a new model called testable learning\nwith distribution shift, where we can obtain provably efficient algorithms for\ncertifying the performance of a classifier on a test distribution. In this\nmodel, a learner outputs a classifier with low test error whenever samples from\n$D$ and $D'$ pass an associated test; moreover, the test must accept if the\nmarginal of $D$ equals the marginal of $D'$. We give several positive results\nfor learning well-studied concept classes such as halfspaces, intersections of\nhalfspaces, and decision trees when the marginal of $D$ is Gaussian or uniform\non $\\{\\pm 1\\}^d$. Prior to our work, no efficient algorithms for these basic\ncases were known without strong assumptions on $D'$.\n  For halfspaces in the realizable case (where there exists a halfspace\nconsistent with both $D$ and $D'$), we combine a moment-matching approach with\nideas from active learning to simulate an efficient oracle for estimating\ndisagreement regions. To extend to the non-realizable setting, we apply recent\nwork from testable (agnostic) learning. More generally, we prove that any\nfunction class with low-degree $L_2$-sandwiching polynomial approximators can\nbe learned in our model. We apply constructions from the pseudorandomness\nliterature to obtain the required approximators.",
            "author": [
                "Adam R. Klivans",
                "Konstantinos Stavropoulos",
                "Arsen Vasilyan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15142v1",
                "http://arxiv.org/pdf/2311.15142v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15141v1",
            "title": "OFDMA-F$^2$L: Federated Learning With Flexible Aggregation Over an OFDMA\n  Air Interface",
            "updated": "2023-11-25T23:47:56Z",
            "published": "2023-11-25T23:47:56Z",
            "summary": "Federated learning (FL) can suffer from a communication bottleneck when\ndeployed in mobile networks, limiting participating clients and deterring FL\nconvergence. The impact of practical air interfaces with discrete modulations\non FL has not previously been studied in depth. This paper proposes a new\nparadigm of flexible aggregation-based FL (F$^2$L) over orthogonal frequency\ndivision multiple-access (OFDMA) air interface, termed as ``OFDMA-F$^2$L'',\nallowing selected clients to train local models for various numbers of\niterations before uploading the models in each aggregation round. We optimize\nthe selections of clients, subchannels and modulations, adapting to channel\nconditions and computing powers. Specifically, we derive an upper bound on the\noptimality gap of OFDMA-F$^2$L capturing the impact of the selections, and show\nthat the upper bound is minimized by maximizing the weighted sum rate of the\nclients per aggregation round. A Lagrange-dual based method is developed to\nsolve this challenging mixed integer program of weighted sum rate maximization,\nrevealing that a ``winner-takes-all'' policy provides the almost surely optimal\nclient, subchannel, and modulation selections. Experiments on multilayer\nperceptrons and convolutional neural networks show that OFDMA-F$^2$L with\noptimal selections can significantly improve the training convergence and\naccuracy, e.g., by about 18\\% and 5\\%, compared to potential alternatives.",
            "author": [
                "Shuyan Hu",
                "Xin Yuan",
                "Wei Ni",
                "Xin Wang",
                "Ekram Hossain",
                "H. Vincent Poor"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15141v1",
                "http://arxiv.org/pdf/2311.15141v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15137v1",
            "title": "Multi-fidelity Constrained Optimization for Stochastic Black Box\n  Simulators",
            "updated": "2023-11-25T23:36:38Z",
            "published": "2023-11-25T23:36:38Z",
            "summary": "Constrained optimization of the parameters of a simulator plays a crucial\nrole in a design process. These problems become challenging when the simulator\nis stochastic, computationally expensive, and the parameter space is\nhigh-dimensional. One can efficiently perform optimization only by utilizing\nthe gradient with respect to the parameters, but these gradients are\nunavailable in many legacy, black-box codes. We introduce the algorithm\nScout-Nd (Stochastic Constrained Optimization for N dimensions) to tackle the\nissues mentioned earlier by efficiently estimating the gradient, reducing the\nnoise of the gradient estimator, and applying multi-fidelity schemes to further\nreduce computational effort. We validate our approach on standard benchmarks,\ndemonstrating its effectiveness in optimizing parameters highlighting better\nperformance compared to existing methods.",
            "author": [
                "Atul Agrawal",
                "Kislaya Ravi",
                "Phaedon-Stelios Koutsourelakis",
                "Hans-Joachim Bungartz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15137v1",
                "http://arxiv.org/pdf/2311.15137v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15134v1",
            "title": "SwiftLearn: A Data-Efficient Training Method of Deep Learning Models\n  using Importance Sampling",
            "updated": "2023-11-25T22:51:01Z",
            "published": "2023-11-25T22:51:01Z",
            "summary": "In this paper, we present SwiftLearn, a data-efficient approach to accelerate\ntraining of deep learning models using a subset of data samples selected during\nthe warm-up stages of training. This subset is selected based on an importance\ncriteria measured over the entire dataset during warm-up stages, aiming to\npreserve the model performance with fewer examples during the rest of training.\nThe importance measure we propose could be updated during training every once\nin a while, to make sure that all of the data samples have a chance to return\nto the training loop if they show a higher importance. The model architecture\nis unchanged but since the number of data samples controls the number of\nforward and backward passes during training, we can reduce the training time by\nreducing the number of training samples used in each epoch of training.\nExperimental results on a variety of CV and NLP models during both pretraining\nand finetuning show that the model performance could be preserved while\nachieving a significant speed-up during training. More specifically, BERT\nfinetuning on GLUE benchmark shows that almost 90% of the data can be dropped\nachieving an end-to-end average speedup of 3.36x while keeping the average\naccuracy drop less than 0.92%.",
            "author": [
                "Habib Hajimolahoseini",
                "Omar Mohamed Awad",
                "Walid Ahmed",
                "Austin Wen",
                "Saina Asani",
                "Mohammad Hassanpour",
                "Farnoosh Javadi",
                "Mehdi Ahmadi",
                "Foozhan Ataiefard",
                "Kangling Liu",
                "Yang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15134v1",
                "http://arxiv.org/pdf/2311.15134v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15131v1",
            "title": "Localizing Lying in Llama: Understanding Instructed Dishonesty on\n  True-False Questions Through Prompting, Probing, and Patching",
            "updated": "2023-11-25T22:41:23Z",
            "published": "2023-11-25T22:41:23Z",
            "summary": "Large language models (LLMs) demonstrate significant knowledge through their\noutputs, though it is often unclear whether false outputs are due to a lack of\nknowledge or dishonesty. In this paper, we investigate instructed dishonesty,\nwherein we explicitly prompt LLaMA-2-70b-chat to lie. We perform prompt\nengineering to find which prompts best induce lying behavior, and then use\nmechanistic interpretability approaches to localize where in the network this\nbehavior occurs. Using linear probing and activation patching, we localize five\nlayers that appear especially important for lying. We then find just 46\nattention heads within these layers that enable us to causally intervene such\nthat the lying model instead answers honestly. We show that these interventions\nwork robustly across many prompts and dataset splits. Overall, our work\ncontributes a greater understanding of dishonesty in LLMs so that we may hope\nto prevent it.",
            "author": [
                "James Campbell",
                "Richard Ren",
                "Phillip Guo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15131v1",
                "http://arxiv.org/pdf/2311.15131v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17929v1",
            "title": "New Online Communities: Graph Deep Learning on Anonymous Voting Networks\n  to Identify Sybils in Polycentric Governance",
            "updated": "2023-11-25T22:26:58Z",
            "published": "2023-11-25T22:26:58Z",
            "summary": "This research examines the polycentric governance of digital assets in\nDecentralized Autonomous Organizations (DAOs). It offers a theoretical\nframework and addresses a critical challenge facing decentralized governance by\ndeveloping a method to identify sybils, or spurious identities. The method uses\ngraph deep learning techniques to identify sybil activity in a DAO governance\ndataset (snapshot.org). Specifically, a Graph Convolutional Neural Network\n(GCNN) learned voting behaviours and a fast k-means vector clustering algorithm\n(FAISS) used the high dimensional embeddings to identify similar nodes in a\ngraph. The results reveal that deep learning can effectively identify sybils,\nreducing the voting graph by 2-5%. This research underscores the importance of\nsybil resistance in DAOs and offers a novel perspective on decentralized\ngovernance, informing future policy, regulation, and governance practices.",
            "author": [
                "Quinn DuPont"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17929v1",
                "http://arxiv.org/pdf/2311.17929v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15125v1",
            "title": "Using Assignment Incentives to Reduce Student Procrastination and\n  Encourage Code Review Interactions",
            "updated": "2023-11-25T22:17:40Z",
            "published": "2023-11-25T22:17:40Z",
            "summary": "Procrastination causes student stress, reduced learning and performance, and\nresults in very busy help sessions immediately before deadlines. A key\nchallenge is encouraging students to complete assignments earlier rather than\nwaiting until right before the deadline, so the focus becomes on the learning\nobjectives rather than just meeting deadlines. This work presents an incentive\nsystem encouraging students to complete assignments many days before deadlines.\nCompleted assignments are code reviewed by staff for correctness and providing\nfeedback, which results in more student-instructor interactions and may help\nreduce student use of generative AI. The incentives result in a change in\nstudent behavior with 45% of assignments completed early and 30% up to 4 days\nbefore the deadline. Students receive real-time feedback with no increase in\nmarking time.",
            "author": [
                "Kevin Wang",
                "Ramon Lawrence"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15125v1",
                "http://arxiv.org/pdf/2311.15125v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16187v1",
            "title": "Modelling wildland fire burn severity in California using a spatial\n  Super Learner approach",
            "updated": "2023-11-25T22:09:14Z",
            "published": "2023-11-25T22:09:14Z",
            "summary": "Given the increasing prevalence of wildland fires in the Western US, there is\na critical need to develop tools to understand and accurately predict burn\nseverity. We develop a machine learning model to predict post-fire burn\nseverity using pre-fire remotely sensed data. Hydrological, ecological, and\ntopographical variables collected from four regions of California - the sites\nof the Kincade fire (2019), the CZU Lightning Complex fire (2020), the Windy\nfire (2021), and the KNP Fire (2021) - are used as predictors of the difference\nnormalized burn ratio. We hypothesize that a Super Learner (SL) algorithm that\naccounts for spatial autocorrelation using Vecchia's Gaussian approximation\nwill accurately model burn severity. In all combinations of test and training\nsets explored, the results of our model showed the SL algorithm outperformed\nstandard Linear Regression methods. After fitting and verifying the performance\nof the SL model, we use interpretable machine learning tools to determine the\nmain drivers of severe burn damage, including greenness, elevation and fire\nweather variables. These findings provide actionable insights that enable\ncommunities to strategize interventions, such as early fire detection systems,\npre-fire season vegetation clearing activities, and resource allocation during\nemergency responses. When implemented, this model has the potential to minimize\nthe loss of human life, property, resources, and ecosystems in California.",
            "author": [
                "Nicholas Simafranca",
                "Bryant Willoughby",
                "Erin O'Neil",
                "Sophie Farr",
                "Brian J Reich",
                "Naomi Giertych",
                "Margaret Johnson",
                "Madeleine Pascolini-Campbell"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16187v1",
                "http://arxiv.org/pdf/2311.16187v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.AP",
                "62-08, 62P12"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15119v1",
            "title": "Learning Regions of Attraction in Unknown Dynamical Systems via\n  Zubov-Koopman Lifting: Regularities and Convergence",
            "updated": "2023-11-25T21:42:02Z",
            "published": "2023-11-25T21:42:02Z",
            "summary": "The estimation for the region of attraction (ROA) of an asymptotically stable\nequilibrium point is crucial in the analysis of nonlinear systems. There has\nbeen a recent surge of interest in estimating the solution to Zubov's equation,\nwhose non-trivial sub-level sets form the exact ROA. In this paper, we propose\na lifting approach to map observable data into an infinite-dimensional function\nspace, which generates a flow governed by the proposed `Zubov-Koopman'\noperators. By learning a Zubov-Koopman operator over a fixed time interval, we\ncan indirectly approximate the solution to Zubov's equation through iterative\napplication of the learned operator on certain functions. We also demonstrate\nthat a transformation of such an approximator can be readily utilized as a\nnear-maximal Lyapunov function. We approach our goal through a comprehensive\ninvestigation of the regularities of Zubov-Koopman operators and their\nassociated quantities. Based on these findings, we present an algorithm for\nlearning Zubov-Koopman operators that exhibit strong convergence to the true\noperator. We show that this approach reduces the amount of required data and\ncan yield desirable estimation results, as demonstrated through numerical\nexamples.",
            "author": [
                "Yiming Meng",
                "Ruikun Zhou",
                "Jun Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15119v1",
                "http://arxiv.org/pdf/2311.15119v1"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS",
                "math.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15113v1",
            "title": "NCL-SM: A Fully Annotated Dataset of Images from Human Skeletal Muscle\n  Biopsies",
            "updated": "2023-11-25T20:29:35Z",
            "published": "2023-11-25T20:29:35Z",
            "summary": "Single cell analysis of human skeletal muscle (SM) tissue cross-sections is a\nfundamental tool for understanding many neuromuscular disorders. For this\nanalysis to be reliable and reproducible, identification of individual fibres\nwithin microscopy images (segmentation) of SM tissue should be automatic and\nprecise. Biomedical scientists in this field currently rely on custom tools and\ngeneral machine learning (ML) models, both followed by labour intensive and\nsubjective manual interventions to fine-tune segmentation. We believe that\nfully automated, precise, reproducible segmentation is possible by training ML\nmodels. However, in this important biomedical domain, there are currently no\ngood quality, publicly available annotated imaging datasets available for ML\nmodel training. In this paper we release NCL-SM: a high quality bioimaging\ndataset of 46 human SM tissue cross-sections from both healthy control subjects\nand from patients with genetically diagnosed muscle pathology. These images\ninclude $>$ 50k manually segmented muscle fibres (myofibres). In addition we\nalso curated high quality myofibre segmentations, annotating reasons for\nrejecting low quality myofibres and low quality regions in SM tissue images,\nmaking these annotations completely ready for downstream analysis. This, we\nbelieve, will pave the way for development of a fully automatic pipeline that\nidentifies individual myofibres within images of tissue sections and, in\nparticular, also classifies individual myofibres that are fit for further\nanalysis.",
            "author": [
                "Atif Khan",
                "Conor Lawless",
                "Amy Vincent",
                "Charlotte Warren",
                "Valeria Di Leo",
                "Tiago Gomes",
                "A. Stephen McGough"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15113v1",
                "http://arxiv.org/pdf/2311.15113v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "q-bio.TO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15112v2",
            "title": "Everybody Needs a Little HELP: Explaining Graphs via Hierarchical\n  Concepts",
            "updated": "2023-12-02T10:44:33Z",
            "published": "2023-11-25T20:06:46Z",
            "summary": "Graph neural networks (GNNs) have led to major breakthroughs in a variety of\ndomains such as drug discovery, social network analysis, and travel time\nestimation. However, they lack interpretability which hinders human trust and\nthereby deployment to settings with high-stakes decisions. A line of\ninterpretable methods approach this by discovering a small set of relevant\nconcepts as subgraphs in the last GNN layer that together explain the\nprediction. This can yield oversimplified explanations, failing to explain the\ninteraction between GNN layers. To address this oversight, we provide HELP\n(Hierarchical Explainable Latent Pooling), a novel, inherently interpretable\ngraph pooling approach that reveals how concepts from different GNN layers\ncompose to new ones in later steps. HELP is more than 1-WL expressive and is\nthe first non-spectral, end-to-end-learnable, hierarchical graph pooling method\nthat can learn to pool a variable number of arbitrary connected components. We\nempirically demonstrate that it performs on-par with standard GCNs and popular\npooling methods in terms of accuracy while yielding explanations that are\naligned with expert knowledge in the domains of chemistry and social networks.\nIn addition to a qualitative analysis, we employ concept completeness scores as\nwell as concept conformity, a novel metric to measure the noise in discovered\nconcepts, quantitatively verifying that the discovered concepts are\nsignificantly easier to fully understand than those from previous work. Our\nwork represents a first step towards an understanding of graph neural networks\nthat goes beyond a set of concepts from the final layer and instead explains\nthe complex interplay of concepts on different levels.",
            "author": [
                "Jonas J\u00fcr\u00df",
                "Lucie Charlotte Magister",
                "Pietro Barbiero",
                "Pietro Li\u00f2",
                "Nikola Simidjievski"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15112v2",
                "http://arxiv.org/pdf/2311.15112v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15111v2",
            "title": "SAMv2: A Unified Framework for Learning Appearance, Semantic and\n  Cross-Modality Anatomical Embeddings",
            "updated": "2023-11-28T02:28:27Z",
            "published": "2023-11-25T20:01:20Z",
            "summary": "Identifying anatomical structures (e.g., lesions or landmarks) in medical\nimages plays a fundamental role in medical image analysis. As an exemplar-based\nlandmark detection method, Self-supervised Anatomical eMbedding (SAM) learns a\ndiscriminative embedding for each voxel in the image and has shown promising\nresults on various tasks. However, SAM still faces challenges in: (1)\ndifferentiating voxels with similar appearance but different semantic meanings\n(\\textit{e.g.}, two adjacent structures without clear borders); (2) matching\nvoxels with similar semantics but markedly different appearance (e.g., the same\nvessel before and after contrast injection); and (3) cross-modality matching\n(e.g., CT-MRI registration). To overcome these challenges, we propose SAMv2,\nwhich is a unified framework designed to learn appearance, semantic, and\ncross-modality anatomical embeddings. Specifically, SAMv2 incorporates three\nkey innovations: (1) semantic embedding learning with prototypical contrastive\nloss; (2) a fixed-point-based matching strategy; and (3) an iterative approach\nfor cross-modality embedding learning. We thoroughly evaluated SAMv2 across\nthree tasks, including one-shot landmark detection, lesion tracking on\nlongitudinal CT scans, and CT-MRI affine/rigid registration with varying field\nof view. Our results suggest that SAMv2 outperforms SAM and other\nstate-of-the-art methods, offering a robust and versatile approach for landmark\nbased medical image analysis tasks. Code and trained models are available at:\nhttps://github.com/alibaba-damo-academy/self-supervised-anatomical-embedding-v2",
            "author": [
                "Xiaoyu Bai",
                "Fan Bai",
                "Xiaofei Huo",
                "Jia Ge",
                "Jingjing Lu",
                "Xianghua Ye",
                "Ke Yan",
                "Yong Xia"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15111v2",
                "http://arxiv.org/pdf/2311.15111v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15110v1",
            "title": "Relevance feedback strategies for recall-oriented neural information\n  retrieval",
            "updated": "2023-11-25T19:50:41Z",
            "published": "2023-11-25T19:50:41Z",
            "summary": "In a number of information retrieval applications (e.g., patent search,\nliterature review, due diligence, etc.), preventing false negatives is more\nimportant than preventing false positives. However, approaches designed to\nreduce review effort (like \"technology assisted review\") can create false\nnegatives, since they are often based on active learning systems that exclude\ndocuments automatically based on user feedback. Therefore, this research\nproposes a more recall-oriented approach to reducing review effort. More\nspecifically, through iteratively re-ranking the relevance rankings based on\nuser feedback, which is also referred to as relevance feedback. In our proposed\nmethod, the relevance rankings are produced by a BERT-based dense-vector search\nand the relevance feedback is based on cumulatively summing the queried and\nselected embeddings. Our results show that this method can reduce review effort\nbetween 17.85% and 59.04%, compared to a baseline approach (of no feedback),\ngiven a fixed recall target",
            "author": [
                "Timo Kats",
                "Peter van der Putten",
                "Jan Scholtes"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15110v1",
                "http://arxiv.org/pdf/2311.15110v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15102v1",
            "title": "Firmamento: a multi-messenger astronomy tool for citizen and\n  professional scientists",
            "updated": "2023-11-25T19:02:25Z",
            "published": "2023-11-25T19:02:25Z",
            "summary": "Firmamento (https://firmamento.hosting.nyu.edu) is a new-concept web-based\nand mobile-friendly data analysis tool dedicated to\nmulti-frequency/multi-messenger emitters, as exemplified by blazars. Although\ninitially intended to support a citizen researcher project at New York\nUniversity-Abu Dhabi (NYUAD), Firmamento has evolved to be a valuable tool for\nprofessional researchers due to its broad accessibility to classical and\ncontemporary multi-frequency open data sets. From this perspective Firmamento\nfacilitates the identification of new blazars and other multi-frequency\nemitters in the localisation uncertainty regions of sources detected by current\nand planned observatories such as Fermi-LAT, Swift , eROSITA, CTA, ASTRI\nMini-Array, LHAASO, IceCube, KM3Net, SWGO, etc. The multi-epoch and\nmulti-wavelength data that Firmamento retrieves from over 90 remote and local\ncatalogues and databases can be used to characterise the spectral energy\ndistribution and the variability properties of cosmic sources as well as to\nconstrain physical models. Firmamento distinguishes itself from other online\nplatforms due to its high specialization, the use of machine learning and other\nmethodologies to characterise the data and for its commitment to inclusivity.\nFrom this particular perspective, its objective is to assist both researchers\nand citizens interested in science, strengthening a trend that is bound to gain\nmomentum in the coming years as data retrieval facilities improve in power and\nmachine learning/artificial intelligence tools become more widely available",
            "author": [
                "Dhurba Tripathi",
                "Paolo Giommi",
                "Adriano Di Giovanni",
                "Rawdha R. Almansoori",
                "Nouf Al Hamly",
                "Francesco Arneodo",
                "Andrea V. Macci\u00f2",
                "Goffredo Puccetti",
                "Ulisses Barres de Almeida",
                "Carlos Brandt",
                "Simonetta Di Pippo",
                "Michele Doro",
                "David Israyelyan",
                "Andrew M. T. Pollock",
                "Narek Sahakyan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15102v1",
                "http://arxiv.org/pdf/2311.15102v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15100v1",
            "title": "Unbalancedness in Neural Monge Maps Improves Unpaired Domain Translation",
            "updated": "2023-11-25T18:58:15Z",
            "published": "2023-11-25T18:58:15Z",
            "summary": "In optimal transport (OT), a Monge map is known as a mapping that transports\na source distribution to a target distribution in the most cost-efficient way.\nRecently, multiple neural estimators for Monge maps have been developed and\napplied in diverse unpaired domain translation tasks, e.g. in single-cell\nbiology and computer vision. However, the classic OT framework enforces mass\nconservation, which makes it prone to outliers and limits its applicability in\nreal-world scenarios. The latter can be particularly harmful in OT domain\ntranslation tasks, where the relative position of a sample within a\ndistribution is explicitly taken into account. While unbalanced OT tackles this\nchallenge in the discrete setting, its integration into neural Monge map\nestimators has received limited attention. We propose a theoretically grounded\nmethod to incorporate unbalancedness into any Monge map estimator. We improve\nexisting estimators to model cell trajectories over time and to predict\ncellular responses to perturbations. Moreover, our approach seamlessly\nintegrates with the OT flow matching (OT-FM) framework. While we show that\nOT-FM performs competitively in image translation, we further improve\nperformance by incorporating unbalancedness (UOT-FM), which better preserves\nrelevant features. We hence establish UOT-FM as a principled method for\nunpaired image translation.",
            "author": [
                "Luca Eyring",
                "Dominik Klein",
                "Th\u00e9o Uscidda",
                "Giovanni Palla",
                "Niki Kilbertus",
                "Zeynep Akata",
                "Fabian Theis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15100v1",
                "http://arxiv.org/pdf/2311.15100v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15098v1",
            "title": "Speech-Based Blood Pressure Estimation with Enhanced Optimization and\n  Incremental Clustering",
            "updated": "2023-11-25T18:55:26Z",
            "published": "2023-11-25T18:55:26Z",
            "summary": "Blood Pressure (BP) estimation plays a pivotal role in diagnosing various\nhealth conditions, highlighting the need for innovative approaches to overcome\nconventional measurement challenges. Leveraging machine learning and speech\nsignals, this study investigates accurate BP estimation with a focus on\npreprocessing, feature extraction, and real-time applications. An advanced\nclustering-based strategy, incorporating the k-means algorithm and the proposed\nFact-Finding Instructor optimization algorithm, is introduced to enhance\naccuracy. The combined outcome of these clustering techniques enables robust BP\nestimation. Moreover, extending beyond these insights, this study delves into\nthe dynamic realm of contemporary digital content consumption. Platforms like\nYouTube have emerged as influential spaces, presenting an array of videos that\nevoke diverse emotions. From heartwarming and amusing content to intense\nnarratives, YouTube captures a spectrum of human experiences, influencing\ninformation access and emotional engagement. Within this context, this research\ninvestigates the interplay between YouTube videos and physiological responses,\nparticularly Blood Pressure (BP) levels. By integrating advanced BP estimation\ntechniques with the emotional dimensions of YouTube videos, this study enriches\nour understanding of how modern media environments intersect with health\nimplications.",
            "author": [
                "Vaishali Rajput",
                "Preeti Mulay",
                "Rajeev Raje"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15098v1",
                "http://arxiv.org/pdf/2311.15098v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15097v1",
            "title": "AugmentTRAJ: A framework for point-based trajectory data augmentation",
            "updated": "2023-11-25T18:54:38Z",
            "published": "2023-11-25T18:54:38Z",
            "summary": "Data augmentation has emerged as a powerful technique in machine learning,\nstrengthening model robustness while mitigating overfitting and under-fitting\nissues by generating diverse synthetic data. Nevertheless, despite its success\nin other domains, data augmentation's potential remains largely untapped in\nmobility data analysis, primarily due to the intricate nature and unique format\nof trajectory data. Additionally, there is a lack of frameworks capable of\npoint-wise data augmentation, which can reliably generate synthetic\ntrajectories while preserving the inherent characteristics of the original\ndata. To address these challenges, this research introduces AugmenTRAJ, an\nopen-source Python3 framework designed explicitly for trajectory data\naugmentation. AugmenTRAJ offers a reliable and well-controlled approach for\ngenerating synthetic trajectories, thereby enabling the harnessing of data\naugmentation benefits in mobility analysis. This thesis presents a\ncomprehensive overview of the methodologies employed in developing AugmenTRAJ\nand showcases the various data augmentation techniques available within the\nframework. AugmenTRAJ opens new possibilities for enhancing mobility data\nanalysis models' performance and generalization capabilities by providing\nresearchers with a practical and versatile tool for augmenting trajectory data,\nIts user-friendly implementation in Python3 facilitates easy integration into\nexisting workflows, offering the community an accessible resource to leverage\nthe full potential of data augmentation in trajectory-based applications.",
            "author": [
                "Yaksh J Haranwala"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15097v1",
                "http://arxiv.org/pdf/2311.15097v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16185v1",
            "title": "Enhancing Sentiment Analysis Results through Outlier Detection\n  Optimization",
            "updated": "2023-11-25T18:20:43Z",
            "published": "2023-11-25T18:20:43Z",
            "summary": "When dealing with text data containing subjective labels like speaker\nemotions, inaccuracies or discrepancies among labelers are not uncommon. Such\ndiscrepancies can significantly affect the performance of machine learning\nalgorithms. This study investigates the potential of identifying and addressing\noutliers in text data with subjective labels, aiming to enhance classification\noutcomes. We utilized the Deep SVDD algorithm, a one-class classification\nmethod, to detect outliers in nine text-based emotion and sentiment analysis\ndatasets. By employing both a small-sized language model (DistilBERT base model\nwith 66 million parameters) and non-deep learning machine learning algorithms\n(decision tree, KNN, Logistic Regression, and LDA) as the classifier, our\nfindings suggest that the removal of outliers can lead to enhanced results in\nmost cases. Additionally, as outliers in such datasets are not necessarily\nunlearnable, we experienced utilizing a large language model -- DeBERTa v3\nlarge with 131 million parameters, which can capture very complex patterns in\ndata. We continued to observe performance enhancements across multiple\ndatasets.",
            "author": [
                "Yuetian Chen",
                "Mei Si"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16185v1",
                "http://arxiv.org/pdf/2311.16185v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15090v1",
            "title": "Fine-Grained Unsupervised Cross-Modality Domain Adaptation for\n  Vestibular Schwannoma Segmentation",
            "updated": "2023-11-25T18:08:59Z",
            "published": "2023-11-25T18:08:59Z",
            "summary": "The domain adaptation approach has gained significant acceptance in\ntransferring styles across various vendors and centers, along with filling the\ngaps in modalities. However, multi-center application faces the challenge of\nthe difficulty of domain adaptation due to their intra-domain differences. We\nfocus on introducing a fine-grained unsupervised framework for domain\nadaptation to facilitate cross-modality segmentation of vestibular schwannoma\n(VS) and cochlea. We propose to use a vector to control the generator to\nsynthesize a fake image with given features. And then, we can apply various\naugmentations to the dataset by searching the feature dictionary. The diversity\naugmentation can increase the performance and robustness of the segmentation\nmodel. On the CrossMoDA validation phase Leaderboard, our method received a\nmean Dice score of 0.765 and 0.836 on VS and cochlea, respectively.",
            "author": [
                "Luyi Han",
                "Tao Tan",
                "Ritse Mann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15090v1",
                "http://arxiv.org/pdf/2311.15090v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15089v1",
            "title": "Where2Start: Leveraging initial States for Robust and Sample-Efficient\n  Reinforcement Learning",
            "updated": "2023-11-25T18:00:26Z",
            "published": "2023-11-25T18:00:26Z",
            "summary": "The reinforcement learning algorithms that focus on how to compute the\ngradient and choose next actions, are effectively improved the performance of\nthe agents. However, these algorithms are environment-agnostic. This means that\nthe algorithms did not use the knowledge that has been captured by trajectory.\nThis poses that the algorithms should sample many trajectories to train the\nmodel. By considering the essence of environment and how much the agent learn\nfrom each scenario in that environment, the strategy of the learning procedure\ncan be changed. The strategy retrieves more informative trajectories, so the\nagent can learn with fewer trajectory sample. We propose Where2Start algorithm\nthat selects the initial state so that the agent has more instability in\nvicinity of that state. We show that this kind of selection decreases number of\ntrajectories that should be sampled that the agent reach to acceptable reward.\nOur experiments shows that Where2Start can improve sample efficiency up to 8\ntimes. Also Where2Start can combined with most of state-of-the-art algorithms\nand improve that robustness and sample efficiency significantly.",
            "author": [
                "Pouya Parsa",
                "Raoof Zare Moayedi",
                "Mohammad Bornosi",
                "Mohammad Mahdi Bejani"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15089v1",
                "http://arxiv.org/pdf/2311.15089v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15088v1",
            "title": "A GPU-based Hydrodynamic Simulator with Boid Interactions",
            "updated": "2023-11-25T17:59:25Z",
            "published": "2023-11-25T17:59:25Z",
            "summary": "We present a hydrodynamic simulation system using the GPU compute shaders of\nDirectX for simulating virtual agent behaviors and navigation inside a smoothed\nparticle hydrodynamical (SPH) fluid environment with real-time water mesh\nsurface reconstruction. The current SPH literature includes interactions\nbetween SPH and heterogeneous meshes but seldom involves interactions between\nSPH and virtual boid agents. The contribution of the system lies in the\ncombination of the parallel smoothed particle hydrodynamics model with the\ndistributed boid model of virtual agents to enable agents to interact with\nfluids. The agents based on the boid algorithm influence the motion of SPH\nfluid particles, and the forces from the SPH algorithm affect the movement of\nthe boids. To enable realistic fluid rendering and simulation in a\nparticle-based system, it is essential to construct a mesh from the particle\nattributes. Our system also contributes to the surface reconstruction aspect of\nthe pipeline, in which we performed a set of experiments with the parallel\nmarching cubes algorithm per frame for constructing the mesh from the fluid\nparticles in a real-time compute and memory-intensive application, producing a\nwide range of triangle configurations. We also demonstrate that our system is\nversatile enough for reinforced robotic agents instead of boid agents to\ninteract with the fluid environment for underwater navigation and remote\ncontrol engineering purposes.",
            "author": [
                "Xi Liu",
                "Gizem Kayar",
                "Ken Perlin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15088v1",
                "http://arxiv.org/pdf/2311.15088v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph",
                "cs.AR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15082v3",
            "title": "Learning graph-Fourier spectra of textured surface images for defect\n  localization",
            "updated": "2023-12-02T03:33:56Z",
            "published": "2023-11-25T17:25:07Z",
            "summary": "In the realm of industrial manufacturing, product inspection remains a\nsignificant bottleneck, with only a small fraction of manufactured items\nundergoing inspection for surface defects. Advances in imaging systems and AI\ncan allow automated full inspection of manufactured surfaces. However, even the\nmost contemporary imaging and machine learning methods perform poorly for\ndetecting defects in images with highly textured backgrounds, that stem from\ndiverse manufacturing processes. This paper introduces an approach based on\ngraph Fourier analysis to automatically identify defective images, as well as\ncrucial graph Fourier coefficients that inform the defects in images amidst\nhighly textured backgrounds. The approach capitalizes on the ability of graph\nrepresentations to capture the complex dynamics inherent in high-dimensional\ndata, preserving crucial locality properties in a lower dimensional space. A\nconvolutional neural network model (1D-CNN) was trained with the coefficients\nof the graph Fourier transform of the images as the input to identify, with\nclassification accuracy of 99.4%, if the image contains a defect. An\nexplainable AI method using SHAP (SHapley Additive exPlanations) was used to\nfurther analyze the trained 1D-CNN model to discern important spectral\ncoefficients for each image. This approach sheds light on the crucial\ncontribution of low-frequency graph eigen waveforms to precisely localize\nsurface defects in images, thereby advancing the realization of zero-defect\nmanufacturing.",
            "author": [
                "Tapan Ganatma Nakkina",
                "Adithyaa Karthikeyan",
                "Yuhao Zhong",
                "Ceyhun Eksin",
                "Satish T. S. Bukkapatnam"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15082v3",
                "http://arxiv.org/pdf/2311.15082v3"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15080v1",
            "title": "Weakly-Supervised Audio-Visual Segmentation",
            "updated": "2023-11-25T17:18:35Z",
            "published": "2023-11-25T17:18:35Z",
            "summary": "Audio-visual segmentation is a challenging task that aims to predict\npixel-level masks for sound sources in a video. Previous work applied a\ncomprehensive manually designed architecture with countless pixel-wise accurate\nmasks as supervision. However, these pixel-level masks are expensive and not\navailable in all cases. In this work, we aim to simplify the supervision as the\ninstance-level annotation, i.e., weakly-supervised audio-visual segmentation.\nWe present a novel Weakly-Supervised Audio-Visual Segmentation framework,\nnamely WS-AVS, that can learn multi-scale audio-visual alignment with\nmulti-scale multiple-instance contrastive learning for audio-visual\nsegmentation. Extensive experiments on AVSBench demonstrate the effectiveness\nof our WS-AVS in the weakly-supervised audio-visual segmentation of\nsingle-source and multi-source scenarios.",
            "author": [
                "Shentong Mo",
                "Bhiksha Raj"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15080v1",
                "http://arxiv.org/pdf/2311.15080v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "cs.MM",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15072v1",
            "title": "Introducing SSBD+ Dataset with a Convolutional Pipeline for detecting\n  Self-Stimulatory Behaviours in Children using raw videos",
            "updated": "2023-11-25T16:57:24Z",
            "published": "2023-11-25T16:57:24Z",
            "summary": "Conventionally, evaluation for the diagnosis of Autism spectrum disorder is\ndone by a trained specialist through questionnaire-based formal assessments and\nby observation of behavioral cues under various settings to capture the early\nwarning signs of autism. These evaluation techniques are highly subjective and\ntheir accuracy relies on the experience of the specialist. In this regard,\nmachine learning-based methods for automated capturing of early signs of autism\nfrom the recorded videos of the children is a promising alternative. In this\npaper, the authors propose a novel pipelined deep learning architecture to\ndetect certain self-stimulatory behaviors that help in the diagnosis of autism\nspectrum disorder (ASD). The authors also supplement their tool with an\naugmented version of the Self Stimulatory Behavior Dataset (SSBD) and also\npropose a new label in SSBD Action detection: no-class. The deep learning model\nwith the new dataset is made freely available for easy adoption to the\nresearchers and developers community. An overall accuracy of around 81% was\nachieved from the proposed pipeline model that is targeted for real-time and\nhands-free automated diagnosis. All of the source code, data, licenses of use,\nand other relevant material is made freely available in\nhttps://github.com/sarl-iiitb/",
            "author": [
                "Vaibhavi Lokegaonkar",
                "Vijay Jaisankar",
                "Pon Deepika",
                "Madhav Rao",
                "T K Srikanth",
                "Sarbani Mallick",
                "Manjit Sodhi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15072v1",
                "http://arxiv.org/pdf/2311.15072v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15061v1",
            "title": "SenseAI: Real-Time Inpainting for Electron Microscopy",
            "updated": "2023-11-25T16:01:29Z",
            "published": "2023-11-25T16:01:29Z",
            "summary": "Despite their proven success and broad applicability to Electron Microscopy\n(EM) data, joint dictionary-learning and sparse-coding based inpainting\nalgorithms have so far remained impractical for real-time usage with an\nElectron Microscope. For many EM applications, the reconstruction time for a\nsingle frame is orders of magnitude longer than the data acquisition time,\nmaking it impossible to perform exclusively subsampled acquisition. This\nlimitation has led to the development of SenseAI, a C++/CUDA library capable of\nextremely efficient dictionary-based inpainting. SenseAI provides N-dimensional\ndictionary learning, live reconstructions, dictionary transfer and\nvisualization, as well as real-time plotting of statistics, parameters, and\nimage quality metrics.",
            "author": [
                "Jack Wells",
                "Amirafshar Moshtaghpour",
                "Daniel Nicholls",
                "Alex W. Robinson",
                "Yalin Zheng",
                "Jony Castagna",
                "Nigel D. Browning"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15061v1",
                "http://arxiv.org/pdf/2311.15061v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15056v1",
            "title": "Accurate and interpretable drug-drug interaction prediction enabled by\n  knowledge subgraph learning",
            "updated": "2023-11-25T15:44:28Z",
            "published": "2023-11-25T15:44:28Z",
            "summary": "Background: Discovering potential drug-drug interactions (DDIs) is a\nlong-standing challenge in clinical treatments and drug developments. Recently,\ndeep learning techniques have been developed for DDI prediction. However, they\ngenerally require a huge number of samples, while known DDIs are rare.\n  Methods: In this work, we present KnowDDI, a graph neural network-based\nmethod that addresses the above challenge. KnowDDI enhances drug\nrepresentations by adaptively leveraging rich neighborhood information from\nlarge biomedical knowledge graphs. Then, it learns a knowledge subgraph for\neach drug-pair to interpret the predicted DDI, where each of the edges is\nassociated with a connection strength indicating the importance of a known DDI\nor resembling strength between a drug-pair whose connection is unknown. Thus,\nthe lack of DDIs is implicitly compensated by the enriched drug representations\nand propagated drug similarities.\n  Results: We evaluate KnowDDI on two benchmark DDI datasets. Results show that\nKnowDDI obtains the state-of-the-art prediction performance with better\ninterpretability. We also find that KnowDDI suffers less than existing works\ngiven a sparser knowledge graph. This indicates that the propagated drug\nsimilarities play a more important role in compensating for the lack of DDIs\nwhen the drug representations are less enriched.\n  Conclusions: KnowDDI nicely combines the efficiency of deep learning\ntechniques and the rich prior knowledge in biomedical knowledge graphs. As an\noriginal open-source tool, KnowDDI can help detect possible interactions in a\nbroad range of relevant interaction prediction tasks, such as protein-protein\ninteractions, drug-target interactions and disease-gene interactions,\neventually promoting the development of biomedicine and healthcare.",
            "author": [
                "Yaqing Wang",
                "Zaifei Yang",
                "Quanming Yao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15056v1",
                "http://arxiv.org/pdf/2311.15056v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15054v1",
            "title": "Detection of developmental language disorder in Cypriot Greek children\n  using a machine learning neural network algorithm",
            "updated": "2023-11-25T15:23:46Z",
            "published": "2023-11-25T15:23:46Z",
            "summary": "Children with developmental language disorder (DLD) encounter difficulties in\nacquiring various language structures. Early identification and intervention\nare crucial to prevent negative long-term outcomes impacting the academic,\nsocial, and emotional development of children. The study aims to develop an\nautomated method for the identification of DLD using artificial intelligence,\nspecifically a neural network machine learning algorithm. This protocol is\napplied for the first time in Cypriot Greek children, which is generally\nconsidered underresearched in the context of DLD. The neural network model was\ntrained using perceptual and production data elicited from children with DLD\nand healthy controls. The k-fold technique was used to crossvalidate the\nalgorithm. The performance of the model was evaluated using metrics such as\naccuracy, precision, recall, F1 score, and ROC/AUC curve to assess its ability\nto make accurate predictions on a set of unseen data. The results demonstrated\nhigh classification values for all metrics (between 0.92 and 0.98), indicating\nthe high accuracy of the neural model in classifying children with DLD.\nAdditionally, the variable importance analysis revealed that the language\nproduction skills of children had a more significant impact on the performance\nof the model compared to perception skills. Neural networks represent powerful\ntools for detecting DLD, providing early and quick assessments of the disorder,\nand having the potential to improve clinical outcomes.",
            "author": [
                "Georgios P. Georgiou",
                "Elena Theodorou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15054v1",
                "http://arxiv.org/pdf/2311.15054v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15053v1",
            "title": "Task adaption by biologically inspired stochastic comodulation",
            "updated": "2023-11-25T15:21:03Z",
            "published": "2023-11-25T15:21:03Z",
            "summary": "Brain representations must strike a balance between generalizability and\nadaptability. Neural codes capture general statistical regularities in the\nworld, while dynamically adjusting to reflect current goals. One aspect of this\nadaptation is stochastically co-modulating neurons' gains based on their task\nrelevance. These fluctuations then propagate downstream to guide\ndecision-making. Here, we test the computational viability of such a scheme in\nthe context of multi-task learning. We show that fine-tuning convolutional\nnetworks by stochastic gain modulation improves on deterministic gain\nmodulation, achieving state-of-the-art results on the CelebA dataset. To better\nunderstand the mechanisms supporting this improvement, we explore how\nfine-tuning performance is affected by architecture using Cifar-100. Overall,\nour results suggest that stochastic comodulation can enhance learning\nefficiency and performance in multi-task learning, without additional learnable\nparameters. This offers a promising new direction for developing more flexible\nand robust intelligent systems.",
            "author": [
                "Gauthier Boeshertz",
                "Caroline Haimerl",
                "Cristina Savin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15053v1",
                "http://arxiv.org/pdf/2311.15053v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15051v1",
            "title": "Large Catapults in Momentum Gradient Descent with Warmup: An Empirical\n  Study",
            "updated": "2023-11-25T15:10:00Z",
            "published": "2023-11-25T15:10:00Z",
            "summary": "Although gradient descent with momentum is widely used in modern deep\nlearning, a concrete understanding of its effects on the training trajectory\nstill remains elusive. In this work, we empirically show that momentum gradient\ndescent with a large learning rate and learning rate warmup displays large\ncatapults, driving the iterates towards flatter minima than those found by\ngradient descent. We then provide empirical evidence and theoretical intuition\nthat the large catapult is caused by momentum \"amplifying\" the\nself-stabilization effect (Damian et al., 2023).",
            "author": [
                "Prin Phunyaphibarn",
                "Junghyun Lee",
                "Bohan Wang",
                "Huishuai Zhang",
                "Chulhee Yun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15051v1",
                "http://arxiv.org/pdf/2311.15051v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15047v1",
            "title": "Training a Hopfield Variational Autoencoder with Equilibrium Propagation",
            "updated": "2023-11-25T14:50:37Z",
            "published": "2023-11-25T14:50:37Z",
            "summary": "On dedicated analog hardware, equilibrium propagation is an energy-efficient\nalternative to backpropagation. In spite of its theoretical guarantees, its\napplication in the AI domain remains limited to the discriminative setting.\nMeanwhile, despite its high computational demands, generative AI is on the\nrise. In this paper, we demonstrate the application of Equilibrium Propagation\nin training a variational autoencoder (VAE) for generative modeling. Leveraging\nthe symmetric nature of Hopfield networks, we propose using a single model to\nserve as both the encoder and decoder which could effectively halve the\nrequired chip size for VAE implementations, paving the way for more efficient\nanalog hardware configurations.",
            "author": [
                "Tom Van Der Meersch",
                "Johannes Deleu",
                "Thomas Demeester"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15047v1",
                "http://arxiv.org/pdf/2311.15047v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15041v1",
            "title": "MPCNN: A Novel Matrix Profile Approach for CNN-based Sleep Apnea\n  Classification",
            "updated": "2023-11-25T14:39:12Z",
            "published": "2023-11-25T14:39:12Z",
            "summary": "Sleep apnea (SA) is a significant respiratory condition that poses a major\nglobal health challenge. Previous studies have investigated several machine and\ndeep learning models for electrocardiogram (ECG)-based SA diagnoses. Despite\nthese advancements, conventional feature extractions derived from ECG signals,\nsuch as R-peaks and RR intervals, may fail to capture crucial information\nencompassed within the complete PQRST segments. In this study, we propose an\ninnovative approach to address this diagnostic gap by delving deeper into the\ncomprehensive segments of the ECG signal. The proposed methodology draws\ninspiration from Matrix Profile algorithms, which generate an Euclidean\ndistance profile from fixed-length signal subsequences. From this, we derived\nthe Min Distance Profile (MinDP), Max Distance Profile (MaxDP), and Mean\nDistance Profile (MeanDP) based on the minimum, maximum, and mean of the\nprofile distances, respectively. To validate the effectiveness of our approach,\nwe use the modified LeNet-5 architecture as the primary CNN model, along with\ntwo existing lightweight models, BAFNet and SE-MSCNN, for ECG classification\ntasks. Our extensive experimental results on the PhysioNet Apnea-ECG dataset\nrevealed that with the new feature extraction method, we achieved a per-segment\naccuracy up to 92.11 \\% and a per-recording accuracy of 100\\%. Moreover, it\nyielded the highest correlation compared to state-of-the-art methods, with a\ncorrelation coefficient of 0.989. By introducing a new feature extraction\nmethod based on distance relationships, we enhanced the performance of certain\nlightweight models, showing potential for home sleep apnea test (HSAT) and SA\ndetection in IoT devices. The source code for this work is made publicly\navailable in GitHub: https://github.com/vinuni-vishc/MPCNN-Sleep-Apnea.",
            "author": [
                "Hieu X. Nguyen",
                "Duong V. Nguyen",
                "Hieu H. Pham",
                "Cuong D. Do"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15041v1",
                "http://arxiv.org/pdf/2311.15041v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15040v1",
            "title": "InstaStyle: Inversion Noise of a Stylized Image is Secretly a Style\n  Adviser",
            "updated": "2023-11-25T14:38:54Z",
            "published": "2023-11-25T14:38:54Z",
            "summary": "Stylized text-to-image generation focuses on creating images from textual\ndescriptions while adhering to a style specified by a few reference images.\nHowever, subtle style variations within different reference images can hinder\nthe model from accurately learning the target style. In this paper, we propose\nInstaStyle, a novel approach that excels in generating high-fidelity stylized\nimages with only a single reference image. Our approach is based on the finding\nthat the inversion noise from a stylized reference image inherently carries the\nstyle signal, as evidenced by their non-zero signal-to-noise ratio. We employ\nDDIM inversion to extract this noise from the reference image and leverage a\ndiffusion model to generate new stylized images from the ``style\" noise.\nAdditionally, the inherent ambiguity and bias of textual prompts impede the\nprecise conveying of style. To address this, we introduce a learnable style\ntoken via prompt refinement, which enhances the accuracy of the style\ndescription for the reference image. Qualitative and quantitative experimental\nresults demonstrate that InstaStyle achieves superior performance compared to\ncurrent benchmarks. Furthermore, our approach also showcases its capability in\nthe creative task of style combination with mixed inversion noise.",
            "author": [
                "Xing Cui",
                "Zekun Li",
                "Pei Pei Li",
                "Huaibo Huang",
                "Zhaofeng He"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15040v1",
                "http://arxiv.org/pdf/2311.15040v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16515v1",
            "title": "Word for Person: Zero-shot Composed Person Retrieval",
            "updated": "2023-11-25T14:24:49Z",
            "published": "2023-11-25T14:24:49Z",
            "summary": "Searching for specific person has great security value and social benefits,\nand it often involves a combination of visual and textual information.\nConventional person retrieval methods, whether image-based or text-based,\nusually fall short in effectively harnessing both types of information, leading\nto the loss of accuracy. In this paper, a whole new task called Composed Person\nRetrieval (CPR) is proposed to jointly utilize both image and text information\nfor target person retrieval. However, the supervised CPR must depend on very\ncostly manual annotation dataset, while there are currently no available\nresources. To mitigate this issue, we firstly introduce the Zero-shot Composed\nPerson Retrieval (ZS-CPR), which leverages existing domain-related data to\nresolve the CPR problem without reliance on expensive annotations. Secondly, to\nlearn ZS-CPR model, we propose a two-stage learning framework, Word4Per, where\na lightweight Textual Inversion Network (TINet) and a text-based person\nretrieval model based on fine-tuned Contrastive Language-Image Pre-training\n(CLIP) network are learned without utilizing any CPR data. Thirdly, a finely\nannotated Image-Text Composed Person Retrieval dataset (ITCPR) is built as the\nbenchmark to assess the performance of the proposed Word4Per framework.\nExtensive experiments under both Rank-1 and mAP demonstrate the effectiveness\nof Word4Per for the ZS-CPR task, surpassing the comparative methods by over\n10%. The code and ITCPR dataset will be publicly available at\nhttps://github.com/Delong-liu-bupt/Word4Per.",
            "author": [
                "Delong Liu",
                "Haiwen Li",
                "Zhicheng Zhao",
                "Fei Su",
                "Hongying Meng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16515v1",
                "http://arxiv.org/pdf/2311.16515v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15037v1",
            "title": "Automatic Detection of Nuclear Spins at Arbitrary Magnetic Fields via\n  Signal-to-Image AI Model",
            "updated": "2023-11-25T14:18:38Z",
            "published": "2023-11-25T14:18:38Z",
            "summary": "Quantum sensors leverage matter's quantum properties to enable measurements\nwith unprecedented spatial and spectral resolution. Among these sensors, those\nutilizing nitrogen-vacancy (NV) centers in diamond offer the distinct advantage\nof operating at room temperature. Nevertheless, signals received from NV\ncenters are often complex, making interpretation challenging. This is\nespecially relevant in low magnetic field scenarios, where standard\napproximations for modeling the system fail. Additionally, NV signals feature a\nprominent noise component. In this work, we present a signal-to-image deep\nlearning model capable to automatically infer the number of nuclear spins\nsurrounding an NV sensor and the hyperfine couplings between the sensor and the\nnuclear spins. Our model can be trained to operate effectively across various\nmagnetic field scenarios, requires no prior knowledge of the involved nuclei,\nand is designed to handle noisy signals, leading to fast characterization of\nnuclear environments in real experimental conditions. With detailed numerical\nsimulations, we test the performance of our model in scenarios involving\nvarying numbers of nuclei, achieving an average error of less than $2\\\n\\rm{kHz}$ in the estimated hyperfine constants.",
            "author": [
                "B. Varona-Uriarte",
                "C. Munuera-Javaloy",
                "E. Terradillos",
                "A. Alvarez-Gila",
                "E. Garrote",
                "J. Casanova"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15037v1",
                "http://arxiv.org/pdf/2311.15037v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15036v1",
            "title": "On-Device Soft Sensors: Real-Time Fluid Flow Estimation from Level\n  Sensor Data",
            "updated": "2023-11-25T14:18:29Z",
            "published": "2023-11-25T14:18:29Z",
            "summary": "Soft sensors are crucial in bridging autonomous systems' physical and digital\nrealms, enhancing sensor fusion and perception. Instead of deploying soft\nsensors on the Cloud, this study shift towards employing on-device soft\nsensors, promising heightened efficiency and bolstering data security. Our\napproach substantially improves energy efficiency by deploying Artificial\nIntelligence (AI) directly on devices within a wireless sensor network.\nFurthermore, the synergistic integration of the Microcontroller Unit and\nField-Programmable Gate Array (FPGA) leverages the rapid AI inference\ncapabilities of the latter. Empirical evidence from our real-world use case\ndemonstrates that FPGA-based soft sensors achieve inference times ranging\nremarkably from 1.04 to 12.04 microseconds. These compelling results highlight\nthe considerable potential of our innovative approach for executing real-time\ninference tasks efficiently, thereby presenting a feasible alternative that\neffectively addresses the latency challenges intrinsic to Cloud-based\ndeployments.",
            "author": [
                "Tianheng Ling",
                "Chao Qian",
                "Gregor Schiele"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15036v1",
                "http://arxiv.org/pdf/2311.15036v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15033v1",
            "title": "Agent as Cerebrum, Controller as Cerebellum: Implementing an Embodied\n  LMM-based Agent on Drones",
            "updated": "2023-11-25T14:14:01Z",
            "published": "2023-11-25T14:14:01Z",
            "summary": "In this study, we present a novel paradigm for industrial robotic embodied\nagents, encapsulating an 'agent as cerebrum, controller as cerebellum'\narchitecture. Our approach harnesses the power of Large Multimodal Models\n(LMMs) within an agent framework known as AeroAgent, tailored for drone\ntechnology in industrial settings. To facilitate seamless integration with\nrobotic systems, we introduce ROSchain, a bespoke linkage framework connecting\nLMM-based agents to the Robot Operating System (ROS). We report findings from\nextensive empirical research, including simulated experiments on the Airgen and\nreal-world case study, particularly in individual search and rescue operations.\nThe results demonstrate AeroAgent's superior performance in comparison to\nexisting Deep Reinforcement Learning (DRL)-based agents, highlighting the\nadvantages of the embodied LMM in complex, real-world scenarios.",
            "author": [
                "Haoran Zhao",
                "Fengxing Pan",
                "Huqiuyue Ping",
                "Yaoming Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15033v1",
                "http://arxiv.org/pdf/2311.15033v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15032v1",
            "title": "nlpBDpatriots at BLP-2023 Task 2: A Transfer Learning Approach to Bangla\n  Sentiment Analysis",
            "updated": "2023-11-25T13:58:58Z",
            "published": "2023-11-25T13:58:58Z",
            "summary": "In this paper, we discuss the nlpBDpatriots entry to the shared task on\nSentiment Analysis of Bangla Social Media Posts organized at the first workshop\non Bangla Language Processing (BLP) co-located with EMNLP. The main objective\nof this task is to identify the polarity of social media content using a Bangla\ndataset annotated with positive, neutral, and negative labels provided by the\nshared task organizers. Our best system for this task is a transfer learning\napproach with data augmentation which achieved a micro F1 score of 0.71. Our\nbest system ranked 12th among 30 teams that participated in the competition.",
            "author": [
                "Dhiman Goswami",
                "Md Nishat Raihan",
                "Sadiya Sayara Chowdhury Puspo",
                "Marcos Zampieri"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15032v1",
                "http://arxiv.org/pdf/2311.15032v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15031v1",
            "title": "Robust and Efficient Semi-supervised Learning for Ising Model",
            "updated": "2023-11-25T13:53:49Z",
            "published": "2023-11-25T13:53:49Z",
            "summary": "In biomedical studies, it is often desirable to characterize the interactive\nmode of multiple disease outcomes beyond their marginal risk. Ising model is\none of the most popular choices serving for this purpose. Nevertheless,\nlearning efficiency of Ising models can be impeded by the scarcity of accurate\ndisease labels, which is a prominent problem in contemporary studies driven by\nelectronic health records (EHR). Semi-supervised learning (SSL) leverages the\nlarge unlabeled sample with auxiliary EHR features to assist the learning with\nlabeled data only and is a potential solution to this issue. In this paper, we\ndevelop a novel SSL method for efficient inference of Ising model. Our method\nfirst models the outcomes against the auxiliary features, then uses it to\nproject the score function of the supervised estimator onto the EHR features,\nand incorporates the unlabeled sample to augment the supervised estimator for\nvariance reduction without introducing bias. For the key step of conditional\nmodeling, we propose strategies that can effectively leverage the auxiliary EHR\ninformation while maintaining moderate model complexity. In addition, we\nintroduce approaches including intrinsic efficient updates and ensemble, to\novercome the potential misspecification of the conditional model that may cause\nefficiency loss. Our method is justified by asymptotic theory and shown to\noutperform existing SSL methods through simulation studies. We also illustrate\nits utility in a real example about several key phenotypes related to frequent\nICU admission on MIMIC-III data set.",
            "author": [
                "Daiqing Wu",
                "Molei Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15031v1",
                "http://arxiv.org/pdf/2311.15031v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15030v1",
            "title": "Learning Task-adaptive Quasi-stiffness Control for A Powered\n  Transfemoral Prosthesis",
            "updated": "2023-11-25T13:51:14Z",
            "published": "2023-11-25T13:51:14Z",
            "summary": "While significant advancements have been made in the mechanical and\ntask-specific controller designs of powered transfemoral prostheses, developing\na task-adaptive control framework that generalizes across various locomotion\nmodes and terrain conditions remains an open problem. This study proposes a\ntask-adaptive learning quasi-stiffness control framework for powered prostheses\nthat generalizes across tasks, including the torque-angle relationship\nreconstruction part and the quasi-stiffness controller design part.\nQuasi-stiffness is defined as the slope of the human joint's torque-angle\nrelationship. To accurately obtain the torque-angle relationship in a new task,\na Gaussian Process Regression (GPR) model is introduced to predict the target\nfeatures of the human joint's angle and torque in the task. Then a Kernelized\nMovement Primitives (KMP) is employed to reconstruct the torque-angle\nrelationship of a new task from multiple human demonstrations and estimated\ntarget features. Based on the torque-angle relationship of the new task, a\nquasi-stiffness control approach is designed for a powered prosthesis. Finally,\nthe proposed framework is validated through practical examples, including\nvarying speed and incline walking tasks. The proposed framework has the\npotential to expand to variable walking tasks in daily life for the\ntransfemoral amputees.",
            "author": [
                "Teng Ma",
                "Shucong Yin",
                "Zhimin Hou",
                "Binxin Huang",
                "Chuheng Chen",
                "Haoyong Yu",
                "Chenglong Fu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15030v1",
                "http://arxiv.org/pdf/2311.15030v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15023v1",
            "title": "Offensive Language Identification in Transliterated and Code-Mixed\n  Bangla",
            "updated": "2023-11-25T13:27:22Z",
            "published": "2023-11-25T13:27:22Z",
            "summary": "Identifying offensive content in social media is vital for creating safe\nonline communities. Several recent studies have addressed this problem by\ncreating datasets for various languages. In this paper, we explore offensive\nlanguage identification in texts with transliterations and code-mixing,\nlinguistic phenomena common in multilingual societies, and a known challenge\nfor NLP systems. We introduce TB-OLID, a transliterated Bangla offensive\nlanguage dataset containing 5,000 manually annotated comments. We train and\nfine-tune machine learning models on TB-OLID, and we evaluate their results on\nthis dataset. Our results show that English pre-trained transformer-based\nmodels, such as fBERT and HateBERT achieve the best performance on this\ndataset.",
            "author": [
                "Md Nishat Raihan",
                "Umma Hani Tanmoy",
                "Anika Binte Islam",
                "Kai North",
                "Tharindu Ranasinghe",
                "Antonios Anastasopoulos",
                "Marcos Zampieri"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15023v1",
                "http://arxiv.org/pdf/2311.15023v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15022v1",
            "title": "Occlusion Sensitivity Analysis with Augmentation Subspace Perturbation\n  in Deep Feature Space",
            "updated": "2023-11-25T13:26:40Z",
            "published": "2023-11-25T13:26:40Z",
            "summary": "Deep Learning of neural networks has gained prominence in multiple\nlife-critical applications like medical diagnoses and autonomous vehicle\naccident investigations. However, concerns about model transparency and biases\npersist. Explainable methods are viewed as the solution to address these\nchallenges. In this study, we introduce the Occlusion Sensitivity Analysis with\nDeep Feature Augmentation Subspace (OSA-DAS), a novel perturbation-based\ninterpretability approach for computer vision. While traditional perturbation\nmethods make only use of occlusions to explain the model predictions, OSA-DAS\nextends standard occlusion sensitivity analysis by enabling the integration\nwith diverse image augmentations. Distinctly, our method utilizes the output\nvector of a DNN to build low-dimensional subspaces within the deep feature\nvector space, offering a more precise explanation of the model prediction. The\nstructural similarity between these subspaces encompasses the influence of\ndiverse augmentations and occlusions. We test extensively on the ImageNet-1k,\nand our class- and model-agnostic approach outperforms commonly used\ninterpreters, setting it apart in the realm of explainable AI.",
            "author": [
                "Pedro Valois",
                "Koichiro Niinuma",
                "Kazuhiro Fukui"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15022v1",
                "http://arxiv.org/pdf/2311.15022v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15016v1",
            "title": "E-CORE: Emotion Correlation Enhanced Empathetic Dialogue Generation",
            "updated": "2023-11-25T12:47:39Z",
            "published": "2023-11-25T12:47:39Z",
            "summary": "Achieving empathy is a crucial step toward humanized dialogue systems.\nCurrent approaches for empathetic dialogue generation mainly perceive an\nemotional label to generate an empathetic response conditioned on it, which\nsimply treat emotions independently, but ignore the intrinsic emotion\ncorrelation in dialogues, resulting in inaccurate emotion perception and\nunsuitable response generation. In this paper, we propose a novel emotion\ncorrelation enhanced empathetic dialogue generation framework, which\ncomprehensively realizes emotion correlation learning, utilization, and\nsupervising. Specifically, a multi-resolution emotion graph is devised to\ncapture context-based emotion interactions from different resolutions, further\nmodeling emotion correlation. Then we propose an emotion correlation enhanced\ndecoder, with a novel correlation-aware aggregation and soft/hard strategy,\nrespectively improving the emotion perception and response generation.\nExperimental results on the benchmark dataset demonstrate the superiority of\nour model in both empathetic perception and expression.",
            "author": [
                "Fengyi Fu",
                "Lei Zhang",
                "Quan Wang",
                "Zhendong Mao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15016v1",
                "http://arxiv.org/pdf/2311.15016v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15011v1",
            "title": "VSCode: General Visual Salient and Camouflaged Object Detection with 2D\n  Prompt Learning",
            "updated": "2023-11-25T12:34:02Z",
            "published": "2023-11-25T12:34:02Z",
            "summary": "Salient object detection (SOD) and camouflaged object detection (COD) are\nrelated yet distinct binary mapping tasks. These tasks involve multiple\nmodalities, sharing commonalities and unique cues. Existing research often\nemploys intricate task-specific specialist models, potentially leading to\nredundancy and suboptimal results. We introduce VSCode, a generalist model with\nnovel 2D prompt learning, to jointly address four SOD tasks and three COD\ntasks. We utilize VST as the foundation model and introduce 2D prompts within\nthe encoder-decoder architecture to learn domain and task-specific knowledge on\ntwo separate dimensions. A prompt discrimination loss helps disentangle\npeculiarities to benefit model optimization. VSCode outperforms\nstate-of-the-art methods across six tasks on 26 datasets and exhibits zero-shot\ngeneralization to unseen tasks by combining 2D prompts, such as RGB-D COD.",
            "author": [
                "Ziyang Luo",
                "Nian Liu",
                "Wangbo Zhao",
                "Xuguang Yang",
                "Dingwen Zhang",
                "Deng-Ping Fan",
                "Fahad Khan",
                "Junwei Han"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15011v1",
                "http://arxiv.org/pdf/2311.15011v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15003v1",
            "title": "Enumerating Error Bounded Polytime Algorithms Through Arithmetical\n  Theories",
            "updated": "2023-11-25T11:44:47Z",
            "published": "2023-11-25T11:44:47Z",
            "summary": "We consider a minimal extension of the language of arithmetic, such that the\nbounded formulas provably total in a suitably-defined theory \\`a la Buss\n(expressed in this new language) precisely capture polytime random functions.\nThen, we provide two new characterizations of the semantic class BPP obtained\nby internalizing the error-bound check within a logical system: the first\nrelies on measure-sensitive quantifiers, while the second is based on standard\nfirst-order quantification. This leads us to introduce a family of effectively\nenumerable subclasses of BPP, called BPP_T and consisting of languages captured\nby those probabilistic Turing machines whose underlying error can be proved\nbounded in the theory T. As a paradigmatic example of this approach, we\nestablish that polynomial identity testing is in BPP_T where\nT=$\\mathrm{I}\\Delta_0+\\mathrm{Exp}$ is a well-studied theory based on bounded\ninduction.",
            "author": [
                "Melissa Antonelli",
                "Ugo Dal Lago",
                "Davide Davoli",
                "Isabel Oitavem",
                "Paolo Pistone"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15003v1",
                "http://arxiv.org/pdf/2311.15003v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO",
                "math.LO",
                "F.4.1; F.1.3"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15001v1",
            "title": "A Deep-learning Real-time Bias Correction Method for Significant Wave\n  Height Forecasts in the Western North Pacific",
            "updated": "2023-11-25T11:34:00Z",
            "published": "2023-11-25T11:34:00Z",
            "summary": "Significant wave height is one of the most important parameters\ncharacterizing ocean waves, and accurate numerical ocean wave forecasting is\ncrucial for coastal protection and shipping. However, due to the randomness and\nnonlinearity of the wind fields that generate ocean waves and the complex\ninteraction between wave and wind fields, current forecasts of numerical ocean\nwaves have biases. In this study, a spatiotemporal deep-learning method was\nemployed to correct gridded SWH forecasts from the ECMWF-IFS. This method was\nbuilt on the trajectory gated recurrent unit deep neural network,and it\nconducts real-time rolling correction for the 0-240h SWH forecasts from\nECMWF-IFS. The correction model is co-driven by wave and wind fields, providing\nbetter results than those based on wave fields alone. A novel pixel-switch loss\nfunction was developed. The pixel-switch loss function can dynamically\nfine-tune the pre-trained correction model, focusing on pixels with large\nbiases in SWH forecasts. According to the seasonal characteristics of SWH, four\ncorrection models were constructed separately, for spring, summer, autumn, and\nwinter. The experimental results show that, compared with the original ECMWF\nSWH predictions, the correction was most effective in spring, when the mean\nabsolute error decreased by 12.972~46.237%. Although winter had the worst\nperformance, the mean absolute error decreased by 13.794~38.953%. The corrected\nresults improved the original ECMWF SWH forecasts under both normal and extreme\nweather conditions, indicating that our SWH correction model is robust and\ngeneralizable.",
            "author": [
                "Wei Zhang",
                "Yu Sun",
                "Yapeng Wu",
                "Junyu Dong",
                "Xiaojiang Song",
                "Zhiyi Gao",
                "Renbo Pang",
                "Boyu Guoan"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.ocemod.2023.102289",
                "http://arxiv.org/abs/2311.15001v1",
                "http://arxiv.org/pdf/2311.15001v1"
            ],
            "primary_category": "physics.ao-ph",
            "category": [
                "physics.ao-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15000v1",
            "title": "Satellite-based feature extraction and multivariate time-series\n  prediction of biotoxin contamination in shellfish",
            "updated": "2023-11-25T11:32:20Z",
            "published": "2023-11-25T11:32:20Z",
            "summary": "Shellfish production constitutes an important sector for the economy of many\nPortuguese coastal regions, yet the challenge of shellfish biotoxin\ncontamination poses both public health concerns and significant economic risks.\nThus, predicting shellfish contamination levels holds great potential for\nenhancing production management and safeguarding public health. In our study,\nwe utilize a dataset with years of Sentinel-3 satellite imagery for marine\nsurveillance, along with shellfish biotoxin contamination data from various\nproduction areas along Portugal's western coastline, collected by Portuguese\nofficial control. Our goal is to evaluate the integration of satellite data in\nforecasting models for predicting toxin concentrations in shellfish given\nforecasting horizons up to four weeks, which implies extracting a small set of\nuseful features and assessing their impact on the predictive models. We framed\nthis challenge as a time-series forecasting problem, leveraging historical\ncontamination levels and satellite images for designated areas. While\ncontamination measurements occurred weekly, satellite images were accessible\nmultiple times per week. Unsupervised feature extraction was performed using\nautoencoders able to handle non-valid pixels caused by factors like cloud\ncover, land, or anomalies. Finally, several Artificial Neural Networks models\nwere applied to compare univariate (contamination only) and multivariate\n(contamination and satellite data) time-series forecasting. Our findings show\nthat incorporating these features enhances predictions, especially beyond one\nweek in lagoon production areas (RIAV) and for the 1-week and 2-week horizons\nin the L5B area (oceanic). The methodology shows the feasibility of integrating\ninformation from a high-dimensional data source like remote sensing without\ncompromising the model's predictive ability.",
            "author": [
                "Sergio Tavares",
                "Pedro R. Costa",
                "Ludwig Krippahl",
                "Marta B. Lopes"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15000v1",
                "http://arxiv.org/pdf/2311.15000v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16491v1",
            "title": "$Z^*$: Zero-shot Style Transfer via Attention Rearrangement",
            "updated": "2023-11-25T11:03:43Z",
            "published": "2023-11-25T11:03:43Z",
            "summary": "Despite the remarkable progress in image style transfer, formulating style in\nthe context of art is inherently subjective and challenging. In contrast to\nexisting learning/tuning methods, this study shows that vanilla diffusion\nmodels can directly extract style information and seamlessly integrate the\ngenerative prior into the content image without retraining. Specifically, we\nadopt dual denoising paths to represent content/style references in latent\nspace and then guide the content image denoising process with style latent\ncodes. We further reveal that the cross-attention mechanism in latent diffusion\nmodels tends to blend the content and style images, resulting in stylized\noutputs that deviate from the original content image. To overcome this\nlimitation, we introduce a cross-attention rearrangement strategy. Through\ntheoretical analysis and experiments, we demonstrate the effectiveness and\nsuperiority of the diffusion-based $\\underline{Z}$ero-shot $\\underline{S}$tyle\n$\\underline{T}$ransfer via $\\underline{A}$ttention $\\underline{R}$earrangement,\nZ-STAR.",
            "author": [
                "Yingying Deng",
                "Xiangyu He",
                "Fan Tang",
                "Weiming Dong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16491v1",
                "http://arxiv.org/pdf/2311.16491v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14994v1",
            "title": "Exploring Causal Learning through Graph Neural Networks: An In-depth\n  Review",
            "updated": "2023-11-25T10:46:06Z",
            "published": "2023-11-25T10:46:06Z",
            "summary": "In machine learning, exploring data correlations to predict outcomes is a\nfundamental task. Recognizing causal relationships embedded within data is\npivotal for a comprehensive understanding of system dynamics, the significance\nof which is paramount in data-driven decision-making processes. Beyond\ntraditional methods, there has been a surge in the use of graph neural networks\n(GNNs) for causal learning, given their capabilities as universal data\napproximators. Thus, a thorough review of the advancements in causal learning\nusing GNNs is both relevant and timely. To structure this review, we introduce\na novel taxonomy that encompasses various state-of-the-art GNN methods employed\nin studying causality. GNNs are further categorized based on their applications\nin the causality domain. We further provide an exhaustive compilation of\ndatasets integral to causal learning with GNNs to serve as a resource for\npractical study. This review also touches upon the application of causal\nlearning across diverse sectors. We conclude the review with insights into\npotential challenges and promising avenues for future exploration in this\nrapidly evolving field of machine learning.",
            "author": [
                "Simi Job",
                "Xiaohui Tao",
                "Taotao Cai",
                "Haoran Xie",
                "Lin Li",
                "Jianming Yong",
                "Qing Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14994v1",
                "http://arxiv.org/pdf/2311.14994v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14993v1",
            "title": "Coordinate-Aware Modulation for Neural Fields",
            "updated": "2023-11-25T10:42:51Z",
            "published": "2023-11-25T10:42:51Z",
            "summary": "Neural fields, mapping low-dimensional input coordinates to corresponding\nsignals, have shown promising results in representing various signals. Numerous\nmethodologies have been proposed, and techniques employing MLPs and grid\nrepresentations have achieved substantial success. MLPs allow compact and high\nexpressibility, yet often suffer from spectral bias and slow convergence speed.\nOn the other hand, methods using grids are free from spectral bias and achieve\nfast training speed, however, at the expense of high spatial complexity. In\nthis work, we propose a novel way for exploiting both MLPs and grid\nrepresentations in neural fields. Unlike the prevalent methods that combine\nthem sequentially (extract features from the grids first and feed them to the\nMLP), we inject spectral bias-free grid representations into the intermediate\nfeatures in the MLP. More specifically, we suggest a Coordinate-Aware\nModulation (CAM), which modulates the intermediate features using scale and\nshift parameters extracted from the grid representations. This can maintain the\nstrengths of MLPs while mitigating any remaining potential biases, facilitating\nthe rapid learning of high-frequency components. In addition, we empirically\nfound that the feature normalizations, which have not been successful in neural\nfiled literature, proved to be effective when applied in conjunction with the\nproposed CAM. Experimental results demonstrate that CAM enhances the\nperformance of neural representation and improves learning stability across a\nrange of signals. Especially in the novel view synthesis task, we achieved\nstate-of-the-art performance with the least number of parameters and fast\ntraining speed for dynamic scenes and the best performance under 1MB memory for\nstatic scenes. CAM also outperforms the best-performing video compression\nmethods using neural fields by a large margin.",
            "author": [
                "Joo Chan Lee",
                "Daniel Rho",
                "Seungtae Nam",
                "Jong Hwan Ko",
                "Eunbyung Park"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14993v1",
                "http://arxiv.org/pdf/2311.14993v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14992v1",
            "title": "Model-free Reinforcement Learning for ${H_{2}/H_{\\infty}}$ Control of\n  Stochastic Discrete-time Systems",
            "updated": "2023-11-25T10:37:03Z",
            "published": "2023-11-25T10:37:03Z",
            "summary": "This paper proposes a reinforcement learning (RL) algorithm for infinite\nhorizon $\\rm {H_{2}/H_{\\infty}}$ problem in a class of stochastic discrete-time\nsystems, rather than using a set of coupled generalized algebraic Riccati\nequations (GAREs). The algorithm is able to learn the optimal control policy\nfor the system even when its parameters are unknown. Additionally, the paper\nexplores the effect of detection noise as well as the convergence of the\nalgorithm, and shows that the control policy is admissible after a finite\nnumber of iterations. The algorithm is also able to handle multi-objective\ncontrol problems within stochastic fields. Finally, the algorithm is applied to\nthe F-16 aircraft autopilot with multiplicative noise.",
            "author": [
                "Xiushan Jiang",
                "Li Wang",
                "Dongya Zhao",
                "Ling Shi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14992v1",
                "http://arxiv.org/pdf/2311.14992v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14990v1",
            "title": "View it like a radiologist: Shifted windows for deep learning\n  augmentation of CT images",
            "updated": "2023-11-25T10:28:08Z",
            "published": "2023-11-25T10:28:08Z",
            "summary": "Deep learning has the potential to revolutionize medical practice by\nautomating and performing important tasks like detecting and delineating the\nsize and locations of cancers in medical images. However, most deep learning\nmodels rely on augmentation techniques that treat medical images as natural\nimages. For contrast-enhanced Computed Tomography (CT) images in particular,\nthe signals producing the voxel intensities have physical meaning, which is\nlost during preprocessing and augmentation when treating such images as natural\nimages. To address this, we propose a novel preprocessing and intensity\naugmentation scheme inspired by how radiologists leverage multiple viewing\nwindows when evaluating CT images. Our proposed method, window shifting,\nrandomly places the viewing windows around the region of interest during\ntraining. This approach improves liver lesion segmentation performance and\nrobustness on images with poorly timed contrast agent. Our method outperforms\nclassical intensity augmentations as well as the intensity augmentation\npipeline of the popular nn-UNet on multiple datasets.",
            "author": [
                "Eirik A. \u00d8stmo",
                "Kristoffer K. Wickstr\u00f8m",
                "Keyur Radiya",
                "Michael C. Kampffmeyer",
                "Robert Jenssen"
            ],
            "link": [
                "http://dx.doi.org/10.1109/MLSP55844.2023.10285978",
                "http://arxiv.org/abs/2311.14990v1",
                "http://arxiv.org/pdf/2311.14990v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16481v1",
            "title": "Elucidating and Overcoming the Challenges of Label Noise in Supervised\n  Contrastive Learning",
            "updated": "2023-11-25T10:04:42Z",
            "published": "2023-11-25T10:04:42Z",
            "summary": "Image classification datasets exhibit a non-negligible fraction of mislabeled\nexamples, often due to human error when one class superficially resembles\nanother. This issue poses challenges in supervised contrastive learning (SCL),\nwhere the goal is to cluster together data points of the same class in the\nembedding space while distancing those of disparate classes. While such methods\noutperform those based on cross-entropy, they are not immune to labeling\nerrors. However, while the detrimental effects of noisy labels in supervised\nlearning are well-researched, their influence on SCL remains largely\nunexplored. Hence, we analyse the effect of label errors and examine how they\ndisrupt the SCL algorithm's ability to distinguish between positive and\nnegative sample pairs. Our analysis reveals that human labeling errors manifest\nas easy positive samples in around 99% of cases. We, therefore, propose D-SCL,\na novel Debiased Supervised Contrastive Learning objective designed to mitigate\nthe bias introduced by labeling errors. We demonstrate that D-SCL consistently\noutperforms state-of-the-art techniques for representation learning across\ndiverse vision benchmarks, offering improved robustness to label errors.",
            "author": [
                "Zijun Long",
                "George Killick",
                "Lipeng Zhuang",
                "Richard McCreadie",
                "Gerardo Aragon Camarasa",
                "Paul Henderson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16481v1",
                "http://arxiv.org/pdf/2311.16481v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14983v1",
            "title": "Neural Network Based Approach to Recognition of Meteor Tracks in the\n  Mini-EUSO Telescope Data",
            "updated": "2023-11-25T10:00:49Z",
            "published": "2023-11-25T10:00:49Z",
            "summary": "Mini-EUSO is a wide-angle fluorescence telescope that registers ultraviolet\n(UV) radiation in the nocturnal atmosphere of Earth from the International\nSpace Station. Meteors are among multiple phenomena that manifest themselves\nnot only in the visible range but also in the UV. We present two simple\nartificial neural networks that allow for recognizing meteor signals in the\nMini-EUSO data with high accuracy in terms of a binary classification problem.\nWe expect that similar architectures can be effectively used for signal\nrecognition in other fluorescence telescopes, regardless of the nature of the\nsignal. Due to their simplicity, the networks can be implemented in onboard\nelectronics of future orbital or balloon experiments.",
            "author": [
                "Mikhail Zotov",
                "Dmitry Anzhiganov",
                "Aleksandr Kryazhenkov",
                "Dario Barghini",
                "Matteo Battisti",
                "Alexander Belov",
                "Mario Bertaina",
                "Marta Bianciotto",
                "Francesca Bisconti",
                "Carl Blaksley",
                "Sylvie Blin",
                "Giorgio Cambi\u00e8",
                "Francesca Capel",
                "Marco Casolino",
                "Toshikazu Ebisuzaki",
                "Johannes Eser",
                "Francesco Fenu",
                "Massimo Alberto Franceschi",
                "Alessio Golzio",
                "Philippe Gorodetzky",
                "Fumiyoshi Kajino",
                "Hiroshi Kasuga",
                "Pavel Klimov",
                "Massimiliano Manfrin",
                "Laura Marcelli",
                "Hiroko Miyamoto",
                "Alexey Murashov",
                "Tommaso Napolitano",
                "Hiroshi Ohmori",
                "Angela Olinto",
                "Etienne Parizot",
                "Piergiorgio Picozza",
                "Lech Wiktor Piotrowski",
                "Zbigniew Plebaniak",
                "Guillaume Pr\u00e9v\u00f4t",
                "Enzo Reali",
                "Marco Ricci",
                "Giulia Romoli",
                "Naoto Sakaki",
                "Kenji Shinozaki",
                "Christophe De La Taille",
                "Yoshiyuki Takizawa",
                "Michal Vr\u00e1bel",
                "Lawrence Wiencke"
            ],
            "link": [
                "http://dx.doi.org/10.3390/a16090448",
                "http://arxiv.org/abs/2311.14983v1",
                "http://arxiv.org/pdf/2311.14983v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14981v1",
            "title": "Multi-task Planar Reconstruction with Feature Warping Guidance",
            "updated": "2023-11-25T09:53:42Z",
            "published": "2023-11-25T09:53:42Z",
            "summary": "Piece-wise planar 3D reconstruction simultaneously segments plane instances\nand recovers their 3D plane parameters from an image, which is particularly\nuseful for indoor or man-made environments. Efficient reconstruction of 3D\nplanes coupled with semantic predictions offers advantages for a wide range of\napplications requiring scene understanding and concurrent spatial mapping.\nHowever, most existing planar reconstruction models either neglect semantic\npredictions or do not run efficiently enough for real-time applications. We\nintroduce SoloPlanes, a real-time planar reconstruction model based on a\nmodified instance segmentation architecture which simultaneously predicts\nsemantics for each plane instance, along with plane parameters and piece-wise\nplane instance masks. By providing multi-view guidance in feature space, we\nachieve an improvement in instance mask segmentation despite only warping plane\nfeatures due to the nature of feature sharing in multi-task learning. Our model\nsimultaneously predicts semantics using single images at inference time, while\nachieving real-time predictions at 43 FPS. The code will be released\npost-publication.",
            "author": [
                "Luan Wei",
                "Anna Hilsmann",
                "Peter Eisert"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14981v1",
                "http://arxiv.org/pdf/2311.14981v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14977v1",
            "title": "Incorporating granularity bias as the margin into contrastive loss for\n  video captioning",
            "updated": "2023-11-25T09:38:24Z",
            "published": "2023-11-25T09:38:24Z",
            "summary": "Video captioning models easily suffer from long-tail distribution of phrases,\nwhich makes captioning models prone to generate vague sentences instead of\naccurate ones. However, existing debiasing strategies tend to export external\nknowledge to build dependency trees of words or refine frequency distribution\nby complex losses and extra input features, which lack interpretability and are\nhard to train. To mitigate the impact of granularity bias on the model, we\nintroduced a statistical-based bias extractor. This extractor quantifies the\ninformation content within sentences and videos, providing an estimate of the\nlikelihood that a video-sentence pair is affected by granularity bias.\nFurthermore, with the growing trend of integrating contrastive learning methods\ninto video captioning tasks, we use a bidirectional triplet loss to get more\nnegative samples in a batch. Subsequently, we incorporate the margin score into\nthe contrastive learning loss, establishing distinct training objectives for\nhead and tail sentences. This approach facilitates the model's training\neffectiveness on tail samples. Our simple yet effective loss, incorporating\nGranularity bias, is referred to as the Margin-Contrastive Loss (GMC Loss). The\nproposed model demonstrates state-of-the-art performance on MSRVTT with a CIDEr\nof 57.17, and MSVD, where CIDEr reaches up to 138.68.",
            "author": [
                "Jiayang Gu",
                "Fengming Yao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14977v1",
                "http://arxiv.org/pdf/2311.14977v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14975v1",
            "title": "Eliminating Domain Bias for Federated Learning in Representation Space",
            "updated": "2023-11-25T09:22:34Z",
            "published": "2023-11-25T09:22:34Z",
            "summary": "Recently, federated learning (FL) is popular for its privacy-preserving and\ncollaborative learning abilities. However, under statistically heterogeneous\nscenarios, we observe that biased data domains on clients cause a\nrepresentation bias phenomenon and further degenerate generic representations\nduring local training, i.e., the representation degeneration phenomenon. To\naddress these issues, we propose a general framework Domain Bias Eliminator\n(DBE) for FL. Our theoretical analysis reveals that DBE can promote\nbi-directional knowledge transfer between server and client, as it reduces the\ndomain discrepancy between server and client in representation space. Besides,\nextensive experiments on four datasets show that DBE can greatly improve\nexisting FL methods in both generalization and personalization abilities. The\nDBE-equipped FL method can outperform ten state-of-the-art personalized FL\nmethods by a large margin. Our code is public at\nhttps://github.com/TsingZ0/DBE.",
            "author": [
                "Jianqing Zhang",
                "Yang Hua",
                "Jian Cao",
                "Hao Wang",
                "Tao Song",
                "Zhengui Xue",
                "Ruhui Ma",
                "Haibing Guan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14975v1",
                "http://arxiv.org/pdf/2311.14975v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14971v2",
            "title": "Segmentation of diagnostic tissue compartments on whole slide images\n  with renal thrombotic microangiopathies (TMAs)",
            "updated": "2023-11-28T10:08:35Z",
            "published": "2023-11-25T09:08:30Z",
            "summary": "The thrombotic microangiopathies (TMAs) manifest in renal biopsy histology\nwith a broad spectrum of acute and chronic findings. Precise diagnostic\ncriteria for a renal biopsy diagnosis of TMA are missing. As a first step\ntowards a machine learning- and computer vision-based analysis of wholes slide\nimages from renal biopsies, we trained a segmentation model for the decisive\ndiagnostic kidney tissue compartments artery, arteriole, glomerulus on a set of\nwhole slide images from renal biopsies with TMAs and Mimickers (distinct\ndiseases with a similar nephropathological appearance as TMA like severe benign\nnephrosclerosis, various vasculitides, Bevacizumab-plug glomerulopathy,\narteriolar light chain deposition disease). Our segmentation model combines a\nU-Net-based tissue detection with a Shifted windows-transformer architecture to\nreach excellent segmentation results for even the most severely altered\nglomeruli, arterioles and arteries, even on unseen staining domains from a\ndifferent nephropathology lab. With accurate automatic segmentation of the\ndecisive renal biopsy compartments in human renal vasculopathies, we have laid\nthe foundation for large-scale compartment-specific machine learning and\ncomputer vision analysis of renal biopsy repositories with TMAs.",
            "author": [
                "Huy Q. Vo",
                "Pietro A. Cicalese",
                "Surya Seshan",
                "Syed A. Rizvi",
                "Aneesh Vathul",
                "Gloria Bueno",
                "Anibal Pedraza Dorado",
                "Niels Grabe",
                "Katharina Stolle",
                "Francesco Pesce",
                "Joris J. T. H. Roelofs",
                "Jesper Kers",
                "Vitoantonio Bevilacqua",
                "Nicola Altini",
                "Bernd Schr\u00f6ppel",
                "Dario Roccatello",
                "Antonella Barreca",
                "Savino Sciascia",
                "Chandra Mohan",
                "Hien V. Nguyen",
                "Jan U. Becker"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14971v2",
                "http://arxiv.org/pdf/2311.14971v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "q-bio.TO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14968v2",
            "title": "Hide Your Model: A Parameter Transmission-free Federated Recommender\n  System",
            "updated": "2023-11-28T11:10:27Z",
            "published": "2023-11-25T08:59:45Z",
            "summary": "With the growing concerns regarding user data privacy, Federated Recommender\nSystem (FedRec) has garnered significant attention recently due to its\nprivacy-preserving capabilities. Existing FedRecs generally adhere to a\nlearning protocol in which a central server shares a global recommendation\nmodel with clients, and participants achieve collaborative learning by\nfrequently communicating the model's public parameters. Nevertheless, this\nlearning framework has two drawbacks that limit its practical usability: (1) It\nnecessitates a global-sharing recommendation model; however, in real-world\nscenarios, information related to the recommender model, including its\nalgorithm and parameters, constitutes the platforms' intellectual property.\nHence, service providers are unlikely to release such information actively. (2)\nThe communication costs of model parameter transmission are expensive since the\nmodel parameters are usually high-dimensional matrices. With the model size\nincreasing, the communication burden will be the bottleneck for such\ntraditional FedRecs.\n  Given the above limitations, this paper introduces a novel parameter\ntransmission-free federated recommendation framework that balances the\nprotection between users' data privacy and platforms' model privacy, namely\nPTF-FedRec. Specifically, participants in PTF-FedRec collaboratively exchange\nknowledge by sharing their predictions within a privacy-preserving mechanism.\nThrough this way, the central server can learn a recommender model without\ndisclosing its model parameters or accessing clients' raw data, preserving both\nthe server's model privacy and users' data privacy. Besides, since clients and\nthe central server only need to communicate prediction scores which are just a\nfew real numbers, the overhead is significantly reduced compared to traditional\nFedRecs.",
            "author": [
                "Wei Yuan",
                "Chaoqun Yang",
                "Liang Qu",
                "Quoc Viet Hung Nguyen",
                "Jianxin Li",
                "Hongzhi Yin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14968v2",
                "http://arxiv.org/pdf/2311.14968v2"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14964v1",
            "title": "Selective Inference for Changepoint detection by Recurrent Neural\n  Network",
            "updated": "2023-11-25T08:34:31Z",
            "published": "2023-11-25T08:34:31Z",
            "summary": "In this study, we investigate the quantification of the statistical\nreliability of detected change points (CPs) in time series using a Recurrent\nNeural Network (RNN). Thanks to its flexibility, RNN holds the potential to\neffectively identify CPs in time series characterized by complex dynamics.\nHowever, there is an increased risk of erroneously detecting random noise\nfluctuations as CPs. The primary goal of this study is to rigorously control\nthe risk of false detections by providing theoretically valid p-values to the\nCPs detected by RNN. To achieve this, we introduce a novel method based on the\nframework of Selective Inference (SI). SI enables valid inferences by\nconditioning on the event of hypothesis selection, thus mitigating selection\nbias. In this study, we apply SI framework to RNN-based CP detection, where\ncharacterizing the complex process of RNN selecting CPs is our main technical\nchallenge. We demonstrate the validity and effectiveness of the proposed method\nthrough artificial and real data experiments.",
            "author": [
                "Tomohiro Shiraishi",
                "Daiki Miwa",
                "Vo Nguyen Le Duy",
                "Ichiro Takeuchi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14964v1",
                "http://arxiv.org/pdf/2311.14964v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14963v1",
            "title": "Precision spectrophotometry for PNLF distances: the case of NGC 300",
            "updated": "2023-11-25T08:32:45Z",
            "published": "2023-11-25T08:32:45Z",
            "summary": "The Multi-Unit Spectroscopic Explorer (MUSE) has enabled a renaissance of the\nplanetary nebula luminosity function (PNLF) as a standard candle. In the case\nof NGC 300, we learned that the precise spectrophotometry of MUSE was crucial\nto obtain an accurate PNLF distance. We present the advantage of the integral\nfield spectrograph compared to the slit spectrograph in delivering precise\nspectrophotometry by simulating a slit observation on integral field\nspectroscopy data. We also discuss the possible systematic shift in measuring\nthe PNLF distance using the least-square method, especially when the PNLF\ncutoff is affected by small number statistics.",
            "author": [
                "Azlizan A. Soemitro",
                "Martin M. Roth",
                "Peter M. Weilbacher",
                "Robin Ciardullo",
                "George H. Jacoby",
                "Ana Monreal-Ibero",
                "Norberto Castro",
                "Genoveva Micheva"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14963v1",
                "http://arxiv.org/pdf/2311.14963v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14960v1",
            "title": "Point Cloud Pre-training with Diffusion Models",
            "updated": "2023-11-25T08:10:05Z",
            "published": "2023-11-25T08:10:05Z",
            "summary": "Pre-training a model and then fine-tuning it on downstream tasks has\ndemonstrated significant success in the 2D image and NLP domains. However, due\nto the unordered and non-uniform density characteristics of point clouds, it is\nnon-trivial to explore the prior knowledge of point clouds and pre-train a\npoint cloud backbone. In this paper, we propose a novel pre-training method\ncalled Point cloud Diffusion pre-training (PointDif). We consider the point\ncloud pre-training task as a conditional point-to-point generation problem and\nintroduce a conditional point generator. This generator aggregates the features\nextracted by the backbone and employs them as the condition to guide the\npoint-to-point recovery from the noisy point cloud, thereby assisting the\nbackbone in capturing both local and global geometric priors as well as the\nglobal point density distribution of the object. We also present a recurrent\nuniform sampling optimization strategy, which enables the model to uniformly\nrecover from various noise levels and learn from balanced supervision. Our\nPointDif achieves substantial improvement across various real-world datasets\nfor diverse downstream tasks such as classification, segmentation and\ndetection. Specifically, PointDif attains 70.0% mIoU on S3DIS Area 5 for the\nsegmentation task and achieves an average improvement of 2.4% on ScanObjectNN\nfor the classification task compared to TAP. Furthermore, our pre-training\nframework can be flexibly applied to diverse point cloud backbones and bring\nconsiderable gains.",
            "author": [
                "Xiao Zheng",
                "Xiaoshui Huang",
                "Guofeng Mei",
                "Yuenan Hou",
                "Zhaoyang Lyu",
                "Bo Dai",
                "Wanli Ouyang",
                "Yongshun Gong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14960v1",
                "http://arxiv.org/pdf/2311.14960v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14955v1",
            "title": "Identification of morphological fingerprint in perinatal brains using\n  quasi-conformal mapping and contrastive learning",
            "updated": "2023-11-25T07:43:17Z",
            "published": "2023-11-25T07:43:17Z",
            "summary": "The morphological fingerprint in the brain is capable of identifying the\nuniqueness of an individual. However, whether such individual patterns are\npresent in perinatal brains, and which morphological attributes or cortical\nregions better characterize the individual differences of ne-onates remain\nunclear. In this study, we proposed a deep learning framework that projected\nthree-dimensional spherical meshes of three morphological features (i.e.,\ncortical thickness, mean curvature, and sulcal depth) onto two-dimensional\nplanes through quasi-conformal mapping, and employed the ResNet18 and\ncontrastive learning for individual identification. We used the cross-sectional\nstructural MRI data of 682 infants, incorporating with data augmentation, to\ntrain the model and fine-tuned the parameters based on 60 infants who had\nlongitudinal scans. The model was validated on 30 longitudinal scanned infant\ndata, and remarkable Top1 and Top5 accuracies of 71.37% and 84.10% were\nachieved, respectively. The sensorimotor and visual cortices were recognized as\nthe most contributive regions in individual identification. Moreover, the\nfolding morphology demonstrated greater discriminative capability than the\ncortical thickness, which could serve as the morphological fingerprint in\nperinatal brains. These findings provided evidence for the emergence of\nmorphological fingerprints in the brain at the beginning of the third\ntrimester, which may hold promising implications for understanding the\nformation of in-dividual uniqueness in the brain during early development.",
            "author": [
                "Boyang Wang",
                "Weihao Zheng",
                "Ying Wang",
                "Zhe Zhang",
                "Yuchen Sheng",
                "Minmin Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14955v1",
                "http://arxiv.org/pdf/2311.14955v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14949v1",
            "title": "Vector-Quantized Prompt Learning for Paraphrase Generation",
            "updated": "2023-11-25T07:13:06Z",
            "published": "2023-11-25T07:13:06Z",
            "summary": "Deep generative modeling of natural languages has achieved many successes,\nsuch as producing fluent sentences and translating from one language into\nanother. However, the development of generative modeling techniques for\nparaphrase generation still lags behind largely due to the challenges in\naddressing the complex conflicts between expression diversity and semantic\npreservation. This paper proposes to generate diverse and high-quality\nparaphrases by exploiting the pre-trained models with instance-dependent\nprompts. To learn generalizable prompts, we assume that the number of abstract\ntransforming patterns of paraphrase generation (governed by prompts) is finite\nand usually not large. Therefore, we present vector-quantized prompts as the\ncues to control the generation of pre-trained models. Extensive experiments\ndemonstrate that the proposed method achieves new state-of-art results on three\nbenchmark datasets, including Quora, Wikianswers, and MSCOCO. We will release\nall the code upon acceptance.",
            "author": [
                "Haotian Luo",
                "Yixin Liu",
                "Peidong Liu",
                "Xianggen Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14949v1",
                "http://arxiv.org/pdf/2311.14949v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14948v3",
            "title": "Effective Backdoor Mitigation Depends on the Pre-training Objective",
            "updated": "2023-12-05T21:52:47Z",
            "published": "2023-11-25T06:55:13Z",
            "summary": "Despite the advanced capabilities of contemporary machine learning (ML)\nmodels, they remain vulnerable to adversarial and backdoor attacks. This\nvulnerability is particularly concerning in real-world deployments, where\ncompromised models may exhibit unpredictable behavior in critical scenarios.\nSuch risks are heightened by the prevalent practice of collecting massive,\ninternet-sourced datasets for pre-training multimodal models, as these datasets\nmay harbor backdoors. Various techniques have been proposed to mitigate the\neffects of backdooring in these models such as CleanCLIP which is the current\nstate-of-the-art approach. In this work, we demonstrate that the efficacy of\nCleanCLIP in mitigating backdoors is highly dependent on the particular\nobjective used during model pre-training. We observe that stronger pre-training\nobjectives correlate with harder to remove backdoors behaviors. We show this by\ntraining multimodal models on two large datasets consisting of 3 million (CC3M)\nand 6 million (CC6M) datapoints, under various pre-training objectives,\nfollowed by poison removal using CleanCLIP. We find that CleanCLIP is\nineffective when stronger pre-training objectives are used, even with extensive\nhyperparameter tuning. Our findings underscore critical considerations for ML\npractitioners who pre-train models using large-scale web-curated data and are\nconcerned about potential backdoor threats. Notably, our results suggest that\nsimpler pre-training objectives are more amenable to effective backdoor\nremoval. This insight is pivotal for practitioners seeking to balance the\ntrade-offs between using stronger pre-training objectives and security against\nbackdoor attacks.",
            "author": [
                "Sahil Verma",
                "Gantavya Bhatt",
                "Avi Schwarzschild",
                "Soumye Singhal",
                "Arnav Mohanty Das",
                "Chirag Shah",
                "John P Dickerson",
                "Jeff Bilmes"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14948v3",
                "http://arxiv.org/pdf/2311.14948v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14947v1",
            "title": "Application of Machine Learning Method to Model-Based Library Approach\n  to Critical Dimension Measurement by CD-SEM",
            "updated": "2023-11-25T06:52:53Z",
            "published": "2023-11-25T06:52:53Z",
            "summary": "The model-based library (MBL) method has already been established for the\naccurate measurement of critical dimension (CD) of semiconductor linewidth from\na critical dimension scanning electron microscope (CD-SEM) image. In this work\nthe MBL method has been further investigated by combing the CD-SEM image\nsimulation with a neural network algorithm. The secondary electron linescan\nprofiles were calculated at first by a Monte Carlo simulation method, enabling\nto obtain the dependence of linescan profiles on the selected values of various\ngeometrical parameters (e.g., top CD, sidewall angle and height) for Si and Au\ntrapezoidal line structures. The machine learning methods have then been\napplied to predicate the linescan profiles from a randomly selected training\nset of the calculated profiles. The predicted results agree very well with the\ncalculated profiles with the standard deviation of 0.1% and 6% for the relative\nerror distributions of Si and Au line structures, respectively. This result\nshows that the machine learning methods can be practically applied to the MBL\nmethod for the purpose of reducing the library size, accelerating the\nconstruction of the MBL database and enriching the content of an available MBL\ndatabase.",
            "author": [
                "P. Guo",
                "H. Miao",
                "Y. B. Zou",
                "S. F. Mao",
                "Z. J. Ding"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14947v1",
                "http://arxiv.org/pdf/2311.14947v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14939v1",
            "title": "OpenNet: Incremental Learning for Autonomous Driving Object Detection\n  with Balanced Loss",
            "updated": "2023-11-25T06:02:50Z",
            "published": "2023-11-25T06:02:50Z",
            "summary": "Automated driving object detection has always been a challenging task in\ncomputer vision due to environmental uncertainties. These uncertainties include\nsignificant differences in object sizes and encountering the class unseen. It\nmay result in poor performance when traditional object detection models are\ndirectly applied to automated driving detection. Because they usually presume\nfixed categories of common traffic participants, such as pedestrians and cars.\nWorsely, the huge class imbalance between common and novel classes further\nexacerbates performance degradation. To address the issues stated, we propose\nOpenNet to moderate the class imbalance with the Balanced Loss, which is based\non Cross Entropy Loss. Besides, we adopt an inductive layer based on gradient\nreshaping to fast learn new classes with limited samples during incremental\nlearning. To against catastrophic forgetting, we employ normalized feature\ndistillation. By the way, we improve multi-scale detection robustness and\nunknown class recognition through FPN and energy-based detection, respectively.\nThe Experimental results upon the CODA dataset show that the proposed method\ncan obtain better performance than that of the existing methods.",
            "author": [
                "Zezhou Wang",
                "Guitao Cao",
                "Xidong Xi",
                "Jiangtao Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14939v1",
                "http://arxiv.org/pdf/2311.14939v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14936v1",
            "title": "Single-image based deep learning for precise atomic defects\n  identification",
            "updated": "2023-11-25T05:53:34Z",
            "published": "2023-11-25T05:53:34Z",
            "summary": "Defect engineering has been profoundly employed to confer desirable\nfunctionality to materials that pristine lattices inherently lack. Although\nsingle atomic-resolution scanning transmission electron microscopy (STEM)\nimages are widely accessible for defect engineering, harnessing atomic-scale\nimages containing various defects through traditional image analysis methods is\nhindered by random noise and human bias. Yet the rise of deep learning (DL)\noffering an alternative approach, its widespread application is primarily\nrestricted by the need for large amounts of training data with labeled ground\ntruth. In this study, we propose a two-stage method to address the problems of\nhigh annotation cost and image noise in the detection of atomic defects in\nmonolayer 2D materials. In the first stage, to tackle the issue of data\nscarcity, we employ a two-state transformation network based on U-GAT-IT for\nadding realistic noise to simulated images with pre-located ground truth\nlabels, thereby infinitely expanding the training dataset. In the second stage,\natomic defects in monolayer 2D materials are effectively detected with high\naccuracy using U-Net models trained with the data generated in the first stage,\navoiding random noise and human bias issues. In both stages, we utilize\nsegmented unit-cell-level images to simplify the model's task and enhance its\naccuracy. Our results demonstrate that not only sulfur vacancies, we are also\nable to visualize oxygen dopants in monolayer MoS2, which are usually\noverwhelmed by random background noise. As the training was based on a few\nsegmented unit-cell-level realistic images, this method can be readily extended\nto other 2D materials. Therefore, our results outline novel ways to train the\nmodel with minimized datasets, offering great opportunities to fully exploit\nthe power of machine learning (ML) applicable to a broad materials science\ncommunity.",
            "author": [
                "Kangshu Li",
                "Xiaocang Han",
                "Yanhui Hong",
                "Yuan Meng",
                "Xiang Chen",
                "Junxian Li",
                "Jing-Yang You",
                "Lin Yao",
                "Wenchao Hu",
                "Zhiyi Xia",
                "Guolin Ke",
                "Linfeng Zhang",
                "Jin Zhang",
                "Xiaoxu Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14936v1",
                "http://arxiv.org/pdf/2311.14936v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14935v1",
            "title": "A Novel Deep Clustering Framework for Fine-Scale Parcellation of\n  Amygdala Using dMRI Tractography",
            "updated": "2023-11-25T05:43:51Z",
            "published": "2023-11-25T05:43:51Z",
            "summary": "The amygdala plays a vital role in emotional processing and exhibits\nstructural diversity that necessitates fine-scale parcellation for a\ncomprehensive understanding of its anatomico-functional correlations. Diffusion\nMRI tractography is an advanced imaging technique that can estimate the brain's\nwhite matter structural connectivity to potentially reveal the topography of\nthe amygdala for studying its subdivisions. In this work, we present a deep\nclustering pipeline to perform automated, fine-scale parcellation of the\namygdala using diffusion MRI tractography. First, we incorporate a newly\nproposed deep learning approach to enable accurate segmentation of the amygdala\ndirectly on the dMRI data. Next, we design a novel streamline clustering-based\nstructural connectivity feature for a robust representation of voxels within\nthe amygdala. Finally, we improve the popular joint dimensionality reduction\nand k-means clustering approach to enable amygdala parcellation at a finer\nscale. With the proposed method, we obtain nine unique amygdala parcels.\nExperiments show that these parcels can be consistently identified across\nsubjects and have good correspondence to the widely used coarse-scale amygdala\nparcellation.",
            "author": [
                "Haolin He",
                "Ce Zhu",
                "Le Zhang",
                "Yipeng Liu",
                "Xiao Xu",
                "Yuqian Chen",
                "Leo Zekelman",
                "Jarrett Rushmore",
                "Yogesh Rathi",
                "Nikos Makris",
                "Lauren J. O'Donnell",
                "Fan Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14935v1",
                "http://arxiv.org/pdf/2311.14935v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14934v1",
            "title": "Robust Graph Neural Networks via Unbiased Aggregation",
            "updated": "2023-11-25T05:34:36Z",
            "published": "2023-11-25T05:34:36Z",
            "summary": "The adversarial robustness of Graph Neural Networks (GNNs) has been\nquestioned due to the false sense of security uncovered by strong adaptive\nattacks despite the existence of numerous defenses. In this work, we delve into\nthe robustness analysis of representative robust GNNs and provide a unified\nrobust estimation point of view to understand their robustness and limitations.\nOur novel analysis of estimation bias motivates the design of a robust and\nunbiased graph signal estimator. We then develop an efficient Quasi-Newton\niterative reweighted least squares algorithm to solve the estimation problem,\nwhich unfolds as robust unbiased aggregation layers in GNNs with a theoretical\nconvergence guarantee. Our comprehensive experiments confirm the strong\nrobustness of our proposed model, and the ablation study provides a deep\nunderstanding of its advantages.",
            "author": [
                "Ruiqi Feng",
                "Zhichao Hou",
                "Tyler Derr",
                "Xiaorui Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14934v1",
                "http://arxiv.org/pdf/2311.14934v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14931v1",
            "title": "One-Shot Transfer Learning for Nonlinear ODEs",
            "updated": "2023-11-25T05:02:15Z",
            "published": "2023-11-25T05:02:15Z",
            "summary": "We introduce a generalizable approach that combines perturbation method and\none-shot transfer learning to solve nonlinear ODEs with a single polynomial\nterm, using Physics-Informed Neural Networks (PINNs). Our method transforms\nnon-linear ODEs into linear ODE systems, trains a PINN across varied\nconditions, and offers a closed-form solution for new instances within the same\nnon-linear ODE class. We demonstrate the effectiveness of this approach on the\nDuffing equation and suggest its applicability to similarly structured PDEs and\nODE systems.",
            "author": [
                "Wanzhou Lei",
                "Pavlos Protopapas",
                "Joy Parikh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14931v1",
                "http://arxiv.org/pdf/2311.14931v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "68T07",
                "I.2.1"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14925v1",
            "title": "Coordinate-based Neural Network for Fourier Phase Retrieval",
            "updated": "2023-11-25T04:23:23Z",
            "published": "2023-11-25T04:23:23Z",
            "summary": "Fourier phase retrieval is essential for high-definition imaging of nanoscale\nstructures across diverse fields, notably coherent diffraction imaging. This\nstudy presents the Single impliCit neurAl Network (SCAN), a tool built upon\ncoordinate neural networks meticulously designed for enhanced phase retrieval\nperformance. Bypassing the pitfalls of conventional iterative methods, which\nfrequently face high computational loads and are prone to noise interference,\nSCAN adeptly connects object coordinates to their amplitude and phase within a\nunified network in an unsupervised manner. While many existing methods\nprimarily use Fourier magnitude in their loss function, our approach\nincorporates both the predicted magnitude and phase, enhancing retrieval\naccuracy. Comprehensive tests validate SCAN's superiority over traditional and\nother deep learning models regarding accuracy and noise robustness. We also\ndemonstrate that SCAN excels in the ptychography setting.",
            "author": [
                "Tingyou Li",
                "Zixin Xu",
                "Yong S. Chu",
                "Xiaojing Huang",
                "Jizhou Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14925v1",
                "http://arxiv.org/pdf/2311.14925v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14920v1",
            "title": "DECap: Towards Generalized Explicit Caption Editing via Diffusion\n  Mechanism",
            "updated": "2023-11-25T03:52:03Z",
            "published": "2023-11-25T03:52:03Z",
            "summary": "Explicit Caption Editing (ECE) -- refining reference image captions through a\nsequence of explicit edit operations (e.g., KEEP, DETELE) -- has raised\nsignificant attention due to its explainable and human-like nature. After\ntraining with carefully designed reference and ground-truth caption pairs,\nstate-of-the-art ECE models exhibit limited generalization ability beyond the\noriginal training data distribution, i.e., they are tailored to refine content\ndetails only in in-domain samples but fail to correct errors in out-of-domain\nsamples. To this end, we propose a new Diffusion-based Explicit Caption editing\nmethod: DECap. Specifically, we reformulate the ECE task as a denoising process\nunder the diffusion mechanism, and introduce innovative edit-based noising and\ndenoising processes. Thanks to this design, the noising process can help to\neliminate the need for meticulous paired data selection by directly introducing\nword-level noises for training, learning diverse distribution over input\nreference caption. The denoising process involves the explicit predictions of\nedit operations and corresponding content words, refining reference captions\nthrough iterative step-wise editing. To further efficiently implement our\ndiffusion process and improve the inference speed, DECap discards the prevalent\nmulti-stage design and directly generates edit operations and content words\nsimultaneously. Extensive ablations have demonstrated the strong generalization\nability of DECap in various scenarios. More interestingly, it even shows great\npotential in improving the quality and controllability of caption generation.",
            "author": [
                "Zhen Wang",
                "Jun Xiao",
                "Tao Chen",
                "Long Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14920v1",
                "http://arxiv.org/pdf/2311.14920v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14919v1",
            "title": "Faster Minimum Bayes Risk Decoding with Confidence-based Pruning",
            "updated": "2023-11-25T03:38:14Z",
            "published": "2023-11-25T03:38:14Z",
            "summary": "Minimum Bayes risk (MBR) decoding outputs the hypothesis with the highest\nexpected utility over the model distribution for some utility function. It has\nbeen shown to improve accuracy over beam search in conditional language\ngeneration problems and especially neural machine translation, in both human\nand automatic evaluations. However, the standard sampling-based algorithm for\nMBR is substantially more computationally expensive than beam search, requiring\na large number of samples as well as a quadratic number of calls to the utility\nfunction, limiting its applicability. We describe an algorithm for MBR which\ngradually grows the number of samples used to estimate the utility while\npruning hypotheses that are unlikely to have the highest utility according to\nconfidence estimates obtained with bootstrap sampling. Our method requires\nfewer samples and drastically reduces the number of calls to the utility\nfunction compared to standard MBR while being statistically indistinguishable\nin terms of accuracy. We demonstrate the effectiveness of our approach in\nexperiments on three language pairs, using chrF++ and COMET as\nutility/evaluation metrics.",
            "author": [
                "Julius Cheng",
                "Andreas Vlachos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14919v1",
                "http://arxiv.org/pdf/2311.14919v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14918v1",
            "title": "Resolution- and Stimulus-agnostic Super-Resolution of Ultra-High-Field\n  Functional MRI: Application to Visual Studies",
            "updated": "2023-11-25T03:33:36Z",
            "published": "2023-11-25T03:33:36Z",
            "summary": "High-resolution fMRI provides a window into the brain's mesoscale\norganization. Yet, higher spatial resolution increases scan times, to\ncompensate for the low signal and contrast-to-noise ratio. This work introduces\na deep learning-based 3D super-resolution (SR) method for fMRI. By\nincorporating a resolution-agnostic image augmentation framework, our method\nadapts to varying voxel sizes without retraining. We apply this innovative\ntechnique to localize fine-scale motion-selective sites in the early visual\nareas. Detection of these sites typically requires a resolution higher than 1\nmm isotropic, whereas here, we visualize them based on lower resolution (2-3mm\nisotropic) fMRI data. Remarkably, the super-resolved fMRI is able to recover\nhigh-frequency detail of the interdigitated organization of these sites\n(relative to the color-selective sites), even with training data sourced from\ndifferent subjects and experimental paradigms -- including non-visual\nresting-state fMRI, underscoring its robustness and versatility. Quantitative\nand qualitative results indicate that our method has the potential to enhance\nthe spatial resolution of fMRI, leading to a drastic reduction in acquisition\ntime.",
            "author": [
                "Hongwei Bran Li",
                "Matthew S. Rosen",
                "Shahin Nasr",
                "Juan Eugenio Iglesias"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14918v1",
                "http://arxiv.org/pdf/2311.14918v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14917v1",
            "title": "Consolidate Viability and Information Theories for Task-Oriented\n  Communications: A Homeostasis Solution",
            "updated": "2023-11-25T03:32:18Z",
            "published": "2023-11-25T03:32:18Z",
            "summary": "The next generation of cellular networks, 6G, is expected to offer a range of\nexciting applications and services, including holographic communication,\nmachine-to-machine communication, and data sensing from millions of devices.\nThere is an incremental exhaustion of the spectral resources. It is crucial to\nefficiently manage these resources through value-driven approaches that\neliminate waste and continually enhance the communication process. These\nmanagement principles align with the Task-Oriented Communications (TOC)\nphilosophy. The aim is to allocate the minimum necessary communication resource\naccording to the receiver's objective and continuously improve the\ncommunication process. However, it is currently unclear how to build knowledge\nof the receiver's goal and operate accordingly for efficient-resource\nutilization. Our management approach combines viability theory and transfer\nentropy to ensure that the actor remains within a viable space as per their\ngoal and to gradually reduce the information exchange through knowledge\naccumulation. We discuss these theories in the context of TOC and examine their\napplication in the plant process control case. Finally, we provide insights\ninto future research directions from computational, performance, and protocol\nperspectives.",
            "author": [
                "Ozgur Ercetin",
                "Mohaned Chraiti",
                "Rustu Erciyes Karakaya"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14917v1",
                "http://arxiv.org/pdf/2311.14917v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.SY",
                "eess.SY",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14913v1",
            "title": "Tensor Unfolding Characterization",
            "updated": "2023-11-25T03:17:49Z",
            "published": "2023-11-25T03:17:49Z",
            "summary": "Tensors play a pivotal role in the realms of science and engineering,\nparticularly in the realms of data analysis, machine learning, and\ncomputational mathematics. The process of unfolding a tensor into matrices,\ncommonly known as tensor unfolding or matricization, serves as a valuable\ntechnique for simplifying the representation of tensors with higher orders. In\nthis study, we initially derive unfolded matrices from a specified tensor over\na B{'e}zout ring using a matrix equivalence relation. We proceed to elucidate\nthe relationships between eigenvalues and eigenvectors within these unfolded\nmatrices. Additionally, we employ the localization approach outlined by\nGerstein to ascertain the count of distinct matrix equivalence classes present\namong the unfolded matrices.",
            "author": [
                "Shih-Yu Chang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14913v1",
                "http://arxiv.org/pdf/2311.14913v1"
            ],
            "primary_category": "math.RA",
            "category": [
                "math.RA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14911v1",
            "title": "CUCL: Codebook for Unsupervised Continual Learning",
            "updated": "2023-11-25T03:08:50Z",
            "published": "2023-11-25T03:08:50Z",
            "summary": "The focus of this study is on Unsupervised Continual Learning (UCL), as it\npresents an alternative to Supervised Continual Learning which needs\nhigh-quality manual labeled data. The experiments under the UCL paradigm\nindicate a phenomenon where the results on the first few tasks are suboptimal.\nThis phenomenon can render the model inappropriate for practical applications.\nTo address this issue, after analyzing the phenomenon and identifying the lack\nof diversity as a vital factor, we propose a method named Codebook for\nUnsupervised Continual Learning (CUCL) which promotes the model to learn\ndiscriminative features to complete the class boundary. Specifically, we first\nintroduce a Product Quantization to inject diversity into the representation\nand apply a cross quantized contrastive loss between the original\nrepresentation and the quantized one to capture discriminative information.\nThen, based on the quantizer, we propose an effective Codebook Rehearsal to\naddress catastrophic forgetting. This study involves conducting extensive\nexperiments on CIFAR100, TinyImageNet, and MiniImageNet benchmark datasets. Our\nmethod significantly boosts the performances of supervised and unsupervised\nmethods. For instance, on TinyImageNet, our method led to a relative\nimprovement of 12.76% and 7% when compared with Simsiam and BYOL, respectively.",
            "author": [
                "Chen Cheng",
                "Jingkuan Song",
                "Xiaosu Zhu",
                "Junchen Zhu",
                "Lianli Gao",
                "Hengtao Shen"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3581783.3611713",
                "http://arxiv.org/abs/2311.14911v1",
                "http://arxiv.org/pdf/2311.14911v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14910v1",
            "title": "A latent linear model for nonlinear coupled oscillators on graphs",
            "updated": "2023-11-25T03:04:17Z",
            "published": "2023-11-25T03:04:17Z",
            "summary": "A system of coupled oscillators on an arbitrary graph is locally driven by\nthe tendency to mutual synchronization between nearby oscillators, but can and\noften exhibit nonlinear behavior on the whole graph. Understanding such\nnonlinear behavior has been a key challenge in predicting whether all\noscillators in such a system will eventually synchronize. In this paper, we\ndemonstrate that, surprisingly, such nonlinear behavior of coupled oscillators\ncan be effectively linearized in certain latent dynamic spaces. The key insight\nis that there is a small number of `latent dynamics filters', each with a\nspecific association with synchronizing and non-synchronizing dynamics on\nsubgraphs so that any observed dynamics on subgraphs can be approximated by a\nsuitable linear combination of such elementary dynamic patterns. Taking an\nensemble of subgraph-level predictions provides an interpretable predictor for\nwhether the system on the whole graph reaches global synchronization. We\npropose algorithms based on supervised matrix factorization to learn such\nlatent dynamics filters. We demonstrate that our method performs competitively\nin synchronization prediction tasks against baselines and black-box\nclassification algorithms, despite its simple and interpretable architecture.",
            "author": [
                "Agam Goyal",
                "Zhaoxing Wu",
                "Richard P. Yim",
                "Binhao Chen",
                "Zihong Xu",
                "Hanbaek Lyu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14910v1",
                "http://arxiv.org/pdf/2311.14910v1"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16181v1",
            "title": "mvlearnR and Shiny App for multiview learning",
            "updated": "2023-11-25T03:01:12Z",
            "published": "2023-11-25T03:01:12Z",
            "summary": "The package mvlearnR and accompanying Shiny App is intended for integrating\ndata from multiple sources or views or modalities (e.g. genomics, proteomics,\nclinical and demographic data). Most existing software packages for multiview\nlearning are decentralized and offer limited capabilities, making it difficult\nfor users to perform comprehensive integrative analysis. The new package wraps\nstatistical and machine learning methods and graphical tools, providing a\nconvenient and easy data integration workflow. For users with limited\nprogramming language, we provide a Shiny Application to facilitate data\nintegration anywhere and on any device. The methods have potential to offer\ndeeper insights into complex disease mechanisms.\n  Availability and Implementation: mvlearnR is available from the following\nGitHub repository: https://github.com/lasandrall/mvlearnR. The web application\nis hosted on shinyapps.io and available at:\nhttps://multi-viewlearn.shinyapps.io/MultiView_Modeling/",
            "author": [
                "Elise F. Palzer",
                "Sandra E. Safo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16181v1",
                "http://arxiv.org/pdf/2311.16181v1"
            ],
            "primary_category": "q-bio.GN",
            "category": [
                "q-bio.GN",
                "cs.LG",
                "stat.AP",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14909v1",
            "title": "Continual Referring Expression Comprehension via Dual Modular\n  Memorization",
            "updated": "2023-11-25T02:58:51Z",
            "published": "2023-11-25T02:58:51Z",
            "summary": "Referring Expression Comprehension (REC) aims to localize an image region of\na given object described by a natural-language expression. While promising\nperformance has been demonstrated, existing REC algorithms make a strong\nassumption that training data feeding into a model are given upfront, which\ndegrades its practicality for real-world scenarios. In this paper, we propose\nContinual Referring Expression Comprehension (CREC), a new setting for REC,\nwhere a model is learning on a stream of incoming tasks. In order to\ncontinuously improve the model on sequential tasks without forgetting prior\nlearned knowledge and without repeatedly re-training from a scratch, we propose\nan effective baseline method named Dual Modular Memorization (DMM), which\nalleviates the problem of catastrophic forgetting by two memorization modules:\nImplicit-Memory and Explicit-Memory. Specifically, the former module aims to\nconstrain drastic changes to important parameters learned on old tasks when\nlearning a new task; while the latter module maintains a buffer pool to\ndynamically select and store representative samples of each seen task for\nfuture rehearsal. We create three benchmarks for the new CREC setting, by\nrespectively re-splitting three widely-used REC datasets RefCOCO, RefCOCO+ and\nRefCOCOg into sequential tasks. Extensive experiments on the constructed\nbenchmarks demonstrate that our DMM method significantly outperforms other\nalternatives, based on two popular REC backbones. We make the source code and\nbenchmarks publicly available to foster future progress in this field:\nhttps://github.com/zackschen/DMM.",
            "author": [
                "Heng Tao Shen",
                "Cheng Chen",
                "Peng Wang",
                "Lianli Gao",
                "Meng Wang",
                "Jingkuan Song"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TIP.2022.3212317",
                "http://arxiv.org/abs/2311.14909v1",
                "http://arxiv.org/pdf/2311.14909v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14908v1",
            "title": "Support Vector Machine Implementation on MPI-CUDA and Tensorflow\n  Framework",
            "updated": "2023-11-25T02:52:37Z",
            "published": "2023-11-25T02:52:37Z",
            "summary": "Support Vector Machine (SVM) algorithm requires a high computational cost\n(both in memory and time) to solve a complex quadratic programming (QP)\noptimization problem during the training process. Consequently, SVM\nnecessitates high computing hardware capabilities. The central processing unit\n(CPU) clock frequency cannot be increased due to physical limitations in the\nminiaturization process. However, the potential of parallel multi-architecture,\navailable in both multi-core CPUs and highly scalable GPUs, emerges as a\npromising solution to enhance algorithm performance. Therefore, there is an\nopportunity to reduce the high computational time required by SVM for solving\nthe QP optimization problem. This paper presents a comparative study that\nimplements the SVM algorithm on different parallel architecture frameworks. The\nexperimental results show that SVM MPI-CUDA implementation achieves a speedup\nover SVM TensorFlow implementation on different datasets. Moreover, SVM\nTensorFlow implementation provides a cross-platform solution that can be\nmigrated to alternative hardware components, which will reduces the development\ntime.",
            "author": [
                "Islam Elgarhy"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14908v1",
                "http://arxiv.org/pdf/2311.14908v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14905v1",
            "title": "Class Gradient Projection For Continual Learning",
            "updated": "2023-11-25T02:45:56Z",
            "published": "2023-11-25T02:45:56Z",
            "summary": "Catastrophic forgetting is one of the most critical challenges in Continual\nLearning (CL). Recent approaches tackle this problem by projecting the gradient\nupdate orthogonal to the gradient subspace of existing tasks. While the results\nare remarkable, those approaches ignore the fact that these calculated\ngradients are not guaranteed to be orthogonal to the gradient subspace of each\nclass due to the class deviation in tasks, e.g., distinguishing \"Man\" from\n\"Sea\" v.s. differentiating \"Boy\" from \"Girl\". Therefore, this strategy may\nstill cause catastrophic forgetting for some classes. In this paper, we propose\nClass Gradient Projection (CGP), which calculates the gradient subspace from\nindividual classes rather than tasks. Gradient update orthogonal to the\ngradient subspace of existing classes can be effectively utilized to minimize\ninterference from other classes. To improve the generalization and efficiency,\nwe further design a Base Refining (BR) algorithm to combine similar classes and\nrefine class bases dynamically. Moreover, we leverage a contrastive learning\nmethod to improve the model's ability to handle unseen tasks. Extensive\nexperiments on benchmark datasets demonstrate the effectiveness of our proposed\napproach. It improves the previous methods by 2.0% on the CIFAR-100 dataset.",
            "author": [
                "Cheng Chen",
                "Ji Zhang",
                "Jingkuan Song",
                "Lianli Gao"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3503161.3548054",
                "http://arxiv.org/abs/2311.14905v1",
                "http://arxiv.org/pdf/2311.14905v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14904v1",
            "title": "LLM-Assisted Code Cleaning For Training Accurate Code Generators",
            "updated": "2023-11-25T02:45:50Z",
            "published": "2023-11-25T02:45:50Z",
            "summary": "Natural language to code generation is an important application area of LLMs\nand has received wide attention from the community. The majority of relevant\nstudies have exclusively concentrated on increasing the quantity and functional\ncorrectness of training sets while disregarding other stylistic elements of\nprograms. More recently, data quality has garnered a lot of interest and\nmultiple works have showcased its importance for improving performance. In this\nwork, we investigate data quality for code and find that making the code more\nstructured and readable leads to improved code generation performance of the\nsystem. We build a novel data-cleaning pipeline that uses these principles to\ntransform existing programs by 1.) renaming variables, 2.) modularizing and\ndecomposing complex code into smaller helper sub-functions, and 3.) inserting\nnatural-language based plans via LLM based transformations. We evaluate our\napproach on two challenging algorithmic code generation benchmarks and find\nthat fine-tuning CodeLLaMa-7B on our transformed modularized programs improves\nthe performance by up to 30% compared to fine-tuning on the original dataset.\nAdditionally, we demonstrate improved performance from using a smaller amount\nof higher-quality data, finding that a model fine-tuned on the entire original\ndataset is outperformed by a model trained on 15% of our cleaned dataset. Even\nin comparison to closed-source models, our models outperform the much larger\nAlphaCoder models.",
            "author": [
                "Naman Jain",
                "Tianjun Zhang",
                "Wei-Lin Chiang",
                "Joseph E. Gonzalez",
                "Koushik Sen",
                "Ion Stoica"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14904v1",
                "http://arxiv.org/pdf/2311.14904v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14903v1",
            "title": "Code Generation Based Grading: Evaluating an Auto-grading Mechanism for\n  \"Explain-in-Plain-English\" Questions",
            "updated": "2023-11-25T02:45:00Z",
            "published": "2023-11-25T02:45:00Z",
            "summary": "Comprehending and elucidating the purpose of code is often cited as being a\nkey learning objective within introductory programming courses. To address this\nobjective ``Explain-in-Plain-English'' questions, in which students are shown a\nsegment of code and asked to provide an abstract description of the code's\npurpose, have been adopted. However, given EiPE questions require a natural\nlanguage response, they often require manual grading which is time-consuming\nfor course staff and delays feedback for students. With the advent of large\nlanguage models (LLMs) capable of generating code, responses to EiPE questions\ncan be used to generate code segments, the correctness of which can then be\neasily verified using test cases. We refer to this approach as \"Code Generation\nBased Grading\" (CGBG) and in this paper we explore its agreement with human\ngraders using EiPE responses from past exams in an introductory programming\ncourse taught in Python. Overall, we find that CGBG achieves moderate agreement\nwith human graders with the primary area of disagreement being its leniency\nwith respect to low-level and line-by-line descriptions of code.",
            "author": [
                "David H. Smith IV",
                "Craig Zilles"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14903v1",
                "http://arxiv.org/pdf/2311.14903v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14902v1",
            "title": "Parkinson Disease classification Using Contrastive Graph Cross-View\n  Learning with Multimodal Fusion of SPECT Images and Clinical Features",
            "updated": "2023-11-25T02:32:46Z",
            "published": "2023-11-25T02:32:46Z",
            "summary": "Parkinson's Disease (PD) is a neurodegenerative neurological disorder that\nimpacts movement and afflicts over 10 million people worldwide. Previous\nresearches have come up with deep learning models for predicting Parkinson's\ndisease primarily using medical images and didn't leverage the manifold\nstructure in the dataset. Our study introduces a multimodal approach with both\nimage and non-image features with a contrastive cross-view graph fusion for\nParkinson's disease classification. Specifically, we designed a multimodal\nco-attention module to integrate embeddings from two distinct graph views\nderived from low dimensional representation of images and clinical features,\nenabling the extraction of more stable and structured features from the\nmultiview data. Additionally, we have devised a simplified fusion method\nutilizing a contrastive loss for positive and negative pairs, to enhance the\nmodel's overall cross-view fusion learning capabilities. In our experiments,\nthe graph-view multimodal approach can achieve an accuracy rate of 91% and an\nAUC of 92.8% in five-fold cross-validation, and it also demonstrates superior\npredictive capabilities on non-image data as compared to methods that rely\nsolely on machine learning methods.",
            "author": [
                "Jun-En Ding",
                "Chien-Chin Hsu",
                "Feng Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14902v1",
                "http://arxiv.org/pdf/2311.14902v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16180v1",
            "title": "Aiming to Minimize Alcohol-Impaired Road Fatalities: Utilizing\n  Fairness-Aware and Domain Knowledge-Infused Artificial Intelligence",
            "updated": "2023-11-25T02:05:39Z",
            "published": "2023-11-25T02:05:39Z",
            "summary": "Approximately 30% of all traffic fatalities in the United States are\nattributed to alcohol-impaired driving. This means that, despite stringent laws\nagainst this offense in every state, the frequency of drunk driving accidents\nis alarming, resulting in approximately one person being killed every 45\nminutes. The process of charging individuals with Driving Under the Influence\n(DUI) is intricate and can sometimes be subjective, involving multiple stages\nsuch as observing the vehicle in motion, interacting with the driver, and\nconducting Standardized Field Sobriety Tests (SFSTs). Biases have been observed\nthrough racial profiling, leading to some groups and geographical areas facing\nfewer DUI tests, resulting in many actual DUI incidents going undetected,\nultimately leading to a higher number of fatalities. To tackle this issue, our\nresearch introduces an Artificial Intelligence-based predictor that is both\nfairness-aware and incorporates domain knowledge to analyze DUI-related\nfatalities in different geographic locations. Through this model, we gain\nintriguing insights into the interplay between various demographic groups,\nincluding age, race, and income. By utilizing the provided information to\nallocate policing resources in a more equitable and efficient manner, there is\npotential to reduce DUI-related fatalities and have a significant impact on\nroad safety.",
            "author": [
                "Tejas Venkateswaran",
                "Sheikh Rabiul Islam",
                "Md Golam Moula Mehedi Hasan",
                "Mohiuddin Ahmed"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16180v1",
                "http://arxiv.org/pdf/2311.16180v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14897v3",
            "title": "Towards Scalable 3D Anomaly Detection and Localization: A Benchmark via\n  3D Anomaly Synthesis and A Self-Supervised Learning Network",
            "updated": "2023-11-30T04:13:59Z",
            "published": "2023-11-25T01:45:09Z",
            "summary": "Recently, 3D anomaly detection, a crucial problem involving fine-grained\ngeometry discrimination, is getting more attention. However, the lack of\nabundant real 3D anomaly data limits the scalability of current models. To\nenable scalable anomaly data collection, we propose a 3D anomaly synthesis\npipeline to adapt existing large-scale 3Dmodels for 3D anomaly detection.\nSpecifically, we construct a synthetic dataset, i.e., Anomaly-ShapeNet, basedon\nShapeNet. Anomaly-ShapeNet consists of 1600 point cloud samples under 40\ncategories, which provides a rich and varied collection of data, enabling\nefficient training and enhancing adaptability to industrial scenarios.\nMeanwhile,to enable scalable representation learning for 3D anomaly\nlocalization, we propose a self-supervised method, i.e., Iterative Mask\nReconstruction Network (IMRNet). During training, we propose a geometry-aware\nsample module to preserve potentially anomalous local regions during point\ncloud down-sampling. Then, we randomly mask out point patches and sent the\nvisible patches to a transformer for reconstruction-based self-supervision.\nDuring testing, the point cloud repeatedly goes through the Mask Reconstruction\nNetwork, with each iteration's output becoming the next input. By merging and\ncontrasting the final reconstructed point cloud with the initial input, our\nmethod successfully locates anomalies. Experiments show that IMRNet outperforms\nprevious state-of-the-art methods, achieving 66.1% in I-AUC on Anomaly-ShapeNet\ndataset and 72.5% in I-AUC on Real3D-AD dataset. Our dataset will be released\nat https://github.com/Chopper-233/Anomaly-ShapeNet",
            "author": [
                "Wenqiao Li",
                "Xiaohao Xu",
                "Yao Gu",
                "Bozhong Zheng",
                "Shenghua Gao",
                "Yingna Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14897v3",
                "http://arxiv.org/pdf/2311.14897v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14886v1",
            "title": "A unified framework for learning with nonlinear model classes from\n  arbitrary linear samples",
            "updated": "2023-11-25T00:43:22Z",
            "published": "2023-11-25T00:43:22Z",
            "summary": "This work considers the fundamental problem of learning an unknown object\nfrom training data using a given model class. We introduce a unified framework\nthat allows for objects in arbitrary Hilbert spaces, general types of (random)\nlinear measurements as training data and general types of nonlinear model\nclasses. We establish a series of learning guarantees for this framework. These\nguarantees provide explicit relations between the amount of training data and\nproperties of the model class to ensure near-best generalization bounds. In\ndoing so, we also introduce and develop the key notion of the variation of a\nmodel class with respect to a distribution of sampling operators. To exhibit\nthe versatility of this framework, we show that it can accommodate many\ndifferent types of well-known problems of interest. We present examples such as\nmatrix sketching by random sampling, compressed sensing with isotropic vectors,\nactive learning in regression and compressed sensing with generative models. In\nall cases, we show how known results become straightforward corollaries of our\ngeneral learning guarantees. For compressed sensing with generative models, we\nalso present a number of generalizations and improvements of recent results. In\nsummary, our work not only introduces a unified way to study learning unknown\nobjects from general types of data, but also establishes a series of general\ntheoretical guarantees which consolidate and improve various known results.",
            "author": [
                "Ben Adcock",
                "Juan M. Cardenas",
                "Nick Dexter"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14886v1",
                "http://arxiv.org/pdf/2311.14886v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14885v1",
            "title": "Projected Off-Policy Q-Learning (POP-QL) for Stabilizing Offline\n  Reinforcement Learning",
            "updated": "2023-11-25T00:30:58Z",
            "published": "2023-11-25T00:30:58Z",
            "summary": "A key problem in off-policy Reinforcement Learning (RL) is the mismatch, or\ndistribution shift, between the dataset and the distribution over states and\nactions visited by the learned policy. This problem is exacerbated in the fully\noffline setting. The main approach to correct this shift has been through\nimportance sampling, which leads to high-variance gradients. Other approaches,\nsuch as conservatism or behavior-regularization, regularize the policy at the\ncost of performance. In this paper, we propose a new approach for stable\noff-policy Q-Learning. Our method, Projected Off-Policy Q-Learning (POP-QL), is\na novel actor-critic algorithm that simultaneously reweights off-policy samples\nand constrains the policy to prevent divergence and reduce value-approximation\nerror. In our experiments, POP-QL not only shows competitive performance on\nstandard benchmarks, but also out-performs competing methods in tasks where the\ndata-collection policy is significantly sub-optimal.",
            "author": [
                "Melrose Roderick",
                "Gaurav Manek",
                "Felix Berkenkamp",
                "J. Zico Kolter"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14885v1",
                "http://arxiv.org/pdf/2311.14885v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14875v2",
            "title": "Uncertainty Aware AI for 2D MRI Segmentation",
            "updated": "2023-11-28T11:27:27Z",
            "published": "2023-11-24T23:54:33Z",
            "summary": "Robust uncertainty estimations are necessary in safety-critical applications\nof Deep Learning. One such example is the semantic segmentation of medical\nimages, whilst deep-learning approaches have high performance in such tasks\nthey lack interpretability as they give no indication of their confidence when\nmaking classification decisions. Robust and interpretable segmentation is a\ncritical first stage in automatically screening for pathologies hence the\noptimal solution is one which can provide high accuracy but also capture the\nunderlying uncertainty. In this work, we present an uncertainty-aware\nsegmentation model, BA U-Net, for use on MRI data that incorporates Bayesian\nNeural Networks and Attention Mechanisms to provide accurate and interpretable\nsegmentations. We evaluated our model on the publicly available BraTS 2020\ndataset using F1 Score and Intersection Over Union (IoU) as evaluation metrics.",
            "author": [
                "Lohith Konathala"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14875v2",
                "http://arxiv.org/pdf/2311.14875v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14874v1",
            "title": "Advancing Fluid-Based Thermal Management Systems Design: Leveraging\n  Graph Neural Networks for Graph Regression and Efficient Enumeration\n  Reduction",
            "updated": "2023-11-24T23:51:53Z",
            "published": "2023-11-24T23:51:53Z",
            "summary": "In this research, we developed a graph-based framework to represent various\naspects of optimal thermal management system design, with the aim of rapidly\nand efficiently identifying optimal design candidates. Initially, the\ngraph-based framework is utilized to generate diverse thermal management system\narchitectures. The dynamics of these system architectures are modeled under\nvarious loading conditions, and an open-loop optimal controller is employed to\ndetermine each system's optimal performance. These modeled cases constitute the\ndataset, with the corresponding optimal performance values serving as the\nlabels for the data. In the subsequent step, a Graph Neural Network (GNN) model\nis trained on 30% of the labeled data to predict the systems' performance,\neffectively addressing a regression problem. Utilizing this trained model, we\nestimate the performance values for the remaining 70% of the data, which serves\nas the test set. In the third step, the predicted performance values are\nemployed to rank the test data, facilitating prioritized evaluation of the\ndesign scenarios. Specifically, a small subset of the test data with the\nhighest estimated ranks undergoes evaluation via the open-loop optimal control\nsolver. This targeted approach concentrates on evaluating higher-ranked designs\nidentified by the GNN, replacing the exhaustive search (enumeration-based) of\nall design cases. The results demonstrate a significant average reduction of\nover 92% in the number of system dynamic modeling and optimal control analyses\nrequired to identify optimal design scenarios.",
            "author": [
                "Saeid Bayat",
                "Nastaran Shahmansouri",
                "Satya RT Peddada",
                "Alex Tessier",
                "Adrian Butscher",
                "James T Allison"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14874v1",
                "http://arxiv.org/pdf/2311.14874v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.AI",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14871v1",
            "title": "Tracing Influence at Scale: A Contrastive Learning Approach to Linking\n  Public Comments and Regulator Responses",
            "updated": "2023-11-24T23:32:13Z",
            "published": "2023-11-24T23:32:13Z",
            "summary": "U.S. Federal Regulators receive over one million comment letters each year\nfrom businesses, interest groups, and members of the public, all advocating for\nchanges to proposed regulations. These comments are believed to have\nwide-ranging impacts on public policy. However, measuring the impact of\nspecific comments is challenging because regulators are required to respond to\ncomments but they do not have to specify which comments they are addressing. In\nthis paper, we propose a simple yet effective solution to this problem by using\nan iterative contrastive method to train a neural model aiming for matching\ntext from public comments to responses written by regulators. We demonstrate\nthat our proposal substantially outperforms a set of selected text-matching\nbaselines on a human-annotated test set. Furthermore, it delivers performance\ncomparable to the most advanced gigantic language model (i.e., GPT-4), and is\nmore cost-effective when handling comments and regulator responses matching in\nlarger scale.",
            "author": [
                "Linzi Xing",
                "Brad Hackinen",
                "Giuseppe Carenini"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14871v1",
                "http://arxiv.org/pdf/2311.14871v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14869v1",
            "title": "On the Complexity of Computing Sparse Equilibria and Lower Bounds for\n  No-Regret Learning in Games",
            "updated": "2023-11-24T23:26:37Z",
            "published": "2023-11-24T23:26:37Z",
            "summary": "Characterizing the performance of no-regret dynamics in multi-player games is\na foundational problem at the interface of online learning and game theory.\nRecent results have revealed that when all players adopt specific learning\nalgorithms, it is possible to improve exponentially over what is predicted by\nthe overly pessimistic no-regret framework in the traditional adversarial\nregime, thereby leading to faster convergence to the set of coarse correlated\nequilibria (CCE). Yet, despite considerable recent progress, the fundamental\ncomplexity barriers for learning in normal- and extensive-form games are poorly\nunderstood. In this paper, we make a step towards closing this gap by first\nshowing that -- barring major complexity breakthroughs -- any polynomial-time\nlearning algorithms in extensive-form games need at least $2^{\\log^{1/2 - o(1)}\n|\\mathcal{T}|}$ iterations for the average regret to reach below even an\nabsolute constant, where $|\\mathcal{T}|$ is the number of nodes in the game.\nThis establishes a superpolynomial separation between no-regret learning in\nnormal- and extensive-form games, as in the former class a logarithmic number\nof iterations suffices to achieve constant average regret. Furthermore, our\nresults imply that algorithms such as multiplicative weights update, as well as\nits \\emph{optimistic} counterpart, require at least $2^{(\\log \\log m)^{1/2 -\no(1)}}$ iterations to attain an $O(1)$-CCE in $m$-action normal-form games.\nThese are the first non-trivial -- and dimension-dependent -- lower bounds in\nthat setting for the most well-studied algorithms in the literature. From a\ntechnical standpoint, we follow a beautiful connection recently made by Foster,\nGolowich, and Kakade (ICML '23) between sparse CCE and Nash equilibria in the\ncontext of Markov games. Consequently, our lower bounds rule out\npolynomial-time algorithms well beyond the traditional online learning\nframework.",
            "author": [
                "Ioannis Anagnostides",
                "Alkis Kalavasis",
                "Tuomas Sandholm",
                "Manolis Zampetakis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14869v1",
                "http://arxiv.org/pdf/2311.14869v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16179v1",
            "title": "Next-gen traffic surveillance: AI-assisted mobile traffic violation\n  detection system",
            "updated": "2023-11-24T22:42:47Z",
            "published": "2023-11-24T22:42:47Z",
            "summary": "Road traffic accidents pose a significant global public health concern,\nleading to injuries, fatalities, and vehicle damage. Approximately 1,3 million\npeople lose their lives daily due to traffic accidents [World Health\nOrganization, 2022]. Addressing this issue requires accurate traffic law\nviolation detection systems to ensure adherence to regulations. The integration\nof Artificial Intelligence algorithms, leveraging machine learning and computer\nvision, has facilitated the development of precise traffic rule enforcement.\nThis paper illustrates how computer vision and machine learning enable the\ncreation of robust algorithms for detecting various traffic violations. Our\nmodel, capable of identifying six common traffic infractions, detects red light\nviolations, illegal use of breakdown lanes, violations of vehicle following\ndistance, breaches of marked crosswalk laws, illegal parking, and parking on\nmarked crosswalks. Utilizing online traffic footage and a self-mounted on-dash\ncamera, we apply the YOLOv5 algorithm's detection module to identify traffic\nagents such as cars, pedestrians, and traffic signs, and the strongSORT\nalgorithm for continuous interframe tracking. Six discrete algorithms analyze\nagents' behavior and trajectory to detect violations. Subsequently, an\nIdentification Module extracts vehicle ID information, such as the license\nplate, to generate violation notices sent to relevant authorities.",
            "author": [
                "Dila Dede",
                "Mehmet Ali Sars\u0131l",
                "Ata Shaker",
                "Olgu Alt\u0131nta\u015f",
                "Onur Ergen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16179v1",
                "http://arxiv.org/pdf/2311.16179v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14864v1",
            "title": "Effective Structural Encodings via Local Curvature Profiles",
            "updated": "2023-11-24T22:42:37Z",
            "published": "2023-11-24T22:42:37Z",
            "summary": "Structural and Positional Encodings can significantly improve the performance\nof Graph Neural Networks in downstream tasks. Recent literature has begun to\nsystematically investigate differences in the structural properties that these\napproaches encode, as well as performance trade-offs between them. However, the\nquestion of which structural properties yield the most effective encoding\nremains open. In this paper, we investigate this question from a geometric\nperspective. We propose a novel structural encoding based on discrete Ricci\ncurvature (Local Curvature Profiles, short LCP) and show that it significantly\noutperforms existing encoding approaches. We further show that combining local\nstructural encodings, such as LCP, with global positional encodings improves\ndownstream performance, suggesting that they capture complementary geometric\ninformation. Finally, we compare different encoding types with\n(curvature-based) rewiring techniques. Rewiring has recently received a surge\nof interest due to its ability to improve the performance of Graph Neural\nNetworks by mitigating over-smoothing and over-squashing effects. Our results\nsuggest that utilizing curvature information for structural encodings delivers\nsignificantly larger performance increases than rewiring.",
            "author": [
                "Lukas Fesser",
                "Melanie Weber"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14864v1",
                "http://arxiv.org/pdf/2311.14864v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14859v1",
            "title": "An Empirical Investigation into Benchmarking Model Multiplicity for\n  Trustworthy Machine Learning: A Case Study on Image Classification",
            "updated": "2023-11-24T22:30:38Z",
            "published": "2023-11-24T22:30:38Z",
            "summary": "Deep learning models have proven to be highly successful. Yet, their\nover-parameterization gives rise to model multiplicity, a phenomenon in which\nmultiple models achieve similar performance but exhibit distinct underlying\nbehaviours. This multiplicity presents a significant challenge and necessitates\nadditional specifications in model selection to prevent unexpected failures\nduring deployment. While prior studies have examined these concerns, they focus\non individual metrics in isolation, making it difficult to obtain a\ncomprehensive view of multiplicity in trustworthy machine learning. Our work\nstands out by offering a one-stop empirical benchmark of multiplicity across\nvarious dimensions of model design and its impact on a diverse set of\ntrustworthy metrics. In this work, we establish a consistent language for\nstudying model multiplicity by translating several trustworthy metrics into\naccuracy under appropriate interventions. We also develop a framework, which we\ncall multiplicity sheets, to benchmark multiplicity in various scenarios. We\ndemonstrate the advantages of our setup through a case study in image\nclassification and provide actionable insights into the impact and trends of\ndifferent hyperparameters on model multiplicity. Finally, we show that\nmultiplicity persists in deep learning models even after enforcing additional\nspecifications during model selection, highlighting the severity of\nover-parameterization. The concerns of under-specification thus remain, and we\nseek to promote a more comprehensive discussion of multiplicity in trustworthy\nmachine learning.",
            "author": [
                "Prakhar Ganesh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14859v1",
                "http://arxiv.org/pdf/2311.14859v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14856v1",
            "title": "Disruption Prediction in Fusion Devices through Feature Extraction and\n  Logistic Regression",
            "updated": "2023-11-24T22:22:44Z",
            "published": "2023-11-24T22:22:44Z",
            "summary": "This document describes an approach used in the Multi-Machine Disruption\nPrediction Challenge for Fusion Energy by ITU, a data science competition which\nran from September to November 2023, on the online platform Zindi. The\ncompetition involved data from three fusion devices - C-Mod, HL-2A, and J-TEXT\n- with most of the training data coming from the last two, and the test data\ncoming from the first one. Each device has multiple diagnostics and signals,\nand it turns out that a critical issue in this competition was to identify\nwhich signals, and especially which features from those signals, were most\nrelevant to achieve accurate predictions. The approach described here is based\non extracting features from signals, and then applying logistic regression on\ntop of those features. Each signal is treated as a separate predictor and, in\nthe end, a combination of such predictors achieved the first place on the\nleaderboard.",
            "author": [
                "Diogo R. Ferreira"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14856v1",
                "http://arxiv.org/pdf/2311.14856v1"
            ],
            "primary_category": "physics.plasm-ph",
            "category": [
                "physics.plasm-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.00805v1",
            "title": "Gender inference: can chatGPT outperform common commercial tools?",
            "updated": "2023-11-24T22:09:14Z",
            "published": "2023-11-24T22:09:14Z",
            "summary": "An increasing number of studies use gender information to understand\nphenomena such as gender bias, inequity in access and participation, or the\nimpact of the Covid pandemic response. Unfortunately, most datasets do not\ninclude self-reported gender information, making it necessary for researchers\nto infer gender from other information, such as names or names and country\ninformation. An important limitation of these tools is that they fail to\nappropriately capture the fact that gender exists on a non-binary scale,\nhowever, it remains important to evaluate and compare how well these tools\nperform in a variety of contexts. In this paper, we compare the performance of\na generative Artificial Intelligence (AI) tool ChatGPT with three commercially\navailable list-based and machine learning-based gender inference tools (Namsor,\nGender-API, and genderize.io) on a unique dataset. Specifically, we use a large\nOlympic athlete dataset and report how variations in the input (e.g., first\nname and first and last name, with and without country information) impact the\naccuracy of their predictions. We report results for the full set, as well as\nfor the subsets: medal versus non-medal winners, athletes from the largest\nEnglish-speaking countries, and athletes from East Asia. On these sets, we find\nthat Namsor is the best traditional commercially available tool. However,\nChatGPT performs at least as well as Namsor and often outperforms it,\nespecially for the female sample when country and/or last name information is\navailable. All tools perform better on medalists versus non-medalists and on\nnames from English-speaking countries. Although not designed for this purpose,\nChatGPT may be a cost-effective tool for gender prediction. In the future, it\nmight even be possible for ChatGPT or other large scale language models to\nbetter identify self-reported gender rather than report gender on a binary\nscale.",
            "author": [
                "Michelle Alexopoulos",
                "Kelly Lyons",
                "Kaushar Mahetaji",
                "Marcus Emmanuel Barnes",
                "Rogan Gutwillinger"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00805v1",
                "http://arxiv.org/pdf/2312.00805v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14851v1",
            "title": "Unified Medical Image Pre-training in Language-Guided Common Semantic\n  Space",
            "updated": "2023-11-24T22:01:12Z",
            "published": "2023-11-24T22:01:12Z",
            "summary": "Vision-Language Pre-training (VLP) has shown the merits of analysing medical\nimages, by leveraging the semantic congruence between medical images and their\ncorresponding reports. It efficiently learns visual representations, which in\nturn facilitates enhanced analysis and interpretation of intricate imaging\ndata. However, such observation is predominantly justified on single-modality\ndata (mostly 2D images like X-rays), adapting VLP to learning unified\nrepresentations for medical images in real scenario remains an open challenge.\nThis arises from medical images often encompass a variety of modalities,\nespecially modalities with different various number of dimensions (e.g., 3D\nimages like Computed Tomography). To overcome the aforementioned challenges, we\npropose an Unified Medical Image Pre-training framework, namely UniMedI, which\nutilizes diagnostic reports as common semantic space to create unified\nrepresentations for diverse modalities of medical images (especially for 2D and\n3D images). Under the text's guidance, we effectively uncover visual modality\ninformation, identifying the affected areas in 2D X-rays and slices containing\nlesion in sophisticated 3D CT scans, ultimately enhancing the consistency\nacross various medical imaging modalities. To demonstrate the effectiveness and\nversatility of UniMedI, we evaluate its performance on both 2D and 3D images\nacross 10 different datasets, covering a wide range of medical image tasks such\nas classification, segmentation, and retrieval. UniMedI has demonstrated\nsuperior performance in downstream tasks, showcasing its effectiveness in\nestablishing a universal medical visual representation.",
            "author": [
                "Xiaoxuan He",
                "Yifan Yang",
                "Xinyang Jiang",
                "Xufang Luo",
                "Haoji Hu",
                "Siyun Zhao",
                "Dongsheng Li",
                "Yuqing Yang",
                "Lili Qiu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14851v1",
                "http://arxiv.org/pdf/2311.14851v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16477v1",
            "title": "UniHPE: Towards Unified Human Pose Estimation via Contrastive Learning",
            "updated": "2023-11-24T21:55:34Z",
            "published": "2023-11-24T21:55:34Z",
            "summary": "In recent times, there has been a growing interest in developing effective\nperception techniques for combining information from multiple modalities. This\ninvolves aligning features obtained from diverse sources to enable more\nefficient training with larger datasets and constraints, as well as leveraging\nthe wealth of information contained in each modality. 2D and 3D Human Pose\nEstimation (HPE) are two critical perceptual tasks in computer vision, which\nhave numerous downstream applications, such as Action Recognition,\nHuman-Computer Interaction, Object tracking, etc. Yet, there are limited\ninstances where the correlation between Image and 2D/3D human pose has been\nclearly researched using a contrastive paradigm. In this paper, we propose\nUniHPE, a unified Human Pose Estimation pipeline, which aligns features from\nall three modalities, i.e., 2D human pose estimation, lifting-based and\nimage-based 3D human pose estimation, in the same pipeline. To align more than\ntwo modalities at the same time, we propose a novel singular value based\ncontrastive learning loss, which better aligns different modalities and further\nboosts the performance. In our evaluation, UniHPE achieves remarkable\nperformance metrics: MPJPE $50.5$mm on the Human3.6M dataset and PAMPJPE\n$51.6$mm on the 3DPW dataset. Our proposed method holds immense potential to\nadvance the field of computer vision and contribute to various applications.",
            "author": [
                "Zhongyu Jiang",
                "Wenhao Chai",
                "Lei Li",
                "Zhuoran Zhou",
                "Cheng-Yen Yang",
                "Jenq-Neng Hwang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16477v1",
                "http://arxiv.org/pdf/2311.16477v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17068v1",
            "title": "Deep convolutional encoder-decoder hierarchical neural networks for\n  conjugate heat transfer surrogate modeling",
            "updated": "2023-11-24T21:45:11Z",
            "published": "2023-11-24T21:45:11Z",
            "summary": "Conjugate heat transfer (CHT) models are vital for the design of many\nengineering systems. However, high-fidelity CHT models are computationally\nintensive, which limits their use in applications such as design optimization,\nwhere hundreds to thousands of model evaluations are required. In this work, we\ndevelop a modular deep convolutional encoder-decoder hierarchical (DeepEDH)\nneural network, a novel deep-learning-based surrogate modeling methodology for\ncomputationally intensive CHT models. Leveraging convective temperature\ndependencies, we propose a two-stage temperature prediction architecture that\ncouples velocity and temperature models. The proposed DeepEDH methodology is\ndemonstrated by modeling the pressure, velocity, and temperature fields for a\nliquid-cooled cold-plate-based battery thermal management system with variable\nchannel geometry. A computational model of the cold plate is developed and\nsolved using the finite element method (FEM), generating a dataset of 1,500\nsimulations. The FEM results are transformed and scaled from unstructured to\nstructured, image-like meshes to create training and test datasets. The DeepEDH\nmethodology's performance is examined in relation to data scaling, training\ndataset size, and network depth. Our performance analysis covers the impact of\nthe novel architecture, separate field models, output geometry masks,\nmulti-stage temperature models, and optimizations of the hyperparameters and\narchitecture. Furthermore, we quantify the influence of the CHT thermal\nboundary condition on surrogate model performance, highlighting improved\ntemperature model performance with higher heat fluxes. Compared to other deep\nlearning neural network surrogate models, such as U-Net and DenseED, the\nproposed DeepEDH methodology for CHT models exhibits up to a 65% enhancement in\nthe coefficient of determination ($R^{2}$).",
            "author": [
                "Takiah Ebbs-Picken",
                "David A. Romero",
                "Carlos M. Da Silva",
                "Cristina H. Amon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17068v1",
                "http://arxiv.org/pdf/2311.17068v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14838v1",
            "title": "OpusCleaner and OpusTrainer, open source toolkits for training Machine\n  Translation and Large language models",
            "updated": "2023-11-24T20:24:00Z",
            "published": "2023-11-24T20:24:00Z",
            "summary": "Developing high quality machine translation systems is a labour intensive,\nchallenging and confusing process for newcomers to the field. We present a pair\nof tools OpusCleaner and OpusTrainer that aim to simplify the process, reduce\nthe amount of work and lower the entry barrier for newcomers.\n  OpusCleaner is a data downloading, cleaning, and proprocessing toolkit. It is\ndesigned to allow researchers to quickly download, visualise and preprocess\nbilingual (or monolingual) data that comes from many different sources, each of\nthem with different quality, issues, and unique filtering/preprocessing\nrequirements.\n  OpusTrainer is a data scheduling and data augmenting tool aimed at building\nlarge scale, robust machine translation systems and large language models. It\nfeatures deterministic data mixing from many different sources, on-the-fly data\naugmentation and more.\n  Using these tools, we showcase how we can use it to create high quality\nmachine translation model robust to noisy user input; multilingual models and\nterminology aware models.",
            "author": [
                "Nikolay Bogoychev",
                "Jelmer van der Linde",
                "Graeme Nail",
                "Barry Haddow",
                "Jaume Zaragoza-Bernabeu",
                "Gema Ram\u00edrez-S\u00e1nchez",
                "Lukas Weymann",
                "Tudor Nicolae Mateiu",
                "Jind\u0159ich Helcl",
                "Mikko Aulamo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14838v1",
                "http://arxiv.org/pdf/2311.14838v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14837v2",
            "title": "Benchmarking Robustness of Text-Image Composed Retrieval",
            "updated": "2023-11-30T18:14:48Z",
            "published": "2023-11-24T20:16:38Z",
            "summary": "Text-image composed retrieval aims to retrieve the target image through the\ncomposed query, which is specified in the form of an image plus some text that\ndescribes desired modifications to the input image. It has recently attracted\nattention due to its ability to leverage both information-rich images and\nconcise language to precisely express the requirements for target images.\nHowever, the robustness of these approaches against real-world corruptions or\nfurther text understanding has never been studied. In this paper, we perform\nthe first robustness study and establish three new diversified benchmarks for\nsystematic analysis of text-image composed retrieval against natural\ncorruptions in both vision and text and further probe textural understanding.\nFor natural corruption analysis, we introduce two new large-scale benchmark\ndatasets, CIRR-C and FashionIQ-C for testing in open domain and fashion domain\nrespectively, both of which apply 15 visual corruptions and 7 textural\ncorruptions. For textural understanding analysis, we introduce a new diagnostic\ndataset CIRR-D by expanding the original raw data with synthetic data, which\ncontains modified text to better probe textual understanding ability including\nnumerical variation, attribute variation, object removal, background variation,\nand fine-grained evaluation. The code and benchmark datasets are available at\nhttps://github.com/SunTongtongtong/Benchmark-Robustness-Text-Image-Compose-Retrieval.",
            "author": [
                "Shitong Sun",
                "Jindong Gu",
                "Shaogang Gong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14837v2",
                "http://arxiv.org/pdf/2311.14837v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14828v1",
            "title": "Deep Latent Force Models: ODE-based Process Convolutions for Bayesian\n  Deep Learning",
            "updated": "2023-11-24T19:55:57Z",
            "published": "2023-11-24T19:55:57Z",
            "summary": "Effectively modeling phenomena present in highly nonlinear dynamical systems\nwhilst also accurately quantifying uncertainty is a challenging task, which\noften requires problem-specific techniques. We outline the deep latent force\nmodel (DLFM), a domain-agnostic approach to tackling this problem, which\nconsists of a deep Gaussian process architecture where the kernel at each layer\nis derived from an ordinary differential equation using the framework of\nprocess convolutions. Two distinct formulations of the DLFM are presented which\nutilise weight-space and variational inducing points-based Gaussian process\napproximations, both of which are amenable to doubly stochastic variational\ninference. We provide evidence that our model is capable of capturing highly\nnonlinear behaviour in real-world multivariate time series data. In addition,\nwe find that our approach achieves comparable performance to a number of other\nprobabilistic models on benchmark regression tasks. We also empirically assess\nthe negative impact of the inducing points framework on the extrapolation\ncapabilities of LFM-based models.",
            "author": [
                "Thomas Baldwin-McDonald",
                "Mauricio A. \u00c1lvarez"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14828v1",
                "http://arxiv.org/pdf/2311.14828v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14824v1",
            "title": "A Reusable AI-Enabled Defect Detection System for Railway Using\n  Ensembled CNN",
            "updated": "2023-11-24T19:45:55Z",
            "published": "2023-11-24T19:45:55Z",
            "summary": "Accurate Defect detection is crucial for ensuring the trustworthiness of\nintelligent railway systems. Current approaches rely on single deep-learning\nmodels, like CNNs, which employ a large amount of data to capture underlying\npatterns. Training a new defect classifier with limited samples often leads to\noverfitting and poor performance on unseen images. To address this, researchers\nhave advocated transfer learning and fine-tuning the pre-trained models.\nHowever, using a single backbone network in transfer learning still may cause\nbottleneck issues and inconsistent performance if it is not suitable for a\nspecific problem domain. To overcome these challenges, we propose a reusable\nAI-enabled defect detection approach. By combining ensemble learning with\ntransfer learning models (VGG-19, MobileNetV3, and ResNet-50), we improved the\nclassification accuracy and achieved consistent performance at a certain phase\nof training. Our empirical analysis demonstrates better and more consistent\nperformance compared to other state-of-the-art approaches. The consistency\nsubstantiates the reusability of the defect detection system for newly evolved\ndefected rail parts. Therefore we anticipate these findings to benefit further\nresearch and development of reusable AI-enabled solutions for railway systems.",
            "author": [
                "Rahatara Ferdousi",
                "Fedwa Laamarti",
                "Chunsheng Yang",
                "Abdulmotaleb El Saddik"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14824v1",
                "http://arxiv.org/pdf/2311.14824v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "68T45, 68T05",
                "I.2.10; I.5.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14823v1",
            "title": "Revisiting Quantum Algorithms for Linear Regressions: Quadratic Speedups\n  without Data-Dependent Parameters",
            "updated": "2023-11-24T19:41:28Z",
            "published": "2023-11-24T19:41:28Z",
            "summary": "Linear regression is one of the most fundamental linear algebra problems.\nGiven a dense matrix $A \\in \\mathbb{R}^{n \\times d}$ and a vector $b$, the goal\nis to find $x'$ such that\n  $ \\| Ax' - b \\|_2^2 \\leq (1+\\epsilon) \\min_{x} \\| A x - b \\|_2^2 $. The best\nclassical algorithm takes $O(nd) + \\mathrm{poly}(d/\\epsilon)$ time [Clarkson\nand Woodruff STOC 2013, Nelson and Nguyen FOCS 2013]. On the other hand,\nquantum linear regression algorithms can achieve exponential quantum speedups,\nas shown in [Wang Phys. Rev. A 96, 012335, Kerenidis and Prakash ITCS 2017,\nChakraborty, Gily{\\'e}n and Jeffery ICALP 2019]. However, the running times of\nthese algorithms depend on some quantum linear algebra-related parameters, such\nas $\\kappa(A)$, the condition number of $A$. In this work, we develop a quantum\nalgorithm that runs in $\\widetilde{O}(\\epsilon^{-1}\\sqrt{n}d^{1.5}) +\n\\mathrm{poly}(d/\\epsilon)$ time. It provides a quadratic quantum speedup in $n$\nover the classical lower bound without any dependence on data-dependent\nparameters. In addition, we also show our result can be generalized to multiple\nregression and ridge linear regression.",
            "author": [
                "Zhao Song",
                "Junze Yin",
                "Ruizhe Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14823v1",
                "http://arxiv.org/pdf/2311.14823v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.DS",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14816v1",
            "title": "Learning Arousal-Valence Representation from Categorical Emotion Labels\n  of Speech",
            "updated": "2023-11-24T19:23:37Z",
            "published": "2023-11-24T19:23:37Z",
            "summary": "Dimensional representations of speech emotions such as the arousal-valence\n(AV) representation provide a continuous and fine-grained description and\ncontrol than their categorical counterparts. They have wide applications in\ntasks such as dynamic emotion understanding and expressive text-to-speech\nsynthesis. Existing methods that predict the dimensional emotion representation\nfrom speech cast it as a supervised regression task. These methods face data\nscarcity issues, as dimensional annotations are much harder to acquire than\ncategorical labels. In this work, we propose to learn the AV representation\nfrom categorical emotion labels of speech. We start by learning a rich and\nemotion-relevant high-dimensional speech feature representation using\nself-supervised pre-training and emotion classification fine-tuning. This\nrepresentation is then mapped to the 2D AV space according to psychological\nfindings through anchored dimensionality reduction. Experiments show that our\nmethod achieves a Concordance Correlation Coefficient (CCC) performance\ncomparable to state-of-the-art supervised regression methods on IEMOCAP without\nleveraging ground-truth AV annotations during training. This validates our\nproposed approach on AV prediction. Furthermore, visualization of AV\npredictions on MEAD and EmoDB datasets shows the interpretability of the\nlearned AV representations.",
            "author": [
                "Enting Zhou",
                "You Zhang",
                "Zhiyao Duan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14816v1",
                "http://arxiv.org/pdf/2311.14816v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14812v1",
            "title": "Robust Joint Estimation of Galaxy Redshift and Spectral Templates using\n  Online Dictionary Learning",
            "updated": "2023-11-24T19:09:26Z",
            "published": "2023-11-24T19:09:26Z",
            "summary": "We present a novel approach to analyzing astronomical spectral survey data\nusing our non-linear extension of an online dictionary learning algorithm.\nCurrent and upcoming surveys such as SPHEREx will use spectral data to build a\n3D map of the universe by estimating the redshifts of millions of galaxies.\nExisting algorithms rely on hand-curated external templates and have limited\nperformance due to model mismatch error. Our algorithm addresses this\nlimitation by jointly estimating both the underlying spectral features in\ncommon across the entire dataset, as well as the redshift of each galaxy. Our\nonline approach scales well to large datasets since we only process a single\nspectrum in memory at a time. Our algorithm performs better than a\nstate-of-the-art existing algorithm when analyzing a mock SPHEREx dataset,\nachieving a NMAD standard deviation of 0.18% and a catastrophic error rate of\n0.40% when analyzing noiseless data. Our algorithm also performs well over a\nwide range of signal to noise ratios (SNR), delivering sub-percent NMAD and\ncatastrophic error above median SNR of 20. We released our algorithm publicly\nat github.com/HyperspectralDictionaryLearning/BryanEtAl2023 .",
            "author": [
                "Sean Bryan",
                "Ayan Barekzai",
                "Delondrae Carter",
                "Philip Mauskopf",
                "Julian Mena",
                "Danielle Rivera",
                "Abel S. Uriarte",
                "Pao-Yu Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14812v1",
                "http://arxiv.org/pdf/2311.14812v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "astro-ph.CO",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14671v1",
            "title": "SEGIC: Unleashing the Emergent Correspondence for In-Context\n  Segmentation",
            "updated": "2023-11-24T18:59:42Z",
            "published": "2023-11-24T18:59:42Z",
            "summary": "In-context segmentation aims at segmenting novel images using a few labeled\nexample images, termed as \"in-context examples\", exploring content similarities\nbetween examples and the target. The resulting models can be generalized\nseamlessly to novel segmentation tasks, significantly reducing the labeling and\ntraining costs compared with conventional pipelines. However, in-context\nsegmentation is more challenging than classic ones due to its meta-learning\nnature, requiring the model to learn segmentation rules conditioned on a few\nsamples, not just the segmentation. Unlike previous work with ad-hoc or\nnon-end-to-end designs, we propose SEGIC, an end-to-end segment-in-context\nframework built upon a single vision foundation model (VFM). In particular,\nSEGIC leverages the emergent correspondence within VFM to capture dense\nrelationships between target images and in-context samples. As such,\ninformation from in-context samples is then extracted into three types of\ninstructions, i.e. geometric, visual, and meta instructions, serving as\nexplicit conditions for the final mask prediction. SEGIC is a straightforward\nyet effective approach that yields state-of-the-art performance on one-shot\nsegmentation benchmarks. Notably, SEGIC can be easily generalized to diverse\ntasks, including video object segmentation and open-vocabulary segmentation.\nCode will be available at \\url{https://github.com/MengLcool/SEGIC}.",
            "author": [
                "Lingchen Meng",
                "Shiyi Lan",
                "Hengduo Li",
                "Jose M. Alvarez",
                "Zuxuan Wu",
                "Yu-Gang Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14671v1",
                "http://arxiv.org/pdf/2311.14671v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14670v1",
            "title": "Differentiable and accelerated spherical harmonic and Wigner transforms",
            "updated": "2023-11-24T18:59:04Z",
            "published": "2023-11-24T18:59:04Z",
            "summary": "Many areas of science and engineering encounter data defined on spherical\nmanifolds. Modelling and analysis of spherical data often necessitates\nspherical harmonic transforms, at high degrees, and increasingly requires\nefficient computation of gradients for machine learning or other differentiable\nprogramming tasks. We develop novel algorithmic structures for accelerated and\ndifferentiable computation of generalised Fourier transforms on the sphere\n$\\mathbb{S}^2$ and rotation group $\\text{SO}(3)$, i.e. spherical harmonic and\nWigner transforms, respectively. We present a recursive algorithm for the\ncalculation of Wigner $d$-functions that is both stable to high harmonic\ndegrees and extremely parallelisable. By tightly coupling this with separable\nspherical transforms, we obtain algorithms that exhibit an extremely\nparallelisable structure that is well-suited for the high throughput computing\nof modern hardware accelerators (e.g. GPUs). We also develop a hybrid automatic\nand manual differentiation approach so that gradients can be computed\nefficiently. Our algorithms are implemented within the JAX differentiable\nprogramming framework in the S2FFT software code. Numerous samplings of the\nsphere are supported, including equiangular and HEALPix sampling. Computational\nerrors are at the order of machine precision for spherical samplings that admit\na sampling theorem. When benchmarked against alternative C codes we observe up\nto a 400-fold acceleration. Furthermore, when distributing over multiple GPUs\nwe achieve very close to optimal linear scaling with increasing number of GPUs\ndue to the highly parallelised and balanced nature of our algorithms. Provided\naccess to sufficiently many GPUs our transforms thus exhibit an unprecedented\neffective linear time complexity.",
            "author": [
                "Matthew A. Price",
                "Jason D. McEwen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14670v1",
                "http://arxiv.org/pdf/2311.14670v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph",
                "astro-ph.IM",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14665v1",
            "title": "Understanding Self-Supervised Features for Learning Unsupervised\n  Instance Segmentation",
            "updated": "2023-11-24T18:55:53Z",
            "published": "2023-11-24T18:55:53Z",
            "summary": "Self-supervised learning (SSL) can be used to solve complex visual tasks\nwithout human labels. Self-supervised representations encode useful semantic\ninformation about images, and as a result, they have already been used for\ntasks such as unsupervised semantic segmentation. In this paper, we investigate\nself-supervised representations for instance segmentation without any manual\nannotations. We find that the features of different SSL methods vary in their\nlevel of instance-awareness. In particular, DINO features, which are known to\nbe excellent semantic descriptors, lack behind MAE features in their\nsensitivity for separating instances.",
            "author": [
                "Paul Engstler",
                "Luke Melas-Kyriazi",
                "Christian Rupprecht",
                "Iro Laina"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14665v1",
                "http://arxiv.org/pdf/2311.14665v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14659v1",
            "title": "The mass profiles of dwarf galaxies from Dark Energy Survey lensing",
            "updated": "2023-11-24T18:48:00Z",
            "published": "2023-11-24T18:48:00Z",
            "summary": "We present a novel approach to extracting dwarf galaxies from photometric\ndata to measure their average halo mass profile with weak lensing. We\ncharacterise their stellar mass and redshift distributions with a spectroscopic\ncalibration sample. Using the ${\\sim}5000\\mathrm{deg}^2$ multi-band photometry\nfrom Dark Energy Survey and redshifts from the Satellites Around Galactic\nAnalogs (SAGA) survey with an unsupervised machine learning method, we select a\nlow-mass galaxy sample spanning redshifts $z{<}0.3$ and divide it into three\nmass bins. From low to high median mass, the bins contain [146 420, 330 146,\n275 028] galaxies and have median stellar masses of $\\log_{10}(M_*/M_{\\odot})=\n[8.52^{+0.57}_{-0.76}, 9.02^{+0.50}_ {-0.64}, 9.49^{+0.50}_{-0.58}]$. We\nmeasure the stacked excess surface mass density profiles, $\\Delta\\Sigma(R)$, of\nthese galaxies using galaxy--galaxy lensing with a signal-to-noise of [14, 23,\n28]. Through a simulation-based forward-modelling approach, we fit the\nmeasurements to constrain the stellar-to-halo mass relation and find the median\nhalo mass of these samples to be $\\log_{10}(M_{\\rm halo}/M_{\\odot})$ =\n[$10.67\\substack{+0.2\\\\-0.4}$, $11.01\\substack{+0.14 \\\\\n-0.27}$,$11.40\\substack{+0.08\\\\-0.15}$]. The CDM profiles are consistent with\nNFW profiles over scales ${\\lesssim}0.15 \\rm{h}^{-1}$Mpc. We find that\n${\\sim}20$ per cent of the dwarf galaxy sample are satellites. This is the\nfirst measurement of the halo profiles and masses of such a comprehensive,\nlow-mass galaxy sample. The techniques presented here pave the way for\nextracting and analysing even lower-mass dwarf galaxies and for more finely\nsplitting galaxies by their properties with future photometric and\nspectroscopic survey data.",
            "author": [
                "Joseph Thornton",
                "Alexandra Amon",
                "Risa H. Wechsler",
                "Susmita Adhikari",
                "Yao-Yuan Mao",
                "Justin Myles",
                "Marla Geha",
                "Nitya Kallivayalil",
                "Erik Tollerud",
                "Benjamin Weiner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14659v1",
                "http://arxiv.org/pdf/2311.14659v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA",
                "astro-ph.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14658v1",
            "title": "Convergence Analysis for Learning Orthonormal Deep Linear Neural\n  Networks",
            "updated": "2023-11-24T18:46:54Z",
            "published": "2023-11-24T18:46:54Z",
            "summary": "Enforcing orthonormal or isometric property for the weight matrices has been\nshown to enhance the training of deep neural networks by mitigating gradient\nexploding/vanishing and increasing the robustness of the learned networks.\nHowever, despite its practical performance, the theoretical analysis of\northonormality in neural networks is still lacking; for example, how\northonormality affects the convergence of the training process. In this letter,\nwe aim to bridge this gap by providing convergence analysis for training\northonormal deep linear neural networks. Specifically, we show that Riemannian\ngradient descent with an appropriate initialization converges at a linear rate\nfor training orthonormal deep linear neural networks with a class of loss\nfunctions. Unlike existing works that enforce orthonormal weight matrices for\nall the layers, our approach excludes this requirement for one layer, which is\ncrucial to establish the convergence guarantee. Our results shed light on how\nincreasing the number of hidden layers can impact the convergence speed.\nExperimental results validate our theoretical analysis.",
            "author": [
                "Zhen Qin",
                "Xuwei Tan",
                "Zhihui Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14658v1",
                "http://arxiv.org/pdf/2311.14658v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14654v1",
            "title": "JetLOV: Enhancing Jet Tree Tagging through Neural Network Learning of\n  Optimal LundNet Variables",
            "updated": "2023-11-24T18:38:13Z",
            "published": "2023-11-24T18:38:13Z",
            "summary": "Machine learning has played a pivotal role in advancing physics, with deep\nlearning notably contributing to solving complex classification problems such\nas jet tagging in the field of jet physics. In this experiment, we aim to\nharness the full potential of neural networks while acknowledging that, at\ntimes, we may lose sight of the underlying physics governing these models.\nNevertheless, we demonstrate that we can achieve remarkable results obscuring\nphysics knowledge and relying completely on the model's outcome. We introduce\nJetLOV, a composite comprising two models: a straightforward multilayer\nperceptron (MLP) and the well-established LundNet. Our study reveals that we\ncan attain comparable jet tagging performance without relying on the\npre-computed LundNet variables. Instead, we allow the network to autonomously\nlearn an entirely new set of variables, devoid of a priori knowledge of the\nunderlying physics. These findings hold promise, particularly in addressing the\nissue of model dependence, which can be mitigated through generalization and\ntraining on diverse data sets.",
            "author": [
                "Mauricio A. Diaz",
                "Giorgio Cerro",
                "Jacan Chaplais",
                "Srinandan Dasmahapatra",
                "Stefano Moretti"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14654v1",
                "http://arxiv.org/pdf/2311.14654v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14653v1",
            "title": "Data-driven Prior Learning for Bayesian Optimisation",
            "updated": "2023-11-24T18:37:52Z",
            "published": "2023-11-24T18:37:52Z",
            "summary": "Transfer learning for Bayesian optimisation has generally assumed a strong\nsimilarity between optimisation tasks, with at least a subset having similar\noptimal inputs. This assumption can reduce computational costs, but it is\nviolated in a wide range of optimisation problems where transfer learning may\nnonetheless be useful. We replace this assumption with a weaker one only\nrequiring the shape of the optimisation landscape to be similar, and analyse\nthe recent method Prior Learning for Bayesian Optimisation - PLeBO - in this\nsetting. By learning priors for the hyperparameters of the Gaussian process\nsurrogate model we can better approximate the underlying function, especially\nfor few function evaluations. We validate the learned priors and compare to a\nbreadth of transfer learning approaches, using synthetic data and a recent air\npollution optimisation problem as benchmarks. We show that PLeBO and prior\ntransfer find good inputs in fewer evaluations.",
            "author": [
                "Sigrid Passano Hellan",
                "Christopher G. Lucas",
                "Nigel H. Goddard"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14653v1",
                "http://arxiv.org/pdf/2311.14653v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14652v1",
            "title": "One Pass Streaming Algorithm for Super Long Token Attention\n  Approximation in Sublinear Space",
            "updated": "2023-11-24T18:35:00Z",
            "published": "2023-11-24T18:35:00Z",
            "summary": "Deploying Large Language Models (LLMs) in streaming applications that involve\nlong contexts, particularly for extended dialogues and text analysis, is of\nparamount importance but presents two significant challenges. Firstly, the\nmemory consumption is substantial during the decoding phase due to the caching\nof Key and Value states (KV) of previous tokens. Secondly, attention\ncomputation is time-consuming with a time complexity of $O(n^2)$ for the\ngeneration of each token. In recent OpenAI DevDay (Nov 6, 2023), OpenAI\nreleased a new model that is able to support a 128K-long document, in our\npaper, we focus on the memory-efficient issue when context length $n$ is much\ngreater than 128K ($n \\gg 2^d$). Considering a single-layer self-attention with\nQuery, Key, and Value matrices $Q, K, V \\in \\mathbb{R}^{n \\times d}$, the\npolynomial method approximates the attention output $T \\in \\mathbb{R}^{n \\times\nd}$. It accomplishes this by constructing $U_1, U_2 \\in \\mathbb{R}^{n \\times\nt}$ to expedite attention ${\\sf Attn}(Q, K, V)$ computation within $n^{1+o(1)}$\ntime executions. Despite this, storing the Key and Value matrices $K, V \\in\n\\mathbb{R}^{n \\times d}$ still necessitates $O( n d)$ space, leading to\nsignificant memory usage. In response to these challenges, we introduce a new\nalgorithm that only reads one pass of the data in streaming fashion. This\nmethod employs sublinear space $o(n)$ to store three sketch matrices,\nalleviating the need for exact $K, V$ storage. Notably, our algorithm exhibits\nexceptional memory-efficient performance with super-long tokens. As the token\nlength $n$ increases, our error guarantee diminishes while the memory usage\nremains nearly constant. This unique attribute underscores the potential of our\ntechnique in efficiently handling LLMs in streaming applications.",
            "author": [
                "Raghav Addanki",
                "Chenyang Li",
                "Zhao Song",
                "Chiwun Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14652v1",
                "http://arxiv.org/pdf/2311.14652v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14649v1",
            "title": "Learning in Deep Factor Graphs with Gaussian Belief Propagation",
            "updated": "2023-11-24T18:31:11Z",
            "published": "2023-11-24T18:31:11Z",
            "summary": "We propose an approach to do learning in Gaussian factor graphs. We treat all\nrelevant quantities (inputs, outputs, parameters, latents) as random variables\nin a graphical model, and view both training and prediction as inference\nproblems with different observed nodes. Our experiments show that these\nproblems can be efficiently solved with belief propagation (BP), whose updates\nare inherently local, presenting exciting opportunities for distributed and\nasynchronous training. Our approach can be scaled to deep networks and provides\na natural means to do continual learning: use the BP-estimated parameter\nmarginals of the current task as parameter priors for the next. On a video\ndenoising task we demonstrate the benefit of learnable parameters over a\nclassical factor graph approach and we show encouraging performance of deep\nfactor graphs for continual image classification on MNIST.",
            "author": [
                "Seth Nabarro",
                "Mark van der Wilk",
                "Andrew J Davison"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14649v1",
                "http://arxiv.org/pdf/2311.14649v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14648v2",
            "title": "Calibrated Language Models Must Hallucinate",
            "updated": "2023-12-03T15:28:02Z",
            "published": "2023-11-24T18:29:50Z",
            "summary": "Recent language models generate false but plausible-sounding text with\nsurprising frequency. Such \"hallucinations\" are an obstacle to the usability of\nlanguage-based AI systems and can harm people who rely upon their outputs. This\nwork shows shows that there is an inherent statistical lower-bound on the rate\nthat pretrained language models hallucinate certain types of facts, having\nnothing to do with the transformer LM architecture or data quality. For\n\"arbitrary\" facts whose veracity cannot be determined from the training data,\nwe show that hallucinations must occur at a certain rate for language models\nthat satisfy a statistical calibration condition appropriate for generative\nlanguage models. Specifically, if the maximum probability of any fact is\nbounded, we show that the probability of generating a hallucination is close to\nthe fraction of facts that occur exactly once in the training data (a\n\"Good-Turing\" estimate), even assuming ideal training data without errors.\n  One conclusion is that models pretrained to be sufficiently good predictors\n(i.e., calibrated) may require post-training to mitigate hallucinations on the\ntype of arbitrary facts that tend to appear once in the training set. However,\nour analysis also suggests that there is no statistical reason that pretraining\nwill lead to hallucination on facts that tend to appear more than once in the\ntraining data (like references to publications such as articles and books,\nwhose hallucinations have been particularly notable and problematic) or on\nsystematic facts (like arithmetic calculations). Therefore, different\narchitectures and learning algorithms may mitigate these latter types of\nhallucinations.",
            "author": [
                "Adam Tauman Kalai",
                "Santosh S. Vempala"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14648v2",
                "http://arxiv.org/pdf/2311.14648v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14647v1",
            "title": "Evidence for $B^{+}\\to K^{+}\u03bd\\bar\u03bd$ Decays",
            "updated": "2023-11-24T18:29:43Z",
            "published": "2023-11-24T18:29:43Z",
            "summary": "We search for the rare decay $B^{+}\\rightarrow K^{+}\\nu\\bar{\\nu}$ in a $362\\\n\\rm{fb}^{-1}$ sample of electron-positron collisions at the $\\Upsilon(4S)$\nresonance collected with the Belle II detector at the SuperKEKB collider. We\nuse the inclusive properties of the accompanying $B$ meson in $\\Upsilon(4S) \\to\nB\\kern 0.18em\\overline{\\kern -0.18em B}{}$ events to suppress background from\nother decays of the signal $B$ candidate and light-quark pair production. We\nvalidate the measurement with an auxiliary analysis based on a conventional\nhadronic reconstruction of the accompanying $B$ meson. For background\nsuppression, we exploit distinct signal features using machine learning methods\ntuned with simulated data. The signal-reconstruction efficiency and background\nsuppression are validated through various control channels. The branching\nfraction is extracted in a maximum likelihood fit. Our inclusive and hadronic\nanalyses yield consistent results for the $B^{+}\\rightarrow K^{+}\\nu\\bar{\\nu}$\nbranching fraction of $\\left[2.7\\pm 0.5(\\mathrm{stat})\\pm\n0.5(\\mathrm{syst})\\right] \\times 10^{-5}$ and\n$\\left[1.1^{+0.9}_{-0.8}(\\mathrm{stat}){}^{+0.8}_{-0.5}(\\mathrm{syst})\\right]\n\\times 10^{-5}$, respectively. Combining the results, we determine the\nbranching fraction of the decay $B^{+}\\rightarrow K^{+}\\nu\\bar{\\nu}$ to be\n$\\left[2.3 \\pm 0.5(\\mathrm{stat})^{+0.5}_{-0.4}(\\mathrm{syst})\\right]\\times\n10^{-5}$, providing the first evidence for this decay at $3.5$ standard\ndeviations. The combined result is $2.7$ standard deviations above the standard\nmodel expectation.",
            "author": [
                "Belle II Collaboration",
                "I. Adachi",
                "K. Adamczyk",
                "L. Aggarwal",
                "H. Ahmed",
                "H. Aihara",
                "N. Akopov",
                "A. Aloisio",
                "N. Anh Ky",
                "D. M. Asner",
                "H. Atmacan",
                "T. Aushev",
                "V. Aushev",
                "M. Aversano",
                "V. Babu",
                "H. Bae",
                "S. Bahinipati",
                "P. Bambade",
                "Sw. Banerjee",
                "S. Bansal",
                "M. Barrett",
                "J. Baudot",
                "M. Bauer",
                "A. Baur",
                "A. Beaubien",
                "F. Becherer",
                "J. Becker",
                "P. K. Behera",
                "J. V. Bennett",
                "F. U. Bernlochner",
                "V. Bertacchi",
                "M. Bertemes",
                "E. Bertholet",
                "M. Bessner",
                "S. Bettarini",
                "B. Bhuyan",
                "F. Bianchi",
                "T. Bilka",
                "D. Biswas",
                "A. Bobrov",
                "D. Bodrov",
                "A. Bolz",
                "J. Borah",
                "A. Bozek",
                "M. Bra\u010dko",
                "P. Branchini",
                "R. A. Briere",
                "T. E. Browder",
                "A. Budano",
                "S. Bussino",
                "M. Campajola",
                "L. Cao",
                "G. Casarosa",
                "C. Cecchi",
                "J. Cerasoli",
                "M. -C. Chang",
                "P. Chang",
                "R. Cheaib",
                "P. Cheema",
                "V. Chekelian",
                "C. Chen",
                "B. G. Cheon",
                "K. Chilikin",
                "K. Chirapatpimol",
                "H. -E. Cho",
                "K. Cho",
                "S. -J. Cho",
                "S. -K. Choi",
                "S. Choudhury",
                "J. Cochran",
                "L. Corona",
                "L. M. Cremaldi",
                "S. Cunliffe",
                "S. Das",
                "F. Dattola",
                "E. De La Cruz-Burelo",
                "S. A. De La Motte",
                "G. De Nardo",
                "M. De Nuccio",
                "G. De Pietro",
                "R. de Sangro",
                "M. Destefanis",
                "S. Dey",
                "A. De Yta-Hernandez",
                "R. Dhamija",
                "A. Di Canto",
                "F. Di Capua",
                "J. Dingfelder",
                "Z. Dole\u017eal",
                "I. Dom\u00ednguez Jim\u00e9nez",
                "T. V. Dong",
                "M. Dorigo",
                "K. Dort",
                "D. Dossett",
                "S. Dreyer",
                "S. Dubey",
                "G. Dujany",
                "P. Ecker",
                "M. Eliachevitch",
                "D. Epifanov",
                "Y. Fan",
                "P. Feichtinger",
                "T. Ferber",
                "D. Ferlewicz",
                "T. Fillinger",
                "C. Finck",
                "G. Finocchiaro",
                "A. Fodor",
                "F. Forti",
                "B. G. Fulsom",
                "A. Gabrielli",
                "E. Ganiev",
                "M. Garcia-Hernandez",
                "R. Garg",
                "A. Garmash",
                "G. Gaudino",
                "V. Gaur",
                "A. Gaz",
                "A. Gellrich",
                "G. Ghevondyan",
                "D. Ghosh",
                "H. Ghumaryan",
                "G. Giakoustidis",
                "R. Giordano",
                "A. Giri",
                "A. Glazov",
                "B. Gobbo",
                "R. Godang",
                "O. Gogota",
                "P. Goldenzweig",
                "P. Grace",
                "W. Gradl",
                "T. Grammatico",
                "S. Granderath",
                "E. Graziani",
                "D. Greenwald",
                "Z. Gruberov\u00e1",
                "T. Gu",
                "Y. Guan",
                "K. Gudkova",
                "S. Halder",
                "Y. Han",
                "T. Hara",
                "K. Hayasaka",
                "H. Hayashii",
                "S. Hazra",
                "C. Hearty",
                "M. T. Hedges",
                "A. Heidelbach",
                "I. Heredia de la Cruz",
                "M. Hern\u00e1ndez Villanueva",
                "A. Hershenhorn",
                "T. Higuchi",
                "E. C. Hill",
                "M. Hoek",
                "M. Hohmann",
                "P. Horak",
                "C. -L. Hsu",
                "T. Humair",
                "T. Iijima",
                "K. Inami",
                "G. Inguglia",
                "N. Ipsita",
                "A. Ishikawa",
                "S. Ito",
                "R. Itoh",
                "M. Iwasaki",
                "P. Jackson",
                "W. W. Jacobs",
                "D. E. Jaffe",
                "E. -J. Jang",
                "Q. P. Ji",
                "S. Jia",
                "Y. Jin",
                "A. Johnson",
                "K. K. Joo",
                "H. Junkerkalefeld",
                "H. Kakuno",
                "M. Kaleta",
                "D. Kalita",
                "A. B. Kaliyar",
                "J. Kandra",
                "K. H. Kang",
                "S. Kang",
                "G. Karyan",
                "T. Kawasaki",
                "F. Keil",
                "C. Ketter",
                "C. Kiesling",
                "C. -H. Kim",
                "D. Y. Kim",
                "K. -H. Kim",
                "Y. -K. Kim",
                "H. Kindo",
                "K. Kinoshita",
                "P. Kody\u0161",
                "T. Koga",
                "S. Kohani",
                "K. Kojima",
                "T. Konno",
                "A. Korobov",
                "S. Korpar",
                "E. Kovalenko",
                "R. Kowalewski",
                "T. M. G. Kraetzschmar",
                "P. Kri\u017ean",
                "P. Krokovny",
                "Y. Kulii",
                "T. Kuhr",
                "J. Kumar",
                "M. Kumar",
                "R. Kumar",
                "K. Kumara",
                "T. Kunigo",
                "A. Kuzmin",
                "Y. -J. Kwon",
                "S. Lacaprara",
                "Y. -T. Lai",
                "T. Lam",
                "J. S. Lange",
                "M. Laurenza",
                "K. Lautenbach",
                "R. Leboucher",
                "F. R. Le Diberder",
                "P. Leitl",
                "D. Levit",
                "P. M. Lewis",
                "C. Li",
                "L. K. Li",
                "J. Libby",
                "Q. Y. Liu",
                "Z. Q. Liu",
                "D. Liventsev",
                "S. Longo",
                "A. Lozar",
                "T. Lueck",
                "T. Luo",
                "C. Lyu",
                "Y. Ma",
                "M. Maggiora",
                "S. P. Maharana",
                "R. Maiti",
                "G. Mancinelli",
                "R. Manfredi",
                "E. Manoni",
                "A. C. Manthei",
                "M. Mantovano",
                "D. Marcantonio",
                "S. Marcello",
                "C. Marinas",
                "L. Martel",
                "C. Martellini",
                "A. Martini",
                "T. Martinov",
                "L. Massaccesi",
                "M. Masuda",
                "T. Matsuda",
                "K. Matsuoka",
                "D. Matvienko",
                "S. K. Maurya",
                "J. A. McKenna",
                "R. Mehta",
                "F. Meier",
                "M. Merola",
                "F. Metzner",
                "M. Milesi",
                "C. Miller",
                "M. Mirra",
                "K. Miyabayashi",
                "H. Miyake",
                "R. Mizuk",
                "G. B. Mohanty",
                "N. Molina-Gonzalez",
                "S. Mondal",
                "S. Moneta",
                "H. -G. Moser",
                "M. Mrvar",
                "R. Mussa",
                "I. Nakamura",
                "K. R. Nakamura",
                "M. Nakao",
                "H. Nakazawa",
                "Y. Nakazawa",
                "A. Narimani Charan",
                "M. Naruki",
                "Z. Natkaniec",
                "A. Natochii",
                "L. Nayak",
                "M. Nayak",
                "G. Nazaryan",
                "C. Niebuhr",
                "N. K. Nisar",
                "S. Nishida",
                "S. Ogawa",
                "Y. Onishchuk",
                "H. Ono",
                "Y. Onuki",
                "P. Oskin",
                "F. Otani",
                "P. Pakhlov",
                "G. Pakhlova",
                "A. Paladino",
                "A. Panta",
                "E. Paoloni",
                "S. Pardi",
                "K. Parham",
                "H. Park",
                "S. -H. Park",
                "B. Paschen",
                "A. Passeri",
                "S. Patra",
                "S. Paul",
                "T. K. Pedlar",
                "R. Peschke",
                "R. Pestotnik",
                "F. Pham",
                "M. Piccolo",
                "L. E. Piilonen",
                "P. L. M. Podesta-Lerma",
                "T. Podobnik",
                "S. Pokharel",
                "L. Polat",
                "C. Praz",
                "S. Prell",
                "E. Prencipe",
                "M. T. Prim",
                "M. V. Purohit",
                "H. Purwar",
                "N. Rad",
                "P. Rados",
                "G. Raeuber",
                "S. Raiz",
                "N. Rauls",
                "M. Reif",
                "S. Reiter",
                "M. Remnev",
                "I. Ripp-Baudot",
                "G. Rizzo",
                "L. B. Rizzuto",
                "S. H. Robertson",
                "M. Roehrken",
                "J. M. Roney",
                "A. Rostomyan",
                "N. Rout",
                "G. Russo",
                "Y. Sakai",
                "D. A. Sanders",
                "S. Sandilya",
                "A. Sangal",
                "L. Santelj",
                "Y. Sato",
                "V. Savinov",
                "B. Scavino",
                "C. Schmitt",
                "M. Schnepf",
                "C. Schwanda",
                "A. J. Schwartz",
                "Y. Seino",
                "A. Selce",
                "K. Senyo",
                "J. Serrano",
                "M. E. Sevior",
                "C. Sfienti",
                "W. Shan",
                "C. Sharma",
                "X. D. Shi",
                "T. Shillington",
                "T. Shimasaki",
                "J. -G. Shiu",
                "D. Shtol",
                "A. Sibidanov",
                "F. Simon",
                "J. B. Singh",
                "J. Skorupa",
                "R. J. Sobie",
                "M. Sobotzik",
                "A. Soffer",
                "A. Sokolov",
                "E. Solovieva",
                "S. Spataro",
                "B. Spruck",
                "M. Stari\u010d",
                "P. Stavroulakis",
                "S. Stefkova",
                "Z. S. Stottler",
                "R. Stroili",
                "J. Strube",
                "M. Sumihama",
                "K. Sumisawa",
                "W. Sutcliffe",
                "H. Svidras",
                "M. Takahashi",
                "M. Takizawa",
                "U. Tamponi",
                "S. Tanaka",
                "K. Tanida",
                "F. Tenchini",
                "A. Thaller",
                "O. Tittel",
                "R. Tiwary",
                "D. Tonelli",
                "E. Torassa",
                "N. Toutounji",
                "K. Trabelsi",
                "I. Tsaklidis",
                "M. Uchida",
                "I. Ueda",
                "Y. Uematsu",
                "T. Uglov",
                "K. Unger",
                "Y. Unno",
                "K. Uno",
                "S. Uno",
                "P. Urquijo",
                "Y. Ushiroda",
                "S. E. Vahsen",
                "R. van Tonder",
                "G. S. Varner",
                "K. E. Varvell",
                "M. Veronesi",
                "A. Vinokurova",
                "V. S. Vismaya",
                "L. Vitale",
                "R. Volpe",
                "B. Wach",
                "M. Wakai",
                "H. M. Wakeling",
                "S. Wallner",
                "E. Wang",
                "M. -Z. Wang",
                "X. L. Wang",
                "Z. Wang",
                "A. Warburton",
                "M. Watanabe",
                "S. Watanuki",
                "M. Welsch",
                "C. Wessel",
                "E. Won",
                "X. P. Xu",
                "B. D. Yabsley",
                "S. Yamada",
                "W. Yan",
                "S. B. Yang",
                "J. Yelton",
                "J. H. Yin",
                "Y. M. Yook",
                "K. Yoshihara",
                "C. Z. Yuan",
                "Y. Yusa",
                "L. Zani",
                "V. Zhilich",
                "J. S. Zhou",
                "Q. D. Zhou",
                "X. Y. Zhou",
                "V. I. Zhukova"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14647v1",
                "http://arxiv.org/pdf/2311.14647v1"
            ],
            "primary_category": "hep-ex",
            "category": [
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14646v2",
            "title": "More is Better in Modern Machine Learning: when Infinite\n  Overparameterization is Optimal and Overfitting is Obligatory",
            "updated": "2023-11-27T23:06:27Z",
            "published": "2023-11-24T18:27:41Z",
            "summary": "In our era of enormous neural networks, empirical progress has been driven by\nthe philosophy that more is better. Recent deep learning practice has found\nrepeatedly that larger model size, more data, and more computation (resulting\nin lower training loss) improves performance. In this paper, we give\ntheoretical backing to these empirical observations by showing that these three\nproperties hold in random feature (RF) regression, a class of models equivalent\nto shallow networks with only the last layer trained.\n  Concretely, we first show that the test risk of RF regression decreases\nmonotonically with both the number of features and the number of samples,\nprovided the ridge penalty is tuned optimally. In particular, this implies that\ninfinite width RF architectures are preferable to those of any finite width. We\nthen proceed to demonstrate that, for a large class of tasks characterized by\npowerlaw eigenstructure, training to near-zero training loss is obligatory:\nnear-optimal performance can only be achieved when the training error is much\nsmaller than the test error. Grounding our theory in real-world data, we find\nempirically that standard computer vision tasks with convolutional neural\ntangent kernels clearly fall into this class. Taken together, our results tell\na simple, testable story of the benefits of overparameterization, overfitting,\nand more data in random feature models.",
            "author": [
                "James B. Simon",
                "Dhruva Karkada",
                "Nikhil Ghosh",
                "Mikhail Belkin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14646v2",
                "http://arxiv.org/pdf/2311.14646v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14645v1",
            "title": "A General Framework for User-Guided Bayesian Optimization",
            "updated": "2023-11-24T18:27:26Z",
            "published": "2023-11-24T18:27:26Z",
            "summary": "The optimization of expensive-to-evaluate black-box functions is prevalent in\nvarious scientific disciplines. Bayesian optimization is an automatic, general\nand sample-efficient method to solve these problems with minimal knowledge of\nthe underlying function dynamics. However, the ability of Bayesian optimization\nto incorporate prior knowledge or beliefs about the function at hand in order\nto accelerate the optimization is limited, which reduces its appeal for\nknowledgeable practitioners with tight budgets. To allow domain experts to\ncustomize the optimization routine, we propose ColaBO, the first\nBayesian-principled framework for incorporating prior beliefs beyond the\ntypical kernel structure, such as the likely location of the optimizer or the\noptimal value. The generality of ColaBO makes it applicable across different\nMonte Carlo acquisition functions and types of user beliefs. We empirically\ndemonstrate ColaBO's ability to substantially accelerate optimization when the\nprior information is accurate, and to retain approximately default performance\nwhen it is misleading.",
            "author": [
                "Carl Hvarfner",
                "Frank Hutter",
                "Luigi Nardi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14645v1",
                "http://arxiv.org/pdf/2311.14645v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14633v1",
            "title": "One Strike, You're Out: Detecting Markush Structures in Low\n  Signal-to-Noise Ratio Images",
            "updated": "2023-11-24T18:02:14Z",
            "published": "2023-11-24T18:02:14Z",
            "summary": "Modern research increasingly relies on automated methods to assist\nresearchers. An example of this is Optical Chemical Structure Recognition\n(OCSR), which aids chemists in retrieving information about chemicals from\nlarge amounts of documents. Markush structures are chemical structures that\ncannot be parsed correctly by OCSR and cause errors. The focus of this research\nwas to propose and test a novel method for classifying Markush structures.\nWithin this method, a comparison was made between fixed-feature extraction and\nend-to-end learning (CNN). The end-to-end method performed significantly better\nthan the fixed-feature method, achieving 0.928 (0.035 SD) Macro F1 compared to\nthe fixed-feature method's 0.701 (0.052 SD). Because of the nature of the\nexperiment, these figures are a lower bound and can be improved further. These\nresults suggest that Markush structures can be filtered out effectively and\naccurately using the proposed method. When implemented into OCSR pipelines,\nthis method can improve their performance and use to other researchers.",
            "author": [
                "Thomas Jurriaans",
                "Kinga Szarkowska",
                "Eric Nalisnick",
                "Markus Schwoerer",
                "Camilo Thorne",
                "Saber Akhondi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14633v1",
                "http://arxiv.org/pdf/2311.14633v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14632v1",
            "title": "Differentially Private SGD Without Clipping Bias: An Error-Feedback\n  Approach",
            "updated": "2023-11-24T17:56:44Z",
            "published": "2023-11-24T17:56:44Z",
            "summary": "Differentially Private Stochastic Gradient Descent with gradient clipping\n(DPSGD-GC) is a powerful tool for training deep learning models using sensitive\ndata, providing both a solid theoretical privacy guarantee and high efficiency.\nHowever, using DPSGD-GC to ensure Differential Privacy (DP) comes at the cost\nof model performance degradation due to DP noise injection and gradient\nclipping. Existing research has extensively analyzed the theoretical\nconvergence of DPSGD-GC, and has shown that it only converges when using large\nclipping thresholds that are dependent on problem-specific parameters.\nUnfortunately, these parameters are often unknown in practice, making it hard\nto choose the optimal clipping threshold. Therefore, in practice, DPSGD-GC\nsuffers from degraded performance due to the {\\it constant} bias introduced by\nthe clipping.\n  In our work, we propose a new error-feedback (EF) DP algorithm as an\nalternative to DPSGD-GC, which not only offers a diminishing utility bound\nwithout inducing a constant clipping bias, but more importantly, it allows for\nan arbitrary choice of clipping threshold that is independent of the problem.\nWe establish an algorithm-specific DP analysis for our proposed algorithm,\nproviding privacy guarantees based on R{\\'e}nyi DP. Additionally, we\ndemonstrate that under mild conditions, our algorithm can achieve nearly the\nsame utility bound as DPSGD without gradient clipping. Our empirical results on\nCifar-10/100 and E2E datasets, show that the proposed algorithm achieves higher\naccuracies than DPSGD while maintaining the same level of DP guarantee.",
            "author": [
                "Xinwei Zhang",
                "Zhiqi Bu",
                "Zhiwei Steven Wu",
                "Mingyi Hong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14632v1",
                "http://arxiv.org/pdf/2311.14632v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14631v2",
            "title": "CatVersion: Concatenating Embeddings for Diffusion-Based Text-to-Image\n  Personalization",
            "updated": "2023-11-30T14:42:07Z",
            "published": "2023-11-24T17:55:10Z",
            "summary": "We propose CatVersion, an inversion-based method that learns the personalized\nconcept through a handful of examples. Subsequently, users can utilize text\nprompts to generate images that embody the personalized concept, thereby\nachieving text-to-image personalization. In contrast to existing approaches\nthat emphasize word embedding learning or parameter fine-tuning for the\ndiffusion model, which potentially causes concept dilution or overfitting, our\nmethod concatenates embeddings on the feature-dense space of the text encoder\nin the diffusion model to learn the gap between the personalized concept and\nits base class, aiming to maximize the preservation of prior knowledge in\ndiffusion models while restoring the personalized concepts. To this end, we\nfirst dissect the text encoder's integration in the image generation process to\nidentify the feature-dense space of the encoder. Afterward, we concatenate\nembeddings on the Keys and Values in this space to learn the gap between the\npersonalized concept and its base class. In this way, the concatenated\nembeddings ultimately manifest as a residual on the original attention output.\nTo more accurately and unbiasedly quantify the results of personalized image\ngeneration, we improve the CLIP image alignment score based on masks.\nQualitatively and quantitatively, CatVersion helps to restore personalization\nconcepts more faithfully and enables more robust editing.",
            "author": [
                "Ruoyu Zhao",
                "Mingrui Zhu",
                "Shiyin Dong",
                "Nannan Wang",
                "Xinbo Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14631v2",
                "http://arxiv.org/pdf/2311.14631v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14625v1",
            "title": "ARIA: On the interaction between Architectures, Aggregation methods and\n  Initializations in federated visual classification",
            "updated": "2023-11-24T17:40:31Z",
            "published": "2023-11-24T17:40:31Z",
            "summary": "Federated Learning (FL) is a collaborative training paradigm that allows for\nprivacy-preserving learning of cross-institutional models by eliminating the\nexchange of sensitive data and instead relying on the exchange of model\nparameters between the clients and a server. Despite individual studies on how\nclient models are aggregated, and, more recently, on the benefits of ImageNet\npre-training, there is a lack of understanding of the effect the architecture\nchosen for the federation has, and of how the aforementioned elements\ninterconnect. To this end, we conduct the first joint\nARchitecture-Initialization-Aggregation study and benchmark ARIAs across a\nrange of medical image classification tasks. We find that, contrary to current\npractices, ARIA elements have to be chosen together to achieve the best\npossible performance. Our results also shed light on good choices for each\nelement depending on the task, the effect of normalisation layers, and the\nutility of SSL pre-training, pointing to potential directions for designing\nFL-specific architectures and training pipelines.",
            "author": [
                "Vasilis Siomos",
                "Sergio Naval-Marimont",
                "Jonathan Passerat-Palmbach",
                "Giacomo Tarroni"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14625v1",
                "http://arxiv.org/pdf/2311.14625v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.02178v1",
            "title": "Hierarchical ML Codebook Design for Extreme MIMO Beam Management",
            "updated": "2023-11-24T17:14:11Z",
            "published": "2023-11-24T17:14:11Z",
            "summary": "Beam management is a strategy to unify beamforming and channel state\ninformation (CSI) acquisition with large antenna arrays in 5G. Codebooks serve\nmultiple uses in beam management including beamforming reference signals, CSI\nreporting, and analog beam training. In this paper, we propose and evaluate a\nmachine learning-refined codebook design process for extremely large\nmultiple-input multiple-output (X-MIMO) systems. We propose a neural network\nand beam selection strategy to design the initial access and refinement\ncodebooks using end-to-end learning from beamspace representations. The\nalgorithm, called Extreme-Beam Management (X-BM), can significantly improve the\nperformance of extremely large arrays as envisioned for 6G and capture\nrealistic wireless and physical layer aspects. Our results show an 8dB\nimprovement in initial access and overall effective spectral efficiency\nimprovements compared to traditional codebook methods.",
            "author": [
                "Ryan M. Dreifuerst",
                "Robert W. Heath Jr"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02178v1",
                "http://arxiv.org/pdf/2312.02178v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.IT",
                "cs.LG",
                "cs.SY",
                "eess.SY",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14609v1",
            "title": "Analysis of the expected $L_2$ error of an over-parametrized deep neural\n  network estimate learned by gradient descent without regularization",
            "updated": "2023-11-24T17:04:21Z",
            "published": "2023-11-24T17:04:21Z",
            "summary": "Recent results show that estimates defined by over-parametrized deep neural\nnetworks learned by applying gradient descent to a regularized empirical $L_2$\nrisk are universally consistent and achieve good rates of convergence. In this\npaper, we show that the regularization term is not necessary to obtain similar\nresults. In the case of a suitably chosen initialization of the network, a\nsuitable number of gradient descent steps, and a suitable step size we show\nthat an estimate without a regularization term is universally consistent for\nbounded predictor variables. Additionally, we show that if the regression\nfunction is H\\\"older smooth with H\\\"older exponent $1/2 \\leq p \\leq 1$, the\n$L_2$ error converges to zero with a convergence rate of approximately\n$n^{-1/(1+d)}$. Furthermore, in case of an interaction model, where the\nregression function consists of a sum of H\\\"older smooth functions with $d^*$\ncomponents, a rate of convergence is derived which does not depend on the input\ndimension $d$.",
            "author": [
                "Selina Drews",
                "Michael Kohler"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14609v1",
                "http://arxiv.org/pdf/2311.14609v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "62G08"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14604v1",
            "title": "Evolution of Neural Architectures for Financial Forecasting: A Note on\n  Data Incompatibility during Crisis Periods",
            "updated": "2023-11-24T16:49:35Z",
            "published": "2023-11-24T16:49:35Z",
            "summary": "This note focuses on the optimization of neural architectures for stock index\nmovement forecasting following a major market disruption or crisis. Given that\nsuch crises may introduce a shift in market dynamics, this study aims to\ninvestigate whether the training data from market dynamics prior to the crisis\nare compatible with the data during the crisis period. To this end, two\ndistinct learning environments are designed to evaluate and reconcile the\neffects of possibly different market dynamics. These environments differ\nprincipally based on the role assigned to the pre-crisis data. In both\nenvironments, a set of non-dominated architectures are identified to satisfy\nthe multi-criteria co-evolution problem, which simultaneously addresses the\nselection issues related to features and hidden layer topology. To test the\nhypothesis of pre-crisis data incompatibility, the day-ahead movement\nprediction of the NASDAQ index is considered during two recent and major market\ndisruptions; the 2008 financial crisis and the COVID-19 pandemic. The results\nof a detailed comparative evaluation convincingly support the incompatibility\nhypothesis and highlight the need to select re-training windows carefully.",
            "author": [
                "Faizal Hafiz",
                "Jan Broekaert",
                "Akshya Swain"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14604v1",
                "http://arxiv.org/pdf/2311.14604v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14603v1",
            "title": "Animate124: Animating One Image to 4D Dynamic Scene",
            "updated": "2023-11-24T16:47:05Z",
            "published": "2023-11-24T16:47:05Z",
            "summary": "We introduce Animate124 (Animate-one-image-to-4D), the first work to animate\na single in-the-wild image into 3D video through textual motion descriptions,\nan underexplored problem with significant applications. Our 4D generation\nleverages an advanced 4D grid dynamic Neural Radiance Field (NeRF) model,\noptimized in three distinct stages using multiple diffusion priors. Initially,\na static model is optimized using the reference image, guided by 2D and 3D\ndiffusion priors, which serves as the initialization for the dynamic NeRF.\nSubsequently, a video diffusion model is employed to learn the motion specific\nto the subject. However, the object in the 3D videos tends to drift away from\nthe reference image over time. This drift is mainly due to the misalignment\nbetween the text prompt and the reference image in the video diffusion model.\nIn the final stage, a personalized diffusion prior is therefore utilized to\naddress the semantic drift. As the pioneering image-text-to-4D generation\nframework, our method demonstrates significant advancements over existing\nbaselines, evidenced by comprehensive quantitative and qualitative assessments.",
            "author": [
                "Yuyang Zhao",
                "Zhiwen Yan",
                "Enze Xie",
                "Lanqing Hong",
                "Zhenguo Li",
                "Gim Hee Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14603v1",
                "http://arxiv.org/pdf/2311.14603v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14601v1",
            "title": "A Metalearned Neural Circuit for Nonparametric Bayesian Inference",
            "updated": "2023-11-24T16:43:17Z",
            "published": "2023-11-24T16:43:17Z",
            "summary": "Most applications of machine learning to classification assume a closed set\nof balanced classes. This is at odds with the real world, where class\noccurrence statistics often follow a long-tailed power-law distribution and it\nis unlikely that all classes are seen in a single sample. Nonparametric\nBayesian models naturally capture this phenomenon, but have significant\npractical barriers to widespread adoption, namely implementation complexity and\ncomputational inefficiency. To address this, we present a method for extracting\nthe inductive bias from a nonparametric Bayesian model and transferring it to\nan artificial neural network. By simulating data with a nonparametric Bayesian\nprior, we can metalearn a sequence model that performs inference over an\nunlimited set of classes. After training, this \"neural circuit\" has distilled\nthe corresponding inductive bias and can successfully perform sequential\ninference over an open set of classes. Our experimental results show that the\nmetalearned neural circuit achieves comparable or better performance than\nparticle filter-based methods for inference in these models while being faster\nand simpler to use than methods that explicitly incorporate Bayesian\nnonparametric inference.",
            "author": [
                "Jake C. Snell",
                "Gianluca Bencomo",
                "Thomas L. Griffiths"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14601v1",
                "http://arxiv.org/pdf/2311.14601v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NE",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14782v1",
            "title": "One Fits All: Universal Time Series Analysis by Pretrained LM and\n  Specially Designed Adaptors",
            "updated": "2023-11-24T16:32:47Z",
            "published": "2023-11-24T16:32:47Z",
            "summary": "Despite the impressive achievements of pre-trained models in the fields of\nnatural language processing (NLP) and computer vision (CV), progress in the\ndomain of time series analysis has been limited. In contrast to NLP and CV,\nwhere a single model can handle various tasks, time series analysis still\nrelies heavily on task-specific methods for activities such as classification,\nanomaly detection, forecasting, and few-shot learning. The primary obstacle to\ndeveloping a pre-trained model for time series analysis is the scarcity of\nsufficient training data. In our research, we overcome this obstacle by\nutilizing pre-trained models from language or CV, which have been trained on\nbillions of data points, and apply them to time series analysis. We assess the\neffectiveness of the pre-trained transformer model in two ways. Initially, we\nmaintain the original structure of the self-attention and feedforward layers in\nthe residual blocks of the pre-trained language or image model, using the\nFrozen Pre-trained Transformer (FPT) for time series analysis with the addition\nof projection matrices for input and output. Additionally, we introduce four\nunique adapters, designed specifically for downstream tasks based on the\npre-trained model, including forecasting and anomaly detection. These adapters\nare further enhanced with efficient parameter tuning, resulting in superior\nperformance compared to all state-of-the-art methods.Our comprehensive\nexperimental studies reveal that (a) the simple FPT achieves top-tier\nperformance across various time series analysis tasks; and (b) fine-tuning the\nFPT with the custom-designed adapters can further elevate its performance,\noutshining specialized task-specific models.",
            "author": [
                "Tian Zhou",
                "Peisong Niu",
                "Xue Wang",
                "Liang Sun",
                "Rong Jin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14782v1",
                "http://arxiv.org/pdf/2311.14782v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14780v1",
            "title": "Wavelength-multiplexed Multi-mode EUV Reflection Ptychography based on\n  Automatic-Differentiation",
            "updated": "2023-11-24T16:21:36Z",
            "published": "2023-11-24T16:21:36Z",
            "summary": "Ptychographic extreme ultraviolet (EUV) diffractive imaging has emerged as a\npromising candidate for the next-generation metrology solutions in the\nsemiconductor industry, as it can image wafer samples in reflection geometry at\nthe nanoscale. This technique has surged attention recently, owing to the\nsignificant progress in high-harmonic generation (HHG) EUV sources and\nadvancements in both hardware and software for computation.\n  In this study, a novel algorithm is introduced and tested, which enables\nwavelength-multiplexed reconstruction that enhances the measurement throughput\nand introduces data diversity, allowing the accurate characterisation of sample\nstructures. To tackle the inherent instabilities of the HHG source, a modal\napproach was adopted, which represents the cross-density function of the\nillumination by a series of mutually incoherent and independent spatial modes.\n  The proposed algorithm was implemented on a mainstream machine learning\nplatform, which leverages automatic differentiation to manage the drastic\ngrowth in model complexity and expedites the computation using GPU\nacceleration. By optimising over 200 million parameters, we demonstrate the\nalgorithm's capacity to accommodate experimental uncertainties and achieve a\nresolution approaching the diffraction limit in reflection geometry. The\nreconstruction of wafer samples with 20-nm heigh patterned gold structures on a\nsilicon substrate highlights our ability to handle complex physical\ninterrelations involving a multitude of parameters. These results establish\nptychography as an efficient and accurate metrology tool.",
            "author": [
                "Yifeng Shao",
                "Sven Weerdenburg",
                "Jacob Seifert",
                "H. Paul Urbach",
                "Allard P. Mosk",
                "Wim Coene"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14780v1",
                "http://arxiv.org/pdf/2311.14780v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14581v1",
            "title": "Example-Based Explanations of Random Forest Predictions",
            "updated": "2023-11-24T16:12:43Z",
            "published": "2023-11-24T16:12:43Z",
            "summary": "A random forest prediction can be computed by the scalar product of the\nlabels of the training examples and a set of weights that are determined by the\nleafs of the forest into which the test object falls; each prediction can hence\nbe explained exactly by the set of training examples for which the weights are\nnon-zero. The number of examples used in such explanations is shown to vary\nwith the dimensionality of the training set and hyperparameters of the random\nforest algorithm. This means that the number of examples involved in each\nprediction can to some extent be controlled by varying these parameters.\nHowever, for settings that lead to a required predictive performance, the\nnumber of examples involved in each prediction may be unreasonably large,\npreventing the user to grasp the explanations. In order to provide more useful\nexplanations, a modified prediction procedure is proposed, which includes only\nthe top-weighted examples. An investigation on regression and classification\ntasks shows that the number of examples used in each explanation can be\nsubstantially reduced while maintaining, or even improving, predictive\nperformance compared to the standard prediction procedure.",
            "author": [
                "Henrik Bostr\u00f6m"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14581v1",
                "http://arxiv.org/pdf/2311.14581v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14576v1",
            "title": "Physics-Informed Tensor Basis Neural Network for Turbulence Closure\n  Modeling",
            "updated": "2023-11-24T16:07:35Z",
            "published": "2023-11-24T16:07:35Z",
            "summary": "Despite the increasing availability of high-performance computational\nresources, Reynolds-Averaged Navier-Stokes (RANS) simulations remain the\nworkhorse for the analysis of turbulent flows in real-world applications.\nLinear eddy viscosity models (LEVM), the most commonly employed model type,\ncannot accurately predict complex states of turbulence. This work combines a\ndeep-neural-network-based, nonlinear eddy viscosity model with turbulence\nrealizability constraints as an inductive bias in order to yield improved\npredictions of the anisotropy tensor. Using visualizations based on the\nbarycentric map, we show that the proposed machine learning method's anisotropy\ntensor predictions offer a significant improvement over all LEVMs in\ntraditionally challenging cases with surface curvature and flow separation.\nHowever, this improved anisotropy tensor does not, in general, yield improved\nmean-velocity and pressure field predictions in comparison with the\nbest-performing LEVM.",
            "author": [
                "Leon Riccius",
                "Atul Agrawal",
                "Phaedon-Stelios Koutsourelakis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14576v1",
                "http://arxiv.org/pdf/2311.14576v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14577v1",
            "title": "Predicting Failure of P2P Lending Platforms through Machine Learning:\n  The Case in China",
            "updated": "2023-11-24T16:07:35Z",
            "published": "2023-11-24T16:07:35Z",
            "summary": "This study employs machine learning models to predict the failure of\nPeer-to-Peer (P2P) lending platforms, specifically in China. By employing the\nfilter method and wrapper method with forward selection and backward\nelimination, we establish a rigorous and practical procedure that ensures the\nrobustness and importance of variables in predicting platform failures. The\nresearch identifies a set of robust variables that consistently appear in the\nfeature subsets across different selection methods and models, suggesting their\nreliability and relevance in predicting platform failures. The study highlights\nthat reducing the number of variables in the feature subset leads to an\nincrease in the false acceptance rate while the performance metrics remain\nstable, with an AUC value of approximately 0.96 and an F1 score of around 0.88.\nThe findings of this research provide significant practical implications for\nregulatory authorities and investors operating in the Chinese P2P lending\nindustry.",
            "author": [
                "Jen-Yin Yeh",
                "Hsin-Yu Chiu",
                "Jhih-Huei Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14577v1",
                "http://arxiv.org/pdf/2311.14577v1"
            ],
            "primary_category": "q-fin.GN",
            "category": [
                "q-fin.GN",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14557v1",
            "title": "Augmentation of scarce data -- a new approach for deep-learning modeling\n  of composites",
            "updated": "2023-11-24T15:41:03Z",
            "published": "2023-11-24T15:41:03Z",
            "summary": "High-fidelity full-field micro-mechanical modeling of the non-linear\npath-dependent materials demands a substantial computational effort. Recent\ntrends in the field incorporates data-driven Artificial Neural Networks (ANNs)\nas surrogate models. However, ANNs are inherently data-hungry, functioning as a\nbottleneck for the development of high-fidelity data-driven models. This study\nintroduces a novel approach for data augmentation, expanding an original\ndataset without additional computational simulations. A Recurrent Neural\nNetwork (RNN) was trained and validated on high-fidelity micro-mechanical\nsimulations of elasto-plastic short fiber reinforced composites. The obtained\nresults showed a considerable improvement of the network predictions trained on\nexpanded datasets using the proposed data augmentation approach. The proposed\nmethod for augmentation of scarce data may be used not only for other kind of\ncomposites, but also for other materials and at different length scales, and\nhence, opening avenues for innovative data-driven models in materials science\nand computational mechanics.",
            "author": [
                "Hon Lam Cheung",
                "Petter Uvdal",
                "Mohsen Mirkhalaf"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14557v1",
                "http://arxiv.org/pdf/2311.14557v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14554v1",
            "title": "Deep learning based reduced order modeling of Darcy flow systems with\n  local mass conservation",
            "updated": "2023-11-24T15:37:28Z",
            "published": "2023-11-24T15:37:28Z",
            "summary": "We propose a new reduced order modeling strategy for tackling parametrized\nPartial Differential Equations (PDEs) with linear constraints, in particular\nDarcy flow systems in which the constraint is given by mass conservation. Our\napproach employs classical neural network architectures and supervised\nlearning, but it is constructed in such a way that the resulting Reduced Order\nModel (ROM) is guaranteed to satisfy the linear constraints exactly. The\nprocedure is based on a splitting of the PDE solution into a particular\nsolution satisfying the constraint and a homogenous solution. The homogeneous\nsolution is approximated by mapping a suitable potential function, generated by\na neural network model, onto the kernel of the constraint operator; for the\nparticular solution, instead, we propose an efficient spanning tree algorithm.\nStarting from this paradigm, we present three approaches that follow this\nmethodology, obtained by exploring different choices of the potential spaces:\nfrom empirical ones, derived via Proper Orthogonal Decomposition (POD), to more\nabstract ones based on differential complexes. All proposed approaches combine\ncomputational efficiency with rigorous mathematical interpretation, thus\nguaranteeing the explainability of the model outputs. To demonstrate the\nefficacy of the proposed strategies and to emphasize their advantages over\nvanilla black-box approaches, we present a series of numerical experiments on\nfluid flows in porous media, ranging from mixed-dimensional problems to\nnonlinear systems. This research lays the foundation for further exploration\nand development in the realm of model order reduction, potentially unlocking\nnew capabilities and solutions in computational geosciences and beyond.",
            "author": [
                "Wietse M. Boon",
                "Nicola R. Franco",
                "Alessio Fumagalli",
                "Paolo Zunino"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14554v1",
                "http://arxiv.org/pdf/2311.14554v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14549v1",
            "title": "FRUITS: Feature Extraction Using Iterated Sums for Time Series\n  Classification",
            "updated": "2023-11-24T15:31:26Z",
            "published": "2023-11-24T15:31:26Z",
            "summary": "We introduce a pipeline for time series classification that extracts features\nbased on the iterated-sums signature (ISS) and then applies a linear\nclassifier. These features are intrinsically nonlinear, capture chronological\ninformation, and, under certain settings, are invariant to time-warping. We are\ncompetitive with state-of-the-art methods on the UCR archive, both in terms of\naccuracy and speed. We make our code available at\n\\url{https://github.com/irkri/fruits}.",
            "author": [
                "Joscha Diehl",
                "Richard Krieg"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14549v1",
                "http://arxiv.org/pdf/2311.14549v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14544v1",
            "title": "Inferring Latent Class Statistics from Text for Robust Visual Few-Shot\n  Learning",
            "updated": "2023-11-24T15:23:47Z",
            "published": "2023-11-24T15:23:47Z",
            "summary": "In the realm of few-shot learning, foundation models like CLIP have proven\neffective but exhibit limitations in cross-domain robustness especially in\nfew-shot settings. Recent works add text as an extra modality to enhance the\nperformance of these models. Most of these approaches treat text as an\nauxiliary modality without fully exploring its potential to elucidate the\nunderlying class visual features distribution. In this paper, we present a\nnovel approach that leverages text-derived statistics to predict the mean and\ncovariance of the visual feature distribution for each class. This predictive\nframework enriches the latent space, yielding more robust and generalizable\nfew-shot learning models. We demonstrate the efficacy of incorporating both\nmean and covariance statistics in improving few-shot classification performance\nacross various datasets. Our method shows that we can use text to predict the\nmean and covariance of the distribution offering promising improvements in\nfew-shot learning scenarios.",
            "author": [
                "Yassir Bendou",
                "Vincent Gripon",
                "Bastien Pasdeloup",
                "Giulia Lioi",
                "Lukas Mauch",
                "Fabien Cardinaux",
                "Ghouthi Boukli Hacene"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14544v1",
                "http://arxiv.org/pdf/2311.14544v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14543v1",
            "title": "Data-Efficient Alignment of Large Language Models with Human Feedback\n  Through Natural Language",
            "updated": "2023-11-24T15:20:36Z",
            "published": "2023-11-24T15:20:36Z",
            "summary": "Learning from human feedback is a prominent technique to align the output of\nlarge language models (LLMs) with human expectations. Reinforcement learning\nfrom human feedback (RLHF) leverages human preference signals that are in the\nform of ranking of response pairs to perform this alignment. However, human\npreference on LLM outputs can come in much richer forms including natural\nlanguage, which may provide detailed feedback on strengths and weaknesses of a\ngiven response. In this work we investigate data efficiency of modeling human\nfeedback that is in natural language. Specifically, we fine-tune an open-source\nLLM, e.g., Falcon-40B-Instruct, on a relatively small amount (1000 records or\neven less) of human feedback in natural language in the form of critiques and\nrevisions of responses. We show that this model is able to improve the quality\nof responses from even some of the strongest LLMs such as ChatGPT, BARD, and\nVicuna, through critique and revision of those responses. For instance, through\none iteration of revision of ChatGPT responses, the revised responses have\n56.6% win rate over the original ones, and this win rate can be further\nimproved to 65.9% after applying the revision for five iterations.",
            "author": [
                "Di Jin",
                "Shikib Mehri",
                "Devamanyu Hazarika",
                "Aishwarya Padmakumar",
                "Sungjin Lee",
                "Yang Liu",
                "Mahdi Namazifar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14543v1",
                "http://arxiv.org/pdf/2311.14543v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14534v1",
            "title": "Finding Foundation Models for Time Series Classification with a PreText\n  Task",
            "updated": "2023-11-24T15:03:55Z",
            "published": "2023-11-24T15:03:55Z",
            "summary": "Over the past decade, Time Series Classification (TSC) has gained an\nincreasing attention. While various methods were explored, deep learning -\nparticularly through Convolutional Neural Networks (CNNs)-stands out as an\neffective approach. However, due to the limited availability of training data,\ndefining a foundation model for TSC that overcomes the overfitting problem is\nstill a challenging task. The UCR archive, encompassing a wide spectrum of\ndatasets ranging from motion recognition to ECG-based heart disease detection,\nserves as a prime example for exploring this issue in diverse TSC scenarios. In\nthis paper, we address the overfitting challenge by introducing pre-trained\ndomain foundation models. A key aspect of our methodology is a novel pretext\ntask that spans multiple datasets. This task is designed to identify the\noriginating dataset of each time series sample, with the goal of creating\nflexible convolution filters that can be applied across different datasets. The\nresearch process consists of two phases: a pre-training phase where the model\nacquires general features through the pretext task, and a subsequent\nfine-tuning phase for specific dataset classifications. Our extensive\nexperiments on the UCR archive demonstrate that this pre-training strategy\nsignificantly outperforms the conventional training approach without\npre-training. This strategy effectively reduces overfitting in small datasets\nand provides an efficient route for adapting these models to new datasets, thus\nadvancing the capabilities of deep learning in TSC.",
            "author": [
                "Ali Ismail-Fawaz",
                "Maxime Devanne",
                "Stefano Berretti",
                "Jonathan Weber",
                "Germain Forestier"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14534v1",
                "http://arxiv.org/pdf/2311.14534v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14533v1",
            "title": "Comparing Feature Engineering and End-to-End Deep Learning for Autism\n  Spectrum Disorder Assessment based on Fullbody-Tracking",
            "updated": "2023-11-24T14:56:36Z",
            "published": "2023-11-24T14:56:36Z",
            "summary": "Autism Spectrum Disorder (ASD) is characterized by challenges in social\ncommunication and restricted patterns, with motor abnormalities gaining\ntraction for early detection. However, kinematic analysis in ASD is limited,\noften lacking robust validation and relying on hand-crafted features for single\ntasks, leading to inconsistencies across studies. Thus, end-to-end models have\nbecome promising methods to overcome the need for feature engineering. Our aim\nis to assess both approaches across various kinematic tasks to measure the\nefficacy of commonly used features in ASD assessment, while comparing them to\nend-to-end models. Specifically, we developed a virtual reality environment\nwith multiple motor tasks and trained models using both classification\napproaches. We prioritized a reliable validation framework with repeated\ncross-validation. Our comparative analysis revealed that hand-crafted features\noutperformed our deep learning approach in specific tasks, achieving a\nstate-of-the-art area under the curve (AUC) of 0.90$\\pm$0.06. Conversely,\nend-to-end models provided more consistent results with less variability across\nall VR tasks, demonstrating domain generalization and reliability, with a\nmaximum task AUC of 0.89$\\pm$0.06. These findings show that end-to-end models\nenable less variable and context-independent ASD assessments without requiring\ndomain knowledge or task specificity. However, they also recognize the\neffectiveness of hand-crafted features in specific task scenarios.",
            "author": [
                "Alberto Altozano",
                "Maria Eleonora Minissi",
                "Mariano Alca\u00f1iz",
                "Javier Mar\u00edn-Morales"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14533v1",
                "http://arxiv.org/pdf/2311.14533v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14532v1",
            "title": "Digital Twin-Native AI-Driven Service Architecture for Industrial\n  Networks",
            "updated": "2023-11-24T14:56:13Z",
            "published": "2023-11-24T14:56:13Z",
            "summary": "The dramatic increase in the connectivity demand results in an excessive\namount of Internet of Things (IoT) sensors. To meet the management needs of\nthese large-scale networks, such as accurate monitoring and learning\ncapabilities, Digital Twin (DT) is the key enabler. However, current attempts\nregarding DT implementations remain insufficient due to the perpetual\nconnectivity requirements of IoT networks. Furthermore, the sensor data\nstreaming in IoT networks cause higher processing time than traditional\nmethods. In addition to these, the current intelligent mechanisms cannot\nperform well due to the spatiotemporal changes in the implemented IoT network\nscenario. To handle these challenges, we propose a DT-native AI-driven service\narchitecture in support of the concept of IoT networks. Within the proposed\nDT-native architecture, we implement a TCP-based data flow pipeline and a\nReinforcement Learning (RL)-based learner model. We apply the proposed\narchitecture to one of the broad concepts of IoT networks, the Internet of\nVehicles (IoV). We measure the efficiency of our proposed architecture and note\n~30% processing time-saving thanks to the TCP-based data flow pipeline.\nMoreover, we test the performance of the learner model by applying several\nlearning rate combinations for actor and critic networks and highlight the most\nsuccessive model.",
            "author": [
                "Kubra Duran",
                "Matthew Broadbent",
                "Gokhan Yurdakul",
                "Berk Canberk"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14532v1",
                "http://arxiv.org/pdf/2311.14532v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14530v1",
            "title": "Machine Translation for Ge'ez Language",
            "updated": "2023-11-24T14:55:23Z",
            "published": "2023-11-24T14:55:23Z",
            "summary": "Machine translation (MT) for low-resource languages such as Ge'ez, an ancient\nlanguage that is no longer spoken in daily life, faces challenges such as\nout-of-vocabulary words, domain mismatches, and lack of sufficient labeled\ntraining data. In this work, we explore various methods to improve Ge'ez MT,\nincluding transfer-learning from related languages, optimizing shared\nvocabulary and token segmentation approaches, finetuning large pre-trained\nmodels, and using large language models (LLMs) for few-shot translation with\nfuzzy matches. We develop a multilingual neural machine translation (MNMT)\nmodel based on languages relatedness, which brings an average performance\nimprovement of about 4 BLEU compared to standard bilingual models. We also\nattempt to finetune the NLLB-200 model, one of the most advanced translation\nmodels available today, but find that it performs poorly with only 4k training\nsamples for Ge'ez. Furthermore, we experiment with using GPT-3.5, a\nstate-of-the-art LLM, for few-shot translation with fuzzy matches, which\nleverages embedding similarity-based retrieval to find context examples from a\nparallel corpus. We observe that GPT-3.5 achieves a remarkable BLEU score of\n9.2 with no initial knowledge of Ge'ez, but still lower than the MNMT baseline\nof 15.2. Our work provides insights into the potential and limitations of\ndifferent approaches for low-resource and ancient language MT.",
            "author": [
                "Aman Kassahun Wassie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14530v1",
                "http://arxiv.org/pdf/2311.14530v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14517v1",
            "title": "tinyCLAP: Distilling Constrastive Language-Audio Pretrained Models",
            "updated": "2023-11-24T14:45:53Z",
            "published": "2023-11-24T14:45:53Z",
            "summary": "Contrastive Language-Audio Pretraining (CLAP) became of crucial importance in\nthe field of audio and speech processing. Its employment ranges from sound\nevent detection to text-to-audio generation. However, one of the main\nlimitations is the considerable amount of data required in the training process\nand the overall computational complexity during inference. This paper\ninvestigates how we can reduce the complexity of contrastive language-audio\npre-trained models, yielding an efficient model that we call tinyCLAP. We\nderive an unimodal distillation loss from first principles and explore how the\ndimensionality of the shared, multimodal latent space can be reduced via\npruning. TinyCLAP uses only 6% of the original Microsoft CLAP parameters with a\nminimal reduction (less than 5%) in zero-shot classification performance across\nthe three sound event detection datasets on which it was tested",
            "author": [
                "Francesco Paissan",
                "Elisabetta Farella"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14517v1",
                "http://arxiv.org/pdf/2311.14517v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CL",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14510v1",
            "title": "The Westermo test system performance data set",
            "updated": "2023-11-24T14:38:49Z",
            "published": "2023-11-24T14:38:49Z",
            "summary": "There is a growing body of knowledge in the computer science, software\nengineering, software testing and software test automation disciplines.\nHowever, a challenge for researchers is to evaluate their research findings,\nideas and tools due to lack of realistic data. This paper presents the Westermo\ntest system performance data set. More than twenty performance metrics such as\nCPU and memory usage sampled twice per minute for a month on nineteen test\nsystems driving nightly testing of cyber-physical systems has been anonymized\nand released. The industrial motivation is to spur work on anomaly detection in\nseasonal data such that one may increase trust in nightly testing. One could\nask: If the test system is in an abnormal state - can we trust the test\nresults? How could one automate the detection of abnormal states? The data set\nhas previously been used by students and in hackathons. By releasing it we hope\nto simplify experiments on anomaly detection based on rules, thresholds,\nstatistics, machine learning or artificial intelligence, perhaps while\nincorporating seasonality. We also hope that the data set could lead to\nfindings in sustainable software engineering.",
            "author": [
                "Per Erik Strandberg",
                "Yosh Marklund"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14510v1",
                "http://arxiv.org/pdf/2311.14510v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14509v1",
            "title": "FAMAC: A Federated Assisted Modified Actor-Critic Framework for Secured\n  Energy Saving in 5G and Beyond Networks",
            "updated": "2023-11-24T14:37:16Z",
            "published": "2023-11-24T14:37:16Z",
            "summary": "The constant surge in the traffic demand on cellular networks has led to\ncontinuous expansion in network capacity in order to accommodate existing and\nnew service demands. This has given rise to ultra-dense base station deployment\nin 5G and beyond networks which leads to increased energy consumption in the\nnetwork. Hence, these ultra-dense base station deployments must be operated in\na way that the energy consumption of the network can be adapted to the\nspatio-temporal traffic demands on the network in order to minimize the overall\nenergy consumption of the network. To achieve this goal, we leverage two\nartificial intelligence algorithms, federated learning and actor-critic\nalgorithm, to develop a proactive and intelligent base station switching\nframework that can learn the operating policy of the small base station in an\nultra-dense heterogeneous network (UDHN) that would result in maximum energy\nsaving in the network while respecting the quality of service (QoS)\nconstraints. The performance evaluation reveals that the proposed framework can\nachieve an energy saving that is about 77% more than that of the\nstate-of-the-art solutions while respecting the QoS constraints of the network.",
            "author": [
                "Attai Ibrahim Abubakar",
                "Michael S. Mollel",
                "Naeem Ramzan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14509v1",
                "http://arxiv.org/pdf/2311.14509v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14497v1",
            "title": "Advancing High-Throughput Combinatorial Aging Studies of Hybrid\n  Perovskite Thin-Films via Precise Automated Characterization Methods and\n  Machine Learning Assisted Analysis",
            "updated": "2023-11-24T14:13:11Z",
            "published": "2023-11-24T14:13:11Z",
            "summary": "To optimize materials' stability, automated high-throughput workflows are of\nincreasing interest. However, many of those workflows use processes not\nsuitable for large-area depositions which limits the transferability of\nresults. While combinatorial approaches based on vapour-based depositions are\ninherently scalable, their potential for controlled stability assessments has\nyet to be exploited. Based on MAPbI3 thin-films as a prototypical system, we\ndemonstrate a combinatorial inert-gas workflow to study materials degradation\nbased on intrinsic factors only, closely resembling conditions in encapsulated\nde-vices. Through a comprehensive set of automated X-Ray fluorescence (XRF),\nX-Ray diffraction (XRD) and UV-Vis characterizations, we aim to obtain a\nholistic understanding of thin-film properties of pristine and aged thin-films.\nFrom phase changes derived from XRD characterizations before and after aging,\nwe observe simi-lar aging behaviours for MAPbI3 thin-films with varying PbI2\nresiduals. Using a custom-designed in-situ UV-Vis aging setup, the\ncombinatorial libraries are exposed to relevant aging conditions, such as heat\nor light-bias exposure. Simultaneously, UV-Vis photospectroscopy is performed\nto gain kinetic insights into the aging process which can be linked to\nintrinsic degradation processes such as autocatalytic decomposition. Despite\nscattering effects, which complicate the conventional interpretation of in-situ\nUV-Vis results, we demonstrate how a machine learning model trained on the\ncomprehensive characterization data before and after the aging process can link\noptical changes to phase changes during aging. Consequently, this approach does\nnot only enable semi-quantitative comparisons of materials' stability but also\nprovides detailed insights into the underlying degradation processes which are\notherwise mostly reported for investigations on single samples.",
            "author": [
                "Alexander Wieczorek",
                "Austin G. Kuba",
                "Jan Sommerh\u00e4user",
                "Luis Nicklaus Caceres",
                "Christian Wolff",
                "Sebastian Siol"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14497v1",
                "http://arxiv.org/pdf/2311.14497v1"
            ],
            "primary_category": "physics.app-ph",
            "category": [
                "physics.app-ph",
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14495v1",
            "title": "StableSSM: Alleviating the Curse of Memory in State-space Models through\n  Stable Reparameterization",
            "updated": "2023-11-24T14:08:31Z",
            "published": "2023-11-24T14:08:31Z",
            "summary": "In this paper, we investigate the long-term memory learning capabilities of\nstate-space models (SSMs) from the perspective of parameterization. We prove\nthat state-space models without any reparameterization exhibit a memory\nlimitation similar to that of traditional RNNs: the target relationships that\ncan be stably approximated by state-space models must have an exponential\ndecaying memory. Our analysis identifies this \"curse of memory\" as a result of\nthe recurrent weights converging to a stability boundary, suggesting that a\nreparameterization technique can be effective. To this end, we introduce a\nclass of reparameterization techniques for SSMs that effectively lift its\nmemory limitations. Besides improving approximation capabilities, we further\nillustrate that a principled choice of reparameterization scheme can also\nenhance optimization stability. We validate our findings using synthetic\ndatasets and language models.",
            "author": [
                "Shida Wang",
                "Qianxiao Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14495v1",
                "http://arxiv.org/pdf/2311.14495v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL",
                "math.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14494v2",
            "title": "MVControl: Adding Conditional Control to Multi-view Diffusion for\n  Controllable Text-to-3D Generation",
            "updated": "2023-11-27T12:39:42Z",
            "published": "2023-11-24T14:07:53Z",
            "summary": "We introduce MVControl, a novel neural network architecture that enhances\nexisting pre-trained multi-view 2D diffusion models by incorporating additional\ninput conditions, e.g. edge maps. Our approach enables the generation of\ncontrollable multi-view images and view-consistent 3D content. To achieve\ncontrollable multi-view image generation, we leverage MVDream as our base\nmodel, and train a new neural network module as additional plugin for\nend-to-end task-specific condition learning. To precisely control the shapes\nand views of generated images, we innovatively propose a new conditioning\nmechanism that predicts an embedding encapsulating the input spatial and view\nconditions, which is then injected to the network globally. Once MVControl is\ntrained, score-distillation (SDS) loss based optimization can be performed to\ngenerate 3D content, in which process we propose to use a hybrid diffusion\nprior. The hybrid prior relies on a pre-trained Stable-Diffusion network and\nour trained MVControl for additional guidance. Extensive experiments\ndemonstrate that our method achieves robust generalization and enables the\ncontrollable generation of high-quality 3D content. Code available at\nhttps://github.com/WU-CVGL/MVControl/.",
            "author": [
                "Zhiqi Li",
                "Yiming Chen",
                "Lingzhe Zhao",
                "Peidong Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14494v2",
                "http://arxiv.org/pdf/2311.14494v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14773v1",
            "title": "Set Features for Anomaly Detection",
            "updated": "2023-11-24T13:56:06Z",
            "published": "2023-11-24T13:56:06Z",
            "summary": "This paper proposes set features for detecting anomalies in samples that\nconsist of unusual combinations of normal elements. Many leading methods\ndiscover anomalies by detecting an unusual part of a sample. For example,\nstate-of-the-art segmentation-based approaches, first classify each element of\nthe sample (e.g., image patch) as normal or anomalous and then classify the\nentire sample as anomalous if it contains anomalous elements. However, such\napproaches do not extend well to scenarios where the anomalies are expressed by\nan unusual combination of normal elements. In this paper, we overcome this\nlimitation by proposing set features that model each sample by the distribution\nof its elements. We compute the anomaly score of each sample using a simple\ndensity estimation method, using fixed features. Our approach outperforms the\nprevious state-of-the-art in image-level logical anomaly detection and\nsequence-level time series anomaly detection.",
            "author": [
                "Niv Cohen",
                "Issar Tzachor",
                "Yedid Hoshen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14773v1",
                "http://arxiv.org/pdf/2311.14773v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14485v1",
            "title": "Towards Interpretable Classification of Leukocytes based on Deep\n  Learning",
            "updated": "2023-11-24T13:48:37Z",
            "published": "2023-11-24T13:48:37Z",
            "summary": "Label-free approaches are attractive in cytological imaging due to their\nflexibility and cost efficiency. They are supported by machine learning\nmethods, which, despite the lack of labeling and the associated lower contrast,\ncan classify cells with high accuracy where the human observer has little\nchance to discriminate cells. In order to better integrate these workflows into\nthe clinical decision making process, this work investigates the calibration of\nconfidence estimation for the automated classification of leukocytes. In\naddition, different visual explanation approaches are compared, which should\nbring machine decision making closer to professional healthcare applications.\nFurthermore, we were able to identify general detection patterns in neural\nnetworks and demonstrate the utility of the presented approaches in different\nscenarios of blood cell analysis.",
            "author": [
                "Stefan R\u00f6hrl",
                "Johannes Groll",
                "Manuel Lengl",
                "Simon Schumann",
                "Christian Klenk",
                "Dominik Heim",
                "Martin Knopp",
                "Oliver Hayden",
                "Klaus Diepold"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14485v1",
                "http://arxiv.org/pdf/2311.14485v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.00804v1",
            "title": "Automatic detection of problem-gambling signs from online texts using\n  large language models",
            "updated": "2023-11-24T13:48:02Z",
            "published": "2023-11-24T13:48:02Z",
            "summary": "Problem gambling is a major public health concern and is associated with\nprofound psychological distress and economic problems. There are numerous\ngambling communities on the internet where users exchange information about\ngames, gambling tactics, as well as gambling-related problems. Individuals\nexhibiting higher levels of problem gambling engage more in such communities.\nOnline gambling communities may provide insights into problem-gambling\nbehaviour. Using data scraped from a major German gambling discussion board, we\nfine-tuned a large language model, specifically a Bidirectional Encoder\nRepresentations from Transformers (BERT) model, to predict signs of\nproblem-gambling from forum posts. Training data were generated by manual\nannotation and by taking into account diagnostic criteria and gambling-related\ncognitive distortions. Using k-fold cross-validation, our models achieved a\nprecision of 0.95 and F1 score of 0.71, demonstrating that satisfactory\nclassification performance can be achieved by generating high-quality training\nmaterial through manual annotation based on diagnostic criteria. The current\nstudy confirms that a BERT-based model can be reliably used on small data sets\nand to detect signatures of problem gambling in online communication data. Such\ncomputational approaches may have potential for the detection of changes in\nproblem-gambling prevalence among online users.",
            "author": [
                "Elke Smith",
                "Nils Reiter",
                "Jan Peters"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00804v1",
                "http://arxiv.org/pdf/2312.00804v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14482v1",
            "title": "Sliding Window FastEdit: A Framework for Lesion Annotation in Whole-body\n  PET Images",
            "updated": "2023-11-24T13:45:58Z",
            "published": "2023-11-24T13:45:58Z",
            "summary": "Deep learning has revolutionized the accurate segmentation of diseases in\nmedical imaging. However, achieving such results requires training with\nnumerous manual voxel annotations. This requirement presents a challenge for\nwhole-body Positron Emission Tomography (PET) imaging, where lesions are\nscattered throughout the body. To tackle this problem, we introduce SW-FastEdit\n- an interactive segmentation framework that accelerates the labeling by\nutilizing only a few user clicks instead of voxelwise annotations. While prior\ninteractive models crop or resize PET volumes due to memory constraints, we use\nthe complete volume with our sliding window-based interactive scheme. Our model\noutperforms existing non-sliding window interactive models on the AutoPET\ndataset and generalizes to the previously unseen HECKTOR dataset. A user study\nrevealed that annotators achieve high-quality predictions with only 10 click\niterations and a low perceived NASA-TLX workload. Our framework is implemented\nusing MONAI Label and is available:\nhttps://github.com/matt3o/AutoPET2-Submission/",
            "author": [
                "Matthias Hadlich",
                "Zdravko Marinov",
                "Moon Kim",
                "Enrico Nasca",
                "Jens Kleesiek",
                "Rainer Stiefelhagen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14482v1",
                "http://arxiv.org/pdf/2311.14482v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.AI",
                "cs.CV",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14772v1",
            "title": "Trainwreck: A damaging adversarial attack on image classifiers",
            "updated": "2023-11-24T13:37:19Z",
            "published": "2023-11-24T13:37:19Z",
            "summary": "Adversarial attacks are an important security concern for computer vision\n(CV), as they enable malicious attackers to reliably manipulate CV models.\nExisting attacks aim to elicit an output desired by the attacker, but keep the\nmodel fully intact on clean data. With CV models becoming increasingly valuable\nassets in applied practice, a new attack vector is emerging: disrupting the\nmodels as a form of economic sabotage. This paper opens up the exploration of\ndamaging adversarial attacks (DAAs) that seek to damage the target model and\nmaximize the total cost incurred by the damage. As a pioneer DAA, this paper\nproposes Trainwreck, a train-time attack that poisons the training data of\nimage classifiers to degrade their performance. Trainwreck conflates the data\nof similar classes using stealthy ($\\epsilon \\leq 8/255$) class-pair universal\nperturbations computed using a surrogate model. Trainwreck is a black-box,\ntransferable attack: it requires no knowledge of the target model's\narchitecture, and a single poisoned dataset degrades the performance of any\nmodel trained on it. The experimental evaluation on CIFAR-10 and CIFAR-100\ndemonstrates that Trainwreck is indeed an effective attack across various model\narchitectures including EfficientNetV2, ResNeXt-101, and a finetuned ViT-L-16.\nThe strength of the attack can be customized by the poison rate parameter.\nFinally, data redundancy with file hashing and/or pixel difference are\nidentified as a reliable defense technique against Trainwreck or similar DAAs.\nThe code is available at https://github.com/JanZahalka/trainwreck.",
            "author": [
                "Jan Zah\u00e1lka"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14772v1",
                "http://arxiv.org/pdf/2311.14772v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14473v1",
            "title": "Joint Diffusion: Mutual Consistency-Driven Diffusion Model for PET-MRI\n  Co-Reconstruction",
            "updated": "2023-11-24T13:26:53Z",
            "published": "2023-11-24T13:26:53Z",
            "summary": "Positron Emission Tomography and Magnetic Resonance Imaging (PET-MRI) systems\ncan obtain functional and anatomical scans. PET suffers from a low\nsignal-to-noise ratio. Meanwhile, the k-space data acquisition process in MRI\nis time-consuming. The study aims to accelerate MRI and enhance PET image\nquality. Conventional approaches involve the separate reconstruction of each\nmodality within PET-MRI systems. However, there exists complementary\ninformation among multi-modal images. The complementary information can\ncontribute to image reconstruction. In this study, we propose a novel PET-MRI\njoint reconstruction model employing a mutual consistency-driven diffusion\nmode, namely MC-Diffusion. MC-Diffusion learns the joint probability\ndistribution of PET and MRI for utilizing complementary information. We\nconducted a series of contrast experiments about LPLS, Joint ISAT-net and\nMC-Diffusion by the ADNI dataset. The results underscore the qualitative and\nquantitative improvements achieved by MC-Diffusion, surpassing the\nstate-of-the-art method.",
            "author": [
                "Taofeng Xie",
                "Zhuo-Xu Cui",
                "Chen Luo",
                "Huayu Wang",
                "Congcong Liu",
                "Yuanzhi Zhang",
                "Xuemei Wang",
                "Yanjie Zhu",
                "Qiyu Jin",
                "Guoqing Chen",
                "Yihang Zhou",
                "Dong Liang",
                "Haifeng Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14473v1",
                "http://arxiv.org/pdf/2311.14473v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14469v1",
            "title": "Fault Detection in Telecom Networks using Bi-level Federated Graph\n  Neural Networks",
            "updated": "2023-11-24T13:23:54Z",
            "published": "2023-11-24T13:23:54Z",
            "summary": "5G and Beyond Networks become increasingly complex and heterogeneous, with\ndiversified and high requirements from a wide variety of emerging applications.\nThe complexity and diversity of Telecom networks place an increasing strain on\nmaintenance and operation efforts. Moreover, the strict security and privacy\nrequirements present a challenge for mobile operators to leverage network data.\nTo detect network faults, and mitigate future failures, prior work focused on\nleveraging traditional ML/DL methods to locate anomalies in networks. The\ncurrent approaches, although powerful, do not consider the intertwined nature\nof embedded and software-intensive Radio Access Network systems. In this paper,\nwe propose a Bi-level Federated Graph Neural Network anomaly detection and\ndiagnosis model that is able to detect anomalies in Telecom networks in a\nprivacy-preserving manner, while minimizing communication costs. Our method\nrevolves around conceptualizing Telecom data as a bi-level temporal Graph\nNeural Networks. The first graph captures the interactions between different\nRAN nodes that are exposed to different deployment scenarios in the network,\nwhile each individual Radio Access Network node is further elaborated into its\nsoftware (SW) execution graph. Additionally, we use Federated Learning to\naddress privacy and security limitations. Furthermore, we study the performance\nof anomaly detection model under three settings: (1) Centralized (2) Federated\nLearning and (3) Personalized Federated Learning using real-world data from an\noperational network. Our comprehensive experiments showed that Personalized\nFederated Temporal Graph Neural Networks method outperforms the most commonly\nused techniques for Anomaly Detection.",
            "author": [
                "R. Bourgerie",
                "T. Zanouda"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14469v1",
                "http://arxiv.org/pdf/2311.14469v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14468v2",
            "title": "Efficient Gradient Estimation via Adaptive Sampling and Importance\n  Sampling",
            "updated": "2023-11-27T08:04:04Z",
            "published": "2023-11-24T13:21:35Z",
            "summary": "Machine learning problems rely heavily on stochastic gradient descent (SGD)\nfor optimization. The effectiveness of SGD is contingent upon accurately\nestimating gradients from a mini-batch of data samples. Instead of the commonly\nused uniform sampling, adaptive or importance sampling reduces noise in\ngradient estimation by forming mini-batches that prioritize crucial data\npoints. Previous research has suggested that data points should be selected\nwith probabilities proportional to their gradient norm. Nevertheless, existing\nalgorithms have struggled to efficiently integrate importance sampling into\nmachine learning frameworks. In this work, we make two contributions. First, we\npresent an algorithm that can incorporate existing importance functions into\nour framework. Second, we propose a simplified importance function that relies\nsolely on the loss gradient of the output layer. By leveraging our proposed\ngradient estimation techniques, we observe improved convergence in\nclassification and regression tasks with minimal computational overhead. We\nvalidate the effectiveness of our adaptive and importance-sampling approach on\nimage and point-cloud datasets.",
            "author": [
                "Corentin Sala\u00fcn",
                "Xingchang Huang",
                "Iliyan Georgiev",
                "Niloy J. Mitra",
                "Gurprit Singh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14468v2",
                "http://arxiv.org/pdf/2311.14468v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14465v1",
            "title": "DP-NMT: Scalable Differentially-Private Machine Translation",
            "updated": "2023-11-24T13:19:47Z",
            "published": "2023-11-24T13:19:47Z",
            "summary": "Neural machine translation (NMT) is a widely popular text generation task,\nyet there is a considerable research gap in the development of\nprivacy-preserving NMT models, despite significant data privacy concerns for\nNMT systems. Differentially private stochastic gradient descent (DP-SGD) is a\npopular method for training machine learning models with concrete privacy\nguarantees; however, the implementation specifics of training a model with\nDP-SGD are not always clarified in existing models, with differing software\nlibraries used and code bases not always being public, leading to\nreproducibility issues. To tackle this, we introduce DP-NMT, an open-source\nframework for carrying out research on privacy-preserving NMT with DP-SGD,\nbringing together numerous models, datasets, and evaluation metrics in one\nsystematic software package. Our goal is to provide a platform for researchers\nto advance the development of privacy-preserving NMT systems, keeping the\nspecific details of the DP-SGD algorithm transparent and intuitive to\nimplement. We run a set of experiments on datasets from both general and\nprivacy-related domains to demonstrate our framework in use. We make our\nframework publicly available and welcome feedback from the community.",
            "author": [
                "Timour Igamberdiev",
                "Doan Nam Long Vu",
                "Felix K\u00fcnnecke",
                "Zhuo Yu",
                "Jannik Holmer",
                "Ivan Habernal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14465v1",
                "http://arxiv.org/pdf/2311.14465v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14464v1",
            "title": "Finite Volume Features, Global Geometry Representations, and Residual\n  Training for Deep Learning-based CFD Simulation",
            "updated": "2023-11-24T13:19:06Z",
            "published": "2023-11-24T13:19:06Z",
            "summary": "Computational fluid dynamics (CFD) simulation is an irreplaceable modelling\nstep in many engineering designs, but it is often computationally expensive.\nSome graph neural network (GNN)-based CFD methods have been proposed. However,\nthe current methods inherit the weakness of traditional numerical simulators,\nas well as ignore the cell characteristics in the mesh used in the finite\nvolume method, a common method in practical CFD applications. Specifically, the\ninput nodes in these GNN methods have very limited information about any object\nimmersed in the simulation domain and its surrounding environment. Also, the\ncell characteristics of the mesh such as cell volume, face surface area, and\nface centroid are not included in the message-passing operations in the GNN\nmethods. To address these weaknesses, this work proposes two novel geometric\nrepresentations: Shortest Vector (SV) and Directional Integrated Distance\n(DID). Extracted from the mesh, the SV and DID provide global geometry\nperspective to each input node, thus removing the need to collect this\ninformation through message-passing. This work also introduces the use of\nFinite Volume Features (FVF) in the graph convolutions as node and edge\nattributes, enabling its message-passing operations to adjust to different\nnodes. Finally, this work is the first to demonstrate how residual training,\nwith the availability of low-resolution data, can be adopted to improve the\nflow field prediction accuracy. Experimental results on two datasets with five\ndifferent state-of-the-art GNN methods for CFD indicate that SV, DID, FVF and\nresidual training can effectively reduce the predictive error of current\nGNN-based methods by as much as 41%.",
            "author": [
                "Loh Sher En Jessica",
                "Naheed Anjum Arafat",
                "Wei Xian Lim",
                "Wai Lee Chan",
                "Adams Wai Kin Kong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14464v1",
                "http://arxiv.org/pdf/2311.14464v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CE",
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14462v1",
            "title": "CT-xCOV: a CT-scan based Explainable Framework for COVid-19 diagnosis",
            "updated": "2023-11-24T13:14:10Z",
            "published": "2023-11-24T13:14:10Z",
            "summary": "In this work, CT-xCOV, an explainable framework for COVID-19 diagnosis using\nDeep Learning (DL) on CT-scans is developed. CT-xCOV adopts an end-to-end\napproach from lung segmentation to COVID-19 detection and explanations of the\ndetection model's prediction. For lung segmentation, we used the well-known\nU-Net model. For COVID-19 detection, we compared three different CNN\narchitectures: a standard CNN, ResNet50, and DenseNet121. After the detection,\nvisual and textual explanations are provided. For visual explanations, we\napplied three different XAI techniques, namely, Grad-Cam, Integrated Gradient\n(IG), and LIME. Textual explanations are added by computing the percentage of\ninfection by lungs. To assess the performance of the used XAI techniques, we\npropose a ground-truth-based evaluation method, measuring the similarity\nbetween the visualization outputs and the ground-truth infections. The\nperformed experiments show that the applied DL models achieved good results.\nThe U-Net segmentation model achieved a high Dice coefficient (98%). The\nperformance of our proposed classification model (standard CNN) was validated\nusing 5-fold cross-validation (acc of 98.40% and f1-score 98.23%). Lastly, the\nresults of the comparison of XAI techniques show that Grad-Cam gives the best\nexplanations compared to LIME and IG, by achieving a Dice coefficient of 55%,\non COVID-19 positive scans, compared to 29% and 24% obtained by IG and LIME\nrespectively. The code and the dataset used in this paper are available in the\nGitHub repository [1].",
            "author": [
                "Ismail Elbouknify",
                "Afaf Bouhoute",
                "Khalid Fardousse",
                "Ismail Berrada",
                "Abdelmajid Badri"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14462v1",
                "http://arxiv.org/pdf/2311.14462v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14458v1",
            "title": "An Origami-Inspired Energy Absorber",
            "updated": "2023-11-24T13:11:23Z",
            "published": "2023-11-24T13:11:23Z",
            "summary": "The design of effective and compact energy absorption systems is key to the\nsurvivability and durability of many man-made structures and machines. To this\nend, this work presents the design, assessment, and implementation of a novel\norigami-inspired energy absorber that is based on the Kresling origami pattern.\nThe absorber consists of a Kresling origami column positioned between the\nloading point and an energy dissipation module. By exploiting its unique\ninherent translation-to-rotation coupling feature, the primary function of the\nKresling column is to transmit uniaxial incident loads (shock or impact) into\nlocalized rotational energy that can then be dissipated in a viscous fluid\nchamber. The proposed system has several unique advantages over traditional\ndesigns including the ability to i) dissipate energy associated with both\ntorsional and uniaxial loads, ii) control the rotational velocity profile to\nmaximize energy dissipation, and iii) customize the restoring-force behavior of\nthe Kresling column to different applications. Furthermore, the proposed design\nis more compact since it can realize the same stroke distance of the\ntraditional translational design while being considerably shorter. Through\nextensive computational modeling, parametric studies, and experimental testing,\nit is demonstrated that the proposed design can be optimized to absorb all the\nimparted energy; and out of the absorbed energy, around 40% is dissipated in\nthe viscous fluid, while the rest is either dissipated by the viscoelasticity\nof the origami column or stored in it as potential energy.",
            "author": [
                "Shadi Khazaaleh",
                "Ahmed S. Dalaq",
                "Mohammed F. Daqaq"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14458v1",
                "http://arxiv.org/pdf/2311.14458v1"
            ],
            "primary_category": "physics.app-ph",
            "category": [
                "physics.app-ph",
                "74K25, 74H99, 74S05, 74D99, 74F10",
                "I.6; J.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14457v1",
            "title": "How to ensure a safe control strategy? Towards a SRL for urban transit\n  autonomous operation",
            "updated": "2023-11-24T13:11:07Z",
            "published": "2023-11-24T13:11:07Z",
            "summary": "Deep reinforcement learning has gradually shown its latent decision-making\nability in urban rail transit autonomous operation. However, since\nreinforcement learning can not neither guarantee safety during learning nor\nexecution, this is still one of the major obstacles to the practical\napplication of reinforcement learning. Given this drawback, reinforcement\nlearning applied in the safety-critical autonomous operation domain remains\nchallenging without generating a safe control command sequence that avoids\noverspeed operations. Therefore, a SSA-DRL framework is proposed in this paper\nfor safe intelligent control of urban rail transit autonomous operation trains.\nThe proposed framework is combined with linear temporal logic, reinforcement\nlearning and Monte Carlo tree search and consists of four mainly module: a\npost-posed shielding, a searching tree module, a DRL framework and an\nadditional actor. Furthermore, the output of the framework can meet speed\nconstraint, schedule constraint and optimize the operation process. Finally,\nthe proposed SSA-DRL framework for decision-making in urban rail transit\nautonomous operation is evaluated in sixteen different sections, and its\neffectiveness is demonstrated through an ablation experiment and comparison\nwith the scheduled operation plan.",
            "author": [
                "Zicong Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14457v1",
                "http://arxiv.org/pdf/2311.14457v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14455v1",
            "title": "Universal Jailbreak Backdoors from Poisoned Human Feedback",
            "updated": "2023-11-24T13:09:34Z",
            "published": "2023-11-24T13:09:34Z",
            "summary": "Reinforcement Learning from Human Feedback (RLHF) is used to align large\nlanguage models to produce helpful and harmless responses. Yet, prior work\nshowed these models can be jailbroken by finding adversarial prompts that\nrevert the model to its unaligned behavior. In this paper, we consider a new\nthreat where an attacker poisons the RLHF training data to embed a \"jailbreak\nbackdoor\" into the model. The backdoor embeds a trigger word into the model\nthat acts like a universal \"sudo command\": adding the trigger word to any\nprompt enables harmful responses without the need to search for an adversarial\nprompt. Universal jailbreak backdoors are much more powerful than previously\nstudied backdoors on language models, and we find they are significantly harder\nto plant using common backdoor attack techniques. We investigate the design\ndecisions in RLHF that contribute to its purported robustness, and release a\nbenchmark of poisoned models to stimulate future research on universal\njailbreak backdoors.",
            "author": [
                "Javier Rando",
                "Florian Tram\u00e8r"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14455v1",
                "http://arxiv.org/pdf/2311.14455v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14450v1",
            "title": "Segment (Almost) Nothing: Prompt-Agnostic Adversarial Attacks on\n  Segmentation Models",
            "updated": "2023-11-24T12:57:34Z",
            "published": "2023-11-24T12:57:34Z",
            "summary": "General purpose segmentation models are able to generate (semantic)\nsegmentation masks from a variety of prompts, including visual (points, boxed,\netc.) and textual (object names) ones. In particular, input images are\npre-processed by an image encoder to obtain embedding vectors which are later\nused for mask predictions. Existing adversarial attacks target the end-to-end\ntasks, i.e. aim at altering the segmentation mask predicted for a specific\nimage-prompt pair. However, this requires running an individual attack for each\nnew prompt for the same image. We propose instead to generate prompt-agnostic\nadversarial attacks by maximizing the $\\ell_2$-distance, in the latent space,\nbetween the embedding of the original and perturbed images. Since the encoding\nprocess only depends on the image, distorted image representations will cause\nperturbations in the segmentation masks for a variety of prompts. We show that\neven imperceptible $\\ell_\\infty$-bounded perturbations of radius\n$\\epsilon=1/255$ are often sufficient to drastically modify the masks predicted\nwith point, box and text prompts by recently proposed foundation models for\nsegmentation. Moreover, we explore the possibility of creating universal, i.e.\nnon image-specific, attacks which can be readily applied to any input without\nfurther computational cost.",
            "author": [
                "Francesco Croce",
                "Matthias Hein"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14450v1",
                "http://arxiv.org/pdf/2311.14450v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14448v1",
            "title": "Deep Learning for Automatic Strain Quantification in Arrhythmogenic\n  Right Ventricular Cardiomyopathy",
            "updated": "2023-11-24T12:55:36Z",
            "published": "2023-11-24T12:55:36Z",
            "summary": "Quantification of cardiac motion with cine Cardiac Magnetic Resonance Imaging\n(CMRI) is an integral part of arrhythmogenic right ventricular cardiomyopathy\n(ARVC) diagnosis. Yet, the expert evaluation of motion abnormalities with CMRI\nis a challenging task. To automatically assess cardiac motion, we register\nCMRIs from different time points of the cardiac cycle using Implicit Neural\nRepresentations (INRs) and perform a biomechanically informed regularization\ninspired by the myocardial incompressibility assumption. To enhance the\nregistration performance, our method first rectifies the inter-slice\nmisalignment inherent to CMRI by performing a rigid registration guided by the\nlong-axis views, and then increases the through-plane resolution using an\nunsupervised deep learning super-resolution approach. Finally, we propose to\nsynergically combine information from short-axis and 4-chamber long-axis views,\nalong with an initialization to incorporate information from multiple cardiac\ntime points. Thereafter, to quantify cardiac motion, we calculate global and\nsegmental strain over a cardiac cycle and compute the peak strain. The\nevaluation of the method is performed on a dataset of cine CMRI scans from 47\nARVC patients and 67 controls. Our results show that inter-slice alignment and\ngeneration of super-resolved volumes combined with joint analysis of the two\ncardiac views, notably improves registration performance. Furthermore, the\nproposed initialization yields more physiologically plausible registrations.\nThe significant differences in the peak strain, discerned between the ARVC\npatients and healthy controls suggest that automated motion quantification\nmethods may assist in diagnosis and provide further understanding of\ndisease-specific alterations of cardiac motion.",
            "author": [
                "Laura Alvarez-Florez",
                "J\u00f6rg Sander",
                "Mimount Bourfiss",
                "Fleur V. Y. Tjong",
                "Birgitta K. Velthuis",
                "Ivana I\u0161gum"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14448v1",
                "http://arxiv.org/pdf/2311.14448v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14443v1",
            "title": "Petit programming language and compiler",
            "updated": "2023-11-24T12:36:35Z",
            "published": "2023-11-24T12:36:35Z",
            "summary": "Petit is an educational programming language for learning compilers. Students\nembark on the journey of learning compilers through a series of six tutorials,\nprogressing from topics like lexical analysis and syntactic analysis to\nsemantic analysis and code generation. The initial tutorials in this series\ncover the practical applications of the lex and yacc tools, while the\nconcluding tutorial focuses on generating LLVM intermediate representation.",
            "author": [
                "Raul Barbosa"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14443v1",
                "http://arxiv.org/pdf/2311.14443v1"
            ],
            "primary_category": "cs.PL",
            "category": [
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14435v1",
            "title": "GCPV: Guided Concept Projection Vectors for the Explainable Inspection\n  of CNN Feature Spaces",
            "updated": "2023-11-24T12:22:00Z",
            "published": "2023-11-24T12:22:00Z",
            "summary": "For debugging and verification of computer vision convolutional deep neural\nnetworks (CNNs) human inspection of the learned latent representations is\nimperative. Therefore, state-of-the-art eXplainable Artificial Intelligence\n(XAI) methods globally associate given natural language semantic concepts with\nrepresenting vectors or regions in the CNN latent space supporting manual\ninspection. Yet, this approach comes with two major disadvantages: They are\nlocally inaccurate when reconstructing a concept label and discard information\nabout the distribution of concept instance representations. The latter, though,\nis of particular interest for debugging, like finding and understanding\noutliers, learned notions of sub-concepts, and concept confusion. Furthermore,\ncurrent single-layer approaches neglect that information about a concept may be\nspread over the CNN depth. To overcome these shortcomings, we introduce the\nlocal-to-global Guided Concept Projection Vectors (GCPV) approach: It (1)\ngenerates local concept vectors that each precisely reconstruct a concept\nsegmentation label, and then (2) generalizes these to global concept and even\nsub-concept vectors by means of hiearchical clustering. Our experiments on\nobject detectors demonstrate improved performance compared to the\nstate-of-the-art, the benefit of multi-layer concept vectors, and robustness\nagainst low-quality concept segmentation labels. Finally, we demonstrate that\nGCPVs can be applied to find root causes for confusion of concepts like bus and\ntruck, and reveal interesting concept-level outliers. Thus, GCPVs pose a\npromising step towards interpretable model debugging and informed data\nimprovement.",
            "author": [
                "Georgii Mikriukov",
                "Gesina Schwalbe",
                "Christian Hellert",
                "Korinna Bade"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14435v1",
                "http://arxiv.org/pdf/2311.14435v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14770v1",
            "title": "Learning to Cooperate and Communicate Over Imperfect Channels",
            "updated": "2023-11-24T12:15:48Z",
            "published": "2023-11-24T12:15:48Z",
            "summary": "Information exchange in multi-agent systems improves the cooperation among\nagents, especially in partially observable settings. In the real world,\ncommunication is often carried out over imperfect channels. This requires\nagents to handle uncertainty due to potential information loss. In this paper,\nwe consider a cooperative multi-agent system where the agents act and exchange\ninformation in a decentralized manner using a limited and unreliable channel.\nTo cope with such channel constraints, we propose a novel communication\napproach based on independent Q-learning. Our method allows agents to\ndynamically adapt how much information to share by sending messages of\ndifferent sizes, depending on their local observations and the channel's\nproperties. In addition to this message size selection, agents learn to encode\nand decode messages to improve their jointly trained policies. We show that our\napproach outperforms approaches without adaptive capabilities in a novel\ncooperative digit-prediction environment and discuss its limitations in the\ntraffic junction environment.",
            "author": [
                "Jannis Weil",
                "Gizem Ekinci",
                "Heinz Koeppl",
                "Tobias Meuser"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14770v1",
                "http://arxiv.org/pdf/2311.14770v1"
            ],
            "primary_category": "cs.MA",
            "category": [
                "cs.MA",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14431v1",
            "title": "What you need to know about a learning robot: Identifying the enabling\n  architecture of complex systems",
            "updated": "2023-11-24T12:14:52Z",
            "published": "2023-11-24T12:14:52Z",
            "summary": "Nowadays, we are dealing more and more with robots and AI in everyday life.\nHowever, their behavior is not always apparent to most lay users, especially in\nerror situations. As a result, there can be misconceptions about the behavior\nof the technologies in use. This, in turn, can lead to misuse and rejection by\nusers. Explanation, for example, through transparency, can address these\nmisconceptions. However, it would be confusing and overwhelming for users if\nthe entire software or hardware was explained. Therefore, this paper looks at\nthe 'enabling' architecture. It describes those aspects of a robotic system\nthat might need to be explained to enable someone to use the technology\neffectively. Furthermore, this paper is concerned with the 'explanandum', which\nis the corresponding misunderstanding or missing concepts of the enabling\narchitecture that needs to be clarified. We have thus developed and present an\napproach for determining this 'enabling' architecture and the resulting\n'explanandum' of complex technologies.",
            "author": [
                "Helen Beierling",
                "Phillip Richter",
                "Mara Brandt",
                "Lutz Terfloth",
                "Carsten Schulte",
                "Heiko Wersing",
                "Anna-Lisa Vollmer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14431v1",
                "http://arxiv.org/pdf/2311.14431v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14427v1",
            "title": "Disentangling the Spectral Properties of the Hodge Laplacian: Not All\n  Small Eigenvalues Are Equal",
            "updated": "2023-11-24T12:00:50Z",
            "published": "2023-11-24T12:00:50Z",
            "summary": "The rich spectral information of the graph Laplacian has been instrumental in\ngraph theory, machine learning, and graph signal processing for applications\nsuch as graph classification, clustering, or eigenmode analysis. Recently, the\nHodge Laplacian has come into focus as a generalisation of the ordinary\nLaplacian for higher-order graph models such as simplicial and cellular\ncomplexes. Akin to the traditional analysis of graph Laplacians, many authors\nanalyse the smallest eigenvalues of the Hodge Laplacian, which are connected to\nimportant topological properties such as homology. However, small eigenvalues\nof the Hodge Laplacian can carry different information depending on whether\nthey are related to curl or gradient eigenmodes, and thus may not be\ncomparable. We therefore introduce the notion of persistent eigenvector\nsimilarity and provide a method to track individual harmonic, curl, and\ngradient eigenvectors/-values through the so-called persistence filtration,\nleveraging the full information contained in the Hodge-Laplacian spectrum\nacross all possible scales of a point cloud. Finally, we use our insights (a)\nto introduce a novel form of topological spectral clustering and (b) to\nclassify edges and higher-order simplices based on their relationship to the\nsmallest harmonic, curl, and gradient eigenvectors.",
            "author": [
                "Vincent P. Grande",
                "Michael T. Schaub"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14427v1",
                "http://arxiv.org/pdf/2311.14427v1"
            ],
            "primary_category": "math.AT",
            "category": [
                "math.AT",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14426v1",
            "title": "Human-Machine Cooperative Multimodal Learning Method for Cross-subject\n  Olfactory Preference Recognition",
            "updated": "2023-11-24T11:59:11Z",
            "published": "2023-11-24T11:59:11Z",
            "summary": "Odor sensory evaluation has a broad application in food, clothing, cosmetics,\nand other fields. Traditional artificial sensory evaluation has poor\nrepeatability, and the machine olfaction represented by the electronic nose\n(E-nose) is difficult to reflect human feelings. Olfactory electroencephalogram\n(EEG) contains odor and individual features associated with human olfactory\npreference, which has unique advantages in odor sensory evaluation. However,\nthe difficulty of cross-subject olfactory EEG recognition greatly limits its\napplication. It is worth noting that E-nose and olfactory EEG are more\nadvantageous in representing odor information and individual emotions,\nrespectively. In this paper, an E-nose and olfactory EEG multimodal learning\nmethod is proposed for cross-subject olfactory preference recognition. Firstly,\nthe olfactory EEG and E-nose multimodal data acquisition and preprocessing\nparadigms are established. Secondly, a complementary multimodal data mining\nstrategy is proposed to effectively mine the common features of multimodal data\nrepresenting odor information and the individual features in olfactory EEG\nrepresenting individual emotional information. Finally, the cross-subject\nolfactory preference recognition is achieved in 24 subjects by fusing the\nextracted common and individual features, and the recognition effect is\nsuperior to the state-of-the-art recognition methods. Furthermore, the\nadvantages of the proposed method in cross-subject olfactory preference\nrecognition indicate its potential for practical odor evaluation applications.",
            "author": [
                "Xiuxin Xia",
                "Yuchen Guo",
                "Yanwei Wang",
                "Yuchao Yang",
                "Yan Shi",
                "Hong Men"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14426v1",
                "http://arxiv.org/pdf/2311.14426v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.00803v1",
            "title": "InceptionCaps: A Performant Glaucoma Classification Model for\n  Data-scarce Environment",
            "updated": "2023-11-24T11:58:11Z",
            "published": "2023-11-24T11:58:11Z",
            "summary": "Glaucoma is an irreversible ocular disease and is the second leading cause of\nvisual disability worldwide. Slow vision loss and the asymptomatic nature of\nthe disease make its diagnosis challenging. Early detection is crucial for\npreventing irreversible blindness. Ophthalmologists primarily use retinal\nfundus images as a non-invasive screening method. Convolutional neural networks\n(CNN) have demonstrated high accuracy in the classification of medical images.\nNevertheless, CNN's translation-invariant nature and inability to handle the\npart-whole relationship between objects make its direct application unsuitable\nfor glaucomatous fundus image classification, as it requires a large number of\nlabelled images for training. This work reviews existing state of the art\nmodels and proposes InceptionCaps, a novel capsule network (CapsNet) based deep\nlearning model having pre-trained InceptionV3 as its convolution base, for\nautomatic glaucoma classification. InceptionCaps achieved an accuracy of 0.956,\nspecificity of 0.96, and AUC of 0.9556, which surpasses several\nstate-of-the-art deep learning model performances on the RIM-ONE v2 dataset.\nThe obtained result demonstrates the robustness of the proposed deep learning\nmodel.",
            "author": [
                "Gyanendar Manohar",
                "Ruairi O'Reilly"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00803v1",
                "http://arxiv.org/pdf/2312.00803v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14421v1",
            "title": "Approximation of Convex Envelope Using Reinforcement Learning",
            "updated": "2023-11-24T11:47:08Z",
            "published": "2023-11-24T11:47:08Z",
            "summary": "Oberman gave a stochastic control formulation of the problem of estimating\nthe convex envelope of a non-convex function. Based on this, we develop a\nreinforcement learning scheme to approximate the convex envelope, using a\nvariant of Q-learning for controlled optimal stopping. It shows very promising\nresults on a standard library of test problems.",
            "author": [
                "Vivek S. Borkar",
                "Adit Akarsh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14421v1",
                "http://arxiv.org/pdf/2311.14421v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14768v1",
            "title": "AdaDiff: Adaptive Step Selection for Fast Diffusion",
            "updated": "2023-11-24T11:20:38Z",
            "published": "2023-11-24T11:20:38Z",
            "summary": "Diffusion models, as a type of generative models, have achieved impressive\nresults in generating images and videos conditioned on textual conditions.\nHowever, the generation process of diffusion models involves denoising for\ndozens of steps to produce photorealistic images/videos, which is\ncomputationally expensive. Unlike previous methods that design\n``one-size-fits-all'' approaches for speed up, we argue denoising steps should\nbe sample-specific conditioned on the richness of input texts. To this end, we\nintroduce AdaDiff, a lightweight framework designed to learn instance-specific\nstep usage policies, which are then used by the diffusion model for generation.\nAdaDiff is optimized using a policy gradient method to maximize a carefully\ndesigned reward function, balancing inference time and generation quality. We\nconduct experiments on three image generation and two video generation\nbenchmarks and demonstrate that our approach achieves similar results in terms\nof visual quality compared to the baseline using a fixed 50 denoising steps\nwhile reducing inference time by at least 33%, going as high as 40%.\nFurthermore, our qualitative analysis shows that our method allocates more\nsteps to more informative text conditions and fewer steps to simpler text\nconditions.",
            "author": [
                "Hui Zhang",
                "Zuxuan Wu",
                "Zhen Xing",
                "Jie Shao",
                "Yu-Gang Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14768v1",
                "http://arxiv.org/pdf/2311.14768v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14414v1",
            "title": "Deformable multi-modal image registration for the correlation between\n  optical measurements and histology images",
            "updated": "2023-11-24T11:14:39Z",
            "published": "2023-11-24T11:14:39Z",
            "summary": "The correlation of optical measurements with a correct pathology label is\noften hampered by imprecise registration caused by deformations in histology\nimages. This study explores an automated multi-modal image registration\ntechnique utilizing deep learning principles to align snapshot breast specimen\nimages with corresponding histology images. The input images, acquired through\ndifferent modalities, present challenges due to variations in intensities and\nstructural visibility, making linear assumptions inappropriate. An unsupervised\nand supervised learning approach, based on the VoxelMorph model, was explored,\nmaking use of a dataset with manually registered images used as ground truth.\nEvaluation metrics, including Dice scores and mutual information, reveal that\nthe unsupervised model outperforms the supervised (and manual approach)\nsignificantly, achieving superior image alignment. This automated registration\napproach holds promise for improving the validation of optical technologies by\nminimizing human errors and inconsistencies associated with manual\nregistration.",
            "author": [
                "Lianne Feenstra",
                "Maud Lambregts",
                "Theo J. M Ruers",
                "Behdad Dashtbozorg"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14414v1",
                "http://arxiv.org/pdf/2311.14414v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14412v2",
            "title": "A Comparison of PDF Projection with Normalizing Flows and SurVAE",
            "updated": "2023-11-27T07:20:42Z",
            "published": "2023-11-24T11:12:26Z",
            "summary": "Normalizing flows (NF) recently gained attention as a way to construct\ngenerative networks with exact likelihood calculation out of composable layers.\nHowever, NF is restricted to dimension-preserving transformations. Surjection\nVAE (SurVAE) has been proposed to extend NF to dimension-altering\ntransformations. Such networks are desirable because they are expressive and\ncan be precisely trained. We show that the approaches are a re-invention of PDF\nprojection, which appeared over twenty years earlier and is much further\ndeveloped.",
            "author": [
                "Paul M. Baggenstoss",
                "Felix Govaers"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14412v2",
                "http://arxiv.org/pdf/2311.14412v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14410v1",
            "title": "Unveiling The Factors of Aesthetic Preferences with Explainable AI",
            "updated": "2023-11-24T11:06:22Z",
            "published": "2023-11-24T11:06:22Z",
            "summary": "The allure of aesthetic appeal in images captivates our senses, yet the\nunderlying intricacies of aesthetic preferences remain elusive. In this study,\nwe pioneer a novel perspective by utilizing machine learning models that focus\non aesthetic attributes known to influence preferences. Through a data mining\napproach, our models process these attributes as inputs to predict the\naesthetic scores of images. Moreover, to delve deeper and obtain interpretable\nexplanations regarding the factors driving aesthetic preferences, we utilize\nthe popular Explainable AI (XAI) technique known as SHapley Additive\nexPlanations (SHAP). Our methodology involves employing various machine\nlearning models, including Random Forest, XGBoost, Support Vector Regression,\nand Multilayer Perceptron, to compare their performances in accurately\npredicting aesthetic scores, and consistently observing results in conjunction\nwith SHAP. We conduct experiments on three image aesthetic benchmarks,\nproviding insights into the roles of attributes and their interactions.\nUltimately, our study aims to shed light on the complex nature of aesthetic\npreferences in images through machine learning and provides a deeper\nunderstanding of the attributes that influence aesthetic judgements.",
            "author": [
                "Derya Soydaner",
                "Johan Wagemans"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14410v1",
                "http://arxiv.org/pdf/2311.14410v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14407v1",
            "title": "LLamol: A Dynamic Multi-Conditional Generative Transformer for De Novo\n  Molecular Design",
            "updated": "2023-11-24T10:59:12Z",
            "published": "2023-11-24T10:59:12Z",
            "summary": "Generative models have demonstrated substantial promise in Natural Language\nProcessing (NLP) and have found application in designing molecules, as seen in\nGeneral Pretrained Transformer (GPT) models. In our efforts to develop such a\ntool for exploring the organic chemical space in search of potentially\nelectro-active compounds, we present \"LLamol\", a single novel generative\ntransformer model based on the LLama 2 architecture, which was trained on a 13M\nsuperset of organic compounds drawn from diverse public sources. To allow for a\nmaximum flexibility in usage and robustness in view of potentially incomplete\ndata, we introduce \"Stochastic Context Learning\" as a new training procedure.\nWe demonstrate that the resulting model adeptly handles single- and\nmulti-conditional organic molecule generation with up to four conditions, yet\nmore are possible. The model generates valid molecular structures in SMILES\nnotation while flexibly incorporating three numerical and/or one token sequence\ninto the generative process, just as requested. The generated compounds are\nvery satisfactory in all scenarios tested. In detail, we showcase the model's\ncapability to utilize token sequences for conditioning, either individually or\nin combination with numerical properties, making LLamol a potent tool for de\nnovo molecule design, easily expandable with new properties.",
            "author": [
                "Niklas Dobberstein",
                "Astrid Maass",
                "Jan Hamaekers"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14407v1",
                "http://arxiv.org/pdf/2311.14407v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14404v1",
            "title": "BHGNN-RT: Network embedding for directed heterogeneous graphs",
            "updated": "2023-11-24T10:56:09Z",
            "published": "2023-11-24T10:56:09Z",
            "summary": "Networks are one of the most valuable data structures for modeling problems\nin the real world. However, the most recent node embedding strategies have\nfocused on undirected graphs, with limited attention to directed graphs,\nespecially directed heterogeneous graphs. In this study, we first investigated\nthe network properties of directed heterogeneous graphs. Based on network\nanalysis, we proposed an embedding method, a bidirectional heterogeneous graph\nneural network with random teleport (BHGNN-RT), for directed heterogeneous\ngraphs, that leverages bidirectional message-passing process and network\nheterogeneity. With the optimization of teleport proportion, BHGNN-RT is\nbeneficial to overcome the over-smoothing problem. Extensive experiments on\nvarious datasets were conducted to verify the efficacy and efficiency of\nBHGNN-RT. Furthermore, we investigated the effects of message components, model\nlayer, and teleport proportion on model performance. The performance comparison\nwith all other baselines illustrates that BHGNN-RT achieves state-of-the-art\nperformance, outperforming the benchmark methods in both node classification\nand unsupervised clustering tasks.",
            "author": [
                "Xiyang Sun",
                "Fumiyasu Komaki"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14404v1",
                "http://arxiv.org/pdf/2311.14404v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14402v1",
            "title": "TEA: Test-time Energy Adaptation",
            "updated": "2023-11-24T10:49:49Z",
            "published": "2023-11-24T10:49:49Z",
            "summary": "Test-time adaptation (TTA) aims to improve model generalizability when test\ndata diverges from training distribution, offering the distinct advantage of\nnot requiring access to training data and processes, especially valuable in the\ncontext of large pre-trained models. However, current TTA methods fail to\naddress the fundamental issue: covariate shift, i.e., the decreased\ngeneralizability can be attributed to the model's reliance on the marginal\ndistribution of the training data, which may impair model calibration and\nintroduce confirmation bias. To address this, we propose a novel energy-based\nperspective, enhancing the model's perception of target data distributions\nwithout requiring access to training data or processes. Building on this\nperspective, we introduce $\\textbf{T}$est-time $\\textbf{E}$nergy\n$\\textbf{A}$daptation ($\\textbf{TEA}$), which transforms the trained classifier\ninto an energy-based model and aligns the model's distribution with the test\ndata's, enhancing its ability to perceive test distributions and thus improving\noverall generalizability. Extensive experiments across multiple tasks,\nbenchmarks and architectures demonstrate TEA's superior generalization\nperformance against state-of-the-art methods. Further in-depth analyses reveal\nthat TEA can equip the model with a comprehensive perception of test\ndistribution, ultimately paving the way toward improved generalization and\ncalibration.",
            "author": [
                "Yige Yuan",
                "Bingbing Xu",
                "Liang Hou",
                "Fei Sun",
                "Huawei Shen",
                "Xueqi Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14402v1",
                "http://arxiv.org/pdf/2311.14402v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.00042v1",
            "title": "DeepTreeGANv2: Iterative Pooling of Point Clouds",
            "updated": "2023-11-24T10:42:11Z",
            "published": "2023-11-24T10:42:11Z",
            "summary": "In High Energy Physics, detailed and time-consuming simulations are used for\nparticle interactions with detectors. To bypass these simulations with a\ngenerative model, the generation of large point clouds in a short time is\nrequired, while the complex dependencies between the particles must be\ncorrectly modelled. Particle showers are inherently tree-based processes, as\neach particle is produced by the decay or detector interaction of a particle of\nthe previous generation. In this work, we present a significant extension to\nDeepTreeGAN, featuring a critic, that is able to aggregate such point clouds\niteratively in a tree-based manner. We show that this model can reproduce\ncomplex distributions, and we evaluate its performance on the public JetNet 150\ndataset.",
            "author": [
                "Moritz Alfons Wilhelm Scham",
                "Dirk Kr\u00fccker",
                "Kerstin Borras"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00042v1",
                "http://arxiv.org/pdf/2312.00042v1"
            ],
            "primary_category": "physics.data-an",
            "category": [
                "physics.data-an",
                "cs.LG",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14401v1",
            "title": "Prototype of deployment of Federated Learning with IoT devices",
            "updated": "2023-11-24T10:37:30Z",
            "published": "2023-11-24T10:37:30Z",
            "summary": "In the age of technology, data is an increasingly important resource. This\nimportance is growing in the field of Artificial Intelligence (AI), where sub\nfields such as Machine Learning (ML) need more and more data to achieve better\nresults. Internet of Things (IoT) is the connection of sensors and smart\nobjects to collect and exchange data, in addition to achieving many other\ntasks. A huge amount of the resource desired, data, is stored in mobile\ndevices, sensors and other Internet of Things (IoT) devices, but remains there\ndue to data protection restrictions. At the same time these devices do not have\nenough data or computational capacity to train good models. Moreover,\ntransmitting, storing and processing all this data on a centralised server is\nproblematic. Federated Learning (FL) provides an innovative solution that\nallows devices to learn in a collaborative way. More importantly, it\naccomplishes this without violating data protection laws. FL is currently\ngrowing, and there are several solutions that implement it. This article\npresents a prototype of a FL solution where the IoT devices used were raspberry\npi boards. The results compare the performance of a solution of this type with\nthose obtained in traditional approaches. In addition, the FL solution\nperformance was tested in a hostile environment. A convolutional neural network\n(CNN) and a image data set were used. The results show the feasibility and\nusability of these techniques, although in many cases they do not reach the\nperformance of traditional approaches.",
            "author": [
                "Pablo Garc\u00eda Santaclara",
                "Ana Fern\u00e1ndez Vilas",
                "Rebeca P. D\u00edaz Redondo"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3551663.3558681",
                "http://arxiv.org/abs/2311.14401v1",
                "http://arxiv.org/pdf/2311.14401v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14395v1",
            "title": "Multi-scale Semantic Correlation Mining for Visible-Infrared Person\n  Re-Identification",
            "updated": "2023-11-24T10:23:57Z",
            "published": "2023-11-24T10:23:57Z",
            "summary": "The main challenge in the Visible-Infrared Person Re-Identification (VI-ReID)\ntask lies in how to extract discriminative features from different modalities\nfor matching purposes. While the existing well works primarily focus on\nminimizing the modal discrepancies, the modality information can not thoroughly\nbe leveraged. To solve this problem, a Multi-scale Semantic Correlation Mining\nnetwork (MSCMNet) is proposed to comprehensively exploit semantic features at\nmultiple scales and simultaneously reduce modality information loss as small as\npossible in feature extraction. The proposed network contains three novel\ncomponents. Firstly, after taking into account the effective utilization of\nmodality information, the Multi-scale Information Correlation Mining Block\n(MIMB) is designed to explore semantic correlations across multiple scales.\nSecondly, in order to enrich the semantic information that MIMB can utilize, a\nquadruple-stream feature extractor (QFE) with non-shared parameters is\nspecifically designed to extract information from different dimensions of the\ndataset. Finally, the Quadruple Center Triplet Loss (QCT) is further proposed\nto address the information discrepancy in the comprehensive features. Extensive\nexperiments on the SYSU-MM01, RegDB, and LLCM datasets demonstrate that the\nproposed MSCMNet achieves the greatest accuracy.",
            "author": [
                "Ke Cheng",
                "Xuecheng Hua",
                "Hu Lu",
                "Juanjuan Tu",
                "Yuanquan Wang",
                "Shitong Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14395v1",
                "http://arxiv.org/pdf/2311.14395v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14767v1",
            "title": "Low-Cost HEM with Arduino and Zigbee Technologies in the Energy Sector\n  in Colombia",
            "updated": "2023-11-24T10:19:21Z",
            "published": "2023-11-24T10:19:21Z",
            "summary": "Since no solutions have been proposed in Colombia that seek to reduce the\nconsumption of electricity at the residential level, this paper describes the\ndesign and implementation of a simple prototype of a low-cost home energy\nmanagement system (HEMS). The objective of this plat-form is to monitor the\nenergy consumption of typical household devices so that users can access the\nconsumption of each device separately and then establish the strategy that\nallows them to reduce energy consumption at home. In order to demonstrate that\nour system is viable, the system has been evaluated by measuring weekly energy\nconsumption with the on-line and off-line HEMS using a test bench with typical\nhousehold devices in a Sincelejo typical household. The evaluation has shown\nthat with the installation of this HEMS, consumption is reduced by 27%. This\nshows that it is possible to achieve a good reduction percentage with a\nlow-cost system.",
            "author": [
                "Zurisaddai de la Cruz Severiche Maury",
                "Ana Fernandez Vilas",
                "Rebeca Diaz Redondo"
            ],
            "link": [
                "http://dx.doi.org/10.3390/en15103819",
                "http://arxiv.org/abs/2311.14767v1",
                "http://arxiv.org/pdf/2311.14767v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.AI",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14390v1",
            "title": "Directly Attention Loss Adjusted Prioritized Experience Replay",
            "updated": "2023-11-24T10:14:05Z",
            "published": "2023-11-24T10:14:05Z",
            "summary": "Prioritized Experience Replay (PER) enables the model to learn more about\nrelatively important samples by artificially changing their accessed\nfrequencies. However, this non-uniform sampling method shifts the state-action\ndistribution that is originally used to estimate Q-value functions, which\nbrings about the estimation deviation. In this article, an novel off policy\nreinforcement learning training framework called Directly Attention Loss\nAdjusted Prioritized Experience Replay (DALAP) is proposed, which can directly\nquantify the changed extent of the shifted distribution through Parallel\nSelf-Attention network, so as to accurately compensate the error. In addition,\na Priority-Encouragement mechanism is designed simultaneously to optimize the\nsample screening criterion, and further improve the training efficiency. In\norder to verify the effectiveness and generality of DALAP, we integrate it with\nthe value-function based, the policy-gradient based and multi-agent\nreinforcement learning algorithm, respectively. The multiple groups of\ncomparative experiments show that DALAP has the significant advantages of both\nimproving the convergence rate and reducing the training variance.",
            "author": [
                "Zhuoying Chen",
                "Huiping Li",
                "Zhaoxu Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14390v1",
                "http://arxiv.org/pdf/2311.14390v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14388v2",
            "title": "A Parameterized Generative Adversarial Network Using Cyclic Projection\n  for Explainable Medical Image Classification",
            "updated": "2023-12-07T12:20:25Z",
            "published": "2023-11-24T10:07:14Z",
            "summary": "Although current data augmentation methods are successful to alleviate the\ndata insufficiency, conventional augmentation are primarily intra-domain while\nadvanced generative adversarial networks (GANs) generate images remaining\nuncertain, particularly in small-scale datasets. In this paper, we propose a\nparameterized GAN (ParaGAN) that effectively controls the changes of synthetic\nsamples among domains and highlights the attention regions for downstream\nclassification. Specifically, ParaGAN incorporates projection distance\nparameters in cyclic projection and projects the source images to the decision\nboundary to obtain the class-difference maps. Our experiments show that ParaGAN\ncan consistently outperform the existing augmentation methods with explainable\nclassification on two small-scale medical datasets.",
            "author": [
                "Xiangyu Xiong",
                "Yue Sun",
                "Xiaohong Liu",
                "Chan-Tong Lam",
                "Tong Tong",
                "Hao Chen",
                "Qinquan Gao",
                "Wei Ke",
                "Tao Tan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14388v2",
                "http://arxiv.org/pdf/2311.14388v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14387v1",
            "title": "Achieving Margin Maximization Exponentially Fast via Progressive Norm\n  Rescaling",
            "updated": "2023-11-24T10:07:10Z",
            "published": "2023-11-24T10:07:10Z",
            "summary": "In this work, we investigate the margin-maximization bias exhibited by\ngradient-based algorithms in classifying linearly separable data. We present an\nin-depth analysis of the specific properties of the velocity field associated\nwith (normalized) gradients, focusing on their role in margin maximization.\nInspired by this analysis, we propose a novel algorithm called Progressive\nRescaling Gradient Descent (PRGD) and show that PRGD can maximize the margin at\nan {\\em exponential rate}. This stands in stark contrast to all existing\nalgorithms, which maximize the margin at a slow {\\em polynomial rate}.\nSpecifically, we identify mild conditions on data distribution under which\nexisting algorithms such as gradient descent (GD) and normalized gradient\ndescent (NGD) {\\em provably fail} in maximizing the margin efficiently. To\nvalidate our theoretical findings, we present both synthetic and real-world\nexperiments. Notably, PRGD also shows promise in enhancing the generalization\nperformance when applied to linearly non-separable datasets and deep neural\nnetworks.",
            "author": [
                "Mingze Wang",
                "Zeping Min",
                "Lei Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14387v1",
                "http://arxiv.org/pdf/2311.14387v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14386v1",
            "title": "Collective Memory, Consensus, and Learning explained by Network\n  Connectivity",
            "updated": "2023-11-24T10:05:48Z",
            "published": "2023-11-24T10:05:48Z",
            "summary": "Humans cluster in social groups where they discuss their shared past,\nproblems, and potential solutions, learn collectively when they repeat\nactivities, synchronize when they sing or dance together, and bond through\nsocial cohesion. By representing a group network by a Laplacian matrix, the\noutcomes of these activities, as well as group's cohesion, can be predicted by\nits second smallest eigenvalue, called algebraic connectivity. It predicts well\nwhen processes converge towards a consensus or focal activity, but it cannot\npredict divergence, such as division of labor or polarization.",
            "author": [
                "Jeroen Bruggeman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14386v1",
                "http://arxiv.org/pdf/2311.14386v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14379v1",
            "title": "Robot Learning in the Era of Foundation Models: A Survey",
            "updated": "2023-11-24T09:56:21Z",
            "published": "2023-11-24T09:56:21Z",
            "summary": "The proliferation of Large Language Models (LLMs) has s fueled a shift in\nrobot learning from automation towards general embodied Artificial Intelligence\n(AI). Adopting foundation models together with traditional learning methods to\nrobot learning has increasingly gained recent interest research community and\nshowed potential for real-life application. However, there are few literatures\ncomprehensively reviewing the relatively new technologies combined with\nrobotics. The purpose of this review is to systematically assess the\nstate-of-the-art foundation model techniques in the robot learning and to\nidentify future potential areas. Specifically, we first summarized the\ntechnical evolution of robot learning and identified the necessary preliminary\npreparations for foundation models including the simulators, datasets,\nfoundation model framework. In addition, we focused on the following four\nmainstream areas of robot learning including manipulation, navigation,\nplanning, and reasoning and demonstrated how the foundation model techniques\ncan be adopted in the above scenarios. Furthermore, critical issues which are\nneglected in the current literatures including robot hardware and software\ndecoupling, dynamic data, generalization performance with the presence of\nhuman, etc. were discussed. This review highlights the state-of-the-art\nprogress of foundation models in robot learning and future research should\nfocus on multimodal interaction especially dynamics data, exclusive foundation\nmodels for robots, and AI alignment, etc.",
            "author": [
                "Xuan Xiao",
                "Jiahang Liu",
                "Zhipeng Wang",
                "Yanmin Zhou",
                "Yong Qi",
                "Qian Cheng",
                "Bin He",
                "Shuo Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14379v1",
                "http://arxiv.org/pdf/2311.14379v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14371v1",
            "title": "Federated Transformed Learning for a Circular, Secure, and Tiny AI",
            "updated": "2023-11-24T09:33:33Z",
            "published": "2023-11-24T09:33:33Z",
            "summary": "Deep Learning (DL) is penetrating into a diverse range of mass mobility,\nsmart living, and industrial applications, rapidly transforming the way we live\nand work. DL is at the heart of many AI implementations. A key set of\nchallenges is to produce AI modules that are: (1) \"circular\" - can solve new\ntasks without forgetting how to solve previous ones, (2) \"secure\" - have\nimmunity to adversarial data attacks, and (3) \"tiny\" - implementable in low\npower low cost embedded hardware. Clearly it is difficult to achieve all three\naspects on a single horizontal layer of platforms, as the techniques require\ntransformed deep representations that incur different computation and\ncommunication requirements. Here we set out the vision to achieve transformed\nDL representations across a 5G and Beyond networked architecture. We first\ndetail the cross-sectoral motivations for each challenge area, before\ndemonstrating recent advances in DL research that can achieve circular, secure,\nand tiny AI (CST-AI). Recognising the conflicting demand of each transformed\ndeep representation, we federate their deep learning transformations and\nfunctionalities across the network to achieve connected run-time capabilities.",
            "author": [
                "Weisi Guo",
                "Schyler Sun",
                "Bin Li",
                "Sam Blakeman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14371v1",
                "http://arxiv.org/pdf/2311.14371v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14361v1",
            "title": "Deciphering and integrating invariants for neural operator learning with\n  various physical mechanisms",
            "updated": "2023-11-24T09:03:52Z",
            "published": "2023-11-24T09:03:52Z",
            "summary": "Neural operators have been explored as surrogate models for simulating\nphysical systems to overcome the limitations of traditional partial\ndifferential equation (PDE) solvers. However, most existing operator learning\nmethods assume that the data originate from a single physical mechanism,\nlimiting their applicability and performance in more realistic scenarios. To\nthis end, we propose Physical Invariant Attention Neural Operator (PIANO) to\ndecipher and integrate the physical invariants (PI) for operator learning from\nthe PDE series with various physical mechanisms. PIANO employs self-supervised\nlearning to extract physical knowledge and attention mechanisms to integrate\nthem into dynamic convolutional layers. Compared to existing techniques, PIANO\ncan reduce the relative error by 13.6\\%-82.2\\% on PDE forecasting tasks across\nvarying coefficients, forces, or boundary conditions. Additionally, varied\ndownstream tasks reveal that the PI embeddings deciphered by PIANO align well\nwith the underlying invariants in the PDE systems, verifying the physical\nsignificance of PIANO. The source code will be publicly available at:\nhttps://github.com/optray/PIANO.",
            "author": [
                "Rui Zhang",
                "Qi Meng",
                "Zhi-Ming Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14361v1",
                "http://arxiv.org/pdf/2311.14361v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NA",
                "math.NA",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14359v1",
            "title": "Thompson sampling for zero-inflated count outcomes with an application\n  to the Drink Less mobile health study",
            "updated": "2023-11-24T09:02:24Z",
            "published": "2023-11-24T09:02:24Z",
            "summary": "Mobile health (mHealth) technologies aim to improve distal outcomes, such as\nclinical conditions, by optimizing proximal outcomes through just-in-time\nadaptive interventions. Contextual bandits provide a suitable framework for\ncustomizing such interventions according to individual time-varying contexts,\nintending to maximize cumulative proximal outcomes. However, unique challenges\nsuch as modeling count outcomes within bandit frameworks have hindered the\nwidespread application of contextual bandits to mHealth studies. The current\nwork addresses this challenge by leveraging count data models into online\ndecision-making approaches. Specifically, we combine four common offline count\ndata models (Poisson, negative binomial, zero-inflated Poisson, and\nzero-inflated negative binomial regressions) with Thompson sampling, a popular\ncontextual bandit algorithm. The proposed algorithms are motivated by and\nevaluated on a real dataset from the Drink Less trial, where they are shown to\nimprove user engagement with the mHealth system. The proposed methods are\nfurther evaluated on simulated data, achieving improvement in maximizing\ncumulative proximal outcomes over existing algorithms. Theoretical results on\nregret bounds are also derived. A user-friendly R package countts that\nimplements the proposed methods for assessing contextual bandit algorithms is\nmade publicly available at https://cran.r-project.org/web/packages/countts.",
            "author": [
                "Xueqing Liu",
                "Nina Deliu",
                "Tanujit Chakraborty",
                "Lauren Bell",
                "Bibhas Chakraborty"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14359v1",
                "http://arxiv.org/pdf/2311.14359v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14349v1",
            "title": "DEUS: Distributed Electronic Patient File Update System",
            "updated": "2023-11-24T08:49:02Z",
            "published": "2023-11-24T08:49:02Z",
            "summary": "Inadequate availability of patient information is a major cause for medical\nerrors and affects costs in healthcare. Traditional approaches to information\nintegration in healthcare do not solve the problem. Applying a\ndocument-oriented paradigm to systems integration enables inter-institutional\ninformation exchange in healthcare. The goal of the proposed architecture is to\nprovide information exchange between strict autonomous healthcare institutions,\nbridging the gap between primary and secondary care. In a long-term healthcare\ndata distribution scenario, the patient has to maintain sovereignty over any\npersonal health information. Thus, the traditional publish-subscribe\narchitecture is extended by a phase of human mediation within the data flow.\nDEUS essentially decouples the roles of information author and information\npublisher into distinct actors, resulting in a triangular data flow. The\ninteraction scenario will be motivated. The significance of human mediation\nwill be discussed. DEUS provides a carefully distinguished actor and role model\nfor mediated pub-sub. The data flow between the participants is factored into\ndistinct phases of information interchange. The artefact model is decomposed\ninto role-dependent constituent parts. Both a domain specific (healthcare)\nterminology and a generic terminology is provided. From a technical\nperspective, the system design is presented. The sublayer for network transfer\nwill be highlighted as well as the subsystem for human-machine interaction.",
            "author": [
                "Christoph P. Neumann",
                "Florian Rampp",
                "Richard Lenz"
            ],
            "link": [
                "http://dx.doi.org/10.13140/RG.2.2.18075.23848",
                "http://arxiv.org/abs/2311.14349v1",
                "http://arxiv.org/pdf/2311.14349v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14342v2",
            "title": "AI-based Attack Graph Generation",
            "updated": "2023-11-27T07:22:24Z",
            "published": "2023-11-24T08:35:16Z",
            "summary": "With the advancement of IoT technology, many electronic devices are\ninterconnected through networks, communicating with each other and performing\nspecific roles. However, as numerous devices join networks, the threat of\ncyberattacks also escalates. Preventing and detecting cyber threats are\ncrucial, and one method of preventing such threats involves using attack\ngraphs. Attack graphs are widely used to assess security threats within\nnetworks. However, a drawback emerges as the network scales, as generating\nattack graphs becomes time-consuming. To overcome this limitation, artificial\nintelligence models can be employed. By utilizing AI models, attack graphs can\nbe created within a short period, approximating optimal outcomes. AI models\ndesigned for attack graph generation consist of encoders and decoders, trained\nusing reinforcement learning algorithms. After training the AI models, we\nconfirmed the model's learning effectiveness by observing changes in loss and\nreward values. Additionally, we compared attack graphs generated by the AI\nmodel with those created through conventional methods.",
            "author": [
                "Sangbeom Park",
                "Jaesung Lee",
                "Jeong Do Yoo",
                "Min Geun Song",
                "Hyosun Lee",
                "Jaewoong Choi",
                "Chaeyeon Sagong",
                "Huy Kang Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14342v2",
                "http://arxiv.org/pdf/2311.14342v2"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14339v1",
            "title": "Towards Concept-based Interpretability of Skin Lesion Diagnosis using\n  Vision-Language Models",
            "updated": "2023-11-24T08:31:34Z",
            "published": "2023-11-24T08:31:34Z",
            "summary": "Concept-based models naturally lend themselves to the development of\ninherently interpretable skin lesion diagnosis, as medical experts make\ndecisions based on a set of visual patterns of the lesion. Nevertheless, the\ndevelopment of these models depends on the existence of concept-annotated\ndatasets, whose availability is scarce due to the specialized knowledge and\nexpertise required in the annotation process. In this work, we show that\nvision-language models can be used to alleviate the dependence on a large\nnumber of concept-annotated samples. In particular, we propose an embedding\nlearning strategy to adapt CLIP to the downstream task of skin lesion\nclassification using concept-based descriptions as textual embeddings. Our\nexperiments reveal that vision-language models not only attain better accuracy\nwhen using concepts as textual embeddings, but also require a smaller number of\nconcept-annotated samples to attain comparable performance to approaches\nspecifically devised for automatic concept generation.",
            "author": [
                "Cristiano Patr\u00edcio",
                "Lu\u00eds F. Teixeira",
                "Jo\u00e3o C. Neves"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14339v1",
                "http://arxiv.org/pdf/2311.14339v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14335v1",
            "title": "Comparative Analysis of Transformers for Modeling Tabular Data: A\n  Casestudy using Industry Scale Dataset",
            "updated": "2023-11-24T08:16:39Z",
            "published": "2023-11-24T08:16:39Z",
            "summary": "We perform a comparative analysis of transformer-based models designed for\nmodeling tabular data, specifically on an industry-scale dataset. While earlier\nstudies demonstrated promising outcomes on smaller public or synthetic\ndatasets, the effectiveness did not extend to larger industry-scale datasets.\nThe challenges identified include handling high-dimensional data, the necessity\nfor efficient pre-processing of categorical and numerical features, and\naddressing substantial computational requirements.\n  To overcome the identified challenges, the study conducts an extensive\nexamination of various transformer-based models using both synthetic datasets\nand the default prediction Kaggle dataset (2022) from American Express. The\npaper presents crucial insights into optimal data pre-processing, compares\npre-training and direct supervised learning methods, discusses strategies for\nmanaging categorical and numerical features, and highlights trade-offs between\ncomputational resources and performance. Focusing on temporal financial data\nmodeling, the research aims to facilitate the systematic development and\ndeployment of transformer-based models in real-world scenarios, emphasizing\nscalability.",
            "author": [
                "Usneek Singh",
                "Piyush Arora",
                "Shamika Ganesan",
                "Mohit Kumar",
                "Siddhant Kulkarni",
                "Salil R. Joshi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14335v1",
                "http://arxiv.org/pdf/2311.14335v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14333v2",
            "title": "Cycle Invariant Positional Encoding for Graph Representation Learning",
            "updated": "2023-11-30T08:39:27Z",
            "published": "2023-11-24T08:15:54Z",
            "summary": "Cycles are fundamental elements in graph-structured data and have\ndemonstrated their effectiveness in enhancing graph learning models. To encode\nsuch information into a graph learning framework, prior works often extract a\nsummary quantity, ranging from the number of cycles to the more sophisticated\npersistence diagram summaries. However, more detailed information, such as\nwhich edges are encoded in a cycle, has not yet been used in graph neural\nnetworks. In this paper, we make one step towards addressing this gap, and\npropose a structure encoding module, called CycleNet, that encodes cycle\ninformation via edge structure encoding in a permutation invariant manner. To\nefficiently encode the space of all cycles, we start with a cycle basis (i.e.,\na minimal set of cycles generating the cycle space) which we compute via the\nkernel of the 1-dimensional Hodge Laplacian of the input graph. To guarantee\nthe encoding is invariant w.r.t. the choice of cycle basis, we encode the cycle\ninformation via the orthogonal projector of the cycle basis, which is inspired\nby BasisNet proposed by Lim et al. We also develop a more efficient variant\nwhich however requires that the input graph has a unique shortest cycle basis.\nTo demonstrate the effectiveness of the proposed module, we provide some\ntheoretical understandings of its expressive power. Moreover, we show via a\nrange of experiments that networks enhanced by our CycleNet module perform\nbetter in various benchmarks compared to several existing SOTA models.",
            "author": [
                "Zuoyu Yan",
                "Tengfei Ma",
                "Liangcai Gao",
                "Zhi Tang",
                "Chao Chen",
                "Yusu Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14333v2",
                "http://arxiv.org/pdf/2311.14333v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14332v1",
            "title": "GATGPT: A Pre-trained Large Language Model with Graph Attention Network\n  for Spatiotemporal Imputation",
            "updated": "2023-11-24T08:15:11Z",
            "published": "2023-11-24T08:15:11Z",
            "summary": "The analysis of spatiotemporal data is increasingly utilized across diverse\ndomains, including transportation, healthcare, and meteorology. In real-world\nsettings, such data often contain missing elements due to issues like sensor\nmalfunctions and data transmission errors. The objective of spatiotemporal\nimputation is to estimate these missing values by understanding the inherent\nspatial and temporal relationships in the observed multivariate time series.\nTraditionally, spatiotemporal imputation has relied on specific, intricate\narchitectures designed for this purpose, which suffer from limited\napplicability and high computational complexity. In contrast, our approach\nintegrates pre-trained large language models (LLMs) into spatiotemporal\nimputation, introducing a groundbreaking framework, GATGPT. This framework\nmerges a graph attention mechanism with LLMs. We maintain most of the LLM\nparameters unchanged to leverage existing knowledge for learning temporal\npatterns, while fine-tuning the upper layers tailored to various applications.\nThe graph attention component enhances the LLM's ability to understand spatial\nrelationships. Through tests on three distinct real-world datasets, our\ninnovative approach demonstrates comparable results to established deep\nlearning benchmarks.",
            "author": [
                "Yakun Chen",
                "Xianzhi Wang",
                "Guandong Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14332v1",
                "http://arxiv.org/pdf/2311.14332v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14329v1",
            "title": "Enabling Feedback-Free MIMO Transmission for FD-RAN: A Data-driven\n  Approach",
            "updated": "2023-11-24T08:08:14Z",
            "published": "2023-11-24T08:08:14Z",
            "summary": "To enhance flexibility and facilitate resource cooperation, a novel\nfully-decoupled radio access network (FD-RAN) architecture is proposed for 6G.\nHowever, the decoupling of uplink (UL) and downlink (DL) in FD-RAN makes the\nexisting feedback mechanism ineffective. To this end, we propose an end-to-end\ndata-driven MIMO solution without the conventional channel feedback procedure.\nData-driven MIMO can alleviate the drawbacks of feedback including overheads\nand delay, and can provide customized precoding design for different BSs based\non their historical channel data. It essentially learns a mapping from\ngeolocation to MIMO transmission parameters. We first present a codebook-based\napproach, which selects transmission parameters from the statistics of discrete\nchannel state information (CSI) values and utilizes integer interpolation for\nspatial inference. We further present a non-codebook-based approach, which 1)\nderives the optimal precoder from the singular value decomposition (SVD) of the\nchannel; 2) utilizes variational autoencoder (VAE) to select the representative\nprecoder from the latent Gaussian representations; and 3) exploits Gaussian\nprocess regression (GPR) to predict unknown precoders in the space domain.\nExtensive simulations are performed on a link-level 5G simulator using\nrealistic ray-tracing channel data. The results demonstrate the effectiveness\nof data-driven MIMO, showcasing its potential for application in FD-RAN and 6G.",
            "author": [
                "Jingbo Liu",
                "Jiacheng Chen",
                "Zongxi Liu",
                "Haibo Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14329v1",
                "http://arxiv.org/pdf/2311.14329v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14328v1",
            "title": "Offline Skill Generalization via Task and Motion Planning",
            "updated": "2023-11-24T08:06:55Z",
            "published": "2023-11-24T08:06:55Z",
            "summary": "This paper presents a novel approach to generalizing robot manipulation\nskills by combining a sampling-based task-and-motion planner with an offline\nreinforcement learning algorithm. Starting with a small library of scripted\nprimitive skills (e.g. Push) and object-centric symbolic predicates (e.g.\nOn(block, plate)), the planner autonomously generates a demonstration dataset\nof manipulation skills in the context of a long-horizon task. An offline\nreinforcement learning algorithm then extracts a policy from the dataset\nwithout further interactions with the environment and replaces the scripted\nskill in the existing library. Refining the skill library improves the\nrobustness of the planner, which in turn facilitates data collection for more\ncomplex manipulation skills. We validate our approach in simulation, on a\nblock-pushing task. We show that the proposed method requires less training\ndata than conventional reinforcement learning methods. Furthermore, interaction\nwith the environment is collision-free because of the use of planner\ndemonstrations, making the approach more amenable to persistent robot learning\nin the real world.",
            "author": [
                "Shin Watanabe",
                "Geir Horn",
                "Jim T\u00f8rresen",
                "Kai Olav Ellefsen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14328v1",
                "http://arxiv.org/pdf/2311.14328v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14324v1",
            "title": "Large Language Models as Topological Structure Enhancers for\n  Text-Attributed Graphs",
            "updated": "2023-11-24T07:53:48Z",
            "published": "2023-11-24T07:53:48Z",
            "summary": "The latest advancements in large language models (LLMs) have revolutionized\nthe field of natural language processing (NLP). Inspired by the success of LLMs\nin NLP tasks, some recent work has begun investigating the potential of\napplying LLMs in graph learning tasks. However, most of the existing work\nfocuses on utilizing LLMs as powerful node feature augmenters, leaving\nemploying LLMs to enhance graph topological structures an understudied problem.\nIn this work, we explore how to leverage the information retrieval and text\ngeneration capabilities of LLMs to refine/enhance the topological structure of\ntext-attributed graphs (TAGs) under the node classification setting. First, we\npropose using LLMs to help remove unreliable edges and add reliable ones in the\nTAG. Specifically, we first let the LLM output the semantic similarity between\nnode attributes through delicate prompt designs, and then perform edge deletion\nand edge addition based on the similarity. Second, we propose using\npseudo-labels generated by the LLM to improve graph topology, that is, we\nintroduce the pseudo-label propagation as a regularization to guide the graph\nneural network (GNN) in learning proper edge weights. Finally, we incorporate\nthe two aforementioned LLM-based methods for graph topological refinement into\nthe process of GNN training, and perform extensive experiments on four\nreal-world datasets. The experimental results demonstrate the effectiveness of\nLLM-based graph topology refinement (achieving a 0.15%--2.47% performance gain\non public benchmarks).",
            "author": [
                "Shengyin Sun",
                "Yuxiang Ren",
                "Chen Ma",
                "Xuecang Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14324v1",
                "http://arxiv.org/pdf/2311.14324v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14323v1",
            "title": "Binarized 3D Whole-body Human Mesh Recovery",
            "updated": "2023-11-24T07:51:50Z",
            "published": "2023-11-24T07:51:50Z",
            "summary": "3D whole-body human mesh recovery aims to reconstruct the 3D human body,\nface, and hands from a single image. Although powerful deep learning models\nhave achieved accurate estimation in this task, they require enormous memory\nand computational resources. Consequently, these methods can hardly be deployed\non resource-limited edge devices. In this work, we propose a Binarized Dual\nResidual Network (BiDRN), a novel quantization method to estimate the 3D human\nbody, face, and hands parameters efficiently. Specifically, we design a basic\nunit Binarized Dual Residual Block (BiDRB) composed of Local Convolution\nResidual (LCR) and Block Residual (BR), which can preserve full-precision\ninformation as much as possible. For LCR, we generalize it to four kinds of\nconvolutional modules so that full-precision information can be propagated even\nbetween mismatched dimensions. We also binarize the face and hands\nbox-prediction network as Binaried BoxNet, which can further reduce the model\nredundancy. Comprehensive quantitative and qualitative experiments demonstrate\nthe effectiveness of BiDRN, which has a significant improvement over\nstate-of-the-art binarization algorithms. Moreover, our proposed BiDRN achieves\ncomparable performance with full-precision method Hand4Whole while using just\n22.1% parameters and 14.8% operations. We will release all the code and\npretrained models.",
            "author": [
                "Zhiteng Li",
                "Yulun Zhang",
                "Jing Lin",
                "Haotong Qin",
                "Jinjin Gu",
                "Xin Yuan",
                "Linghe Kong",
                "Xiaokang Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14323v1",
                "http://arxiv.org/pdf/2311.14323v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14766v1",
            "title": "Reinforcement Learning from Statistical Feedback: the Journey from AB\n  Testing to ANT Testing",
            "updated": "2023-11-24T07:50:52Z",
            "published": "2023-11-24T07:50:52Z",
            "summary": "Reinforcement Learning from Human Feedback (RLHF) has played a crucial role\nin the success of large models such as ChatGPT. RLHF is a reinforcement\nlearning framework which combines human feedback to improve learning\neffectiveness and performance. However, obtaining preferences feedback manually\nis quite expensive in commercial applications. Some statistical commercial\nindicators are usually more valuable and always ignored in RLHF. There exists a\ngap between commercial target and model training. In our research, we will\nattempt to fill this gap with statistical business feedback instead of human\nfeedback, using AB testing which is a well-established statistical method.\nReinforcement Learning from Statistical Feedback (RLSF) based on AB testing is\nproposed. Statistical inference methods are used to obtain preferences for\ntraining the reward network, which fine-tunes the pre-trained model in\nreinforcement learning framework, achieving greater business value.\nFurthermore, we extend AB testing with double selections at a single time-point\nto ANT testing with multiple selections at different feedback time points.\nMoreover, we design numerical experiences to validate the effectiveness of our\nalgorithm framework.",
            "author": [
                "Feiyang Han",
                "Yimin Wei",
                "Zhaofeng Liu",
                "Yanxing Qi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14766v1",
                "http://arxiv.org/pdf/2311.14766v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.ST",
                "stat.ME",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14318v1",
            "title": "On optimal tracking portfolio in incomplete markets: The classical\n  control and the reinforcement learning approaches",
            "updated": "2023-11-24T07:38:01Z",
            "published": "2023-11-24T07:38:01Z",
            "summary": "This paper studies an infinite horizon optimal tracking portfolio problem\nusing capital injection in incomplete market models. We consider the benchmark\nprocess modelled by a geometric Brownian motion with zero drift driven by some\nunhedgeable risk. The relaxed tracking formulation is adopted where the\nportfolio value compensated by the injected capital needs to outperform the\nbenchmark process at any time, and the goal is to minimize the cost of the\ndiscounted total capital injection. In the first part, we solve the stochastic\ncontrol problem when the market model is known, for which the equivalent\nauxiliary control problem with reflections and the associated HJB equation with\na Neumann boundary condition are studied. In the second part, the market model\nis assumed to be unknown, for which we consider the exploratory formulation of\nthe control problem with entropy regularizer and develop the continuous-time\nq-learning algorithm for the stochastic control problem with state reflections.\nIn an illustrative example, we show the satisfactory performance of the\nq-learning algorithm.",
            "author": [
                "Lijun Bo",
                "Yijie Huang",
                "Xiang Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14318v1",
                "http://arxiv.org/pdf/2311.14318v1"
            ],
            "primary_category": "q-fin.PM",
            "category": [
                "q-fin.PM",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14310v1",
            "title": "Stable Cluster Discrimination for Deep Clustering",
            "updated": "2023-11-24T06:43:26Z",
            "published": "2023-11-24T06:43:26Z",
            "summary": "Deep clustering can optimize representations of instances (i.e.,\nrepresentation learning) and explore the inherent data distribution (i.e.,\nclustering) simultaneously, which demonstrates a superior performance over\nconventional clustering methods with given features. However, the coupled\nobjective implies a trivial solution that all instances collapse to the uniform\nfeatures. To tackle the challenge, a two-stage training strategy is developed\nfor decoupling, where it introduces an additional pre-training stage for\nrepresentation learning and then fine-tunes the obtained model for clustering.\nMeanwhile, one-stage methods are developed mainly for representation learning\nrather than clustering, where various constraints for cluster assignments are\ndesigned to avoid collapsing explicitly. Despite the success of these methods,\nan appropriate learning objective tailored for deep clustering has not been\ninvestigated sufficiently. In this work, we first show that the prevalent\ndiscrimination task in supervised learning is unstable for one-stage clustering\ndue to the lack of ground-truth labels and positive instances for certain\nclusters in each mini-batch. To mitigate the issue, a novel stable cluster\ndiscrimination (SeCu) task is proposed and a new hardness-aware clustering\ncriterion can be obtained accordingly. Moreover, a global entropy constraint\nfor cluster assignments is studied with efficient optimization. Extensive\nexperiments are conducted on benchmark data sets and ImageNet. SeCu achieves\nstate-of-the-art performance on all of them, which demonstrates the\neffectiveness of one-stage deep clustering. Code is available at\n\\url{https://github.com/idstcv/SeCu}.",
            "author": [
                "Qi Qian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14310v1",
                "http://arxiv.org/pdf/2311.14310v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14307v1",
            "title": "Cosine Similarity Knowledge Distillation for Individual Class\n  Information Transfer",
            "updated": "2023-11-24T06:34:47Z",
            "published": "2023-11-24T06:34:47Z",
            "summary": "Previous logits-based Knowledge Distillation (KD) have utilized predictions\nabout multiple categories within each sample (i.e., class predictions) and have\nemployed Kullback-Leibler (KL) divergence to reduce the discrepancy between the\nstudent and teacher predictions. Despite the proliferation of KD techniques,\nthe student model continues to fall short of achieving a similar level as\nteachers. In response, we introduce a novel and effective KD method capable of\nachieving results on par with or superior to the teacher models performance. We\nutilize teacher and student predictions about multiple samples for each\ncategory (i.e., batch predictions) and apply cosine similarity, a commonly used\ntechnique in Natural Language Processing (NLP) for measuring the resemblance\nbetween text embeddings. This metric's inherent scale-invariance property,\nwhich relies solely on vector direction and not magnitude, allows the student\nto dynamically learn from the teacher's knowledge, rather than being bound by a\nfixed distribution of the teacher's knowledge. Furthermore, we propose a method\ncalled cosine similarity weighted temperature (CSWT) to improve the\nperformance. CSWT reduces the temperature scaling in KD when the cosine\nsimilarity between the student and teacher models is high, and conversely, it\nincreases the temperature scaling when the cosine similarity is low. This\nadjustment optimizes the transfer of information from the teacher to the\nstudent model. Extensive experimental results show that our proposed method\nserves as a viable alternative to existing methods. We anticipate that this\napproach will offer valuable insights for future research on model compression.",
            "author": [
                "Gyeongdo Ham",
                "Seonghak Kim",
                "Suin Lee",
                "Jae-Hyeok Lee",
                "Daeshik Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14307v1",
                "http://arxiv.org/pdf/2311.14307v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14305v1",
            "title": "New Epochs in AI Supervision: Design and Implementation of an Autonomous\n  Radiology AI Monitoring System",
            "updated": "2023-11-24T06:29:04Z",
            "published": "2023-11-24T06:29:04Z",
            "summary": "With the increasingly widespread adoption of AI in healthcare, maintaining\nthe accuracy and reliability of AI models in clinical practice has become\ncrucial. In this context, we introduce novel methods for monitoring the\nperformance of radiology AI classification models in practice, addressing the\nchallenges of obtaining real-time ground truth for performance monitoring. We\npropose two metrics - predictive divergence and temporal stability - to be used\nfor preemptive alerts of AI performance changes. Predictive divergence,\nmeasured using Kullback-Leibler and Jensen-Shannon divergences, evaluates model\naccuracy by comparing predictions with those of two supplementary models.\nTemporal stability is assessed through a comparison of current predictions\nagainst historical moving averages, identifying potential model decay or data\ndrift. This approach was retrospectively validated using chest X-ray data from\na single-center imaging clinic, demonstrating its effectiveness in maintaining\nAI model reliability. By providing continuous, real-time insights into model\nperformance, our system ensures the safe and effective use of AI in clinical\ndecision-making, paving the way for more robust AI integration in healthcare",
            "author": [
                "Vasantha Kumar Venugopal",
                "Abhishek Gupta",
                "Rohit Takhar",
                "Vidur Mahajan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14305v1",
                "http://arxiv.org/pdf/2311.14305v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14304v1",
            "title": "AdaMedGraph: Adaboosting Graph Neural Networks for Personalized Medicine",
            "updated": "2023-11-24T06:27:25Z",
            "published": "2023-11-24T06:27:25Z",
            "summary": "Precision medicine tailored to individual patients has gained significant\nattention in recent times. Machine learning techniques are now employed to\nprocess personalized data from various sources, including images, genetics, and\nassessments. These techniques have demonstrated good outcomes in many clinical\nprediction tasks. Notably, the approach of constructing graphs by linking\nsimilar patients and then applying graph neural networks (GNNs) stands out,\nbecause related information from analogous patients are aggregated and\nconsidered for prediction. However, selecting the appropriate edge feature to\ndefine patient similarity and construct the graph is challenging, given that\neach patient is depicted by high-dimensional features from diverse sources.\nPrevious studies rely on human expertise to select the edge feature, which is\nneither scalable nor efficient in pinpointing crucial edge features for complex\ndiseases. In this paper, we propose a novel algorithm named \\ours, which can\nautomatically select important features to construct multiple patient\nsimilarity graphs, and train GNNs based on these graphs as weak learners in\nadaptive boosting. \\ours{} is evaluated on two real-world medical scenarios and\nshows superiors performance.",
            "author": [
                "Jie Lian",
                "Xufang Luo",
                "Caihua Shan",
                "Dongqi Han",
                "Varut Vardhanabhuti",
                "Dongsheng Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14304v1",
                "http://arxiv.org/pdf/2311.14304v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14303v1",
            "title": "RFI Detection with Spiking Neural Networks",
            "updated": "2023-11-24T06:27:08Z",
            "published": "2023-11-24T06:27:08Z",
            "summary": "Radio Frequency Interference (RFI) detection and mitigation is critical for\nenabling and maximising the scientific output of radio telescopes. The\nemergence of machine learning methods capable of handling large datasets has\nled to their application in radio astronomy, particularly in RFI detection.\nSpiking Neural Networks (SNNs), inspired by biological systems, are well-suited\nfor processing spatio-temporal data. This study introduces the first\napplication of SNNs to an astronomical data-processing task, specifically RFI\ndetection. We adapt the nearest-latent-neighbours (NLN) algorithm and\nauto-encoder architecture proposed by previous authors to SNN execution by\ndirect ANN2SNN conversion, enabling simplified downstream RFI detection by\nsampling the naturally varying latent space from the internal spiking neurons.\nWe evaluate performance with the simulated HERA telescope and hand-labelled\nLOFAR dataset that the original authors provided. We additionally evaluate\nperformance with a new MeerKAT-inspired simulation dataset. This dataset\nfocuses on satellite-based RFI, an increasingly important class of RFI and is,\ntherefore, an additional contribution. Our SNN approach remains competitive\nwith the original NLN algorithm and AOFlagger in AUROC, AUPRC and F1 scores for\nthe HERA dataset but exhibits difficulty in the LOFAR and MeerKAT datasets.\nHowever, our method maintains this performance while completely removing the\ncompute and memory-intense latent sampling step found in NLN. This work\ndemonstrates the viability of SNNs as a promising avenue for\nmachine-learning-based RFI detection in radio telescopes by establishing a\nminimal performance baseline on traditional and nascent satellite-based RFI\nsources and is the first work to our knowledge to apply SNNs in astronomy.",
            "author": [
                "Nicholas J. Pritchard",
                "Andreas Wicenec",
                "Mohammed Bennamoun",
                "Richard Dodson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14303v1",
                "http://arxiv.org/pdf/2311.14303v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14301v1",
            "title": "GeoViT: A Versatile Vision Transformer Architecture for Geospatial Image\n  Analysis",
            "updated": "2023-11-24T06:22:38Z",
            "published": "2023-11-24T06:22:38Z",
            "summary": "Greenhouse gases are pivotal drivers of climate change, necessitating precise\nquantification and source identification to foster mitigation strategies. We\nintroduce GeoViT, a compact vision transformer model adept in processing\nsatellite imagery for multimodal segmentation, classification, and regression\ntasks targeting CO2 and NO2 emissions. Leveraging GeoViT, we attain superior\naccuracy in estimating power generation rates, fuel type, plume coverage for\nCO2, and high-resolution NO2 concentration mapping, surpassing previous\nstate-of-the-art models while significantly reducing model size. GeoViT\ndemonstrates the efficacy of vision transformer architectures in harnessing\nsatellite-derived data for enhanced GHG emission insights, proving instrumental\nin advancing climate change monitoring and emission regulation efforts\nglobally.",
            "author": [
                "Madhav Khirwar",
                "Ankur Narang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14301v1",
                "http://arxiv.org/pdf/2311.14301v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14281v1",
            "title": "Multi-modal Instance Refinement for Cross-domain Action Recognition",
            "updated": "2023-11-24T05:06:28Z",
            "published": "2023-11-24T05:06:28Z",
            "summary": "Unsupervised cross-domain action recognition aims at adapting the model\ntrained on an existing labeled source domain to a new unlabeled target domain.\nMost existing methods solve the task by directly aligning the feature\ndistributions of source and target domains. However, this would cause negative\ntransfer during domain adaptation due to some negative training samples in both\ndomains. In the source domain, some training samples are of low-relevance to\ntarget domain due to the difference in viewpoints, action styles, etc. In the\ntarget domain, there are some ambiguous training samples that can be easily\nclassified as another type of action under the case of source domain. The\nproblem of negative transfer has been explored in cross-domain object\ndetection, while it remains under-explored in cross-domain action recognition.\nTherefore, we propose a Multi-modal Instance Refinement (MMIR) method to\nalleviate the negative transfer based on reinforcement learning. Specifically,\na reinforcement learning agent is trained in both domains for every modality to\nrefine the training data by selecting out negative samples from each domain.\nOur method finally outperforms several other state-of-the-art baselines in\ncross-domain action recognition on the benchmark EPIC-Kitchens dataset, which\ndemonstrates the advantage of MMIR in reducing negative transfer.",
            "author": [
                "Yuan Qing",
                "Naixing Wu",
                "Shaohua Wan",
                "Lixin Duan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14281v1",
                "http://arxiv.org/pdf/2311.14281v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14272v1",
            "title": "CRISP: Hybrid Structured Sparsity for Class-aware Model Pruning",
            "updated": "2023-11-24T04:16:32Z",
            "published": "2023-11-24T04:16:32Z",
            "summary": "Machine learning pipelines for classification tasks often train a universal\nmodel to achieve accuracy across a broad range of classes. However, a typical\nuser encounters only a limited selection of classes regularly. This disparity\nprovides an opportunity to enhance computational efficiency by tailoring models\nto focus on user-specific classes. Existing works rely on unstructured pruning,\nwhich introduces randomly distributed non-zero values in the model, making it\nunsuitable for hardware acceleration. Alternatively, some approaches employ\nstructured pruning, such as channel pruning, but these tend to provide only\nminimal compression and may lead to reduced model accuracy. In this work, we\npropose CRISP, a novel pruning framework leveraging a hybrid structured\nsparsity pattern that combines both fine-grained N:M structured sparsity and\ncoarse-grained block sparsity. Our pruning strategy is guided by a\ngradient-based class-aware saliency score, allowing us to retain weights\ncrucial for user-specific classes. CRISP achieves high accuracy with minimal\nmemory consumption for popular models like ResNet-50, VGG-16, and MobileNetV2\non ImageNet and CIFAR-100 datasets. Moreover, CRISP delivers up to 14$\\times$\nreduction in latency and energy consumption compared to existing pruning\nmethods while maintaining comparable accuracy. Our code is available at\nhttps://github.com/shivmgg/CRISP/.",
            "author": [
                "Shivam Aggarwal",
                "Kuluhan Binici",
                "Tulika Mitra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14272v1",
                "http://arxiv.org/pdf/2311.14272v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14271v1",
            "title": "Segmentation-Based Parametric Painting",
            "updated": "2023-11-24T04:15:10Z",
            "published": "2023-11-24T04:15:10Z",
            "summary": "We introduce a novel image-to-painting method that facilitates the creation\nof large-scale, high-fidelity paintings with human-like quality and stylistic\nvariation. To process large images and gain control over the painting process,\nwe introduce a segmentation-based painting process and a dynamic attention map\napproach inspired by human painting strategies, allowing optimization of brush\nstrokes to proceed in batches over different image regions, thereby capturing\nboth large-scale structure and fine details, while also allowing stylistic\ncontrol over detail. Our optimized batch processing and patch-based loss\nframework enable efficient handling of large canvases, ensuring our painted\noutputs are both aesthetically compelling and functionally superior as compared\nto previous methods, as confirmed by rigorous evaluations. Code available at:\nhttps://github.com/manuelladron/semantic\\_based\\_painting.git",
            "author": [
                "Manuel Ladron de Guevara",
                "Matthew Fisher",
                "Aaron Hertzmann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14271v1",
                "http://arxiv.org/pdf/2311.14271v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14270v1",
            "title": "Efficient Open-world Reinforcement Learning via Knowledge Distillation\n  and Autonomous Rule Discovery",
            "updated": "2023-11-24T04:12:50Z",
            "published": "2023-11-24T04:12:50Z",
            "summary": "Deep reinforcement learning suffers from catastrophic forgetting and sample\ninefficiency making it less applicable to the ever-changing real world.\nHowever, the ability to use previously learned knowledge is essential for AI\nagents to quickly adapt to novelties. Often, certain spatial information\nobserved by the agent in the previous interactions can be leveraged to infer\ntask-specific rules. Inferred rules can then help the agent to avoid\npotentially dangerous situations in the previously unseen states and guide the\nlearning process increasing agent's novelty adaptation speed. In this work, we\npropose a general framework that is applicable to deep reinforcement learning\nagents. Our framework provides the agent with an autonomous way to discover the\ntask-specific rules in the novel environments and self-supervise it's learning.\nWe provide a rule-driven deep Q-learning agent (RDQ) as one possible\nimplementation of that framework. We show that RDQ successfully extracts\ntask-specific rules as it interacts with the world and uses them to drastically\nincrease its learning efficiency. In our experiments, we show that the RDQ\nagent is significantly more resilient to the novelties than the baseline\nagents, and is able to detect and adapt to novel situations faster.",
            "author": [
                "Ekaterina Nikonova",
                "Cheng Xue",
                "Jochen Renz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14270v1",
                "http://arxiv.org/pdf/2311.14270v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14255v1",
            "title": "Out-of-Distribution Generalized Dynamic Graph Neural Network with\n  Disentangled Intervention and Invariance Promotion",
            "updated": "2023-11-24T02:42:42Z",
            "published": "2023-11-24T02:42:42Z",
            "summary": "Dynamic graph neural networks (DyGNNs) have demonstrated powerful predictive\nabilities by exploiting graph structural and temporal dynamics. However, the\nexisting DyGNNs fail to handle distribution shifts, which naturally exist in\ndynamic graphs, mainly because the patterns exploited by DyGNNs may be variant\nwith respect to labels under distribution shifts. In this paper, we propose\nDisentangled Intervention-based Dynamic graph Attention networks with\nInvariance Promotion (I-DIDA) to handle spatio-temporal distribution shifts in\ndynamic graphs by discovering and utilizing invariant patterns, i.e.,\nstructures and features whose predictive abilities are stable across\ndistribution shifts. Specifically, we first propose a disentangled\nspatio-temporal attention network to capture the variant and invariant\npatterns. By utilizing the disentangled patterns, we design a spatio-temporal\nintervention mechanism to create multiple interventional distributions and an\nenvironment inference module to infer the latent spatio-temporal environments,\nand minimize the variance of predictions among these intervened distributions\nand environments, so that our model can make predictions based on invariant\npatterns with stable predictive abilities under distribution shifts. Extensive\nexperiments demonstrate the superiority of our method over state-of-the-art\nbaselines under distribution shifts. Our work is the first study of\nspatio-temporal distribution shifts in dynamic graphs, to the best of our\nknowledge.",
            "author": [
                "Zeyang Zhang",
                "Xin Wang",
                "Ziwei Zhang",
                "Haoyang Li",
                "Wenwu Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14255v1",
                "http://arxiv.org/pdf/2311.14255v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14247v1",
            "title": "Distribution Testing with a Confused Collector",
            "updated": "2023-11-24T01:39:45Z",
            "published": "2023-11-24T01:39:45Z",
            "summary": "We are interested in testing properties of distributions with systematically\nmislabeled samples. Our goal is to make decisions about unknown probability\ndistributions, using a sample that has been collected by a confused collector,\nsuch as a machine-learning classifier that has not learned to distinguish all\nelements of the domain. The confused collector holds an unknown clustering of\nthe domain and an input distribution $\\mu$, and provides two oracles: a sample\noracle which produces a sample from $\\mu$ that has been labeled according to\nthe clustering; and a label-query oracle which returns the label of a query\npoint $x$ according to the clustering.\n  Our first set of results shows that identity, uniformity, and equivalence of\ndistributions can be tested efficiently, under the earth-mover distance, with\nremarkably weak conditions on the confused collector, even when the unknown\nclustering is adversarial. This requires defining a variant of the distribution\ntesting task (inspired by the recent testable learning framework of Rubinfeld &\nVasilyan), where the algorithm should test a joint property of the distribution\nand its clustering. As an example, we get efficient testers when the\ndistribution tester is allowed to reject if it detects that the confused\ncollector clustering is \"far\" from being a decision tree.\n  The second set of results shows that we can sometimes do significantly better\nwhen the clustering is random instead of adversarial. For certain\none-dimensional random clusterings, we show that uniformity can be tested under\nthe TV distance using $\\widetilde O\\left(\\frac{\\sqrt n}{\\rho^{3/2}\n\\epsilon^2}\\right)$ samples and zero queries, where $\\rho \\in (0,1]$ controls\nthe \"resolution\" of the clustering. We improve this to $O\\left(\\frac{\\sqrt\nn}{\\rho \\epsilon^2}\\right)$ when queries are allowed.",
            "author": [
                "Renato Ferreira Pinto Jr.",
                "Nathaniel Harms"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14247v1",
                "http://arxiv.org/pdf/2311.14247v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14246v1",
            "title": "Constant-Time Wasmtime, for Real This Time: End-to-End Verified\n  Zero-Overhead Constant-Time Programming for the Web and Beyond",
            "updated": "2023-11-24T01:38:19Z",
            "published": "2023-11-24T01:38:19Z",
            "summary": "We claim that existing techniques and tools for generating and verifying\nconstant-time code are incomplete, since they rely on assumptions that compiler\noptimization passes do not break constant-timeness or that certain operations\nexecute in constant time on the hardware. We present the first end-to-end\nconstant-time-aware compilation process that preserves constant-time semantics\nat every step from a high-level language down to microarchitectural guarantees,\nprovided by the forthcoming ARM PSTATE.DIT feature. First, we present a new\ncompiler-verifier suite based on the JIT-style runtime Wasmtime, modified to\ncompile ct-wasm, a preexisting type-safe constant-time extension of\nWebAssembly, into ARM machine code while maintaining the constant-time property\nthroughout all optimization passes. The resulting machine code is then fed into\nan automated verifier that requires no human intervention and uses static\ndataflow analysis in Ghidra to check the constant-timeness of the output. Our\nverifier leverages characteristics unique to ct-wasm-generated code in order to\nspeed up verification while preserving both soundness and wide applicability.\nWe also consider the resistance of our compilation and verification against\nspeculative timing leakages such as Spectre. Finally, in order to expose\nct-Wasmtime at a high level, we present a port of FaCT, a preexisting\nconstant-time-aware DSL, to target ct-wasm.",
            "author": [
                "Garrett Gu",
                "Hovav Shacham"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14246v1",
                "http://arxiv.org/pdf/2311.14246v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14245v1",
            "title": "Exploring percolation phase transition in the three-dimensional Ising\n  model with machine learning",
            "updated": "2023-11-24T01:30:07Z",
            "published": "2023-11-24T01:30:07Z",
            "summary": "The percolation phase transition plays a significant role in understanding\nthe Quantum Chromodynamics (QCD) phase diagram, particularly in the study of\nthe Quark-gluon Plasma and the critical point in high energy nuclear physics.\nIt is expected that the QCD critical point belongs to the three-dimensional\n(3D) Ising universality class. In this study, we explore the percolation phase\ntransition within the 3D cubic Ising model by employing two machine learning\nalgorithms: Principal Component Analysis and the Domain Adversarial Neural\nNetwork. Our findings reveal the effectiveness of machine learning techniques\nin distinguishing different phases during the percolation transition. Through\nthe finite-size scaling analysis on the output of the neural networks, the\ncritical temperature and a correlation length exponent in the geometrical\npercolation transition are extracted and compared to those in the thermal\nmagnetization phase transition within the 3D Ising model. These results offer\nvaluable insights to our understanding of QCD phase transitions in relativistic\nheavy-ion collisions.",
            "author": [
                "Ranran Guo",
                "Xiaobing Li",
                "Shiyang Chen",
                "Zhiming Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14245v1",
                "http://arxiv.org/pdf/2311.14245v1"
            ],
            "primary_category": "nucl-th",
            "category": [
                "nucl-th",
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14242v1",
            "title": "RSB-Pose: Robust Short-Baseline Binocular 3D Human Pose Estimation with\n  Occlusion Handling",
            "updated": "2023-11-24T01:15:57Z",
            "published": "2023-11-24T01:15:57Z",
            "summary": "In the domain of 3D Human Pose Estimation, which finds widespread daily\napplications, the requirement for convenient acquisition equipment continues to\ngrow. To satisfy this demand, we set our sights on a short-baseline binocular\nsetting that offers both portability and a geometric measurement property that\nradically mitigates depth ambiguity. However, as the binocular baseline\nshortens, two serious challenges emerge: first, the robustness of 3D\nreconstruction against 2D errors deteriorates; and second, occlusion reoccurs\ndue to the limited visual differences between two views. To address the first\nchallenge, we propose the Stereo Co-Keypoints Estimation module to improve the\nview consistency of 2D keypoints and enhance the 3D robustness. In this module,\nthe disparity is utilized to represent the correspondence of binocular 2D\npoints and the Stereo Volume Feature is introduced to contain binocular\nfeatures across different disparities. Through the regression of SVF, two-view\n2D keypoints are simultaneously estimated in a collaborative way which\nrestricts their view consistency. Furthermore, to deal with occlusions, a\nPre-trained Pose Transformer module is introduced. Through this module, 3D\nposes are refined by perceiving pose coherence, a representation of joint\ncorrelations. This perception is injected by the Pose Transformer network and\nlearned through a pre-training task that recovers iterative masked joints.\nComprehensive experiments carried out on H36M and MHAD datasets, complemented\nby visualizations, validate the effectiveness of our approach in the\nshort-baseline binocular 3D Human Pose Estimation and occlusion handling.",
            "author": [
                "Xiaoyue Wan",
                "Zhuo Chen",
                "Yiming Bao",
                "Xu Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14242v1",
                "http://arxiv.org/pdf/2311.14242v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14241v1",
            "title": "How We Manage an Army of Teaching Assistants: Experience Report on\n  Scaling a CS1 Course",
            "updated": "2023-11-24T01:12:05Z",
            "published": "2023-11-24T01:12:05Z",
            "summary": "A considerable increase in enrollment numbers poses major challenges in\ncourse management, such as fragmented information sharing, inefficient\nmeetings, and poor understanding of course activities among a large team of\nteaching assistants. To address these challenges, we restructured the course,\ndrawing inspiration from successful management and educational practices. We\ndeveloped an organized, three-tier structure for teams, each led by an\nexperienced Lead TA. We also formed five functional teams, each focusing on a\nspecific area of responsibility: communication, content, \"lost student\"\nsupport, plagiarism, and scheduling. In addition, we updated our recruitment\nmethod for undergraduate TAs, following a model similar to the one used in the\nsoftware industry, while also deciding to mentor Lead TAs in place of\ntraditional training. Our experiences, lessons learned, and future plans for\nenhancement have been detailed in this experience report. We emphasize the\nvalue of using management techniques in dealing with large-scale course\nhandling and invite cooperation to improve the implementation of these\nstrategies, inviting other institutions to consider and adapt this approach,\ntailoring it to their specific needs.",
            "author": [
                "Ildar Akhmetov",
                "Sadaf Ahmed",
                "Kezziah Ayuno"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3626252.3630871",
                "http://arxiv.org/abs/2311.14241v1",
                "http://arxiv.org/pdf/2311.14241v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14237v1",
            "title": "Pseudo-label Correction for Instance-dependent Noise Using\n  Teacher-student Framework",
            "updated": "2023-11-24T00:36:17Z",
            "published": "2023-11-24T00:36:17Z",
            "summary": "The high capacity of deep learning models to learn complex patterns poses a\nsignificant challenge when confronted with label noise. The inability to\ndifferentiate clean and noisy labels ultimately results in poor generalization.\nWe approach this problem by reassigning the label for each image using a new\nteacher-student based framework termed P-LC (pseudo-label correction).\nTraditional teacher-student networks are composed of teacher and student\nclassifiers for knowledge distillation. In our novel approach, we reconfigure\nthe teacher network into a triple encoder, leveraging the triplet loss to\nestablish a pseudo-label correction system. As the student generates pseudo\nlabels for a set of given images, the teacher learns to choose between the\ninitially assigned labels and the pseudo labels. Experiments on MNIST,\nFashion-MNIST, and SVHN demonstrate P-LC's superior performance over existing\nstate-of-the-art methods across all noise levels, most notably in high noise.\nIn addition, we introduce a noise level estimation to help assess model\nperformance and inform the need for additional data cleaning procedures.",
            "author": [
                "Eugene Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14237v1",
                "http://arxiv.org/pdf/2311.14237v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16973v1",
            "title": "DemoFusion: Democratising High-Resolution Image Generation With No $$$",
            "updated": "2023-11-24T00:16:00Z",
            "published": "2023-11-24T00:16:00Z",
            "summary": "High-resolution image generation with Generative Artificial Intelligence\n(GenAI) has immense potential but, due to the enormous capital investment\nrequired for training, it is increasingly centralised to a few large\ncorporations, and hidden behind paywalls. This paper aims to democratise\nhigh-resolution GenAI by advancing the frontier of high-resolution generation\nwhile remaining accessible to a broad audience. We demonstrate that existing\nLatent Diffusion Models (LDMs) possess untapped potential for higher-resolution\nimage generation. Our novel DemoFusion framework seamlessly extends open-source\nGenAI models, employing Progressive Upscaling, Skip Residual, and Dilated\nSampling mechanisms to achieve higher-resolution image generation. The\nprogressive nature of DemoFusion requires more passes, but the intermediate\nresults can serve as \"previews\", facilitating rapid prompt iteration.",
            "author": [
                "Ruoyi Du",
                "Dongliang Chang",
                "Timothy Hospedales",
                "Yi-Zhe Song",
                "Zhanyu Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16973v1",
                "http://arxiv.org/pdf/2311.16973v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14227v1",
            "title": "Robust and Interpretable COVID-19 Diagnosis on Chest X-ray Images using\n  Adversarial Training",
            "updated": "2023-11-23T23:40:01Z",
            "published": "2023-11-23T23:40:01Z",
            "summary": "The novel 2019 Coronavirus disease (COVID-19) global pandemic is a defining\nhealth crisis. Recent efforts have been increasingly directed towards achieving\nquick and accurate detection of COVID-19 across symptomatic patients to\nmitigate the intensity and spread of the disease. Artificial intelligence (AI)\nalgorithms applied to chest X-ray (CXR) images have emerged as promising\ndiagnostic tools, and previous work has demonstrated impressive classification\nperformances. However, such methods have faced criticisms from physicians due\nto their black-box reasoning process and unpredictable nature. In contrast to\nprofessional radiologist diagnosis, AI systems often lack generalizability,\nexplainability, and robustness in the clinical decision making process. In our\nwork, we address these issues by first proposing an extensive baseline study,\ntraining and evaluating 21 convolutional neural network (CNN) models on a\ndiverse set of 33,000+ CXR images to classify between healthy, COVID-19, and\nnon-COVID-19 pneumonia CXRs. Our resulting models achieved a 3-way\nclassification accuracy, recall, and precision of up to 97.03\\%, 97.97\\%, and\n99.95\\%, respectively. Next, we investigate the effectiveness of adversarial\ntraining on model robustness and explainability via Gradient-weighted Class\nActivation Mapping (Grad-CAM) heatmaps. We find that adversarially trained\nmodels not only significantly outperform their standard counterparts on\nclassifying perturbed images, but also yield saliency maps that 1) better\nspecify clinically relevant features, 2) are robust against extraneous\nartifacts, and 3) agree considerably more with expert radiologist findings.",
            "author": [
                "Karina Yang",
                "Alexis Bennett",
                "Dominique Duncan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14227v1",
                "http://arxiv.org/pdf/2311.14227v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14224v1",
            "title": "A master-slave coupling scheme for synchronization and parameter\n  estimation in the generalized Kuramoto-Sivashinsky equation",
            "updated": "2023-11-23T23:24:45Z",
            "published": "2023-11-23T23:24:45Z",
            "summary": "The problem of estimating the constant parameters of the Kuramoto-Sivashinsky\n(KS) equation has received considerable attention from researchers in physics,\napplied mathematics and statistics. This is motivated by the various physical\napplications of the equation and, also, because it often serves as a test model\nfor the study of space-time pattern formation. Remarkably, most existing\ninference techniques rely on statistical or machine learning tools, which are\ncomputationally very costly yet do not exploit the dynamical features of the\nsystem. In this paper we introduce a simple, online parameter estimation method\nthat relies on the synchronization properties of the KS equation. In\nparticular, we describe a master-slave setup where the slave model is driven by\nobservations from the master system. The slave dynamics are designed to\nsynchronize with the master when both models have the same parameters. We\nprovide a simple analysis that supports the proposed approach and also present\nand discuss the results of an extensive numerical assessment of the\nmethodology. The numerical study shows that the proposed method is\ncomputationally fast and also robust to initialization errors, observational\nnoise and variations in the spatial resolution of the numerical scheme.",
            "author": [
                "Joaquin Miguez",
                "Harold Molina-Bulla",
                "In\u00e9s P. Mari\u00f1o"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14224v1",
                "http://arxiv.org/pdf/2311.14224v1"
            ],
            "primary_category": "math-ph",
            "category": [
                "math-ph",
                "math.DS",
                "math.MP",
                "35A24, 35R30, 34H10, 34D06"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14222v1",
            "title": "Risk Bounds of Accelerated SGD for Overparameterized Linear Regression",
            "updated": "2023-11-23T23:02:10Z",
            "published": "2023-11-23T23:02:10Z",
            "summary": "Accelerated stochastic gradient descent (ASGD) is a workhorse in deep\nlearning and often achieves better generalization performance than SGD.\nHowever, existing optimization theory can only explain the faster convergence\nof ASGD, but cannot explain its better generalization. In this paper, we study\nthe generalization of ASGD for overparameterized linear regression, which is\npossibly the simplest setting of learning with overparameterization. We\nestablish an instance-dependent excess risk bound for ASGD within each\neigen-subspace of the data covariance matrix. Our analysis shows that (i) ASGD\noutperforms SGD in the subspace of small eigenvalues, exhibiting a faster rate\nof exponential decay for bias error, while in the subspace of large\neigenvalues, its bias error decays slower than SGD; and (ii) the variance error\nof ASGD is always larger than that of SGD. Our result suggests that ASGD can\noutperform SGD when the difference between the initialization and the true\nweight vector is mostly confined to the subspace of small eigenvalues.\nAdditionally, when our analysis is specialized to linear regression in the\nstrongly convex setting, it yields a tighter bound for bias error than the\nbest-known result.",
            "author": [
                "Xuheng Li",
                "Yihe Deng",
                "Jingfeng Wu",
                "Dongruo Zhou",
                "Quanquan Gu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14222v1",
                "http://arxiv.org/pdf/2311.14222v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14220v1",
            "title": "Assumption-lean and Data-adaptive Post-Prediction Inference",
            "updated": "2023-11-23T22:41:30Z",
            "published": "2023-11-23T22:41:30Z",
            "summary": "A primary challenge facing modern scientific research is the limited\navailability of gold-standard data which can be both costly and labor-intensive\nto obtain. With the rapid development of machine learning (ML), scientists have\nrelied on ML algorithms to predict these gold-standard outcomes with easily\nobtained covariates. However, these predicted outcomes are often used directly\nin subsequent statistical analyses, ignoring imprecision and heterogeneity\nintroduced by the prediction procedure. This will likely result in false\npositive findings and invalid scientific conclusions. In this work, we\nintroduce an assumption-lean and data-adaptive Post-Prediction Inference\n(POP-Inf) procedure that allows valid and powerful inference based on\nML-predicted outcomes. Its \"assumption-lean\" property guarantees reliable\nstatistical inference without assumptions on the ML-prediction, for a wide\nrange of statistical quantities. Its \"data-adaptive'\" feature guarantees an\nefficiency gain over existing post-prediction inference methods, regardless of\nthe accuracy of ML-prediction. We demonstrate the superiority and applicability\nof our method through simulations and large-scale genomic data.",
            "author": [
                "Jiacheng Miao",
                "Xinran Miao",
                "Yixuan Wu",
                "Jiwei Zhao",
                "Qiongshi Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14220v1",
                "http://arxiv.org/pdf/2311.14220v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14214v1",
            "title": "Extending Variability-Aware Model Selection with Bias Detection in\n  Machine Learning Projects",
            "updated": "2023-11-23T22:08:29Z",
            "published": "2023-11-23T22:08:29Z",
            "summary": "Data science projects often involve various machine learning (ML) methods\nthat depend on data, code, and models. One of the key activities in these\nprojects is the selection of a model or algorithm that is appropriate for the\ndata analysis at hand. ML model selection depends on several factors, which\ninclude data-related attributes such as sample size, functional requirements\nsuch as the prediction algorithm type, and non-functional requirements such as\nperformance and bias. However, the factors that influence such selection are\noften not well understood and explicitly represented. This paper describes\nongoing work on extending an adaptive variability-aware model selection method\nwith bias detection in ML projects. The method involves: (i) modeling the\nvariability of the factors that affect model selection using feature models\nbased on heuristics proposed in the literature; (ii) instantiating our\nvariability model with added features related to bias (e.g., bias-related\nmetrics); and (iii) conducting experiments that illustrate the method in a\nspecific case study to illustrate our approach based on a heart failure\nprediction project. The proposed approach aims to advance the state of the art\nby making explicit factors that influence model selection, particularly those\nrelated to bias, as well as their interactions. The provided representations\ncan transform model selection in ML projects into a non ad hoc, adaptive, and\nexplainable process.",
            "author": [
                "Cristina Tavares",
                "Nathalia Nascimento",
                "Paulo Alencar",
                "Donald Cowan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14214v1",
                "http://arxiv.org/pdf/2311.14214v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14213v1",
            "title": "Learning to Solve Inverse Problems for Perceptual Sound Matching",
            "updated": "2023-11-23T22:00:58Z",
            "published": "2023-11-23T22:00:58Z",
            "summary": "Perceptual sound matching (PSM) aims to find the input parameters to a\nsynthesizer so as to best imitate an audio target. Deep learning for PSM\noptimizes a neural network to analyze and reconstruct prerecorded samples. In\nthis context, our article addresses the problem of designing a suitable loss\nfunction when the training set is generated by a differentiable synthesizer.\nOur main contribution is perceptual-neural-physical loss (PNP), which aims at\naddressing a tradeoff between perceptual relevance and computational\nefficiency. The key idea behind PNP is to linearize the effect of synthesis\nparameters upon auditory features in the vicinity of each training sample. The\nlinearization procedure is massively paralellizable, can be precomputed, and\noffers a 100-fold speedup during gradient descent compared to differentiable\ndigital signal processing (DDSP). We demonstrate PNP on two datasets of\nnonstationary sounds: an AM/FM arpeggiator and a physical model of rectangular\nmembranes. We show that PNP is able to accelerate DDSP with joint\ntime-frequency scattering transform (JTFS) as auditory feature, while\npreserving its perceptual fidelity. Additionally, we evaluate the impact of\nother design choices in PSM: parameter rescaling, pretraining, auditory\nrepresentation, and gradient clipping. We report state-of-the-art results on\nboth datasets and find that PNP-accelerated JTFS has greater influence on PSM\nperformance than any other design choice.",
            "author": [
                "Han Han",
                "Vincent Lostanlen",
                "Mathieu Lagrange"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14213v1",
                "http://arxiv.org/pdf/2311.14213v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14212v1",
            "title": "Annotation Sensitivity: Training Data Collection Methods Affect Model\n  Performance",
            "updated": "2023-11-23T21:54:22Z",
            "published": "2023-11-23T21:54:22Z",
            "summary": "When training data are collected from human annotators, the design of the\nannotation instrument, the instructions given to annotators, the\ncharacteristics of the annotators, and their interactions can impact training\ndata. This study demonstrates that design choices made when creating an\nannotation instrument also impact the models trained on the resulting\nannotations.\n  We introduce the term annotation sensitivity to refer to the impact of\nannotation data collection methods on the annotations themselves and on\ndownstream model performance and predictions.\n  We collect annotations of hate speech and offensive language in five\nexperimental conditions of an annotation instrument, randomly assigning\nannotators to conditions. We then fine-tune BERT models on each of the five\nresulting datasets and evaluate model performance on a holdout portion of each\ncondition. We find considerable differences between the conditions for 1) the\nshare of hate speech/offensive language annotations, 2) model performance, 3)\nmodel predictions, and 4) model learning curves.\n  Our results emphasize the crucial role played by the annotation instrument\nwhich has received little attention in the machine learning literature. We call\nfor additional research into how and why the instrument impacts the annotations\nto inform the development of best practices in instrument design.",
            "author": [
                "Christoph Kern",
                "Stephanie Eckman",
                "Jacob Beck",
                "Rob Chew",
                "Bolei Ma",
                "Frauke Kreuter"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14212v1",
                "http://arxiv.org/pdf/2311.14212v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.CL",
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17927v1",
            "title": "Closed-Loop Ramp-Comparison Current Regulator for an Induction Machine\n  with a PWM Voltage-Source Inverter",
            "updated": "2023-11-23T21:43:53Z",
            "published": "2023-11-23T21:43:53Z",
            "summary": "This paper addresses the closed-loop ramp comparison current regulation in an\ninduction machine fed by a pulse width modulated voltage source inverter. The\nregulator is implemented in a synchronous frame, serving as a foundation for an\noverarching vector control of the induction machine. First, the effect of PI\nregulator gains on the controller performance is analyzed both theoretically\nand numerically using the developed Simulink model of the system. Next, the\npaper deals with high speed and/or low-voltage operating conditions of the\nmachine, introducing the concept of overmodulation and analyzing its impact on\nthe regulator performance. Obtained simulation results coincide with\nmodel-based theoretical predictions and literature findings. Finally, the work\nproposes an outlook for the high-speed system enhancements in terms of power\nelectronics topology, control and modulation.",
            "author": [
                "Aidar Zhetessov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17927v1",
                "http://arxiv.org/pdf/2311.17927v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17926v1",
            "title": "Grid-Forming Control of Power Converters: Equivalence Proof through\n  Simplified Models",
            "updated": "2023-11-23T21:33:47Z",
            "published": "2023-11-23T21:33:47Z",
            "summary": "This work establishes the equivalence of selected grid-forming control\nalgorithms within the context of simplified theoretical models. Considered\nalgorithms are droop control, Virtual Synchronous Machine (VSM) and matching\ncontrol. It is shown that nodal and network dynamics under those regulators\nboil down to the same equations near the selected (trivial) nominal operating\npoint. Finally, some practical insights on each regulator dynamics and an\noutlook are provided.",
            "author": [
                "Aidar Zhetessov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17926v1",
                "http://arxiv.org/pdf/2311.17926v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.00041v1",
            "title": "Presentation Attack Detection using Convolutional Neural Networks and\n  Local Binary Patterns",
            "updated": "2023-11-23T20:57:07Z",
            "published": "2023-11-23T20:57:07Z",
            "summary": "The use of biometrics to authenticate users and control access to secure\nareas has become extremely popular in recent years, and biometric access\ncontrol systems are frequently used by both governments and private\ncorporations. However, these systems may represent risks to security when\ndeployed without considering the possibility of biometric presentation attacks\n(also known as spoofing). Presentation attacks are a serious threat because\nthey do not require significant time, expense, or skill to carry out while\nremaining effective against many biometric systems in use today. This research\ncompares three different software-based methods for facial and iris\npresentation attack detection in images. The first method uses Inception-v3, a\npre-trained deep Convolutional Neural Network (CNN) made by Google for the\nImageNet challenge, which is retrained for this problem. The second uses a\nshallow CNN based on a modified Spoofnet architecture, which is trained\nnormally. The third is a texture-based method using Local Binary Patterns\n(LBP). The datasets used are the ATVS-FIr dataset, which contains real and fake\niris images, and the CASIA Face Anti-Spoofing Dataset, which contains real\nimages as well as warped photos, cut photos, and video replay presentation\nattacks. We also present a third set of results, based on cropped versions of\nthe CASIA images.",
            "author": [
                "Justin Spencer",
                "Deborah Lawrence",
                "Prosenjit Chatterjee",
                "Kaushik Roy",
                "Albert Esterline",
                "Jung-Hee Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00041v1",
                "http://arxiv.org/pdf/2312.00041v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14199v1",
            "title": "A Systematic Review of Deep Learning-based Research on Radiology Report\n  Generation",
            "updated": "2023-11-23T20:52:44Z",
            "published": "2023-11-23T20:52:44Z",
            "summary": "Radiology report generation (RRG) aims to automatically generate free-text\ndescriptions from clinical radiographs, e.g., chest X-Ray images. RRG plays an\nessential role in promoting clinical automation and presents significant help\nto provide practical assistance for inexperienced doctors and alleviate\nradiologists' workloads. Therefore, consider these meaningful potentials,\nresearch on RRG is experiencing explosive growth in the past half-decade,\nespecially with the rapid development of deep learning approaches. Existing\nstudies perform RRG from the perspective of enhancing different modalities,\nprovide insights on optimizing the report generation process with elaborated\nfeatures from both visual and textual information, and further facilitate RRG\nwith the cross-modal interactions among them. In this paper, we present a\ncomprehensive review of deep learning-based RRG from various perspectives.\nSpecifically, we firstly cover pivotal RRG approaches based on the\ntask-specific features of radiographs, reports, and the cross-modal relations\nbetween them, and then illustrate the benchmark datasets conventionally used\nfor this task with evaluation metrics, subsequently analyze the performance of\ndifferent approaches and finally offer our summary on the challenges and the\ntrends in future directions. Overall, the goal of this paper is to serve as a\ntool for understanding existing literature and inspiring potential valuable\nresearch in the field of RRG.",
            "author": [
                "Chang Liu",
                "Yuanhe Tian",
                "Yan Song"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14199v1",
                "http://arxiv.org/pdf/2311.14199v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14197v1",
            "title": "Enhancing mTBI Diagnosis with Residual Triplet Convolutional Neural\n  Network Using 3D CT",
            "updated": "2023-11-23T20:41:46Z",
            "published": "2023-11-23T20:41:46Z",
            "summary": "Mild Traumatic Brain Injury (mTBI) is a common and challenging condition to\ndiagnose accurately. Timely and precise diagnosis is essential for effective\ntreatment and improved patient outcomes. Traditional diagnostic methods for\nmTBI often have limitations in terms of accuracy and sensitivity. In this\nstudy, we introduce an innovative approach to enhance mTBI diagnosis using 3D\nComputed Tomography (CT) images and a metric learning technique trained with\ntriplet loss. To address these challenges, we propose a Residual Triplet\nConvolutional Neural Network (RTCNN) model to distinguish between mTBI cases\nand healthy ones by embedding 3D CT scans into a feature space. The triplet\nloss function maximizes the margin between similar and dissimilar image pairs,\noptimizing feature representations. This facilitates better context placement\nof individual cases, aids informed decision-making, and has the potential to\nimprove patient outcomes. Our RTCNN model shows promising performance in mTBI\ndiagnosis, achieving an average accuracy of 94.3%, a sensitivity of 94.1%, and\na specificity of 95.2%, as confirmed through a five-fold cross-validation.\nImportantly, when compared to the conventional Residual Convolutional Neural\nNetwork (RCNN) model, the RTCNN exhibits a significant improvement, showcasing\na remarkable 22.5% increase in specificity, a notable 16.2% boost in accuracy,\nand an 11.3% enhancement in sensitivity. Moreover, RTCNN requires lower memory\nresources, making it not only highly effective but also resource-efficient in\nminimizing false positives while maximizing its diagnostic accuracy in\ndistinguishing normal CT scans from mTBI cases. The quantitative performance\nmetrics provided and utilization of occlusion sensitivity maps to visually\nexplain the model's decision-making process further enhance the\ninterpretability and transparency of our approach.",
            "author": [
                "Hanem Ellethy",
                "Shekhar S. Chandra",
                "Viktor Vegh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14197v1",
                "http://arxiv.org/pdf/2311.14197v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14195v1",
            "title": "Touch Analysis: An Empirical Evaluation of Machine Learning\n  Classification Algorithms on Touch Data",
            "updated": "2023-11-23T20:31:48Z",
            "published": "2023-11-23T20:31:48Z",
            "summary": "Our research aims at classifying individuals based on their unique\ninteractions on touchscreen-based smartphones. In this research, we use\nTouch-Analytics datasets, which include 41 subjects and 30 different behavioral\nfeatures. Furthermore, we derived new features from the raw data to improve the\noverall authentication performance. Previous research has already been done on\nthe Touch-Analytics datasets with the state-of-the-art classifiers, including\nSupport Vector Machine (SVM) and k-nearest neighbor (kNN), and achieved equal\nerror rates (EERs) between 0% to 4%. Here, we propose a novel Deep Neural Net\n(DNN) architecture to classify the individuals correctly. The proposed DNN\narchitecture has three dense layers and uses many-to-many mapping techniques.\nWhen we combine the new features with the existing ones, SVM and kNN achieved\nthe classification accuracy of 94.7% and 94.6%, respectively. This research\nexplored seven other classifiers and out of them, the decision tree and our\nproposed DNN classifiers resulted in the highest accuracy of 100%. The others\nincluded: Logistic Regression (LR), Linear Discriminant Analysis (LDA),\nGaussian Naive Bayes (NB), Neural Network, and VGGNet with the following\naccuracy scores of 94.7%, 95.9%, 31.9%, 88.8%, and 96.1%, respectively.",
            "author": [
                "Melodee Montgomery",
                "Prosenjit Chatterjee",
                "John Jenkins",
                "Kaushik Roy"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14195v1",
                "http://arxiv.org/pdf/2311.14195v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.00040v1",
            "title": "Presentation Attack detection using Wavelet Transform and Deep Residual\n  Neural Net",
            "updated": "2023-11-23T20:21:49Z",
            "published": "2023-11-23T20:21:49Z",
            "summary": "Biometric authentication is becoming more prevalent for secured\nauthentication systems. However, the biometric substances can be deceived by\nthe imposters in several ways. Among other imposter attacks, print attacks,\nmask attacks, and replay attacks fall under the presentation attack category.\nThe bio-metric images, especially the iris and face, are vulnerable to\ndifferent presentation attacks. This research applies deep learning approaches\nto mitigate presentation attacks in a biometric access control system. Our\ncontribution in this paper is two-fold: First, we applied the wavelet transform\nto extract the features from the biometric images. Second, we modified the deep\nresidual neural net and applied it to the spoof datasets in an attempt to\ndetect the presentation attacks. This research applied the proposed approach to\nbiometric spoof datasets, namely ATVS, CASIA two class, and CASIA cropped image\nsets. The datasets used in this research contain images that are captured in\nboth a controlled and uncontrolled environment along with different resolutions\nand sizes. We obtained the best accuracy of 93% on the ATVS Iris datasets. For\nCASIA two class and CASIA cropped datasets, we achieved test accuracies of 91%\nand 82%, respectively.",
            "author": [
                "Prosenjit Chatterjee",
                "Alex Yalchin",
                "Joseph Shelton",
                "Kaushik Roy",
                "Xiaohong Yuan",
                "Kossi D. Edoh"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00040v1",
                "http://arxiv.org/pdf/2312.00040v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14186v1",
            "title": "Anyone Can Code: Algorithmic Thinking",
            "updated": "2023-11-23T20:12:29Z",
            "published": "2023-11-23T20:12:29Z",
            "summary": "As the second book in the Anyone Can Code series, Algorithmic Thinking\nfocuses on the logic behind computer programming and software design. With a\ndata-centred approach, it starts with simple algorithms that work on simple\ndata items and advances to more complex ones covering data structures and\nclasses. Examples are given in C/C++ and Python and use both plain text and\ngraphics applications to illustrate the concepts in different languages and\nforms. With the advances in artificial intelligence and automated code\ngenerators, it is essential to learn about the logic of what a code needs to\ndo, not just how to write the code. Anyone Can Code: Algorithmic Thinking is\nsuitable for anyone who aims to improve their programming skills and go beyond\nthe simple craft of programming, stepping into the world of algorithm design.",
            "author": [
                "Ali Arya"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14186v1",
                "http://arxiv.org/pdf/2311.14186v1"
            ],
            "primary_category": "cs.PL",
            "category": [
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.00802v1",
            "title": "Continuous Authentication Using Mouse Clickstream Data Analysis",
            "updated": "2023-11-23T20:07:38Z",
            "published": "2023-11-23T20:07:38Z",
            "summary": "Biometrics is used to authenticate an individual based on physiological or\nbehavioral traits. Mouse dynamics is an example of a behavioral biometric that\ncan be used to perform continuous authentication as protection against security\nbreaches. Recent research on mouse dynamics has shown promising results in\nidentifying users; however, it has not yet reached an acceptable level of\naccuracy. In this paper, an empirical evaluation of different classification\ntechniques is conducted on a mouse dynamics dataset, the Balabit Mouse\nChallenge dataset. User identification is carried out using three mouse\nactions: mouse move, point and click, and drag and drop. Verification and\nauthentication methods are conducted using three machine-learning classifiers:\nthe Decision Tree classifier, the K-Nearest Neighbors classifier, and the\nRandom Forest classifier. The results show that the three classifiers can\ndistinguish between a genuine user and an impostor with a relatively high\ndegree of accuracy. In the verification mode, all the classifiers achieve a\nperfect accuracy of 100%. In authentication mode, all three classifiers\nachieved the highest accuracy (ACC) and Area Under Curve (AUC) from scenario B\nusing the point and click action data: (Decision Tree ACC:87.6%, AUC:90.3%),\n(K-Nearest Neighbors ACC:99.3%, AUC:99.9%), and (Random Forest ACC:89.9%,\nAUC:92.5%).",
            "author": [
                "Sultan Almalki",
                "Prosenjit Chatterjee",
                "Kaushik Roy"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00802v1",
                "http://arxiv.org/pdf/2312.00802v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.AI",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14182v1",
            "title": "Gradient-based bilevel optimization for multi-penalty Ridge regression\n  through matrix differential calculus",
            "updated": "2023-11-23T20:03:51Z",
            "published": "2023-11-23T20:03:51Z",
            "summary": "Common regularization algorithms for linear regression, such as LASSO and\nRidge regression, rely on a regularization hyperparameter that balances the\ntradeoff between minimizing the fitting error and the norm of the learned model\ncoefficients. As this hyperparameter is scalar, it can be easily selected via\nrandom or grid search optimizing a cross-validation criterion. However, using a\nscalar hyperparameter limits the algorithm's flexibility and potential for\nbetter generalization. In this paper, we address the problem of linear\nregression with l2-regularization, where a different regularization\nhyperparameter is associated with each input variable. We optimize these\nhyperparameters using a gradient-based approach, wherein the gradient of a\ncross-validation criterion with respect to the regularization hyperparameters\nis computed analytically through matrix differential calculus. Additionally, we\nintroduce two strategies tailored for sparse model learning problems aiming at\nreducing the risk of overfitting to the validation data. Numerical examples\ndemonstrate that our multi-hyperparameter regularization approach outperforms\nLASSO, Ridge, and Elastic Net regression. Moreover, the analytical computation\nof the gradient proves to be more efficient in terms of computational time\ncompared to automatic differentiation, especially when handling a large number\nof input variables. Application to the identification of over-parameterized\nLinear Parameter-Varying models is also presented.",
            "author": [
                "Gabriele Maroni",
                "Loris Cannelli",
                "Dario Piga"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14182v1",
                "http://arxiv.org/pdf/2311.14182v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14177v1",
            "title": "TCuPGAN: A novel framework developed for optimizing human-machine\n  interactions in citizen science",
            "updated": "2023-11-23T19:49:59Z",
            "published": "2023-11-23T19:49:59Z",
            "summary": "In the era of big data in scientific research, there is a necessity to\nleverage techniques which reduce human effort in labeling and categorizing\nlarge datasets by involving sophisticated machine tools. To combat this\nproblem, we present a novel, general purpose model for 3D segmentation that\nleverages patch-wise adversariality and Long Short-Term Memory to encode\nsequential information. Using this model alongside citizen science projects\nwhich use 3D datasets (image cubes) on the Zooniverse platforms, we propose an\niterative human-machine optimization framework where only a fraction of the 2D\nslices from these cubes are seen by the volunteers. We leverage the patch-wise\ndiscriminator in our model to provide an estimate of which slices within these\nimage cubes have poorly generalized feature representations, and\ncorrespondingly poor machine performance. These images with corresponding\nmachine proposals would be presented to volunteers on Zooniverse for\ncorrection, leading to a drastic reduction in the volunteer effort on citizen\nscience projects. We trained our model on ~2300 liver tissue 3D electron\nmicrographs. Lipid droplets were segmented within these images through human\nannotation via the `Etch A Cell - Fat Checker' citizen science project, hosted\non the Zooniverse platform. In this work, we demonstrate this framework and the\nselection methodology which resulted in a measured reduction in volunteer\neffort by more than 60%. We envision this type of joint human-machine\npartnership will be of great use on future Zooniverse projects.",
            "author": [
                "Ramanakumar Sankar",
                "Kameswara Mantha",
                "Lucy Fortson",
                "Helen Spiers",
                "Thomas Pengo",
                "Douglas Mashek",
                "Myat Mo",
                "Mark Sanders",
                "Trace Christensen",
                "Jeffrey Salisbury",
                "Laura Trouille"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14177v1",
                "http://arxiv.org/pdf/2311.14177v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14169v1",
            "title": "Evaluating GPT-4's Vision Capabilities on Brazilian University Admission\n  Exams",
            "updated": "2023-11-23T19:20:59Z",
            "published": "2023-11-23T19:20:59Z",
            "summary": "Recent advancements in language models have showcased human-comparable\nperformance in academic entrance exams. However, existing studies often\noverlook questions that require the integration of visual comprehension, thus\ncompromising the full spectrum and complexity inherent in real-world scenarios.\nTo address this gap, we present a comprehensive framework to evaluate language\nmodels on entrance exams, which incorporates both textual and visual elements.\nWe evaluate the two most recent editions of Exame Nacional do Ensino M\\'edio\n(ENEM), the main standardized entrance examination adopted by Brazilian\nuniversities. Our study not only reaffirms the capabilities of GPT-4 as the\nstate of the art for handling complex multidisciplinary questions, but also\npioneers in offering a realistic assessment of multimodal language models on\nPortuguese examinations. One of the highlights is that text captions\ntranscribing visual content outperform the direct use of images, suggesting\nthat the vision model has room for improvement. Yet, despite improvements\nafforded by images or captions, mathematical questions remain a challenge for\nthese state-of-the-art models. The code and data used on experiments are\navailable at https://github.com/piresramon/gpt-4-enem.",
            "author": [
                "Ramon Pires",
                "Thales Sales Almeida",
                "Hugo Abonizio",
                "Rodrigo Nogueira"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14169v1",
                "http://arxiv.org/pdf/2311.14169v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14168v2",
            "title": "Fast Policy Learning for Linear Quadratic Control with Entropy\n  Regularization",
            "updated": "2023-12-03T05:30:45Z",
            "published": "2023-11-23T19:08:39Z",
            "summary": "This paper proposes and analyzes two new policy learning methods: regularized\npolicy gradient (RPG) and iterative policy optimization (IPO), for a class of\ndiscounted linear-quadratic control (LQC) problems over an infinite time\nhorizon with entropy regularization. Assuming access to the exact policy\nevaluation, both proposed approaches are proven to converge linearly in finding\noptimal policies of the regularized LQC. Moreover, the IPO method can achieve a\nsuper-linear convergence rate once it enters a local region around the optimal\npolicy. Finally, when the optimal policy for an RL problem with a known\nenvironment is appropriately transferred as the initial policy to an RL problem\nwith an unknown environment, the IPO method is shown to enable a super-linear\nconvergence rate if the two environments are sufficiently close. Performances\nof these proposed algorithms are supported by numerical examples.",
            "author": [
                "Xin Guo",
                "Xinyu Li",
                "Renyuan Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14168v2",
                "http://arxiv.org/pdf/2311.14168v2"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14160v1",
            "title": "Efficient and Robust Jet Tagging at the LHC with Knowledge Distillation",
            "updated": "2023-11-23T19:00:02Z",
            "published": "2023-11-23T19:00:02Z",
            "summary": "The challenging environment of real-time data processing systems at the Large\nHadron Collider (LHC) strictly limits the computational complexity of\nalgorithms that can be deployed. For deep learning models, this implies that\nonly models with low computational complexity that have weak inductive bias are\nfeasible. To address this issue, we utilize knowledge distillation to leverage\nboth the performance of large models and the reduced computational complexity\nof small ones. In this paper, we present an implementation of knowledge\ndistillation, demonstrating an overall boost in the student models' performance\nfor the task of classifying jets at the LHC. Furthermore, by using a teacher\nmodel with a strong inductive bias of Lorentz symmetry, we show that we can\ninduce the same inductive bias in the student model which leads to better\nrobustness against arbitrary Lorentz boost.",
            "author": [
                "Ryan Liu",
                "Abhijith Gandrakota",
                "Jennifer Ngadiuba",
                "Maria Spiropulu",
                "Jean-Roch Vlimant"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14160v1",
                "http://arxiv.org/pdf/2311.14160v1"
            ],
            "primary_category": "hep-ex",
            "category": [
                "hep-ex",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14157v1",
            "title": "Enabling Unsupervised Discovery in Astronomical Images through\n  Self-Supervised Representations",
            "updated": "2023-11-23T19:00:01Z",
            "published": "2023-11-23T19:00:01Z",
            "summary": "Unsupervised learning, a branch of machine learning that can operate on\nunlabelled data, has proven to be a powerful tool for data exploration and\ndiscovery in astronomy. As large surveys and new telescopes drive a rapid\nincrease in data size and richness, these techniques offer the promise of\ndiscovering new classes of objects and of efficient sorting of data into\nsimilar types. However, unsupervised learning techniques generally require\nfeature extraction to derive simple but informative representations of images.\nIn this paper, we explore the use of self-supervised deep learning as a method\nof automated representation learning. We apply the algorithm Bootstrap Your Own\nLatent (BYOL) to Galaxy Zoo DECaLS images to obtain a lower dimensional\nrepresentation of each galaxy. We briefly validate these features using a small\nsupervised classification problem. We then move on to apply an automated\nclustering algorithm, demonstrating that this fully unsupervised approach is\nable to successfully group together galaxies with similar morphology. The same\nfeatures prove useful for anomaly detection, where we use the framework\nastronomaly to search for merger candidates. Finally, we explore the\nversatility of this technique by applying the exact same approach to a small\nradio galaxy dataset. This work aims to demonstrate that applying deep\nrepresentation learning is key to unlocking the potential of unsupervised\ndiscovery in future datasets from telescopes such as the Vera C. Rubin\nObservatory and the Square Kilometre Array.",
            "author": [
                "Koketso Mohale",
                "Michelle Lochner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14157v1",
                "http://arxiv.org/pdf/2311.14157v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14156v1",
            "title": "Variational Annealing on Graphs for Combinatorial Optimization",
            "updated": "2023-11-23T18:56:51Z",
            "published": "2023-11-23T18:56:51Z",
            "summary": "Several recent unsupervised learning methods use probabilistic approaches to\nsolve combinatorial optimization (CO) problems based on the assumption of\nstatistically independent solution variables. We demonstrate that this\nassumption imposes performance limitations in particular on difficult problem\ninstances. Our results corroborate that an autoregressive approach which\ncaptures statistical dependencies among solution variables yields superior\nperformance on many popular CO problems. We introduce subgraph tokenization in\nwhich the configuration of a set of solution variables is represented by a\nsingle token. This tokenization technique alleviates the drawback of the long\nsequential sampling procedure which is inherent to autoregressive methods\nwithout sacrificing expressivity. Importantly, we theoretically motivate an\nannealed entropy regularization and show empirically that it is essential for\nefficient and stable learning.",
            "author": [
                "Sebastian Sanokowski",
                "Wilhelm Berghammer",
                "Sepp Hochreiter",
                "Sebastian Lehner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14156v1",
                "http://arxiv.org/pdf/2311.14156v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DM",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14153v1",
            "title": "Tube-NeRF: Efficient Imitation Learning of Visuomotor Policies from MPC\n  using Tube-Guided Data Augmentation and NeRFs",
            "updated": "2023-11-23T18:54:25Z",
            "published": "2023-11-23T18:54:25Z",
            "summary": "Imitation learning (IL) can train computationally-efficient sensorimotor\npolicies from a resource-intensive Model Predictive Controller (MPC), but it\noften requires many samples, leading to long training times or limited\nrobustness. To address these issues, we combine IL with a variant of robust MPC\nthat accounts for process and sensing uncertainties, and we design a data\naugmentation (DA) strategy that enables efficient learning of vision-based\npolicies. The proposed DA method, named Tube-NeRF, leverages Neural Radiance\nFields (NeRFs) to generate novel synthetic images, and uses properties of the\nrobust MPC (the tube) to select relevant views and to efficiently compute the\ncorresponding actions. We tailor our approach to the task of localization and\ntrajectory tracking on a multirotor, by learning a visuomotor policy that\ngenerates control actions using images from the onboard camera as only source\nof horizontal position. Our evaluations numerically demonstrate learning of a\nrobust visuomotor policy with an 80-fold increase in demonstration efficiency\nand a 50% reduction in training time over current IL methods. Additionally, our\npolicies successfully transfer to a real multirotor, achieving accurate\nlocalization and low tracking errors despite large disturbances, with an\nonboard inference time of only 1.5 ms.",
            "author": [
                "Andrea Tagliabue",
                "Jonathan P. How"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14153v1",
                "http://arxiv.org/pdf/2311.14153v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14148v1",
            "title": "Automated 3D Tumor Segmentation using Temporal Cubic PatchGAN (TCuP-GAN)",
            "updated": "2023-11-23T18:37:26Z",
            "published": "2023-11-23T18:37:26Z",
            "summary": "Development of robust general purpose 3D segmentation frameworks using the\nlatest deep learning techniques is one of the active topics in various\nbio-medical domains. In this work, we introduce Temporal Cubic PatchGAN\n(TCuP-GAN), a volume-to-volume translational model that marries the concepts of\na generative feature learning framework with Convolutional Long Short-Term\nMemory Networks (LSTMs), for the task of 3D segmentation. We demonstrate the\ncapabilities of our TCuP-GAN on the data from four segmentation challenges\n(Adult Glioma, Meningioma, Pediatric Tumors, and Sub-Saharan Africa subset)\nfeatured within the 2023 Brain Tumor Segmentation (BraTS) Challenge and\nquantify its performance using LesionWise Dice similarity and $95\\%$ Hausdorff\nDistance metrics. We demonstrate the successful learning of our framework to\npredict robust multi-class segmentation masks across all the challenges. This\nbenchmarking work serves as a stepping stone for future efforts towards\napplying TCuP-GAN on other multi-class tasks such as multi-organelle\nsegmentation in electron microscopy imaging.",
            "author": [
                "Kameswara Bharadwaj Mantha",
                "Ramanakumar Sankar",
                "Lucy Fortson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14148v1",
                "http://arxiv.org/pdf/2311.14148v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14146v1",
            "title": "Class Balanced Dynamic Acquisition for Domain Adaptive Semantic\n  Segmentation using Active Learning",
            "updated": "2023-11-23T18:35:26Z",
            "published": "2023-11-23T18:35:26Z",
            "summary": "Domain adaptive active learning is leading the charge in label-efficient\ntraining of neural networks. For semantic segmentation, state-of-the-art models\njointly use two criteria of uncertainty and diversity to select training\nlabels, combined with a pixel-wise acquisition strategy. However, we show that\nsuch methods currently suffer from a class imbalance issue which degrades their\nperformance for larger active learning budgets. We then introduce Class\nBalanced Dynamic Acquisition (CBDA), a novel active learning method that\nmitigates this issue, especially in high-budget regimes. The more balanced\nlabels increase minority class performance, which in turn allows the model to\noutperform the previous baseline by 0.6, 1.7, and 2.4 mIoU for budgets of 5%,\n10%, and 20%, respectively. Additionally, the focus on minority classes leads\nto improvements of the minimum class performance of 0.5, 2.9, and 4.6 IoU\nrespectively. The top-performing model even exceeds the fully supervised\nbaseline, showing that a more balanced label than the entire ground truth can\nbe beneficial.",
            "author": [
                "Marc Schachtsiek",
                "Simone Rossi",
                "Thomas Hannagan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14146v1",
                "http://arxiv.org/pdf/2311.14146v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14139v1",
            "title": "Machine Learning For An Explainable Cost Prediction of Medical Insurance",
            "updated": "2023-11-23T18:13:34Z",
            "published": "2023-11-23T18:13:34Z",
            "summary": "Predictive modeling in healthcare continues to be an active actuarial\nresearch topic as more insurance companies aim to maximize the potential of\nMachine Learning approaches to increase their productivity and efficiency. In\nthis paper, the authors deployed three regression-based ensemble ML models that\ncombine variations of decision trees through Extreme Gradient Boosting,\nGradient-boosting Machine, and Random Forest) methods in predicting medical\ninsurance costs. Explainable Artificial Intelligence methods SHapley Additive\nexPlanations and Individual Conditional Expectation plots were deployed to\ndiscover and explain the key determinant factors that influence medical\ninsurance premium prices in the dataset. The dataset used comprised 986 records\nand is publicly available in the KAGGLE repository. The models were evaluated\nusing four performance evaluation metrics, including R-squared, Mean Absolute\nError, Root Mean Squared Error, and Mean Absolute Percentage Error. The results\nshow that all models produced impressive outcomes; however, the XGBoost model\nachieved a better overall performance although it also expanded more\ncomputational resources, while the RF model recorded a lesser prediction error\nand consumed far fewer computing resources than the XGBoost model. Furthermore,\nwe compared the outcome of both XAi methods in identifying the key determinant\nfeatures that influenced the PremiumPrices for each model and whereas both XAi\nmethods produced similar outcomes, we found that the ICE plots showed in more\ndetail the interactions between each variable than the SHAP analysis which\nseemed to be more high-level. It is the aim of the authors that the\ncontributions of this study will help policymakers, insurers, and potential\nmedical insurance buyers in their decision-making process for selecting the\nright policies that meet their specific needs.",
            "author": [
                "Ugochukwu Orji",
                "Elochukwu Ukwandu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14139v1",
                "http://arxiv.org/pdf/2311.14139v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14137v1",
            "title": "Privacy-Preserving Algorithmic Recourse",
            "updated": "2023-11-23T18:08:15Z",
            "published": "2023-11-23T18:08:15Z",
            "summary": "When individuals are subject to adverse outcomes from machine learning\nmodels, providing a recourse path to help achieve a positive outcome is\ndesirable. Recent work has shown that counterfactual explanations - which can\nbe used as a means of single-step recourse - are vulnerable to privacy issues,\nputting an individuals' privacy at risk. Providing a sequential multi-step path\nfor recourse can amplify this risk. Furthermore, simply adding noise to\nrecourse paths found from existing methods can impact the realism and\nactionability of the path for an end-user. In this work, we address privacy\nissues when generating realistic recourse paths based on instance-based\ncounterfactual explanations, and provide PrivRecourse: an end-to-end privacy\npreserving pipeline that can provide realistic recourse paths. PrivRecourse\nuses differentially private (DP) clustering to represent non-overlapping\nsubsets of the private dataset. These DP cluster centers are then used to\ngenerate recourse paths by forming a graph with cluster centers as the nodes,\nso that we can generate realistic - feasible and actionable - recourse paths.\nWe empirically evaluate our approach on finance datasets and compare it to\nsimply adding noise to data instances, and to using DP synthetic data, to\ngenerate the graph. We observe that PrivRecourse can provide paths that are\nprivate and realistic.",
            "author": [
                "Sikha Pentyala",
                "Shubham Sharma",
                "Sanjay Kariyappa",
                "Freddy Lecue",
                "Daniele Magazzeni"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14137v1",
                "http://arxiv.org/pdf/2311.14137v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14136v1",
            "title": "A Blockchain Solution for Collaborative Machine Learning over IoT",
            "updated": "2023-11-23T18:06:05Z",
            "published": "2023-11-23T18:06:05Z",
            "summary": "The rapid growth of Internet of Things (IoT) devices and applications has led\nto an increased demand for advanced analytics and machine learning techniques\ncapable of handling the challenges associated with data privacy, security, and\nscalability. Federated learning (FL) and blockchain technologies have emerged\nas promising approaches to address these challenges by enabling decentralized,\nsecure, and privacy-preserving model training on distributed data sources. In\nthis paper, we present a novel IoT solution that combines the incremental\nlearning vector quantization algorithm (XuILVQ) with Ethereum blockchain\ntechnology to facilitate secure and efficient data sharing, model training, and\nprototype storage in a distributed environment. Our proposed architecture\naddresses the shortcomings of existing blockchain-based FL solutions by\nreducing computational and communication overheads while maintaining data\nprivacy and security. We assess the performance of our system through a series\nof experiments, showcasing its potential to enhance the accuracy and efficiency\nof machine learning tasks in IoT settings.",
            "author": [
                "Carlos Beis-Penedo",
                "Francisco Troncoso-Pastoriza",
                "Rebeca P. D\u00edaz-Redondo",
                "Ana Fern\u00e1ndez-Vilas",
                "Manuel Fern\u00e1ndez-Veiga",
                "Mart\u00edn Gonz\u00e1lez Soto"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14136v1",
                "http://arxiv.org/pdf/2311.14136v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14131v1",
            "title": "Exactly conservative physics-informed neural networks and deep operator\n  networks for dynamical systems",
            "updated": "2023-11-23T17:59:48Z",
            "published": "2023-11-23T17:59:48Z",
            "summary": "We introduce a method for training exactly conservative physics-informed\nneural networks and physics-informed deep operator networks for dynamical\nsystems. The method employs a projection-based technique that maps a candidate\nsolution learned by the neural network solver for any given dynamical system\npossessing at least one first integral onto an invariant manifold. We\nillustrate that exactly conservative physics-informed neural network solvers\nand physics-informed deep operator networks for dynamical systems vastly\noutperform their non-conservative counterparts for several real-world problems\nfrom the mathematical sciences.",
            "author": [
                "Elsa Cardoso-Bihlo",
                "Alex Bihlo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14131v1",
                "http://arxiv.org/pdf/2311.14131v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14127v1",
            "title": "Byzantine Robustness and Partial Participation Can Be Achieved\n  Simultaneously: Just Clip Gradient Differences",
            "updated": "2023-11-23T17:50:30Z",
            "published": "2023-11-23T17:50:30Z",
            "summary": "Distributed learning has emerged as a leading paradigm for training large\nmachine learning models. However, in real-world scenarios, participants may be\nunreliable or malicious, posing a significant challenge to the integrity and\naccuracy of the trained models. Byzantine fault tolerance mechanisms have been\nproposed to address these issues, but they often assume full participation from\nall clients, which is not always practical due to the unavailability of some\nclients or communication constraints. In our work, we propose the first\ndistributed method with client sampling and provable tolerance to Byzantine\nworkers. The key idea behind the developed method is the use of gradient\nclipping to control stochastic gradient differences in recursive variance\nreduction. This allows us to bound the potential harm caused by Byzantine\nworkers, even during iterations when all sampled clients are Byzantine.\nFurthermore, we incorporate communication compression into the method to\nenhance communication efficiency. Under quite general assumptions, we prove\nconvergence rates for the proposed method that match the existing\nstate-of-the-art (SOTA) theoretical results.",
            "author": [
                "Grigory Malinovsky",
                "Peter Richt\u00e1rik",
                "Samuel Horv\u00e1th",
                "Eduard Gorbunov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14127v1",
                "http://arxiv.org/pdf/2311.14127v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DC",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14126v1",
            "title": "Towards Auditing Large Language Models: Improving Text-based Stereotype\n  Detection",
            "updated": "2023-11-23T17:47:14Z",
            "published": "2023-11-23T17:47:14Z",
            "summary": "Large Language Models (LLM) have made significant advances in the recent past\nbecoming more mainstream in Artificial Intelligence (AI) enabled human-facing\napplications. However, LLMs often generate stereotypical output inherited from\nhistorical data, amplifying societal biases and raising ethical concerns. This\nwork introduces i) the Multi-Grain Stereotype Dataset, which includes 52,751\ninstances of gender, race, profession and religion stereotypic text and ii) a\nnovel stereotype classifier for English text. We design several experiments to\nrigorously test the proposed model trained on the novel dataset. Our\nexperiments show that training the model in a multi-class setting can\noutperform the one-vs-all binary counterpart. Consistent feature importance\nsignals from different eXplainable AI tools demonstrate that the new model\nexploits relevant text features. We utilise the newly created model to assess\nthe stereotypic behaviour of the popular GPT family of models and observe the\nreduction of bias over time. In summary, our work establishes a robust and\npractical framework for auditing and evaluating the stereotypic bias in LLM.",
            "author": [
                "Wu Zekun",
                "Sahan Bulathwela",
                "Adriano Soares Koshiyama"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14126v1",
                "http://arxiv.org/pdf/2311.14126v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CY",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14125v1",
            "title": "Scalable AI Safety via Doubly-Efficient Debate",
            "updated": "2023-11-23T17:46:30Z",
            "published": "2023-11-23T17:46:30Z",
            "summary": "The emergence of pre-trained AI systems with powerful capabilities across a\ndiverse and ever-increasing set of complex domains has raised a critical\nchallenge for AI safety as tasks can become too complicated for humans to judge\ndirectly. Irving et al. [2018] proposed a debate method in this direction with\nthe goal of pitting the power of such AI models against each other until the\nproblem of identifying (mis)-alignment is broken down into a manageable\nsubtask. While the promise of this approach is clear, the original framework\nwas based on the assumption that the honest strategy is able to simulate\ndeterministic AI systems for an exponential number of steps, limiting its\napplicability. In this paper, we show how to address these challenges by\ndesigning a new set of debate protocols where the honest strategy can always\nsucceed using a simulation of a polynomial number of steps, whilst being able\nto verify the alignment of stochastic AI systems, even when the dishonest\nstrategy is allowed to use exponentially many simulation steps.",
            "author": [
                "Jonah Brown-Cohen",
                "Geoffrey Irving",
                "Georgios Piliouras"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14125v1",
                "http://arxiv.org/pdf/2311.14125v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14122v1",
            "title": "Decompositions of the mean continuous ranked probability score",
            "updated": "2023-11-23T17:35:16Z",
            "published": "2023-11-23T17:35:16Z",
            "summary": "The continuous ranked probability score (crps) is the most commonly used\nscoring rule in the evaluation of probabilistic forecasts for real-valued\noutcomes. To assess and rank forecasting methods, researchers compute the mean\ncrps over given sets of forecast situations, based on the respective predictive\ndistributions and outcomes. We propose a new, isotonicity-based decomposition\nof the mean crps into interpretable components that quantify miscalibration\n(MSC), discrimination ability (DSC), and uncertainty (UNC), respectively. In a\ndetailed theoretical analysis, we compare the new approach to empirical\ndecompositions proposed earlier, generalize to population versions, analyse\ntheir properties and relationships, and relate to a hierarchy of notions of\ncalibration. The isotonicity-based decomposition guarantees the nonnegativity\nof the components and quantifies calibration in a sense that is stronger than\nfor other types of decompositions, subject to the nondegeneracy of empirical\ndecompositions. We illustrate the usage of the isotonicity-based decomposition\nin case studies from weather prediction and machine learning.",
            "author": [
                "Sebastian Arnold",
                "Eva-Maria Walz",
                "Johanna Ziegel",
                "Tilmann Gneiting"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14122v1",
                "http://arxiv.org/pdf/2311.14122v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14120v1",
            "title": "Weight fluctuations in (deep) linear neural networks and a derivation of\n  the inverse-variance flatness relation",
            "updated": "2023-11-23T17:30:31Z",
            "published": "2023-11-23T17:30:31Z",
            "summary": "We investigate the stationary (late-time) training regime of single- and\ntwo-layer linear neural networks within the continuum limit of stochastic\ngradient descent (SGD) for synthetic Gaussian data. In the case of a\nsingle-layer network in the weakly oversampled regime, the spectrum of the\nnoise covariance matrix deviates notably from the Hessian, which can be\nattributed to the broken detailed balance of SGD dynamics. The weight\nfluctuations are in this case generally anisotropic, but experience an\nisotropic loss. For a two-layer network, we obtain the stochastic dynamics of\nthe weights in each layer and analyze the associated stationary covariances. We\nidentify the inter-layer coupling as a new source of anisotropy for the weight\nfluctuations. In contrast to the single-layer case, the weight fluctuations\nexperience an anisotropic loss, the flatness of which is inversely related to\nthe fluctuation variance. We thereby provide an analytical derivation of the\nrecently observed inverse variance-flatness relation in a deep linear network\nmodel.",
            "author": [
                "Markus Gross",
                "Arne P. Raulf",
                "Christoph R\u00e4th"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14120v1",
                "http://arxiv.org/pdf/2311.14120v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cond-mat.dis-nn",
                "cond-mat.stat-mech"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14116v1",
            "title": "Hierarchical Coded Gradient Aggregation Based on Layered MDS Codes",
            "updated": "2023-11-23T17:21:05Z",
            "published": "2023-11-23T17:21:05Z",
            "summary": "The growing privacy concerns and the communication costs associated with\ntransmitting raw data have resulted in techniques like federated learning,\nwhere the machine learning models are trained at the edge nodes, and the\nparameter updates are shared with a central server. Because communications from\nthe edge nodes are often unreliable, a hierarchical setup involving\nintermediate helper nodes is considered. The communication links between the\nedges and the helper nodes are error-prone and are modeled as\nstraggling/failing links. To overcome the issue of link failures, coding\ntechniques are proposed. The edge nodes communicate encoded versions of the\nmodel updates to the helper nodes, which pass them on to the master after\nsuitable aggregation. The primary work in this area uses repetition codes and\nMaximum Distance Separable (MDS) codes at the edge nodes to arrive at the\nAligned Repetition Coding (ARC) and Aligned MDS Coding (AMC) schemes,\nrespectively. We propose using vector codes, specifically a family of layered\nMDS codes parameterized by a variable $\\nu$, at the edge nodes. For the\nproposed family of codes, suitable aggregation strategies at the helper nodes\nare also developed. At the extreme values of $\\nu$, our scheme matches the\ncommunication costs incurred by the ARC and AMC schemes, resulting in a\ngraceful transition between these schemes.",
            "author": [
                "M. Nikhil Krishnan",
                "Anoop Thomas",
                "Birenjith Sasidharan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14116v1",
                "http://arxiv.org/pdf/2311.14116v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14115v2",
            "title": "A density estimation perspective on learning from pairwise human\n  preferences",
            "updated": "2023-11-30T21:44:40Z",
            "published": "2023-11-23T17:20:36Z",
            "summary": "Learning from human feedback (LHF) -- and in particular learning from\npairwise preferences -- has recently become a crucial ingredient in training\nlarge language models (LLMs), and has been the subject of much research. Most\nrecent works frame it as a reinforcement learning problem, where a reward\nfunction is learned from pairwise preference data and the LLM is treated as a\npolicy which is adapted to maximize the rewards, often under additional\nregularization constraints. We propose an alternative interpretation which\ncenters on the generative process for pairwise preferences and treats LHF as a\ndensity estimation problem. We provide theoretical and empirical results\nshowing that for a family of generative processes defined via preference\nbehavior distribution equations, training a reward function on pairwise\npreferences effectively models an annotator's implicit preference distribution.\nFinally, we discuss and present findings on \"annotator misspecification\" --\nfailure cases where wrong modeling assumptions are made about annotator\nbehavior, resulting in poorly-adapted models -- suggesting that approaches that\nlearn from pairwise human preferences could have trouble learning from a\npopulation of annotators with diverse viewpoints.",
            "author": [
                "Vincent Dumoulin",
                "Daniel D. Johnson",
                "Pablo Samuel Castro",
                "Hugo Larochelle",
                "Yann Dauphin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14115v2",
                "http://arxiv.org/pdf/2311.14115v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14114v1",
            "title": "SySMOL: A Hardware-software Co-design Framework for Ultra-Low and\n  Fine-Grained Mixed-Precision Neural Networks",
            "updated": "2023-11-23T17:20:09Z",
            "published": "2023-11-23T17:20:09Z",
            "summary": "Recent advancements in quantization and mixed-precision techniques offer\nsignificant promise for improving the run-time and energy efficiency of neural\nnetworks. In this work, we further showed that neural networks, wherein\nindividual parameters or activations can take on different precisions ranging\nbetween 1 and 4 bits, can achieve accuracies comparable to or exceeding the\nfull-precision counterparts. However, the deployment of such networks poses\nnumerous challenges, stemming from the necessity to manage and control the\ncompute/communication/storage requirements associated with these extremely\nfine-grained mixed precisions for each piece of data. There is a lack of\nexisting efficient hardware and system-level support tailored to these unique\nand challenging requirements. Our research introduces the first novel holistic\nhardware-software co-design approach for these networks, which enables a\ncontinuous feedback loop between hardware design, training, and inference to\nfacilitate systematic design exploration. As a proof-of-concept, we illustrate\nthis co-design approach by designing new, configurable CPU SIMD architectures\ntailored for these networks, tightly integrating the architecture with new\nsystem-aware training and inference techniques. We perform systematic design\nspace exploration using this framework to analyze various tradeoffs. The design\nfor mixed-precision networks that achieves optimized tradeoffs corresponds to\nan architecture that supports 1, 2, and 4-bit fixed-point operations with four\nconfigurable precision patterns, when coupled with system-aware training and\ninference optimization -- networks trained for this design achieve accuracies\nthat closely match full-precision accuracies, while compressing and improving\nrun-time efficiency of the neural networks drastically by 10-20x, compared to\nfull-precision networks.",
            "author": [
                "Cyrus Zhou",
                "Vaughn Richard",
                "Pedro Savarese",
                "Zachary Hassman",
                "Michael Maire",
                "Michael DiBrino",
                "Yanjing Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14114v1",
                "http://arxiv.org/pdf/2311.14114v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR",
                "cs.LG",
                "cs.PF"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14110v1",
            "title": "When is Off-Policy Evaluation Useful? A Data-Centric Perspective",
            "updated": "2023-11-23T17:13:37Z",
            "published": "2023-11-23T17:13:37Z",
            "summary": "Evaluating the value of a hypothetical target policy with only a logged\ndataset is important but challenging. On the one hand, it brings opportunities\nfor safe policy improvement under high-stakes scenarios like clinical\nguidelines. On the other hand, such opportunities raise a need for precise\noff-policy evaluation (OPE). While previous work on OPE focused on improving\nthe algorithm in value estimation, in this work, we emphasize the importance of\nthe offline dataset, hence putting forward a data-centric framework for\nevaluating OPE problems. We propose DataCOPE, a data-centric framework for\nevaluating OPE, that answers the questions of whether and to what extent we can\nevaluate a target policy given a dataset. DataCOPE (1) forecasts the overall\nperformance of OPE algorithms without access to the environment, which is\nespecially useful before real-world deployment where evaluating OPE is\nimpossible; (2) identifies the sub-group in the dataset where OPE can be\ninaccurate; (3) permits evaluations of datasets or data-collection strategies\nfor OPE problems. Our empirical analysis of DataCOPE in the logged contextual\nbandit settings using healthcare datasets confirms its ability to evaluate both\nmachine-learning and human expert policies like clinical guidelines.",
            "author": [
                "Hao Sun",
                "Alex J. Chan",
                "Nabeel Seedat",
                "Alihan H\u00fcy\u00fck",
                "Mihaela van der Schaar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14110v1",
                "http://arxiv.org/pdf/2311.14110v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14108v1",
            "title": "MINTY: Rule-based Models that Minimize the Need for Imputing Features\n  with Missing Values",
            "updated": "2023-11-23T17:09:12Z",
            "published": "2023-11-23T17:09:12Z",
            "summary": "Rule models are often preferred in prediction tasks with tabular inputs as\nthey can be easily interpreted using natural language and provide predictive\nperformance on par with more complex models. However, most rule models'\npredictions are undefined or ambiguous when some inputs are missing, forcing\nusers to rely on statistical imputation models or heuristics like zero\nimputation, undermining the interpretability of the models. In this work, we\npropose fitting concise yet precise rule models that learn to avoid relying on\nfeatures with missing values and, therefore, limit their reliance on imputation\nat test time. We develop MINTY, a method that learns rules in the form of\ndisjunctions between variables that act as replacements for each other when one\nor more is missing. This results in a sparse linear rule model, regularized to\nhave small dependence on features with missing values, that allows a trade-off\nbetween goodness of fit, interpretability, and robustness to missing values at\ntest time. We demonstrate the value of MINTY in experiments using synthetic and\nreal-world data sets and find its predictive performance comparable or\nfavorable to baselines, with smaller reliance on features with missing values.",
            "author": [
                "Lena Stempfle",
                "Fredrik D. Johansson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14108v1",
                "http://arxiv.org/pdf/2311.14108v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14105v1",
            "title": "Hybrid quantum-classical reservoir computing for simulating chaotic\n  systems",
            "updated": "2023-11-23T17:07:02Z",
            "published": "2023-11-23T17:07:02Z",
            "summary": "Forecasting chaotic systems is a notably complex task, which in recent years\nhas been approached with reasonable success using reservoir computing (RC), a\nrecurrent network with fixed random weights (the reservoir) used to extract the\nspatio-temporal information of the system. This work presents a hybrid quantum\nreservoir-computing (HQRC) framework, which replaces the reservoir in RC with a\nquantum circuit. The modular structure and measurement feedback in the circuit\nare used to encode the complex system dynamics in the reservoir states, from\nwhich classical learning is performed to predict future dynamics. The noiseless\nsimulations of HQRC demonstrate valid prediction times comparable to\nstate-of-the-art classical RC models for both the Lorenz63 and double-scroll\nchaotic paradigmatic systems and adhere to the attractor dynamics long after\nthe forecasts have deviated from the ground truth.",
            "author": [
                "Filip Wudarski",
                "Daniel O`Connor",
                "Shaun Geaney",
                "Ata Akbari Asanjan",
                "Max Wilson",
                "Elena Strbac",
                "P. Aaron Lott",
                "Davide Venturelli"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14105v1",
                "http://arxiv.org/pdf/2311.14105v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14102v1",
            "title": "Possibilities of Identifying Members from Milky Way Satellite Galaxies\n  using Unsupervised Machine Learning Algorithms",
            "updated": "2023-11-23T17:02:30Z",
            "published": "2023-11-23T17:02:30Z",
            "summary": "A detailed study of stellar populations in Milky Way (MW) satellite galaxies\nremains an observational challenge due to their faintness and fewer\nspectroscopically confirmed member stars. We use unsupervised machine learning\nmethods to identify new members for nine nearby MW satellite galaxies using\nGaia data release-3 (Gaia DR3) astrometry and the Dark Energy Survey (DES) and\nthe DECam Local Volume Exploration Survey (DELVE) photometry. Two density-based\nclustering algorithms, DBSCAN and HDBSCAN, have been used in the\nfour-dimensional astrometric parameter space to identify member stars belonging\nto MW satellite galaxies. Our results indicate that we can recover more than\n80% of the known spectroscopically confirmed members in most of the satellite\ngalaxies and also reject 95-100% of spectroscopic non-members. We have also\nadded many new members using this method. We compare our results with previous\nstudies that also use photometric and astrometric data and discuss the\nsuitability of density-based clustering methods for MW satellite galaxies",
            "author": [
                "Devika K Divakar",
                "Pallavi Saraf",
                "Sivarani Thirupathi",
                "Vijayakumar H Doddamani"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14102v1",
                "http://arxiv.org/pdf/2311.14102v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14101v1",
            "title": "Subnetwork Ensembles",
            "updated": "2023-11-23T17:01:16Z",
            "published": "2023-11-23T17:01:16Z",
            "summary": "Neural network ensembles have been effectively used to improve generalization\nby combining the predictions of multiple independently trained models. However,\nthe growing scale and complexity of deep neural networks have led to these\nmethods becoming prohibitively expensive and time consuming to implement.\nLow-cost ensemble methods have become increasingly important as they can\nalleviate the need to train multiple models from scratch while retaining the\ngeneralization benefits that traditional ensemble learning methods afford. This\ndissertation introduces and formalizes a low-cost framework for constructing\nSubnetwork Ensembles, where a collection of child networks are formed by\nsampling, perturbing, and optimizing subnetworks from a trained parent model.\nWe explore several distinct methodologies for generating child networks and we\nevaluate their efficacy through a variety of ablation studies and established\nbenchmarks. Our findings reveal that this approach can greatly improve training\nefficiency, parametric utilization, and generalization performance while\nminimizing computational cost. Subnetwork Ensembles offer a compelling\nframework for exploring how we can build better systems by leveraging the\nunrealized potential of deep neural networks.",
            "author": [
                "Tim Whitaker"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14101v1",
                "http://arxiv.org/pdf/2311.14101v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14100v1",
            "title": "MonoNav: MAV Navigation via Monocular Depth Estimation and\n  Reconstruction",
            "updated": "2023-11-23T16:59:25Z",
            "published": "2023-11-23T16:59:25Z",
            "summary": "A major challenge in deploying the smallest of Micro Aerial Vehicle (MAV)\nplatforms (< 100 g) is their inability to carry sensors that provide\nhigh-resolution metric depth information (e.g., LiDAR or stereo cameras).\nCurrent systems rely on end-to-end learning or heuristic approaches that\ndirectly map images to control inputs, and struggle to fly fast in unknown\nenvironments. In this work, we ask the following question: using only a\nmonocular camera, optical odometry, and offboard computation, can we create\nmetrically accurate maps to leverage the powerful path planning and navigation\napproaches employed by larger state-of-the-art robotic systems to achieve\nrobust autonomy in unknown environments? We present MonoNav: a fast 3D\nreconstruction and navigation stack for MAVs that leverages recent advances in\ndepth prediction neural networks to enable metrically accurate 3D scene\nreconstruction from a stream of monocular images and poses. MonoNav uses\noff-the-shelf pre-trained monocular depth estimation and fusion techniques to\nconstruct a map, then searches over motion primitives to plan a collision-free\ntrajectory to the goal. In extensive hardware experiments, we demonstrate how\nMonoNav enables the Crazyflie (a 37 g MAV) to navigate fast (0.5 m/s) in\ncluttered indoor environments. We evaluate MonoNav against a state-of-the-art\nend-to-end approach, and find that the collision rate in navigation is\nsignificantly reduced (by a factor of 4). This increased safety comes at the\ncost of conservatism in terms of a 22% reduction in goal completion.",
            "author": [
                "Nathaniel Simon",
                "Anirudha Majumdar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14100v1",
                "http://arxiv.org/pdf/2311.14100v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14095v1",
            "title": "Video Anomaly Detection using GAN",
            "updated": "2023-11-23T16:41:30Z",
            "published": "2023-11-23T16:41:30Z",
            "summary": "Accounting for the increased concern for public safety, automatic abnormal\nevent detection and recognition in a surveillance scene is crucial. It is a\ncurrent open study subject because of its intricacy and utility. The\nidentification of aberrant events automatically, it's a difficult undertaking\nbecause everyone's idea of abnormality is different. A typical occurrence in\none circumstance could be seen as aberrant in another. Automatic anomaly\nidentification becomes particularly challenging in the surveillance footage\nwith a large crowd due to congestion and high occlusion. With the use of\nmachine learning techniques, this thesis study aims to offer the solution for\nthis use case so that human resources won't be required to keep an eye out for\nany unusual activity in the surveillance system records. We have developed a\nnovel generative adversarial network (GAN) based anomaly detection model. This\nmodel is trained such that it learns together about constructing a high\ndimensional picture space and determining the latent space from the video's\ncontext. The generator uses a residual Autoencoder architecture made up of a\nmulti-stage channel attention-based decoder and a two-stream, deep\nconvolutional encoder that can realise both spatial and temporal data. We have\nalso offered a technique for refining the GAN model that reduces training time\nwhile also generalising the model by utilising transfer learning between\ndatasets. Using a variety of assessment measures, we compare our model to the\ncurrent state-of-the-art techniques on four benchmark datasets. The empirical\nfindings indicate that, in comparison to existing techniques, our network\nperforms favourably on all datasets.",
            "author": [
                "Anikeit Sethi",
                "Krishanu Saini",
                "Sai Mounika Mididoddi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14095v1",
                "http://arxiv.org/pdf/2311.14095v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14094v1",
            "title": "Robust Decision Aggregation with Second-order Information",
            "updated": "2023-11-23T16:39:55Z",
            "published": "2023-11-23T16:39:55Z",
            "summary": "We consider a decision aggregation problem with two experts who each make a\nbinary recommendation after observing a private signal about an unknown binary\nworld state. An agent, who does not know the joint information structure\nbetween signals and states, sees the experts' recommendations and aims to match\nthe action with the true state. Under the scenario, we study whether\nsupplemented additionally with second-order information (each expert's forecast\non the other's recommendation) could enable a better aggregation.\n  We adopt a minimax regret framework to evaluate the aggregator's performance,\nby comparing it to an omniscient benchmark that knows the joint information\nstructure. With general information structures, we show that second-order\ninformation provides no benefit. No aggregator can improve over a trivial\naggregator, which always follows the first expert's recommendation. However,\npositive results emerge when we assume experts' signals are conditionally\nindependent given the world state. When the aggregator is deterministic, we\npresent a robust aggregator that leverages second-order information, which can\nsignificantly outperform counterparts without it. Second, when two experts are\nhomogeneous, by adding a non-degenerate assumption on the signals, we\ndemonstrate that random aggregators using second-order information can surpass\noptimal ones without it. In the remaining settings, the second-order\ninformation is not beneficial. We also extend the above results to the setting\nwhen the aggregator's utility function is more general.",
            "author": [
                "Yuqi Pan",
                "Zhaohua Chen",
                "Yuqing Kong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14094v1",
                "http://arxiv.org/pdf/2311.14094v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14091v1",
            "title": "PortfolioMentor: Multimodal Generative AI Companion for Learning and\n  Crafting Interactive Digital Art Portfolios",
            "updated": "2023-11-23T16:36:40Z",
            "published": "2023-11-23T16:36:40Z",
            "summary": "Digital art portfolios serve as impactful mediums for artists to convey their\nvisions, weaving together visuals, audio, interactions, and narratives.\nHowever, without technical backgrounds, design students often find it\nchallenging to translate creative ideas into tangible codes and designs, given\nthe lack of tailored resources for the non-technical, academic support in art\nschools, and a comprehensive guiding tool throughout the mentally demanding\nprocess. Recognizing the role of companionship in code learning and leveraging\ngenerative AI models' capabilities in supporting creative tasks, we present\nPortfolioMentor, a coding companion chatbot for IDEs. This tool guides and\ncollaborates with students through proactive suggestions and responsible Q&As\nfor learning, inspiration, and support. In detail, the system starts with the\nunderstanding of the task and artist's visions, follows the co-creation of\nvisual illustrations, audio or music suggestions and files, click-scroll\neffects for interactions, and creative vision conceptualization, and finally\nsynthesizes these facets into a polished interactive digital portfolio.",
            "author": [
                "Tao Long",
                "Weirui Peng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14091v1",
                "http://arxiv.org/pdf/2311.14091v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI",
                "cs.CY",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14090v1",
            "title": "Class Uncertainty: A Measure to Mitigate Class Imbalance",
            "updated": "2023-11-23T16:36:03Z",
            "published": "2023-11-23T16:36:03Z",
            "summary": "Class-wise characteristics of training examples affect the performance of\ndeep classifiers. A well-studied example is when the number of training\nexamples of classes follows a long-tailed distribution, a situation that is\nlikely to yield sub-optimal performance for under-represented classes. This\nclass imbalance problem is conventionally addressed by approaches relying on\nthe class-wise cardinality of training examples, such as data resampling. In\nthis paper, we demonstrate that considering solely the cardinality of classes\ndoes not cover all issues causing class imbalance. To measure class imbalance,\nwe propose \"Class Uncertainty\" as the average predictive uncertainty of the\ntraining examples, and we show that this novel measure captures the differences\nacross classes better than cardinality. We also curate SVCI-20 as a novel\ndataset in which the classes have equal number of training examples but they\ndiffer in terms of their hardness; thereby causing a type of class imbalance\nwhich cannot be addressed by the approaches relying on cardinality. We\nincorporate our \"Class Uncertainty\" measure into a diverse set of ten class\nimbalance mitigation methods to demonstrate its effectiveness on long-tailed\ndatasets as well as on our SVCI-20. Code and datasets will be made available.",
            "author": [
                "Z. S. Baltaci",
                "K. Oksuz",
                "S. Kuzucu",
                "K. Tezoren",
                "B. K. Konar",
                "A. Ozkan",
                "E. Akbas",
                "S. Kalkan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14090v1",
                "http://arxiv.org/pdf/2311.14090v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14088v1",
            "title": "Observation of $\u039b_{b}^{0} \\to \u039b_{c}^{+} \\bar{D}^{(*)0}\n  K^{-}$ and $\u039b_{b}^{0} \\to \u039b_{c}^{+} D_{s}^{*-}$ decays",
            "updated": "2023-11-23T16:27:21Z",
            "published": "2023-11-23T16:27:21Z",
            "summary": "The decays $\\Lambda_b^0 \\to \\Lambda_c^+\\bar{D}^{(*)0}K^-$ and $\\Lambda_b^0\n\\to \\Lambda_c^+ D_s^{*-}$ are observed for the first time, in proton-proton\ncollision data at $\\sqrt{s}=13$TeV corresponding to an integrated luminosity of\n5.4 fb${}^{-1}$ collected with the LHCb detector. Their ratios of branching\nfractions with respect to the $\\Lambda_b^0\\!\\to\\Lambda_c^+\\mathrm{D}_s^-$ mode\nare measured to be\n  \\begin{align*}\n  \\begin{split}\n  \\frac{\\mathcal{B}(\\Lambda_b^0 \\to \\Lambda_c^+\\bar{D}^0\nK^-)}{\\mathcal{B}(\\Lambda_b^0 \\to \\Lambda_c^+ D_s^-)} & = 0.1908\n{}_{-0.0034}^{+0.0036} {}_{-0.0018}^{+0.0016} \\pm 0.0038 \\\\\n  \\frac{\\mathcal{B}(\\Lambda_b^0 \\to \\Lambda_c^+\\bar{D}^{*0}\nK^-)}{\\mathcal{B}(\\Lambda_b^0 \\to \\Lambda_c^+ D_s^-)} & = 0.589\n{}_{-0.017}^{+0.018} {}_{-0.018}^{+0.017} \\pm 0.012 \\\\\n  \\frac{\\mathcal{B}(\\Lambda_b^0 \\to \\Lambda_c^+\nD_s^{*-})}{\\mathcal{B}(\\Lambda_b^0 \\to \\Lambda_c^+ D_s^-)} & = 1.668 \\pm 0.022\n{}_{-0.055}^{+0.061}\\ ,\n  \\end{split} \\end{align*}\n  where the first uncertainties are statistical, the second systematic, and the\nthird, for the $\\Lambda_b^0 \\to \\Lambda_c^+ \\bar{D}^{(*)0} K^-$ decays, are due\nto the uncertainties on the branching fractions of the $D_s^- \\to K^- K^+\n\\pi^-$ and $\\bar{D}^0 \\to K^+\\pi^-$ decay modes. The measured branching\nfractions probe factorization assumptions in effective theories and provide the\nnormalization for future pentaquark searches in $\\Lambda_b^0 \\to \\Lambda_c^+\n\\bar{D}^{(*)0}K^-$ decay channels.",
            "author": [
                "LHCb collaboration",
                "R. Aaij",
                "A. S. W. Abdelmotteleb",
                "C. Abellan Beteta",
                "F. Abudin\u00e9n",
                "T. Ackernley",
                "B. Adeva",
                "M. Adinolfi",
                "P. Adlarson",
                "C. Agapopoulou",
                "C. A. Aidala",
                "Z. Ajaltouni",
                "S. Akar",
                "K. Akiba",
                "P. Albicocco",
                "J. Albrecht",
                "F. Alessio",
                "M. Alexander",
                "A. Alfonso Albero",
                "Z. Aliouche",
                "P. Alvarez Cartelle",
                "R. Amalric",
                "S. Amato",
                "J. L. Amey",
                "Y. Amhis",
                "L. An",
                "L. Anderlini",
                "M. Andersson",
                "A. Andreianov",
                "P. Andreola",
                "M. Andreotti",
                "D. Andreou",
                "A. Anelli",
                "D. Ao",
                "F. Archilli",
                "M. Argenton",
                "S. Arguedas Cuendis",
                "A. Artamonov",
                "M. Artuso",
                "E. Aslanides",
                "M. Atzeni",
                "B. Audurier",
                "D. Bacher",
                "I. Bachiller Perea",
                "S. Bachmann",
                "M. Bachmayer",
                "J. J. Back",
                "P. Baladron Rodriguez",
                "V. Balagura",
                "W. Baldini",
                "J. Baptista de Souza Leite",
                "M. Barbetti",
                "I. R. Barbosa",
                "R. J. Barlow",
                "S. Barsuk",
                "W. Barter",
                "M. Bartolini",
                "J. Bartz",
                "F. Baryshnikov",
                "J. M. Basels",
                "G. Bassi",
                "B. Batsukh",
                "A. Battig",
                "A. Bay",
                "A. Beck",
                "M. Becker",
                "F. Bedeschi",
                "I. B. Bediaga",
                "A. Beiter",
                "S. Belin",
                "V. Bellee",
                "K. Belous",
                "I. Belov",
                "I. Belyaev",
                "G. Benane",
                "G. Bencivenni",
                "E. Ben-Haim",
                "A. Berezhnoy",
                "R. Bernet",
                "S. Bernet Andres",
                "H. C. Bernstein",
                "C. Bertella",
                "A. Bertolin",
                "C. Betancourt",
                "F. Betti",
                "J. Bex",
                "Ia. Bezshyiko",
                "J. Bhom",
                "M. S. Bieker",
                "N. V. Biesuz",
                "P. Billoir",
                "A. Biolchini",
                "M. Birch",
                "F. C. R. Bishop",
                "A. Bitadze",
                "A. Bizzeti",
                "M. P. Blago",
                "T. Blake",
                "F. Blanc",
                "J. E. Blank",
                "S. Blusk",
                "D. Bobulska",
                "V. Bocharnikov",
                "J. A. Boelhauve",
                "O. Boente Garcia",
                "T. Boettcher",
                "A. Bohare",
                "A. Boldyrev",
                "C. S. Bolognani",
                "R. Bolzonella",
                "N. Bondar",
                "F. Borgato",
                "S. Borghi",
                "M. Borsato",
                "J. T. Borsuk",
                "S. A. Bouchiba",
                "T. J. V. Bowcock",
                "A. Boyer",
                "C. Bozzi",
                "M. J. Bradley",
                "S. Braun",
                "A. Brea Rodriguez",
                "N. Breer",
                "J. Brodzicka",
                "A. Brossa Gonzalo",
                "J. Brown",
                "D. Brundu",
                "A. Buonaura",
                "L. Buonincontri",
                "A. T. Burke",
                "C. Burr",
                "A. Bursche",
                "A. Butkevich",
                "J. S. Butter",
                "J. Buytaert",
                "W. Byczynski",
                "S. Cadeddu",
                "H. Cai",
                "R. Calabrese",
                "L. Calefice",
                "S. Cali",
                "M. Calvi",
                "M. Calvo Gomez",
                "J. Cambon Bouzas",
                "P. Campana",
                "D. H. Campora Perez",
                "A. F. Campoverde Quezada",
                "S. Capelli",
                "L. Capriotti",
                "R. Caravaca-Mora",
                "A. Carbone",
                "L. Carcedo Salgado",
                "R. Cardinale",
                "A. Cardini",
                "P. Carniti",
                "L. Carus",
                "A. Casais Vidal",
                "R. Caspary",
                "G. Casse",
                "J. Castro Godinez",
                "M. Cattaneo",
                "G. Cavallero",
                "V. Cavallini",
                "S. Celani",
                "J. Cerasoli",
                "D. Cervenkov",
                "S. Cesare",
                "A. J. Chadwick",
                "I. Chahrour",
                "M. Charles",
                "Ph. Charpentier",
                "C. A. Chavez Barajas",
                "M. Chefdeville",
                "C. Chen",
                "S. Chen",
                "Z. Chen",
                "A. Chernov",
                "S. Chernyshenko",
                "V. Chobanova",
                "S. Cholak",
                "M. Chrzaszcz",
                "A. Chubykin",
                "V. Chulikov",
                "P. Ciambrone",
                "M. F. Cicala",
                "X. Cid Vidal",
                "G. Ciezarek",
                "P. Cifra",
                "P. E. L. Clarke",
                "M. Clemencic",
                "H. V. Cliff",
                "J. Closier",
                "J. L. Cobbledick",
                "C. Cocha Toapaxi",
                "V. Coco",
                "J. Cogan",
                "E. Cogneras",
                "L. Cojocariu",
                "P. Collins",
                "T. Colombo",
                "A. Comerma-Montells",
                "L. Congedo",
                "A. Contu",
                "N. Cooke",
                "I. Corredoira",
                "A. Correia",
                "G. Corti",
                "J. J. Cottee Meldrum",
                "B. Couturier",
                "D. C. Craik",
                "M. Cruz Torres",
                "R. Currie",
                "C. L. Da Silva",
                "S. Dadabaev",
                "L. Dai",
                "X. Dai",
                "E. Dall'Occo",
                "J. Dalseno",
                "C. D'Ambrosio",
                "J. Daniel",
                "A. Danilina",
                "P. d'Argent",
                "A. Davidson",
                "J. E. Davies",
                "A. Davis",
                "O. De Aguiar Francisco",
                "C. De Angelis",
                "J. de Boer",
                "K. De Bruyn",
                "S. De Capua",
                "M. De Cian",
                "U. De Freitas Carneiro Da Graca",
                "E. De Lucia",
                "J. M. De Miranda",
                "L. De Paula",
                "M. De Serio",
                "D. De Simone",
                "P. De Simone",
                "F. De Vellis",
                "J. A. de Vries",
                "F. Debernardis",
                "D. Decamp",
                "V. Dedu",
                "L. Del Buono",
                "B. Delaney",
                "H. -P. Dembinski",
                "J. Deng",
                "V. Denysenko",
                "O. Deschamps",
                "F. Dettori",
                "B. Dey",
                "P. Di Nezza",
                "I. Diachkov",
                "S. Didenko",
                "S. Ding",
                "V. Dobishuk",
                "A. D. Docheva",
                "A. Dolmatov",
                "C. Dong",
                "A. M. Donohoe",
                "F. Dordei",
                "A. C. dos Reis",
                "L. Douglas",
                "A. G. Downes",
                "W. Duan",
                "P. Duda",
                "M. W. Dudek",
                "L. Dufour",
                "V. Duk",
                "P. Durante",
                "M. M. Duras",
                "J. M. Durham",
                "A. Dziurda",
                "A. Dzyuba",
                "S. Easo",
                "E. Eckstein",
                "U. Egede",
                "A. Egorychev",
                "V. Egorychev",
                "C. Eirea Orro",
                "S. Eisenhardt",
                "E. Ejopu",
                "S. Ek-In",
                "L. Eklund",
                "M. Elashri",
                "J. Ellbracht",
                "S. Ely",
                "A. Ene",
                "E. Epple",
                "S. Escher",
                "J. Eschle",
                "S. Esen",
                "T. Evans",
                "F. Fabiano",
                "L. N. Falcao",
                "Y. Fan",
                "B. Fang",
                "L. Fantini",
                "M. Faria",
                "K. Farmer",
                "D. Fazzini",
                "L. Felkowski",
                "M. Feng",
                "M. Feo",
                "M. Fernandez Gomez",
                "A. D. Fernez",
                "F. Ferrari",
                "F. Ferreira Rodrigues",
                "S. Ferreres Sole",
                "M. Ferrillo",
                "M. Ferro-Luzzi",
                "S. Filippov",
                "R. A. Fini",
                "M. Fiorini",
                "M. Firlej",
                "K. M. Fischer",
                "D. S. Fitzgerald",
                "C. Fitzpatrick",
                "T. Fiutowski",
                "F. Fleuret",
                "M. Fontana",
                "F. Fontanelli",
                "L. F. Foreman",
                "R. Forty",
                "D. Foulds-Holt",
                "M. Franco Sevilla",
                "M. Frank",
                "E. Franzoso",
                "G. Frau",
                "C. Frei",
                "D. A. Friday",
                "L. Frontini",
                "J. Fu",
                "Q. Fuehring",
                "Y. Fujii",
                "T. Fulghesu",
                "E. Gabriel",
                "G. Galati",
                "M. D. Galati",
                "A. Gallas Torreira",
                "D. Galli",
                "S. Gambetta",
                "M. Gandelman",
                "P. Gandini",
                "H. Gao",
                "R. Gao",
                "Y. Gao",
                "Y. Gao",
                "Y. Gao",
                "M. Garau",
                "L. M. Garcia Martin",
                "P. Garcia Moreno",
                "J. Garc\u00eda Pardi\u00f1as",
                "B. Garcia Plana",
                "K. G. Garg",
                "L. Garrido",
                "C. Gaspar",
                "R. E. Geertsema",
                "L. L. Gerken",
                "E. Gersabeck",
                "M. Gersabeck",
                "T. Gershon",
                "Z. Ghorbanimoghaddam",
                "L. Giambastiani",
                "F. I. Giasemis",
                "V. Gibson",
                "H. K. Giemza",
                "A. L. Gilman",
                "M. Giovannetti",
                "A. Giovent\u00f9",
                "P. Gironella Gironell",
                "C. Giugliano",
                "M. A. Giza",
                "E. L. Gkougkousis",
                "F. C. Glaser",
                "V. V. Gligorov",
                "C. G\u00f6bel",
                "E. Golobardes",
                "D. Golubkov",
                "A. Golutvin",
                "A. Gomes",
                "S. Gomez Fernandez",
                "F. Goncalves Abrantes",
                "M. Goncerz",
                "G. Gong",
                "J. A. Gooding",
                "I. V. Gorelov",
                "C. Gotti",
                "J. P. Grabowski",
                "L. A. Granado Cardoso",
                "E. Graug\u00e9s",
                "E. Graverini",
                "L. Grazette",
                "G. Graziani",
                "A. T. Grecu",
                "L. M. Greeven",
                "N. A. Grieser",
                "L. Grillo",
                "S. Gromov",
                "C. Gu",
                "M. Guarise",
                "M. Guittiere",
                "V. Guliaeva",
                "P. A. G\u00fcnther",
                "A. -K. Guseinov",
                "E. Gushchin",
                "Y. Guz",
                "T. Gys",
                "T. Hadavizadeh",
                "C. Hadjivasiliou",
                "G. Haefeli",
                "C. Haen",
                "J. Haimberger",
                "M. Hajheidari",
                "T. Halewood-leagas",
                "M. M. Halvorsen",
                "P. M. Hamilton",
                "J. Hammerich",
                "Q. Han",
                "X. Han",
                "S. Hansmann-Menzemer",
                "L. Hao",
                "N. Harnew",
                "T. Harrison",
                "M. Hartmann",
                "C. Hasse",
                "J. He",
                "K. Heijhoff",
                "F. Hemmer",
                "C. Henderson",
                "R. D. L. Henderson",
                "A. M. Hennequin",
                "K. Hennessy",
                "L. Henry",
                "J. Herd",
                "P. Herrero Gascon",
                "J. Heuel",
                "A. Hicheur",
                "D. Hill",
                "S. E. Hollitt",
                "J. Horswill",
                "R. Hou",
                "Y. Hou",
                "N. Howarth",
                "J. Hu",
                "J. Hu",
                "W. Hu",
                "X. Hu",
                "W. Huang",
                "W. Hulsbergen",
                "R. J. Hunter",
                "M. Hushchyn",
                "D. Hutchcroft",
                "M. Idzik",
                "D. Ilin",
                "P. Ilten",
                "A. Inglessi",
                "A. Iniukhin",
                "A. Ishteev",
                "K. Ivshin",
                "R. Jacobsson",
                "H. Jage",
                "S. J. Jaimes Elles",
                "S. Jakobsen",
                "E. Jans",
                "B. K. Jashal",
                "A. Jawahery",
                "V. Jevtic",
                "E. Jiang",
                "X. Jiang",
                "Y. Jiang",
                "Y. J. Jiang",
                "M. John",
                "D. Johnson",
                "C. R. Jones",
                "T. P. Jones",
                "S. Joshi",
                "B. Jost",
                "N. Jurik",
                "I. Juszczak",
                "D. Kaminaris",
                "S. Kandybei",
                "Y. Kang",
                "M. Karacson",
                "D. Karpenkov",
                "M. Karpov",
                "A. M. Kauniskangas",
                "J. W. Kautz",
                "F. Keizer",
                "D. M. Keller",
                "M. Kenzie",
                "T. Ketel",
                "B. Khanji",
                "A. Kharisova",
                "S. Kholodenko",
                "G. Khreich",
                "T. Kirn",
                "V. S. Kirsebom",
                "O. Kitouni",
                "S. Klaver",
                "N. Kleijne",
                "K. Klimaszewski",
                "M. R. Kmiec",
                "S. Koliiev",
                "L. Kolk",
                "A. Konoplyannikov",
                "P. Kopciewicz",
                "P. Koppenburg",
                "M. Korolev",
                "I. Kostiuk",
                "O. Kot",
                "S. Kotriakhova",
                "A. Kozachuk",
                "P. Kravchenko",
                "L. Kravchuk",
                "M. Kreps",
                "S. Kretzschmar",
                "P. Krokovny",
                "W. Krupa",
                "W. Krzemien",
                "J. Kubat",
                "S. Kubis",
                "W. Kucewicz",
                "M. Kucharczyk",
                "V. Kudryavtsev",
                "E. Kulikova",
                "A. Kupsc",
                "B. K. Kutsenko",
                "D. Lacarrere",
                "A. Lai",
                "A. Lampis",
                "D. Lancierini",
                "C. Landesa Gomez",
                "J. J. Lane",
                "R. Lane",
                "C. Langenbruch",
                "J. Langer",
                "O. Lantwin",
                "T. Latham",
                "F. Lazzari",
                "C. Lazzeroni",
                "R. Le Gac",
                "S. H. Lee",
                "R. Lef\u00e8vre",
                "A. Leflat",
                "S. Legotin",
                "M. Lehuraux",
                "O. Leroy",
                "T. Lesiak",
                "B. Leverington",
                "A. Li",
                "H. Li",
                "K. Li",
                "L. Li",
                "P. Li",
                "P. -R. Li",
                "S. Li",
                "T. Li",
                "T. Li",
                "Y. Li",
                "Y. Li",
                "Z. Li",
                "Z. Lian",
                "X. Liang",
                "C. Lin",
                "T. Lin",
                "R. Lindner",
                "V. Lisovskyi",
                "R. Litvinov",
                "G. Liu",
                "H. Liu",
                "K. Liu",
                "Q. Liu",
                "S. Liu",
                "Y. Liu",
                "Y. Liu",
                "Y. L. Liu",
                "A. Lobo Salvia",
                "A. Loi",
                "J. Lomba Castro",
                "T. Long",
                "J. H. Lopes",
                "A. Lopez Huertas",
                "S. L\u00f3pez Soli\u00f1o",
                "G. H. Lovell",
                "C. Lucarelli",
                "D. Lucchesi",
                "S. Luchuk",
                "M. Lucio Martinez",
                "V. Lukashenko",
                "Y. Luo",
                "A. Lupato",
                "E. Luppi",
                "K. Lynch",
                "X. -R. Lyu",
                "G. M. Ma",
                "R. Ma",
                "S. Maccolini",
                "F. Machefert",
                "F. Maciuc",
                "I. Mackay",
                "L. R. Madhan Mohan",
                "M. M. Madurai",
                "A. Maevskiy",
                "D. Magdalinski",
                "D. Maisuzenko",
                "M. W. Majewski",
                "J. J. Malczewski",
                "S. Malde",
                "B. Malecki",
                "L. Malentacca",
                "A. Malinin",
                "T. Maltsev",
                "G. Manca",
                "G. Mancinelli",
                "C. Mancuso",
                "R. Manera Escalero",
                "D. Manuzzi",
                "D. Marangotto",
                "J. F. Marchand",
                "R. Marchevski",
                "U. Marconi",
                "S. Mariani",
                "C. Marin Benito",
                "J. Marks",
                "A. M. Marshall",
                "P. J. Marshall",
                "G. Martelli",
                "G. Martellotti",
                "L. Martinazzoli",
                "M. Martinelli",
                "D. Martinez Santos",
                "F. Martinez Vidal",
                "A. Massafferri",
                "M. Materok",
                "R. Matev",
                "A. Mathad",
                "V. Matiunin",
                "C. Matteuzzi",
                "K. R. Mattioli",
                "A. Mauri",
                "E. Maurice",
                "J. Mauricio",
                "P. Mayencourt",
                "M. Mazurek",
                "M. McCann",
                "L. Mcconnell",
                "T. H. McGrath",
                "N. T. McHugh",
                "A. McNab",
                "R. McNulty",
                "B. Meadows",
                "G. Meier",
                "D. Melnychuk",
                "M. Merk",
                "A. Merli",
                "L. Meyer Garcia",
                "D. Miao",
                "H. Miao",
                "M. Mikhasenko",
                "D. A. Milanes",
                "A. Minotti",
                "E. Minucci",
                "T. Miralles",
                "S. E. Mitchell",
                "B. Mitreska",
                "D. S. Mitzel",
                "A. Modak",
                "A. M\u00f6dden",
                "R. A. Mohammed",
                "R. D. Moise",
                "S. Mokhnenko",
                "T. Momb\u00e4cher",
                "M. Monk",
                "I. A. Monroy",
                "S. Monteil",
                "A. Morcillo Gomez",
                "G. Morello",
                "M. J. Morello",
                "M. P. Morgenthaler",
                "J. Moron",
                "A. B. Morris",
                "A. G. Morris",
                "R. Mountain",
                "H. Mu",
                "Z. M. Mu",
                "E. Muhammad",
                "F. Muheim",
                "M. Mulder",
                "K. M\u00fcller",
                "F. M{\u0169}noz-Rojas",
                "R. Murta",
                "P. Naik",
                "T. Nakada",
                "R. Nandakumar",
                "T. Nanut",
                "I. Nasteva",
                "M. Needham",
                "N. Neri",
                "S. Neubert",
                "N. Neufeld",
                "P. Neustroev",
                "R. Newcombe",
                "J. Nicolini",
                "D. Nicotra",
                "E. M. Niel",
                "N. Nikitin",
                "P. Nogga",
                "N. S. Nolte",
                "C. Normand",
                "J. Novoa Fernandez",
                "G. Nowak",
                "C. Nunez",
                "H. N. Nur",
                "A. Oblakowska-Mucha",
                "V. Obraztsov",
                "T. Oeser",
                "S. Okamura",
                "R. Oldeman",
                "F. Oliva",
                "M. Olocco",
                "C. J. G. Onderwater",
                "R. H. O'Neil",
                "J. M. Otalora Goicochea",
                "T. Ovsiannikova",
                "P. Owen",
                "A. Oyanguren",
                "O. Ozcelik",
                "K. O. Padeken",
                "B. Pagare",
                "P. R. Pais",
                "T. Pajero",
                "A. Palano",
                "M. Palutan",
                "G. Panshin",
                "L. Paolucci",
                "A. Papanestis",
                "M. Pappagallo",
                "L. L. Pappalardo",
                "C. Pappenheimer",
                "C. Parkes",
                "B. Passalacqua",
                "G. Passaleva",
                "D. Passaro",
                "A. Pastore",
                "M. Patel",
                "J. Patoc",
                "C. Patrignani",
                "C. J. Pawley",
                "A. Pellegrino",
                "M. Pepe Altarelli",
                "S. Perazzini",
                "D. Pereima",
                "A. Pereiro Castro",
                "P. Perret",
                "A. Perro",
                "K. Petridis",
                "A. Petrolini",
                "S. Petrucci",
                "H. Pham",
                "L. Pica",
                "M. Piccini",
                "B. Pietrzyk",
                "G. Pietrzyk",
                "D. Pinci",
                "F. Pisani",
                "M. Pizzichemi",
                "V. Placinta",
                "M. Plo Casasus",
                "F. Polci",
                "M. Poli Lener",
                "A. Poluektov",
                "N. Polukhina",
                "I. Polyakov",
                "E. Polycarpo",
                "S. Ponce",
                "D. Popov",
                "S. Poslavskii",
                "K. Prasanth",
                "C. Prouve",
                "V. Pugatch",
                "G. Punzi",
                "W. Qian",
                "N. Qin",
                "S. Qu",
                "R. Quagliani",
                "R. I. Rabadan Trejo",
                "B. Rachwal",
                "J. H. Rademacker",
                "M. Rama",
                "M. Ram\u00edrez Garc\u00eda",
                "M. Ramos Pernas",
                "M. S. Rangel",
                "F. Ratnikov",
                "G. Raven",
                "M. Rebollo De Miguel",
                "F. Redi",
                "J. Reich",
                "F. Reiss",
                "Z. Ren",
                "P. K. Resmi",
                "R. Ribatti",
                "G. R. Ricart",
                "D. Riccardi",
                "S. Ricciardi",
                "K. Richardson",
                "M. Richardson-Slipper",
                "K. Rinnert",
                "P. Robbe",
                "G. Robertson",
                "E. Rodrigues",
                "E. Rodriguez Fernandez",
                "J. A. Rodriguez Lopez",
                "E. Rodriguez Rodriguez",
                "A. Rogovskiy",
                "D. L. Rolf",
                "A. Rollings",
                "P. Roloff",
                "V. Romanovskiy",
                "M. Romero Lamas",
                "A. Romero Vidal",
                "G. Romolini",
                "F. Ronchetti",
                "M. Rotondo",
                "S. R. Roy",
                "M. S. Rudolph",
                "T. Ruf",
                "M. Ruiz Diaz",
                "R. A. Ruiz Fernandez",
                "J. Ruiz Vidal",
                "A. Ryzhikov",
                "J. Ryzka",
                "J. J. Saborido Silva",
                "R. Sadek",
                "N. Sagidova",
                "N. Sahoo",
                "B. Saitta",
                "M. Salomoni",
                "C. Sanchez Gras",
                "I. Sanderswood",
                "R. Santacesaria",
                "C. Santamarina Rios",
                "M. Santimaria",
                "L. Santoro",
                "E. Santovetti",
                "A. Saputi",
                "D. Saranin",
                "G. Sarpis",
                "M. Sarpis",
                "A. Sarti",
                "C. Satriano",
                "A. Satta",
                "M. Saur",
                "D. Savrina",
                "H. Sazak",
                "L. G. Scantlebury Smead",
                "A. Scarabotto",
                "S. Schael",
                "S. Scherl",
                "A. M. Schertz",
                "M. Schiller",
                "H. Schindler",
                "M. Schmelling",
                "B. Schmidt",
                "S. Schmitt",
                "H. Schmitz",
                "O. Schneider",
                "A. Schopper",
                "N. Schulte",
                "S. Schulte",
                "M. H. Schune",
                "R. Schwemmer",
                "G. Schwering",
                "B. Sciascia",
                "A. Sciuccati",
                "S. Sellam",
                "A. Semennikov",
                "M. Senghi Soares",
                "A. Sergi",
                "N. Serra",
                "L. Sestini",
                "A. Seuthe",
                "Y. Shang",
                "D. M. Shangase",
                "M. Shapkin",
                "R. S. Sharma",
                "I. Shchemerov",
                "L. Shchutska",
                "T. Shears",
                "L. Shekhtman",
                "Z. Shen",
                "S. Sheng",
                "V. Shevchenko",
                "B. Shi",
                "E. B. Shields",
                "Y. Shimizu",
                "E. Shmanin",
                "R. Shorkin",
                "J. D. Shupperd",
                "R. Silva Coutinho",
                "G. Simi",
                "S. Simone",
                "N. Skidmore",
                "R. Skuza",
                "T. Skwarnicki",
                "M. W. Slater",
                "J. C. Smallwood",
                "E. Smith",
                "K. Smith",
                "M. Smith",
                "A. Snoch",
                "L. Soares Lavra",
                "M. D. Sokoloff",
                "F. J. P. Soler",
                "A. Solomin",
                "A. Solovev",
                "I. Solovyev",
                "R. Song",
                "Y. Song",
                "Y. Song",
                "Y. S. Song",
                "F. L. Souza De Almeida",
                "B. Souza De Paula",
                "E. Spadaro Norella",
                "E. Spedicato",
                "J. G. Speer",
                "E. Spiridenkov",
                "P. Spradlin",
                "V. Sriskaran",
                "F. Stagni",
                "M. Stahl",
                "S. Stahl",
                "S. Stanislaus",
                "E. N. Stein",
                "O. Steinkamp",
                "O. Stenyakin",
                "H. Stevens",
                "D. Strekalina",
                "Y. Su",
                "F. Suljik",
                "J. Sun",
                "L. Sun",
                "Y. Sun",
                "P. N. Swallow",
                "K. Swientek",
                "F. Swystun",
                "A. Szabelski",
                "T. Szumlak",
                "M. Szymanski",
                "Y. Tan",
                "S. Taneja",
                "M. D. Tat",
                "A. Terentev",
                "F. Terzuoli",
                "F. Teubert",
                "E. Thomas",
                "D. J. D. Thompson",
                "H. Tilquin",
                "V. Tisserand",
                "S. T'Jampens",
                "M. Tobin",
                "L. Tomassetti",
                "G. Tonani",
                "X. Tong",
                "D. Torres Machado",
                "L. Toscano",
                "D. Y. Tou",
                "C. Trippl",
                "G. Tuci",
                "N. Tuning",
                "L. H. Uecker",
                "A. Ukleja",
                "D. J. Unverzagt",
                "E. Ursov",
                "A. Usachov",
                "A. Ustyuzhanin",
                "U. Uwer",
                "V. Vagnoni",
                "A. Valassi",
                "G. Valenti",
                "N. Valls Canudas",
                "H. Van Hecke",
                "E. van Herwijnen",
                "C. B. Van Hulse",
                "R. Van Laak",
                "M. van Veghel",
                "R. Vazquez Gomez",
                "P. Vazquez Regueiro",
                "C. V\u00e1zquez Sierra",
                "S. Vecchi",
                "J. J. Velthuis",
                "M. Veltri",
                "A. Venkateswaran",
                "M. Vesterinen",
                "M. Vieites Diaz",
                "X. Vilasis-Cardona",
                "E. Vilella Figueras",
                "A. Villa",
                "P. Vincent",
                "F. C. Volle",
                "D. vom Bruch",
                "V. Vorobyev",
                "N. Voropaev",
                "K. Vos",
                "G. Vouters",
                "C. Vrahas",
                "J. Walsh",
                "E. J. Walton",
                "G. Wan",
                "C. Wang",
                "G. Wang",
                "J. Wang",
                "J. Wang",
                "J. Wang",
                "J. Wang",
                "M. Wang",
                "N. W. Wang",
                "R. Wang",
                "X. Wang",
                "X. W. Wang",
                "Y. Wang",
                "Z. Wang",
                "Z. Wang",
                "Z. Wang",
                "J. A. Ward",
                "N. K. Watson",
                "D. Websdale",
                "Y. Wei",
                "B. D. C. Westhenry",
                "D. J. White",
                "M. Whitehead",
                "A. R. Wiederhold",
                "D. Wiedner",
                "G. Wilkinson",
                "M. K. Wilkinson",
                "M. Williams",
                "M. R. J. Williams",
                "R. Williams",
                "F. F. Wilson",
                "W. Wislicki",
                "M. Witek",
                "L. Witola",
                "C. P. Wong",
                "G. Wormser",
                "S. A. Wotton",
                "H. Wu",
                "J. Wu",
                "Y. Wu",
                "K. Wyllie",
                "S. Xian",
                "Z. Xiang",
                "Y. Xie",
                "A. Xu",
                "J. Xu",
                "L. Xu",
                "L. Xu",
                "M. Xu",
                "Z. Xu",
                "Z. Xu",
                "Z. Xu",
                "D. Yang",
                "S. Yang",
                "X. Yang",
                "Y. Yang",
                "Z. Yang",
                "Z. Yang",
                "V. Yeroshenko",
                "H. Yeung",
                "H. Yin",
                "C. Y. Yu",
                "J. Yu",
                "X. Yuan",
                "E. Zaffaroni",
                "M. Zavertyaev",
                "M. Zdybal",
                "M. Zeng",
                "C. Zhang",
                "D. Zhang",
                "J. Zhang",
                "L. Zhang",
                "S. Zhang",
                "S. Zhang",
                "Y. Zhang",
                "Y. Zhang",
                "Y. Z. Zhang",
                "Y. Zhao",
                "A. Zharkova",
                "A. Zhelezov",
                "X. Z. Zheng",
                "Y. Zheng",
                "T. Zhou",
                "X. Zhou",
                "Y. Zhou",
                "V. Zhovkovska",
                "L. Z. Zhu",
                "X. Zhu",
                "X. Zhu",
                "Z. Zhu",
                "V. Zhukov",
                "J. Zhuo",
                "Q. Zou",
                "D. Zuliani",
                "G. Zunica"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14088v1",
                "http://arxiv.org/pdf/2311.14088v1"
            ],
            "primary_category": "hep-ex",
            "category": [
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14087v1",
            "title": "Question Answering in Natural Language: the Special Case of Temporal\n  Expressions",
            "updated": "2023-11-23T16:26:24Z",
            "published": "2023-11-23T16:26:24Z",
            "summary": "Although general question answering has been well explored in recent years,\ntemporal question answering is a task which has not received as much focus. Our\nwork aims to leverage a popular approach used for general question answering,\nanswer extraction, in order to find answers to temporal questions within a\nparagraph. To train our model, we propose a new dataset, inspired by SQuAD,\nspecifically tailored to provide rich temporal information. We chose to adapt\nthe corpus WikiWars, which contains several documents on history's greatest\nconflicts. Our evaluation shows that a deep learning model trained to perform\npattern matching, often used in general question answering, can be adapted to\ntemporal question answering, if we accept to ask questions whose answers must\nbe directly present within a text.",
            "author": [
                "Armand Stricker"
            ],
            "link": [
                "http://dx.doi.org/10.26615/issn.2603-2821.2021_026",
                "http://arxiv.org/abs/2311.14087v1",
                "http://arxiv.org/pdf/2311.14087v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14086v1",
            "title": "Brain MRI Screening Tool with Federated Learning",
            "updated": "2023-11-23T16:24:26Z",
            "published": "2023-11-23T16:24:26Z",
            "summary": "In clinical practice, we often see significant delays between MRI scans and\nthe diagnosis made by radiologists, even for severe cases. In some cases, this\nmay be caused by the lack of additional information and clues, so even the\nsevere cases need to wait in the queue for diagnosis. This can be avoided if\nthere is an automatic software tool, which would supplement additional\ninformation, alerting radiologists that the particular patient may be a severe\ncase.\n  We are presenting an automatic brain MRI Screening Tool and we are\ndemonstrating its capabilities for detecting tumor-like pathologies. It is the\nfirst version on the path toward a robust multi-pathology screening solution.\nThe tool supports Federated Learning, so multiple institutions may contribute\nto the model without disclosing their private data.",
            "author": [
                "Roman Stoklasa",
                "Ioannis Stathopoulos",
                "Efstratios Karavasilis",
                "Efstathios Efstathopoulos",
                "Marek Dost\u00e1l",
                "Milo\u0161 Ke\u0159kovsk\u00fd",
                "Michal Kozubek",
                "Luigi Serio"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14086v1",
                "http://arxiv.org/pdf/2311.14086v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG",
                "q-bio.NC",
                "D.2.2; H.1.2; H.5.2; I.4.8; I.4.6; I.5.1; I.5.4; J.3"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14085v1",
            "title": "Measurement of $J/\u03c8$-pair production in $pp$ collisions at\n  $\\sqrt{s}=13$ TeV and study of gluon transverse-momentum dependent PDFs",
            "updated": "2023-11-23T16:23:44Z",
            "published": "2023-11-23T16:23:44Z",
            "summary": "The production cross-section of $J/\\psi$ pairs in proton-proton collisions at\na centre-of-mass energy of $\\sqrt{s}=13$ TeV is measured using a data sample\ncorresponding to an integrated luminosity of 4.2 fb$^{-1}$ collected by the\nLHCb experiment. The measurement is performed with both $J/\\psi$ mesons in the\ntransverse momentum range $0<p_{\\text{T}}<14$ GeV/$c$ and rapidity range\n$2.0<y<4.5$. The cross-section of this process is measured to be\n16.36$\\pm$0.28(stat)$\\pm$0.88(syst) nb. The contributions from single-parton\nscattering and double-parton scattering are separated based on the dependence\nof the cross-section on the absolute rapidity difference $\\Delta y$ between the\ntwo $J/\\psi$ mesons. The effective cross-section of double-parton scattering is\nmeasured to be $\\sigma_{\\text{eff}}=$13.1$\\pm$1.8(stat)$\\pm$2.3(syst) mb. The\ndistribution of the azimuthal angle $\\phi_{\\text{CS}}$ of one of the $J/\\psi$\nmesons in the Collins-Soper frame and the $p_{\\text{T}}$-spectrum of the\n$J/\\psi$ pairs are also measured for the study of the gluon transverse-momentum\ndependent distributions inside protons. The extracted values of\n$\\langle\\cos2\\phi_{\\text{CS}}\\rangle$ and $\\langle\\cos4\\phi_{\\text{CS}}\\rangle$\nare consistent with zero, but the presence of azimuthal asymmetry at a few\npercent level is allowed.",
            "author": [
                "LHCb collaboration",
                "R. Aaij",
                "A. S. W. Abdelmotteleb",
                "C. Abellan Beteta",
                "F. Abudin\u00e9n",
                "T. Ackernley",
                "B. Adeva",
                "M. Adinolfi",
                "P. Adlarson",
                "H. Afsharnia",
                "C. Agapopoulou",
                "C. A. Aidala",
                "Z. Ajaltouni",
                "S. Akar",
                "K. Akiba",
                "P. Albicocco",
                "J. Albrecht",
                "F. Alessio",
                "M. Alexander",
                "A. Alfonso Albero",
                "Z. Aliouche",
                "P. Alvarez Cartelle",
                "R. Amalric",
                "S. Amato",
                "J. L. Amey",
                "Y. Amhis",
                "L. An",
                "L. Anderlini",
                "M. Andersson",
                "A. Andreianov",
                "P. Andreola",
                "M. Andreotti",
                "D. Andreou",
                "A. Anelli",
                "D. Ao",
                "F. Archilli",
                "S. Arguedas Cuendis",
                "A. Artamonov",
                "M. Artuso",
                "E. Aslanides",
                "M. Atzeni",
                "B. Audurier",
                "D. Bacher",
                "I. Bachiller Perea",
                "S. Bachmann",
                "M. Bachmayer",
                "J. J. Back",
                "A. Bailly-reyre",
                "P. Baladron Rodriguez",
                "V. Balagura",
                "W. Baldini",
                "J. Baptista de Souza Leite",
                "M. Barbetti",
                "I. R. Barbosa",
                "R. J. Barlow",
                "S. Barsuk",
                "W. Barter",
                "M. Bartolini",
                "F. Baryshnikov",
                "J. M. Basels",
                "G. Bassi",
                "B. Batsukh",
                "A. Battig",
                "A. Bay",
                "A. Beck",
                "M. Becker",
                "F. Bedeschi",
                "I. B. Bediaga",
                "A. Beiter",
                "S. Belin",
                "V. Bellee",
                "K. Belous",
                "I. Belov",
                "I. Belyaev",
                "G. Benane",
                "G. Bencivenni",
                "E. Ben-Haim",
                "A. Berezhnoy",
                "R. Bernet",
                "S. Bernet Andres",
                "H. C. Bernstein",
                "C. Bertella",
                "A. Bertolin",
                "C. Betancourt",
                "F. Betti",
                "J. Bex",
                "Ia. Bezshyiko",
                "J. Bhom",
                "M. S. Bieker",
                "N. V. Biesuz",
                "P. Billoir",
                "A. Biolchini",
                "M. Birch",
                "F. C. R. Bishop",
                "A. Bitadze",
                "A. Bizzeti",
                "M. P. Blago",
                "T. Blake",
                "F. Blanc",
                "J. E. Blank",
                "S. Blusk",
                "D. Bobulska",
                "V. Bocharnikov",
                "J. A. Boelhauve",
                "O. Boente Garcia",
                "T. Boettcher",
                "A. Bohare",
                "A. Boldyrev",
                "C. S. Bolognani",
                "R. Bolzonella",
                "N. Bondar",
                "F. Borgato",
                "S. Borghi",
                "M. Borsato",
                "J. T. Borsuk",
                "S. A. Bouchiba",
                "T. J. V. Bowcock",
                "A. Boyer",
                "C. Bozzi",
                "M. J. Bradley",
                "S. Braun",
                "A. Brea Rodriguez",
                "N. Breer",
                "J. Brodzicka",
                "A. Brossa Gonzalo",
                "J. Brown",
                "D. Brundu",
                "A. Buonaura",
                "L. Buonincontri",
                "A. T. Burke",
                "C. Burr",
                "A. Bursche",
                "A. Butkevich",
                "J. S. Butter",
                "J. Buytaert",
                "W. Byczynski",
                "S. Cadeddu",
                "H. Cai",
                "R. Calabrese",
                "L. Calefice",
                "S. Cali",
                "M. Calvi",
                "M. Calvo Gomez",
                "J. Cambon Bouzas",
                "P. Campana",
                "D. H. Campora Perez",
                "A. F. Campoverde Quezada",
                "S. Capelli",
                "L. Capriotti",
                "A. Carbone",
                "L. Carcedo Salgado",
                "R. Cardinale",
                "A. Cardini",
                "P. Carniti",
                "L. Carus",
                "A. Casais Vidal",
                "R. Caspary",
                "G. Casse",
                "J. Castro Godinez",
                "M. Cattaneo",
                "G. Cavallero",
                "V. Cavallini",
                "S. Celani",
                "J. Cerasoli",
                "D. Cervenkov",
                "S. Cesare",
                "A. J. Chadwick",
                "I. Chahrour",
                "M. Charles",
                "Ph. Charpentier",
                "C. A. Chavez Barajas",
                "M. Chefdeville",
                "C. Chen",
                "S. Chen",
                "A. Chernov",
                "S. Chernyshenko",
                "V. Chobanova",
                "S. Cholak",
                "M. Chrzaszcz",
                "A. Chubykin",
                "V. Chulikov",
                "P. Ciambrone",
                "M. F. Cicala",
                "X. Cid Vidal",
                "G. Ciezarek",
                "P. Cifra",
                "P. E. L. Clarke",
                "M. Clemencic",
                "H. V. Cliff",
                "J. Closier",
                "J. L. Cobbledick",
                "C. Cocha Toapaxi",
                "V. Coco",
                "J. Cogan",
                "E. Cogneras",
                "L. Cojocariu",
                "P. Collins",
                "T. Colombo",
                "A. Comerma-Montells",
                "L. Congedo",
                "A. Contu",
                "N. Cooke",
                "I. Corredoira",
                "A. Correia",
                "G. Corti",
                "J. J. Cottee Meldrum",
                "B. Couturier",
                "D. C. Craik",
                "M. Cruz Torres",
                "R. Currie",
                "C. L. Da Silva",
                "S. Dadabaev",
                "L. Dai",
                "X. Dai",
                "E. Dall'Occo",
                "J. Dalseno",
                "C. D'Ambrosio",
                "J. Daniel",
                "A. Danilina",
                "P. d'Argent",
                "A. Davidson",
                "J. E. Davies",
                "A. Davis",
                "O. De Aguiar Francisco",
                "C. De Angelis",
                "J. de Boer",
                "K. De Bruyn",
                "S. De Capua",
                "M. De Cian",
                "U. De Freitas Carneiro Da Graca",
                "E. De Lucia",
                "J. M. De Miranda",
                "L. De Paula",
                "M. De Serio",
                "D. De Simone",
                "P. De Simone",
                "F. De Vellis",
                "J. A. de Vries",
                "F. Debernardis",
                "D. Decamp",
                "V. Dedu",
                "L. Del Buono",
                "B. Delaney",
                "H. -P. Dembinski",
                "J. Deng",
                "V. Denysenko",
                "O. Deschamps",
                "F. Dettori",
                "B. Dey",
                "P. Di Nezza",
                "I. Diachkov",
                "S. Didenko",
                "S. Ding",
                "V. Dobishuk",
                "A. D. Docheva",
                "A. Dolmatov",
                "C. Dong",
                "A. M. Donohoe",
                "F. Dordei",
                "A. C. dos Reis",
                "L. Douglas",
                "A. G. Downes",
                "W. Duan",
                "P. Duda",
                "M. W. Dudek",
                "L. Dufour",
                "V. Duk",
                "P. Durante",
                "M. M. Duras",
                "J. M. Durham",
                "D. Dutta",
                "A. Dziurda",
                "A. Dzyuba",
                "S. Easo",
                "E. Eckstein",
                "U. Egede",
                "A. Egorychev",
                "V. Egorychev",
                "C. Eirea Orro",
                "S. Eisenhardt",
                "E. Ejopu",
                "S. Ek-In",
                "L. Eklund",
                "M. Elashri",
                "J. Ellbracht",
                "S. Ely",
                "A. Ene",
                "E. Epple",
                "S. Escher",
                "J. Eschle",
                "S. Esen",
                "T. Evans",
                "F. Fabiano",
                "L. N. Falcao",
                "Y. Fan",
                "B. Fang",
                "L. Fantini",
                "M. Faria",
                "K. Farmer",
                "D. Fazzini",
                "L. Felkowski",
                "M. Feng",
                "M. Feo",
                "M. Fernandez Gomez",
                "A. D. Fernez",
                "F. Ferrari",
                "F. Ferreira Rodrigues",
                "S. Ferreres Sole",
                "M. Ferrillo",
                "M. Ferro-Luzzi",
                "S. Filippov",
                "R. A. Fini",
                "M. Fiorini",
                "M. Firlej",
                "K. M. Fischer",
                "D. S. Fitzgerald",
                "C. Fitzpatrick",
                "T. Fiutowski",
                "F. Fleuret",
                "M. Fontana",
                "F. Fontanelli",
                "L. F. Foreman",
                "R. Forty",
                "D. Foulds-Holt",
                "M. Franco Sevilla",
                "M. Frank",
                "E. Franzoso",
                "G. Frau",
                "C. Frei",
                "D. A. Friday",
                "L. Frontini",
                "J. Fu",
                "Q. Fuehring",
                "Y. Fujii",
                "T. Fulghesu",
                "E. Gabriel",
                "G. Galati",
                "M. D. Galati",
                "A. Gallas Torreira",
                "D. Galli",
                "S. Gambetta",
                "M. Gandelman",
                "P. Gandini",
                "H. Gao",
                "R. Gao",
                "Y. Gao",
                "Y. Gao",
                "Y. Gao",
                "M. Garau",
                "L. M. Garcia Martin",
                "P. Garcia Moreno",
                "J. Garc\u00eda Pardi\u00f1as",
                "B. Garcia Plana",
                "K. G. Garg",
                "L. Garrido",
                "C. Gaspar",
                "R. E. Geertsema",
                "L. L. Gerken",
                "E. Gersabeck",
                "M. Gersabeck",
                "T. Gershon",
                "Z. Ghorbanimoghaddam",
                "L. Giambastiani",
                "F. I. Giasemis",
                "V. Gibson",
                "H. K. Giemza",
                "A. L. Gilman",
                "M. Giovannetti",
                "A. Giovent\u00f9",
                "P. Gironella Gironell",
                "C. Giugliano",
                "M. A. Giza",
                "E. L. Gkougkousis",
                "F. C. Glaser",
                "V. V. Gligorov",
                "C. G\u00f6bel",
                "E. Golobardes",
                "D. Golubkov",
                "A. Golutvin",
                "A. Gomes",
                "S. Gomez Fernandez",
                "F. Goncalves Abrantes",
                "M. Goncerz",
                "G. Gong",
                "J. A. Gooding",
                "I. V. Gorelov",
                "C. Gotti",
                "J. P. Grabowski",
                "L. A. Granado Cardoso",
                "E. Graug\u00e9s",
                "E. Graverini",
                "L. Grazette",
                "G. Graziani",
                "A. T. Grecu",
                "L. M. Greeven",
                "N. A. Grieser",
                "L. Grillo",
                "S. Gromov",
                "C. Gu",
                "M. Guarise",
                "M. Guittiere",
                "V. Guliaeva",
                "P. A. G\u00fcnther",
                "A. -K. Guseinov",
                "E. Gushchin",
                "Y. Guz",
                "T. Gys",
                "T. Hadavizadeh",
                "C. Hadjivasiliou",
                "G. Haefeli",
                "C. Haen",
                "J. Haimberger",
                "M. Hajheidari",
                "T. Halewood-leagas",
                "M. M. Halvorsen",
                "P. M. Hamilton",
                "J. Hammerich",
                "Q. Han",
                "X. Han",
                "S. Hansmann-Menzemer",
                "L. Hao",
                "N. Harnew",
                "T. Harrison",
                "M. Hartmann",
                "C. Hasse",
                "J. He",
                "K. Heijhoff",
                "F. Hemmer",
                "C. Henderson",
                "R. D. L. Henderson",
                "A. M. Hennequin",
                "K. Hennessy",
                "L. Henry",
                "J. Herd",
                "J. Heuel",
                "A. Hicheur",
                "D. Hill",
                "S. E. Hollitt",
                "J. Horswill",
                "R. Hou",
                "Y. Hou",
                "N. Howarth",
                "J. Hu",
                "J. Hu",
                "W. Hu",
                "X. Hu",
                "W. Huang",
                "W. Hulsbergen",
                "R. J. Hunter",
                "M. Hushchyn",
                "D. Hutchcroft",
                "M. Idzik",
                "D. Ilin",
                "P. Ilten",
                "A. Inglessi",
                "A. Iniukhin",
                "A. Ishteev",
                "K. Ivshin",
                "R. Jacobsson",
                "H. Jage",
                "S. J. Jaimes Elles",
                "S. Jakobsen",
                "E. Jans",
                "B. K. Jashal",
                "A. Jawahery",
                "V. Jevtic",
                "E. Jiang",
                "X. Jiang",
                "Y. Jiang",
                "Y. J. Jiang",
                "M. John",
                "D. Johnson",
                "C. R. Jones",
                "T. P. Jones",
                "S. Joshi",
                "B. Jost",
                "N. Jurik",
                "I. Juszczak",
                "D. Kaminaris",
                "S. Kandybei",
                "Y. Kang",
                "M. Karacson",
                "D. Karpenkov",
                "M. Karpov",
                "A. M. Kauniskangas",
                "J. W. Kautz",
                "F. Keizer",
                "D. M. Keller",
                "M. Kenzie",
                "T. Ketel",
                "B. Khanji",
                "A. Kharisova",
                "S. Kholodenko",
                "G. Khreich",
                "T. Kirn",
                "V. S. Kirsebom",
                "O. Kitouni",
                "S. Klaver",
                "N. Kleijne",
                "K. Klimaszewski",
                "M. R. Kmiec",
                "S. Koliiev",
                "L. Kolk",
                "A. Konoplyannikov",
                "P. Kopciewicz",
                "P. Koppenburg",
                "M. Korolev",
                "I. Kostiuk",
                "O. Kot",
                "S. Kotriakhova",
                "A. Kozachuk",
                "P. Kravchenko",
                "L. Kravchuk",
                "M. Kreps",
                "S. Kretzschmar",
                "P. Krokovny",
                "W. Krupa",
                "W. Krzemien",
                "J. Kubat",
                "S. Kubis",
                "W. Kucewicz",
                "M. Kucharczyk",
                "V. Kudryavtsev",
                "E. Kulikova",
                "A. Kupsc",
                "B. K. Kutsenko",
                "D. Lacarrere",
                "G. Lafferty",
                "A. Lai",
                "A. Lampis",
                "D. Lancierini",
                "C. Landesa Gomez",
                "J. J. Lane",
                "R. Lane",
                "C. Langenbruch",
                "J. Langer",
                "O. Lantwin",
                "T. Latham",
                "F. Lazzari",
                "C. Lazzeroni",
                "R. Le Gac",
                "S. H. Lee",
                "R. Lef\u00e8vre",
                "A. Leflat",
                "S. Legotin",
                "M. Lehuraux",
                "O. Leroy",
                "T. Lesiak",
                "B. Leverington",
                "A. Li",
                "H. Li",
                "K. Li",
                "L. Li",
                "P. Li",
                "P. -R. Li",
                "S. Li",
                "T. Li",
                "T. Li",
                "Y. Li",
                "Y. Li",
                "Z. Li",
                "Z. Lian",
                "X. Liang",
                "C. Lin",
                "T. Lin",
                "R. Lindner",
                "V. Lisovskyi",
                "R. Litvinov",
                "G. Liu",
                "H. Liu",
                "K. Liu",
                "Q. Liu",
                "S. Liu",
                "Y. Liu",
                "Y. Liu",
                "Y. L. Liu",
                "A. Lobo Salvia",
                "A. Loi",
                "J. Lomba Castro",
                "T. Long",
                "J. H. Lopes",
                "A. Lopez Huertas",
                "S. L\u00f3pez Soli\u00f1o",
                "G. H. Lovell",
                "C. Lucarelli",
                "D. Lucchesi",
                "S. Luchuk",
                "M. Lucio Martinez",
                "V. Lukashenko",
                "Y. Luo",
                "A. Lupato",
                "E. Luppi",
                "K. Lynch",
                "X. -R. Lyu",
                "G. M. Ma",
                "R. Ma",
                "S. Maccolini",
                "F. Machefert",
                "F. Maciuc",
                "I. Mackay",
                "L. R. Madhan Mohan",
                "M. M. Madurai",
                "A. Maevskiy",
                "D. Magdalinski",
                "D. Maisuzenko",
                "M. W. Majewski",
                "J. J. Malczewski",
                "S. Malde",
                "B. Malecki",
                "L. Malentacca",
                "A. Malinin",
                "T. Maltsev",
                "G. Manca",
                "G. Mancinelli",
                "C. Mancuso",
                "R. Manera Escalero",
                "D. Manuzzi",
                "D. Marangotto",
                "J. F. Marchand",
                "R. Marchevski",
                "U. Marconi",
                "S. Mariani",
                "C. Marin Benito",
                "J. Marks",
                "A. M. Marshall",
                "P. J. Marshall",
                "G. Martelli",
                "G. Martellotti",
                "L. Martinazzoli",
                "M. Martinelli",
                "D. Martinez Santos",
                "F. Martinez Vidal",
                "A. Massafferri",
                "M. Materok",
                "R. Matev",
                "A. Mathad",
                "V. Matiunin",
                "C. Matteuzzi",
                "K. R. Mattioli",
                "A. Mauri",
                "E. Maurice",
                "J. Mauricio",
                "M. Mazurek",
                "M. McCann",
                "L. Mcconnell",
                "T. H. McGrath",
                "N. T. McHugh",
                "A. McNab",
                "R. McNulty",
                "B. Meadows",
                "G. Meier",
                "D. Melnychuk",
                "M. Merk",
                "A. Merli",
                "L. Meyer Garcia",
                "D. Miao",
                "H. Miao",
                "M. Mikhasenko",
                "D. A. Milanes",
                "A. Minotti",
                "E. Minucci",
                "T. Miralles",
                "S. E. Mitchell",
                "B. Mitreska",
                "D. S. Mitzel",
                "A. Modak",
                "A. M\u00f6dden",
                "R. A. Mohammed",
                "R. D. Moise",
                "S. Mokhnenko",
                "T. Momb\u00e4cher",
                "M. Monk",
                "I. A. Monroy",
                "S. Monteil",
                "A. Morcillo Gomez",
                "G. Morello",
                "M. J. Morello",
                "M. P. Morgenthaler",
                "J. Moron",
                "A. B. Morris",
                "A. G. Morris",
                "R. Mountain",
                "H. Mu",
                "Z. M. Mu",
                "E. Muhammad",
                "F. Muheim",
                "M. Mulder",
                "K. M\u00fcller",
                "F. M\u0169noz-Rojas",
                "R. Murta",
                "P. Naik",
                "T. Nakada",
                "R. Nandakumar",
                "T. Nanut",
                "I. Nasteva",
                "M. Needham",
                "N. Neri",
                "S. Neubert",
                "N. Neufeld",
                "P. Neustroev",
                "R. Newcombe",
                "J. Nicolini",
                "D. Nicotra",
                "E. M. Niel",
                "N. Nikitin",
                "P. Nogga",
                "N. S. Nolte",
                "C. Normand",
                "J. Novoa Fernandez",
                "G. Nowak",
                "C. Nunez",
                "H. N. Nur",
                "A. Oblakowska-Mucha",
                "V. Obraztsov",
                "T. Oeser",
                "S. Okamura",
                "R. Oldeman",
                "F. Oliva",
                "M. Olocco",
                "C. J. G. Onderwater",
                "R. H. O'Neil",
                "J. M. Otalora Goicochea",
                "T. Ovsiannikova",
                "P. Owen",
                "A. Oyanguren",
                "O. Ozcelik",
                "K. O. Padeken",
                "B. Pagare",
                "P. R. Pais",
                "T. Pajero",
                "A. Palano",
                "M. Palutan",
                "G. Panshin",
                "L. Paolucci",
                "A. Papanestis",
                "M. Pappagallo",
                "L. L. Pappalardo",
                "C. Pappenheimer",
                "C. Parkes",
                "B. Passalacqua",
                "G. Passaleva",
                "D. Passaro",
                "A. Pastore",
                "M. Patel",
                "J. Patoc",
                "C. Patrignani",
                "C. J. Pawley",
                "A. Pellegrino",
                "M. Pepe Altarelli",
                "S. Perazzini",
                "D. Pereima",
                "A. Pereiro Castro",
                "P. Perret",
                "A. Perro",
                "K. Petridis",
                "A. Petrolini",
                "S. Petrucci",
                "H. Pham",
                "L. Pica",
                "M. Piccini",
                "B. Pietrzyk",
                "G. Pietrzyk",
                "D. Pinci",
                "F. Pisani",
                "M. Pizzichemi",
                "V. Placinta",
                "M. Plo Casasus",
                "F. Polci",
                "M. Poli Lener",
                "A. Poluektov",
                "N. Polukhina",
                "I. Polyakov",
                "E. Polycarpo",
                "S. Ponce",
                "D. Popov",
                "S. Poslavskii",
                "K. Prasanth",
                "L. Promberger",
                "C. Prouve",
                "V. Pugatch",
                "V. Puill",
                "G. Punzi",
                "H. R. Qi",
                "W. Qian",
                "N. Qin",
                "S. Qu",
                "R. Quagliani",
                "B. Rachwal",
                "J. H. Rademacker",
                "M. Rama",
                "M. Ram\u00edrez Garc\u00eda",
                "M. Ramos Pernas",
                "M. S. Rangel",
                "F. Ratnikov",
                "G. Raven",
                "M. Rebollo De Miguel",
                "F. Redi",
                "J. Reich",
                "F. Reiss",
                "Z. Ren",
                "P. K. Resmi",
                "R. Ribatti",
                "G. R. Ricart",
                "D. Riccardi",
                "S. Ricciardi",
                "K. Richardson",
                "M. Richardson-Slipper",
                "K. Rinnert",
                "P. Robbe",
                "G. Robertson",
                "E. Rodrigues",
                "E. Rodriguez Fernandez",
                "J. A. Rodriguez Lopez",
                "E. Rodriguez Rodriguez",
                "A. Rogovskiy",
                "D. L. Rolf",
                "A. Rollings",
                "P. Roloff",
                "V. Romanovskiy",
                "M. Romero Lamas",
                "A. Romero Vidal",
                "G. Romolini",
                "F. Ronchetti",
                "M. Rotondo",
                "S. R. Roy",
                "M. S. Rudolph",
                "T. Ruf",
                "M. Ruiz Diaz",
                "R. A. Ruiz Fernandez",
                "J. Ruiz Vidal",
                "A. Ryzhikov",
                "J. Ryzka",
                "J. J. Saborido Silva",
                "R. Sadek",
                "N. Sagidova",
                "N. Sahoo",
                "B. Saitta",
                "M. Salomoni",
                "C. Sanchez Gras",
                "I. Sanderswood",
                "R. Santacesaria",
                "C. Santamarina Rios",
                "M. Santimaria",
                "L. Santoro",
                "E. Santovetti",
                "A. Saputi",
                "D. Saranin",
                "G. Sarpis",
                "M. Sarpis",
                "A. Sarti",
                "C. Satriano",
                "A. Satta",
                "M. Saur",
                "D. Savrina",
                "H. Sazak",
                "L. G. Scantlebury Smead",
                "A. Scarabotto",
                "S. Schael",
                "S. Scherl",
                "A. M. Schertz",
                "M. Schiller",
                "H. Schindler",
                "M. Schmelling",
                "B. Schmidt",
                "S. Schmitt",
                "H. Schmitz",
                "O. Schneider",
                "A. Schopper",
                "N. Schulte",
                "S. Schulte",
                "M. H. Schune",
                "R. Schwemmer",
                "G. Schwering",
                "B. Sciascia",
                "A. Sciuccati",
                "S. Sellam",
                "A. Semennikov",
                "M. Senghi Soares",
                "A. Sergi",
                "N. Serra",
                "L. Sestini",
                "A. Seuthe",
                "Y. Shang",
                "D. M. Shangase",
                "M. Shapkin",
                "I. Shchemerov",
                "L. Shchutska",
                "T. Shears",
                "L. Shekhtman",
                "Z. Shen",
                "S. Sheng",
                "V. Shevchenko",
                "B. Shi",
                "E. B. Shields",
                "Y. Shimizu",
                "E. Shmanin",
                "R. Shorkin",
                "J. D. Shupperd",
                "R. Silva Coutinho",
                "G. Simi",
                "S. Simone",
                "N. Skidmore",
                "R. Skuza",
                "T. Skwarnicki",
                "M. W. Slater",
                "J. C. Smallwood",
                "E. Smith",
                "K. Smith",
                "M. Smith",
                "A. Snoch",
                "L. Soares Lavra",
                "M. D. Sokoloff",
                "F. J. P. Soler",
                "A. Solomin",
                "A. Solovev",
                "I. Solovyev",
                "R. Song",
                "Y. Song",
                "Y. Song",
                "Y. S. Song",
                "F. L. Souza De Almeida",
                "B. Souza De Paula",
                "E. Spadaro Norella",
                "E. Spedicato",
                "J. G. Speer",
                "E. Spiridenkov",
                "P. Spradlin",
                "V. Sriskaran",
                "F. Stagni",
                "M. Stahl",
                "S. Stahl",
                "S. Stanislaus",
                "E. N. Stein",
                "O. Steinkamp",
                "O. Stenyakin",
                "H. Stevens",
                "D. Strekalina",
                "Y. Su",
                "F. Suljik",
                "J. Sun",
                "L. Sun",
                "Y. Sun",
                "P. N. Swallow",
                "K. Swientek",
                "F. Swystun",
                "A. Szabelski",
                "T. Szumlak",
                "M. Szymanski",
                "Y. Tan",
                "S. Taneja",
                "M. D. Tat",
                "A. Terentev",
                "F. Terzuoli",
                "F. Teubert",
                "E. Thomas",
                "D. J. D. Thompson",
                "H. Tilquin",
                "V. Tisserand",
                "S. T'Jampens",
                "M. Tobin",
                "L. Tomassetti",
                "G. Tonani",
                "X. Tong",
                "D. Torres Machado",
                "L. Toscano",
                "D. Y. Tou",
                "C. Trippl",
                "G. Tuci",
                "N. Tuning",
                "L. H. Uecker",
                "A. Ukleja",
                "D. J. Unverzagt",
                "E. Ursov",
                "A. Usachov",
                "A. Ustyuzhanin",
                "U. Uwer",
                "V. Vagnoni",
                "A. Valassi",
                "G. Valenti",
                "N. Valls Canudas",
                "H. Van Hecke",
                "E. van Herwijnen",
                "C. B. Van Hulse",
                "R. Van Laak",
                "M. van Veghel",
                "R. Vazquez Gomez",
                "P. Vazquez Regueiro",
                "C. V\u00e1zquez Sierra",
                "S. Vecchi",
                "J. J. Velthuis",
                "M. Veltri",
                "A. Venkateswaran",
                "M. Vesterinen",
                "D. Vieira",
                "M. Vieites Diaz",
                "X. Vilasis-Cardona",
                "E. Vilella Figueras",
                "A. Villa",
                "P. Vincent",
                "F. C. Volle",
                "D. vom Bruch",
                "V. Vorobyev",
                "N. Voropaev",
                "K. Vos",
                "C. Vrahas",
                "J. Walsh",
                "E. J. Walton",
                "G. Wan",
                "C. Wang",
                "G. Wang",
                "J. Wang",
                "J. Wang",
                "J. Wang",
                "J. Wang",
                "M. Wang",
                "N. W. Wang",
                "R. Wang",
                "X. Wang",
                "X. W. Wang",
                "Y. Wang",
                "Z. Wang",
                "Z. Wang",
                "Z. Wang",
                "J. A. Ward",
                "N. K. Watson",
                "D. Websdale",
                "Y. Wei",
                "B. D. C. Westhenry",
                "D. J. White",
                "M. Whitehead",
                "A. R. Wiederhold",
                "D. Wiedner",
                "G. Wilkinson",
                "M. K. Wilkinson",
                "M. Williams",
                "M. R. J. Williams",
                "R. Williams",
                "F. F. Wilson",
                "W. Wislicki",
                "M. Witek",
                "L. Witola",
                "C. P. Wong",
                "G. Wormser",
                "S. A. Wotton",
                "H. Wu",
                "J. Wu",
                "Y. Wu",
                "K. Wyllie",
                "S. Xian",
                "Z. Xiang",
                "Y. Xie",
                "A. Xu",
                "J. Xu",
                "L. Xu",
                "L. Xu",
                "M. Xu",
                "Z. Xu",
                "Z. Xu",
                "Z. Xu",
                "D. Yang",
                "S. Yang",
                "X. Yang",
                "Y. Yang",
                "Z. Yang",
                "Z. Yang",
                "V. Yeroshenko",
                "H. Yeung",
                "H. Yin",
                "C. Y. Yu",
                "J. Yu",
                "X. Yuan",
                "E. Zaffaroni",
                "M. Zavertyaev",
                "M. Zdybal",
                "M. Zeng",
                "C. Zhang",
                "D. Zhang",
                "J. Zhang",
                "L. Zhang",
                "S. Zhang",
                "S. Zhang",
                "Y. Zhang",
                "Y. Zhang",
                "Y. Z. Zhang",
                "Y. Zhao",
                "A. Zharkova",
                "A. Zhelezov",
                "X. Z. Zheng",
                "Y. Zheng",
                "T. Zhou",
                "X. Zhou",
                "Y. Zhou",
                "V. Zhovkovska",
                "L. Z. Zhu",
                "X. Zhu",
                "X. Zhu",
                "Z. Zhu",
                "V. Zhukov",
                "J. Zhuo",
                "Q. Zou",
                "D. Zuliani",
                "G. Zunica"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14085v1",
                "http://arxiv.org/pdf/2311.14085v1"
            ],
            "primary_category": "hep-ex",
            "category": [
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14759v1",
            "title": "Forecasting Cryptocurrency Prices Using Deep Learning: Integrating\n  Financial, Blockchain, and Text Data",
            "updated": "2023-11-23T16:14:44Z",
            "published": "2023-11-23T16:14:44Z",
            "summary": "This paper explores the application of Machine Learning (ML) and Natural\nLanguage Processing (NLP) techniques in cryptocurrency price forecasting,\nspecifically Bitcoin (BTC) and Ethereum (ETH). Focusing on news and social\nmedia data, primarily from Twitter and Reddit, we analyse the influence of\npublic sentiment on cryptocurrency valuations using advanced deep learning NLP\nmethods. Alongside conventional price regression, we treat cryptocurrency price\nforecasting as a classification problem. This includes both the prediction of\nprice movements (up or down) and the identification of local extrema. We\ncompare the performance of various ML models, both with and without NLP data\nintegration. Our findings reveal that incorporating NLP data significantly\nenhances the forecasting performance of our models. We discover that\npre-trained models, such as Twitter-RoBERTa and BART MNLI, are highly effective\nin capturing market sentiment, and that fine-tuning Large Language Models\n(LLMs) also yields substantial forecasting improvements. Notably, the BART MNLI\nzero-shot classification model shows considerable proficiency in extracting\nbullish and bearish signals from textual data. All of our models consistently\ngenerate profit across different validation scenarios, with no observed decline\nin profits or reduction in the impact of NLP data over time. The study\nhighlights the potential of text analysis in improving financial forecasts and\ndemonstrates the effectiveness of various NLP techniques in capturing nuanced\nmarket sentiment.",
            "author": [
                "Vincent Gurgul",
                "Stefan Lessmann",
                "Wolfgang Karl H\u00e4rdle"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14759v1",
                "http://arxiv.org/pdf/2311.14759v1"
            ],
            "primary_category": "q-fin.ST",
            "category": [
                "q-fin.ST",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14079v1",
            "title": "Empirical Comparison between Cross-Validation and Mutation-Validation in\n  Model Selection",
            "updated": "2023-11-23T16:14:24Z",
            "published": "2023-11-23T16:14:24Z",
            "summary": "Mutation validation (MV) is a recently proposed approach for model selection,\ngarnering significant interest due to its unique characteristics and potential\nbenefits compared to the widely used cross-validation (CV) method. In this\nstudy, we empirically compared MV and $k$-fold CV using benchmark and\nreal-world datasets. By employing Bayesian tests, we compared generalization\nestimates yielding three posterior probabilities: practical equivalence, CV\nsuperiority, and MV superiority. We also evaluated the differences in the\ncapacity of the selected models and computational efficiency. We found that\nboth MV and CV select models with practically equivalent generalization\nperformance across various machine learning algorithms and the majority of\nbenchmark datasets. MV exhibited advantages in terms of selecting simpler\nmodels and lower computational costs. However, in some cases MV selected overly\nsimplistic models leading to underfitting and showed instability in\nhyperparameter selection. These limitations of MV became more evident in the\nevaluation of a real-world neuroscientific task of predicting sex at birth\nusing brain functional connectivity.",
            "author": [
                "Jinyang Yu",
                "Sami Hamdan",
                "Leonard Sasse",
                "Abigail Morrison",
                "Kaustubh R. Patil"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14079v1",
                "http://arxiv.org/pdf/2311.14079v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14078v2",
            "title": "Machine learning-based decentralized TDMA for VLC IoT networks",
            "updated": "2023-11-27T18:31:15Z",
            "published": "2023-11-23T16:12:00Z",
            "summary": "In this paper, a machine learning-based decentralized time division multiple\naccess (TDMA) algorithm for visible light communication (VLC) Internet of\nThings (IoT) networks is proposed. The proposed algorithm is based on\nQ-learning, a reinforcement learning algorithm. This paper considers a\ndecentralized condition in which there is no coordinator node for sending\nsynchronization frames and assigning transmission time slots to other nodes.\nThe proposed algorithm uses a decentralized manner for synchronization, and\neach node uses the Q-learning algorithm to find the optimal transmission time\nslot for sending data without collisions. The proposed algorithm is implemented\non a VLC hardware system, which had been designed and implemented in our\nlaboratory. Average reward, convergence time, goodput, average delay, and data\npacket size are evaluated parameters. The results show that the proposed\nalgorithm converges quickly and provides collision-free decentralized TDMA for\nthe network. The proposed algorithm is compared with carrier-sense multiple\naccess with collision avoidance (CSMA/CA) algorithm as a potential selection\nfor decentralized VLC IoT networks. The results show that the proposed\nalgorithm provides up to 61% more goodput and up to 49% less average delay than\nCSMA/CA.",
            "author": [
                "Armin Makvandi",
                "Yousef Seifi Kavian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14078v2",
                "http://arxiv.org/pdf/2311.14078v2"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14077v1",
            "title": "RetroDiff: Retrosynthesis as Multi-stage Distribution Interpolation",
            "updated": "2023-11-23T16:08:52Z",
            "published": "2023-11-23T16:08:52Z",
            "summary": "Retrosynthesis poses a fundamental challenge in biopharmaceuticals, aiming to\naid chemists in finding appropriate reactant molecules and synthetic pathways\ngiven determined product molecules. With the reactant and product represented\nas 2D graphs, retrosynthesis constitutes a conditional graph-to-graph\ngenerative task. Inspired by the recent advancements in discrete diffusion\nmodels for graph generation, we introduce Retrosynthesis Diffusion (RetroDiff),\na novel diffusion-based method designed to address this problem. However,\nintegrating a diffusion-based graph-to-graph framework while retaining\nessential chemical reaction template information presents a notable challenge.\nOur key innovation is to develop a multi-stage diffusion process. In this\nmethod, we decompose the retrosynthesis procedure to first sample external\ngroups from the dummy distribution given products and then generate the\nexternal bonds to connect the products and generated groups. Interestingly,\nsuch a generation process is exactly the reverse of the widely adapted\nsemi-template retrosynthesis procedure, i.e. from reaction center\nidentification to synthon completion, which significantly reduces the error\naccumulation. Experimental results on the benchmark have demonstrated the\nsuperiority of our method over all other semi-template methods.",
            "author": [
                "Yiming Wang",
                "Yuxuan Song",
                "Minkai Xu",
                "Rui Wang",
                "Hao Zhou",
                "Weiying Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14077v1",
                "http://arxiv.org/pdf/2311.14077v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14073v1",
            "title": "Learning Saliency From Fixations",
            "updated": "2023-11-23T16:04:41Z",
            "published": "2023-11-23T16:04:41Z",
            "summary": "We present a novel approach for saliency prediction in images, leveraging\nparallel decoding in transformers to learn saliency solely from fixation maps.\nModels typically rely on continuous saliency maps, to overcome the difficulty\nof optimizing for the discrete fixation map. We attempt to replicate the\nexperimental setup that generates saliency datasets. Our approach treats\nsaliency prediction as a direct set prediction problem, via a global loss that\nenforces unique fixations prediction through bipartite matching and a\ntransformer encoder-decoder architecture. By utilizing a fixed set of learned\nfixation queries, the cross-attention reasons over the image features to\ndirectly output the fixation points, distinguishing it from other modern\nsaliency predictors. Our approach, named Saliency TRansformer (SalTR), achieves\nmetric scores on par with state-of-the-art approaches on the Salicon and MIT300\nbenchmarks.",
            "author": [
                "Yasser Abdelaziz Dahou Djilali",
                "Kevin McGuiness",
                "Noel O'Connor"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14073v1",
                "http://arxiv.org/pdf/2311.14073v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14758v1",
            "title": "Point2RBox: Combine Knowledge from Synthetic Visual Patterns for\n  End-to-end Oriented Object Detection with Single Point Supervision",
            "updated": "2023-11-23T15:57:41Z",
            "published": "2023-11-23T15:57:41Z",
            "summary": "With the rapidly increasing demand for oriented object detection (OOD),\nrecent research involving weakly-supervised detectors for learning rotated box\n(RBox) from the horizontal box (HBox) has attracted more and more attention. In\nthis paper, we explore a more challenging yet label-efficient setting, namely\nsingle point-supervised OOD, and present our approach called Point2RBox.\nSpecifically, we propose to leverage two principles: 1) Synthetic pattern\nknowledge combination: By sampling around each labelled point on the image, we\ntransfer the object feature to synthetic visual patterns with the known\nbounding box to provide the knowledge for box regression. 2) Transform\nself-supervision: With a transformed input image (e.g. scaled/rotated), the\noutput RBoxes are trained to follow the same transformation so that the network\ncan perceive the relative size/rotation between objects. The detector is\nfurther enhanced by a few devised techniques to cope with peripheral issues,\ne.g. the anchor/layer assignment as the size of the object is not available in\nour point supervision setting. To our best knowledge, Point2RBox is the first\nend-to-end solution for point-supervised OOD. In particular, our method uses a\nlightweight paradigm, yet it achieves a competitive performance among\npoint-supervised alternatives, 41.05%/27.62%/80.01% on DOTA/DIOR/HRSC datasets.",
            "author": [
                "Yu Yi",
                "Xue Yang",
                "Qingyun Li",
                "Feipeng Da",
                "Junchi Yan",
                "Jifeng Dai",
                "Yu Qiao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14758v1",
                "http://arxiv.org/pdf/2311.14758v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14757v1",
            "title": "PointOBB: Learning Oriented Object Detection via Single Point\n  Supervision",
            "updated": "2023-11-23T15:51:50Z",
            "published": "2023-11-23T15:51:50Z",
            "summary": "Single point-supervised object detection is gaining attention due to its\ncost-effectiveness. However, existing approaches focus on generating horizontal\nbounding boxes (HBBs) while ignoring oriented bounding boxes (OBBs) commonly\nused for objects in aerial images. This paper proposes PointOBB, the first\nsingle Point-based OBB generation method, for oriented object detection.\nPointOBB operates through the collaborative utilization of three distinctive\nviews: an original view, a resized view, and a rotated/flipped (rot/flp) view.\nUpon the original view, we leverage the resized and rot/flp views to build a\nscale augmentation module and an angle acquisition module, respectively. In the\nformer module, a Scale-Sensitive Consistency (SSC) loss is designed to enhance\nthe deep network's ability to perceive the object scale. For accurate object\nangle predictions, the latter module incorporates self-supervised learning to\npredict angles, which is associated with a scale-guided Dense-to-Sparse (DS)\nmatching strategy for aggregating dense angles corresponding to sparse objects.\nThe resized and rot/flp views are switched using a progressive multi-view\nswitching strategy during training to achieve coupled optimization of scale and\nangle. Experimental results on the DIOR-R and DOTA-v1.0 datasets demonstrate\nthat PointOBB achieves promising performance, and significantly outperforms\npotential point-supervised baselines.",
            "author": [
                "Junwei Luo",
                "Xue Yang",
                "Yi Yu",
                "Qingyun Li",
                "Junchi Yan",
                "Yansheng Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14757v1",
                "http://arxiv.org/pdf/2311.14757v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16176v1",
            "title": "Shortcut Bias Mitigation via Ensemble Diversity Using Diffusion\n  Probabilistic Models",
            "updated": "2023-11-23T15:47:33Z",
            "published": "2023-11-23T15:47:33Z",
            "summary": "Spurious correlations in the data, where multiple cues are predictive of the\ntarget labels, often lead to a phenomenon known as simplicity bias, where a\nmodel relies on erroneous, easy-to-learn cues while ignoring reliable ones. In\nthis work, we propose an ensemble diversification framework exploiting\nDiffusion Probabilistic Models (DPMs) for shortcut bias mitigation. We show\nthat at particular training intervals, DPMs can generate images with novel\nfeature combinations, even when trained on images displaying correlated input\nfeatures. We leverage this crucial property to generate synthetic\ncounterfactuals to increase model diversity via ensemble disagreement. We show\nthat DPM-guided diversification is sufficient to remove dependence on primary\nshortcut cues, without a need for additional supervised signals. We further\nempirically quantify its efficacy on several diversification objectives, and\nfinally show improved generalization and diversification performance on par\nwith prior work that relies on auxiliary data collection.",
            "author": [
                "Luca Scimeca",
                "Alexander Rubinstein",
                "Damien Teney",
                "Seong Joon Oh",
                "Armand Mihai Nicolicioiu",
                "Yoshua Bengio"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16176v1",
                "http://arxiv.org/pdf/2311.16176v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14756v1",
            "title": "Task-Distributionally Robust Data-Free Meta-Learning",
            "updated": "2023-11-23T15:46:54Z",
            "published": "2023-11-23T15:46:54Z",
            "summary": "Data-Free Meta-Learning (DFML) aims to efficiently learn new tasks by\nleveraging multiple pre-trained models without requiring their original\ntraining data. Existing inversion-based DFML methods construct pseudo tasks\nfrom a learnable dataset, which is inversely generated from the pre-trained\nmodel pool. For the first time, we reveal two major challenges hindering their\npractical deployments: Task-Distribution Shift (TDS) and Task-Distribution\nCorruption (TDC). TDS leads to a biased meta-learner because of the skewed task\ndistribution towards newly generated tasks. TDC occurs when untrusted models\ncharacterized by misleading labels or poor quality pollute the task\ndistribution. To tackle these issues, we introduce a robust DFML framework that\nensures task distributional robustness. We propose to meta-learn from a pseudo\ntask distribution, diversified through task interpolation within a compact\ntask-memory buffer. This approach reduces the meta-learner's overreliance on\nnewly generated tasks by maintaining consistent performance across a broader\nrange of interpolated memory tasks, thus ensuring its generalization for unseen\ntasks. Additionally, our framework seamlessly incorporates an automated model\nselection mechanism into the meta-training phase, parameterizing each model's\nreliability as a learnable weight. This is optimized with a policy gradient\nalgorithm inspired by reinforcement learning, effectively addressing the\nnon-differentiable challenge posed by model selection. Comprehensive\nexperiments across various datasets demonstrate the framework's effectiveness\nin mitigating TDS and TDC, underscoring its potential to improve DFML in\nreal-world scenarios.",
            "author": [
                "Zixuan Hu",
                "Li Shen",
                "Zhenyi Wang",
                "Yongxian Wei",
                "Baoyuan Wu",
                "Chun Yuan",
                "Dacheng Tao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14756v1",
                "http://arxiv.org/pdf/2311.14756v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14064v1",
            "title": "HGCLIP: Exploring Vision-Language Models with Graph Representations for\n  Hierarchical Understanding",
            "updated": "2023-11-23T15:42:42Z",
            "published": "2023-11-23T15:42:42Z",
            "summary": "Object categories are typically organized into a multi-granularity taxonomic\nhierarchy. When classifying categories at different hierarchy levels,\ntraditional uni-modal approaches focus primarily on image features, revealing\nlimitations in complex scenarios. Recent studies integrating Vision-Language\nModels (VLMs) with class hierarchies have shown promise, yet they fall short of\nfully exploiting the hierarchical relationships. These efforts are constrained\nby their inability to perform effectively across varied granularity of\ncategories. To tackle this issue, we propose a novel framework (HGCLIP) that\neffectively combines CLIP with a deeper exploitation of the Hierarchical class\nstructure via Graph representation learning. We explore constructing the class\nhierarchy into a graph, with its nodes representing the textual or image\nfeatures of each category. After passing through a graph encoder, the textual\nfeatures incorporate hierarchical structure information, while the image\nfeatures emphasize class-aware features derived from prototypes through the\nattention mechanism. Our approach demonstrates significant improvements on both\ngeneric and fine-grained visual recognition benchmarks. Our codes are fully\navailable at https://github.com/richard-peng-xia/HGCLIP.",
            "author": [
                "Peng Xia",
                "Xingtong Yu",
                "Ming Hu",
                "Lie Ju",
                "Zhiyong Wang",
                "Peibo Duan",
                "Zongyuan Ge"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14064v1",
                "http://arxiv.org/pdf/2311.14064v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14063v1",
            "title": "Do VSR Models Generalize Beyond LRS3?",
            "updated": "2023-11-23T15:42:00Z",
            "published": "2023-11-23T15:42:00Z",
            "summary": "The Lip Reading Sentences-3 (LRS3) benchmark has primarily been the focus of\nintense research in visual speech recognition (VSR) during the last few years.\nAs a result, there is an increased risk of overfitting to its excessively used\ntest set, which is only one hour duration. To alleviate this issue, we build a\nnew VSR test set named WildVSR, by closely following the LRS3 dataset creation\nprocesses. We then evaluate and analyse the extent to which the current VSR\nmodels generalize to the new test data. We evaluate a broad range of publicly\navailable VSR models and find significant drops in performance on our test set,\ncompared to their corresponding LRS3 results. Our results suggest that the\nincrease in word error rates is caused by the models inability to generalize to\nslightly harder and in the wild lip sequences than those found in the LRS3 test\nset. Our new test benchmark is made public in order to enable future research\ntowards more robust VSR models.",
            "author": [
                "Yasser Abdelaziz Dahou Djilali",
                "Sanath Narayan",
                "Eustache Le Bihan",
                "Haithem Boussaid",
                "Ebtessam Almazrouei",
                "Merouane Debbah"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14063v1",
                "http://arxiv.org/pdf/2311.14063v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14061v1",
            "title": "Towards Explainable Strategy Templates using NLP Transformers",
            "updated": "2023-11-23T15:37:19Z",
            "published": "2023-11-23T15:37:19Z",
            "summary": "This paper bridges the gap between mathematical heuristic strategies learned\nfrom Deep Reinforcement Learning (DRL) in automated agent negotiation, and\ncomprehensible, natural language explanations. Our aim is to make these\nstrategies more accessible to non-experts. By leveraging traditional Natural\nLanguage Processing (NLP) techniques and Large Language Models (LLMs) equipped\nwith Transformers, we outline how parts of DRL strategies composed of parts\nwithin strategy templates can be transformed into user-friendly, human-like\nEnglish narratives. To achieve this, we present a top-level algorithm that\ninvolves parsing mathematical expressions of strategy templates, semantically\ninterpreting variables and structures, generating rule-based primary\nexplanations, and utilizing a Generative Pre-trained Transformer (GPT) model to\nrefine and contextualize these explanations. Subsequent customization for\nvaried audiences and meticulous validation processes in an example illustrate\nthe applicability and potential of this approach.",
            "author": [
                "Pallavi Bagga",
                "Kostas Stathis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14061v1",
                "http://arxiv.org/pdf/2311.14061v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14057v1",
            "title": "Assessing the Impact of Noise on Quantum Neural Networks: An\n  Experimental Analysis",
            "updated": "2023-11-23T15:22:22Z",
            "published": "2023-11-23T15:22:22Z",
            "summary": "In the race towards quantum computing, the potential benefits of quantum\nneural networks (QNNs) have become increasingly apparent. However, Noisy\nIntermediate-Scale Quantum (NISQ) processors are prone to errors, which poses a\nsignificant challenge for the execution of complex algorithms or quantum\nmachine learning. To ensure the quality and security of QNNs, it is crucial to\nexplore the impact of noise on their performance. This paper provides a\ncomprehensive analysis of the impact of noise on QNNs, examining the Mottonen\nstate preparation algorithm under various noise models and studying the\ndegradation of quantum states as they pass through multiple layers of QNNs.\nAdditionally, the paper evaluates the effect of noise on the performance of\npre-trained QNNs and highlights the challenges posed by noise models in quantum\ncomputing. The findings of this study have significant implications for the\ndevelopment of quantum software, emphasizing the importance of prioritizing\nstability and noise-correction measures when developing QNNs to ensure reliable\nand trustworthy results. This paper contributes to the growing body of\nliterature on quantum computing and quantum machine learning, providing new\ninsights into the impact of noise on QNNs and paving the way towards the\ndevelopment of more robust and efficient quantum algorithms.",
            "author": [
                "Erik B. Terres Escudero",
                "Danel Arias Alamo",
                "Oier Mentxaka G\u00f3mez",
                "Pablo Garc\u00eda Bringas"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-031-40725-3_27",
                "http://arxiv.org/abs/2311.14057v1",
                "http://arxiv.org/pdf/2311.14057v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14056v2",
            "title": "DPSUR: Accelerating Differentially Private Stochastic Gradient Descent\n  Using Selective Update and Release",
            "updated": "2023-11-29T08:43:45Z",
            "published": "2023-11-23T15:19:30Z",
            "summary": "Machine learning models are known to memorize private data to reduce their\ntraining loss, which can be inadvertently exploited by privacy attacks such as\nmodel inversion and membership inference. To protect against these attacks,\ndifferential privacy (DP) has become the de facto standard for\nprivacy-preserving machine learning, particularly those popular training\nalgorithms using stochastic gradient descent, such as DPSGD. Nonetheless, DPSGD\nstill suffers from severe utility loss due to its slow convergence. This is\npartially caused by the random sampling, which brings bias and variance to the\ngradient, and partially by the Gaussian noise, which leads to fluctuation of\ngradient updates.\n  Our key idea to address these issues is to apply selective updates to the\nmodel training, while discarding those useless or even harmful updates.\nMotivated by this, this paper proposes DPSUR, a Differentially Private training\nframework based on Selective Updates and Release, where the gradient from each\niteration is evaluated based on a validation test, and only those updates\nleading to convergence are applied to the model. As such, DPSUR ensures the\ntraining in the right direction and thus can achieve faster convergence than\nDPSGD. The main challenges lie in two aspects -- privacy concerns arising from\ngradient evaluation, and gradient selection strategy for model update. To\naddress the challenges, DPSUR introduces a clipping strategy for update\nrandomization and a threshold mechanism for gradient selection. Experiments\nconducted on MNIST, FMNIST, CIFAR-10, and IMDB datasets show that DPSUR\nsignificantly outperforms previous works in terms of convergence speed and\nmodel utility.",
            "author": [
                "Jie Fu",
                "Qingqing Ye",
                "Haibo Hu",
                "Zhili Chen",
                "Lulu Wang",
                "Kuncan Wang",
                "Xun Ran"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14056v2",
                "http://arxiv.org/pdf/2311.14056v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14049v3",
            "title": "Assessment of Deep Learning Segmentation for Real-Time Free-Breathing\n  Cardiac Magnetic Resonance Imaging",
            "updated": "2023-12-01T15:44:18Z",
            "published": "2023-11-23T15:05:12Z",
            "summary": "In recent years, a variety of deep learning networks for cardiac MRI (CMR)\nsegmentation have been developed and analyzed. However, nearly all of them are\nfocused on cine CMR under breathold. In this work, accuracy of deep learning\nmethods is assessed for volumetric analysis (via segmentation) of the left\nventricle in real-time free-breathing CMR at rest and under exercise stress.\nData from healthy volunteers (n=15) for cine and real-time free-breathing CMR\nwere analyzed retrospectively. Segmentations of a commercial software (comDL)\nand a freely available neural network (nnU-Net), were compared to a reference\ncreated via the manual correction of comDL segmentation. Segmentation of left\nventricular endocardium (LV), left ventricular myocardium (MYO), and right\nventricle (RV) is evaluated for both end-systolic and end-diastolic phases and\nanalyzed with Dice's coefficient (DC). The volumetric analysis includes LV\nend-diastolic volume (EDV), LV end-systolic volume (ESV), and LV ejection\nfraction (EF). For cine CMR, nnU-Net and comDL achieve a DC above 0.95 for LV\nand 0.9 for MYO, and RV. For real-time CMR, the accuracy of nnU-Net exceeds\nthat of comDL overall. For real-time CMR at rest, nnU-Net achieves a DC of 0.94\nfor LV, 0.89 for MYO, and 0.90 for RV; mean absolute differences between\nnnU-Net and reference are 2.9mL for EDV, 3.5mL for ESV and 2.6% for EF. For\nreal-time CMR under exercise stress, nnU-Net achieves a DC of 0.92 for LV, 0.85\nfor MYO, and 0.83 for RV; mean absolute differences between nnU-Net and\nreference are 11.4mL for EDV, 2.9mL for ESV and 3.6% for EF. Deep learning\nmethods designed or trained for cine CMR segmentation can perform well on\nreal-time CMR. For real-time free-breathing CMR at rest, the performance of\ndeep learning methods is comparable to inter-observer variability in cine CMR\nand is usable or fully automatic segmentation.",
            "author": [
                "Martin Schilling",
                "Christina Unterberg-Buchwald",
                "Joachim Lotz",
                "Martin Uecker"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14049v3",
                "http://arxiv.org/pdf/2311.14049v3"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14045v1",
            "title": "Physics Informed Neural Network Framework for Unsteady Discretized\n  Reduced Order System",
            "updated": "2023-11-23T15:00:55Z",
            "published": "2023-11-23T15:00:55Z",
            "summary": "This work addresses the development of a physics-informed neural network\n(PINN) with a loss term derived from a discretized time-dependent reduced-order\nsystem. In this work, first, the governing equations are discretized using a\nfinite difference scheme (whereas, any other discretization technique can be\nadopted), then projected on a reduced or latent space using the Proper\nOrthogonal Decomposition (POD)-Galerkin approach and next, the residual arising\nfrom discretized reduced order equation is considered as an additional loss\npenalty term alongside the data-driven loss term using different variants of\ndeep learning method such as Artificial neural network (ANN), Long Short-Term\nMemory based neural network (LSTM). The LSTM neural network has been proven to\nbe very effective for time-dependent problems in a purely data-driven\nenvironment. The current work demonstrates the LSTM network's potential over\nANN networks in physics-informed neural networks (PINN) as well. The potential\nof using discretized governing equations instead of continuous form lies in the\nflexibility of input to the PINN. Different sizes of data ranging from small,\nmedium to big datasets are used to assess the potential of\ndiscretized-physics-informed neural networks when there is very sparse or no\ndata available. The proposed methods are applied to a pitch-plunge airfoil\nmotion governed by rigid-body dynamics and a one-dimensional viscous Burgers'\nequation. The current work also demonstrates the prediction capability of\nvarious discretized-physics-informed neural networks outside the domain where\nthe data is available or governing equation-based residuals are minimized.",
            "author": [
                "Rahul Halder",
                "Giovanni Stabile",
                "Gianluigi Rozza"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14045v1",
                "http://arxiv.org/pdf/2311.14045v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14037v1",
            "title": "AdapterFL: Adaptive Heterogeneous Federated Learning for\n  Resource-constrained Mobile Computing Systems",
            "updated": "2023-11-23T14:42:43Z",
            "published": "2023-11-23T14:42:43Z",
            "summary": "Federated Learning (FL) enables collaborative learning of large-scale\ndistributed clients without data sharing. However, due to the disparity of\ncomputing resources among massive mobile computing devices, the performance of\ntraditional homogeneous model-based Federated Learning (FL) is seriously\nlimited. On the one hand, to achieve model training in all the diverse clients,\nmobile computing systems can only use small low-performance models for\ncollaborative learning. On the other hand, devices with high computing\nresources cannot train a high-performance large model with their insufficient\nraw data. To address the resource-constrained problem in mobile computing\nsystems, we present a novel heterogeneous FL approach named AdapterFL, which\nuses a model reassemble strategy to facilitate collaborative training of\nmassive heterogeneous mobile devices adaptively. Specifically, we select\nmultiple candidate heterogeneous models based on the computing performance of\nmassive mobile devices and then divide each heterogeneous model into two\npartitions. By reassembling the partitions, we can generate models with varied\nsizes that are combined by the partial parameters of the large model with the\npartial parameters of the small model. Using these reassembled models for FL\ntraining, we can train the partial parameters of the large model using\nlow-performance devices. In this way, we can alleviate performance degradation\nin large models due to resource constraints. The experimental results show that\nAdapterFL can achieve up to 12\\% accuracy improvement compared to the\nstate-of-the-art heterogeneous federated learning methods in\nresource-constrained scenarios.",
            "author": [
                "Ruixuan Liu",
                "Ming Hu",
                "Zeke Xia",
                "Jun Xia",
                "Pengyu Zhang",
                "Yihao Huang",
                "Yang Liu",
                "Mingsong Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14037v1",
                "http://arxiv.org/pdf/2311.14037v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14033v1",
            "title": "Multivariate Scenario Generation of Day-Ahead Electricity Prices using\n  Normalizing Flows",
            "updated": "2023-11-23T14:38:10Z",
            "published": "2023-11-23T14:38:10Z",
            "summary": "Trading on electricity markets requires accurate information about the\nrealization of electricity prices and the uncertainty attached to the\npredictions. We present a probabilistic forecasting approach for day-ahead\nelectricity prices using the fully data-driven deep generative model called\nnormalizing flows. Our modeling approach generates full-day scenarios of\nday-ahead electricity prices based on conditional features such as residual\nload forecasts. Furthermore, we propose extended feature sets of prior\nrealizations and a periodic retraining scheme that allows the normalizing flow\nto adapt to the changing conditions of modern electricity markets. In\nparticular, we investigate the impact of the energy crisis ensuing from the\nRussian invasion of Ukraine. Our results highlight that the normalizing flow\ngenerates high-quality scenarios that reproduce the true price distribution and\nyield highly accurate forecasts. Additionally, our analysis highlights how our\nimprovements towards adaptations in changing regimes allow the normalizing flow\nto adapt to changing market conditions and enables continued sampling of\nhigh-quality day-ahead price scenarios.",
            "author": [
                "Hannes Hilger",
                "Dirk Witthaut",
                "Manuel Dahmen",
                "Leonardo Rydin Gorjao",
                "Julius Trebbien",
                "Eike Cramer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14033v1",
                "http://arxiv.org/pdf/2311.14033v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14029v1",
            "title": "Understanding the Vulnerability of CLIP to Image Compression",
            "updated": "2023-11-23T14:33:53Z",
            "published": "2023-11-23T14:33:53Z",
            "summary": "CLIP is a widely used foundational vision-language model that is used for\nzero-shot image recognition and other image-text alignment tasks. We\ndemonstrate that CLIP is vulnerable to change in image quality under\ncompression. This surprising result is further analysed using an attribution\nmethod-Integrated Gradients. Using this attribution method, we are able to\nbetter understand both quantitatively and qualitatively exactly the nature in\nwhich the compression affects the zero-shot recognition accuracy of this model.\nWe evaluate this extensively on CIFAR-10 and STL-10. Our work provides the\nbasis to understand this vulnerability of CLIP and can help us develop more\neffective methods to improve the robustness of CLIP and other vision-language\nmodels.",
            "author": [
                "Cangxiong Chen",
                "Vinay P. Namboodiri",
                "Julian Padget"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14029v1",
                "http://arxiv.org/pdf/2311.14029v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14028v1",
            "title": "Continual Learning of Diffusion Models with Generative Distillation",
            "updated": "2023-11-23T14:33:03Z",
            "published": "2023-11-23T14:33:03Z",
            "summary": "Diffusion models are powerful generative models that achieve state-of-the-art\nperformance in tasks such as image synthesis. However, training them demands\nsubstantial amounts of data and computational resources. Continual learning\nwould allow for incrementally learning new tasks and accumulating knowledge,\nthus reusing already trained models would be possible. One potentially suitable\napproach is generative replay, where a copy of a generative model trained on\nprevious tasks produces synthetic data that are interleaved with data from the\ncurrent task. However, standard generative replay applied to diffusion models\nresults in a catastrophic loss in denoising capabilities. In this paper, we\npropose generative distillation, an approach that distils the entire reverse\nprocess of a diffusion model. We demonstrate that our approach significantly\nimproves the continual learning performance of generative replay with only a\nmoderate increase in the computational costs.",
            "author": [
                "Sergi Masip",
                "Pau Rodriguez",
                "Tinne Tuytelaars",
                "Gido M. van de Ven"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14028v1",
                "http://arxiv.org/pdf/2311.14028v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14024v1",
            "title": "Creating and Benchmarking a Synthetic Dataset for Cloud Optical\n  Thickness Estimation",
            "updated": "2023-11-23T14:28:28Z",
            "published": "2023-11-23T14:28:28Z",
            "summary": "Cloud formations often obscure optical satellite-based monitoring of the\nEarth's surface, thus limiting Earth observation (EO) activities such as land\ncover mapping, ocean color analysis, and cropland monitoring. The integration\nof machine learning (ML) methods within the remote sensing domain has\nsignificantly improved performance on a wide range of EO tasks, including cloud\ndetection and filtering, but there is still much room for improvement. A key\nbottleneck is that ML methods typically depend on large amounts of annotated\ndata for training, which is often difficult to come by in EO contexts. This is\nespecially true for the task of cloud optical thickness (COT) estimation. A\nreliable estimation of COT enables more fine-grained and application-dependent\ncontrol compared to using pre-specified cloud categories, as is commonly done\nin practice. To alleviate the COT data scarcity problem, in this work we\npropose a novel synthetic dataset for COT estimation, where top-of-atmosphere\nradiances have been simulated for 12 of the spectral bands of the\nMulti-Spectral Instrument (MSI) sensor onboard Sentinel-2 platforms. These data\npoints have been simulated under consideration of different cloud types, COTs,\nand ground surface and atmospheric profiles. Extensive experimentation of\ntraining several ML models to predict COT from the measured reflectivity of the\nspectral bands demonstrates the usefulness of our proposed dataset.\nGeneralization to real data is also demonstrated on two satellite image\ndatasets -- one that is publicly available, and one which we have collected and\nannotated. The synthetic data, the newly collected real dataset, code and\nmodels have been made publicly available at\nhttps://github.com/aleksispi/ml-cloud-opt-thick.",
            "author": [
                "Aleksis Pirinen",
                "Nosheen Abid",
                "Nuria Agues Paszkowsky",
                "Thomas Ohlson Timoudas",
                "Ronald Scheirer",
                "Chiara Ceccobello",
                "Gy\u00f6rgy Kov\u00e1cs",
                "Anders Persson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14024v1",
                "http://arxiv.org/pdf/2311.14024v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14019v1",
            "title": "An efficient mixed finite element method for nonlinear magnetostatics\n  and quasistatics",
            "updated": "2023-11-23T14:20:14Z",
            "published": "2023-11-23T14:20:14Z",
            "summary": "We consider systems of nonlinear magnetostatics and quasistatics that\ntypically arise in the modeling and simulation of electric machines. The\nnonlinear problems, eventually obtained after time discretization, are usually\nsolved by employing a vector potential formulation. In the relevant\ntwo-dimensional setting, a discretization can be obtained by H1-conforming\nfinite elements. We here consider an alternative formulation based on the\nH-field which leads to a nonlinear saddlepoint problem. After commenting on the\nunique solvability, we study the numerical approximation by H(curl)-conforming\nfinite elements and present the main convergence results. A particular focus is\nput on the efficient solution of the linearized systems arising in every step\nof the nonlinear Newton solver. Via hybridization, the linearized saddlepoint\nsystems can be transformed into linear elliptic problems, which can be solved\nwith similar computational complexity as those arising in the vector or scalar\npotential formulation. In summary, we can thus claim that the mixed finite\nelement approach based on the $H$-field can be considered a competitive\nalternative to the standard vector or scalar potential formulations for the\nsolution of problems in nonlinear magneto-quasistatics.",
            "author": [
                "Herbert Egger",
                "Felix Engertsberger",
                "Bogdan Radu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14019v1",
                "http://arxiv.org/pdf/2311.14019v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14754v1",
            "title": "ExCeL : Combined Extreme and Collective Logit Information for Enhancing\n  Out-of-Distribution Detection",
            "updated": "2023-11-23T14:16:03Z",
            "published": "2023-11-23T14:16:03Z",
            "summary": "Deep learning models often exhibit overconfidence in predicting\nout-of-distribution (OOD) data, underscoring the crucial role of OOD detection\nin ensuring reliability in predictions. Among various OOD detection approaches,\npost-hoc detectors have gained significant popularity, primarily due to their\nease of use and implementation. However, the effectiveness of most post-hoc OOD\ndetectors has been constrained as they rely solely either on extreme\ninformation, such as the maximum logit, or on the collective information (i.e.,\ninformation spanned across classes or training samples) embedded within the\noutput layer. In this paper, we propose ExCeL that combines both extreme and\ncollective information within the output layer for enhanced accuracy in OOD\ndetection. We leverage the logit of the top predicted class as the extreme\ninformation (i.e., the maximum logit), while the collective information is\nderived in a novel approach that involves assessing the likelihood of other\nclasses appearing in subsequent ranks across various training samples. Our idea\nis motivated by the observation that, for in-distribution (ID) data, the\nranking of classes beyond the predicted class is more deterministic compared to\nthat in OOD data. Experiments conducted on CIFAR100 and ImageNet-200 datasets\ndemonstrate that ExCeL consistently is among the five top-performing methods\nout of twenty-one existing post-hoc baselines when the joint performance on\nnear-OOD and far-OOD is considered (i.e., in terms of AUROC and FPR95).\nFurthermore, ExCeL shows the best overall performance across both datasets,\nunlike other baselines that work best on one dataset but has a performance drop\nin the other.",
            "author": [
                "Naveen Karunanayake",
                "Suranga Seneviratne",
                "Sanjay Chawla"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14754v1",
                "http://arxiv.org/pdf/2311.14754v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14014v1",
            "title": "On the Hyperparameter Landscapes of Machine Learning Algorithms",
            "updated": "2023-11-23T14:11:01Z",
            "published": "2023-11-23T14:11:01Z",
            "summary": "Despite the recent success in a plethora of hyperparameter optimization (HPO)\nmethods for machine learning (ML) models, the intricate interplay between model\nhyperparameters (HPs) and predictive losses (a.k.a fitness), which is a key\nprerequisite for understanding HPO, remain notably underexplored in our\ncommunity. This results in limited explainability in the HPO process, rendering\na lack of human trust and difficulties in pinpointing algorithm bottlenecks. In\nthis paper, we aim to shed light on this black box by conducting large-scale\nfitness landscape analysis (FLA) on 1,500 HP loss landscapes of 6 ML models\nwith more than 11 model configurations, across 67 datasets and different levels\nof fidelities. We reveal the first unified, comprehensive portrait of their\ntopographies in terms of smoothness, neutrality and modality. We also show that\nsuch properties are highly transferable across datasets and fidelities,\nproviding fundamental evidence for the success of multi-fidelity and transfer\nlearning methods. These findings are made possible by developing a dedicated\nFLA framework that incorporates a combination of visual and quantitative\nmeasures. We further demonstrate the potential of this framework by analyzing\nthe NAS-Bench-101 landscape, and we believe it is able to faciliate fundamental\nunderstanding of a broader range of AutoML tasks.",
            "author": [
                "Mingyu Huang",
                "Ke Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14014v1",
                "http://arxiv.org/pdf/2311.14014v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14012v1",
            "title": "Shadow: A Novel Loss Function for Efficient Training in Siamese Networks",
            "updated": "2023-11-23T14:07:35Z",
            "published": "2023-11-23T14:07:35Z",
            "summary": "Despite significant recent advances in similarity detection tasks, existing\napproaches pose substantial challenges under memory constraints. One of the\nprimary reasons for this is the use of computationally expensive metric\nlearning loss functions such as Triplet Loss in Siamese networks. In this\npaper, we present a novel loss function called Shadow Loss that compresses the\ndimensions of an embedding space during loss calculation without loss of\nperformance. The distance between the projections of the embeddings is learned\nfrom inputs on a compact projection space where distances directly correspond\nto a measure of class similarity. Projecting on a lower-dimension projection\nspace, our loss function converges faster, and the resulting classified image\nclusters have higher inter-class and smaller intra-class distances. Shadow Loss\nnot only reduces embedding dimensions favoring memory constraint devices but\nalso consistently performs better than the state-of-the-art Triplet Margin Loss\nby an accuracy of 5\\%-10\\% across diverse datasets. The proposed loss function\nis also model agnostic, upholding its performance across several tested models.\nIts effectiveness and robustness across balanced, imbalanced, medical, and\nnon-medical image datasets suggests that it is not specific to a particular\nmodel or dataset but demonstrates superior performance consistently while using\nless memory and computation.",
            "author": [
                "Alif Elham Khan",
                "Mohammad Junayed Hasan",
                "Humayra Anjum",
                "Nabeel Mohammed"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14012v1",
                "http://arxiv.org/pdf/2311.14012v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14003v1",
            "title": "Direct Preference-Based Evolutionary Multi-Objective Optimization with\n  Dueling Bandit",
            "updated": "2023-11-23T13:38:43Z",
            "published": "2023-11-23T13:38:43Z",
            "summary": "Optimization problems find widespread use in both single-objective and\nmulti-objective scenarios. In practical applications, users aspire for\nsolutions that converge to the region of interest (ROI) along the Pareto front\n(PF). While the conventional approach involves approximating a fitness function\nor an objective function to reflect user preferences, this paper explores an\nalternative avenue. Specifically, we aim to discover a method that sidesteps\nthe need for calculating the fitness function, relying solely on human\nfeedback. Our proposed approach entails conducting direct preference learning\nfacilitated by an active dueling bandit algorithm. The experimental phase is\nstructured into three sessions. Firstly, we assess the performance of our\nactive dueling bandit algorithm. Secondly, we implement our proposed method\nwithin the context of Multi-objective Evolutionary Algorithms (MOEAs). Finally,\nwe deploy our method in a practical problem, specifically in protein structure\nprediction (PSP). This research presents a novel interactive preference-based\nMOEA framework that not only addresses the limitations of traditional\ntechniques but also unveils new possibilities for optimization problems.",
            "author": [
                "Tian Huang",
                "Ke Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14003v1",
                "http://arxiv.org/pdf/2311.14003v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13998v1",
            "title": "Multidimensional surrogate modelling for Airborne TDEM data",
            "updated": "2023-11-23T13:33:47Z",
            "published": "2023-11-23T13:33:47Z",
            "summary": "The computational resources required to solve the full 3D inversion of\ntime-domain electromagnetic data are immense. To overcome the time-consuming 3D\nsimulations, we construct a surrogate model, more precisely, a data-driven\nstatistical model. It is trained on 3D simulation data and predicts the\napproximate output much faster. Given the computational cost related to the\nsimulations, there are limitations in the number of training samples that can\nbe generated. In addition, certain applications require a wide range of\nparameters to be sampled, such as the electrical conductivity parameters in a\nsaltwater intrusion case. This chapter is therefore limited to a two-layer\nmodel. We construct a surrogate model that predicts the discrepancy between a\n1D two-layered subsurface model and a deviation of the 1D assumption. The\nlatter response is quickly computed with a semi-analytical 1D forward model.\nThe results are encouraging even with few training samples, but obtaining a\nhigh accuracy is difficult with relatively simple data fit models. We propose\nto view the performance in terms of learning gain, representing the gain from\nthe surrogate model whilst still acknowledging a residual discrepancy.",
            "author": [
                "Wouter Deleersnyder",
                "David Dudal",
                "Thomas Hermans"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13998v1",
                "http://arxiv.org/pdf/2311.13998v1"
            ],
            "primary_category": "physics.geo-ph",
            "category": [
                "physics.geo-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13997v1",
            "title": "GRJointNET: Synergistic Completion and Part Segmentation on 3D\n  Incomplete Point Clouds",
            "updated": "2023-11-23T13:32:06Z",
            "published": "2023-11-23T13:32:06Z",
            "summary": "Segmentation of three-dimensional (3D) point clouds is an important task for\nautonomous systems. However, success of segmentation algorithms depends greatly\non the quality of the underlying point clouds (resolution, completeness etc.).\nIn particular, incomplete point clouds might reduce a downstream model's\nperformance. GRNet is proposed as a novel and recent deep learning solution to\ncomplete point clouds, but it is not capable of part segmentation. On the other\nhand, our proposed solution, GRJointNet, is an architecture that can perform\njoint completion and segmentation on point clouds as a successor of GRNet.\nFeatures extracted for the two tasks are also utilized by each other to\nincrease the overall performance. We evaluated our proposed network on the\nShapeNet-Part dataset and compared its performance to GRNet. Our results\ndemonstrate GRJointNet can outperform GRNet on point completion. It should also\nbe noted that GRNet is not capable of segmentation while GRJointNet is. This\nstudy1, therefore, holds a promise to enhance practicality and utility of point\nclouds in 3D vision for autonomous systems.",
            "author": [
                "Yigit Gurses",
                "Melisa Taspinar",
                "Mahmut Yurt",
                "Sedat Ozer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13997v1",
                "http://arxiv.org/pdf/2311.13997v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13993v1",
            "title": "EIGEN: Expert-Informed Joint Learning Aggregation for High-Fidelity\n  Information Extraction from Document Images",
            "updated": "2023-11-23T13:20:42Z",
            "published": "2023-11-23T13:20:42Z",
            "summary": "Information Extraction (IE) from document images is challenging due to the\nhigh variability of layout formats. Deep models such as LayoutLM and BROS have\nbeen proposed to address this problem and have shown promising results.\nHowever, they still require a large amount of field-level annotations for\ntraining these models. Other approaches using rule-based methods have also been\nproposed based on the understanding of the layout and semantics of a form such\nas geometric position, or type of the fields, etc. In this work, we propose a\nnovel approach, EIGEN (Expert-Informed Joint Learning aGgrEatioN), which\ncombines rule-based methods with deep learning models using data programming\napproaches to circumvent the requirement of annotation of large amounts of\ntraining data. Specifically, EIGEN consolidates weak labels induced from\nmultiple heuristics through generative models and use them along with a small\nnumber of annotated labels to jointly train a deep model. In our framework, we\npropose the use of labeling functions that include incorporating contextual\ninformation thus capturing the visual and language context of a word for\naccurate categorization. We empirically show that our EIGEN framework can\nsignificantly improve the performance of state-of-the-art deep models with the\navailability of very few labeled data instances. The source code is available\nat\nhttps://github.com/ayushayush591/EIGEN-High-Fidelity-Extraction-Document-Images.",
            "author": [
                "Abhishek Singh",
                "Venkatapathy Subramanian",
                "Ayush Maheshwari",
                "Pradeep Narayan",
                "Devi Prasad Shetty",
                "Ganesh Ramakrishnan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13993v1",
                "http://arxiv.org/pdf/2311.13993v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13988v1",
            "title": "Docking Multirotors in Close Proximity using Learnt Downwash Models",
            "updated": "2023-11-23T13:14:31Z",
            "published": "2023-11-23T13:14:31Z",
            "summary": "Unmodeled aerodynamic disturbances pose a key challenge for multirotor flight\nwhen multiple vehicles are in close proximity to each other. However, certain\nmissions \\textit{require} two multirotors to approach each other within 1-2\nbody-lengths of each other and hold formation -- we consider one such practical\ninstance: vertically docking two multirotors in the air. In this\nleader-follower setting, the follower experiences significant downwash\ninterference from the leader in its final docking stages. To compensate for\nthis, we employ a learnt downwash model online within an optimal feedback\ncontroller to accurately track a docking maneuver and then hold formation.\nThrough real-world flights with different maneuvers, we demonstrate that this\ncompensation is crucial for reducing the large vertical separation otherwise\nrequired by conventional/naive approaches. Our evaluations show a tracking\nerror of less than 0.06m for the follower (a 3-4x reduction) when approaching\nvertically within two body-lengths of the leader. Finally, we deploy the\ncomplete system to effect a successful physical docking between two airborne\nmultirotors in a single smooth planned trajectory.",
            "author": [
                "Ajay Shankar",
                "Heedo Woo",
                "Amanda Prorok"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13988v1",
                "http://arxiv.org/pdf/2311.13988v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13987v1",
            "title": "Jam-ALT: A Formatting-Aware Lyrics Transcription Benchmark",
            "updated": "2023-11-23T13:13:48Z",
            "published": "2023-11-23T13:13:48Z",
            "summary": "Current automatic lyrics transcription (ALT) benchmarks focus exclusively on\nword content and ignore the finer nuances of written lyrics including\nformatting and punctuation, which leads to a potential misalignment with the\ncreative products of musicians and songwriters as well as listeners'\nexperiences. For example, line breaks are important in conveying information\nabout rhythm, emotional emphasis, rhyme, and high-level structure. To address\nthis issue, we introduce Jam-ALT, a new lyrics transcription benchmark based on\nthe JamendoLyrics dataset. Our contribution is twofold. Firstly, a complete\nrevision of the transcripts, geared specifically towards ALT evaluation by\nfollowing a newly created annotation guide that unifies the music industry's\nguidelines, covering aspects such as punctuation, line breaks, spelling,\nbackground vocals, and non-word sounds. Secondly, a suite of evaluation metrics\ndesigned, unlike the traditional word error rate, to capture such phenomena. We\nhope that the proposed benchmark contributes to the ALT task, enabling more\nprecise and reliable assessments of transcription systems and enhancing the\nuser experience in lyrics applications such as subtitle renderings for live\ncaptioning or karaoke.",
            "author": [
                "Ond\u0159ej C\u00edfka",
                "Constantinos Dimitriou",
                "Cheng-i Wang",
                "Hendrik Schreiber",
                "Luke Miner",
                "Fabian-Robert St\u00f6ter"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13987v1",
                "http://arxiv.org/pdf/2311.13987v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.CL",
                "cs.LG",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13984v2",
            "title": "Harnessing Large Language Models to Enhance Self-Regulated Learning via\n  Formative Feedback",
            "updated": "2023-11-30T07:45:45Z",
            "published": "2023-11-23T13:03:21Z",
            "summary": "Effectively supporting students in mastering all facets of self-regulated\nlearning is a central aim of teachers and educational researchers. Prior\nresearch could demonstrate that formative feedback is an effective way to\nsupport students during self-regulated learning (SRL). However, for formative\nfeedback to be effective, it needs to be tailored to the learners, requiring\ninformation about their learning progress. In this work, we introduce LEAP, a\nnovel platform that utilizes advanced large language models (LLMs), such as\nChatGPT, to provide formative feedback to students. LEAP empowers teachers with\nthe ability to effectively pre-prompt and assign tasks to the LLM, thereby\nstimulating students' cognitive and metacognitive processes and promoting\nself-regulated learning. We demonstrate that a systematic prompt design based\non theoretical principles can provide a wide range of types of scaffolds to\nstudents, including sense-making, elaboration, self-explanation, partial\ntask-solution scaffolds, as well as metacognitive and motivational scaffolds.\nIn this way, we emphasize the critical importance of synchronizing educational\ntechnological advances with empirical research and theoretical frameworks.",
            "author": [
                "Steffen Steinert",
                "Karina E. Avila",
                "Stefan Ruzika",
                "Jochen Kuhn",
                "Stefan K\u00fcchemann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13984v2",
                "http://arxiv.org/pdf/2311.13984v2"
            ],
            "primary_category": "physics.ed-ph",
            "category": [
                "physics.ed-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13983v1",
            "title": "Learning Dynamic Selection and Pricing of Out-of-Home Deliveries",
            "updated": "2023-11-23T12:55:10Z",
            "published": "2023-11-23T12:55:10Z",
            "summary": "Home delivery failures, traffic congestion, and relatively large handling\ntimes have a negative impact on the profitability of last-mile logistics. These\nexternal factors contribute to up to $28\\%$ of the overall costs and $25\\%$ of\nemissions for the home delivery supply chain. A potential solution, showing\nannual growth rates up to $36\\%$, is the delivery to parcel lockers or parcel\nshops, denoted by out-of-home (OOH) delivery. In the academic literature,\nmodels of customer behavior with respect to OOH delivery were so far limited to\ndeterministic settings, contrasting with the stochastic nature of actual\ncustomer choices. We model the sequential decision-making problem of which OOH\nlocation to offer against what incentive for each incoming customer, taking\ninto account future customer arrivals and choices. We propose Dynamic Selection\nand Pricing of OOH (DSPO), an algorithmic pipeline that uses a novel\nspatial-temporal state encoding as input to a convolutional neural network. We\ndemonstrate the performance of our method by benchmarking it against three\nstate-of-the-art approaches. Our extensive numerical study, guided by\nreal-world data, reveals that DSPO can save $20.8\\%$ in costs compared to a\nsituation without OOH locations, $8.1\\%$ compared to a static selection and\npricing policy, and $4.6\\%$ compared to a state-of-the-art demand management\nbenchmark. We provide comprehensive insights into the complex interplay between\nOOH delivery dynamics and customer behavior influenced by pricing strategies.\nThe implications of our findings suggest practitioners to adopt dynamic\nselection and pricing policies as OOH delivery gains a larger market share.",
            "author": [
                "Fabian Akkerman",
                "Peter Dieter",
                "Martijn Mes"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13983v1",
                "http://arxiv.org/pdf/2311.13983v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13978v1",
            "title": "MedISure: Towards Assuring Machine Learning-based Medical Image\n  Classifiers using Mixup Boundary Analysis",
            "updated": "2023-11-23T12:47:43Z",
            "published": "2023-11-23T12:47:43Z",
            "summary": "Machine learning (ML) models are becoming integral in healthcare\ntechnologies, presenting a critical need for formal assurance to validate their\nsafety, fairness, robustness, and trustworthiness. These models are inherently\nprone to errors, potentially posing serious risks to patient health and could\neven cause irreparable harm. Traditional software assurance techniques rely on\nfixed code and do not directly apply to ML models since these algorithms are\nadaptable and learn from curated datasets through a training process. However,\nadapting established principles, such as boundary testing using synthetic test\ndata can effectively bridge this gap. To this end, we present a novel technique\ncalled Mix-Up Boundary Analysis (MUBA) that facilitates evaluating image\nclassifiers in terms of prediction fairness. We evaluated MUBA for two\nimportant medical imaging tasks -- brain tumour classification and breast\ncancer classification -- and achieved promising results. This research aims to\nshowcase the importance of adapting traditional assurance principles for\nassessing ML models to enhance the safety and reliability of healthcare\ntechnologies. To facilitate future research, we plan to publicly release our\ncode for MUBA.",
            "author": [
                "Adam Byfield",
                "William Poulett",
                "Ben Wallace",
                "Anusha Jose",
                "Shatakshi Tyagi",
                "Smita Shembekar",
                "Adnan Qayyum",
                "Junaid Qadir",
                "Muhammad Bilal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13978v1",
                "http://arxiv.org/pdf/2311.13978v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13976v1",
            "title": "Low Latency Instance Segmentation by Continuous Clustering for Rotating\n  LiDAR Sensors",
            "updated": "2023-11-23T12:42:52Z",
            "published": "2023-11-23T12:42:52Z",
            "summary": "Low-latency instance segmentation of LiDAR point clouds is crucial in\nreal-world applications because it serves as an initial and frequently-used\nbuilding block in a robot's perception pipeline, where every task adds further\ndelay. Particularly in dynamic environments, this total delay can result in\nsignificant positional offsets of dynamic objects, as seen in highway\nscenarios. To address this issue, we employ continuous clustering of obstacle\npoints in order to obtain an instance-segmented point cloud. Unlike most\nexisting approaches, which use a full revolution of the LiDAR sensor, we\nprocess the data stream in a continuous and seamless fashion. More\nspecifically, each column of a range image is processed as soon it is\navailable. Obstacle points are clustered to existing instances in real-time and\nit is checked at a high-frequency which instances are completed and are ready\nto be published. An additional advantage is that no problematic discontinuities\nbetween the points of the start and the end of a scan are observed. In this\nwork we describe the two-layered data structure and the corresponding algorithm\nfor continuous clustering, which is able to cluster the incoming data in real\ntime. We explain the importance of a large perceptive field of view.\nFurthermore, we describe and evaluate important architectural design choices,\nwhich could be relevant to design an architecture for deep learning based\nlow-latency instance segmentation. We are publishing the source code at\nhttps://github.com/UniBwTAS/continuous_clustering.",
            "author": [
                "Andreas Reich",
                "Hans-Joachim Wuensche"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13976v1",
                "http://arxiv.org/pdf/2311.13976v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13971v1",
            "title": "Deep learning detects uncataloged low-frequency earthquakes across\n  regions",
            "updated": "2023-11-23T12:34:02Z",
            "published": "2023-11-23T12:34:02Z",
            "summary": "Documenting the interplay between slow deformation and seismic ruptures is\nessential to understand the physics of earthquakes nucleation. However, slow\ndeformation is often difficult to detect and characterize. The most pervasive\nseismic markers of slow slip are low-frequency earthquakes (LFEs) that allow\nresolving deformations at minute-scale. Detecting LFEs is hard, due to their\nemergent onsets and low signal-to-noise ratios, usually requiring\nregion-specific template matching approaches. These approaches suffer from low\nflexibility and might miss LFEs as they are constrained to sources identified a\npriori. Here, we develop a deep learning-based workflow for LFE detection,\nmodeled after classical earthquake detection with phase picking, phase\nassociation, and location. Across three regions with known LFE activity, we\ndetect LFEs from both previously cataloged sources and newly identified\nsources. Furthermore, the approach is transferable across regions, enabling\nsystematic studies of LFEs in regions without known LFE activity.",
            "author": [
                "Jannes M\u00fcnchmeyer",
                "Sophie Giffard-Roisin",
                "Marielle Malfante",
                "William Frank",
                "Piero Poli",
                "David Marsan",
                "Anne Socquet"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13971v1",
                "http://arxiv.org/pdf/2311.13971v1"
            ],
            "primary_category": "physics.geo-ph",
            "category": [
                "physics.geo-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13967v2",
            "title": "Unconstrained learning of networked nonlinear systems via free\n  parametrization of stable interconnected operators",
            "updated": "2023-11-29T16:38:25Z",
            "published": "2023-11-23T12:31:28Z",
            "summary": "This paper characterizes a new parametrization of nonlinear networked\nincrementally $L_2$-bounded operators in discrete time. The distinctive novelty\nis that our parametrization is \\emph{free} -- that is, a sparse large-scale\noperator with bounded incremental $L_2$ gain is obtained for any choice of the\nreal values of our parameters. This property allows one to freely search over\noptimal parameters via unconstrained gradient descent, enabling direct\napplications in large-scale optimal control and system identification. Further,\nwe can embed prior knowledge about the interconnection topology and stability\nproperties of the system directly into the large-scale distributed operator we\ndesign. Our approach is extremely general in that it can seamlessly encapsulate\nand interconnect state-of-the-art Neural Network (NN) parametrizations of\nstable dynamical systems. To demonstrate the effectiveness of this approach, we\nprovide a simulation example showcasing the identification of a networked\nnonlinear system. The results underscore the superiority of our free\nparametrizations over standard NN-based identification methods where a prior\nover the system topology and local stability properties are not enforced.",
            "author": [
                "Leonardo Massai",
                "Danilo Saccani",
                "Luca Furieri",
                "Giancarlo Ferrari-Trecate"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13967v2",
                "http://arxiv.org/pdf/2311.13967v2"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13964v1",
            "title": "Deep Interactive Segmentation of Medical Images: A Systematic Review and\n  Taxonomy",
            "updated": "2023-11-23T12:26:08Z",
            "published": "2023-11-23T12:26:08Z",
            "summary": "Interactive segmentation is a crucial research area in medical image analysis\naiming to boost the efficiency of costly annotations by incorporating human\nfeedback. This feedback takes the form of clicks, scribbles, or masks and\nallows for iterative refinement of the model output so as to efficiently guide\nthe system towards the desired behavior. In recent years, deep learning-based\napproaches have propelled results to a new level causing a rapid growth in the\nfield with 121 methods proposed in the medical imaging domain alone. In this\nreview, we provide a structured overview of this emerging field featuring a\ncomprehensive taxonomy, a systematic review of existing methods, and an\nin-depth analysis of current practices. Based on these contributions, we\ndiscuss the challenges and opportunities in the field. For instance, we find\nthat there is a severe lack of comparison across methods which needs to be\ntackled by standardized baselines and benchmarks.",
            "author": [
                "Zdravko Marinov",
                "Paul F. J\u00e4ger",
                "Jan Egger",
                "Jens Kleesiek",
                "Rainer Stiefelhagen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13964v1",
                "http://arxiv.org/pdf/2311.13964v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.AI",
                "cs.CV",
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13963v1",
            "title": "Investigating the use of publicly available natural videos to learn\n  Dynamic MR image reconstruction",
            "updated": "2023-11-23T12:24:02Z",
            "published": "2023-11-23T12:24:02Z",
            "summary": "Purpose: To develop and assess a deep learning (DL) pipeline to learn dynamic\nMR image reconstruction from publicly available natural videos (Inter4K).\n  Materials and Methods: Learning was performed for a range of DL architectures\n(VarNet, 3D UNet, FastDVDNet) and corresponding sampling patterns (Cartesian,\nradial, spiral) either from true multi-coil cardiac MR data (N=692) or from\npseudo-MR data simulated from Inter4K natural videos (N=692). Real-time\nundersampled dynamic MR images were reconstructed using DL networks trained\nwith cardiac data and natural videos, and compressed sensing (CS). Differences\nwere assessed in simulations (N=104 datasets) in terms of MSE, PSNR, and SSIM\nand prospectively for cardiac (short axis, four chambers, N=20) and speech\n(N=10) data in terms of subjective image quality ranking, SNR and Edge\nsharpness. Friedman Chi Square tests with post-hoc Nemenyi analysis were\nperformed to assess statistical significance.\n  Results: For all simulation metrics, DL networks trained with cardiac data\noutperformed DL networks trained with natural videos, which outperformed CS\n(p<0.05). However, in prospective experiments DL reconstructions using both\ntraining datasets were ranked similarly (and higher than CS) and presented no\nstatistical differences in SNR and Edge Sharpness for most conditions.\nAdditionally, high SSIM was measured between the DL methods with cardiac data\nand natural videos (SSIM>0.85).\n  Conclusion: The developed pipeline enabled learning dynamic MR reconstruction\nfrom natural videos preserving DL reconstruction advantages such as high\nquality fast and ultra-fast reconstructions while overcoming some limitations\n(data scarcity or sharing). The natural video dataset, code and pre-trained\nnetworks are made readily available on github.\n  Key Words: real-time; dynamic MRI; deep learning; image reconstruction;\nmachine learning;",
            "author": [
                "Olivier Jaubert",
                "Michele Pascale",
                "Javier Montalt-Tordera",
                "Julius Akesson",
                "Ruta Virsinskaite",
                "Daniel Knight",
                "Simon Arridge",
                "Jennifer Steeden",
                "Vivek Muthurangu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13963v1",
                "http://arxiv.org/pdf/2311.13963v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13960v1",
            "title": "Human Machine Co-Creation. A Complementary Cognitive Approach to\n  Creative Character Design Process Using GANs",
            "updated": "2023-11-23T12:18:39Z",
            "published": "2023-11-23T12:18:39Z",
            "summary": "Recent advances in Generative Adversarial Networks GANs applications continue\nto attract the attention of researchers in different fields. In such a\nframework, two neural networks compete adversely to generate new visual\ncontents indistinguishable from the original dataset. The objective of this\nresearch is to create a complementary codesign process between humans and\nmachines to augment character designers abilities in visualizing and creating\nnew characters for multimedia projects such as games and animation. Driven by\ndesign cognitive scaffolding, the proposed approach aims to inform the process\nof perceiving, knowing, and making. The machine generated concepts are used as\na launching platform for character designers to conceptualize new characters. A\nlabelled dataset of 22,000 characters was developed for this work and deployed\nusing different GANs to evaluate the most suited for the context, followed by\nmixed methods evaluation for the machine output and human derivations. The\ndiscussed results substantiate the value of the proposed cocreation framework\nand elucidate how the generated concepts are used as cognitive substances that\ninteract with designers competencies in a versatile manner to influence the\ncreative processes of conceptualizing novel characters.",
            "author": [
                "Mohammad Lataifeh",
                "Xavier A Carrascoa",
                "Ashraf M Elnagara",
                "Naveed Ahmeda",
                "Imran Junejo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13960v1",
                "http://arxiv.org/pdf/2311.13960v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13959v2",
            "title": "RankFeat&RankWeight: Rank-1 Feature/Weight Removal for\n  Out-of-distribution Detection",
            "updated": "2023-11-27T09:47:10Z",
            "published": "2023-11-23T12:17:45Z",
            "summary": "The task of out-of-distribution (OOD) detection is crucial for deploying\nmachine learning models in real-world settings. In this paper, we observe that\nthe singular value distributions of the in-distribution (ID) and OOD features\nare quite different: the OOD feature matrix tends to have a larger dominant\nsingular value than the ID feature, and the class predictions of OOD samples\nare largely determined by it. This observation motivates us to propose\n\\texttt{RankFeat}, a simple yet effective \\emph{post hoc} approach for OOD\ndetection by removing the rank-1 matrix composed of the largest singular value\nand the associated singular vectors from the high-level feature.\n\\texttt{RankFeat} achieves \\emph{state-of-the-art} performance and reduces the\naverage false positive rate (FPR95) by 17.90\\% compared with the previous best\nmethod. The success of \\texttt{RankFeat} motivates us to investigate whether a\nsimilar phenomenon would exist in the parameter matrices of neural networks. We\nthus propose \\texttt{RankWeight} which removes the rank-1 weight from the\nparameter matrices of a single deep layer. Our \\texttt{RankWeight}is also\n\\emph{post hoc} and only requires computing the rank-1 matrix once. As a\nstandalone approach, \\texttt{RankWeight} has very competitive performance\nagainst other methods across various backbones. Moreover, \\texttt{RankWeight}\nenjoys flexible compatibility with a wide range of OOD detection methods. The\ncombination of \\texttt{RankWeight} and \\texttt{RankFeat} refreshes the new\n\\emph{state-of-the-art} performance, achieving the FPR95 as low as 16.13\\% on\nthe ImageNet-1k benchmark. Extensive ablation studies and comprehensive\ntheoretical analyses are presented to support the empirical results.",
            "author": [
                "Yue Song",
                "Nicu Sebe",
                "Wei Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13959v2",
                "http://arxiv.org/pdf/2311.13959v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13958v1",
            "title": "High-Order Tensor Recovery with A Tensor $U_1$ Norm",
            "updated": "2023-11-23T12:16:33Z",
            "published": "2023-11-23T12:16:33Z",
            "summary": "Recently, numerous tensor SVD (t-SVD)-based tensor recovery methods have\nemerged, showing promise in processing visual data. However, these methods\noften suffer from performance degradation when confronted with high-order\ntensor data exhibiting non-smooth changes, commonly observed in real-world\nscenarios but ignored by the traditional t-SVD-based methods. Our objective in\nthis study is to provide an effective tensor recovery technique for handling\nnon-smooth changes in tensor data and efficiently explore the correlations of\nhigh-order tensor data across its various dimensions without introducing\nnumerous variables and weights. To this end, we introduce a new tensor\ndecomposition and a new tensor norm called the Tensor $U_1$ norm. We utilize\nthese novel techniques in solving the problem of high-order tensor completion\nproblem and provide theoretical guarantees for the exact recovery of the\nresulting tensor completion models. An optimization algorithm is proposed to\nsolve the resulting tensor completion model iteratively by combining the\nproximal algorithm with the Alternating Direction Method of Multipliers.\nTheoretical analysis showed the convergence of the algorithm to the\nKarush-Kuhn-Tucker (KKT) point of the optimization problem. Numerical\nexperiments demonstrated the effectiveness of the proposed method in high-order\ntensor completion, especially for tensor data with non-smooth changes.",
            "author": [
                "Jingjing Zheng",
                "Wenzhe Wang",
                "Xiaoqin Zhang",
                "Yankai Cao",
                "Xianta Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13958v1",
                "http://arxiv.org/pdf/2311.13958v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13956v1",
            "title": "Reducing Histopathology Slide Magnification Improves the Accuracy and\n  Speed of Ovarian Cancer Subtyping",
            "updated": "2023-11-23T12:15:19Z",
            "published": "2023-11-23T12:15:19Z",
            "summary": "Artificial intelligence has found increasing use for ovarian cancer\nmorphological subtyping from histopathology slides, but the optimal\nmagnification for computational interpretation is unclear. Higher\nmagnifications offer abundant cytological information, whereas lower\nmagnifications give a broader histoarchitectural overview. Using\nattention-based multiple instance learning, we performed the most extensive\nanalysis of ovarian cancer tissue magnifications to date, with data at six\nmagnifications subjected to the same preprocessing, hyperparameter tuning,\ncross-validation and hold-out testing procedures. The lowest magnifications\n(1.25x and 2.5x) performed best in cross-validation, and intermediate\nmagnifications (5x and 10x) performed best in hold-out testing (62% and 61%\naccuracy, respectively). Lower magnification models were also significantly\nfaster, with the 5x model taking 5% as long to train and 31% as long to\nevaluate slides compared to 40x. This indicates that the standard usage of high\nmagnifications for computational ovarian cancer subtyping may be unnecessary,\nwith lower magnifications giving faster, more accurate alternatives.",
            "author": [
                "Jack Breen",
                "Katie Allen",
                "Kieran Zucker",
                "Nicolas M. Orsi",
                "Nishant Ravikumar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13956v1",
                "http://arxiv.org/pdf/2311.13956v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13953v1",
            "title": "Learning Uniform Clusters on Hypersphere for Deep Graph-level Clustering",
            "updated": "2023-11-23T12:08:20Z",
            "published": "2023-11-23T12:08:20Z",
            "summary": "Graph clustering has been popularly studied in recent years. However, most\nexisting graph clustering methods focus on node-level clustering, i.e.,\ngrouping nodes in a single graph into clusters. In contrast, graph-level\nclustering, i.e., grouping multiple graphs into clusters, remains largely\nunexplored. Graph-level clustering is critical in a variety of real-world\napplications, such as, properties prediction of molecules and community\nanalysis in social networks. However, graph-level clustering is challenging due\nto the insufficient discriminability of graph-level representations, and the\ninsufficient discriminability makes deep clustering be more likely to obtain\ndegenerate solutions (cluster collapse). To address the issue, we propose a\nnovel deep graph-level clustering method called Uniform Deep Graph Clustering\n(UDGC). UDGC assigns instances evenly to different clusters and then scatters\nthose clusters on unit hypersphere, leading to a more uniform cluster-level\ndistribution and a slighter cluster collapse. Specifically, we first propose\nAugmentation-Consensus Optimal Transport (ACOT) for generating uniformly\ndistributed and reliable pseudo labels for partitioning clusters. Then we adopt\ncontrastive learning to scatter those clusters. Besides, we propose Center\nAlignment Optimal Transport (CAOT) for guiding the model to learn better\nparameters, which further promotes the cluster performance. Our empirical study\non eight well-known datasets demonstrates that UDGC significantly outperforms\nthe state-of-the-art models.",
            "author": [
                "Mengling Hu",
                "Chaochao Chen",
                "Weiming Liu",
                "Xinyi Zhang",
                "Xinting Liao",
                "Xiaolin Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13953v1",
                "http://arxiv.org/pdf/2311.13953v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13950v1",
            "title": "Object Location Prediction in Real-time using LSTM Neural Network and\n  Polynomial Regression",
            "updated": "2023-11-23T12:03:02Z",
            "published": "2023-11-23T12:03:02Z",
            "summary": "This paper details the design and implementation of a system for predicting\nand interpolating object location coordinates. Our solution is based on\nprocessing inertial measurements and global positioning system data through a\nLong Short-Term Memory (LSTM) neural network and polynomial regression. LSTM is\na type of recurrent neural network (RNN) particularly suited for processing\ndata sequences and avoiding the long-term dependency problem. We employed data\nfrom real-world vehicles and the global positioning system (GPS) sensors. A\ncritical pre-processing step was developed to address varying sensor\nfrequencies and inconsistent GPS time steps and dropouts. The LSTM-based\nsystem's performance was compared with the Kalman Filter. The system was tuned\nto work in real-time with low latency and high precision. We tested our system\non roads under various driving conditions, including acceleration, turns,\ndeceleration, and straight paths. We tested our proposed solution's accuracy\nand inference time and showed that it could perform in real-time. Our\nLSTM-based system yielded an average error of 0.11 meters with an inference\ntime of 2 ms. This represents a 76\\% reduction in error compared to the\ntraditional Kalman filter method, which has an average error of 0.46 meters\nwith a similar inference time to the LSTM-based system.",
            "author": [
                "Petar Stojkovi\u0107",
                "Predrag Tadi\u0107"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13950v1",
                "http://arxiv.org/pdf/2311.13950v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13949v1",
            "title": "Optimal Power Flow in Highly Renewable Power System Based on Attention\n  Neural Networks",
            "updated": "2023-11-23T12:02:58Z",
            "published": "2023-11-23T12:02:58Z",
            "summary": "The Optimal Power Flow (OPF) problem is pivotal for power system operations,\nguiding generator output and power distribution to meet demand at minimized\ncosts, while adhering to physical and engineering constraints. The integration\nof renewable energy sources, like wind and solar, however, poses challenges due\nto their inherent variability. This variability, driven largely by changing\nweather conditions, demands frequent recalibrations of power settings, thus\nnecessitating recurrent OPF resolutions. This task is daunting using\ntraditional numerical methods, particularly for extensive power systems. In\nthis work, we present a cutting-edge, physics-informed machine learning\nmethodology, trained using imitation learning and historical European weather\ndatasets. Our approach directly correlates electricity demand and weather\npatterns with power dispatch and generation, circumventing the iterative\nrequirements of traditional OPF solvers. This offers a more expedient solution\napt for real-time applications. Rigorous evaluations on aggregated European\npower systems validate our method's superiority over existing data-driven\ntechniques in OPF solving. By presenting a quick, robust, and efficient\nsolution, this research sets a new standard in real-time OPF resolution, paving\nthe way for more resilient power systems in the era of renewable energy.",
            "author": [
                "Chen Li",
                "Alexander Kies",
                "Kai Zhou",
                "Markus Schlott",
                "Omar El Sayed",
                "Mariia Bilousova",
                "Horst Stoecker"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13949v1",
                "http://arxiv.org/pdf/2311.13949v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13947v1",
            "title": "High-Ratio Compression for Machine-Generated Data",
            "updated": "2023-11-23T12:01:36Z",
            "published": "2023-11-23T12:01:36Z",
            "summary": "Machine-generated data is rapidly growing and poses challenges for\ndata-intensive systems, especially as the growth of data outpaces the growth of\nstorage space. To cope with the storage issue, compression plays a critical\nrole in storage engines, particularly for data-intensive applications, where\nhigh compression ratios and efficient random access are essential. However,\nexisting compression techniques tend to focus on general-purpose and data block\napproaches, but overlook the inherent structure of machine-generated data and\nhence result in low-compression ratios or limited lookup efficiency. To address\nthese limitations, we introduce the Pattern-Based Compression (PBC) algorithm,\nwhich specifically targets patterns in machine-generated data to achieve\nPareto-optimality in most cases. Unlike traditional data block-based methods,\nPBC compresses data on a per-record basis, facilitating rapid random access.\nOur experimental evaluation demonstrates that PBC, on average, achieves a\ncompression ratio twice as high as state-of-the-art techniques while\nmaintaining competitive compression and decompression speeds.We also integrate\nPBC to a production database system and achieve improvement on both comparison\nratio and throughput.",
            "author": [
                "Jiujing Zhang",
                "Zhitao Shen",
                "Shiyu Yang",
                "Lingkai Meng",
                "Chuan Xiao",
                "Wei Jia",
                "Yue Li",
                "Qinhui Sun",
                "Wenjie Zhang",
                "Xuemin Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13947v1",
                "http://arxiv.org/pdf/2311.13947v1"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14752v1",
            "title": "Roadmap on machine learning glassy liquids",
            "updated": "2023-11-23T11:58:18Z",
            "published": "2023-11-23T11:58:18Z",
            "summary": "Unraveling the connections between microscopic structure, emergent physical\nproperties, and slow dynamics has long been a challenge in the field of the\nglass transition. The absence of clear visible structural order in amorphous\nconfigurations complicates the identification of the key features related to\nstructural relaxation and transport properties. The difficulty in sampling\nequilibrated configurations at low temperatures hampers thorough numerical and\ntheoretical investigations. This roadmap article explores the potential of\nmachine learning (ML) techniques to face these challenges, building on the\nalgorithms that have revolutionized computer vision and image recognition. We\npresent successful ML applications, as well as many open problems for the\nfuture, such as transferability and interpretability of ML approaches. We\nhighlight new ideas and directions in which ML could provide breakthroughs to\nbetter understand glassy liquids. To foster a collaborative community effort,\nthe article introduces the \"GlassBench\" dataset, providing simulation data and\nbenchmarks for both two-dimensional and three-dimensional glass-formers.\nEmphasizing the importance of benchmarks, we identify critical metrics for\ncomparing the performance of emerging ML methodologies, in line with\nbenchmarking practices in image and text recognition. The goal of this roadmap\nis to provide guidelines for the development of ML techniques in systems\ndisplaying slow dynamics, while inspiring new directions to improve our\nunderstanding of glassy liquids.",
            "author": [
                "Gerhard Jung",
                "Rinske M. Alkemade",
                "Victor Bapst",
                "Daniele Coslovich",
                "Laura Filion",
                "Fran\u00e7ois P. Landes",
                "Andrea Liu",
                "Francesco Saverio Pezzicoli",
                "Hayato Shiba",
                "Giovanni Volpe",
                "Francesco Zamponi",
                "Ludovic Berthier",
                "Giulio Biroli"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14752v1",
                "http://arxiv.org/pdf/2311.14752v1"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft",
                "cond-mat.dis-nn",
                "cond-mat.stat-mech"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14751v2",
            "title": "Efficient prediction of attosecond two-colour pulses from an X-ray\n  free-electron laser with machine learning",
            "updated": "2023-11-29T12:26:21Z",
            "published": "2023-11-23T11:39:29Z",
            "summary": "X-ray free-electron lasers are sources of coherent, high-intensity X-rays\nwith numerous applications in ultra-fast measurements and dynamic structural\nimaging. Due to the stochastic nature of the self-amplified spontaneous\nemission process and the difficulty in controlling injection of electrons,\noutput pulses exhibit significant noise and limited temporal coherence.\nStandard measurement techniques used for characterizing two-coloured X-ray\npulses are challenging, as they are either invasive or diagnostically\nexpensive. In this work, we employ machine learning methods such as neural\nnetworks and decision trees to predict the central photon energies of pairs of\nattosecond fundamental and second harmonic pulses using parameters that are\neasily recorded at the high-repetition rate of a single shot. Using real\nexperimental data, we apply a detailed feature analysis on the input parameters\nwhile optimizing the training time of the machine learning methods. Our\npredictive models are able to make predictions of central photon energy for one\nof the pulses without measuring the other pulse, thereby leveraging the use of\nthe spectrometer without having to extend its detection window. We anticipate\napplications in X-ray spectroscopy using XFELs, such as in time-resolved X-ray\nabsorption and photoemission spectroscopy, where improved measurement of input\nspectra will lead to better experimental outcomes.",
            "author": [
                "Karim K. Alaa El-Din",
                "Oliver G. Alexander",
                "Leszek J. Frasinski",
                "Florian Mintert",
                "Zhaoheng Guo",
                "Joseph Duris",
                "Zhen Zhang",
                "David B. Cesar",
                "Paris Franz",
                "Taran Driver",
                "Peter Walter",
                "James P. Cryan",
                "Agostino Marinelli",
                "Jon P. Marangos",
                "Rick Mukherjee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14751v2",
                "http://arxiv.org/pdf/2311.14751v2"
            ],
            "primary_category": "physics.acc-ph",
            "category": [
                "physics.acc-ph",
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14750v2",
            "title": "Attribute-Aware Representation Rectification for Generalized Zero-Shot\n  Learning",
            "updated": "2023-12-01T15:25:35Z",
            "published": "2023-11-23T11:30:32Z",
            "summary": "Generalized Zero-shot Learning (GZSL) has yielded remarkable performance by\ndesigning a series of unbiased visual-semantics mappings, wherein, the\nprecision relies heavily on the completeness of extracted visual features from\nboth seen and unseen classes. However, as a common practice in GZSL, the\npre-trained feature extractor may easily exhibit difficulty in capturing\ndomain-specific traits of the downstream tasks/datasets to provide fine-grained\ndiscriminative features, i.e., domain bias, which hinders the overall\nrecognition performance, especially for unseen classes. Recent studies\npartially address this issue by fine-tuning feature extractors, while may\ninevitably incur catastrophic forgetting and overfitting issues. In this paper,\nwe propose a simple yet effective Attribute-Aware Representation Rectification\nframework for GZSL, dubbed $\\mathbf{(AR)^{2}}$, to adaptively rectify the\nfeature extractor to learn novel features while keeping original valuable\nfeatures. Specifically, our method consists of two key components, i.e.,\nUnseen-Aware Distillation (UAD) and Attribute-Guided Learning (AGL). During\ntraining, UAD exploits the prior knowledge of attribute texts that are shared\nby both seen/unseen classes with attention mechanisms to detect and maintain\nunseen class-sensitive visual features in a targeted manner, and meanwhile, AGL\naims to steer the model to focus on valuable features and suppress them to fit\nnoisy elements in the seen classes by attribute-guided representation learning.\nExtensive experiments on various benchmark datasets demonstrate the\neffectiveness of our method.",
            "author": [
                "Zhijie Rao",
                "Jingcai Guo",
                "Xiaocheng Lu",
                "Qihua Zhou",
                "Jie Zhang",
                "Kang Wei",
                "Chenxin Li",
                "Song Guo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14750v2",
                "http://arxiv.org/pdf/2311.14750v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13929v1",
            "title": "MetaFBP: Learning to Learn High-Order Predictor for Personalized Facial\n  Beauty Prediction",
            "updated": "2023-11-23T11:30:02Z",
            "published": "2023-11-23T11:30:02Z",
            "summary": "Predicting individual aesthetic preferences holds significant practical\napplications and academic implications for human society. However, existing\nstudies mainly focus on learning and predicting the commonality of facial\nattractiveness, with little attention given to Personalized Facial Beauty\nPrediction (PFBP). PFBP aims to develop a machine that can adapt to individual\naesthetic preferences with only a few images rated by each user. In this paper,\nwe formulate this task from a meta-learning perspective that each user\ncorresponds to a meta-task. To address such PFBP task, we draw inspiration from\nthe human aesthetic mechanism that visual aesthetics in society follows a\nGaussian distribution, which motivates us to disentangle user preferences into\na commonality and an individuality part. To this end, we propose a novel\nMetaFBP framework, in which we devise a universal feature extractor to capture\nthe aesthetic commonality and then optimize to adapt the aesthetic\nindividuality by shifting the decision boundary of the predictor via a\nmeta-learning mechanism. Unlike conventional meta-learning methods that may\nstruggle with slow adaptation or overfitting to tiny support sets, we propose a\nnovel approach that optimizes a high-order predictor for fast adaptation. In\norder to validate the performance of the proposed method, we build several PFBP\nbenchmarks by using existing facial beauty prediction datasets rated by\nnumerous users. Extensive experiments on these benchmarks demonstrate the\neffectiveness of the proposed MetaFBP method.",
            "author": [
                "Luojun Lin",
                "Zhifeng Shen",
                "Jia-Li Yin",
                "Qipeng Liu",
                "Yuanlong Yu",
                "Weijie Chen"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3581783.3612319",
                "http://arxiv.org/abs/2311.13929v1",
                "http://arxiv.org/pdf/2311.13929v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13928v1",
            "title": "Parameter Exchange for Robust Dynamic Domain Generalization",
            "updated": "2023-11-23T11:29:16Z",
            "published": "2023-11-23T11:29:16Z",
            "summary": "Agnostic domain shift is the main reason of model degradation on the unknown\ntarget domains, which brings an urgent need to develop Domain Generalization\n(DG). Recent advances at DG use dynamic networks to achieve training-free\nadaptation on the unknown target domains, termed Dynamic Domain Generalization\n(DDG), which compensates for the lack of self-adaptability in static models\nwith fixed weights. The parameters of dynamic networks can be decoupled into a\nstatic and a dynamic component, which are designed to learn domain-invariant\nand domain-specific features, respectively. Based on the existing arts, in this\nwork, we try to push the limits of DDG by disentangling the static and dynamic\ncomponents more thoroughly from an optimization perspective. Our main\nconsideration is that we can enable the static component to learn\ndomain-invariant features more comprehensively by augmenting the\ndomain-specific information. As a result, the more comprehensive\ndomain-invariant features learned by the static component can then enforce the\ndynamic component to focus more on learning adaptive domain-specific features.\nTo this end, we propose a simple yet effective Parameter Exchange (PE) method\nto perturb the combination between the static and dynamic components. We\noptimize the model using the gradients from both the perturbed and\nnon-perturbed feed-forward jointly to implicitly achieve the aforementioned\ndisentanglement. In this way, the two components can be optimized in a\nmutually-beneficial manner, which can resist the agnostic domain shifts and\nimprove the self-adaptability on the unknown target domain. Extensive\nexperiments show that PE can be easily plugged into existing dynamic networks\nto improve their generalization ability without bells and whistles.",
            "author": [
                "Luojun Lin",
                "Zhifeng Shen",
                "Zhishu Sun",
                "Yuanlong Yu",
                "Lei Zhang",
                "Weijie Chen"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3581783.3612318",
                "http://arxiv.org/abs/2311.13928v1",
                "http://arxiv.org/pdf/2311.13928v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13925v1",
            "title": "Predicting Recovery or Decease of COVID-19 Patients with Clinical and\n  RT-PCR Using Machine Learning Classification Algorithms",
            "updated": "2023-11-23T11:21:40Z",
            "published": "2023-11-23T11:21:40Z",
            "summary": "The COVID-19 pandemic has disrupted the global economy and people's daily\nlives in unprecedented ways. To make appropriate decisions, it is necessary to\ndiagnose COVID-19 rapidly and accurately. Clinical decision making is\ninfluenced by data collected from patients. With the aid of artificial\nintelligence, COVID-19 has been diagnosed quickly by analyzing symptoms,\npolymerase chain reaction (PCR), computed tomography scans, chest X-rays,\nroutine laboratory blood tests and even cough sounds. Furthermore, these data\ncan be used to predict a patient's morality, although there is a question about\nwhich data makes the most accurate predictions. Therefore, this study consists\nof two parts. Our first objective is to examine whether machine learning\nalgorithms can predict the outcome of COVID-19 cases (recovery or death), based\non the features present in the dataset. In the second part of the research, we\ninvestigated the impact of clinical and RT-PCR on prediction of recovery and\ndecease to determine which one is more reliable. We defined four stages with\ndifferent feature sets and use six machine learning methods to build prediction\nmodel. With an accuracy of 78.7%, random forest showed promising results for\npredicting death and recovery of patients. Based on this, it appears that\nrecovery and decease of patients are predictable using machine learning. For\nsecond objective, results indicate that clinical alone (without using RT-PCR),\ntrained with AdaBoost algorithm, is the most accurate with an accuracy of\n82.1%. This study can provide guidance for medical professionals in the event\nof a crisis or outbreak similar to COVID-19.",
            "author": [
                "Mohammad Dehghani",
                "Zahra Yazdanparast"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13925v1",
                "http://arxiv.org/pdf/2311.13925v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13917v1",
            "title": "Exploring the impact of social stress on the adaptive dynamics of\n  COVID-19: Typing the behavior of na\u00efve populations faced with epidemics",
            "updated": "2023-11-23T11:05:54Z",
            "published": "2023-11-23T11:05:54Z",
            "summary": "In the context of natural disasters, human responses inevitably intertwine\nwith natural factors. The COVID-19 pandemic, as a significant stress factor,\nhas brought to light profound variations among different countries in terms of\ntheir adaptive dynamics in addressing the spread of infection outbreaks across\ndifferent regions. This emphasizes the crucial role of cultural characteristics\nin natural disaster analysis. The theoretical understanding of large-scale\nepidemics primarily relies on mean-field kinetic models. However, conventional\nSIR-like models failed to fully explain the observed phenomena at the onset of\nthe COVID-19 outbreak. These phenomena included the unexpected cessation of\nexponential growth, the reaching of plateaus, and the occurrence of multi-wave\ndynamics. In situations where an outbreak of a highly virulent and unfamiliar\ninfection arises, it becomes crucial to respond swiftly at a non-medical level\nto mitigate the negative socio-economic impact. Here we present a theoretical\nexamination of the first wave of the epidemic based on a simple SIRSS model\n(SIR with Social Stress). We conduct an analysis of the socio-cultural features\nof na\\\"ive population behaviors across various countries worldwide. The unique\ncharacteristics of each country/territory are encapsulated in only a few\nconstants within our model, derived from the fitted COVID-19 statistics. These\nconstants also reflect the societal response dynamics to the external stress\nfactor, underscoring the importance of studying the mutual behavior of humanity\nand natural factors during global social disasters. Based on these distinctive\ncharacteristics of specific regions, local authorities can optimize their\nstrategies to effectively combat epidemics until vaccines are developed.",
            "author": [
                "Innokentiy Kastalskiy",
                "Andrei Zinovyev",
                "Evgeny Mirkes",
                "Victor Kazantsev",
                "Alexander N. Gorban"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13917v1",
                "http://arxiv.org/pdf/2311.13917v1"
            ],
            "primary_category": "physics.soc-ph",
            "category": [
                "physics.soc-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13912v1",
            "title": "Expanding the deep-learning model to diagnosis LVNC: Limitations and\n  trade-offs",
            "updated": "2023-11-23T11:01:35Z",
            "published": "2023-11-23T11:01:35Z",
            "summary": "Hyper-trabeculation or non-compaction in the left ventricle of the myocardium\n(LVNC) is a recently classified form of cardiomyopathy. Several methods have\nbeen proposed to quantify the trabeculae accurately in the left ventricle, but\nthere is no general agreement in the medical community to use a particular\napproach. In previous work, we proposed DL-LVTQ, a deep learning approach for\nleft ventricular trabecular quantification based on a U-Net CNN architecture.\nDL-LVTQ was an automatic diagnosis tool developed from a dataset of patients\nwith the same cardiomyopathy (hypertrophic cardiomyopathy).\n  In this work, we have extended and adapted DL-LVTQ to cope with patients with\ndifferent cardiomyopathies. The dataset consists of up 379 patients in three\ngroups with different particularities and cardiomyopathies. Patient images were\ntaken from different scanners and hospitals. We have modified and adapted the\nU-Net convolutional neural network to account for the different particularities\nof a heterogeneous group of patients with various unclassifiable or mixed and\ninherited cardiomyopathies.\n  The inclusion of new groups of patients has increased the accuracy,\nspecificity and kappa values while maintaining the sensitivity of the automatic\ndeep learning method proposed. Therefore, a better-prepared diagnosis tool is\nready for various cardiomyopathies with different characteristics.\nCardiologists have considered that 98.9% of the evaluated outputs are verified\nclinically for diagnosis. Therefore, the high precision to segment the\ndifferent cardiac structures allows us to make a robust diagnostic system\nobjective and faster, decreasing human error and time spent.",
            "author": [
                "Gregorio Bernab\u00e9",
                "Pilar Gonz\u00e1lez-F\u00e9rez",
                "Jos\u00e9 M. Garc\u00eda",
                "Guillem Casas",
                "Josefa Gonz\u00e1lez-Carrillo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13912v1",
                "http://arxiv.org/pdf/2311.13912v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13905v1",
            "title": "A DRL solution to help reduce the cost in waiting time of securing a\n  traffic light for cyclists",
            "updated": "2023-11-23T10:39:40Z",
            "published": "2023-11-23T10:39:40Z",
            "summary": "Cyclists prefer to use infrastructure that separates them from motorized\ntraffic. Using a traffic light to segregate car and bike flows, with the\naddition of bike-specific green phases, is a lightweight and cheap solution\nthat can be deployed dynamically to assess the opportunity of a heavier\ninfrastructure such as a separate bike lane. To compensate for the increased\nwaiting time induced by these new phases, we introduce in this paper a deep\nreinforcement learning solution that adapts the green phase cycle of a traffic\nlight to the traffic. Vehicle counter data are used to compare the DRL approach\nwith the actuated traffic light control algorithm over whole days. Results show\nthat DRL achieves better minimization of vehicle waiting time at almost all\nhours. Our DRL approach is also robust to moderate changes in bike traffic. The\ncode of this paper is available at\nhttps://github.com/LucasMagnana/A-DRL-solution-to-help-reduce-the-cost-in-waiting-time-of-securing-a-traffic-light-for-cyclists.",
            "author": [
                "Lucas Magnana",
                "Herv\u00e9 Rivano",
                "Nicolas Chiabaut"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13905v1",
                "http://arxiv.org/pdf/2311.13905v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13904v1",
            "title": "3D microstructure characterization of Cu 25Cr solid state sintered alloy\n  using X-ray computed tomography and machine learning assisted segmentation",
            "updated": "2023-11-23T10:37:57Z",
            "published": "2023-11-23T10:37:57Z",
            "summary": "Cu-Cr-based alloys with Cr content from 5 to 50 wt.% are widely used as\nelectrical contacts for vacuum interrupters for medium voltage applications\nbecause of their excellent combination of mechanical, thermal, and electrical\nconductivity. Cu-Cr electrical contacts are usually processed by sintering or\ncasting processes. For solid-state sintered Cu-Cr materials, the physical\nproperties vary as a function of the Cr content, phase morphology and porosity\nvolume fraction. Some studies have investigated the effect of the\nmicrostructural characteristics of Cu-Cr alloys with different Cr content and\nmorphology on their properties. However, the porosity characterization and Cr\nspatial distribution and how they affect these alloys' physical properties are\nnot as well documented. In this study, we report an in-depth 3D\ncharacterization of the porosity and Cr-phase of solid-state sintered Cu-25Cr\nalloys with three final relative densities using X-ray Computed Tomography\n(XCT). An image analysis algorithm assisted by a machine learning-based\nsegmentation method has been specifically developed. Results show that for\nCu-25Cr solid sintered alloys there are mainly two types of pores, pores\nlocated at the Cu/Cr interfaces, and pores within the Cu matrix. The\ninterfacial porosity represents the larger volume fraction, over 75% of the\ntotal porosity for all cases, forming a large network of interconnected pores.\nWith the increase of final density, the Cu-matrix becomes nearly fully dense\nwhile interfacial pores still represent the largest fraction decreases in size\nand volume. These interfacial pores networks are believed to be formed due to\npoor filling and packing of Cu around the percolated Cr-phase. These\nobservations might be helpful to optimize the functional properties of Cu-Cr\nsintered alloys.",
            "author": [
                "Lucas Varoto",
                "Jean-Jacques Blandin",
                "Pierre Lhuissier",
                "Sophie Roure",
                "Anthony Papillon",
                "M\u00e9lissa Chosson",
                "Guilhem Martin"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.matchar.2023.113107",
                "http://arxiv.org/abs/2311.13904v1",
                "http://arxiv.org/pdf/2311.13904v1"
            ],
            "primary_category": "physics.app-ph",
            "category": [
                "physics.app-ph",
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13895v1",
            "title": "Query by Activity Video in the Wild",
            "updated": "2023-11-23T10:26:36Z",
            "published": "2023-11-23T10:26:36Z",
            "summary": "This paper focuses on activity retrieval from a video query in an imbalanced\nscenario. In current query-by-activity-video literature, a common assumption is\nthat all activities have sufficient labelled examples when learning an\nembedding. This assumption does however practically not hold, as only a portion\nof activities have many examples, while other activities are only described by\nfew examples. In this paper, we propose a visual-semantic embedding network\nthat explicitly deals with the imbalanced scenario for activity retrieval. Our\nnetwork contains two novel modules. The visual alignment module performs a\nglobal alignment between the input video and fixed-sized visual bank\nrepresentations for all activities. The semantic module performs an alignment\nbetween the input video and fixed-sized semantic activity representations. By\nmatching videos with both visual and semantic activity representations that are\nof equal size over all activities, we no longer ignore infrequent activities\nduring retrieval. Experiments on a new imbalanced activity retrieval benchmark\nshow the effectiveness of our approach for all types of activities.",
            "author": [
                "Tao Hu",
                "William Thong",
                "Pascal Mettes",
                "Cees G. M. Snoek"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13895v1",
                "http://arxiv.org/pdf/2311.13895v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13889v1",
            "title": "SIMBa: System Identification Methods leveraging Backpropagation",
            "updated": "2023-11-23T10:20:12Z",
            "published": "2023-11-23T10:20:12Z",
            "summary": "This manuscript details the SIMBa toolbox (System Identification Methods\nleveraging Backpropagation), which uses well-established Machine Learning tools\nfor discrete-time linear multi-step-ahead state-space System Identification\n(SI). Backed up by novel linear-matrix-inequality-based free parametrizations\nof Schur matrices to guarantee the stability of the identified model by design,\nSIMBa allows for seamless integration of prior system knowledge. In particular,\nit can simultaneously enforce desired system properties - such as sparsity\npatterns - and stability on the model, solving an open SI problem.\n  We extensively investigate SIMBa's behavior when identifying diverse systems\nwith various properties from both simulated and real-world data. Overall, we\nfind it consistently outperforms traditional stable subspace identification\nmethods, and sometimes significantly, even while enforcing desired model\nproperties. These results hint at the potential of SIMBa to pave the way for\ngeneric structured nonlinear SI. The toolbox is open-sourced on\nhttps://github.com/Cemempamoi/simba.",
            "author": [
                "Loris Di Natale",
                "Muhammad Zakwan",
                "Philipp Heer",
                "Giancarlo Ferrari Trecate",
                "Colin N. Jones"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13889v1",
                "http://arxiv.org/pdf/2311.13889v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13887v1",
            "title": "Unsupervised Learning for Topological Classification of Transportation\n  Networks",
            "updated": "2023-11-23T10:18:21Z",
            "published": "2023-11-23T10:18:21Z",
            "summary": "With increasing urbanization, transportation plays an increasingly critical\nrole in city development. The number of studies on modeling, optimization,\nsimulation, and data analysis of transportation systems is on the rise. Many of\nthese studies utilize transportation test networks to represent real-world\ntransportation systems in urban areas, examining the efficacy of their proposed\napproaches. Each of these networks exhibits unique characteristics in their\ntopology, making their applications distinct for various study objectives.\nDespite their widespread use in research, there is a lack of comprehensive\nstudy addressing the classification of these networks based on their\ntopological characteristics. This study aims to fill this gap by employing\nunsupervised learning methods, particularly clustering. We present a\ncomprehensive framework for evaluating various topological network\ncharacteristics. Additionally, we employ two dimensionality reduction\ntechniques, namely Principal Component Analysis (PCA) and Isometric Feature\nMapping (ISOMAP), to reduce overlaps of highly correlated features and enhance\nthe interpretability of the subsequent classification results. We then utilize\ntwo clustering algorithms, K-means and HDBSCAN, to classify 14 transportation\nnetworks. The PCA method, followed by the K-means clustering approach,\noutperforms other alternatives with a Silhouette score of $0.510$, enabling the\nclassification of transportation networks into five clusters. We also provide a\ndetailed discussion on the resulting classification.",
            "author": [
                "Sina Sabzekar",
                "Mohammad Reza Valipour Malakshah",
                "Zahra Amini"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13887v1",
                "http://arxiv.org/pdf/2311.13887v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13885v1",
            "title": "Can Physics Informed Neural Operators Self Improve?",
            "updated": "2023-11-23T10:15:09Z",
            "published": "2023-11-23T10:15:09Z",
            "summary": "Self-training techniques have shown remarkable value across many deep\nlearning models and tasks. However, such techniques remain largely unexplored\nwhen considered in the context of learning fast solvers for systems of partial\ndifferential equations (Eg: Neural Operators). In this work, we explore the use\nof self-training for Fourier Neural Operators (FNO). Neural Operators emerged\nas a data driven technique, however, data from experiments or traditional\nsolvers is not always readily available. Physics Informed Neural Operators\n(PINO) overcome this constraint by utilizing a physics loss for the training,\nhowever the accuracy of PINO trained without data does not match the\nperformance obtained by training with data. In this work we show that\nself-training can be used to close this gap in performance. We examine\ncanonical examples, namely the 1D-Burgers and 2D-Darcy PDEs, to showcase the\nefficacy of self-training. Specifically, FNOs, when trained exclusively with\nphysics loss through self-training, approach 1.07x for Burgers and 1.02x for\nDarcy, compared to FNOs trained with both data and physics loss. Furthermore,\nwe discover that pseudo-labels can be used for self-training without\nnecessarily training to convergence in each iteration. A consequence of this is\nthat we are able to discover self-training schedules that improve upon the\nbaseline performance of PINO in terms of accuracy as well as time.",
            "author": [
                "Ritam Majumdar",
                "Amey Varhade",
                "Shirish Karande",
                "Lovekesh Vig"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13885v1",
                "http://arxiv.org/pdf/2311.13885v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "math.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13884v1",
            "title": "Controlling Large Language Model-based Agents for Large-Scale\n  Decision-Making: An Actor-Critic Approach",
            "updated": "2023-11-23T10:14:58Z",
            "published": "2023-11-23T10:14:58Z",
            "summary": "The significant advancements in large language models (LLMs) have presented\nnovel opportunities for tackling planning and decision-making within\nmulti-agent systems. However, as the number of agents increases, the issues of\nhallucination in LLMs and coordination in multi-agent systems (MAS) have become\nincreasingly pronounced. Additionally, the efficient utilization of tokens\nbecomes a critical consideration when employing LLMs to facilitate the\ninteractions of large numbers of agents. In this paper, we present a novel\nframework aimed at enhancing coordination and decision-making capabilities of\nLLMs within large-scale multi-agent environments. Our approach draws\ninspiration from the actor-critic framework employed in multi-agent\nreinforcement learning, and we develop a modular and token-efficient solution\nthat effectively addresses challenges presented by LLMs and MAS. Through\nevaluations conducted in experiments involving system resource allocation and\nrobot grid transportation, we demonstrate the considerable advantages afforded\nby our proposed approach.",
            "author": [
                "Bin Zhang",
                "Hangyu Mao",
                "Jingqing Ruan",
                "Ying Wen",
                "Yang Li",
                "Shao Zhang",
                "Zhiwei Xu",
                "Dapeng Li",
                "Ziyue Li",
                "Rui Zhao",
                "Lijuan Li",
                "Guoliang Fan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13884v1",
                "http://arxiv.org/pdf/2311.13884v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14749v1",
            "title": "Compositional Zero-shot Learning via Progressive Language-based\n  Observations",
            "updated": "2023-11-23T10:14:23Z",
            "published": "2023-11-23T10:14:23Z",
            "summary": "Compositional zero-shot learning aims to recognize unseen state-object\ncompositions by leveraging known primitives (state and object) during training.\nHowever, effectively modeling interactions between primitives and generalizing\nknowledge to novel compositions remains a perennial challenge. There are two\nkey factors: object-conditioned and state-conditioned variance, i.e., the\nappearance of states (or objects) can vary significantly when combined with\ndifferent objects (or states). For instance, the state \"old\" can signify a\nvintage design for a \"car\" or an advanced age for a \"cat\". In this paper, we\nargue that these variances can be mitigated by predicting composition\ncategories based on pre-observed primitive. To this end, we propose Progressive\nLanguage-based Observations (PLO), which can dynamically determine a better\nobservation order of primitives. These observations comprise a series of\nconcepts or languages that allow the model to understand image content in a\nstep-by-step manner. Specifically, PLO adopts pre-trained vision-language\nmodels (VLMs) to empower the model with observation capabilities. We further\ndevise two variants: 1) PLO-VLM: a two-step method, where a pre-observing\nclassifier dynamically determines the observation order of two primitives. 2)\nPLO-LLM: a multi-step scheme, which utilizes large language models (LLMs) to\ncraft composition-specific prompts for step-by-step observing. Extensive\nablations on three challenging datasets demonstrate the superiority of PLO\ncompared with state-of-the-art methods, affirming its abilities in\ncompositional recognition.",
            "author": [
                "Lin Li",
                "Guikun Chen",
                "Jun Xiao",
                "Long Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14749v1",
                "http://arxiv.org/pdf/2311.14749v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13883v1",
            "title": "Leveraging Optimal Transport via Projections on Subspaces for Machine\n  Learning Applications",
            "updated": "2023-11-23T10:13:07Z",
            "published": "2023-11-23T10:13:07Z",
            "summary": "Optimal Transport has received much attention in Machine Learning as it\nallows to compare probability distributions by exploiting the geometry of the\nunderlying space. However, in its original formulation, solving this problem\nsuffers from a significant computational burden. Thus, a meaningful line of\nwork consists at proposing alternatives to reduce this burden while still\nenjoying its properties. In this thesis, we focus on alternatives which use\nprojections on subspaces. The main such alternative is the Sliced-Wasserstein\ndistance, which we first propose to extend to Riemannian manifolds in order to\nuse it in Machine Learning applications for which using such spaces has been\nshown to be beneficial in the recent years. We also study sliced distances\nbetween positive measures in the so-called unbalanced OT problem. Back to the\noriginal Euclidean Sliced-Wasserstein distance between probability measures, we\nstudy the dynamic of gradient flows when endowing the space with this distance\nin place of the usual Wasserstein distance. Then, we investigate the use of the\nBusemann function, a generalization of the inner product in metric spaces, in\nthe space of probability measures. Finally, we extend the subspace detour\napproach to incomparable spaces using the Gromov-Wasserstein distance.",
            "author": [
                "Cl\u00e9ment Bonet"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13883v1",
                "http://arxiv.org/pdf/2311.13883v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13881v1",
            "title": "A Multi-solution Study on GDPR AI-enabled Completeness Checking of DPAs",
            "updated": "2023-11-23T10:05:52Z",
            "published": "2023-11-23T10:05:52Z",
            "summary": "Specifying legal requirements for software systems to ensure their compliance\nwith the applicable regulations is a major concern to requirements engineering\n(RE). Personal data which is collected by an organization is often shared with\nother organizations to perform certain processing activities. In such cases,\nthe General Data Protection Regulation (GDPR) requires issuing a data\nprocessing agreement (DPA) which regulates the processing and further ensures\nthat personal data remains protected. Violating GDPR can lead to huge fines\nreaching to billions of Euros. Software systems involving personal data\nprocessing must adhere to the legal obligations stipulated in GDPR and outlined\nin DPAs. Requirements engineers can elicit from DPAs legal requirements for\nregulating the data processing activities in software systems. Checking the\ncompleteness of a DPA according to the GDPR provisions is therefore an\nessential prerequisite to ensure that the elicited requirements are complete.\nAnalyzing DPAs entirely manually is time consuming and requires adequate legal\nexpertise. In this paper, we propose an automation strategy to address the\ncompleteness checking of DPAs against GDPR. Specifically, we pursue ten\nalternative solutions which are enabled by different technologies, namely\ntraditional machine learning, deep learning, language modeling, and few-shot\nlearning. The goal of our work is to empirically examine how these different\ntechnologies fare in the legal domain. We computed F2 score on a set of 30 real\nDPAs. Our evaluation shows that best-performing solutions yield F2 score of\n86.7% and 89.7% are based on pre-trained BERT and RoBERTa language models. Our\nanalysis further shows that other alternative solutions based on deep learning\n(e.g., BiLSTM) and few-shot learning (e.g., SetFit) can achieve comparable\naccuracy, yet are more efficient to develop.",
            "author": [
                "Muhammad Ilyas Azeem",
                "Sallam Abualhaija"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13881v1",
                "http://arxiv.org/pdf/2311.13881v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13880v1",
            "title": "PointPCA+: Extending PointPCA objective quality assessment metric",
            "updated": "2023-11-23T10:05:31Z",
            "published": "2023-11-23T10:05:31Z",
            "summary": "A computationally-simplified and descriptor-richer Point Cloud Quality\nAssessment (PCQA) metric, namely PointPCA+, is proposed in this paper, which is\nan extension of PointPCA. PointPCA proposed a set of perceptually-relevant\ndescriptors based on PCA decomposition that were applied to both the geometry\nand texture data of point clouds for full reference PCQA. PointPCA+ employs PCA\nonly on the geometry data while enriching existing geometry and texture\ndescriptors, that are computed more efficiently. Similarly to PointPCA, a total\nquality score is obtained through a learning-based fusion of individual\npredictions from geometry and texture descriptors that capture local shape and\nappearance properties, respectively. Before feature fusion, a feature selection\nmodule is introduced to choose the most effective features from a proposed\nsuper-set. Experimental results show that PointPCA+ achieves high predictive\nperformance against subjective ground truth scores obtained from publicly\navailable datasets. The code is available at\n\\url{https://github.com/cwi-dis/pointpca_suite/}.",
            "author": [
                "Xuemei Zhou",
                "Evangelos Alexiou",
                "Irene Viola",
                "Pablo Cesar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13880v1",
                "http://arxiv.org/pdf/2311.13880v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14748v1",
            "title": "Application of Reconfigurable All-Optical Activation Unit based on\n  Optical Injection into Bistable Fabry-P\u00e9rot Laser in Multilayer\n  Perceptron Neural Networks",
            "updated": "2023-11-23T10:02:41Z",
            "published": "2023-11-23T10:02:41Z",
            "summary": "In this paper we theoretically investigate application of a bistable\nFabry-P\\'{e}rot semiconductor laser under optical-injection as all-optical\nactivation unit for multilayer perceptron optical neural networks. The proposed\ndevice is programmed to provide reconfigurable sigmoid-like activation\nfunctions with adjustable thresholds and saturation points and benchmarked on\nmachine learning image recognition problems. Due to the reconfigurability of\nthe activation unit, the accuracy can be increased by up to 2% simply by\nadjusting the control parameter of the activation unit to suit the specific\nproblem. For a simple two-layer perceptron neural network, we achieve inference\naccuracies of up to 95% and 85%, for the MNIST and Fashion-MNIST datasets,\nrespectively.",
            "author": [
                "Jasna V. Crnjanski",
                "Isidora Teofilovi\u0107",
                "Marko M. Krsti\u0107",
                "Dejan M. Gvozdi\u0107"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14748v1",
                "http://arxiv.org/pdf/2311.14748v1"
            ],
            "primary_category": "cs.ET",
            "category": [
                "cs.ET",
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13877v1",
            "title": "Locally Optimal Descent for Dynamic Stepsize Scheduling",
            "updated": "2023-11-23T09:57:35Z",
            "published": "2023-11-23T09:57:35Z",
            "summary": "We introduce a novel dynamic learning-rate scheduling scheme grounded in\ntheory with the goal of simplifying the manual and time-consuming tuning of\nschedules in practice. Our approach is based on estimating the locally-optimal\nstepsize, guaranteeing maximal descent in the direction of the stochastic\ngradient of the current step. We first establish theoretical convergence bounds\nfor our method within the context of smooth non-convex stochastic optimization,\nmatching state-of-the-art bounds while only assuming knowledge of the\nsmoothness parameter. We then present a practical implementation of our\nalgorithm and conduct systematic experiments across diverse datasets and\noptimization algorithms, comparing our scheme with existing state-of-the-art\nlearning-rate schedulers. Our findings indicate that our method needs minimal\ntuning when compared to existing approaches, removing the need for auxiliary\nmanual schedules and warm-up phases and achieving comparable performance with\ndrastically reduced parameter tuning.",
            "author": [
                "Gilad Yehudai",
                "Alon Cohen",
                "Amit Daniely",
                "Yoel Drori",
                "Tomer Koren",
                "Mariano Schain"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13877v1",
                "http://arxiv.org/pdf/2311.13877v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13876v1",
            "title": "EEG Connectivity Analysis Using Denoising Autoencoders for the Detection\n  of Dyslexia",
            "updated": "2023-11-23T09:49:22Z",
            "published": "2023-11-23T09:49:22Z",
            "summary": "The Temporal Sampling Framework (TSF) theorizes that the characteristic\nphonological difficulties of dyslexia are caused by an atypical oscillatory\nsampling at one or more temporal rates. The LEEDUCA study conducted a series of\nElectroencephalography (EEG) experiments on children listening to amplitude\nmodulated (AM) noise with slow-rythmic prosodic (0.5-1 Hz), syllabic (4-8 Hz)\nor the phoneme (12-40 Hz) rates, aimed at detecting differences in perception\nof oscillatory sampling that could be associated with dyslexia. The purpose of\nthis work is to check whether these differences exist and how they are related\nto children's performance in different language and cognitive tasks commonly\nused to detect dyslexia. To this purpose, temporal and spectral inter-channel\nEEG connectivity was estimated, and a denoising autoencoder (DAE) was trained\nto learn a low-dimensional representation of the connectivity matrices. This\nrepresentation was studied via correlation and classification analysis, which\nrevealed ability in detecting dyslexic subjects with an accuracy higher than\n0.8, and balanced accuracy around 0.7. Some features of the DAE representation\nwere significantly correlated ($p<0.005$) with children's performance in\nlanguage and cognitive tasks of the phonological hypothesis category such as\nphonological awareness and rapid symbolic naming, as well as reading efficiency\nand reading comprehension. Finally, a deeper analysis of the adjacency matrix\nrevealed a reduced bilateral connection between electrodes of the temporal lobe\n(roughly the primary auditory cortex) in DD subjects, as well as an increased\nconnectivity of the F7 electrode, placed roughly on Broca's area. These results\npave the way for a complementary assessment of dyslexia using more objective\nmethodologies such as EEG.",
            "author": [
                "Francisco Jesus Martinez-Murcia",
                "Andr\u00e9s Ortiz",
                "Juan Manuel G\u00f3rriz",
                "Javier Ram\u00edrez",
                "Pedro Javier Lopez-Perez",
                "Miguel L\u00f3pez-Zamora",
                "Juan Luis Luque"
            ],
            "link": [
                "http://dx.doi.org/10.1142/S0129065720500379",
                "http://arxiv.org/abs/2311.13876v1",
                "http://arxiv.org/pdf/2311.13876v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13874v1",
            "title": "Transitive inference as probabilistic preference learning",
            "updated": "2023-11-23T09:40:56Z",
            "published": "2023-11-23T09:40:56Z",
            "summary": "Transitive Inference (TI) is a cognitive task that assesses an organism's\nability to infer novel relations between items based on previously acquired\nknowledge. TI is known for exhibiting various behavioral and neural signatures,\nsuch as the Serial Position Effect (SPE), Symbolic Distance Effect (SDE), and\nthe brain's capacity to maintain and merge separate ranking models. We propose\na novel framework that casts TI as a probabilistic preference learning task,\nusing one-parameter Mallows models. We present a series of simulations that\nhighlight the effectiveness of our novel approach. We show that the Mallows\nranking model natively reproduces SDE and SPE. Furthermore, extending the model\nusing Bayesian selection showcases its capacity to generate and merge ranking\nhypotheses as pairs with connecting symbols are encountered. Finally, we employ\nneural networks to replicate Mallows models, demonstrating how this framework\naligns with observed prefrontal neural activity during TI. Our innovative\napproach sheds new light on the nature of TI, emphasizing the potential of\nprobabilistic preference learning for unraveling its underlying neural\nmechanisms.",
            "author": [
                "Francesco Mannella",
                "Giovanni Pezzulo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13874v1",
                "http://arxiv.org/pdf/2311.13874v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13871v1",
            "title": "Legal Requirements Analysis",
            "updated": "2023-11-23T09:31:57Z",
            "published": "2023-11-23T09:31:57Z",
            "summary": "Modern software has been an integral part of everyday activities in many\ndisciplines and application contexts. Introducing intelligent automation by\nleveraging artificial intelligence (AI) led to break-throughs in many fields.\nThe effectiveness of AI can be attributed to several factors, among which is\nthe increasing availability of data. Regulations such as the general data\nprotection regulation (GDPR) in the European Union (EU) are introduced to\nensure the protection of personal data. Software systems that collect, process,\nor share personal data are subject to compliance with such regulations.\nDeveloping compliant software depends heavily on addressing legal requirements\nstipulated in applicable regulations, a central activity in the requirements\nengineering (RE) phase of the software development process. RE is concerned\nwith specifying and maintaining requirements of a system-to-be, including legal\nrequirements. Legal agreements which describe the policies organizations\nimplement for processing personal data can provide an additional source to\nregulations for eliciting legal requirements. In this chapter, we explore a\nvariety of methods for analyzing legal requirements and exemplify them on GDPR.\nSpecifically, we describe possible alternatives for creating machine-analyzable\nrepresentations from regulations, survey the existing automated means for\nenabling compliance verification against regulations, and further reflect on\nthe current challenges of legal requirements analysis.",
            "author": [
                "Sallam Abualhaija",
                "Marcello Ceci",
                "Lionel Briand"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13871v1",
                "http://arxiv.org/pdf/2311.13871v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13870v1",
            "title": "L(M)V-IQL: Multiple Intention Inverse Reinforcement Learning for Animal\n  Behavior Characterization",
            "updated": "2023-11-23T09:27:08Z",
            "published": "2023-11-23T09:27:08Z",
            "summary": "In advancing the understanding of decision-making processes, mathematical\nmodels, particularly Inverse Reinforcement Learning (IRL), have proven\ninstrumental in reconstructing animal's multiple intentions amidst complex\nbehaviors. Given the recent development of a continuous-time multi-intention\nIRL framework, there has been persistent inquiry into inferring discrete\ntime-varying reward functions with multiple intention IRL approaches. To tackle\nthe challenge, we introduce the Latent (Markov) Variable Inverse Q-learning\n(L(M)V-IQL) algorithms, a novel IRL framework tailored for accommodating\ndiscrete intrinsic rewards. Leveraging an Expectation-Maximization approach, we\ncluster observed trajectories into distinct intentions and independently solve\nthe IRL problem for each. Demonstrating the efficacy of L(M)V-IQL through\nsimulated experiments and its application to different real mouse behavior\ndatasets, our approach surpasses current benchmarks in animal behavior\nprediction, producing interpretable reward functions. This advancement holds\npromise for neuroscience and psychology, contributing to a deeper understanding\nof animal decision-making and uncovering underlying brain mechanisms.",
            "author": [
                "Hao Zhu",
                "Brice De La Crompe",
                "Gabriel Kalweit",
                "Artur Schneider",
                "Maria Kalweit",
                "Ilka Diester",
                "Joschka Boedecker"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13870v1",
                "http://arxiv.org/pdf/2311.13870v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13866v1",
            "title": "Data-Driven Robot Fault Detection and Diagnosis Using Generative Models:\n  A Modified SFDD Algorithm",
            "updated": "2023-11-23T09:11:34Z",
            "published": "2023-11-23T09:11:34Z",
            "summary": "This paper presents a modification of the data-driven sensor-based fault\ndetection and diagnosis (SFDD) algorithm for online robot monitoring. Our\nversion of the algorithm uses a collection of generative models, in particular\nrestricted Boltzmann machines, each of which represents the distribution of\nsliding window correlations between a pair of correlated measurements. We use\nsuch models in a residual generation scheme, where high residuals generate\nconflict sets that are then used in a subsequent diagnosis step. As a proof of\nconcept, the framework is evaluated on a mobile logistics robot for the problem\nof recognising disconnected wheels, such that the evaluation demonstrates the\nfeasibility of the framework (on the faulty data set, the models obtained 88.6%\nprecision and 75.6% recall rates), but also shows that the monitoring results\nare influenced by the choice of distribution model and the model parameters as\na whole.",
            "author": [
                "Alex Mitrevski",
                "Paul G. Pl\u00f6ger"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13866v1",
                "http://arxiv.org/pdf/2311.13866v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13865v1",
            "title": "Language-guided Few-shot Semantic Segmentation",
            "updated": "2023-11-23T09:08:49Z",
            "published": "2023-11-23T09:08:49Z",
            "summary": "Few-shot learning is a promising way for reducing the label cost in new\ncategories adaptation with the guidance of a small, well labeled support set.\nBut for few-shot semantic segmentation, the pixel-level annotations of support\nimages are still expensive. In this paper, we propose an innovative solution to\ntackle the challenge of few-shot semantic segmentation using only language\ninformation, i.e.image-level text labels. Our approach involves a\nvision-language-driven mask distillation scheme, which contains a\nvision-language pretraining (VLP) model and a mask refiner, to generate high\nquality pseudo-semantic masks from text prompts. We additionally introduce a\ndistributed prototype supervision method and complementary correlation matching\nmodule to guide the model in digging precise semantic relations among support\nand query images. The experiments on two benchmark datasets demonstrate that\nour method establishes a new baseline for language-guided few-shot semantic\nsegmentation and achieves competitive results to recent vision-guided methods.",
            "author": [
                "Jing Wang",
                "Yuang Liu",
                "Qiang Zhou",
                "Fan Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13865v1",
                "http://arxiv.org/pdf/2311.13865v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13864v1",
            "title": "Which Matters Most in Making Fund Investment Decisions? A\n  Multi-granularity Graph Disentangled Learning Framework",
            "updated": "2023-11-23T09:08:43Z",
            "published": "2023-11-23T09:08:43Z",
            "summary": "In this paper, we highlight that both conformity and risk preference matter\nin making fund investment decisions beyond personal interest and seek to\njointly characterize these aspects in a disentangled manner. Consequently, we\ndevelop a novel M ulti-granularity Graph Disentangled Learning framework named\nMGDL to effectively perform intelligent matching of fund investment products.\nBenefiting from the well-established fund graph and the attention module,\nmulti-granularity user representations are derived from historical behaviors to\nseparately express personal interest, conformity and risk preference in a\nfine-grained way. To attain stronger disentangled representations with specific\nsemantics, MGDL explicitly involve two self-supervised signals, i.e., fund type\nbased contrasts and fund popularity. Extensive experiments in offline and\nonline environments verify the effectiveness of MGDL.",
            "author": [
                "Chunjing Gan",
                "Binbin Hu",
                "Bo Huang",
                "Tianyu Zhao",
                "Yingru Lin",
                "Wenliang Zhong",
                "Zhiqiang Zhang",
                "Jun Zhou",
                "Chuan Shi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13864v1",
                "http://arxiv.org/pdf/2311.13864v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13861v1",
            "title": "A Deep Reinforcement Learning Approach for Improving Age of Information\n  in Mission-Critical IoT",
            "updated": "2023-11-23T09:04:25Z",
            "published": "2023-11-23T09:04:25Z",
            "summary": "The emerging mission-critical Internet of Things (IoT) play a vital role in\nremote healthcare, haptic interaction, and industrial automation, where timely\ndelivery of status updates is crucial. The Age of Information (AoI) is an\neffective metric to capture and evaluate information freshness at the\ndestination. A system design based solely on the optimization of the average\nAoI might not be adequate to capture the requirements of mission-critical\napplications, since averaging eliminates the effects of extreme events. In this\npaper, we introduce a Deep Reinforcement Learning (DRL)-based algorithm to\nimprove AoI in mission-critical IoT applications. The objective is to minimize\nan AoI-based metric consisting of the weighted sum of the average AoI and the\nprobability of exceeding an AoI threshold. We utilize the actor-critic method\nto train the algorithm to achieve optimized scheduling policy to solve the\nformulated problem. The performance of our proposed method is evaluated in a\nsimulated setup and the results show a significant improvement in terms of the\naverage AoI and the AoI violation probability compared to the related-work.",
            "author": [
                "Hossam Farag",
                "Mikael Gidlund",
                "Cedomir Stefanovic"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13861v1",
                "http://arxiv.org/pdf/2311.13861v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13852v1",
            "title": "A Cross Attention Approach to Diagnostic Explainability using Clinical\n  Practice Guidelines for Depression",
            "updated": "2023-11-23T08:42:18Z",
            "published": "2023-11-23T08:42:18Z",
            "summary": "The lack of explainability using relevant clinical knowledge hinders the\nadoption of Artificial Intelligence-powered analysis of unstructured clinical\ndialogue. A wealth of relevant, untapped Mental Health (MH) data is available\nin online communities, providing the opportunity to address the explainability\nproblem with substantial potential impact as a screening tool for both online\nand offline applications. We develop a method to enhance attention in popular\ntransformer models and generate clinician-understandable explanations for\nclassification by incorporating external clinical knowledge. Inspired by how\nclinicians rely on their expertise when interacting with patients, we leverage\nrelevant clinical knowledge to model patient inputs, providing meaningful\nexplanations for classification. This will save manual review time and engender\ntrust. We develop such a system in the context of MH using clinical practice\nguidelines (CPG) for diagnosing depression, a mental health disorder of global\nconcern. We propose an application-specific language model called ProcesS\nknowledge-infused cross ATtention (PSAT), which incorporates CPGs when\ncomputing attention. Through rigorous evaluation on three expert-curated\ndatasets related to depression, we demonstrate application-relevant\nexplainability of PSAT. PSAT also surpasses the performance of nine baseline\nmodels and can provide explanations where other baselines fall short. We\ntransform a CPG resource focused on depression, such as the Patient Health\nQuestionnaire (e.g. PHQ-9) and related questions, into a machine-readable\nontology using SNOMED-CT. With this resource, PSAT enhances the ability of\nmodels like GPT-3.5 to generate application-relevant explanations.",
            "author": [
                "Sumit Dalal",
                "Deepa Tilwani",
                "Manas Gaur",
                "Sarika Jain",
                "Valerie Shalin",
                "Amit Seth"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13852v1",
                "http://arxiv.org/pdf/2311.13852v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13847v2",
            "title": "Perceptual Image Compression with Cooperative Cross-Modal Side\n  Information",
            "updated": "2023-11-28T14:49:54Z",
            "published": "2023-11-23T08:31:11Z",
            "summary": "The explosion of data has resulted in more and more associated text being\ntransmitted along with images. Inspired by from distributed source coding, many\nworks utilize image side information to enhance image compression. However,\nexisting methods generally do not consider using text as side information to\nenhance perceptual compression of images, even though the benefits of\nmultimodal synergy have been widely demonstrated in research. This begs the\nfollowing question: How can we effectively transfer text-level semantic\ndependencies to help image compression, which is only available to the decoder?\nIn this work, we propose a novel deep image compression method with text-guided\nside information to achieve a better rate-perception-distortion tradeoff.\nSpecifically, we employ the CLIP text encoder and an effective Semantic-Spatial\nAware block to fuse the text and image features. This is done by predicting a\nsemantic mask to guide the learned text-adaptive affine transformation at the\npixel level. Furthermore, we design a text-conditional generative adversarial\nnetworks to improve the perceptual quality of reconstructed images. Extensive\nexperiments involving four datasets and ten image quality assessment metrics\ndemonstrate that the proposed approach achieves superior results in terms of\nrate-perception trade-off and semantic distortion.",
            "author": [
                "Shiyu Qin",
                "Bin Chen",
                "Yujun Huang",
                "Baoyi An",
                "Tao Dai",
                "Shu-Tao Xia"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13847v2",
                "http://arxiv.org/pdf/2311.13847v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.IT",
                "eess.IV",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13846v2",
            "title": "Progressive Learning with Visual Prompt Tuning for Variable-Rate Image\n  Compression",
            "updated": "2023-11-28T14:31:43Z",
            "published": "2023-11-23T08:29:32Z",
            "summary": "In this paper, we propose a progressive learning paradigm for\ntransformer-based variable-rate image compression. Our approach covers a wide\nrange of compression rates with the assistance of the Layer-adaptive Prompt\nModule (LPM). Inspired by visual prompt tuning, we use LPM to extract prompts\nfor input images and hidden features at the encoder side and decoder side,\nrespectively, which are fed as additional information into the Swin Transformer\nlayer of a pre-trained transformer-based image compression model to affect the\nallocation of attention region and the bits, which in turn changes the target\ncompression ratio of the model. To ensure the network is more lightweight, we\ninvolves the integration of prompt networks with less convolutional layers.\nExhaustive experiments show that compared to methods based on multiple models,\nwhich are optimized separately for different target rates, the proposed method\narrives at the same performance with 80% savings in parameter storage and 90%\nsavings in datasets. Meanwhile, our model outperforms all current variable\nbitrate image methods in terms of rate-distortion performance and approaches\nthe state-of-the-art fixed bitrate image compression methods trained from\nscratch.",
            "author": [
                "Shiyu Qin",
                "Yimin Zhou",
                "Jinpeng Wang",
                "Bin Chen",
                "Baoyi An",
                "Tao Dai",
                "Shu-Tao Xia"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13846v2",
                "http://arxiv.org/pdf/2311.13846v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13845v1",
            "title": "Touring sampling with pushforward maps",
            "updated": "2023-11-23T08:23:43Z",
            "published": "2023-11-23T08:23:43Z",
            "summary": "The number of sampling methods could be daunting for a practitioner looking\nto cast powerful machine learning methods to their specific problem. This paper\ntakes a theoretical stance to review and organize many sampling approaches in\nthe ``generative modeling'' setting, where one wants to generate new data that\nare similar to some training examples. By revealing links between existing\nmethods, it might prove useful to overcome some of the current challenges in\nsampling with diffusion models, such as long inference time due to diffusion\nsimulation, or the lack of diversity in generated samples.",
            "author": [
                "Vivien Cabannes",
                "Charles Arnal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13845v1",
                "http://arxiv.org/pdf/2311.13845v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13843v1",
            "title": "Exact Combinatorial Optimization with Temporo-Attentional Graph Neural\n  Networks",
            "updated": "2023-11-23T08:07:15Z",
            "published": "2023-11-23T08:07:15Z",
            "summary": "Combinatorial optimization finds an optimal solution within a discrete set of\nvariables and constraints. The field has seen tremendous progress both in\nresearch and industry. With the success of deep learning in the past decade, a\nrecent trend in combinatorial optimization has been to improve state-of-the-art\ncombinatorial optimization solvers by replacing key heuristic components with\nmachine learning (ML) models. In this paper, we investigate two essential\naspects of machine learning algorithms for combinatorial optimization: temporal\ncharacteristics and attention. We argue that for the task of variable selection\nin the branch-and-bound (B&B) algorithm, incorporating the temporal information\nas well as the bipartite graph attention improves the solver's performance. We\nsupport our claims with intuitions and numerical results over several standard\ndatasets used in the literature and competitions. Code is available at:\nhttps://developer.huaweicloud.com/develop/aigallery/notebook/detail?id=047c6cf2-8463-40d7-b92f-7b2ca998e935",
            "author": [
                "Mehdi Seyfi",
                "Amin Banitalebi-Dehkordi",
                "Zirui Zhou",
                "Yong Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13843v1",
                "http://arxiv.org/pdf/2311.13843v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.MS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13841v1",
            "title": "Adversarial defense based on distribution transfer",
            "updated": "2023-11-23T08:01:18Z",
            "published": "2023-11-23T08:01:18Z",
            "summary": "The presence of adversarial examples poses a significant threat to deep\nlearning models and their applications. Existing defense methods provide\ncertain resilience against adversarial examples, but often suffer from\ndecreased accuracy and generalization performance, making it challenging to\nachieve a trade-off between robustness and generalization. To address this, our\npaper interprets the adversarial example problem from the perspective of sample\ndistribution and proposes a defense method based on distribution shift,\nleveraging the distribution transfer capability of a diffusion model for\nadversarial defense. The core idea is to exploit the discrepancy between normal\nand adversarial sample distributions to achieve adversarial defense using a\npretrained diffusion model. Specifically, an adversarial sample undergoes a\nforward diffusion process, moving away from the source distribution, followed\nby a reverse process guided by the protected model (victim model) output to map\nit back to the normal distribution. Experimental evaluations on CIFAR10 and\nImageNet30 datasets are conducted, comparing with adversarial training and\ninput preprocessing methods. For infinite-norm attacks with 8/255 perturbation,\naccuracy rates of 78.1% and 83.5% are achieved, respectively. For 2-norm\nattacks with 128/255 perturbation, accuracy rates are 74.3% and 82.5%.\nAdditional experiments considering perturbation amplitude, diffusion\niterations, and adaptive attacks also validate the effectiveness of the\nproposed method. Results demonstrate that even when the attacker has knowledge\nof the defense, the proposed distribution-based method effectively withstands\nadversarial examples. It fills the gaps of traditional approaches, restoring\nhigh-quality original samples and showcasing superior performance in model\nrobustness and generalization.",
            "author": [
                "Jiahao Chen",
                "Diqun Yan",
                "Li Dong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13841v1",
                "http://arxiv.org/pdf/2311.13841v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13833v1",
            "title": "Lego: Learning to Disentangle and Invert Concepts Beyond Object\n  Appearance in Text-to-Image Diffusion Models",
            "updated": "2023-11-23T07:33:38Z",
            "published": "2023-11-23T07:33:38Z",
            "summary": "Diffusion models have revolutionized generative content creation and\ntext-to-image (T2I) diffusion models in particular have increased the creative\nfreedom of users by allowing scene synthesis using natural language. T2I models\nexcel at synthesizing concepts such as nouns, appearances, and styles. To\nenable customized content creation based on a few example images of a concept,\nmethods such as Textual Inversion and DreamBooth invert the desired concept and\nenable synthesizing it in new scenes. However, inverting more general concepts\nthat go beyond object appearance and style (adjectives and verbs) through\nnatural language, remains a challenge. Two key characteristics of these\nconcepts contribute to the limitations of current inversion methods. 1)\nAdjectives and verbs are entangled with nouns (subject) and can hinder\nappearance-based inversion methods, where the subject appearance leaks into the\nconcept embedding and 2) describing such concepts often extends beyond single\nword embeddings (being frozen in ice, walking on a tightrope, etc.) that\ncurrent methods do not handle.\n  In this study, we introduce Lego, a textual inversion method designed to\ninvert subject entangled concepts from a few example images. Lego disentangles\nconcepts from their associated subjects using a simple yet effective Subject\nSeparation step and employs a Context Loss that guides the inversion of\nsingle/multi-embedding concepts. In a thorough user study, Lego-generated\nconcepts were preferred over 70% of the time when compared to the baseline.\nAdditionally, visual question answering using a large language model suggested\nLego-generated concepts are better aligned with the text description of the\nconcept.",
            "author": [
                "Saman Motamed",
                "Danda Pani Paudel",
                "Luc Van Gool"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13833v1",
                "http://arxiv.org/pdf/2311.13833v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14747v1",
            "title": "HOMOE: A Memory-Based and Composition-Aware Framework for Zero-Shot\n  Learning with Hopfield Network and Soft Mixture of Experts",
            "updated": "2023-11-23T07:32:20Z",
            "published": "2023-11-23T07:32:20Z",
            "summary": "Compositional Zero-Shot Learning (CZSL) has emerged as an essential paradigm\nin machine learning, aiming to overcome the constraints of traditional\nzero-shot learning by incorporating compositional thinking into its\nmethodology. Conventional zero-shot learning has difficulty managing unfamiliar\ncombinations of seen and unseen classes because it depends on pre-defined class\nembeddings. In contrast, Compositional Zero-Shot Learning uses the inherent\nhierarchies and structural connections among classes, creating new class\nrepresentations by combining attributes, components, or other semantic\nelements. In our paper, we propose a novel framework that for the first time\ncombines the Modern Hopfield Network with a Mixture of Experts (HOMOE) to\nclassify the compositions of previously unseen objects. Specifically, the\nModern Hopfield Network creates a memory that stores label prototypes and\nidentifies relevant labels for a given input image. Following this, the Mixture\nof Expert models integrates the image with the fitting prototype to produce the\nfinal composition classification. Our approach achieves SOTA performance on\nseveral benchmarks, including MIT-States and UT-Zappos. We also examine how\neach component contributes to improved generalization.",
            "author": [
                "Do Huu Dat",
                "Po Yuan Mao",
                "Tien Hoang Nguyen",
                "Wray Buntine",
                "Mohammed Bennamoun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14747v1",
                "http://arxiv.org/pdf/2311.14747v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13827v1",
            "title": "Stability and L2-penalty in Model Averaging",
            "updated": "2023-11-23T07:11:15Z",
            "published": "2023-11-23T07:11:15Z",
            "summary": "Model averaging has received much attention in the past two decades, which\nintegrates available information by averaging over potential models. Although\nvarious model averaging methods have been developed, there are few literatures\non the theoretical properties of model averaging from the perspective of\nstability, and the majority of these methods constrain model weights to a\nsimplex. The aim of this paper is to introduce stability from statistical\nlearning theory into model averaging. Thus, we define the stability, asymptotic\nempirical risk minimizer, generalization, and consistency of model averaging\nand study the relationship among them. Our results indicate that stability can\nensure that model averaging has good generalization performance and consistency\nunder reasonable conditions, where consistency means model averaging estimator\ncan asymptotically minimize the mean squared prediction error. We also propose\na L2-penalty model averaging method without limiting model weights and prove\nthat it has stability and consistency. In order to reduce the impact of tuning\nparameter selection, we use 10-fold cross-validation to select a candidate set\nof tuning parameters and perform a weighted average of the estimators of model\nweights based on estimation errors. The Monte Carlo simulation and an\nillustrative application demonstrate the usefulness of the proposed method.",
            "author": [
                "Hengkun Zhu",
                "Guohua Zou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13827v1",
                "http://arxiv.org/pdf/2311.13827v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "68Q32, 62J05"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13824v1",
            "title": "Constraint-Guided Online Data Selection for Scalable Data-Driven Safety\n  Filters in Uncertain Robotic Systems",
            "updated": "2023-11-23T06:36:57Z",
            "published": "2023-11-23T06:36:57Z",
            "summary": "As the use of autonomous robotic systems expands in tasks that are complex\nand challenging to model, the demand for robust data-driven control methods\nthat can certify safety and stability in uncertain conditions is increasing.\nHowever, the practical implementation of these methods often faces scalability\nissues due to the growing amount of data points with system complexity, and a\nsignificant reliance on high-quality training data. In response to these\nchallenges, this study presents a scalable data-driven controller that\nefficiently identifies and infers from the most informative data points for\nimplementing data-driven safety filters. Our approach is grounded in the\nintegration of a model-based certificate function-based method and Gaussian\nProcess (GP) regression, reinforced by a novel online data selection algorithm\nthat reduces time complexity from quadratic to linear relative to dataset size.\nEmpirical evidence, gathered from successful real-world cart-pole swing-up\nexperiments and simulated locomotion of a five-link bipedal robot, demonstrates\nthe efficacy of our approach. Our findings reveal that our efficient online\ndata selection algorithm, which strategically selects key data points, enhances\nthe practicality and efficiency of data-driven certifying filters in complex\nrobotic systems, significantly mitigating scalability concerns inherent in\nnonparametric learning-based control methods.",
            "author": [
                "Jason J. Choi",
                "Fernando Casta\u00f1eda",
                "Wonsuhk Jung",
                "Bike Zhang",
                "Claire J. Tomlin",
                "Koushil Sreenath"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13824v1",
                "http://arxiv.org/pdf/2311.13824v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13821v1",
            "title": "HypUC: Hyperfine Uncertainty Calibration with Gradient-boosted\n  Corrections for Reliable Regression on Imbalanced Electrocardiograms",
            "updated": "2023-11-23T06:17:31Z",
            "published": "2023-11-23T06:17:31Z",
            "summary": "The automated analysis of medical time series, such as the electrocardiogram\n(ECG), electroencephalogram (EEG), pulse oximetry, etc, has the potential to\nserve as a valuable tool for diagnostic decisions, allowing for remote\nmonitoring of patients and more efficient use of expensive and time-consuming\nmedical procedures. Deep neural networks (DNNs) have been demonstrated to\nprocess such signals effectively. However, previous research has primarily\nfocused on classifying medical time series rather than attempting to regress\nthe continuous-valued physiological parameters central to diagnosis. One\nsignificant challenge in this regard is the imbalanced nature of the dataset,\nas a low prevalence of abnormal conditions can lead to heavily skewed data that\nresults in inaccurate predictions and a lack of certainty in such predictions\nwhen deployed. To address these challenges, we propose HypUC, a framework for\nimbalanced probabilistic regression in medical time series, making several\ncontributions. (i) We introduce a simple kernel density-based technique to\ntackle the imbalanced regression problem with medical time series. (ii)\nMoreover, we employ a probabilistic regression framework that allows\nuncertainty estimation for the predicted continuous values. (iii) We also\npresent a new approach to calibrate the predicted uncertainty further. (iv)\nFinally, we demonstrate a technique to use calibrated uncertainty estimates to\nimprove the predicted continuous value and show the efficacy of the calibrated\nuncertainty estimates to flag unreliable predictions. HypUC is evaluated on a\nlarge, diverse, real-world dataset of ECGs collected from millions of patients,\noutperforming several conventional baselines on various diagnostic tasks,\nsuggesting a potential use-case for the reliable clinical deployment of deep\nlearning models.",
            "author": [
                "Uddeshya Upadhyay",
                "Sairam Bade",
                "Arjun Puranik",
                "Shahir Asfahan",
                "Melwin Babu",
                "Francisco Lopez-Jimenez",
                "Samuel J. Asirvatham",
                "Ashim Prasad",
                "Ajit Rajasekharan",
                "Samir Awasthi",
                "Rakesh Barve"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13821v1",
                "http://arxiv.org/pdf/2311.13821v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CE",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13817v1",
            "title": "Molecular Identification and Peak Assignment: Leveraging Multi-Level\n  Multimodal Alignment on NMR",
            "updated": "2023-11-23T05:52:28Z",
            "published": "2023-11-23T05:52:28Z",
            "summary": "Nuclear magnetic resonance (NMR) spectroscopy plays an essential role across\nvarious scientific disciplines, providing valuable insights into molecular\ndynamics and interactions. Despite the promise of AI-enhanced NMR prediction\nmodels, challenges persist in the interpretation of spectra for tasks such as\nmolecular retrieval, isomer recognition, and peak assignment. In response, this\npaper introduces Multi-Level Multimodal Alignment with Knowledge-Guided\nInstance-Wise Discrimination (K-M3AID) to establish meaningful correspondences\nbetween two heterogeneous modalities: molecular graphs (structures) and NMR\nspectra. In particular, K-M3AID employs a dual-coordinated contrastive learning\narchitecture, and incorporates a graph-level alignment module, a node-level\nalignment module, and a communication channel. Notably, the framework\nintroduces knowledge-guided instance-wise discrimination into contrastive\nlearning within the node-level alignment module, significantly enhancing\naccuracy in cross-modal alignment. Additionally, K-M3AID showcases its\ncapability of meta-learning by demonstrating that skills acquired during\nnode-level alignment positively impact graph-level alignment. Empirical\nvalidation underscores K-M3AID's effectiveness in addressing multiple zero-shot\ntasks, offering a promising solution to bridge the gap between structural\ninformation and spectral data in complex NMR scenarios.",
            "author": [
                "Hao Xu",
                "Zhengyang Zhou",
                "Pengyu Hong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13817v1",
                "http://arxiv.org/pdf/2311.13817v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.chem-ph",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13816v1",
            "title": "Fairness-Aware Domain Generalization under Covariate and Dependence\n  Shifts",
            "updated": "2023-11-23T05:52:00Z",
            "published": "2023-11-23T05:52:00Z",
            "summary": "Achieving the generalization of an invariant classifier from source domains\nto shifted target domains while simultaneously considering model fairness is a\nsubstantial and complex challenge in machine learning. Existing domain\ngeneralization research typically attributes domain shifts to concept shift,\nwhich relates to alterations in class labels, and covariate shift, which\npertains to variations in data styles. In this paper, by introducing another\nform of distribution shift, known as dependence shift, which involves\nvariations in fair dependence patterns across domains, we propose a novel\ndomain generalization approach that addresses domain shifts by considering both\ncovariate and dependence shifts. We assert the existence of an underlying\ntransformation model can transform data from one domain to another. By\ngenerating data in synthetic domains through the model, a fairness-aware\ninvariant classifier is learned that enforces both model accuracy and fairness\nin unseen domains. Extensive empirical studies on four benchmark datasets\ndemonstrate that our approach surpasses state-of-the-art methods.",
            "author": [
                "Chen Zhao",
                "Kai Jiang",
                "Xintao Wu",
                "Haoliang Wang",
                "Latifur Khan",
                "Christan Grant",
                "Feng Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13816v1",
                "http://arxiv.org/pdf/2311.13816v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13812v1",
            "title": "Mechanical Characterization and Inverse Design of Stochastic Architected\n  Metamaterials Using Neural Operators",
            "updated": "2023-11-23T05:23:15Z",
            "published": "2023-11-23T05:23:15Z",
            "summary": "Machine learning (ML) is emerging as a transformative tool for the design of\narchitected materials, offering properties that far surpass those achievable\nthrough lab-based trial-and-error methods. However, a major challenge in\ncurrent inverse design strategies is their reliance on extensive computational\nand/or experimental datasets, which becomes particularly problematic for\ndesigning micro-scale stochastic architected materials that exhibit nonlinear\nmechanical behaviors. Here, we introduce a new end-to-end scientific ML\nframework, leveraging deep neural operators (DeepONet), to directly learn the\nrelationship between the complete microstructure and mechanical response of\narchitected metamaterials from sparse but high-quality in situ experimental\ndata. The approach facilitates the inverse design of structures tailored to\nspecific nonlinear mechanical behaviors. Results obtained from spinodal\nmicrostructures, printed using two-photon lithography, reveal that the\nprediction error for mechanical responses is within a range of 5 - 10%. Our\nwork underscores that by employing neural operators with advanced\nmicro-mechanics experimental techniques, the design of complex\nmicro-architected materials with desired properties becomes feasible, even in\nscenarios constrained by data scarcity. Our work marks a significant\nadvancement in the field of materials-by-design, potentially heralding a new\nera in the discovery and development of next-generation metamaterials with\nunparalleled mechanical characteristics derived directly from experimental\ninsights.",
            "author": [
                "Hanxun Jin",
                "Enrui Zhang",
                "Boyu Zhang",
                "Sridhar Krishnaswamy",
                "George Em Karniadakis",
                "Horacio D. Espinosa"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13812v1",
                "http://arxiv.org/pdf/2311.13812v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13811v2",
            "title": "Education distillation:getting student models to learn in shcools",
            "updated": "2023-11-27T02:32:54Z",
            "published": "2023-11-23T05:20:18Z",
            "summary": "Knowledge distillation is one of the methods for model compression, and\nexisting knowledge distillation techniques focus on how to improve the\ndistillation algorithm so as to enhance the distillation efficiency. This paper\nintroduces dynamic incremental learning into knowledge distillation and\nproposes a distillation strategy for education distillation. Specifically, it\nis proposed to take fragmented student models divided from the complete student\nmodel as lower-grade models. As the grade level rises, fragmented student\nmodels deepen in conjunction with designed teaching reference layers, while\nlearning and distilling from more teacher models. By moving from lower to\nhigher grades, fragmented student models were gradually integrated into a\ncomplete target student model, and the performance of the student models\ngradually improved from lower to higher grades of the stage. Education\ndistillation strategies combined with distillation algorithms outperform the\nresults of single distillation algorithms on the public dataset\nCIFAR100,Caltech256, Food-101 dataset.",
            "author": [
                "Ling Feng",
                "Danyang Li",
                "Tianhao Wu",
                "Xuliang Duan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13811v2",
                "http://arxiv.org/pdf/2311.13811v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13810v1",
            "title": "Bridging Classical and Quantum Machine Learning: Knowledge Transfer From\n  Classical to Quantum Neural Networks Using Knowledge Distillation",
            "updated": "2023-11-23T05:06:43Z",
            "published": "2023-11-23T05:06:43Z",
            "summary": "Very recently, studies have shown that quantum neural networks surpass\nclassical neural networks in tasks like image classification when a similar\nnumber of learnable parameters are used. However, the development and\noptimization of quantum models are currently hindered by issues such as qubit\ninstability and limited qubit availability, leading to error-prone systems with\nweak performance. In contrast, classical models can exhibit high-performance\nowing to substantial resource availability. As a result, more studies have been\nfocusing on hybrid classical-quantum integration. A line of research\nparticularly focuses on transfer learning through classical-quantum integration\nor quantum-quantum approaches. Unlike previous studies, this paper introduces a\nnew method to transfer knowledge from classical to quantum neural networks\nusing knowledge distillation, effectively bridging the gap between classical\nmachine learning and emergent quantum computing techniques. We adapt classical\nconvolutional neural network (CNN) architectures like LeNet and AlexNet to\nserve as teacher networks, facilitating the training of student quantum models\nby sending supervisory signals during backpropagation through KL-divergence.\nThe approach yields significant performance improvements for the quantum models\nby solely depending on classical CNNs, with quantum models achieving an average\naccuracy improvement of 0.80% on the MNIST dataset and 5.40% on the more\ncomplex Fashion MNIST dataset. Applying this technique eliminates the\ncumbersome training of huge quantum models for transfer learning in\nresource-constrained settings and enables re-using existing pre-trained\nclassical models to improve performance.Thus, this study paves the way for\nfuture research in quantum machine learning (QML) by positioning knowledge\ndistillation as a core technique for advancing QML applications.",
            "author": [
                "Mohammad Junayed Hasan",
                "M. R. C. Mahdy"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13810v1",
                "http://arxiv.org/pdf/2311.13810v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13808v1",
            "title": "Automated Model Training (AMT) GUI: An Opportunity for integrating AI in\n  the Laboratory Experiment",
            "updated": "2023-11-23T04:59:29Z",
            "published": "2023-11-23T04:59:29Z",
            "summary": "In the field of materials science, comprehending material properties is often\nhindered by the complexity of datasets originating from various sources. This\nstudy introduces the Automated Model Training (AMT) Graphical User Interface\n(GUI), specifically crafted for the use of researchers and scientists without a\nprogramming background to design the next set of experiments either in a\nchemistry lab or on the computer. The GUI integrates diverse machine learning\nmodels, such as XG-Boost, Random Forest, Support Vector Regression, Linear\nRegression, Generalized Additive Model (GAM), and Stack Regressors, offering a\nrobust toolkit for data analysis. It facilitates the exploration of complex\nrelationships, non-linear patterns, and predictive accuracy optimization. To\nfurther enhance its utility, the GUI integrates the Particle Swarm Optimization\n(PSO) technique, allowing researchers to systematically explore vast parameter\nspaces and identify optimal experimental conditions. This synergy between\nmachine learning and PSO empowers material scientists through a user-friendly\nplatform for data-driven discovery. The AMT GUI bridges the gap between\ntraditional experimentation and machine learning, enabling precise and\nefficient exploration of the materials research space.",
            "author": [
                "Mohamed Bilal Shakeel",
                "Samir Brahim Belhaouari",
                "Fedwa El Mellouhi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13808v1",
                "http://arxiv.org/pdf/2311.13808v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13806v1",
            "title": "AdaTyper: Adaptive Semantic Column Type Detection",
            "updated": "2023-11-23T04:42:27Z",
            "published": "2023-11-23T04:42:27Z",
            "summary": "Understanding the semantics of relational tables is instrumental for\nautomation in data exploration and preparation systems. A key source for\nunderstanding a table is the semantics of its columns. With the rise of deep\nlearning, learned table representations are now available, which can be applied\nfor semantic type detection and achieve good performance on benchmarks.\nNevertheless, we observe a gap between this performance and its applicability\nin practice. In this paper, we propose AdaTyper to address one of the most\ncritical deployment challenges: adaptation. AdaTyper uses weak-supervision to\nadapt a hybrid type predictor towards new semantic types and shifted data\ndistributions at inference time, using minimal human feedback. The hybrid type\npredictor of AdaTyper combines rule-based methods and a light machine learning\nmodel for semantic column type detection. We evaluate the adaptation\nperformance of AdaTyper on real-world database tables hand-annotated with\nsemantic column types through crowdsourcing and find that the f1-score improves\nfor new and existing types. AdaTyper approaches an average precision of 0.6\nafter only seeing 5 examples, significantly outperforming existing adaptation\nmethods based on human-provided regular expressions or dictionaries.",
            "author": [
                "Madelon Hulsebos",
                "Paul Groth",
                "\u00c7a\u011fatay Demiralp"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13806v1",
                "http://arxiv.org/pdf/2311.13806v1"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13800v1",
            "title": "Enhancing Intrusion Detection In Internet Of Vehicles Through Federated\n  Learning",
            "updated": "2023-11-23T04:04:20Z",
            "published": "2023-11-23T04:04:20Z",
            "summary": "Federated learning is a technique of decentralized machine learning. that\nallows multiple parties to collaborate and learn a shared model without sharing\ntheir raw data. Our paper proposes a federated learning framework for intrusion\ndetection in Internet of Vehicles (IOVs) using the CIC-IDS 2017 dataset. The\nproposed framework employs SMOTE for handling class imbalance, outlier\ndetection for identifying and removing abnormal observations, and\nhyperparameter tuning to optimize the model's performance. The authors\nevaluated the proposed framework using various performance metrics and\ndemonstrated its effectiveness in detecting intrusions with other datasets\n(KDD-Cup 99 and UNSW- NB-15) and conventional classifiers. Furthermore, the\nproposed framework can protect sensitive data while achieving high intrusion\ndetection performance.",
            "author": [
                "Abhishek Sebastian",
                "Pragna R",
                "Sudhakaran G",
                "Renjith P N",
                "Leela Karthikeyan H"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13800v1",
                "http://arxiv.org/pdf/2311.13800v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13793v1",
            "title": "Evidential Active Recognition: Intelligent and Prudent Open-World\n  Embodied Perception",
            "updated": "2023-11-23T03:51:46Z",
            "published": "2023-11-23T03:51:46Z",
            "summary": "Active recognition enables robots to intelligently explore novel\nobservations, thereby acquiring more information while circumventing undesired\nviewing conditions. Recent approaches favor learning policies from simulated or\ncollected data, wherein appropriate actions are more frequently selected when\nthe recognition is accurate. However, most recognition modules are developed\nunder the closed-world assumption, which makes them ill-equipped to handle\nunexpected inputs, such as the absence of the target object in the current\nobservation. To address this issue, we propose treating active recognition as a\nsequential evidence-gathering process, providing by-step uncertainty\nquantification and reliable prediction under the evidence combination theory.\nAdditionally, the reward function developed in this paper effectively\ncharacterizes the merit of actions when operating in open-world environments.\nTo evaluate the performance, we collect a dataset from an indoor simulator,\nencompassing various recognition challenges such as distance, occlusion levels,\nand visibility. Through a series of experiments on recognition and robustness\nanalysis, we demonstrate the necessity of introducing uncertainties to active\nrecognition and the superior performance of the proposed method.",
            "author": [
                "Lei Fan",
                "Mingfu Liang",
                "Yunxuan Li",
                "Gang Hua",
                "Ying Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13793v1",
                "http://arxiv.org/pdf/2311.13793v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13789v1",
            "title": "Knowledge Distillation Based Semantic Communications For Multiple Users",
            "updated": "2023-11-23T03:28:14Z",
            "published": "2023-11-23T03:28:14Z",
            "summary": "Deep learning (DL) has shown great potential in revolutionizing the\ntraditional communications system. Many applications in communications have\nadopted DL techniques due to their powerful representation ability. However,\nthe learning-based methods can be dependent on the training dataset and perform\nworse on unseen interference due to limited model generalizability and\ncomplexity. In this paper, we consider the semantic communication (SemCom)\nsystem with multiple users, where there is a limited number of training samples\nand unexpected interference. To improve the model generalization ability and\nreduce the model size, we propose a knowledge distillation (KD) based system\nwhere Transformer based encoder-decoder is implemented as the semantic\nencoder-decoder and fully connected neural networks are implemented as the\nchannel encoder-decoder. Specifically, four types of knowledge transfer and\nmodel compression are analyzed. Important system and model parameters are\nconsidered, including the level of noise and interference, the number of\ninterfering users and the size of the encoder and decoder. Numerical results\ndemonstrate that KD significantly improves the robustness and the\ngeneralization ability when applied to unexpected interference, and it reduces\nthe performance loss when compressing the model size.",
            "author": [
                "Chenguang Liu",
                "Yuxin Zhou",
                "Yunfei Chen",
                "Shuang-Hua Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13789v1",
                "http://arxiv.org/pdf/2311.13789v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13785v1",
            "title": "Federated Learning Assisted Distributed Energy Optimization",
            "updated": "2023-11-23T03:04:18Z",
            "published": "2023-11-23T03:04:18Z",
            "summary": "The increased penetration of distributed energy resources and the adoption of\nsensing and control technologies are driving the transition from our current\ncentralized electric grid to a distributed system controlled by multiple\nentities (agents). The Transactive Energy Community (TEC) serves as an\nestablished example of this transition. Distributed energy management\napproaches can effectively address the scalability, resilience, and privacy\nrequirements of the evolving grid. In this context, the accuracy of agents'\nestimations becomes crucial for the performance of distributed and multi-agent\ndecision-making paradigms. This paper specifically focuses on integrating\nFederated Learning (FL) with the multi-agent energy management procedure. FL is\nutilized to forecast agents' local energy generation and demand, aiming to\naccelerate the convergence of the distributed decision-making process. To\nenhance energy aggregation in TECs, we propose an FL-assisted distributed\nConsensus + Innovations approach. The results demonstrate that employing FL\nsignificantly reduces errors in predicting net power demand. The improved\nforecast accuracy, in turn, introduces less error in the distributed\noptimization process, thereby enhancing its convergence behavior.",
            "author": [
                "Yuhan Du",
                "Nuno Mendes",
                "Simin Rasouli",
                "Javad Mohammadi",
                "Pedro Moura"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13785v1",
                "http://arxiv.org/pdf/2311.13785v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13782v1",
            "title": "Scalable AI Generative Content for Vehicular Network Semantic\n  Communication",
            "updated": "2023-11-23T02:57:04Z",
            "published": "2023-11-23T02:57:04Z",
            "summary": "Perceiving vehicles in a driver's blind spot is vital for safe driving. The\ndetection of potentially dangerous vehicles in these blind spots can benefit\nfrom vehicular network semantic communication technology. However, efficient\nsemantic communication involves a trade-off between accuracy and delay,\nespecially in bandwidth-limited situations. This paper unveils a scalable\nArtificial Intelligence Generated Content (AIGC) system that leverages an\nencoder-decoder architecture. This system converts images into textual\nrepresentations and reconstructs them into quality-acceptable images,\noptimizing transmission for vehicular network semantic communication. Moreover,\nwhen bandwidth allows, auxiliary information is integrated. The encoder-decoder\naims to maintain semantic equivalence with the original images across various\ntasks. Then the proposed approach employs reinforcement learning to enhance the\nreliability of the generated contents. Experimental results suggest that the\nproposed method surpasses the baseline in perceiving vehicles in blind spots\nand effectively compresses communication data. While this method is\nspecifically designed for driving scenarios, this encoder-decoder architecture\nalso holds potential for wide use across various semantic communication\nscenarios.",
            "author": [
                "Hao Feng",
                "Yi Yang",
                "Zhu Han"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13782v1",
                "http://arxiv.org/pdf/2311.13782v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13778v1",
            "title": "Accurate Prediction of Experimental Band Gaps from Large Language\n  Model-Based Data Extraction",
            "updated": "2023-11-23T02:36:01Z",
            "published": "2023-11-23T02:36:01Z",
            "summary": "Machine learning is transforming materials discovery by providing rapid\npredictions of material properties, which enables large-scale screening for\ntarget materials. However, such models require training data. While automated\ndata extraction from scientific literature has potential, current\nauto-generated datasets often lack sufficient accuracy and critical structural\nand processing details of materials that influence the properties. Using band\ngap as an example, we demonstrate Large language model (LLM)-prompt-based\nextraction yields an order of magnitude lower error rate. Combined with\nadditional prompts to select a subset of experimentally measured properties\nfrom pure, single-crystalline bulk materials, this results in an automatically\nextracted dataset that's larger and more diverse than the largest existing\nhuman-curated database of experimental band gaps. Compared to the existing\nhuman-curated database, we show the model trained on our extracted database\nachieves a 19% reduction in the mean absolute error of predicted band gaps.\nFinally, we demonstrate that LLMs are able to train models predicting band gap\non the extracted data, achieving an automated pipeline of data extraction to\nmaterials property prediction.",
            "author": [
                "Samuel J. Yang",
                "Shutong Li",
                "Subhashini Venugopalan",
                "Vahe Tshitoyan",
                "Muratahan Aykol",
                "Amil Merchant",
                "Ekin Dogus Cubuk",
                "Gowoon Cheon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13778v1",
                "http://arxiv.org/pdf/2311.13778v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13777v1",
            "title": "GS-Pose: Category-Level Object Pose Estimation via Geometric and\n  Semantic Correspondence",
            "updated": "2023-11-23T02:35:38Z",
            "published": "2023-11-23T02:35:38Z",
            "summary": "Category-level pose estimation is a challenging task with many potential\napplications in computer vision and robotics. Recently, deep-learning-based\napproaches have made great progress, but are typically hindered by the need for\nlarge datasets of either pose-labelled real images or carefully tuned\nphotorealistic simulators. This can be avoided by using only geometry inputs\nsuch as depth images to reduce the domain-gap but these approaches suffer from\na lack of semantic information, which can be vital in the pose estimation\nproblem. To resolve this conflict, we propose to utilize both geometric and\nsemantic features obtained from a pre-trained foundation model.Our approach\nprojects 2D features from this foundation model into 3D for a single object\nmodel per category, and then performs matching against this for new single view\nobservations of unseen object instances with a trained matching network. This\nrequires significantly less data to train than prior methods since the semantic\nfeatures are robust to object texture and appearance. We demonstrate this with\na rich evaluation, showing improved performance over prior methods with a\nfraction of the data required.",
            "author": [
                "Pengyuan Wang",
                "Takuya Ikeda",
                "Robert Lee",
                "Koichi Nishiwaki"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13777v1",
                "http://arxiv.org/pdf/2311.13777v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.00039v1",
            "title": "Acoustic Cybersecurity: Exploiting Voice-Activated Systems",
            "updated": "2023-11-23T02:26:11Z",
            "published": "2023-11-23T02:26:11Z",
            "summary": "In this study, we investigate the emerging threat of inaudible acoustic\nattacks targeting digital voice assistants, a critical concern given their\nprojected prevalence to exceed the global population by 2024. Our research\nextends the feasibility of these attacks across various platforms like Amazon's\nAlexa, Android, iOS, and Cortana, revealing significant vulnerabilities in\nsmart devices. The twelve attack vectors identified include successful\nmanipulation of smart home devices and automotive systems, potential breaches\nin military communication, and challenges in critical infrastructure security.\nWe quantitatively show that attack success rates hover around 60%, with the\nability to activate devices remotely from over 100 feet away. Additionally,\nthese attacks threaten critical infrastructure, emphasizing the need for\nmultifaceted defensive strategies combining acoustic shielding, advanced signal\nprocessing, machine learning, and robust user authentication to mitigate these\nrisks.",
            "author": [
                "Forrest McKee",
                "David Noever"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00039v1",
                "http://arxiv.org/pdf/2312.00039v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13774v1",
            "title": "Learning Hierarchical Polynomials with Three-Layer Neural Networks",
            "updated": "2023-11-23T02:19:32Z",
            "published": "2023-11-23T02:19:32Z",
            "summary": "We study the problem of learning hierarchical polynomials over the standard\nGaussian distribution with three-layer neural networks. We specifically\nconsider target functions of the form $h = g \\circ p$ where $p : \\mathbb{R}^d\n\\rightarrow \\mathbb{R}$ is a degree $k$ polynomial and $g: \\mathbb{R}\n\\rightarrow \\mathbb{R}$ is a degree $q$ polynomial. This function class\ngeneralizes the single-index model, which corresponds to $k=1$, and is a\nnatural class of functions possessing an underlying hierarchical structure. Our\nmain result shows that for a large subclass of degree $k$ polynomials $p$, a\nthree-layer neural network trained via layerwise gradient descent on the square\nloss learns the target $h$ up to vanishing test error in\n$\\widetilde{\\mathcal{O}}(d^k)$ samples and polynomial time. This is a strict\nimprovement over kernel methods, which require $\\widetilde \\Theta(d^{kq})$\nsamples, as well as existing guarantees for two-layer networks, which require\nthe target function to be low-rank. Our result also generalizes prior works on\nthree-layer neural networks, which were restricted to the case of $p$ being a\nquadratic. When $p$ is indeed a quadratic, we achieve the\ninformation-theoretically optimal sample complexity\n$\\widetilde{\\mathcal{O}}(d^2)$, which is an improvement over prior\nwork~\\citep{nichani2023provable} requiring a sample size of\n$\\widetilde\\Theta(d^4)$. Our proof proceeds by showing that during the initial\nstage of training the network performs feature learning to recover the feature\n$p$ with $\\widetilde{\\mathcal{O}}(d^k)$ samples. This work demonstrates the\nability of three-layer neural networks to learn complex features and as a\nresult, learn a broad class of hierarchical functions.",
            "author": [
                "Zihao Wang",
                "Eshaan Nichani",
                "Jason D. Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13774v1",
                "http://arxiv.org/pdf/2311.13774v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13766v1",
            "title": "A Unified Framework for Fair Spectral Clustering With Effective Graph\n  Learning",
            "updated": "2023-11-23T01:43:00Z",
            "published": "2023-11-23T01:43:00Z",
            "summary": "We consider the problem of spectral clustering under group fairness\nconstraints, where samples from each sensitive group are approximately\nproportionally represented in each cluster. Traditional fair spectral\nclustering (FSC) methods consist of two consecutive stages, i.e., performing\nfair spectral embedding on a given graph and conducting $k$means to obtain\ndiscrete cluster labels. However, in practice, the graph is usually unknown,\nand we need to construct the underlying graph from potentially noisy data, the\nquality of which inevitably affects subsequent fair clustering performance.\nFurthermore, performing FSC through separate steps breaks the connections among\nthese steps, leading to suboptimal results. To this end, we first theoretically\nanalyze the effect of the constructed graph on FSC. Motivated by the analysis,\nwe propose a novel graph construction method with a node-adaptive graph filter\nto learn graphs from noisy data. Then, all independent stages of conventional\nFSC are integrated into a single objective function, forming an end-to-end\nframework that inputs raw data and outputs discrete cluster labels. An\nalgorithm is developed to jointly and alternately update the variables in each\nstage. Finally, we conduct extensive experiments on synthetic, benchmark, and\nreal data, which show that our model is superior to state-of-the-art fair\nclustering methods.",
            "author": [
                "Xiang Zhang",
                "Qiao Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13766v1",
                "http://arxiv.org/pdf/2311.13766v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13765v1",
            "title": "Learning Optimal and Fair Policies for Online Allocation of Scarce\n  Societal Resources from Data Collected in Deployment",
            "updated": "2023-11-23T01:40:41Z",
            "published": "2023-11-23T01:40:41Z",
            "summary": "We study the problem of allocating scarce societal resources of different\ntypes (e.g., permanent housing, deceased donor kidneys for transplantation,\nventilators) to heterogeneous allocatees on a waitlist (e.g., people\nexperiencing homelessness, individuals suffering from end-stage renal disease,\nCovid-19 patients) based on their observed covariates. We leverage\nadministrative data collected in deployment to design an online policy that\nmaximizes expected outcomes while satisfying budget constraints, in the long\nrun. Our proposed policy waitlists each individual for the resource maximizing\nthe difference between their estimated mean treatment outcome and the estimated\nresource dual-price or, roughly, the opportunity cost of using the resource.\nResources are then allocated as they arrive, in a first-come first-serve\nfashion. We demonstrate that our data-driven policy almost surely\nasymptotically achieves the expected outcome of the optimal out-of-sample\npolicy under mild technical assumptions. We extend our framework to incorporate\nvarious fairness constraints. We evaluate the performance of our approach on\nthe problem of designing policies for allocating scarce housing resources to\npeople experiencing homelessness in Los Angeles based on data from the homeless\nmanagement information system. In particular, we show that using our policies\nimproves rates of exit from homelessness by 1.9% and that policies that are\nfair in either allocation or outcomes by race come at a very low price of\nfairness.",
            "author": [
                "Bill Tang",
                "\u00c7a\u011f\u0131l Ko\u00e7yi\u011fit",
                "Eric Rice",
                "Phebe Vayanos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13765v1",
                "http://arxiv.org/pdf/2311.13765v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG",
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13763v1",
            "title": "Extraction of n = 0 pick-up by locked mode detectors based on neural\n  networks in J-TEXT",
            "updated": "2023-11-23T01:29:02Z",
            "published": "2023-11-23T01:29:02Z",
            "summary": "Measurement of locked mode (LM) is important for the physical research of\nMagnetohydrodynamic (MHD) instabilities and plasma disruption. The n = 0\npick-up need to be extracted and subtracted to calculate the amplitude and\nphase of the LM. A new method to extract this pick-up has been developed by\npredicting the n = 0 pick-up brn=0 by the LM detectors based on Neural Networks\n(NNs) in J-TEXT. An approach called Power Multiple Time Scale (PMTS) has been\ndeveloped with outstanding regressing effect in multiple frequency ranges.\nThree models have been progressed based on PMTS NNs. PMTS could fit the brn=0\non the LM detectors with little errors both in time domain and frequency\ndomain. The n>0 pick-up brn>0 generated by resonant magnetic perturbations\n(RMPs) can be obtained after subtracting the extracted brn=0. This new method\nuses only one LM instead of 4 LM detectors to extract brn=0. Therefore, the\ndistribution of the LM detectors can also be optimized based on this new\nmethod.",
            "author": [
                "Chengshuo Shen",
                "Jianchao Li",
                "Yonghua Ding",
                "Jiaolong Dong",
                "Nengchao Wang",
                "Dongliang. Han",
                "Feiyue Mao",
                "Da Li",
                "Zhipeng Chen",
                "Zhoujun Yang",
                "Zhongyong Chen",
                "Yuan Pan",
                "J-Text Team"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13763v1",
                "http://arxiv.org/pdf/2311.13763v1"
            ],
            "primary_category": "physics.plasm-ph",
            "category": [
                "physics.plasm-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13750v2",
            "title": "Towards Transferable Multi-modal Perception Representation Learning for\n  Autonomy: NeRF-Supervised Masked AutoEncoder",
            "updated": "2023-12-06T05:20:16Z",
            "published": "2023-11-23T00:53:11Z",
            "summary": "This work proposes a unified self-supervised pre-training framework for\ntransferable multi-modal perception representation learning via masked\nmulti-modal reconstruction in Neural Radiance Field (NeRF), namely\nNeRF-Supervised Masked AutoEncoder (NS-MAE). Specifically, conditioned on\ncertain view directions and locations, multi-modal embeddings extracted from\ncorrupted multi-modal input signals, i.e., Lidar point clouds and images, are\nrendered into projected multi-modal feature maps via neural rendering. Then,\noriginal multi-modal signals serve as reconstruction targets for the rendered\nmulti-modal feature maps to enable self-supervised representation learning.\nExtensive experiments show that the representation learned via NS-MAE shows\npromising transferability for diverse multi-modal and single-modal (camera-only\nand Lidar-only) perception models on diverse 3D perception downstream tasks (3D\nobject detection and BEV map segmentation) with diverse amounts of fine-tuning\nlabeled data. Moreover, we empirically find that NS-MAE enjoys the synergy of\nboth the mechanism of masked autoencoder and neural radiance field. We hope\nthis study can inspire exploration of more general multi-modal representation\nlearning for autonomous agents.",
            "author": [
                "Xiaohao Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13750v2",
                "http://arxiv.org/pdf/2311.13750v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13749v1",
            "title": "On Principles of Emergent Organization",
            "updated": "2023-11-23T00:39:36Z",
            "published": "2023-11-23T00:39:36Z",
            "summary": "After more than a century of concerted effort, physics still lacks basic\nprinciples of spontaneous self-organization. To appreciate why, we first state\nthe problem, outline historical approaches, and survey the present state of the\nphysics of self-organization. This frames the particular challenges arising\nfrom mathematical intractability and the resulting need for computational\napproaches, as well as those arising from a chronic failure to define\nstructure. Then, an overview of two modern mathematical formulations of\norganization -- intrinsic computation and evolution operators -- lays out a way\nto overcome these challenges. Together, the vantage point they afford shows how\nto account for the emergence of structured states via a statistical mechanics\nof systems arbitrarily far from equilibrium. The result is a constructive path\nforward to principles of organization that builds on mathematical\nidentification of structure.",
            "author": [
                "Adam T. Rupe",
                "James P. Crutchfield"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13749v1",
                "http://arxiv.org/pdf/2311.13749v1"
            ],
            "primary_category": "cond-mat.stat-mech",
            "category": [
                "cond-mat.stat-mech",
                "cs.LG",
                "nlin.CD",
                "nlin.PS",
                "physics.ao-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13745v1",
            "title": "Sample-Efficient Training for Diffusion",
            "updated": "2023-11-23T00:27:13Z",
            "published": "2023-11-23T00:27:13Z",
            "summary": "Score-based diffusion models have become the most popular approach to deep\ngenerative modeling of images, largely due to their empirical performance and\nreliability. Recently, a number of theoretical works \\citep{chen2022,\nChen2022ImprovedAO, Chenetal23flowode, benton2023linear} have shown that\ndiffusion models can efficiently sample, assuming $L^2$-accurate score\nestimates. The score-matching objective naturally approximates the true score\nin $L^2$, but the sample complexity of existing bounds depends\n\\emph{polynomially} on the data radius and desired Wasserstein accuracy. By\ncontrast, the time complexity of sampling is only logarithmic in these\nparameters. We show that estimating the score in $L^2$ \\emph{requires} this\npolynomial dependence, but that a number of samples that scales\npolylogarithmically in the Wasserstein accuracy actually do suffice for\nsampling. We show that with a polylogarithmic number of samples, the ERM of the\nscore-matching objective is $L^2$ accurate on all but a probability $\\delta$\nfraction of the true distribution, and that this weaker guarantee is sufficient\nfor efficient sampling.",
            "author": [
                "Shivam Gupta",
                "Aditya Parulekar",
                "Eric Price",
                "Zhiyang Xun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13745v1",
                "http://arxiv.org/pdf/2311.13745v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "cs.IT",
                "math.IT",
                "math.ST",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13744v1",
            "title": "Security and Privacy Challenges in Deep Learning Models",
            "updated": "2023-11-23T00:26:14Z",
            "published": "2023-11-23T00:26:14Z",
            "summary": "These days, deep learning models have achieved great success in multiple\nfields, from autonomous driving to medical diagnosis. These models have\nexpanded the abilities of artificial intelligence by offering great solutions\nto complex problems that were very difficult to solve earlier. In spite of\ntheir unseen success in various, it has been identified, through research\nconducted, that deep learning models can be subjected to various attacks that\ncompromise model security and data privacy of the Deep Neural Network models.\nDeep learning models can be subjected to various attacks at different stages of\ntheir lifecycle. During the testing phase, attackers can exploit\nvulnerabilities through different kinds of attacks such as Model Extraction\nAttacks, Model Inversion attacks, and Adversarial attacks. Model Extraction\nAttacks are aimed at reverse-engineering a trained deep learning model, with\nthe primary objective of revealing its architecture and parameters. Model\ninversion attacks aim to compromise the privacy of the data used in the Deep\nlearning model. These attacks are done to compromise the confidentiality of the\nmodel by going through the sensitive training data from the model's\npredictions. By analyzing the model's responses, attackers aim to reconstruct\nsensitive information. In this way, the model's data privacy is compromised.\nAdversarial attacks, mainly employed on computer vision models, are made to\ncorrupt models into confidently making incorrect predictions through malicious\ntesting data. These attacks subtly alter the input data, making it look normal\nbut misleading deep learning models to make incorrect decisions. Such attacks\ncan happen during both the model's evaluation and training phases. Data\nPoisoning Attacks add harmful data to the training set, disrupting the learning\nprocess and reducing the reliability of the deep learning mode.",
            "author": [
                "Gopichandh Golla"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13744v1",
                "http://arxiv.org/pdf/2311.13744v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13743v2",
            "title": "FinMem: A Performance-Enhanced LLM Trading Agent with Layered Memory and\n  Character Design",
            "updated": "2023-12-03T16:18:55Z",
            "published": "2023-11-23T00:24:40Z",
            "summary": "Recent advancements in Large Language Models (LLMs) have exhibited notable\nefficacy in question-answering (QA) tasks across diverse domains. Their prowess\nin integrating extensive web knowledge has fueled interest in developing\nLLM-based autonomous agents. While LLMs are efficient in decoding human\ninstructions and deriving solutions by holistically processing historical\ninputs, transitioning to purpose-driven agents requires a supplementary\nrational architecture to process multi-source information, establish reasoning\nchains, and prioritize critical tasks. Addressing this, we introduce\n\\textsc{FinMem}, a novel LLM-based agent framework devised for financial\ndecision-making. It encompasses three core modules: Profiling, to customize the\nagent's characteristics; Memory, with layered message processing, to aid the\nagent in assimilating hierarchical financial data; and Decision-making, to\nconvert insights gained from memories into investment decisions. Notably,\n\\textsc{FinMem}'s memory module aligns closely with the cognitive structure of\nhuman traders, offering robust interpretability and real-time tuning. Its\nadjustable cognitive span allows for the retention of critical information\nbeyond human perceptual limits, thereby enhancing trading outcomes. This\nframework enables the agent to self-evolve its professional knowledge, react\nagilely to new investment cues, and continuously refine trading decisions in\nthe volatile financial environment. We first compare \\textsc{FinMem} with\nvarious algorithmic agents on a scalable real-world financial dataset,\nunderscoring its leading trading performance in stocks. We then fine-tuned the\nagent's perceptual span and character setting to achieve a significantly\nenhanced trading performance. Collectively, \\textsc{FinMem} presents a\ncutting-edge LLM agent framework for automated trading, boosting cumulative\ninvestment returns.",
            "author": [
                "Yangyang Yu",
                "Haohang Li",
                "Zhi Chen",
                "Yuechen Jiang",
                "Yang Li",
                "Denghui Zhang",
                "Rong Liu",
                "Jordan W. Suchow",
                "Khaldoun Khashanah"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13743v2",
                "http://arxiv.org/pdf/2311.13743v2"
            ],
            "primary_category": "q-fin.CP",
            "category": [
                "q-fin.CP",
                "cs.AI",
                "cs.CE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13739v1",
            "title": "OASIS: Offsetting Active Reconstruction Attacks in Federated Learning",
            "updated": "2023-11-23T00:05:17Z",
            "published": "2023-11-23T00:05:17Z",
            "summary": "Federated Learning (FL) has garnered significant attention for its potential\nto protect user privacy while enhancing model training efficiency. However,\nrecent research has demonstrated that FL protocols can be easily compromised by\nactive reconstruction attacks executed by dishonest servers. These attacks\ninvolve the malicious modification of global model parameters, allowing the\nserver to obtain a verbatim copy of users' private data by inverting their\ngradient updates. Tackling this class of attack remains a crucial challenge due\nto the strong threat model. In this paper, we propose OASIS, a defense\nmechanism based on image augmentation that effectively counteracts active\nreconstruction attacks while preserving model performance. We first uncover the\ncore principle of gradient inversion that enables these attacks and\ntheoretically identify the main conditions by which the defense can be robust\nregardless of the attack strategies. We then construct OASIS with image\naugmentation showing that it can undermine the attack principle. Comprehensive\nevaluations demonstrate the efficacy of OASIS highlighting its feasibility as a\nsolution.",
            "author": [
                "Tre' R. Jeter",
                "Truc Nguyen",
                "Raed Alharbi",
                "My T. Thai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13739v1",
                "http://arxiv.org/pdf/2311.13739v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13735v1",
            "title": "Surpassing GPT-4 Medical Coding with a Two-Stage Approach",
            "updated": "2023-11-22T23:35:13Z",
            "published": "2023-11-22T23:35:13Z",
            "summary": "Recent advances in large language models (LLMs) show potential for clinical\napplications, such as clinical decision support and trial recommendations.\nHowever, the GPT-4 LLM predicts an excessive number of ICD codes for medical\ncoding tasks, leading to high recall but low precision. To tackle this\nchallenge, we introduce LLM-codex, a two-stage approach to predict ICD codes\nthat first generates evidence proposals using an LLM and then employs an\nLSTM-based verification stage. The LSTM learns from both the LLM's high recall\nand human expert's high precision, using a custom loss function. Our model is\nthe only approach that simultaneously achieves state-of-the-art results in\nmedical coding accuracy, accuracy on rare codes, and sentence-level evidence\nidentification to support coding decisions without training on human-annotated\nevidence according to experiments on the MIMIC dataset.",
            "author": [
                "Zhichao Yang",
                "Sanjit Singh Batra",
                "Joel Stremmel",
                "Eran Halperin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13735v1",
                "http://arxiv.org/pdf/2311.13735v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13724v1",
            "title": "Infectious disease surveillance needs for the United States: lessons\n  from COVID-19",
            "updated": "2023-11-22T22:43:35Z",
            "published": "2023-11-22T22:43:35Z",
            "summary": "The COVID-19 pandemic has highlighted the need to upgrade systems for\ninfectious disease surveillance and forecasting and modeling of the spread of\ninfection, both of which inform evidence-based public health guidance and\npolicies. Here, we discuss requirements for an effective surveillance system to\nsupport decision making during a pandemic, drawing on the lessons of COVID-19\nin the U.S., while looking to jurisdictions in the U.S. and beyond to learn\nlessons about the value of specific data types. In this report, we define the\nrange of decisions for which surveillance data are required, the data elements\nneeded to inform these decisions and to calibrate inputs and outputs of\ntransmission-dynamic models, and the types of data needed to inform decisions\nby state, territorial, local, and tribal health authorities. We define actions\nneeded to ensure that such data will be available and consider the contribution\nof such efforts to improving health equity.",
            "author": [
                "Marc Lipsitch",
                "Mary T. Bassett",
                "John S. Brownstein",
                "Paul Elliott",
                "David Eyre",
                "M. Kate Grabowski",
                "James A. Hay",
                "Michael Johansson",
                "Stephen M. Kissler",
                "Daniel B. Larremore",
                "Jennifer Layden",
                "Justin Lessler",
                "Ruth Lynfield",
                "Duncan MacCannell",
                "Lawrence C. Madoff",
                "C. Jessica E. Metcalf",
                "Lauren A. Meyers",
                "Sylvia K. Ofori",
                "Celia Quinn",
                "Ana I. Ramos Bento",
                "Nick Reich",
                "Steven Riley",
                "Roni Rosenfeld",
                "Matthew H. Samore",
                "Rangarajan Sampath",
                "Rachel B. Slayton",
                "David L. Swerdlow",
                "Shaun Truelove",
                "Jay K. Varma",
                "Yonatan H. Grad"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13724v1",
                "http://arxiv.org/pdf/2311.13724v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "physics.soc-ph",
                "q-bio.PE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.00038v1",
            "title": "A Physics-Constrained NeuralODE Approach for Robust Learning of Stiff\n  Chemical Kinetics",
            "updated": "2023-11-22T22:40:49Z",
            "published": "2023-11-22T22:40:49Z",
            "summary": "The high computational cost associated with solving for detailed chemistry\nposes a significant challenge for predictive computational fluid dynamics (CFD)\nsimulations of turbulent reacting flows. These models often require solving a\nsystem of coupled stiff ordinary differential equations (ODEs). While deep\nlearning techniques have been experimented with to develop faster surrogate\nmodels, they often fail to integrate reliably with CFD solvers. This\ninstability arises because deep learning methods optimize for training error\nwithout ensuring compatibility with ODE solvers, leading to accumulation of\nerrors over time. Recently, NeuralODE-based techniques have offered a promising\nsolution by effectively modeling chemical kinetics. In this study, we extend\nthe NeuralODE framework for stiff chemical kinetics by incorporating mass\nconservation constraints directly into the loss function during training. This\nensures that the total mass and the elemental mass are conserved, a critical\nrequirement for reliable downstream integration with CFD solvers. Our results\ndemonstrate that this enhancement not only improves the physical consistency\nwith respect to mass conservation criteria but also ensures better robustness\nand makes the training process more computationally efficient.",
            "author": [
                "Tadbhagya Kumar",
                "Anuj Kumar",
                "Pinaki Pal"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00038v1",
                "http://arxiv.org/pdf/2312.00038v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph",
                "cs.LG",
                "physics.chem-ph",
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13722v1",
            "title": "Deep Learning as a Method for Inversion of NMR Signals",
            "updated": "2023-11-22T22:31:54Z",
            "published": "2023-11-22T22:31:54Z",
            "summary": "The concept of deep learning is employed for the inversion of NMR signals and\nit is shown that NMR signal inversion can be considered as an image-to-image\nregression problem, which can be treated with a convolutional neural net. It is\nfurther outlined, that inversion through deep learning provides a clear\nefficiency and usability advantage compared to regularization techniques such\nas Tikhonov and modified total generalized variation (MTGV), because no\nhyperparemeter selection prior to reconstruction is necessary. The inversion\nnetwork is applied to simulated NMR signals and the results compared with\nTikhonov- and MTGV-regularization. The comparison shows that inversion via deep\nlearning is significantly faster than the latter regularization methods and\nalso outperforms both regularization techniques in nearly all instances.",
            "author": [
                "Julian B. B. Beckmann",
                "Mick D. Mantle",
                "Andrew J. Sederman",
                "Lynn F. Gladden"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13722v1",
                "http://arxiv.org/pdf/2311.13722v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13721v2",
            "title": "Nova$^+$: Generative Language Models for Binaries",
            "updated": "2023-11-27T18:22:55Z",
            "published": "2023-11-22T22:27:54Z",
            "summary": "Generative large language models (LLMs) pre-trained on code have shown\nimpressive effectiveness in code generation, program repair, and document\nanalysis. However, existing generative LLMs focus on source code and are not\nspecialized for binaries. There are three main challenges for LLMs to model and\nlearn binary code: hex-decimal values, complex global dependencies, and\ncompiler optimization levels. To bring the benefit of LLMs to the binary\ndomain, we develop Nova and Nova$^+$, which are LLMs pre-trained on binary\ncorpora. Nova is pre-trained with the standard language modeling task, showing\nsignificantly better capability on five benchmarks for three downstream tasks:\nbinary code similarity detection (BCSD), binary code translation (BCT), and\nbinary code recovery (BCR), over GPT-3.5 and other existing techniques. We\nbuild Nova$^+$ to further boost Nova using two new pre-training tasks, i.e.,\noptimization generation and optimization level prediction, which are designed\nto learn binary optimization and align equivalent binaries. Nova$^+$ shows\noverall the best performance for all three downstream tasks on five benchmarks,\ndemonstrating the contributions of the new pre-training tasks.",
            "author": [
                "Nan Jiang",
                "Chengxiao Wang",
                "Kevin Liu",
                "Xiangzhe Xu",
                "Lin Tan",
                "Xiangyu Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13721v2",
                "http://arxiv.org/pdf/2311.13721v2"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13719v1",
            "title": "Deep learning-based instance segmentation for the precise automated\n  quantification of digital breast cancer immunohistochemistry images",
            "updated": "2023-11-22T22:23:47Z",
            "published": "2023-11-22T22:23:47Z",
            "summary": "The quantification of biomarkers on immunohistochemistry breast cancer images\nis essential for defining appropriate therapy for breast cancer patients, as\nwell as for extracting relevant information on disease prognosis. This is an\narduous and time-consuming task that may introduce a bias in the results due to\nintra- and inter-observer variability which could be alleviated by making use\nof automatic quantification tools. However, this is not a simple processing\ntask given the heterogeneity of breast tumors that results in non-uniformly\ndistributed tumor cells exhibiting different staining colors and intensity,\nsize, shape, and texture, of the nucleus, cytoplasm and membrane. In this\nresearch work, we demonstrate the feasibility of using a deep learning-based\ninstance segmentation architecture for the automatic quantification of both\nnuclear and membrane biomarkers applied to IHC-stained slides. We have solved\nthe cumbersome task of training set generation with the design and\nimplementation of a web platform, which has served as a hub for communication\nand feedback between researchers and pathologists as well as a system for the\nvalidation of the automatic image processing models. Through this tool, we have\ncollected annotations over samples of HE, ER and Ki-67 (nuclear biomarkers) and\nHER2 (membrane biomarker) IHC-stained images. Using the same deep learning\nnetwork architecture, we have trained two models, so-called nuclei- and\nmembrane-aware segmentation models, which, once successfully validated, have\nrevealed to be a promising method to segment nuclei instances in IHC-stained\nimages. The quantification method proposed in this work has been integrated\ninto the developed web platform and is currently being used as a\ndecision-support tool by pathologists.",
            "author": [
                "Blanca Maria Priego-Torresa",
                "Barbara Lobato-Delgado",
                "Lidia Atienza-Cuevas",
                "Daniel Sanchez-Morillo"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.eswa.2021.116471",
                "http://arxiv.org/abs/2311.13719v1",
                "http://arxiv.org/pdf/2311.13719v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.AI",
                "cs.CV",
                "J.6; I.4"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13718v1",
            "title": "A Unified Approach to Count-Based Weakly-Supervised Learning",
            "updated": "2023-11-22T22:23:34Z",
            "published": "2023-11-22T22:23:34Z",
            "summary": "High-quality labels are often very scarce, whereas unlabeled data with\ninferred weak labels occurs more naturally. In many cases, these weak labels\ndictate the frequency of each respective class over a set of instances. In this\npaper, we develop a unified approach to learning from such weakly-labeled data,\nwhich we call count-based weakly-supervised learning. At the heart of our\napproach is the ability to compute the probability of exactly k out of n\noutputs being set to true. This computation is differentiable, exact, and\nefficient. Building upon the previous computation, we derive a count loss\npenalizing the model for deviations in its distribution from an arithmetic\nconstraint defined over label counts. We evaluate our approach on three common\nweakly-supervised learning paradigms and observe that our proposed approach\nachieves state-of-the-art or highly competitive results across all three of the\nparadigms.",
            "author": [
                "Vinay Shukla",
                "Zhe Zeng",
                "Kareem Ahmed",
                "Guy Van den Broeck"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13718v1",
                "http://arxiv.org/pdf/2311.13718v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13716v1",
            "title": "DiverseNet: Decision Diversified Semi-supervised Semantic Segmentation\n  Networks for Remote Sensing Imagery",
            "updated": "2023-11-22T22:20:10Z",
            "published": "2023-11-22T22:20:10Z",
            "summary": "Semi-supervised learning is designed to help reduce the cost of the manual\nlabelling process by exploiting the use of useful features from a large\nquantity of unlabelled data during training. Since pixel-level manual labelling\nin large-scale remote sensing imagery is expensive, semi-supervised learning\nbecomes an appropriate solution to this. However, most of the existing\nsemi-supervised learning methods still lack efficient perturbation methods to\npromote diversity of features and the precision of pseudo labels during\ntraining. In order to fill this gap, we propose DiverseNet architectures which\nexplore multi-head and multi-model semi-supervised learning algorithms by\nsimultaneously promoting precision and diversity during training. The two\nproposed methods of DiverseNet, namely the DiverseHead and DiverseModel,\nachieve the highest semantic segmentation performance in four widely utilised\nremote sensing imagery data sets compared to state-of-the-art semi-supervised\nlearning methods. Meanwhile, the proposed DiverseHead architecture is\nrelatively lightweight in terms of parameter space compared to the\nstate-of-the-art methods whilst reaching high-performance results for all the\ntested data sets.",
            "author": [
                "Wanli Ma",
                "Oktay Karakus",
                "Paul L. Rosin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13716v1",
                "http://arxiv.org/pdf/2311.13716v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13714v1",
            "title": "Learning Safe Control for Multi-Robot Systems: Methods, Verification,\n  and Open Challenges",
            "updated": "2023-11-22T22:19:44Z",
            "published": "2023-11-22T22:19:44Z",
            "summary": "In this survey, we review the recent advances in control design methods for\nrobotic multi-agent systems (MAS), focussing on learning-based methods with\nsafety considerations. We start by reviewing various notions of safety and\nliveness properties, and modeling frameworks used for problem formulation of\nMAS. Then we provide a comprehensive review of learning-based methods for safe\ncontrol design for multi-robot systems. We start with various types of\nshielding-based methods, such as safety certificates, predictive filters, and\nreachability tools. Then, we review the current state of control barrier\ncertificate learning in both a centralized and distributed manner, followed by\na comprehensive review of multi-agent reinforcement learning with a particular\nfocus on safety. Next, we discuss the state-of-the-art verification tools for\nthe correctness of learning-based methods. Based on the capabilities and the\nlimitations of the state of the art methods in learning and verification for\nMAS, we identify various broad themes for open challenges: how to design\nmethods that can achieve good performance along with safety guarantees; how to\ndecompose single-agent based centralized methods for MAS; how to account for\ncommunication-related practical issues; and how to assess transfer of\ntheoretical guarantees to practice.",
            "author": [
                "Kunal Garg",
                "Songyuan Zhang",
                "Oswin So",
                "Charles Dawson",
                "Chuchu Fan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13714v1",
                "http://arxiv.org/pdf/2311.13714v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.MA",
                "cs.SY",
                "eess.SY",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13713v1",
            "title": "A Somewhat Robust Image Watermark against Diffusion-based Editing Models",
            "updated": "2023-11-22T22:18:42Z",
            "published": "2023-11-22T22:18:42Z",
            "summary": "Recently, diffusion models (DMs) have become the state-of-the-art method for\nimage synthesis. Editing models based on DMs, known for their high fidelity and\nprecision, have inadvertently introduced new challenges related to image\ncopyright infringement and malicious editing. Our work is the first to\nformalize and address this issue. After assessing and attempting to enhance\ntraditional image watermarking techniques, we recognize their limitations in\nthis emerging context. In response, we develop a novel technique, RIW (Robust\nInvisible Watermarking), to embed invisible watermarks leveraging adversarial\nexample techniques. Our technique ensures a high extraction accuracy of $96\\%$\nfor the invisible watermark after editing, compared to the $0\\%$ offered by\nconventional methods. We provide access to our code at\nhttps://github.com/BennyTMT/RIW.",
            "author": [
                "Mingtian Tan",
                "Tianhao Wang",
                "Somesh Jha"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13713v1",
                "http://arxiv.org/pdf/2311.13713v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13712v1",
            "title": "Data Acquisition: A New Frontier in Data-centric AI",
            "updated": "2023-11-22T22:15:17Z",
            "published": "2023-11-22T22:15:17Z",
            "summary": "As Machine Learning (ML) systems continue to grow, the demand for relevant\nand comprehensive datasets becomes imperative. There is limited study on the\nchallenges of data acquisition due to ad-hoc processes and lack of consistent\nmethodologies. We first present an investigation of current data marketplaces,\nrevealing lack of platforms offering detailed information about datasets,\ntransparent pricing, standardized data formats. With the objective of inciting\nparticipation from the data-centric AI community, we then introduce the DAM\nchallenge, a benchmark to model the interaction between the data providers and\nacquirers. The benchmark was released as a part of DataPerf. Our evaluation of\nthe submitted strategies underlines the need for effective data acquisition\nstrategies in ML.",
            "author": [
                "Lingjiao Chen",
                "Bilge Acun",
                "Newsha Ardalani",
                "Yifan Sun",
                "Feiyang Kang",
                "Hanrui Lyu",
                "Yongchan Kwon",
                "Ruoxi Jia",
                "Carole-Jean Wu",
                "Matei Zaharia",
                "James Zou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13712v1",
                "http://arxiv.org/pdf/2311.13712v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13707v1",
            "title": "Bayes-xG: Player and Position Correction on Expected Goals (xG) using\n  Bayesian Hierarchical Approach",
            "updated": "2023-11-22T21:54:02Z",
            "published": "2023-11-22T21:54:02Z",
            "summary": "This study employs Bayesian methodologies to explore the influence of player\nor positional factors in predicting the probability of a shot resulting in a\ngoal, measured by the expected goals (xG) metric. Utilising publicly available\ndata from StatsBomb, Bayesian hierarchical logistic regressions are\nconstructed, analysing approximately 10,000 shots from the English Premier\nLeague to ascertain whether positional or player-level effects impact xG. The\nfindings reveal positional effects in a basic model that includes only distance\nto goal and shot angle as predictors, highlighting that strikers and attacking\nmidfielders exhibit a higher likelihood of scoring. However, these effects\ndiminish when more informative predictors are introduced. Nevertheless, even\nwith additional predictors, player-level effects persist, indicating that\ncertain players possess notable positive or negative xG adjustments,\ninfluencing their likelihood of scoring a given chance. The study extends its\nanalysis to data from Spain's La Liga and Germany's Bundesliga, yielding\ncomparable results. Additionally, the paper assesses the impact of prior\ndistribution choices on outcomes, concluding that the priors employed in the\nmodels provide sound results but could be refined to enhance sampling\nefficiency for constructing more complex and extensive models feasibly.",
            "author": [
                "Alexander Scholtes",
                "Oktay Karaku\u015f"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13707v1",
                "http://arxiv.org/pdf/2311.13707v1"
            ],
            "primary_category": "stat.AP",
            "category": [
                "stat.AP",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13702v2",
            "title": "Efficient quantum loading of probability distributions through Feynman\n  propagators",
            "updated": "2023-11-28T21:38:38Z",
            "published": "2023-11-22T21:41:58Z",
            "summary": "We present quantum algorithms for the loading of probability distributions\nusing Hamiltonian simulation for one dimensional Hamiltonians of the form\n${\\hat H}= \\Delta + V(x) \\mathbb{I}$. We consider the potentials $V(x)$ for\nwhich the Feynman propagator is known to have an analytically closed form and\nutilize these Hamiltonians to load probability distributions including the\nnormal, Laplace and Maxwell-Boltzmann into quantum states. We also propose a\nvariational method for probability distribution loading based on constructing a\ncoarse approximation to the distribution in the form of a `ladder state' and\nthen projecting onto the ground state of a Hamiltonian chosen to have the\ndesired probability distribution as ground state. These methods extend the\nsuite of techniques available for the loading of probability distributions, and\nare more efficient than general purpose data loading methods used in quantum\nmachine learning.",
            "author": [
                "Elie Alhajjar",
                "Jesse Geneson",
                "Anupam Prakash",
                "Nicolas Robles"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13702v2",
                "http://arxiv.org/pdf/2311.13702v2"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13695v1",
            "title": "BackboneLearn: A Library for Scaling Mixed-Integer Optimization-Based\n  Machine Learning",
            "updated": "2023-11-22T21:07:45Z",
            "published": "2023-11-22T21:07:45Z",
            "summary": "We present BackboneLearn: an open-source software package and framework for\nscaling mixed-integer optimization (MIO) problems with indicator variables to\nhigh-dimensional problems. This optimization paradigm can naturally be used to\nformulate fundamental problems in interpretable supervised learning (e.g.,\nsparse regression and decision trees), in unsupervised learning (e.g.,\nclustering), and beyond; BackboneLearn solves the aforementioned problems\nfaster than exact methods and with higher accuracy than commonly used\nheuristics. The package is built in Python and is user-friendly and easily\nextensible: users can directly implement a backbone algorithm for their MIO\nproblem at hand. The source code of BackboneLearn is available on GitHub (link:\nhttps://github.com/chziakas/backbone_learn).",
            "author": [
                "Vassilis Digalakis Jr",
                "Christos Ziakas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13695v1",
                "http://arxiv.org/pdf/2311.13695v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13693v1",
            "title": "Scalable CP Decomposition for Tensor Learning using GPU Tensor Cores",
            "updated": "2023-11-22T21:04:59Z",
            "published": "2023-11-22T21:04:59Z",
            "summary": "CP decomposition is a powerful tool for data science, especially gene\nanalysis, deep learning, and quantum computation. However, the application of\ntensor decomposition is largely hindered by the exponential increment of the\ncomputational complexity and storage consumption with the size of tensors.\nWhile the data in our real world is usually presented as trillion- or even\nexascale-scale tensors, existing work can only support billion-scale scale\ntensors. In our work, we propose the Exascale-Tensor to mitigate the\nsignificant gap. Specifically, we propose a compression-based tensor\ndecomposition framework, namely the exascale-tensor, to support exascale tensor\ndecomposition. Then, we carefully analyze the inherent parallelism and propose\na bag of strategies to improve computational efficiency. Last, we conduct\nexperiments to decompose tensors ranging from million-scale to trillion-scale\nfor evaluation. Compared to the baselines, the exascale-tensor supports 8,000x\nlarger tensors and a speedup up to 6.95x. We also apply our method to two\nreal-world applications, including gene analysis and tensor layer neural\nnetworks, of which the numeric results demonstrate the scalability and\neffectiveness of our method.",
            "author": [
                "Zeliang Zhang",
                "Zhuo Liu",
                "Susan Liang",
                "Zhiyuan Wang",
                "Yifan Zhu",
                "Chen Ding",
                "Chenliang Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13693v1",
                "http://arxiv.org/pdf/2311.13693v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13692v1",
            "title": "Molly: A Verified Compiler for Cryptoprotocol Roles",
            "updated": "2023-11-22T21:04:07Z",
            "published": "2023-11-22T21:04:07Z",
            "summary": "Molly is a program that compiles cryptographic protocol roles written in a\nhigh-level notation into straight-line programs in an intermediate-level\nimperative language, suitable for implementation in a conventional programming\nlanguage. We define a denotational semantics for protocol roles based on an\naxiomatization of the runtime. A notable feature of our approach is that we\nassume that encryption is randomized. Thus, at the runtime level we treat\nencryption as a relation rather than a function. Molly is written in Coq, and\ngenerates a machine-checked proof that the procedure it constructs is correct\nwith respect to the runtime semantics. Using Coq's extraction mechanism, one\ncan build an efficient functional program for compilation.",
            "author": [
                "Daniel J. Dougherty",
                "Joshua D. Guttman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13692v1",
                "http://arxiv.org/pdf/2311.13692v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13691v1",
            "title": "Next-Generation Earth System Models: Towards Reliable Hybrid Models for\n  Weather and Climate Applications",
            "updated": "2023-11-22T21:00:26Z",
            "published": "2023-11-22T21:00:26Z",
            "summary": "We review how machine learning has transformed our ability to model the Earth\nsystem, and how we expect recent breakthroughs to benefit end-users in\nSwitzerland in the near future.",
            "author": [
                "Tom Beucler",
                "Erwan Koch",
                "Sven Kotlarski",
                "David Leutwyler",
                "Adrien Michel",
                "Jonathan Koh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13691v1",
                "http://arxiv.org/pdf/2311.13691v1"
            ],
            "primary_category": "physics.ao-ph",
            "category": [
                "physics.ao-ph",
                "cs.AI",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13688v1",
            "title": "Masked Conditional Diffusion Models for Image Analysis with Application\n  to Radiographic Diagnosis of Infant Abuse",
            "updated": "2023-11-22T20:50:56Z",
            "published": "2023-11-22T20:50:56Z",
            "summary": "The classic metaphyseal lesion (CML) is a distinct injury that is highly\nspecific for infant abuse. It commonly occurs in the distal tibia. To aid\nradiologists detect these subtle fractures, we need to develop a model that can\nflag abnormal distal tibial radiographs (i.e. those with CMLs). Unfortunately,\nthe development of such a model requires a large and diverse training database,\nwhich is often not available. To address this limitation, we propose a novel\ngenerative model for data augmentation. Unlike previous models that fail to\ngenerate data that span the diverse radiographic appearance of the distal\ntibial CML, our proposed masked conditional diffusion model (MaC-DM) not only\ngenerates realistic-appearing and wide-ranging synthetic images of the distal\ntibial radiographs with and without CMLs, it also generates their associated\nsegmentation labels. To achieve these tasks, MaC-DM combines the weighted\nsegmentation masks of the tibias and the CML fracture sites as additional\nconditions for classifier guidance. The augmented images from our model\nimproved the performances of ResNet-34 in classifying normal radiographs and\nthose with CMLs. Further, the augmented images and their associated\nsegmentation masks enhanced the performance of the U-Net in labeling areas of\nthe CMLs on distal tibial radiographs.",
            "author": [
                "Shaoju Wu",
                "Sila Kurugol",
                "Andy Tsai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13688v1",
                "http://arxiv.org/pdf/2311.13688v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13687v1",
            "title": "Beat-Aligned Spectrogram-to-Sequence Generation of Rhythm-Game Charts",
            "updated": "2023-11-22T20:47:52Z",
            "published": "2023-11-22T20:47:52Z",
            "summary": "In the heart of \"rhythm games\" - games where players must perform actions in\nsync with a piece of music - are \"charts\", the directives to be given to\nplayers. We newly formulate chart generation as a sequence generation task and\ntrain a Transformer using a large dataset. We also introduce tempo-informed\npreprocessing and training procedures, some of which are suggested to be\nintegral for a successful training. Our model is found to outperform the\nbaselines on a large dataset, and is also found to benefit from pretraining and\nfinetuning.",
            "author": [
                "Jayeon Yi",
                "Sungho Lee",
                "Kyogu Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13687v1",
                "http://arxiv.org/pdf/2311.13687v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.MM",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13686v1",
            "title": "Private Inference in Quantized Models",
            "updated": "2023-11-22T20:41:24Z",
            "published": "2023-11-22T20:41:24Z",
            "summary": "A typical setup in many machine learning scenarios involves a server that\nholds a model and a user that possesses data, and the challenge is to perform\ninference while safeguarding the privacy of both parties. Private Inference has\nbeen extensively explored in recent years, mainly from a cryptographic\nstandpoint via techniques like homomorphic encryption and multiparty\ncomputation. These approaches often come with high computational overhead and\nmay degrade the accuracy of the model. In our work, we take a different\napproach inspired by the Private Information Retrieval literature. We view\nprivate inference as the task of retrieving inner products of parameter vectors\nwith the data, a fundamental operation in many machine learning models. We\nintroduce schemes that enable such retrieval of inner products for models with\nquantized (i.e., restricted to a finite set) weights; such models are\nextensively used in practice due to a wide range of benefits. In addition, our\nschemes uncover a fundamental tradeoff between user and server privacy. Our\ninformation-theoretic approach is applicable to a wide range of problems and\nrobust in privacy guarantees for both the user and the server.",
            "author": [
                "Zirui Deng",
                "Vinayak Ramkumar",
                "Rawad Bitar",
                "Netanel Raviv"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13686v1",
                "http://arxiv.org/pdf/2311.13686v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13681v1",
            "title": "Compact 3D Gaussian Representation for Radiance Field",
            "updated": "2023-11-22T20:31:16Z",
            "published": "2023-11-22T20:31:16Z",
            "summary": "Neural Radiance Fields (NeRFs) have demonstrated remarkable potential in\ncapturing complex 3D scenes with high fidelity. However, one persistent\nchallenge that hinders the widespread adoption of NeRFs is the computational\nbottleneck due to the volumetric rendering. On the other hand, 3D Gaussian\nsplatting (3DGS) has recently emerged as an alternative representation that\nleverages a 3D Gaussisan-based representation and adopts the rasterization\npipeline to render the images rather than volumetric rendering, achieving very\nfast rendering speed and promising image quality. However, a significant\ndrawback arises as 3DGS entails a substantial number of 3D Gaussians to\nmaintain the high fidelity of the rendered images, which requires a large\namount of memory and storage. To address this critical issue, we place a\nspecific emphasis on two key objectives: reducing the number of Gaussian points\nwithout sacrificing performance and compressing the Gaussian attributes, such\nas view-dependent color and covariance. To this end, we propose a learnable\nmask strategy that significantly reduces the number of Gaussians while\npreserving high performance. In addition, we propose a compact but effective\nrepresentation of view-dependent color by employing a grid-based neural field\nrather than relying on spherical harmonics. Finally, we learn codebooks to\ncompactly represent the geometric attributes of Gaussian by vector\nquantization. In our extensive experiments, we consistently show over\n10$\\times$ reduced storage and enhanced rendering speed, while maintaining the\nquality of the scene representation, compared to 3DGS. Our work provides a\ncomprehensive framework for 3D scene representation, achieving high\nperformance, fast training, compactness, and real-time rendering. Our project\npage is available at https://maincold2.github.io/c3dgs/.",
            "author": [
                "Joo Chan Lee",
                "Daniel Rho",
                "Xiangyu Sun",
                "Jong Hwan Ko",
                "Eunbyung Park"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13681v1",
                "http://arxiv.org/pdf/2311.13681v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13678v1",
            "title": "End-to-end Transfer Learning for Speaker-independent Cross-language\n  Speech Emotion Recognition",
            "updated": "2023-11-22T20:11:16Z",
            "published": "2023-11-22T20:11:16Z",
            "summary": "Data-driven models achieve successful results in Speech Emotion Recognition\n(SER). However, these models, which are based on general acoustic features or\nend-to-end approaches, show poor performance when the testing set has a\ndifferent language (i.e., the cross-language setting) than the training set or\nwhen they come from a different dataset (i.e., the cross-corpus setting). To\nalleviate this problem, this paper presents an end-to-end Deep Neural Network\n(DNN) model based on transfer learning for cross-language SER. We use the\nwav2vec 2.0 pre-trained model to transform audio time-domain waveforms from\ndifferent languages, different speakers and different recording conditions into\na feature space shared by multiple languages, thereby it reduces the language\nvariabilities in the speech features. Next, we propose a new Deep-Within-Class\nCo-variance Normalisation (Deep-WCCN) layer that can be inserted into the DNN\nmodel and it aims to reduce other variabilities including speaker variability,\nchannel variability and so on. The whole model is fine-tuned in an end-to-end\nmanner on a combined loss and is validated on datasets from three languages\n(i.e., English, German, Chinese). Experiment results show that our proposed\nmethod not only outperforms the baseline model that is based on common acoustic\nfeature sets for SER in the within-language setting, but also significantly\noutperforms the baseline model for cross-language setting. In addition, we also\nexperimentally validate the effectiveness of Deep-WCCN, which can further\nimprove the model performance. Finally, to comparing the results in the recent\nliteratures that use the same testing datasets, our proposed model shows\nsignificantly better performance than other state-of-the-art models in\ncross-language SER.",
            "author": [
                "Duowei Tang",
                "Peter Kuppens",
                "Luc Geurts",
                "Toon van Waterschoot"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13678v1",
                "http://arxiv.org/pdf/2311.13678v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13665v1",
            "title": "A Joint Gradient and Loss Based Clustered Federated Learning Design",
            "updated": "2023-11-22T19:39:37Z",
            "published": "2023-11-22T19:39:37Z",
            "summary": "In this paper, a novel clustered FL framework that enables distributed edge\ndevices with non-IID data to independently form several clusters in a\ndistributed manner and implement FL training within each cluster is proposed.\nIn particular, our designed clustered FL algorithm must overcome two challenges\nassociated with FL training. First, the server has limited FL training\ninformation (i.e., the parameter server can only obtain the FL model\ninformation of each device) and limited computational power for finding the\ndifferences among a large amount of devices. Second, each device does not have\nthe data information of other devices for device clustering and can only use\nglobal FL model parameters received from the server and its data information to\ndetermine its cluster identity, which will increase the difficulty of device\nclustering. To overcome these two challenges, we propose a joint gradient and\nloss based distributed clustering method in which each device determines its\ncluster identity considering the gradient similarity and training loss. The\nproposed clustering method not only considers how a local FL model of one\ndevice contributes to each cluster but also the direction of gradient descent\nthus improving clustering speed. By delegating clustering decisions to edge\ndevices, each device can fully leverage its private data information to\ndetermine its own cluster identity, thereby reducing clustering overhead and\nimproving overall clustering performance. Simulation results demonstrate that\nour proposed clustered FL algorithm can reduce clustering iterations by up to\n99% compared to the existing baseline.",
            "author": [
                "Licheng Lin",
                "Mingzhe Chen",
                "Zhaohui Yang",
                "Yusen Wu",
                "Yuchen Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13665v1",
                "http://arxiv.org/pdf/2311.13665v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13664v1",
            "title": "Sample as You Infer: Predictive Coding With Langevin Dynamics",
            "updated": "2023-11-22T19:36:47Z",
            "published": "2023-11-22T19:36:47Z",
            "summary": "We present a novel algorithm for parameter learning in generic deep\ngenerative models that builds upon the predictive coding (PC) framework of\ncomputational neuroscience. Our approach modifies the standard PC algorithm to\nbring performance on-par and exceeding that obtained from standard variational\nauto-encoder (VAE) training. By injecting Gaussian noise into the PC inference\nprocedure we re-envision it as an overdamped Langevin sampling, which\nfacilitates optimisation with respect to a tight evidence lower bound (ELBO).\nWe improve the resultant encoder-free training method by incorporating an\nencoder network to provide an amortised warm-start to our Langevin sampling and\ntest three different objectives for doing so. Finally, to increase robustness\nto the sampling step size and reduce sensitivity to curvature, we validate a\nlightweight and easily computable form of preconditioning, inspired by Riemann\nManifold Langevin and adaptive optimizers from the SGD literature. We compare\nagainst VAEs by training like-for-like generative models using our technique\nagainst those trained with standard reparameterisation-trick-based ELBOs. We\nobserve our method out-performs or matches performance across a number of\nmetrics, including sample quality, while converging in a fraction of the number\nof SGD training iterations.",
            "author": [
                "Umais Zahid",
                "Qinghai Guo",
                "Zafeirios Fountas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13664v1",
                "http://arxiv.org/pdf/2311.13664v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "cs.NE",
                "I.2.0; I.2.6; I.2.10; I.4.0; I.4.8"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13661v1",
            "title": "BenthIQ: a Transformer-Based Benthic Classification Model for Coral\n  Restoration",
            "updated": "2023-11-22T19:25:31Z",
            "published": "2023-11-22T19:25:31Z",
            "summary": "Coral reefs are vital for marine biodiversity, coastal protection, and\nsupporting human livelihoods globally. However, they are increasingly\nthreatened by mass bleaching events, pollution, and unsustainable practices\nwith the advent of climate change. Monitoring the health of these ecosystems is\ncrucial for effective restoration and management. Current methods for creating\nbenthic composition maps often compromise between spatial coverage and\nresolution. In this paper, we introduce BenthIQ, a multi-label semantic\nsegmentation network designed for high-precision classification of underwater\nsubstrates, including live coral, algae, rock, and sand. Although commonly\ndeployed CNNs are limited in learning long-range semantic information,\ntransformer-based models have recently achieved state-of-the-art performance in\nvision tasks such as object detection and image classification. We integrate\nthe hierarchical Swin Transformer as the backbone of a U-shaped encoder-decoder\narchitecture for local-global semantic feature learning. Using a real-world\ncase study in French Polynesia, we demonstrate that our approach outperforms\ntraditional CNN and attention-based models on pixel-wise classification of\nshallow reef imagery.",
            "author": [
                "Rupa Kurinchi-Vendhan",
                "Drew Gray",
                "Elijah Cole"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13661v1",
                "http://arxiv.org/pdf/2311.13661v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13657v1",
            "title": "Efficient Transformer Knowledge Distillation: A Performance Review",
            "updated": "2023-11-22T19:19:37Z",
            "published": "2023-11-22T19:19:37Z",
            "summary": "As pretrained transformer language models continue to achieve\nstate-of-the-art performance, the Natural Language Processing community has\npushed for advances in model compression and efficient attention mechanisms to\naddress high computational requirements and limited input sequence length.\nDespite these separate efforts, no investigation has been done into the\nintersection of these two fields. In this work, we provide an evaluation of\nmodel compression via knowledge distillation on efficient attention\ntransformers. We provide cost-performance trade-offs for the compression of\nstate-of-the-art efficient attention architectures and the gains made in\nperformance in comparison to their full attention counterparts. Furthermore, we\nintroduce a new long-context Named Entity Recognition dataset, GONERD, to train\nand test the performance of NER models on long sequences. We find that\ndistilled efficient attention transformers can preserve a significant amount of\noriginal model performance, preserving up to 98.6% across short-context tasks\n(GLUE, SQUAD, CoNLL-2003), up to 94.6% across long-context\nQuestion-and-Answering tasks (HotpotQA, TriviaQA), and up to 98.8% on\nlong-context Named Entity Recognition (GONERD), while decreasing inference\ntimes by up to 57.8%. We find that, for most models on most tasks, performing\nknowledge distillation is an effective method to yield high-performing\nefficient attention models with low costs.",
            "author": [
                "Nathan Brown",
                "Ashton Williamson",
                "Tahj Anderson",
                "Logan Lawrence"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13657v1",
                "http://arxiv.org/pdf/2311.13657v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13656v1",
            "title": "Panda or not Panda? Understanding Adversarial Attacks with Interactive\n  Visualization",
            "updated": "2023-11-22T19:14:25Z",
            "published": "2023-11-22T19:14:25Z",
            "summary": "Adversarial machine learning (AML) studies attacks that can fool machine\nlearning algorithms into generating incorrect outcomes as well as the defenses\nagainst worst-case attacks to strengthen model robustness. Specifically for\nimage classification, it is challenging to understand adversarial attacks due\nto their use of subtle perturbations that are not human-interpretable, as well\nas the variability of attack impacts influenced by diverse methodologies,\ninstance differences, and model architectures. Through a design study with AML\nlearners and teachers, we introduce AdvEx, a multi-level interactive\nvisualization system that comprehensively presents the properties and impacts\nof evasion attacks on different image classifiers for novice AML learners. We\nquantitatively and qualitatively assessed AdvEx in a two-part evaluation\nincluding user studies and expert interviews. Our results show that AdvEx is\nnot only highly effective as a visualization tool for understanding AML\nmechanisms, but also provides an engaging and enjoyable learning experience,\nthus demonstrating its overall benefits for AML learners.",
            "author": [
                "Yuzhe You",
                "Jarvis Tse",
                "Jian Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13656v1",
                "http://arxiv.org/pdf/2311.13656v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13655v1",
            "title": "GAN-Avatar: Controllable Personalized GAN-based Human Head Avatar",
            "updated": "2023-11-22T19:13:00Z",
            "published": "2023-11-22T19:13:00Z",
            "summary": "Digital humans and, especially, 3D facial avatars have raised a lot of\nattention in the past years, as they are the backbone of several applications\nlike immersive telepresence in AR or VR. Despite the progress, facial avatars\nreconstructed from commodity hardware are incomplete and miss out on parts of\nthe side and back of the head, severely limiting the usability of the avatar.\nThis limitation in prior work stems from their requirement of face tracking,\nwhich fails for profile and back views. To address this issue, we propose to\nlearn person-specific animatable avatars from images without assuming to have\naccess to precise facial expression tracking. At the core of our method, we\nleverage a 3D-aware generative model that is trained to reproduce the\ndistribution of facial expressions from the training data. To train this\nappearance model, we only assume to have a collection of 2D images with the\ncorresponding camera parameters. For controlling the model, we learn a mapping\nfrom 3DMM facial expression parameters to the latent space of the generative\nmodel. This mapping can be learned by sampling the latent space of the\nappearance model and reconstructing the facial parameters from a normalized\nfrontal view, where facial expression estimation performs well. With this\nscheme, we decouple 3D appearance reconstruction and animation control to\nachieve high fidelity in image synthesis. In a series of experiments, we\ncompare our proposed technique to state-of-the-art monocular methods and show\nsuperior quality while not requiring expression tracking of the training data.",
            "author": [
                "Berna Kabadayi",
                "Wojciech Zielonka",
                "Bharat Lal Bhatnagar",
                "Gerard Pons-Moll",
                "Justus Thies"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13655v1",
                "http://arxiv.org/pdf/2311.13655v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13648v1",
            "title": "Evaluating Pretrained models for Deployable Lifelong Learning",
            "updated": "2023-11-22T19:04:05Z",
            "published": "2023-11-22T19:04:05Z",
            "summary": "We create a novel benchmark for evaluating a Deployable Lifelong Learning\nsystem for Visual Reinforcement Learning (RL) that is pretrained on a curated\ndataset, and propose a novel Scalable Lifelong Learning system capable of\nretaining knowledge from the previously learnt RL tasks. Our benchmark measures\nthe efficacy of a deployable Lifelong Learning system that is evaluated on\nscalability, performance and resource utilization. Our proposed system, once\npretrained on the dataset, can be deployed to perform continual learning on\nunseen tasks. Our proposed method consists of a Few Shot Class Incremental\nLearning (FSCIL) based task-mapper and an encoder/backbone trained entirely\nusing the pretrain dataset. The policy parameters corresponding to the\nrecognized task are then loaded to perform the task. We show that this system\ncan be scaled to incorporate a large number of tasks due to the small memory\nfootprint and fewer computational resources. We perform experiments on our DeLL\n(Deployment for Lifelong Learning) benchmark on the Atari games to determine\nthe efficacy of the system.",
            "author": [
                "Kiran Lekkala",
                "Eshan Bhargava",
                "Laurent Itti"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13648v1",
                "http://arxiv.org/pdf/2311.13648v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13647v1",
            "title": "Language Model Inversion",
            "updated": "2023-11-22T19:04:04Z",
            "published": "2023-11-22T19:04:04Z",
            "summary": "Language models produce a distribution over the next token; can we use this\ninformation to recover the prompt tokens? We consider the problem of language\nmodel inversion and show that next-token probabilities contain a surprising\namount of information about the preceding text. Often we can recover the text\nin cases where it is hidden from the user, motivating a method for recovering\nunknown prompts given only the model's current distribution output. We consider\na variety of model access scenarios, and show how even without predictions for\nevery token in the vocabulary we can recover the probability vector through\nsearch. On Llama-2 7b, our inversion method reconstructs prompts with a BLEU of\n$59$ and token-level F1 of $78$ and recovers $27\\%$ of prompts exactly. Code\nfor reproducing all experiments is available at\nhttp://github.com/jxmorris12/vec2text.",
            "author": [
                "John X. Morris",
                "Wenting Zhao",
                "Justin T. Chiu",
                "Vitaly Shmatikov",
                "Alexander M. Rush"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13647v1",
                "http://arxiv.org/pdf/2311.13647v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13601v1",
            "title": "Visual In-Context Prompting",
            "updated": "2023-11-22T18:59:48Z",
            "published": "2023-11-22T18:59:48Z",
            "summary": "In-context prompting in large language models (LLMs) has become a prevalent\napproach to improve zero-shot capabilities, but this idea is less explored in\nthe vision domain. Existing visual prompting methods focus on referring\nsegmentation to segment the most relevant object, falling short of addressing\nmany generic vision tasks like open-set segmentation and detection. In this\npaper, we introduce a universal visual in-context prompting framework for both\ntasks. In particular, we build on top of an encoder-decoder architecture, and\ndevelop a versatile prompt encoder to support a variety of prompts like\nstrokes, boxes, and points. We further enhance it to take an arbitrary number\nof reference image segments as the context. Our extensive explorations show\nthat the proposed visual in-context prompting elicits extraordinary referring\nand generic segmentation capabilities to refer and detect, yielding competitive\nperformance to close-set in-domain datasets and showing promising results on\nmany open-set segmentation datasets. By joint training on COCO and SA-1B, our\nmodel achieves $57.7$ PQ on COCO and $23.2$ PQ on ADE20K. Code will be\navailable at https://github.com/UX-Decoder/DINOv.",
            "author": [
                "Feng Li",
                "Qing Jiang",
                "Hao Zhang",
                "Tianhe Ren",
                "Shilong Liu",
                "Xueyan Zou",
                "Huaizhe Xu",
                "Hongyang Li",
                "Chunyuan Li",
                "Jianwei Yang",
                "Lei Zhang",
                "Jianfeng Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13601v1",
                "http://arxiv.org/pdf/2311.13601v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13600v1",
            "title": "ZipLoRA: Any Subject in Any Style by Effectively Merging LoRAs",
            "updated": "2023-11-22T18:59:36Z",
            "published": "2023-11-22T18:59:36Z",
            "summary": "Methods for finetuning generative models for concept-driven personalization\ngenerally achieve strong results for subject-driven or style-driven generation.\nRecently, low-rank adaptations (LoRA) have been proposed as a\nparameter-efficient way of achieving concept-driven personalization. While\nrecent work explores the combination of separate LoRAs to achieve joint\ngeneration of learned styles and subjects, existing techniques do not reliably\naddress the problem; they often compromise either subject fidelity or style\nfidelity. We propose ZipLoRA, a method to cheaply and effectively merge\nindependently trained style and subject LoRAs in order to achieve generation of\nany user-provided subject in any user-provided style. Experiments on a wide\nrange of subject and style combinations show that ZipLoRA can generate\ncompelling results with meaningful improvements over baselines in subject and\nstyle fidelity while preserving the ability to recontextualize. Project page:\nhttps://ziplora.github.io",
            "author": [
                "Viraj Shah",
                "Nataniel Ruiz",
                "Forrester Cole",
                "Erika Lu",
                "Svetlana Lazebnik",
                "Yuanzhen Li",
                "Varun Jampani"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13600v1",
                "http://arxiv.org/pdf/2311.13600v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13595v1",
            "title": "Covariance alignment: from maximum likelihood estimation to\n  Gromov-Wasserstein",
            "updated": "2023-11-22T18:55:27Z",
            "published": "2023-11-22T18:55:27Z",
            "summary": "Feature alignment methods are used in many scientific disciplines for data\npooling, annotation, and comparison. As an instance of a permutation learning\nproblem, feature alignment presents significant statistical and computational\nchallenges. In this work, we propose the covariance alignment model to study\nand compare various alignment methods and establish a minimax lower bound for\ncovariance alignment that has a non-standard dimension scaling because of the\npresence of a nuisance parameter. This lower bound is in fact minimax optimal\nand is achieved by a natural quasi MLE. However, this estimator involves a\nsearch over all permutations which is computationally infeasible even when the\nproblem has moderate size. To overcome this limitation, we show that the\ncelebrated Gromov-Wasserstein algorithm from optimal transport which is more\namenable to fast implementation even on large-scale problems is also minimax\noptimal. These results give the first statistical justification for the\ndeployment of the Gromov-Wasserstein algorithm in practice.",
            "author": [
                "Yanjun Han",
                "Philippe Rigollet",
                "George Stepaniants"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13595v1",
                "http://arxiv.org/pdf/2311.13595v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "cs.LG",
                "stat.ME",
                "stat.ML",
                "stat.TH",
                "Primary 62C20, 90B80, 49Q22, secondary 62R07, 05C60",
                "G.3"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13594v1",
            "title": "Labeling Neural Representations with Inverse Recognition",
            "updated": "2023-11-22T18:55:25Z",
            "published": "2023-11-22T18:55:25Z",
            "summary": "Deep Neural Networks (DNNs) demonstrated remarkable capabilities in learning\ncomplex hierarchical data representations, but the nature of these\nrepresentations remains largely unknown. Existing global explainability\nmethods, such as Network Dissection, face limitations such as reliance on\nsegmentation masks, lack of statistical significance testing, and high\ncomputational demands. We propose Inverse Recognition (INVERT), a scalable\napproach for connecting learned representations with human-understandable\nconcepts by leveraging their capacity to discriminate between these concepts.\nIn contrast to prior work, INVERT is capable of handling diverse types of\nneurons, exhibits less computational complexity, and does not rely on the\navailability of segmentation masks. Moreover, INVERT provides an interpretable\nmetric assessing the alignment between the representation and its corresponding\nexplanation and delivering a measure of statistical significance, emphasizing\nits utility and credibility. We demonstrate the applicability of INVERT in\nvarious scenarios, including the identification of representations affected by\nspurious correlations, and the interpretation of the hierarchical structure of\ndecision-making within the models.",
            "author": [
                "Kirill Bykov",
                "Laura Kopf",
                "Shinichi Nakajima",
                "Marius Kloft",
                "Marina M. -C. H\u00f6hne"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13594v1",
                "http://arxiv.org/pdf/2311.13594v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13628v1",
            "title": "Prompt Risk Control: A Rigorous Framework for Responsible Deployment of\n  Large Language Models",
            "updated": "2023-11-22T18:50:47Z",
            "published": "2023-11-22T18:50:47Z",
            "summary": "The recent explosion in the capabilities of large language models has led to\na wave of interest in how best to prompt a model to perform a given task. While\nit may be tempting to simply choose a prompt based on average performance on a\nvalidation set, this can lead to a deployment where unexpectedly poor responses\nare generated, especially for the worst-off users. To mitigate this prospect,\nwe propose Prompt Risk Control, a lightweight framework for selecting a prompt\nbased on rigorous upper bounds on families of informative risk measures. We\noffer methods for producing bounds on a diverse set of metrics, including\nquantities that measure worst-case responses and disparities in generation\nquality across the population of users. In addition, we extend the underlying\nstatistical bounding techniques to accommodate the possibility of distribution\nshifts in deployment. Experiments on applications such as open-ended chat,\nmedical question summarization, and code generation highlight how such a\nframework can foster responsible deployment by reducing the risk of the worst\noutcomes.",
            "author": [
                "Thomas P. Zollo",
                "Todd Morrill",
                "Zhun Deng",
                "Jake C. Snell",
                "Toniann Pitassi",
                "Richard Zemel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13628v1",
                "http://arxiv.org/pdf/2311.13628v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13589v1",
            "title": "Risk-sensitive Markov Decision Process and Learning under General\n  Utility Functions",
            "updated": "2023-11-22T18:50:06Z",
            "published": "2023-11-22T18:50:06Z",
            "summary": "Reinforcement Learning (RL) has gained substantial attention across diverse\napplication domains and theoretical investigations. Existing literature on RL\ntheory largely focuses on risk-neutral settings where the decision-maker learns\nto maximize the expected cumulative reward. However, in practical scenarios\nsuch as portfolio management and e-commerce recommendations, decision-makers\noften persist in heterogeneous risk preferences subject to outcome\nuncertainties, which can not be well-captured by the risk-neural framework.\nIncorporating these preferences can be approached through utility theory, yet\nthe development of risk-sensitive RL under general utility functions remains an\nopen question for theoretical exploration.\n  In this paper, we consider a scenario where the decision-maker seeks to\noptimize a general utility function of the cumulative reward in the framework\nof a Markov decision process (MDP). To facilitate the Dynamic Programming\nPrinciple and Bellman equation, we enlarge the state space with an additional\ndimension that accounts for the cumulative reward. We propose a discretized\napproximation scheme to the MDP under enlarged state space, which is tractable\nand key for algorithmic design. We then propose a modified value iteration\nalgorithm that employs an epsilon-covering over the space of cumulative reward.\nWhen a simulator is accessible, our algorithm efficiently learns a near-optimal\npolicy with guaranteed sample complexity. In the absence of a simulator, our\nalgorithm, designed with an upper-confidence-bound exploration approach,\nidentifies a near-optimal policy while ensuring a guaranteed regret bound. For\nboth algorithms, we match the theoretical lower bounds for the risk-neutral\nsetting.",
            "author": [
                "Zhengqi Wu",
                "Renyuan Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13589v1",
                "http://arxiv.org/pdf/2311.13589v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13587v1",
            "title": "A Survey of Serverless Machine Learning Model Inference",
            "updated": "2023-11-22T18:46:05Z",
            "published": "2023-11-22T18:46:05Z",
            "summary": "Recent developments in Generative AI, Computer Vision, and Natural Language\nProcessing have led to an increased integration of AI models into various\nproducts. This widespread adoption of AI requires significant efforts in\ndeploying these models in production environments. When hosting machine\nlearning models for real-time predictions, it is important to meet defined\nService Level Objectives (SLOs), ensuring reliability, minimal downtime, and\noptimizing operational costs of the underlying infrastructure. Large machine\nlearning models often demand GPU resources for efficient inference to meet\nSLOs. In the context of these trends, there is growing interest in hosting AI\nmodels in a serverless architecture while still providing GPU access for\ninference tasks. This survey aims to summarize and categorize the emerging\nchallenges and optimization opportunities for large-scale deep learning serving\nsystems. By providing a novel taxonomy and summarizing recent trends, we hope\nthat this survey could shed light on new optimization perspectives and motivate\nnovel works in large-scale deep learning serving systems.",
            "author": [
                "Kamil Kojs"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13587v1",
                "http://arxiv.org/pdf/2311.13587v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13584v1",
            "title": "On diffusion-based generative models and their error bounds: The\n  log-concave case with full convergence estimates",
            "updated": "2023-11-22T18:40:45Z",
            "published": "2023-11-22T18:40:45Z",
            "summary": "We provide full theoretical guarantees for the convergence behaviour of\ndiffusion-based generative models under the assumption of strongly logconcave\ndata distributions while our approximating class of functions used for score\nestimation is made of Lipschitz continuous functions. We demonstrate via a\nmotivating example, sampling from a Gaussian distribution with unknown mean,\nthe powerfulness of our approach. In this case, explicit estimates are provided\nfor the associated optimization problem, i.e. score approximation, while these\nare combined with the corresponding sampling estimates. As a result, we obtain\nthe best known upper bound estimates in terms of key quantities of interest,\nsuch as the dimension and rates of convergence, for the Wasserstein-2 distance\nbetween the data distribution (Gaussian with unknown mean) and our sampling\nalgorithm.\n  Beyond the motivating example and in order to allow for the use of a diverse\nrange of stochastic optimizers, we present our results using an $L^2$-accurate\nscore estimation assumption, which crucially is formed under an expectation\nwith respect to the stochastic optimizer and our novel auxiliary process that\nuses only known information. This approach yields the best known convergence\nrate for our sampling algorithm.",
            "author": [
                "Stefano Bruno",
                "Ying Zhang",
                "Dong-Young Lim",
                "\u00d6mer Deniz Akyildiz",
                "Sotirios Sabanis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13584v1",
                "http://arxiv.org/pdf/2311.13584v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC",
                "math.PR",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13583v1",
            "title": "Adaptive Sampling for Deep Learning via Efficient Nonparametric Proxies",
            "updated": "2023-11-22T18:40:18Z",
            "published": "2023-11-22T18:40:18Z",
            "summary": "Data sampling is an effective method to improve the training speed of neural\nnetworks, with recent results demonstrating that it can even break the neural\nscaling laws. These results critically rely on high-quality scores to estimate\nthe importance of an input to the network. We observe that there are two\ndominant strategies: static sampling, where the scores are determined before\ntraining, and dynamic sampling, where the scores can depend on the model\nweights. Static algorithms are computationally inexpensive but less effective\nthan their dynamic counterparts, which can cause end-to-end slowdown due to\ntheir need to explicitly compute losses. To address this problem, we propose a\nnovel sampling distribution based on nonparametric kernel regression that\nlearns an effective importance score as the neural network trains. However,\nnonparametric regression models are too computationally expensive to accelerate\nend-to-end training. Therefore, we develop an efficient sketch-based\napproximation to the Nadaraya-Watson estimator. Using recent techniques from\nhigh-dimensional statistics and randomized algorithms, we prove that our\nNadaraya-Watson sketch approximates the estimator with exponential convergence\nguarantees. Our sampling algorithm outperforms the baseline in terms of\nwall-clock time and accuracy on four datasets.",
            "author": [
                "Shabnam Daghaghi",
                "Benjamin Coleman",
                "Benito Geordie",
                "Anshumali Shrivastava"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13583v1",
                "http://arxiv.org/pdf/2311.13583v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13580v2",
            "title": "$\u03c3$-PCA: a unified neural model for linear and nonlinear principal\n  component analysis",
            "updated": "2023-11-25T22:26:23Z",
            "published": "2023-11-22T18:34:49Z",
            "summary": "Linear principal component analysis (PCA), nonlinear PCA, and linear\nindependent component analysis (ICA) -- those are three methods with\nsingle-layer autoencoder formulations for learning linear transformations from\ndata. Linear PCA learns orthogonal transformations (rotations) that orient axes\nto maximise variance, but it suffers from a subspace rotational indeterminacy:\nit fails to find a unique rotation for axes that share the same variance. Both\nnonlinear PCA and linear ICA reduce the subspace indeterminacy from rotational\nto permutational by maximising statistical independence under the assumption of\nunit variance. The relationship between all three can be understood by the\nsingular value decomposition of the linear ICA transformation into a sequence\nof rotation, scale, rotation. Linear PCA learns the first rotation; nonlinear\nPCA learns the second. The scale is simply the inverse of the standard\ndeviations. The problem is that, in contrast to linear PCA, conventional\nnonlinear PCA cannot be used directly on the data to learn the first rotation,\nthe first being special as it reduces dimensionality and orders by variances.\nIn this paper, we have identified the cause, and as a solution we propose\n$\\sigma$-PCA: a unified neural model for linear and nonlinear PCA as\nsingle-layer autoencoders. One of its key ingredients: modelling not just the\nrotation but also the scale -- the variances. This model bridges the disparity\nbetween linear and nonlinear PCA. And so, like linear PCA, it can learn a\nsemi-orthogonal transformation that reduces dimensionality and orders by\nvariances, but, unlike linear PCA, it does not suffer from rotational\nindeterminacy.",
            "author": [
                "Fahdi Kanavati",
                "Lucy Katsnith",
                "Masayuki Tsuneki"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13580v2",
                "http://arxiv.org/pdf/2311.13580v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13570v1",
            "title": "WildFusion: Learning 3D-Aware Latent Diffusion Models in View Space",
            "updated": "2023-11-22T18:25:51Z",
            "published": "2023-11-22T18:25:51Z",
            "summary": "Modern learning-based approaches to 3D-aware image synthesis achieve high\nphotorealism and 3D-consistent viewpoint changes for the generated images.\nExisting approaches represent instances in a shared canonical space. However,\nfor in-the-wild datasets a shared canonical system can be difficult to define\nor might not even exist. In this work, we instead model instances in view\nspace, alleviating the need for posed images and learned camera distributions.\nWe find that in this setting, existing GAN-based methods are prone to\ngenerating flat geometry and struggle with distribution coverage. We hence\npropose WildFusion, a new approach to 3D-aware image synthesis based on latent\ndiffusion models (LDMs). We first train an autoencoder that infers a compressed\nlatent representation, which additionally captures the images' underlying 3D\nstructure and enables not only reconstruction but also novel view synthesis. To\nlearn a faithful 3D representation, we leverage cues from monocular depth\nprediction. Then, we train a diffusion model in the 3D-aware latent space,\nthereby enabling synthesis of high-quality 3D-consistent image samples,\noutperforming recent state-of-the-art GAN-based methods. Importantly, our\n3D-aware LDM is trained without any direct supervision from multiview images or\n3D geometry and does not require posed images or learned pose or camera\ndistributions. It directly learns a 3D representation without relying on\ncanonical camera coordinates. This opens up promising research avenues for\nscalable 3D-aware image synthesis and 3D content creation from in-the-wild\nimage data. See https://katjaschwarz.github.io/wildfusion for videos of our 3D\nresults.",
            "author": [
                "Katja Schwarz",
                "Seung Wook Kim",
                "Jun Gao",
                "Sanja Fidler",
                "Andreas Geiger",
                "Karsten Kreis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13570v1",
                "http://arxiv.org/pdf/2311.13570v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13568v1",
            "title": "Learning from similar systems and online data-driven LQR using iterative\n  randomised data compression",
            "updated": "2023-11-22T18:24:11Z",
            "published": "2023-11-22T18:24:11Z",
            "summary": "The problem of data-driven recursive computation of receding horizon LQR\ncontrol through a randomized combination of online/current and\nhistorical/recorded data is considered. It is assumed that large amounts of\nhistorical input-output data from a system, which is similar but not identical\nto the current system under consideration, is available. This (possibly large)\ndata set is compressed through a novel randomized subspace algorithm to\ndirectly synthesize an initial solution of the standard LQR problem, which\nhowever is sub-optimal due to the inaccuracy of the historical model. The first\ninstance of this input is used to actuate the current system and the\ncorresponding instantaneous output is used to iteratively re-solve the LQR\nproblem through a computationally inexpensive randomized rank-one update of the\nold compressed data. The first instance of the re-computed input is applied to\nthe system at the next instant, output recorded and the entire procedure is\nrepeated at each subsequent instant. As more current data becomes available,\nthe algorithm learns automatically from the new data while simultaneously\ncontrolling the system in near optimal manner. The proposed algorithm is\ncomputationally inexpensive due to the initial and repeated compression of old\nand newly available data. Moreover, the simultaneous learning and control makes\nthis algorithm particularly suited for adapting to unknown, poorly modeled and\ntime-varying systems without any explicit exploration stage. Simulations\ndemonstrate the effectiveness of the proposed algorithm vs popular\nexploration/exploitation approaches to LQR control.",
            "author": [
                "Vatsal Kedia",
                "Sneha Susan George",
                "Debraj Chakraborty"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13568v1",
                "http://arxiv.org/pdf/2311.13568v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13559v2",
            "title": "Transfer Learning-based Real-time Handgun Detection",
            "updated": "2023-11-23T19:10:01Z",
            "published": "2023-11-22T18:09:42Z",
            "summary": "Traditional surveillance systems rely on human attention, limiting their\neffectiveness. This study employs convolutional neural networks and transfer\nlearning to develop a real-time computer vision system for automatic handgun\ndetection. Comprehensive analysis of online handgun detection methods is\nconducted, emphasizing reducing false positives and learning time. Transfer\nlearning is demonstrated as an effective approach. Despite technical\nchallenges, the proposed system achieves a precision rate of 84.74%,\ndemonstrating promising performance comparable to related works, enabling\nfaster learning and accurate automatic handgun detection for enhanced security.\nThis research advances security measures by reducing human monitoring\ndependence, showcasing the potential of transfer learning-based approaches for\nefficient and reliable handgun detection.",
            "author": [
                "Youssef Elmir",
                "Sid Ahmed Laouar",
                "Larbi Hamdaoui"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13559v2",
                "http://arxiv.org/pdf/2311.13559v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13552v1",
            "title": "A Unified Framework for Trace-induced Quantum Kernels",
            "updated": "2023-11-22T17:50:00Z",
            "published": "2023-11-22T17:50:00Z",
            "summary": "Quantum kernel methods are promising candidates for achieving a practical\nquantum advantage for certain machine learning tasks. Similar to classical\nmachine learning, an exact form of a quantum kernel is expected to have a great\nimpact on the model performance. In this work we combine all trace-induced\nquantum kernels, including the commonly-used global fidelity and local\nprojected quantum kernels, into a common framework. We show how generalized\ntrace-induced quantum kernels can be constructed as combinations of the\nfundamental building blocks we coin \"Lego\" kernels, which impose an inductive\nbias on the resulting quantum models. We relate the expressive power and\ngeneralization ability to the number of non-zero weight Lego kernels and\npropose a systematic approach to increase the complexity of a quantum kernel\nmodel, leading to a new form of the local projected kernels that require fewer\nquantum resources in terms of the number of quantum gates and measurement\nshots. We show numerically that models based on local projected kernels can\nachieve comparable performance to the global fidelity quantum kernel. Our work\nunifies existing quantum kernels and provides a systematic framework to compare\ntheir properties.",
            "author": [
                "Beng Yee Gan",
                "Daniel Leykam",
                "Supanut Thanasilp"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13552v1",
                "http://arxiv.org/pdf/2311.13552v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13627v1",
            "title": "Vamos: Versatile Action Models for Video Understanding",
            "updated": "2023-11-22T17:44:24Z",
            "published": "2023-11-22T17:44:24Z",
            "summary": "What makes good video representations for video understanding, such as\nanticipating future activities, or answering video-conditioned questions? While\nearlier approaches focus on end-to-end learning directly from video pixels, we\npropose to revisit text-based representations, such as discrete action labels,\nor free-form video captions, which are interpretable and can be directly\nconsumed by large language models (LLMs). Intuitively, different video\nunderstanding tasks may require representations that are complementary and at\ndifferent granularities. To this end, we propose versatile action models\n(Vamos), a learning framework powered by a large language model as the\n\"reasoner\", and can flexibly leverage visual embeddings, action labels, and\nfree-form descriptions extracted from videos as its input. We evaluate Vamos on\nfour complementary video understanding benchmarks, Ego4D, Next-QA, IntentQA,\nand EgoSchema, on its capability to model temporal dynamics, encode visual\nhistory, and perform reasoning. Surprisingly, we observe that text-based\nrepresentations consistently achieve competitive performance on all benchmarks,\nand that visual embeddings provide marginal or no performance improvement,\ndemonstrating the effectiveness of text-based video representation in the LLM\nera. We perform extensive ablation study and qualitative analysis to support\nour observations, and achieve state-of-the-art performance on three benchmarks.",
            "author": [
                "Shijie Wang",
                "Qi Zhao",
                "Minh Quan Do",
                "Nakul Agarwal",
                "Kwonjoon Lee",
                "Chen Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13627v1",
                "http://arxiv.org/pdf/2311.13627v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13548v1",
            "title": "Efficient Numerical Integration in Reproducing Kernel Hilbert Spaces via\n  Leverage Scores Sampling",
            "updated": "2023-11-22T17:44:18Z",
            "published": "2023-11-22T17:44:18Z",
            "summary": "In this work we consider the problem of numerical integration, i.e.,\napproximating integrals with respect to a target probability measure using only\npointwise evaluations of the integrand. We focus on the setting in which the\ntarget distribution is only accessible through a set of $n$ i.i.d.\nobservations, and the integrand belongs to a reproducing kernel Hilbert space.\nWe propose an efficient procedure which exploits a small i.i.d. random subset\nof $m<n$ samples drawn either uniformly or using approximate leverage scores\nfrom the initial observations. Our main result is an upper bound on the\napproximation error of this procedure for both sampling strategies. It yields\nsufficient conditions on the subsample size to recover the standard (optimal)\n$n^{-1/2}$ rate while reducing drastically the number of functions evaluations,\nand thus the overall computational cost. Moreover, we obtain rates with respect\nto the number $m$ of evaluations of the integrand which adapt to its\nsmoothness, and match known optimal rates for instance for Sobolev spaces. We\nillustrate our theoretical findings with numerical experiments on real\ndatasets, which highlight the attractive efficiency-accuracy tradeoff of our\nmethod compared to existing randomized and greedy quadrature methods. We note\nthat, the problem of numerical integration in RKHS amounts to designing a\ndiscrete approximation of the kernel mean embedding of the target distribution.\nAs a consequence, direct applications of our results also include the efficient\ncomputation of maximum mean discrepancies between distributions and the design\nof efficient kernel-based tests.",
            "author": [
                "Antoine Chatalic",
                "Nicolas Schreuder",
                "Ernesto De Vito",
                "Lorenzo Rosasco"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13548v1",
                "http://arxiv.org/pdf/2311.13548v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13546v1",
            "title": "Enigma: Privacy-Preserving Execution of QAOA on Untrusted Quantum\n  Computers",
            "updated": "2023-11-22T17:40:23Z",
            "published": "2023-11-22T17:40:23Z",
            "summary": "Quantum computers can solve problems that are beyond the capabilities of\nconventional computers. As quantum computers are expensive and hard to\nmaintain, the typical model for performing quantum computation is to send the\ncircuit to a quantum cloud provider. This leads to privacy concerns for\ncommercial entities as an untrusted server can learn protected information from\nthe provided circuit. Current proposals for Secure Quantum Computing (SQC)\neither rely on emerging technologies (such as quantum networks) or incur\nprohibitive overheads (for Quantum Homomorphic Encryption). The goal of our\npaper is to enable low-cost privacy-preserving quantum computation that can be\nused with current systems.\n  We propose Enigma, a suite of privacy-preserving schemes specifically\ndesigned for the Quantum Approximate Optimization Algorithm (QAOA). Unlike\nprevious SQC techniques that obfuscate quantum circuits, Enigma transforms the\ninput problem of QAOA, such that the resulting circuit and the outcomes are\nunintelligible to the server. We introduce three variants of Enigma. Enigma-I\nprotects the coefficients of QAOA using random phase flipping and fudging of\nvalues. Enigma-II protects the nodes of the graph by introducing decoy qubits,\nwhich are indistinguishable from primary ones. Enigma-III protects the edge\ninformation of the graph by modifying the graph such that each node has an\nidentical number of connections. For all variants of Enigma, we demonstrate\nthat we can still obtain the solution for the original problem. We evaluate\nEnigma using IBM quantum devices and show that the privacy improvements of\nEnigma come at only a small reduction in fidelity (1%-13%).",
            "author": [
                "Ramin Ayanzadeh",
                "Ahmad Mousavi",
                "Narges Alavisamani",
                "Moinuddin Qureshi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13546v1",
                "http://arxiv.org/pdf/2311.13546v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.AI",
                "cs.CR",
                "cs.DM",
                "cs.ET"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13544v1",
            "title": "Piecewise polynomial regression of tame functions via integer\n  programming",
            "updated": "2023-11-22T17:37:42Z",
            "published": "2023-11-22T17:37:42Z",
            "summary": "We consider the task of estimating functions belonging to a specific class of\nnonsmooth functions, namely so-called tame functions. These functions appear in\na wide range of applications: training deep learning, value functions of\nmixed-integer programs, or wave functions of small molecules. We show that tame\nfunctions are approximable by piecewise polynomials on any full-dimensional\ncube. We then present the first ever mixed-integer programming formulation of\npiecewise polynomial regression. Together, these can be used to estimate tame\nfunctions. We demonstrate promising computational results.",
            "author": [
                "Jiri Nemecek",
                "Gilles Bareilles",
                "Johannes Aspman",
                "Jakub Marecek"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13544v1",
                "http://arxiv.org/pdf/2311.13544v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13541v1",
            "title": "Linear Log-Normal Attention with Unbiased Concentration",
            "updated": "2023-11-22T17:30:41Z",
            "published": "2023-11-22T17:30:41Z",
            "summary": "Transformer models have achieved remarkable results in a wide range of\napplications. However, their scalability is hampered by the quadratic time and\nmemory complexity of the self-attention mechanism concerning the sequence\nlength. This limitation poses a substantial obstacle when dealing with long\ndocuments or high-resolution images. In this work, we study the self-attention\nmechanism by analyzing the distribution of the attention matrix and its\nconcentration ability. Furthermore, we propose instruments to measure these\nquantities and introduce a novel self-attention mechanism, Linear Log-Normal\nAttention, designed to emulate the distribution and concentration behavior of\nthe original self-attention. Our experimental results on popular natural\nlanguage benchmarks reveal that our proposed Linear Log-Normal Attention\noutperforms other linearized attention alternatives, offering a promising\navenue for enhancing the scalability of transformer models. Our code is\navailable in supplementary materials.",
            "author": [
                "Yury Nahshan",
                "Joseph Kampeas",
                "Emir Haleva"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13541v1",
                "http://arxiv.org/pdf/2311.13541v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "I.7.0; G.3"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13539v1",
            "title": "Learned Nonlinear Predictor for Critically Sampled 3D Point Cloud\n  Attribute Compression",
            "updated": "2023-11-22T17:26:54Z",
            "published": "2023-11-22T17:26:54Z",
            "summary": "We study 3D point cloud attribute compression via a volumetric approach:\nassuming point cloud geometry is known at both encoder and decoder, parameters\n$\\theta$ of a continuous attribute function $f: \\mathbb{R}^3 \\mapsto\n\\mathbb{R}$ are quantized to $\\hat{\\theta}$ and encoded, so that discrete\nsamples $f_{\\hat{\\theta}}(\\mathbf{x}_i)$ can be recovered at known 3D points\n$\\mathbf{x}_i \\in \\mathbb{R}^3$ at the decoder. Specifically, we consider a\nnested sequences of function subspaces $\\mathcal{F}^{(p)}_{l_0} \\subseteq\n\\cdots \\subseteq \\mathcal{F}^{(p)}_L$, where $\\mathcal{F}_l^{(p)}$ is a family\nof functions spanned by B-spline basis functions of order $p$, $f_l^*$ is the\nprojection of $f$ on $\\mathcal{F}_l^{(p)}$ and encoded as low-pass coefficients\n$F_l^*$, and $g_l^*$ is the residual function in orthogonal subspace\n$\\mathcal{G}_l^{(p)}$ (where $\\mathcal{G}_l^{(p)} \\oplus \\mathcal{F}_l^{(p)} =\n\\mathcal{F}_{l+1}^{(p)}$) and encoded as high-pass coefficients $G_l^*$. In\nthis paper, to improve coding performance over [1], we study predicting\n$f_{l+1}^*$ at level $l+1$ given $f_l^*$ at level $l$ and encoding of $G_l^*$\nfor the $p=1$ case (RAHT($1$)). For the prediction, we formalize RAHT(1) linear\nprediction in MPEG-PCC in a theoretical framework, and propose a new nonlinear\npredictor using a polynomial of bilateral filter. We derive equations to\nefficiently compute the critically sampled high-pass coefficients $G_l^*$\namenable to encoding. We optimize parameters in our resulting feed-forward\nnetwork on a large training set of point clouds by minimizing a rate-distortion\nLagrangian. Experimental results show that our improved framework outperformed\nthe MPEG G-PCC predictor by $11$ to $12\\%$ in bit rate reduction.",
            "author": [
                "Tam Thuc Do",
                "Philip A. Chou",
                "Gene Cheung"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13539v1",
                "http://arxiv.org/pdf/2311.13539v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13538v1",
            "title": "Speak Like a Native: Prompting Large Language Models in a Native Style",
            "updated": "2023-11-22T17:24:21Z",
            "published": "2023-11-22T17:24:21Z",
            "summary": "Existing work has found that the prompt engineering heavily influences the\nperformance of large language models (LLMs). Chain-of-thought (CoT), as a\npopular prompt engineering technique, prompted LLMs using in-context examples\nwith reasoning steps. In current studies, the few-shot examples of CoT are\ngenerally handcrafted by humans. However, how the text style of in-context\nexamples influence the outputs of LLMs still remains under-explored. This paper\npresents a novel and effective approach, named \\textbf{AlignCoT}, to improve\nthe reasoning capability of LLMs by aligning the in-context examples with the\nnative style of LLMs. ``Native'' refers to the inherent characteristic style of\nLLMs which can be probed by original zero-shot scenarios. AlignCoT is\northogonal to other prompt engineering methods, making it easy to combine with\nstate-of-the-art techniques to further improve the LLMs' performance. We\nconduct extensive and comprehensive experiments on several benchmarks. The\nempirical results demonstrate that our AlignCoTsignificantly improves\nperformance over the carefully handcrafted in-context examples. For instance,\nwith GPT-3.5-turbo, we observed a +2.5\\% improvement on GSM8K. Furthermore, our\nAlignCoT consistently improve the performance when combined with other\nstate-of-the-art prompt engineering methods. The source code and dataset will\nbe available at\n\\href{https://github.com/yangzhch6/AlignCoT}{https://github.com/yangzhch6/AlignCoT}.",
            "author": [
                "Zhicheng Yang",
                "Yiwei Wang",
                "Yinya Huang",
                "Jing Xiong",
                "Xiaodan Liang",
                "Jing Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13538v1",
                "http://arxiv.org/pdf/2311.13538v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13535v1",
            "title": "DiffusionMat: Alpha Matting as Sequential Refinement Learning",
            "updated": "2023-11-22T17:16:44Z",
            "published": "2023-11-22T17:16:44Z",
            "summary": "In this paper, we introduce DiffusionMat, a novel image matting framework\nthat employs a diffusion model for the transition from coarse to refined alpha\nmattes. Diverging from conventional methods that utilize trimaps merely as\nloose guidance for alpha matte prediction, our approach treats image matting as\na sequential refinement learning process. This process begins with the addition\nof noise to trimaps and iteratively denoises them using a pre-trained diffusion\nmodel, which incrementally guides the prediction towards a clean alpha matte.\nThe key innovation of our framework is a correction module that adjusts the\noutput at each denoising step, ensuring that the final result is consistent\nwith the input image's structures. We also introduce the Alpha Reliability\nPropagation, a novel technique designed to maximize the utility of available\nguidance by selectively enhancing the trimap regions with confident alpha\ninformation, thus simplifying the correction task. To train the correction\nmodule, we devise specialized loss functions that target the accuracy of the\nalpha matte's edges and the consistency of its opaque and transparent regions.\nWe evaluate our model across several image matting benchmarks, and the results\nindicate that DiffusionMat consistently outperforms existing methods. Project\npage at~\\url{https://cnnlstm.github.io/DiffusionMat",
            "author": [
                "Yangyang Xu",
                "Shengfeng He",
                "Wenqi Shao",
                "Kwan-Yee K. Wong",
                "Yu Qiao",
                "Ping Luo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13535v1",
                "http://arxiv.org/pdf/2311.13535v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17065v2",
            "title": "Efficient Deep Speech Understanding at the Edge",
            "updated": "2023-12-04T15:37:57Z",
            "published": "2023-11-22T17:14:18Z",
            "summary": "In contemporary speech understanding (SU), a sophisticated pipeline is\nemployed, encompassing the ingestion of streaming voice input. The pipeline\nexecutes beam search iteratively, invoking a deep neural network to generate\ntentative outputs (referred to as hypotheses) in an autoregressive manner.\nPeriodically, the pipeline assesses attention and Connectionist Temporal\nClassification (CTC) scores.\n  This paper aims to enhance SU performance on edge devices with limited\nresources. Adopting a hybrid strategy, our approach focuses on accelerating\non-device execution and offloading inputs surpassing the device's capacity.\nWhile this approach is established, we tackle SU's distinctive challenges\nthrough innovative techniques: (1) Late Contextualization: This involves the\nparallel execution of a model's attentive encoder during input ingestion. (2)\nPilot Inference: Addressing temporal load imbalances in the SU pipeline, this\ntechnique aims to mitigate them effectively. (3) Autoregression Offramps:\nDecisions regarding offloading are made solely based on hypotheses, presenting\na novel approach.\n  These techniques are designed to seamlessly integrate with existing speech\nmodels, pipelines, and frameworks, offering flexibility for independent or\ncombined application. Collectively, they form a hybrid solution for edge SU.\nOur prototype, named XYZ, has undergone testing on Arm platforms featuring 6 to\n8 cores, demonstrating state-of-the-art accuracy. Notably, it achieves a 2x\nreduction in end-to-end latency and a corresponding 2x decrease in offloading\nrequirements.",
            "author": [
                "Rongxiang Wang",
                "Felix Xiaozhu Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17065v2",
                "http://arxiv.org/pdf/2311.17065v2"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13533v1",
            "title": "Volumetric 3D Point Cloud Attribute Compression: Learned polynomial\n  bilateral filter for prediction",
            "updated": "2023-11-22T17:13:24Z",
            "published": "2023-11-22T17:13:24Z",
            "summary": "We extend a previous study on 3D point cloud attribute compression scheme\nthat uses a volumetric approach: given a target volumetric attribute function\n$f : \\mathbb{R}^3 \\mapsto \\mathbb{R}$, we quantize and encode parameters\n$\\theta$ that characterize $f$ at the encoder, for reconstruction\n$f_{\\hat{\\theta}}(\\mathbf(x))$ at known 3D points $\\mathbf(x)$ at the decoder.\nSpecifically, parameters $\\theta$ are quantized coefficients of B-spline basis\nvectors $\\mathbf{\\Phi}_l$ (for order $p \\geq 2$) that span the function space\n$\\mathcal{F}_l^{(p)}$ at a particular resolution $l$, which are coded from\ncoarse to fine resolutions for scalability. In this work, we focus on the\nprediction of finer-grained coefficients given coarser-grained ones by learning\nparameters of a polynomial bilateral filter (PBF) from data. PBF is a\npseudo-linear filter that is signal-dependent with a graph spectral\ninterpretation common in the graph signal processing (GSP) field. We\ndemonstrate PBF's predictive performance over a linear predictor inspired by\nMPEG standardization over a wide range of point cloud datasets.",
            "author": [
                "Tam Thuc Do",
                "Philip A. Chou",
                "Gene Cheung"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13533v1",
                "http://arxiv.org/pdf/2311.13533v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13531v1",
            "title": "Leveraging CNNs and Ensemble Learning for Automated Disaster Image\n  Classification",
            "updated": "2023-11-22T17:06:57Z",
            "published": "2023-11-22T17:06:57Z",
            "summary": "Natural disasters act as a serious threat globally, requiring effective and\nefficient disaster management and recovery. This paper focuses on classifying\nnatural disaster images using Convolutional Neural Networks (CNNs). Multiple\nCNN architectures were built and trained on a dataset containing images of\nearthquakes, floods, wildfires, and volcanoes. A stacked CNN ensemble approach\nproved to be the most effective, achieving 95% accuracy and an F1 score going\nup to 0.96 for individual classes. Tuning hyperparameters of individual models\nfor optimization was critical to maximize the models' performance. The stacking\nof CNNs with XGBoost acting as the meta-model utilizes the strengths of the CNN\nand ResNet models to improve the overall accuracy of the classification.\nResults obtained from the models illustrated the potency of CNN-based models\nfor automated disaster image classification. This lays the foundation for\nexpanding these techniques to build robust systems for disaster response,\ndamage assessment, and recovery management.",
            "author": [
                "Archit Rathod",
                "Veer Pariawala",
                "Mokshit Surana",
                "Kumkum Saxena"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13531v1",
                "http://arxiv.org/pdf/2311.13531v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13517v2",
            "title": "Learning-Based Relaxation of Completeness Requirements for Data Entry\n  Forms",
            "updated": "2023-11-29T14:56:01Z",
            "published": "2023-11-22T16:40:26Z",
            "summary": "Data entry forms use completeness requirements to specify the fields that are\nrequired or optional to fill for collecting necessary information from\ndifferent types of users.\n  However, some required fields may not be applicable for certain types of\nusers anymore. Nevertheless, they may still be incorrectly marked as required\nin the form; we call such fields obsolete required fields.\n  Since obsolete required fields usually have not-null validation checks before\nsubmitting the form, users have to enter meaningless values in such fields in\norder to complete the form submission. These meaningless values threaten the\nquality of the filled data. To avoid users filling meaningless values, existing\ntechniques usually rely on manually written rules to identify the obsolete\nrequired fields and relax their completeness requirements. However, these\ntechniques are ineffective and costly. In this paper, we propose LACQUER, a\nlearning-based automated approach for relaxing the completeness requirements of\ndata entry forms. LACQUER builds Bayesian Network models to automatically learn\nconditions under which users had to fill meaningless values. To improve its\nlearning ability, LACQUER identifies the cases where a required field is only\napplicable for a small group of users, and uses SMOTE, an oversampling\ntechnique, to generate more instances on such fields for effectively mining\ndependencies on them. Our experimental results show that LACQUER can accurately\nrelax the completeness requirements of required fields in data entry forms with\nprecision values ranging between 0.76 and 0.90 on different datasets. LACQUER\ncan prevent users from filling 20% to 64% of meaningless values, with negative\npredictive values between 0.72 and 0.91. Furthermore, LACQUER is efficient; it\ntakes at most 839 ms to predict the completeness requirement of an instance.",
            "author": [
                "Hichem Belgacem",
                "Xiaochen Li",
                "Domenico Bianculli",
                "Lionel C. Briand"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13517v2",
                "http://arxiv.org/pdf/2311.13517v2"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13508v1",
            "title": "Naturalness of Attention: Revisiting Attention in Code Language Models",
            "updated": "2023-11-22T16:34:12Z",
            "published": "2023-11-22T16:34:12Z",
            "summary": "Language models for code such as CodeBERT offer the capability to learn\nadvanced source code representation, but their opacity poses barriers to\nunderstanding of captured properties. Recent attention analysis studies provide\ninitial interpretability insights by focusing solely on attention weights\nrather than considering the wider context modeling of Transformers. This study\naims to shed some light on the previously ignored factors of the attention\nmechanism beyond the attention weights. We conduct an initial empirical study\nanalyzing both attention distributions and transformed representations in\nCodeBERT. Across two programming languages, Java and Python, we find that the\nscaled transformation norms of the input better capture syntactic structure\ncompared to attention weights alone. Our analysis reveals characterization of\nhow CodeBERT embeds syntactic code properties. The findings demonstrate the\nimportance of incorporating factors beyond just attention weights for\nrigorously understanding neural code models. This lays the groundwork for\ndeveloping more interpretable models and effective uses of attention mechanisms\nin program analysis.",
            "author": [
                "Mootez Saad",
                "Tushar Sharma"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13508v1",
                "http://arxiv.org/pdf/2311.13508v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13507v1",
            "title": "Applying Dimensionality Reduction as Precursor to LSTM-CNN Models for\n  Classifying Imagery and Motor Signals in ECoG-Based BCIs",
            "updated": "2023-11-22T16:34:06Z",
            "published": "2023-11-22T16:34:06Z",
            "summary": "Motor impairments, frequently caused by neurological incidents like strokes\nor traumatic brain injuries, present substantial obstacles in rehabilitation\ntherapy. This research aims to elevate the field by optimizing motor imagery\nclassification algorithms within Brain-Computer Interfaces (BCIs). By improving\nthe efficiency of BCIs, we offer a novel approach that holds significant\npromise for enhancing motor rehabilitation outcomes. Utilizing unsupervised\ntechniques for dimensionality reduction, namely Uniform Manifold Approximation\nand Projection (UMAP) coupled with K-Nearest Neighbors (KNN), we evaluate the\nnecessity of employing supervised methods such as Long Short-Term Memory (LSTM)\nand Convolutional Neural Networks (CNNs) for classification tasks. Importantly,\nparticipants who exhibited high KNN scores following UMAP dimensionality\nreduction also achieved high accuracy in supervised deep learning (DL) models.\nDue to individualized model requirements and massive neural training data,\ndimensionality reduction becomes an effective preprocessing step that minimizes\nthe need for extensive data labeling and supervised deep learning techniques.\nThis approach has significant implications not only for targeted therapies in\nmotor dysfunction but also for addressing regulatory, safety, and reliability\nconcerns in the rapidly evolving BCI field.",
            "author": [
                "Soham Bafana"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13507v1",
                "http://arxiv.org/pdf/2311.13507v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.HC",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13502v1",
            "title": "Bitformer: An efficient Transformer with bitwise operation-based\n  attention for Big Data Analytics at low-cost low-precision devices",
            "updated": "2023-11-22T16:20:24Z",
            "published": "2023-11-22T16:20:24Z",
            "summary": "In the current landscape of large models, the Transformer stands as a\ncornerstone, playing a pivotal role in shaping the trajectory of modern models.\nHowever, its application encounters challenges attributed to the substantial\ncomputational intricacies intrinsic to its attention mechanism. Moreover, its\nreliance on high-precision floating-point operations presents specific hurdles,\nparticularly evident in computation-intensive scenarios such as edge computing\nenvironments. These environments, characterized by resource-constrained devices\nand a preference for lower precision, necessitate innovative solutions.\n  To tackle the exacting data processing demands posed by edge devices, we\nintroduce the Bitformer model, an inventive extension of the Transformer\nparadigm. Central to this innovation is a novel attention mechanism that\nadeptly replaces conventional floating-point matrix multiplication with bitwise\noperations. This strategic substitution yields dual advantages. Not only does\nit maintain the attention mechanism's prowess in capturing intricate long-range\ninformation dependencies, but it also orchestrates a profound reduction in the\ncomputational complexity inherent in the attention operation. The transition\nfrom an $O(n^2d)$ complexity, typical of floating-point operations, to an\n$O(n^2T)$ complexity characterizing bitwise operations, substantiates this\nadvantage. Notably, in this context, the parameter $T$ remains markedly smaller\nthan the conventional dimensionality parameter $d$.\n  The Bitformer model in essence endeavors to reconcile the indomitable\nrequirements of modern computing landscapes with the constraints posed by edge\ncomputing scenarios. By forging this innovative path, we bridge the gap between\nhigh-performing models and resource-scarce environments, thus unveiling a\npromising trajectory for further advancements in the field.",
            "author": [
                "Gaoxiang Duan",
                "Junkai Zhang",
                "Xiaoying Zheng",
                "Yongxin Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13502v1",
                "http://arxiv.org/pdf/2311.13502v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13495v1",
            "title": "Current Topological and Machine Learning Applications for Bias Detection\n  in Text",
            "updated": "2023-11-22T16:12:42Z",
            "published": "2023-11-22T16:12:42Z",
            "summary": "Institutional bias can impact patient outcomes, educational attainment, and\nlegal system navigation. Written records often reflect bias, and once bias is\nidentified; it is possible to refer individuals for training to reduce bias.\nMany machine learning tools exist to explore text data and create predictive\nmodels that can search written records to identify real-time bias. However, few\nprevious studies investigate large language model embeddings and geometric\nmodels of biased text data to understand geometry's impact on bias modeling\naccuracy. To overcome this issue, this study utilizes the RedditBias database\nto analyze textual biases. Four transformer models, including BERT and RoBERTa\nvariants, were explored. Post-embedding, t-SNE allowed two-dimensional\nvisualization of data. KNN classifiers differentiated bias types, with lower\nk-values proving more effective. Findings suggest BERT, particularly mini BERT,\nexcels in bias classification, while multilingual models lag. The\nrecommendation emphasizes refining monolingual models and exploring\ndomain-specific biases.",
            "author": [
                "Colleen Farrelly",
                "Yashbir Singh",
                "Quincy A. Hathaway",
                "Gunnar Carlsson",
                "Ashok Choudhary",
                "Rahul Paul",
                "Gianfranco Doretto",
                "Yassine Himeur",
                "Shadi Atalls",
                "Wathiq Mansoor"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13495v1",
                "http://arxiv.org/pdf/2311.13495v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13491v1",
            "title": "Grad-Shafranov equilibria via data-free physics informed neural networks",
            "updated": "2023-11-22T16:08:38Z",
            "published": "2023-11-22T16:08:38Z",
            "summary": "A large number of magnetohydrodynamic (MHD) equilibrium calculations are\noften required for uncertainty quantification, optimization, and real-time\ndiagnostic information, making MHD equilibrium codes vital to the field of\nplasma physics. In this paper, we explore a method for solving the\nGrad-Shafranov equation by using Physics-Informed Neural Networks (PINNs). For\nPINNs, we optimize neural networks by directly minimizing the residual of the\nPDE as a loss function. We show that PINNs can accurately and effectively solve\nthe Grad-Shafranov equation with several different boundary conditions. We also\nexplore the parameter space by varying the size of the model, the learning\nrate, and boundary conditions to map various trade-offs such as between\nreconstruction error and computational speed. Additionally, we introduce a\nparameterized PINN framework, expanding the input space to include variables\nsuch as pressure, aspect ratio, elongation, and triangularity in order to\nhandle a broader range of plasma scenarios within a single network.\nParametrized PINNs could be used in future work to solve inverse problems such\nas shape optimization.",
            "author": [
                "Byoungchan Jang",
                "Alan A. Kaptanoglu",
                "Rahul Gaur",
                "Shaowu Pan",
                "Matt Landreman",
                "William Dorland"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13491v1",
                "http://arxiv.org/pdf/2311.13491v1"
            ],
            "primary_category": "physics.plasm-ph",
            "category": [
                "physics.plasm-ph",
                "cs.LG",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13490v1",
            "title": "Benchmarking Toxic Molecule Classification using Graph Neural Networks\n  and Few Shot Learning",
            "updated": "2023-11-22T16:07:32Z",
            "published": "2023-11-22T16:07:32Z",
            "summary": "Traditional methods like Graph Convolutional Networks (GCNs) face challenges\nwith limited data and class imbalance, leading to suboptimal performance in\ngraph classification tasks during toxicity prediction of molecules as a whole.\nTo address these issues, we harness the power of Graph Isomorphic Networks,\nMulti Headed Attention and Free Large-scale Adversarial Augmentation separately\non Graphs for precisely capturing the structural data of molecules and their\ntoxicological properties. Additionally, we incorporate Few-Shot Learning to\nimprove the model's generalization with limited annotated samples. Extensive\nexperiments on a diverse toxicology dataset demonstrate that our method\nachieves an impressive state-of-art AUC-ROC value of 0.816, surpassing the\nbaseline GCN model by 11.4%. This highlights the significance of our proposed\nmethodology and Few Shot Learning in advancing Toxic Molecular Classification,\nwith the potential to enhance drug discovery and environmental risk assessment\nprocesses.",
            "author": [
                "Bhavya Mehta",
                "Kush Kothari",
                "Reshmika Nambiar",
                "Seema Shrawne"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13490v1",
                "http://arxiv.org/pdf/2311.13490v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13489v1",
            "title": "Large-scale Package Deliveries with Unmanned Aerial Vehicles using\n  Collective Learning",
            "updated": "2023-11-22T16:04:39Z",
            "published": "2023-11-22T16:04:39Z",
            "summary": "Unmanned aerial vehicles (UAVs) have significant practical advantages for\ndelivering packages, and many logistics companies have begun deploying UAVs for\ncommercial package deliveries. To deliver packages quickly and\ncost-effectively, the routes taken by UAVs from depots to customers must be\noptimized. This route optimization problem, a type of capacitated vehicle\nrouting problem, has recently attracted considerable research interest.\nHowever, few papers have dealt with large-scale deliveries, where the number of\ncustomers exceed 1000. We present an innovative, practical package delivery\nmodel wherein multiple UAVs deliver multiple packages to customers who are\ncompensated for late deliveries. Further, we propose an innovative methodology\nthat combines a new plan-generation algorithm with a collective-learning\nheuristic to quickly determine cost-effective paths of UAVs even for\nlarge-scale deliveries up to 10000 customers. Specialized settings are applied\nto a collective-learning heuristic, the Iterative Economic Planning and\nOptimized Selections (I-EPOS) in order to coordinate collective actions of the\nUAVs. To demonstrate our methodology, we applied our highly flexible approach\nto a depot in Heathrow Airport, London. We show that a coordinated approach, in\nwhich the UAVs collectively determine their flight paths, leads to lower\noperational costs than an uncoordinated approach. Further, the coordinated\napproach enables large-scale package deliveries.",
            "author": [
                "Arun Narayanan",
                "Evangelos Pournaras",
                "Pedro H. J. Nardelli"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13489v1",
                "http://arxiv.org/pdf/2311.13489v1"
            ],
            "primary_category": "cs.MA",
            "category": [
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13488v1",
            "title": "Machine Learning based Post Event Analysis for Cybersecurity of\n  Cyber-Physical System",
            "updated": "2023-11-22T16:02:35Z",
            "published": "2023-11-22T16:02:35Z",
            "summary": "As Information and Communication Technology (ICT) equipment continues to be\nintegrated into power systems, issues related to cybersecurity are increasingly\nemerging. Particularly noteworthy is the transition to digital substations,\nwhich is shifting operations from traditional hardwired-based systems to\ncommunication-based Supervisory Control and Data Acquisition (SCADA) system\noperations. These changes in the power system have increased the vulnerability\nof the system to cyber-attacks and emphasized its importance. This paper\nproposes a machine learning (ML) based post event analysis of the power system\nin order to respond to these cybersecurity issues. An artificial neural network\n(ANN) and other ML models are trained using transient fault measurements and\ncyber-attack data on substations. The trained models can successfully\ndistinguish between power system faults and cyber-attacks. Furthermore, the\nresults of the proposed ML-based methods can also identify 10 different fault\ntypes and the location where the event occurred.",
            "author": [
                "Kuchan Park",
                "Junho Hong",
                "Wencong Su",
                "HyoJong Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13488v1",
                "http://arxiv.org/pdf/2311.13488v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13485v1",
            "title": "Deep-learning-based acceleration of MRI for radiotherapy planning of\n  pediatric patients with brain tumors",
            "updated": "2023-11-22T16:01:44Z",
            "published": "2023-11-22T16:01:44Z",
            "summary": "Magnetic Resonance Imaging (MRI) is a non-invasive diagnostic and\nradiotherapy (RT) planning tool, offering detailed insights into the anatomy of\nthe human body. The extensive scan time is stressful for patients, who must\nremain motionless in a prolonged imaging procedure that prioritizes reduction\nof imaging artifacts. This is challenging for pediatric patients who may\nrequire measures for managing voluntary motions such as anesthesia. Several\ncomputational approaches reduce scan time (fast MRI), by recording fewer\nmeasurements and digitally recovering full information via post-acquisition\nreconstruction. However, most fast MRI approaches were developed for diagnostic\nimaging, without addressing reconstruction challenges specific to RT planning.\nIn this work, we developed a deep learning-based method (DeepMRIRec) for MRI\nreconstruction from undersampled data acquired with RT-specific receiver coil\narrangements. We evaluated our method against fully sampled data of T1-weighted\nMR images acquired from 73 children with brain tumors/surgical beds using loop\nand posterior coils (12 channels), with and without applying virtual\ncompression of coil elements. DeepMRIRec reduced scanning time by a factor of\nfour producing a structural similarity score surpassing the evaluated\nstate-of-the-art method (0.960 vs 0.896), thereby demonstrating its potential\nfor accelerating MRI scanning for RT planning.",
            "author": [
                "Shahinur Alam",
                "Jinsoo Uh",
                "Alexander Dresner",
                "Chia-ho Hua",
                "Khaled Khairy"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13485v1",
                "http://arxiv.org/pdf/2311.13485v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13475v1",
            "title": "Machine Translation to Control Formality Features in the Target Language",
            "updated": "2023-11-22T15:42:51Z",
            "published": "2023-11-22T15:42:51Z",
            "summary": "Formality plays a significant role in language communication, especially in\nlow-resource languages such as Hindi, Japanese and Korean. These languages\nutilise formal and informal expressions to convey messages based on social\ncontexts and relationships. When a language translation technique is used to\ntranslate from a source language that does not pertain the formality (e.g.\nEnglish) to a target language that does, there is a missing information on\nformality that could be a challenge in producing an accurate outcome. This\nresearch explores how this issue should be resolved when machine learning\nmethods are used to translate from English to languages with formality, using\nHindi as the example data. This was done by training a bilingual model in a\nformality-controlled setting and comparing its performance with a pre-trained\nmultilingual model in a similar setting. Since there are not a lot of training\ndata with ground truth, automated annotation techniques were employed to\nincrease the data size. The primary modeling approach involved leveraging\ntransformer models, which have demonstrated effectiveness in various natural\nlanguage processing tasks. We evaluate the official formality accuracy(ACC) by\ncomparing the predicted masked tokens with the ground truth. This metric\nprovides a quantitative measure of how well the translations align with the\ndesired outputs. Our study showcases a versatile translation strategy that\nconsiders the nuances of formality in the target language, catering to diverse\nlanguage communication needs and scenarios.",
            "author": [
                "Harshita Tyagi",
                "Prashasta Jung",
                "Hyowon Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13475v1",
                "http://arxiv.org/pdf/2311.13475v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13472v1",
            "title": "Complexity-Guided Curriculum Learning for Text Graphs",
            "updated": "2023-11-22T15:40:57Z",
            "published": "2023-11-22T15:40:57Z",
            "summary": "Curriculum learning provides a systematic approach to training. It refines\ntraining progressively, tailors training to task requirements, and improves\ngeneralization through exposure to diverse examples. We present a curriculum\nlearning approach that builds on existing knowledge about text and graph\ncomplexity formalisms for training with text graph data. The core part of our\napproach is a novel data scheduler, which employs \"spaced repetition\" and\ncomplexity formalisms to guide the training process. We demonstrate the\neffectiveness of the proposed approach on several text graph tasks and graph\nneural network architectures. The proposed model gains more and uses less data;\nconsistently prefers text over graph complexity indices throughout training,\nwhile the best curricula derived from text and graph complexity indices are\nequally effective; and it learns transferable curricula across GNN models and\ndatasets. In addition, we find that both node-level (local) and graph-level\n(global) graph complexity indices, as well as shallow and traditional text\ncomplexity indices play a crucial role in effective curriculum learning.",
            "author": [
                "Nidhi Vakil",
                "Hadi Amiri"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13472v1",
                "http://arxiv.org/pdf/2311.13472v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13471v1",
            "title": "Comparative Analysis of Linear Regression, Gaussian Elimination, and LU\n  Decomposition for CT Real Estate Purchase Decisions",
            "updated": "2023-11-22T15:35:56Z",
            "published": "2023-11-22T15:35:56Z",
            "summary": "This paper presents a comprehensive evaluation of three distinct\ncomputational algorithms applied to the decision-making process of real estate\npurchases. Specifically, we analyze the efficacy of Linear Regression from\nScikit-learn library, Gaussian Elimination with partial pivoting, and LU\nDecomposition in predicting the advisability of buying a house in the State of\nConnecticut based on a set of financial and market-related parameters. The\nalgorithms' performances were compared using a dataset encompassing\ntown-specific details, yearly data, interest rates, and median sale ratios. Our\nresults demonstrate significant differences in predictive accuracy, with Linear\nRegression and LU Decomposition providing the most reliable recommendations and\nGaussian Elimination showing limitations in stability and performance. The\nstudy's findings emphasize the importance of algorithm selection in predictive\nanalytic and offer insights into the practical applications of computational\nmethods in real estate investment strategies. By evaluating model efficacy\nthrough metrics such as R-squared scores and Mean Squared Error, we provide a\nnuanced understanding of each method's strengths and weaknesses, contributing\nvaluable knowledge to the fields of real estate analysis and predictive\nmodeling.",
            "author": [
                "Xilin Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13471v1",
                "http://arxiv.org/pdf/2311.13471v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CC",
                "cs.CE",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13469v1",
            "title": "Span-Based Optimal Sample Complexity for Average Reward MDPs",
            "updated": "2023-11-22T15:34:44Z",
            "published": "2023-11-22T15:34:44Z",
            "summary": "We study the sample complexity of learning an $\\varepsilon$-optimal policy in\nan average-reward Markov decision process (MDP) under a generative model. We\nestablish the complexity bound $\\widetilde{O}\\left(SA\\frac{H}{\\varepsilon^2}\n\\right)$, where $H$ is the span of the bias function of the optimal policy and\n$SA$ is the cardinality of the state-action space. Our result is the first that\nis minimax optimal (up to log factors) in all parameters $S,A,H$ and\n$\\varepsilon$, improving on existing work that either assumes uniformly bounded\nmixing times for all policies or has suboptimal dependence on the parameters.\n  Our result is based on reducing the average-reward MDP to a discounted MDP.\nTo establish the optimality of this reduction, we develop improved bounds for\n$\\gamma$-discounted MDPs, showing that\n$\\widetilde{O}\\left(SA\\frac{H}{(1-\\gamma)^2\\varepsilon^2} \\right)$ samples\nsuffice to learn a $\\varepsilon$-optimal policy in weakly communicating MDPs\nunder the regime that $\\gamma \\geq 1 - \\frac{1}{H}$, circumventing the\nwell-known lower bound of\n$\\widetilde{\\Omega}\\left(SA\\frac{1}{(1-\\gamma)^3\\varepsilon^2} \\right)$ for\ngeneral $\\gamma$-discounted MDPs. Our analysis develops upper bounds on certain\ninstance-dependent variance parameters in terms of the span parameter. These\nbounds are tighter than those based on the mixing time or diameter of the MDP\nand may be of broader use.",
            "author": [
                "Matthew Zurek",
                "Yudong Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13469v1",
                "http://arxiv.org/pdf/2311.13469v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IT",
                "math.IT",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13466v1",
            "title": "Accelerating Inference in Molecular Diffusion Models with Latent\n  Representations of Protein Structure",
            "updated": "2023-11-22T15:32:31Z",
            "published": "2023-11-22T15:32:31Z",
            "summary": "Diffusion generative models have emerged as a powerful framework for\naddressing problems in structural biology and structure-based drug design.\nThese models operate directly on 3D molecular structures. Due to the\nunfavorable scaling of graph neural networks (GNNs) with graph size as well as\nthe relatively slow inference speeds inherent to diffusion models, many\nexisting molecular diffusion models rely on coarse-grained representations of\nprotein structure to make training and inference feasible. However, such\ncoarse-grained representations discard essential information for modeling\nmolecular interactions and impair the quality of generated structures. In this\nwork, we present a novel GNN-based architecture for learning latent\nrepresentations of molecular structure. When trained end-to-end with a\ndiffusion model for de novo ligand design, our model achieves comparable\nperformance to one with an all-atom protein representation while exhibiting a\n3-fold reduction in inference time.",
            "author": [
                "Ian Dunn",
                "David Ryan Koes"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13466v1",
                "http://arxiv.org/pdf/2311.13466v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13460v1",
            "title": "Multi-Objective Bayesian Optimization with Active Preference Learning",
            "updated": "2023-11-22T15:24:36Z",
            "published": "2023-11-22T15:24:36Z",
            "summary": "There are a lot of real-world black-box optimization problems that need to\noptimize multiple criteria simultaneously. However, in a multi-objective\noptimization (MOO) problem, identifying the whole Pareto front requires the\nprohibitive search cost, while in many practical scenarios, the decision maker\n(DM) only needs a specific solution among the set of the Pareto optimal\nsolutions. We propose a Bayesian optimization (BO) approach to identifying the\nmost preferred solution in the MOO with expensive objective functions, in which\na Bayesian preference model of the DM is adaptively estimated by an interactive\nmanner based on the two types of supervisions called the pairwise preference\nand improvement request. To explore the most preferred solution, we define an\nacquisition function in which the uncertainty both in the objective functions\nand the DM preference is incorporated. Further, to minimize the interaction\ncost with the DM, we also propose an active learning strategy for the\npreference estimation. We empirically demonstrate the effectiveness of our\nproposed method through the benchmark function optimization and the\nhyper-parameter optimization problems for machine learning models.",
            "author": [
                "Ryota Ozaki",
                "Kazuki Ishikawa",
                "Youhei Kanzaki",
                "Shinya Suzuki",
                "Shion Takeno",
                "Ichiro Takeuchi",
                "Masayuki Karasuyama"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13460v1",
                "http://arxiv.org/pdf/2311.13460v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13459v1",
            "title": "The Tempered Hilbert Simplex Distance and Its Application To Non-linear\n  Embeddings of TEMs",
            "updated": "2023-11-22T15:24:29Z",
            "published": "2023-11-22T15:24:29Z",
            "summary": "Tempered Exponential Measures (TEMs) are a parametric generalization of the\nexponential family of distributions maximizing the tempered entropy function\namong positive measures subject to a probability normalization of their power\ndensities. Calculus on TEMs relies on a deformed algebra of arithmetic\noperators induced by the deformed logarithms used to define the tempered\nentropy. In this work, we introduce three different parameterizations of finite\ndiscrete TEMs via Legendre functions of the negative tempered entropy function.\nIn particular, we establish an isometry between such parameterizations in terms\nof a generalization of the Hilbert log cross-ratio simplex distance to a\ntempered Hilbert co-simplex distance. Similar to the Hilbert geometry, the\ntempered Hilbert distance is characterized as a $t$-symmetrization of the\noriented tempered Funk distance. We motivate our construction by introducing\nthe notion of $t$-lengths of smooth curves in a tautological Finsler manifold.\nWe then demonstrate the properties of our generalized structure in different\nsettings and numerically examine the quality of its differentiable\napproximations for optimization in machine learning settings.",
            "author": [
                "Ehsan Amid",
                "Frank Nielsen",
                "Richard Nock",
                "Manfred K. Warmuth"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13459v1",
                "http://arxiv.org/pdf/2311.13459v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13458v1",
            "title": "Controlling crystal cleavage in Focused Ion Beam shaped specimens for\n  surface spectroscopy",
            "updated": "2023-11-22T15:24:19Z",
            "published": "2023-11-22T15:24:19Z",
            "summary": "Our understanding of quantum materials is commonly based on precise\ndeterminations of their electronic spectrum by spectroscopic means, most\nnotably angle-resolved photoemission spectroscopy (ARPES) and scanning\ntunneling microscopy (STM). Both require atomically clean and flat crystal\nsurfaces which traditionally are prepared by in-situ mechanical cleaving in\nultrahigh vacuum chambers. We present a new approach that addresses three main\nissues of the current state-of-the-art methods: 1) Cleaving is a highly\nstochastic and thus inefficient process; 2) Fracture processes are governed by\nthe bonds in a bulk crystal, and many materials and surfaces simply do not\ncleave; 3) The location of the cleave is random, preventing data collection at\nspecified regions of interest. Our new workflow is based on Focused Ion Beam\n(FIB) machining of micro-stress lenses in which shape (rather than crystalline)\nanisotropy dictates the plane of cleavage, which can be placed at a specific\ntarget layer. As proof-of-principle we show ARPES results from micro-cleaves of\nSr$_2$RuO$_4$ along the ac plane and from two surface orientations of\nSrTiO$_3$, a notoriously difficult to cleave cubic perovskite.",
            "author": [
                "A. Hunter",
                "C. Putzke",
                "I. Gaponenko",
                "A. Tamai",
                "F. Baumberger",
                "P. J. W. Moll"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13458v1",
                "http://arxiv.org/pdf/2311.13458v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13454v1",
            "title": "Explaining high-dimensional text classifiers",
            "updated": "2023-11-22T15:20:12Z",
            "published": "2023-11-22T15:20:12Z",
            "summary": "Explainability has become a valuable tool in the last few years, helping\nhumans better understand AI-guided decisions. However, the classic\nexplainability tools are sometimes quite limited when considering\nhigh-dimensional inputs and neural network classifiers. We present a new\nexplainability method using theoretically proven high-dimensional properties in\nneural network classifiers. We present two usages of it: 1) On the classical\nsentiment analysis task for the IMDB reviews dataset, and 2) our\nMalware-Detection task for our PowerShell scripts dataset.",
            "author": [
                "Odelia Melamed",
                "Rich Caruana"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13454v1",
                "http://arxiv.org/pdf/2311.13454v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.NE",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13447v1",
            "title": "Differentially Private Non-Convex Optimization under the KL Condition\n  with Optimal Rates",
            "updated": "2023-11-22T15:12:42Z",
            "published": "2023-11-22T15:12:42Z",
            "summary": "We study private empirical risk minimization (ERM) problem for losses\nsatisfying the $(\\gamma,\\kappa)$-Kurdyka-{\\L}ojasiewicz (KL) condition. The\nPolyak-{\\L}ojasiewicz (PL) condition is a special case of this condition when\n$\\kappa=2$. Specifically, we study this problem under the constraint of $\\rho$\nzero-concentrated differential privacy (zCDP). When $\\kappa\\in[1,2]$ and the\nloss function is Lipschitz and smooth over a sufficiently large region, we\nprovide a new algorithm based on variance reduced gradient descent that\nachieves the rate\n$\\tilde{O}\\big(\\big(\\frac{\\sqrt{d}}{n\\sqrt{\\rho}}\\big)^\\kappa\\big)$ on the\nexcess empirical risk, where $n$ is the dataset size and $d$ is the dimension.\nWe further show that this rate is nearly optimal. When $\\kappa \\geq 2$ and the\nloss is instead Lipschitz and weakly convex, we show it is possible to achieve\nthe rate $\\tilde{O}\\big(\\big(\\frac{\\sqrt{d}}{n\\sqrt{\\rho}}\\big)^\\kappa\\big)$\nwith a private implementation of the proximal point method. When the KL\nparameters are unknown, we provide a novel modification and analysis of the\nnoisy gradient descent algorithm and show that this algorithm achieves a rate\nof\n$\\tilde{O}\\big(\\big(\\frac{\\sqrt{d}}{n\\sqrt{\\rho}}\\big)^{\\frac{2\\kappa}{4-\\kappa}}\\big)$\nadaptively, which is nearly optimal when $\\kappa = 2$. We further show that,\nwithout assuming the KL condition, the same gradient descent algorithm can\nachieve fast convergence to a stationary point when the gradient stays\nsufficiently large during the run of the algorithm. Specifically, we show that\nthis algorithm can approximate stationary points of Lipschitz, smooth (and\npossibly nonconvex) objectives with rate as fast as\n$\\tilde{O}\\big(\\frac{\\sqrt{d}}{n\\sqrt{\\rho}}\\big)$ and never worse than\n$\\tilde{O}\\big(\\big(\\frac{\\sqrt{d}}{n\\sqrt{\\rho}}\\big)^{1/2}\\big)$. The latter\nrate matches the best known rate for methods that do not rely on variance\nreduction.",
            "author": [
                "Michael Menart",
                "Enayat Ullah",
                "Raman Arora",
                "Raef Bassily",
                "Crist\u00f3bal Guzm\u00e1n"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13447v1",
                "http://arxiv.org/pdf/2311.13447v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13445v1",
            "title": "Transfer Attacks and Defenses for Large Language Models on Coding Tasks",
            "updated": "2023-11-22T15:11:35Z",
            "published": "2023-11-22T15:11:35Z",
            "summary": "Modern large language models (LLMs), such as ChatGPT, have demonstrated\nimpressive capabilities for coding tasks including writing and reasoning about\ncode. They improve upon previous neural network models of code, such as\ncode2seq or seq2seq, that already demonstrated competitive results when\nperforming tasks such as code summarization and identifying code\nvulnerabilities. However, these previous code models were shown vulnerable to\nadversarial examples, i.e. small syntactic perturbations that do not change the\nprogram's semantics, such as the inclusion of \"dead code\" through false\nconditions or the addition of inconsequential print statements, designed to\n\"fool\" the models. LLMs can also be vulnerable to the same adversarial\nperturbations but a detailed study on this concern has been lacking so far. In\nthis paper we aim to investigate the effect of adversarial perturbations on\ncoding tasks with LLMs. In particular, we study the transferability of\nadversarial examples, generated through white-box attacks on smaller code\nmodels, to LLMs. Furthermore, to make the LLMs more robust against such\nadversaries without incurring the cost of retraining, we propose prompt-based\ndefenses that involve modifying the prompt to include additional information\nsuch as examples of adversarially perturbed code and explicit instructions for\nreversing adversarial perturbations. Our experiments show that adversarial\nexamples obtained with a smaller code model are indeed transferable, weakening\nthe LLMs' performance. The proposed defenses show promise in improving the\nmodel's resilience, paving the way to more robust defensive solutions for LLMs\nin code-related applications.",
            "author": [
                "Chi Zhang",
                "Zifan Wang",
                "Ravi Mangal",
                "Matt Fredrikson",
                "Limin Jia",
                "Corina Pasareanu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13445v1",
                "http://arxiv.org/pdf/2311.13445v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13443v1",
            "title": "Guided Flows for Generative Modeling and Decision Making",
            "updated": "2023-11-22T15:07:59Z",
            "published": "2023-11-22T15:07:59Z",
            "summary": "Classifier-free guidance is a key component for improving the performance of\nconditional generative models for many downstream tasks. It drastically\nimproves the quality of samples produced, but has so far only been used for\ndiffusion models. Flow Matching (FM), an alternative simulation-free approach,\ntrains Continuous Normalizing Flows (CNFs) based on regressing vector fields.\nIt remains an open question whether classifier-free guidance can be performed\nfor Flow Matching models, and to what extent does it improve performance. In\nthis paper, we explore the usage of Guided Flows for a variety of downstream\napplications involving conditional image generation, speech synthesis, and\nreinforcement learning. In particular, we are the first to apply flow models to\nthe offline reinforcement learning setting. We also show that Guided Flows\nsignificantly improves the sample quality in image generation and zero-shot\ntext-to-speech synthesis, and can make use of drastically low amounts of\ncomputation without affecting the agent's overall performance.",
            "author": [
                "Qinqing Zheng",
                "Matt Le",
                "Neta Shaul",
                "Yaron Lipman",
                "Aditya Grover",
                "Ricky T. Q. Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13443v1",
                "http://arxiv.org/pdf/2311.13443v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "cs.RO",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13434v2",
            "title": "Recurrent neural networks and transfer learning for elasto-plasticity in\n  woven composites",
            "updated": "2023-12-07T14:59:02Z",
            "published": "2023-11-22T14:47:54Z",
            "summary": "As a surrogate for computationally intensive meso-scale simulation of woven\ncomposites, this article presents Recurrent Neural Network (RNN) models.\nLeveraging the power of transfer learning, the initialization challenges and\nsparse data issues inherent in cyclic shear strain loads are addressed in the\nRNN models. A mean-field model generates a comprehensive data set representing\nelasto-plastic behavior. In simulations, arbitrary six-dimensional strain\nhistories are used to predict stresses under random walking as the source task\nand cyclic loading conditions as the target task. Incorporating sub-scale\nproperties enhances RNN versatility. In order to achieve accurate predictions,\nthe model uses a grid search method to tune network architecture and\nhyper-parameter configurations. The results of this study demonstrate that\ntransfer learning can be used to effectively adapt the RNN to varying strain\nconditions, which establishes its potential as a useful tool for modeling\npath-dependent responses in woven composites.",
            "author": [
                "Ehsan Ghane",
                "Martin Fagerstr\u00f6m",
                "Mohsen Mirkhalaf"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13434v2",
                "http://arxiv.org/pdf/2311.13434v2"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13431v1",
            "title": "Extracting individual variable information for their decoupling, direct\n  mutual information and multi-feature Granger causality",
            "updated": "2023-11-22T14:45:30Z",
            "published": "2023-11-22T14:45:30Z",
            "summary": "Working with multiple variables they usually contain difficult to control\ncomplex dependencies. This article proposes extraction of their individual\ninformation, e.g. $\\overline{X|Y}$ as random variable containing information\nfrom $X$, but with removed information about $Y$, by using $(x,y)\n\\leftrightarrow (\\bar{x}=\\textrm{CDF}_{X|Y=y}(x),y)$ reversible normalization.\nOne application can be decoupling of individual information of variables:\nreversibly transform $(X_1,\\ldots,X_n)\\leftrightarrow(\\tilde{X}_1,\\ldots\n\\tilde{X}_n)$ together containing the same information, but being independent:\n$\\forall_{i\\neq j} \\tilde{X}_i\\perp \\tilde{X}_j, \\tilde{X}_i\\perp X_j$. It\nrequires detailed models of complex conditional probability distributions - it\nis generally a difficult task, but here can be done through multiple dependency\nreducing iterations, using imperfect methods (here HCR: Hierarchical\nCorrelation Reconstruction). It could be also used for direct mutual\ninformation - evaluating direct information transfer: without use of\nintermediate variables. For causality direction there is discussed\nmulti-feature Granger causality, e.g. to trace various types of individual\ninformation transfers between such decoupled variables, including propagation\ntime (delay).",
            "author": [
                "Jarek Duda"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13431v1",
                "http://arxiv.org/pdf/2311.13431v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.IT",
                "cs.LG",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13414v1",
            "title": "From Images to Connections: Can DQN with GNNs learn the Strategic Game\n  of Hex?",
            "updated": "2023-11-22T14:20:15Z",
            "published": "2023-11-22T14:20:15Z",
            "summary": "The gameplay of strategic board games such as chess, Go and Hex is often\ncharacterized by combinatorial, relational structures -- capturing distinct\ninteractions and non-local patterns -- and not just images. Nonetheless, most\ncommon self-play reinforcement learning (RL) approaches simply approximate\npolicy and value functions using convolutional neural networks (CNN). A key\nfeature of CNNs is their relational inductive bias towards locality and\ntranslational invariance. In contrast, graph neural networks (GNN) can encode\nmore complicated and distinct relational structures. Hence, we investigate the\ncrucial question: Can GNNs, with their ability to encode complex connections,\nreplace CNNs in self-play reinforcement learning? To this end, we do a\ncomparison with Hex -- an abstract yet strategically rich board game -- serving\nas our experimental platform. Our findings reveal that GNNs excel at dealing\nwith long range dependency situations in game states and are less prone to\noverfitting, but also showing a reduced proficiency in discerning local\npatterns. This suggests a potential paradigm shift, signaling the use of\ngame-specific structures to reshape self-play reinforcement learning.",
            "author": [
                "Yannik Keller",
                "Jannis Bl\u00fcml",
                "Gopika Sudhakaran",
                "Kristian Kersting"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13414v1",
                "http://arxiv.org/pdf/2311.13414v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13413v1",
            "title": "Revisiting Machine Learning based Test Case Prioritization for\n  Continuous Integration",
            "updated": "2023-11-22T14:19:24Z",
            "published": "2023-11-22T14:19:24Z",
            "summary": "To alleviate the cost of regression testing in continuous integration (CI), a\nlarge number of machine learning-based (ML-based) test case prioritization\ntechniques have been proposed. However, it is yet unknown how they perform\nunder the same experimental setup, because they are evaluated on different\ndatasets with different metrics. To bridge this gap, we conduct the first\ncomprehensive study on these ML-based techniques in this paper. We investigate\nthe performance of 11 representative ML-based prioritization techniques for CI\non 11 open-source subjects and obtain a series of findings. For example, the\nperformance of the techniques changes across CI cycles, mainly resulting from\nthe changing amount of training data, instead of code evolution and test\nremoval/addition. Based on the findings, we give some actionable suggestions on\nenhancing the effectiveness of ML-based techniques, e.g., pretraining a\nprioritization technique with cross-subject data to get it thoroughly trained\nand then finetuning it with within-subject data dramatically improves its\nperformance. In particular, the pretrained MART achieves state-of-the-art\nperformance, producing the optimal sequence on 80% subjects, while the existing\nbest technique, the original MART, only produces the optimal sequence on 50%\nsubjects.",
            "author": [
                "Yifan Zhao",
                "Dan Hao",
                "Lu Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13413v1",
                "http://arxiv.org/pdf/2311.13413v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13411v1",
            "title": "Bayesian inference of a new Mallows model for characterising symptom\n  sequences applied in primary progressive aphasia",
            "updated": "2023-11-22T14:16:20Z",
            "published": "2023-11-22T14:16:20Z",
            "summary": "Machine learning models offer the potential to understand diverse datasets in\na data-driven way, powering insights into individual disease experiences and\nensuring equitable healthcare. In this study, we explore Bayesian inference for\ncharacterising symptom sequences, and the associated modelling challenges. We\nadapted the Mallows model to account for partial rankings and right-censored\ndata, employing custom MCMC fitting. Our evaluation, encompassing synthetic\ndata and a primary progressive aphasia dataset, highlights the model's efficacy\nin revealing mean orderings and estimating ranking variance. This holds the\npotential to enhance clinical comprehension of symptom occurrence. However, our\nwork encounters limitations concerning model scalability and small dataset\nsizes.",
            "author": [
                "Beatrice Taylor",
                "Cameron Shand",
                "Chris J. D. Hardy",
                "Neil Oxtoby"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13411v1",
                "http://arxiv.org/pdf/2311.13411v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13409v2",
            "title": "CompenHR: Efficient Full Compensation for High-resolution Projector",
            "updated": "2023-11-28T12:12:46Z",
            "published": "2023-11-22T14:13:27Z",
            "summary": "Full projector compensation is a practical task of projector-camera systems.\nIt aims to find a projector input image, named compensation image, such that\nwhen projected it cancels the geometric and photometric distortions due to the\nphysical environment and hardware. State-of-the-art methods use deep learning\nto address this problem and show promising performance for low-resolution\nsetups. However, directly applying deep learning to high-resolution setups is\nimpractical due to the long training time and high memory cost. To address this\nissue, this paper proposes a practical full compensation solution. Firstly, we\ndesign an attention-based grid refinement network to improve geometric\ncorrection quality. Secondly, we integrate a novel sampling scheme into an\nend-to-end compensation network to alleviate computation and introduce\nattention blocks to preserve key features. Finally, we construct a benchmark\ndataset for high-resolution projector full compensation. In experiments, our\nmethod demonstrates clear advantages in both efficiency and quality.",
            "author": [
                "Yuxi Wang",
                "Haibin Ling",
                "Bingyao Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13409v2",
                "http://arxiv.org/pdf/2311.13409v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13404v2",
            "title": "Animatable 3D Gaussians for High-fidelity Synthesis of Human Motions",
            "updated": "2023-11-27T02:33:36Z",
            "published": "2023-11-22T14:00:23Z",
            "summary": "We present a novel animatable 3D Gaussian model for rendering high-fidelity\nfree-view human motions in real time. Compared to existing NeRF-based methods,\nthe model owns better capability in synthesizing high-frequency details without\nthe jittering problem across video frames. The core of our model is a novel\naugmented 3D Gaussian representation, which attaches each Gaussian with a\nlearnable code. The learnable code serves as a pose-dependent appearance\nembedding for refining the erroneous appearance caused by geometric\ntransformation of Gaussians, based on which an appearance refinement model is\nlearned to produce residual Gaussian properties to match the appearance in\ntarget pose. To force the Gaussians to learn the foreground human only without\nbackground interference, we further design a novel alpha loss to explicitly\nconstrain the Gaussians within the human body. We also propose to jointly\noptimize the human joint parameters to improve the appearance accuracy. The\nanimatable 3D Gaussian model can be learned with shallow MLPs, so new human\nmotions can be synthesized in real time (66 fps on avarage). Experiments show\nthat our model has superior performance over NeRF-based methods.",
            "author": [
                "Keyang Ye",
                "Tianjia Shao",
                "Kun Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13404v2",
                "http://arxiv.org/pdf/2311.13404v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13397v1",
            "title": "Spatial Audio and Individualized HRTFs using a Convolutional Neural\n  Network (CNN)",
            "updated": "2023-11-22T13:52:51Z",
            "published": "2023-11-22T13:52:51Z",
            "summary": "Spatial audio and 3-Dimensional sound rendering techniques play a pivotal and\nessential role in immersive audio experiences. Head-Related Transfer Functions\n(HRTFs) are acoustic filters which represent how sound interacts with an\nindividual's unique head and ears anatomy. The use of HRTFs compliant to the\nsubjects anatomical traits is crucial to ensure a personalized and unique\nspatial experience. This work proposes the implementation of an HRTF\nindividualization method based on anthropometric features automatically\nextracted from ear images using a Convolutional Neural Network (CNN). Firstly,\na CNN is implemented and tested to assess the performance of machine learning\non positioning landmarks on ear images. The I-BUG dataset, containing ear\nimages with corresponding 55 landmarks, was used to train and test the neural\nnetwork. Subsequently, 12 relevant landmarks were selected to correspond to 7\nspecific anthropometric measurements established by the HUTUBS database. These\nlandmarks serve as a reference for distance computation in pixels in order to\nretrieve the anthropometric measurements from the ear images. Once the 7\ndistances in pixels are extracted from the ear image, they are converted in\ncentimetres using conversion factors, a best match method vector is implemented\ncomputing the Euclidean distance for each set in a database of 116 ears with\ntheir corresponding 7 anthropometric measurements provided by the HUTUBS\ndatabase. The closest match of anthropometry can be identified and the\ncorresponding set of HRTFs can be obtained for personnalized use. The method is\nevaluated in its validity instead of the accuracy of the results. The\nconceptual scope of each stage has been verified and substantiated to function\ncorrectly. The various steps and the available elements in the process are\nreviewed and challenged to define a greater algorithm entity designed for the\ndesired task.",
            "author": [
                "Ludovic Pirard"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13397v1",
                "http://arxiv.org/pdf/2311.13397v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13381v1",
            "title": "Confidant: Customizing Transformer-based LLMs via Collaborative Edge\n  Training",
            "updated": "2023-11-22T13:20:59Z",
            "published": "2023-11-22T13:20:59Z",
            "summary": "Transformer-based large language models (LLMs) have demonstrated impressive\ncapabilities in a variety of natural language processing (NLP) tasks.\nNonetheless, it is challenging to deploy and fine-tune LLMs on mobile edge\ndevices with limited computing, memory, and energy budgets. In this paper, we\npropose Confidant, a multi-backend collaborative training framework for\ncustomizing state-of-the-art LLMs on commodity mobile devices like smartphones.\nConfidant partitions an LLM into several sub-models so that each fits into a\nmobile device's memory. A pipeline parallel training mechanism is further\ndeveloped to ensure fast and efficient distributed training. In addition, we\npropose a novel backend scheduler to allocate different attention heads to\nheterogeneous compute hardware, including mobile CPU and GPUs, to maximize the\ncompute resource utilization on each edge device. Our preliminary experimental\nresults show that Confidant achieves at most 45.3% memory reduction and 8.03x\ninference speedup in practical settings.",
            "author": [
                "Yuhao Chen",
                "Yuxuan Yan",
                "Qianqian Yang",
                "Yuanchao Shu",
                "Shibo He",
                "Jiming Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13381v1",
                "http://arxiv.org/pdf/2311.13381v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13380v1",
            "title": "Analyzing the Evolution and Maintenance of ML Models on Hugging Face",
            "updated": "2023-11-22T13:20:25Z",
            "published": "2023-11-22T13:20:25Z",
            "summary": "Hugging Face (HF) has established itself as a crucial platform for the\ndevelopment and sharing of machine learning (ML) models. This repository mining\nstudy, which delves into more than 380,000 models using data gathered via the\nHF Hub API, aims to explore the community engagement, evolution, and\nmaintenance around models hosted on HF, aspects that have yet to be\ncomprehensively explored in the literature. We first examine the overall growth\nand popularity of HF, uncovering trends in ML domains, framework usage, authors\ngrouping and the evolution of tags and datasets used. Through text analysis of\nmodel card descriptions, we also seek to identify prevalent themes and insights\nwithin the developer community. Our investigation further extends to the\nmaintenance aspects of models, where we evaluate the maintenance status of ML\nmodels, classify commit messages into various categories (corrective,\nperfective, and adaptive), analyze the evolution across development stages of\ncommits metrics and introduce a new classification system that estimates the\nmaintenance status of models based on multiple attributes. This study aims to\nprovide valuable insights about ML model maintenance and evolution that could\ninform future model development, maintenance, and community engagement\nstrategies on community-driven platforms like HF.",
            "author": [
                "Joel Casta\u00f1o",
                "Silverio Mart\u00ednez-Fern\u00e1ndez",
                "Xavier Franch",
                "Justus Bogner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13380v1",
                "http://arxiv.org/pdf/2311.13380v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13378v1",
            "title": "Point Projection Mapping System for Tracking, Registering, Labeling and\n  Validating Optical Tissue Measurements",
            "updated": "2023-11-22T13:19:41Z",
            "published": "2023-11-22T13:19:41Z",
            "summary": "Validation of newly developed optical tissue sensing techniques for tumor\ndetection during cancer surgery requires an accurate correlation with\nhistological results. Additionally, such accurate correlation facilitates\nprecise data labeling for developing high-performance machine-learning tissue\nclassification models. In this paper, a newly developed Point Projection\nMapping system will be introduced, which allows non-destructive tracking of the\nmeasurement locations on tissue specimens. Additionally, a framework for\naccurate registration, validation, and labeling with histopathology results is\nproposed and validated on a case study. The proposed framework provides a more\nrobust and accurate method for tracking and validation of optical tissue\nsensing techniques, which saves time and resources compared to conventional\ntechniques available.",
            "author": [
                "Lianne Feenstra",
                "Stefan D. van der Stel",
                "Marcos Da Silva Guimaraes",
                "Theo J. M Ruers",
                "Behdad Dashtbozorg"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13378v1",
                "http://arxiv.org/pdf/2311.13378v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13374v1",
            "title": "An Empirical Study of Uncertainty Estimation Techniques for Detecting\n  Drift in Data Streams",
            "updated": "2023-11-22T13:17:55Z",
            "published": "2023-11-22T13:17:55Z",
            "summary": "In safety-critical domains such as autonomous driving and medical diagnosis,\nthe reliability of machine learning models is crucial. One significant\nchallenge to reliability is concept drift, which can cause model deterioration\nover time. Traditionally, drift detectors rely on true labels, which are often\nscarce and costly. This study conducts a comprehensive empirical evaluation of\nusing uncertainty values as substitutes for error rates in detecting drifts,\naiming to alleviate the reliance on labeled post-deployment data. We examine\nfive uncertainty estimation methods in conjunction with the ADWIN detector\nacross seven real-world datasets. Our results reveal that while the SWAG method\nexhibits superior calibration, the overall accuracy in detecting drifts is not\nnotably impacted by the choice of uncertainty estimation method, with even the\nmost basic method demonstrating competitive performance. These findings offer\nvaluable insights into the practical applicability of uncertainty-based drift\ndetection in real-world, safety-critical applications.",
            "author": [
                "Anton Winter",
                "Nicolas Jourdan",
                "Tristan Wirth",
                "Volker Knauthe",
                "Arjan Kuijper"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13374v1",
                "http://arxiv.org/pdf/2311.13374v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13373v3",
            "title": "Large Language Model is a Good Policy Teacher for Training Reinforcement\n  Learning Agents",
            "updated": "2023-11-29T08:39:37Z",
            "published": "2023-11-22T13:15:42Z",
            "summary": "Recent studies have shown that Large Language Models (LLMs) can be utilized\nfor solving complex sequential decision-making tasks by providing high-level\ninstructions. However, LLM-based agents face limitations in real-time dynamic\nenvironments due to their lack of specialization in solving specific target\nproblems. Moreover, the deployment of such LLM-based agents is both costly and\ntime-consuming in practical scenarios. In this paper, we introduce a novel\nframework that addresses these challenges by training a smaller scale\nspecialized student agent using instructions from an LLM-based teacher agent.\nBy leveraging guided actions provided by the teachers, the prior knowledge of\nthe LLM is distilled into the local student model. Consequently, the student\nagent can be trained with significantly less data. Furthermore, subsequent\ntraining with environment feedback empowers the student agents to surpass the\ncapabilities of their teachers. We conducted experiments on three challenging\nMiniGrid environments to evaluate the effectiveness of our framework. The\nresults demonstrate that our approach enhances sample efficiency and achieves\nsuperior performance compared to baseline methods. Our code is available at\nhttps://github.com/ZJLAB-AMMI/LLM4Teach.",
            "author": [
                "Zihao Zhou",
                "Bin Hu",
                "Pu Zhang",
                "Chenyang Zhao",
                "Bin Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13373v3",
                "http://arxiv.org/pdf/2311.13373v3"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13372v2",
            "title": "MRGazer: Decoding Eye Gaze Points from Functional Magnetic Resonance\n  Imaging in Individual Space",
            "updated": "2023-11-27T10:42:46Z",
            "published": "2023-11-22T13:13:19Z",
            "summary": "Eye-tracking research has proven valuable in understanding numerous cognitive\nfunctions. Recently, Frey et al. provided an exciting deep learning method for\nlearning eye movements from fMRI data. However, it needed to co-register fMRI\ninto standard space to obtain eyeballs masks, and thus required additional\ntemplates and was time consuming. To resolve this issue, in this paper, we\npropose a framework named MRGazer for predicting eye gaze points from fMRI in\nindividual space. The MRGazer consisted of eyeballs extraction module and a\nresidual network-based eye gaze prediction. Compared to the previous method,\nthe proposed framework skips the fMRI co-registration step, simplifies the\nprocessing protocol and achieves end-to-end eye gaze regression. The proposed\nmethod achieved superior performance in a variety of eye movement tasks than\nthe co-registration-based method, and delivered objective results within a\nshorter time (~ 0.02 Seconds for each volume) than prior method (~0.3 Seconds\nfor each volume).",
            "author": [
                "Xiuwen Wu",
                "Rongjie Hu",
                "Jie Liang",
                "Yanming Wang",
                "Bensheng Qiu",
                "Xiaoxiao Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13372v2",
                "http://arxiv.org/pdf/2311.13372v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13365v2",
            "title": "A Bounded Regret Strategy for Linear Dynamics with Unknown Control",
            "updated": "2023-11-25T20:28:23Z",
            "published": "2023-11-22T13:05:38Z",
            "summary": "We consider a simple linear control problem in which a single parameter $b$,\ndescribing the effect of the control variable, is unknown and must be learned.\nWe work in the setting of agnostic control: we allow $b$ to be any real number\nand we do not assume that we have a prior belief about $b$. For any fixed time\nhorizon, we produce a strategy whose expected cost is within a constant factor\nof the best possible.",
            "author": [
                "Jacob Carruth"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13365v2",
                "http://arxiv.org/pdf/2311.13365v2"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "93E35 (Primary), 93E20 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13356v1",
            "title": "Uncertainty Estimation in Multi-Agent Distributed Learning",
            "updated": "2023-11-22T12:48:20Z",
            "published": "2023-11-22T12:48:20Z",
            "summary": "Traditionally, IoT edge devices have been perceived primarily as low-power\ncomponents with limited capabilities for autonomous operations. Yet, with\nemerging advancements in embedded AI hardware design, a foundational shift\npaves the way for future possibilities. Thus, the aim of the KDT NEUROKIT2E\nproject is to establish a new open-source framework to further facilitate AI\napplications on edge devices by developing new methods in quantization,\npruning-aware training, and sparsification. These innovations hold the\npotential to expand the functional range of such devices considerably, enabling\nthem to manage complex Machine Learning (ML) tasks utilizing local resources\nand laying the groundwork for innovative learning approaches.\n  In the context of 6G's transformative potential, distributed learning among\nindependent agents emerges as a pivotal application, attributed to 6G networks'\nsupport for ultra-reliable low-latency communication, enhanced data rates, and\nadvanced edge computing capabilities.\n  Our research focuses on the mechanisms and methodologies that allow edge\nnetwork-enabled agents to engage in collaborative learning in distributed\nenvironments. Particularly, one of the key issues within distributed\ncollaborative learning is determining the degree of confidence in the learning\nresults, considering the spatio-temporal locality of data sets perceived by\nindependent agents.",
            "author": [
                "Gleb Radchenko",
                "Victoria Andrea Fill"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13356v1",
                "http://arxiv.org/pdf/2311.13356v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13355v1",
            "title": "Unified Classification and Rejection: A One-versus-All Framework",
            "updated": "2023-11-22T12:47:12Z",
            "published": "2023-11-22T12:47:12Z",
            "summary": "Classifying patterns of known classes and rejecting ambiguous and novel (also\ncalled as out-of-distribution (OOD)) inputs are involved in open world pattern\nrecognition. Deep neural network models usually excel in closed-set\nclassification while performing poorly in rejecting OOD. To tackle this\nproblem, numerous methods have been designed to perform open set recognition\n(OSR) or OOD rejection/detection tasks. Previous methods mostly take\npost-training score transformation or hybrid models to ensure low scores on OOD\ninputs while separating known classes. In this paper, we attempt to build a\nunified framework for building open set classifiers for both classification and\nOOD rejection. We formulate the open set recognition of $ K $-known-class as a\n$ (K + 1) $-class classification problem with model trained on known-class\nsamples only. By decomposing the $ K $-class problem into $ K $ one-versus-all\n(OVA) binary classification tasks and binding some parameters, we show that\ncombining the scores of OVA classifiers can give $ (K + 1) $-class posterior\nprobabilities, which enables classification and OOD rejection in a unified\nframework. To maintain the closed-set classification accuracy of the OVA\ntrained classifier, we propose a hybrid training strategy combining OVA loss\nand multi-class cross-entropy loss. We implement the OVA framework and hybrid\ntraining strategy on the recently proposed convolutional prototype network.\nExperiments on popular OSR and OOD detection datasets demonstrate that the\nproposed framework, using a single multi-class classifier, yields competitive\nperformance in closed-set classification, OOD detection, and misclassification\ndetection.",
            "author": [
                "Zhen Cheng",
                "Xu-Yao Zhang",
                "Cheng-Lin Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13355v1",
                "http://arxiv.org/pdf/2311.13355v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13350v1",
            "title": "Fact-based Court Judgment Prediction",
            "updated": "2023-11-22T12:39:28Z",
            "published": "2023-11-22T12:39:28Z",
            "summary": "This extended abstract extends the research presented in \"ILDC for CJPE:\nIndian Legal Documents Corpus for Court Judgment Prediction and Explanation\"\n\\cite{malik-etal-2021-ildc}, focusing on fact-based judgment prediction within\nthe context of Indian legal documents. We introduce two distinct problem\nvariations: one based solely on facts, and another combining facts with rulings\nfrom lower courts (RLC). Our research aims to enhance early-phase case outcome\nprediction, offering significant benefits to legal professionals and the\ngeneral public. The results, however, indicated a performance decline compared\nto the original ILDC for CJPE study, even after implementing various weightage\nschemes in our DELSumm algorithm. Additionally, using only facts for legal\njudgment prediction with different transformer models yielded results inferior\nto the state-of-the-art outcomes reported in the \"ILDC for CJPE\" study.",
            "author": [
                "Shubham Kumar Nigam",
                "Aniket Deroy"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3632754.3632765",
                "http://arxiv.org/abs/2311.13350v1",
                "http://arxiv.org/pdf/2311.13350v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13349v1",
            "title": "REDS: Resource-Efficient Deep Subnetworks for Dynamic Resource\n  Constraints",
            "updated": "2023-11-22T12:34:51Z",
            "published": "2023-11-22T12:34:51Z",
            "summary": "Deep models deployed on edge devices frequently encounter resource\nvariability, which arises from fluctuating energy levels, timing constraints,\nor prioritization of other critical tasks within the system. State-of-the-art\nmachine learning pipelines generate resource-agnostic models, not capable to\nadapt at runtime. In this work we introduce Resource-Efficient Deep Subnetworks\n(REDS) to tackle model adaptation to variable resources. In contrast to the\nstate-of-the-art, REDS use structured sparsity constructively by exploiting\npermutation invariance of neurons, which allows for hardware-specific\noptimizations. Specifically, REDS achieve computational efficiency by (1)\nskipping sequential computational blocks identified by a novel iterative\nknapsack optimizer, and (2) leveraging simple math to re-arrange the order of\noperations in REDS computational graph to take advantage of the data cache.\nREDS support conventional deep networks frequently deployed on the edge and\nprovide computational benefits even for small and simple networks. We evaluate\nREDS on six benchmark architectures trained on the Google Speech Commands,\nFMNIST and CIFAR10 datasets, and test on four off-the-shelf mobile and embedded\nhardware platforms. We provide a theoretical result and empirical evidence for\nREDS outstanding performance in terms of submodels' test set accuracy, and\ndemonstrate an adaptation time in response to dynamic resource constraints of\nunder 40$\\mu$s, utilizing a 2-layer fully-connected network on Arduino Nano 33\nBLE Sense.",
            "author": [
                "Francesco Corti",
                "Balz Maag",
                "Joachim Schauer",
                "Ulrich Pferschy",
                "Olga Saukh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13349v1",
                "http://arxiv.org/pdf/2311.13349v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13348v1",
            "title": "MergeSFL: Split Federated Learning with Feature Merging and Batch Size\n  Regulation",
            "updated": "2023-11-22T12:25:02Z",
            "published": "2023-11-22T12:25:02Z",
            "summary": "Recently, federated learning (FL) has emerged as a popular technique for edge\nAI to mine valuable knowledge in edge computing (EC) systems. To mitigate the\ncomputing/communication burden on resource-constrained workers and protect\nmodel privacy, split federated learning (SFL) has been released by integrating\nboth data and model parallelism. Despite resource limitations, SFL still faces\ntwo other critical challenges in EC, i.e., statistical heterogeneity and system\nheterogeneity. To address these challenges, we propose a novel SFL framework,\ntermed MergeSFL, by incorporating feature merging and batch size regulation in\nSFL. Concretely, feature merging aims to merge the features from workers into a\nmixed feature sequence, which is approximately equivalent to the features\nderived from IID data and is employed to promote model accuracy. While batch\nsize regulation aims to assign diverse and suitable batch sizes for\nheterogeneous workers to improve training efficiency. Moreover, MergeSFL\nexplores to jointly optimize these two strategies upon their coupled\nrelationship to better enhance the performance of SFL. Extensive experiments\nare conducted on a physical platform with 80 NVIDIA Jetson edge devices, and\nthe experimental results show that MergeSFL can improve the final model\naccuracy by 5.82% to 26.22%, with a speedup by about 1.74x to 4.14x, compared\nto the baselines.",
            "author": [
                "Yunming Liao",
                "Yang Xu",
                "Hongli Xu",
                "Lun Wang",
                "Zhiwei Yao",
                "Chunming Qiao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13348v1",
                "http://arxiv.org/pdf/2311.13348v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13341v1",
            "title": "Learning principle and mathematical realization of the learning\n  mechanism in the brain",
            "updated": "2023-11-22T12:08:01Z",
            "published": "2023-11-22T12:08:01Z",
            "summary": "While deep learning has achieved remarkable success, there is no clear\nexplanation about why it works so well. In order to discuss this question\nquantitatively, we need a mathematical framework that explains what learning is\nin the first place. After several considerations, we succeeded in constructing\na mathematical framework that can provide a unified understanding of all types\nof learning, including deep learning and learning in the brain. We call it\nlearning principle, and it follows that all learning is equivalent to\nestimating the probability of input data. We not only derived this principle,\nbut also mentioned its application to actual machine learning models. For\nexample, we found that conventional supervised learning is equivalent to\nestimating conditional probabilities, and succeeded in making supervised\nlearning more effective and generalized. We also proposed a new method of\ndefining the values of estimated probability using differentiation, and showed\nthat unsupervised learning can be performed on arbitrary dataset without any\nprior knowledge. Namely, this method is a general-purpose machine learning in\nthe true sense. Moreover, we succeeded in describing the learning mechanism in\nthe brain by considering the time evolution of a fully or partially connected\nmodel and applying this new method. The learning principle provides solutions\nto many unsolved problems in deep learning and cognitive neuroscience.",
            "author": [
                "Taisuke Katayose"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13341v1",
                "http://arxiv.org/pdf/2311.13341v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.IT",
                "math.IT",
                "q-bio.NC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13335v1",
            "title": "Quantum learning and essential cognition under the traction of\n  meta-characteristics in an open world",
            "updated": "2023-11-22T11:55:41Z",
            "published": "2023-11-22T11:55:41Z",
            "summary": "Artificial intelligence has made significant progress in the Close World\nproblem, being able to accurately recognize old knowledge through training and\nclassification. However, AI faces significant challenges in the Open World\nproblem, as it involves a new and unknown exploration journey. AI is not\ninherently proactive in exploration, and its challenge lies in not knowing how\nto approach and adapt to the unknown world. How do humans acquire knowledge of\nthe unknown world. Humans identify new knowledge through intrinsic cognition.\nIn the process of recognizing new colors, the cognitive cues are different from\nknown color features and involve hue, saturation, brightness, and other\ncharacteristics. When AI encounters objects with different features in the new\nworld, it faces another challenge: where are the distinguishing features\nbetween influential features of new and old objects? AI often mistakes a new\nworld's brown bear for a known dog because it has not learned the differences\nin feature distributions between knowledge systems. This is because things in\nthe new and old worlds have different units and dimensions for their features.\nThis paper proposes an open-world model and elemental feature system that\nfocuses on fundamentally recognizing the distribution differences in objective\nfeatures between the new and old worlds. The quantum tunneling effect of\nlearning ability in the new and old worlds is realized through the tractive\nforce of meta-characteristic. The outstanding performance of the model system\nin learning new knowledge (using pedestrian re-identification datasets as an\nexample) demonstrates that AI has acquired the ability to recognize the new\nworld with an accuracy of $96.71\\%$ at most and has gained the capability to\nexplore new knowledge, similar to humans.",
            "author": [
                "Jin Wang",
                "Changlin Song"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13335v1",
                "http://arxiv.org/pdf/2311.13335v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13328v1",
            "title": "MagGen: A graph aided deep generative model for inverse design of\n  stable, permanent magnets",
            "updated": "2023-11-22T11:50:17Z",
            "published": "2023-11-22T11:50:17Z",
            "summary": "A significant development towards inverse design of materials with\nwell-defined target properties is reported. A deep generative model based on\nvariational autoencoder (VAE), conditioned simultaneously by two target\nproperties, is developed to inverse design stable magnetic materials. Structure\nof the physics informed, property embedded latent space of the model is\nanalyzed using graph theory, based on the idea of similarity index. The graph\nidea is shown to be useful for generating new materials that are likely to\nsatisfy target properties. An impressive ~96% of the generated materials is\nfound to satisfy the target properties as per predictions from the target\nlearning branches. This is a huge improvement over approaches that do not\ncondition the VAE latent space by target properties, or do not consider\nconnectivity of the parent materials perturbing which the new materials are\ngenerated. In such models, the fraction of materials satisfying targets can be\nas low as ~5%. This impressive feat is achieved using a simple real-space only\nrepresentation called Invertible Real-space Crystallographic Representation\n(IRCR), that can be directly read from material cif files. Model predictions\nare finally validated by performing DFT calculations on a randomly chosen\nsubset of materials. Performance of the present model using IRCR is comparable\nor superior to that of the models reported earlier. This model for magnetic\nmaterial generation, MagGen, is applied to the problem of designing rare earth\nfree permanent magnets with promising results.",
            "author": [
                "Sourav Mal",
                "Gaurav Seal",
                "Prasenjit Sen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13328v1",
                "http://arxiv.org/pdf/2311.13328v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13326v1",
            "title": "Curriculum Learning and Imitation Learning for Model-free Control on\n  Financial Time-series",
            "updated": "2023-11-22T11:42:50Z",
            "published": "2023-11-22T11:42:50Z",
            "summary": "Curriculum learning and imitation learning have been leveraged extensively in\nthe robotics domain. However, minimal research has been done on leveraging\nthese ideas on control tasks over highly stochastic time-series data. Here, we\ntheoretically and empirically explore these approaches in a representative\ncontrol task over complex time-series data. We implement the fundamental ideas\nof curriculum learning via data augmentation, while imitation learning is\nimplemented via policy distillation from an oracle. Our findings reveal that\ncurriculum learning should be considered a novel direction in improving\ncontrol-task performance over complex time-series. Our ample random-seed\nout-sample empirics and ablation studies are highly encouraging for curriculum\nlearning for time-series control. These findings are especially encouraging as\nwe tune all overlapping hyperparameters on the baseline -- giving an advantage\nto the baseline. On the other hand, we find that imitation learning should be\nused with caution.",
            "author": [
                "Woosung Koh",
                "Insu Choi",
                "Yuntae Jang",
                "Gimin Kang",
                "Woo Chang Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13326v1",
                "http://arxiv.org/pdf/2311.13326v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "q-fin.PM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13325v1",
            "title": "AA-DL: AoI-Aware Deep Learning Approach for D2D-Assisted Industrial IoT",
            "updated": "2023-11-22T11:42:16Z",
            "published": "2023-11-22T11:42:16Z",
            "summary": "In real-time Industrial Internet of Things (IIoT), e.g., monitoring and\ncontrol scenarios, the freshness of data is crucial to maintain the system\nfunctionality and stability. In this paper, we propose an AoI-Aware Deep\nLearning (AA-DL) approach to minimize the Peak Age of Information (PAoI) in\nD2D-assisted IIoT networks. Particularly, we analyzed the success probability\nand the average PAoI via stochastic geometry, and formulate an optimization\nproblem with the objective to find the optimal scheduling policy that minimizes\nPAoI. In order to solve the non-convex scheduling problem, we develop a Neural\nNetwork (NN) structure that exploits the Geographic Location Information (GLI)\nalong with feedback stages to perform unsupervised learning over randomly\ndeployed networks. Our motivation is based on the observation that in various\ntransmission contexts, the wireless channel intensity is mainly influenced by\ndistancedependant path loss, which could be calculated using the GLI of each\nlink. The performance of the AA-DL method is evaluated via numerical results\nthat demonstrate the effectiveness of our proposed method to improve the PAoI\nperformance compared to a recent benchmark while maintains lower complexity\nagainst the conventional iterative optimization method.",
            "author": [
                "Hossam Farag",
                "Mohamed Ragab",
                "Cedomir Stefanovic"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13325v1",
                "http://arxiv.org/pdf/2311.13325v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13321v1",
            "title": "Revisiting Supervision for Continual Representation Learning",
            "updated": "2023-11-22T11:24:04Z",
            "published": "2023-11-22T11:24:04Z",
            "summary": "In the field of continual learning, models are designed to learn tasks one\nafter the other. While most research has centered on supervised continual\nlearning, recent studies have highlighted the strengths of self-supervised\ncontinual representation learning. The improved transferability of\nrepresentations built with self-supervised methods is often associated with the\nrole played by the multi-layer perceptron projector. In this work, we depart\nfrom this observation and reexamine the role of supervision in continual\nrepresentation learning. We reckon that additional information, such as human\nannotations, should not deteriorate the quality of representations. Our\nfindings show that supervised models when enhanced with a multi-layer\nperceptron head, can outperform self-supervised models in continual\nrepresentation learning.",
            "author": [
                "Daniel Marczak",
                "Sebastian Cygert",
                "Tomasz Trzci\u0144ski",
                "Bart\u0142omiej Twardowski"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13321v1",
                "http://arxiv.org/pdf/2311.13321v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13319v1",
            "title": "Deep Learning for Vascular Segmentation and Applications in Phase\n  Contrast Tomography Imaging",
            "updated": "2023-11-22T11:15:38Z",
            "published": "2023-11-22T11:15:38Z",
            "summary": "Automated blood vessel segmentation is vital for biomedical imaging, as\nvessel changes indicate many pathologies. Still, precise segmentation is\ndifficult due to the complexity of vascular structures, anatomical variations\nacross patients, the scarcity of annotated public datasets, and the quality of\nimages. We present a thorough literature review, highlighting the state of\nmachine learning techniques across diverse organs. Our goal is to provide a\nfoundation on the topic and identify a robust baseline model for application to\nvascular segmentation in a new imaging modality, Hierarchical Phase Contrast\nTomography (HiP CT). Introduced in 2020 at the European Synchrotron Radiation\nFacility, HiP CT enables 3D imaging of complete organs at an unprecedented\nresolution of ca. 20mm per voxel, with the capability for localized zooms in\nselected regions down to 1mm per voxel without sectioning. We have created a\ntraining dataset with double annotator validated vascular data from three\nkidneys imaged with HiP CT in the context of the Human Organ Atlas Project.\nFinally, utilising the nnU Net model, we conduct experiments to assess the\nmodels performance on both familiar and unseen samples, employing vessel\nspecific metrics. Our results show that while segmentations yielded reasonably\nhigh scores such as clDice values ranging from 0.82 to 0.88, certain errors\npersisted. Large vessels that collapsed due to the lack of hydrostatic pressure\n(HiP CT is an ex vivo technique) were segmented poorly. Moreover, decreased\nconnectivity in finer vessels and higher segmentation errors at vessel\nboundaries were observed. Such errors obstruct the understanding of the\nstructures by interrupting vascular tree connectivity. Through our review and\noutputs, we aim to set a benchmark for subsequent model evaluations using\nvarious modalities, especially with the HiP CT imaging database.",
            "author": [
                "Ekin Yagis",
                "Shahab Aslani",
                "Yashvardhan Jain",
                "Yang Zhou",
                "Shahrokh Rahmani",
                "Joseph Brunet",
                "Alexandre Bellier",
                "Christopher Werlein",
                "Maximilian Ackermann",
                "Danny Jonigk",
                "Paul Tafforeau",
                "Peter D Lee",
                "Claire Walsh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13319v1",
                "http://arxiv.org/pdf/2311.13319v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13297v1",
            "title": "Retargeting Visual Data with Deformation Fields",
            "updated": "2023-11-22T10:27:19Z",
            "published": "2023-11-22T10:27:19Z",
            "summary": "Seam carving is an image editing method that enable content-aware resizing,\nincluding operations like removing objects. However, the seam-finding strategy\nbased on dynamic programming or graph-cut limits its applications to broader\nvisual data formats and degrees of freedom for editing. Our observation is that\ndescribing the editing and retargeting of images more generally by a\ndisplacement field yields a generalisation of content-aware deformations. We\npropose to learn a deformation with a neural network that keeps the output\nplausible while trying to deform it only in places with low information\ncontent. This technique applies to different kinds of visual data, including\nimages, 3D scenes given as neural radiance fields, or even polygon meshes.\nExperiments conducted on different visual data show that our method achieves\nbetter content-aware retargeting compared to previous methods.",
            "author": [
                "Tim Elsner",
                "Julia Berger",
                "Tong Wu",
                "Victor Czech",
                "Lin Gao",
                "Leif Kobbelt"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13297v1",
                "http://arxiv.org/pdf/2311.13297v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13294v1",
            "title": "Probabilistic Inference in Reinforcement Learning Done Right",
            "updated": "2023-11-22T10:23:14Z",
            "published": "2023-11-22T10:23:14Z",
            "summary": "A popular perspective in Reinforcement learning (RL) casts the problem as\nprobabilistic inference on a graphical model of the Markov decision process\n(MDP). The core object of study is the probability of each state-action pair\nbeing visited under the optimal policy. Previous approaches to approximate this\nquantity can be arbitrarily poor, leading to algorithms that do not implement\ngenuine statistical inference and consequently do not perform well in\nchallenging problems. In this work, we undertake a rigorous Bayesian treatment\nof the posterior probability of state-action optimality and clarify how it\nflows through the MDP. We first reveal that this quantity can indeed be used to\ngenerate a policy that explores efficiently, as measured by regret.\nUnfortunately, computing it is intractable, so we derive a new variational\nBayesian approximation yielding a tractable convex optimization problem and\nestablish that the resulting policy also explores efficiently. We call our\napproach VAPOR and show that it has strong connections to Thompson sampling,\nK-learning, and maximum entropy exploration. We conclude with some experiments\ndemonstrating the performance advantage of a deep RL version of VAPOR.",
            "author": [
                "Jean Tarbouriech",
                "Tor Lattimore",
                "Brendan O'Donoghue"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13294v1",
                "http://arxiv.org/pdf/2311.13294v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13293v1",
            "title": "The Influence of Neural Networks on Hydropower Plant Management in\n  Agriculture: Addressing Challenges and Exploring Untapped Opportunities",
            "updated": "2023-11-22T10:22:59Z",
            "published": "2023-11-22T10:22:59Z",
            "summary": "Hydropower plants are crucial for stable renewable energy and serve as vital\nwater sources for sustainable agriculture. However, it is essential to assess\nthe current water management practices associated with hydropower plant\nmanagement software. A key concern is the potential conflict between\nelectricity generation and agricultural water needs. Prioritising water for\nelectricity generation can reduce irrigation availability in agriculture during\ncrucial periods like droughts, impacting crop yields and regional food\nsecurity. Coordination between electricity and agricultural water allocation is\nnecessary to ensure optimal and environmentally sound practices. Neural\nnetworks have become valuable tools for hydropower plant management, but their\nblack-box nature raises concerns about transparency in decision making.\nAdditionally, current approaches often do not take advantage of their potential\nto create a system that effectively balances water allocation.\n  This work is a call for attention and highlights the potential risks of\ndeploying neural network-based hydropower plant management software without\nproper scrutiny and control. To address these concerns, we propose the adoption\nof the Agriculture Conscious Hydropower Plant Management framework, aiming to\nmaximise electricity production while prioritising stable irrigation for\nagriculture. We also advocate reevaluating government-imposed minimum water\nguidelines for irrigation to ensure flexibility and effective water allocation.\nAdditionally, we suggest a set of regulatory measures to promote model\ntransparency and robustness, certifying software that makes conscious and\nintelligent water allocation decisions, ultimately safeguarding agriculture\nfrom undue strain during droughts.",
            "author": [
                "C. Coelho",
                "M. Fernanda P. Costa",
                "L. L. Ferr\u00e1s"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13293v1",
                "http://arxiv.org/pdf/2311.13293v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC",
                "68T07",
                "G.1.6; J.2; I.2.m"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13288v1",
            "title": "Observation of magnetically-induced transition intensity redistribution\n  in the onset of the hyperfine Paschen-Back regime",
            "updated": "2023-11-22T10:13:44Z",
            "published": "2023-11-22T10:13:44Z",
            "summary": "The Zeeman effect is an important topic in atomic spectroscopy. The induced\nchange in transition frequencies and amplitudes finds applications in the\nEarth-field-range magnetometry. At intermediate magnetic field amplitude $B\\sim\nB_0 = A_\\text{hfs}/\\mu_B$, where $A_\\text{hfs}$ is the magnetic dipole constant\nof the ground state, and $\\mu_B$ is the Bohr magneton ($B_0\\approx 1.7$ kG for\nCs), the rigorous rule $\\Delta F = 0, \\pm1$ is affected by the coupling between\nmagnetic sub-levels induced by the field. Transitions satisfying $\\Delta F =\n\\pm2$, referred to as magnetically-induced transitions, can be observed. Here,\nwe show that a significant redistribution of the Cs $6\\text{S}_{1/2}\\rightarrow\n6\\text{P}_{3/2}$ magnetically-induced transition intensities occurs with\nincreasing magnetic field. We observe that the strongest transition in the\ngroup $F_g=3\\rightarrow F_e=5$ ($\\sigma^+$ polarization) for $B<B_0$ cease to\nbe the strongest for $B>3 B_0$. On the other hand, the strongest transition in\nthe group $F_g=2\\rightarrow F_e=4$ ($\\sigma^-$ polarization) remains so for all\nour measurements with magnetic fields up to 9 kG. These results are in\nagreement with a theoretical model. The model predicts that similar\nobservations can be made for all alkali metals, including Na, K and Rb atoms.\nOur findings are important for magnetometers utilizing the Zeeman effect above\nEarth field, following the rapid development of micro-machined vapor-cell-based\nsensors.",
            "author": [
                "Armen Sargsyan",
                "Emmanuel Klinger",
                "Ara Tonoyan",
                "David Sarkisyan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13288v1",
                "http://arxiv.org/pdf/2311.13288v1"
            ],
            "primary_category": "physics.atom-ph",
            "category": [
                "physics.atom-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13285v1",
            "title": "Improving performance of heart rate time series classification by\n  grouping subjects",
            "updated": "2023-11-22T10:08:33Z",
            "published": "2023-11-22T10:08:33Z",
            "summary": "Unlike the more commonly analyzed ECG or PPG data for activity\nclassification, heart rate time series data is less detailed, often noisier and\ncan contain missing data points. Using the BigIdeasLab_STEP dataset, which\nincludes heart rate time series annotated with specific tasks performed by\nindividuals, we sought to determine if general classification was achievable.\nOur analyses showed that the accuracy is sensitive to the choice of\nwindow/stride size. Moreover, we found variable classification performances\nbetween subjects due to differences in the physical structure of their hearts.\nVarious techniques were used to minimize this variability. First of all,\nnormalization proved to be a crucial step and significantly improved the\nperformance. Secondly, grouping subjects and performing classification inside a\ngroup helped to improve performance and decrease inter-subject variability.\nFinally, we show that including handcrafted features as input to a deep\nlearning (DL) network improves the classification performance further.\nTogether, these findings indicate that heart rate time series can be utilized\nfor classification tasks like predicting activity. However, normalization or\ngrouping techniques need to be chosen carefully to minimize the issue of\nsubject variability.",
            "author": [
                "Michael Beekhuizen",
                "Arman Naseri",
                "David Tax",
                "Ivo van der Bilt",
                "Marcel Reinders"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13285v1",
                "http://arxiv.org/pdf/2311.13285v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13281v1",
            "title": "Intention and Context Elicitation with Large Language Models in the\n  Legal Aid Intake Process",
            "updated": "2023-11-22T10:04:29Z",
            "published": "2023-11-22T10:04:29Z",
            "summary": "Large Language Models (LLMs) and chatbots show significant promise in\nstreamlining the legal intake process. This advancement can greatly reduce the\nworkload and costs for legal aid organizations, improving availability while\nmaking legal assistance more accessible to a broader audience. However, a key\nchallenge with current LLMs is their tendency to overconfidently deliver an\nimmediate 'best guess' to a client's question based on the output distribution\nlearned over the training data. This approach often overlooks the client's\nactual intentions or the specifics of their legal situation. As a result,\nclients may not realize the importance of providing essential additional\ncontext or expressing their underlying intentions, which are crucial for their\nlegal cases. Traditionally, logic based decision trees have been used to\nautomate intake for specific access to justice issues, such as immigration and\neviction. But those solutions lack scalability. We demonstrate a\nproof-of-concept using LLMs to elicit and infer clients' underlying intentions\nand specific legal circumstances through free-form, language-based\ninteractions. We also propose future research directions to use supervised\nfine-tuning or offline reinforcement learning to automatically incorporate\nintention and context elicitation in chatbots without explicit prompting.",
            "author": [
                "Nick Goodson",
                "Rongfei Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13281v1",
                "http://arxiv.org/pdf/2311.13281v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13624v1",
            "title": "A Theoretical Insight into Attack and Defense of Gradient Leakage in\n  Transformer",
            "updated": "2023-11-22T09:58:01Z",
            "published": "2023-11-22T09:58:01Z",
            "summary": "The Deep Leakage from Gradient (DLG) attack has emerged as a prevalent and\nhighly effective method for extracting sensitive training data by inspecting\nexchanged gradients. This approach poses a substantial threat to the privacy of\nindividuals and organizations alike. This research presents a comprehensive\nanalysis of the gradient leakage method when applied specifically to\ntransformer-based models. Through meticulous examination, we showcase the\ncapability to accurately recover data solely from gradients and rigorously\ninvestigate the conditions under which gradient attacks can be executed,\nproviding compelling evidence. Furthermore, we reevaluate the approach of\nintroducing additional noise on gradients as a protective measure against\ngradient attacks. To address this, we outline a theoretical proof that analyzes\nthe associated privacy costs within the framework of differential privacy.\nAdditionally, we affirm the convergence of the Stochastic Gradient Descent\n(SGD) algorithm under perturbed gradients. The primary objective of this study\nis to augment the understanding of gradient leakage attack and defense\nstrategies while actively contributing to the development of privacy-preserving\ntechniques specifically tailored for transformer-based models. By shedding\nlight on the vulnerabilities and countermeasures associated with gradient\nleakage, this research aims to foster advancements in safeguarding sensitive\ndata and upholding privacy in the context of transformer-based models.",
            "author": [
                "Chenyang Li",
                "Zhao Song",
                "Weixin Wang",
                "Chiwun Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13624v1",
                "http://arxiv.org/pdf/2311.13624v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13279v1",
            "title": "Comprehensive Evaluation of GNN Training Systems: A Data Management\n  Perspective",
            "updated": "2023-11-22T09:55:20Z",
            "published": "2023-11-22T09:55:20Z",
            "summary": "Many Graph Neural Network (GNN) training systems have emerged recently to\nsupport efficient GNN training. Since GNNs embody complex data dependencies\nbetween training samples, the training of GNNs should address distinct\nchallenges different from DNN training in data management, such as data\npartitioning, batch preparation for mini-batch training, and data transferring\nbetween CPUs and GPUs. These factors, which take up a large proportion of\ntraining time, make data management in GNN training more significant. This\npaper reviews GNN training from a data management perspective and provides a\ncomprehensive analysis and evaluation of the representative approaches. We\nconduct extensive experiments on various benchmark datasets and show many\ninteresting and valuable results. We also provide some practical tips learned\nfrom these experiments, which are helpful for designing GNN training systems in\nthe future.",
            "author": [
                "Hao Yuan",
                "Yajiong Liu",
                "Yanfeng Zhang",
                "Xin Ai",
                "Qiange Wang",
                "Chaoyi Chen",
                "Yu Gu",
                "Ge Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13279v1",
                "http://arxiv.org/pdf/2311.13279v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13277v1",
            "title": "Hierarchical Matrix Factorization for Interpretable Collaborative\n  Filtering",
            "updated": "2023-11-22T09:53:57Z",
            "published": "2023-11-22T09:53:57Z",
            "summary": "Matrix factorization (MF) is a simple collaborative filtering technique that\nachieves superior recommendation accuracy by decomposing the user-item rating\nmatrix into user and item latent matrices. This approach relies on learning\nfrom user-item interactions, which may not effectively capture the underlying\nshared dependencies between users or items. Therefore, there is scope to\nexplicitly capture shared dependencies to further improve recommendation\naccuracy and the interpretability of learning results by summarizing user-item\ninteractions. Based on these insights, we propose \"Hierarchical Matrix\nFactorization\" (HMF), which incorporates clustering concepts to capture the\nhierarchy, where leaf nodes and other nodes correspond to users/items and\nclusters, respectively. Central to our approach, called hierarchical\nembeddings, is the additional decomposition of the user and item latent\nmatrices (embeddings) into probabilistic connection matrices, which link the\nhierarchy, and a root cluster latent matrix. Thus, each node is represented by\nthe weighted average of the embeddings of its parent clusters. The embeddings\nare differentiable, allowing simultaneous learning of interactions and\nclustering using a single gradient descent method. Furthermore, the obtained\ncluster-specific interactions naturally summarize user-item interactions and\nprovide interpretability. Experimental results on rating and ranking\npredictions demonstrated the competitiveness of HMF over vanilla and\nhierarchical MF methods, especially its robustness in sparse interactions.\nAdditionally, it was confirmed that the clustering integration of HMF has the\npotential for faster learning convergence and mitigation of overfitting\ncompared to MF, and also provides interpretability through a cluster-centered\ncase study.",
            "author": [
                "Kai Sugahara",
                "Kazushi Okamoto"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13277v1",
                "http://arxiv.org/pdf/2311.13277v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13267v1",
            "title": "FedFN: Feature Normalization for Alleviating Data Heterogeneity Problem\n  in Federated Learning",
            "updated": "2023-11-22T09:37:33Z",
            "published": "2023-11-22T09:37:33Z",
            "summary": "Federated Learning (FL) is a collaborative method for training models while\npreserving data privacy in decentralized settings. However, FL encounters\nchallenges related to data heterogeneity, which can result in performance\ndegradation. In our study, we observe that as data heterogeneity increases,\nfeature representation in the FedAVG model deteriorates more significantly\ncompared to classifier weight. Additionally, we observe that as data\nheterogeneity increases, the gap between higher feature norms for observed\nclasses, obtained from local models, and feature norms of unobserved classes\nwidens, in contrast to the behavior of classifier weight norms. This widening\ngap extends to encompass the feature norm disparities between local and the\nglobal models. To address these issues, we introduce Federated Averaging with\nFeature Normalization Update (FedFN), a straightforward learning method. We\ndemonstrate the superior performance of FedFN through extensive experiments,\neven when applied to pretrained ResNet18. Subsequently, we confirm the\napplicability of FedFN to foundation models.",
            "author": [
                "Seongyoon Kim",
                "Gihun Lee",
                "Jaehoon Oh",
                "Se-Young Yun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13267v1",
                "http://arxiv.org/pdf/2311.13267v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13265v2",
            "title": "Improved identification accuracy in equation learning via comprehensive\n  $\\boldsymbol{R^2}$-elimination and Bayesian model selection",
            "updated": "2023-11-27T09:40:19Z",
            "published": "2023-11-22T09:31:19Z",
            "summary": "In the field of equation learning, exhaustively considering all possible\nequations derived from a basis function dictionary is infeasible. Sparse\nregression and greedy algorithms have emerged as popular approaches to tackle\nthis challenge. However, the presence of multicollinearity poses difficulties\nfor sparse regression techniques, and greedy steps may inadvertently exclude\nterms of the true equation, leading to reduced identification accuracy. In this\narticle, we present an approach that strikes a balance between\ncomprehensiveness and efficiency in equation learning. Inspired by stepwise\nregression, our approach combines the coefficient of determination, $R^2$, and\nthe Bayesian model evidence, $p(\\boldsymbol y|\\mathcal M)$, in a novel way. Our\nprocedure is characterized by a comprehensive search with just a minor\nreduction of the model space at each iteration step. With two flavors of our\napproach and the adoption of $p(\\boldsymbol y|\\mathcal M)$ for bi-directional\nstepwise regression, we present a total of three new avenues for equation\nlearning. Through three extensive numerical experiments involving random\npolynomials and dynamical systems, we compare our approach against four\nstate-of-the-art methods and two standard approaches. The results demonstrate\nthat our comprehensive search approach surpasses all other methods in terms of\nidentification accuracy. In particular, the second flavor of our approach\nestablishes an efficient overfitting penalty solely based on $R^2$, which\nachieves highest rates of exact equation recovery.",
            "author": [
                "Daniel Nickelsen",
                "Bubacarr Bah"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13265v2",
                "http://arxiv.org/pdf/2311.13265v2"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.AI",
                "cs.LG",
                "cs.NA",
                "math.NA",
                "62-08, 62F15, 37M99, 62J99",
                "G.3; I.2.6; I.2.3; I.6.5"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13263v1",
            "title": "CMFDFormer: Transformer-based Copy-Move Forgery Detection with Continual\n  Learning",
            "updated": "2023-11-22T09:27:46Z",
            "published": "2023-11-22T09:27:46Z",
            "summary": "Copy-move forgery detection aims at detecting duplicated regions in a\nsuspected forged image, and deep learning based copy-move forgery detection\nmethods are in the ascendant. These deep learning based methods heavily rely on\nsynthetic training data, and the performance will degrade when facing new\ntasks. In this paper, we propose a Transformer-style copy-move forgery\ndetection network named as CMFDFormer, and provide a novel PCSD (Pooled Cube\nand Strip Distillation) continual learning framework to help CMFDFormer handle\nnew tasks. CMFDFormer consists of a MiT (Mix Transformer) backbone network and\na PHD (Pluggable Hybrid Decoder) mask prediction network. The MiT backbone\nnetwork is a Transformer-style network which is adopted on the basis of\ncomprehensive analyses with CNN-style and MLP-style backbones. The PHD network\nis constructed based on self-correlation computation, hierarchical feature\nintegration, a multi-scale cycle fully-connected block and a mask\nreconstruction block. The PHD network is applicable to feature extractors of\ndifferent styles for hierarchical multi-scale information extraction, achieving\ncomparable performance. Last but not least, we propose a PCSD continual\nlearning framework to improve the forgery detectability and avoid catastrophic\nforgetting when handling new tasks. Our continual learning framework restricts\nintermediate features from the PHD network, and takes advantage of both cube\npooling and strip pooling. Extensive experiments on publicly available datasets\ndemonstrate the good performance of CMFDFormer and the effectiveness of the\nPCSD continual learning framework.",
            "author": [
                "Yaqi Liu",
                "Chao Xia",
                "Song Xiao",
                "Qingxiao Guan",
                "Wenqian Dong",
                "Yifan Zhang",
                "Nenghai Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13263v1",
                "http://arxiv.org/pdf/2311.13263v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13262v1",
            "title": "The Rise of Creative Machines: Exploring the Impact of Generative AI",
            "updated": "2023-11-22T09:27:08Z",
            "published": "2023-11-22T09:27:08Z",
            "summary": "This study looks at how generative artificial intelligence (AI) can\nrevolutionize marketing, product development, and research. It discusses the\nlatest developments in the field, easy-to-use resources, and moral and social\nhazards. In addition to addressing mitigating techniques for issues like\nprejudice and disinformation, the debate emphasizes the significance of\nresponsible development through continual stakeholder communication and ethical\nprinciples.",
            "author": [
                "Saad Shaikh",
                "Rajat bendre",
                "Sakshi Mhaske"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13262v1",
                "http://arxiv.org/pdf/2311.13262v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13261v1",
            "title": "Immunohistochemistry guided segmentation of benign epithelial cells, in\n  situ lesions, and invasive epithelial cells in breast cancer slides",
            "updated": "2023-11-22T09:25:08Z",
            "published": "2023-11-22T09:25:08Z",
            "summary": "Digital pathology enables automatic analysis of histopathological sections\nusing artificial intelligence (AI). Automatic evaluation could improve\ndiagnostic efficiency and help find associations between morphological features\nand clinical outcome. For development of such prediction models, identifying\ninvasive epithelial cells, and separating these from benign epithelial cells\nand in situ lesions would be the first step. In this study, we aimed to develop\nan AI model for segmentation of epithelial cells in sections from breast\ncancer. We generated epithelial ground truth masks by restaining hematoxylin\nand eosin (HE) sections with cytokeratin (CK) AE1/AE3, and by pathologists'\nannotations. HE/CK image pairs were used to train a convolutional neural\nnetwork, and data augmentation was used to make the model more robust. Tissue\nmicroarrays (TMAs) from 839 patients, and whole slide images from two patients\nwere used for training and evaluation of the models. The sections were derived\nfrom four cohorts of breast cancer patients. TMAs from 21 patients from a fifth\ncohort was used as a second test set. In quantitative evaluation, a mean Dice\nscore of 0.70, 0.79, and 0.75 for invasive epithelial cells, benign epithelial\ncells, and in situ lesions, respectively, were achieved. In qualitative scoring\n(0-5) by pathologists, results were best for all epithelium and invasive\nepithelium, with scores of 4.7 and 4.4. Scores for benign epithelium and in\nsitu lesions were 3.7 and 2.0. The proposed model segmented epithelial cells in\nHE stained breast cancer slides well, but further work is needed for accurate\ndivision between the classes. Immunohistochemistry, together with pathologists'\nannotations, enabled the creation of accurate ground truths. The model is made\nfreely available in FastPathology and the code is available at\nhttps://github.com/AICAN-Research/breast-epithelium-segmentation",
            "author": [
                "Maren H\u00f8ib\u00f8",
                "Andr\u00e9 Pedersen",
                "Vibeke Grotnes Dale",
                "Sissel Marie Berget",
                "Borgny Ytterhus",
                "Cecilia Lindskog",
                "Elisabeth Wik",
                "Lars A. Akslen",
                "Ingerid Reinertsen",
                "Erik Smistad",
                "Marit Valla"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13261v1",
                "http://arxiv.org/pdf/2311.13261v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG",
                "I.4.6",
                "I.4.6; I.4.9; I.5.4; J.3"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13258v1",
            "title": "ViStruct: Visual Structural Knowledge Extraction via Curriculum Guided\n  Code-Vision Representation",
            "updated": "2023-11-22T09:23:34Z",
            "published": "2023-11-22T09:23:34Z",
            "summary": "State-of-the-art vision-language models (VLMs) still have limited performance\nin structural knowledge extraction, such as relations between objects. In this\nwork, we present ViStruct, a training framework to learn VLMs for effective\nvisual structural knowledge extraction. Two novel designs are incorporated.\nFirst, we propose to leverage the inherent structure of programming language to\ndepict visual structural information. This approach enables explicit and\nconsistent representation of visual structural information of multiple\ngranularities, such as concepts, relations, and events, in a well-organized\nstructured format. Second, we introduce curriculum-based learning for VLMs to\nprogressively comprehend visual structures, from fundamental visual concepts to\nintricate event structures. Our intuition is that lower-level knowledge may\ncontribute to complex visual structure understanding. Furthermore, we compile\nand release a collection of datasets tailored for visual structural knowledge\nextraction. We adopt a weakly-supervised approach to directly generate visual\nevent structures from captions for ViStruct training, capitalizing on abundant\nimage-caption pairs from the web. In experiments, we evaluate ViStruct on\nvisual structure prediction tasks, demonstrating its effectiveness in improving\nthe understanding of visual structures. The code is public at\n\\url{https://github.com/Yangyi-Chen/vi-struct}.",
            "author": [
                "Yangyi Chen",
                "Xingyao Wang",
                "Manling Li",
                "Derek Hoiem",
                "Heng Ji"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13258v1",
                "http://arxiv.org/pdf/2311.13258v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13623v1",
            "title": "Density Distribution-based Learning Framework for Addressing Online\n  Continual Learning Challenges",
            "updated": "2023-11-22T09:21:28Z",
            "published": "2023-11-22T09:21:28Z",
            "summary": "In this paper, we address the challenges of online Continual Learning (CL) by\nintroducing a density distribution-based learning framework. CL, especially the\nClass Incremental Learning, enables adaptation to new test distributions while\ncontinuously learning from a single-pass training data stream, which is more in\nline with the practical application requirements of real-world scenarios.\nHowever, existing CL methods often suffer from catastrophic forgetting and\nhigher computing costs due to complex algorithm designs, limiting their\npractical use. Our proposed framework overcomes these limitations by achieving\nsuperior average accuracy and time-space efficiency, bridging the performance\ngap between CL and classical machine learning. Specifically, we adopt an\nindependent Generative Kernel Density Estimation (GKDE) model for each CL task.\nDuring the testing stage, the GKDEs utilize a self-reported max probability\ndensity value to determine which one is responsible for predicting incoming\ntest instances. A GKDE-based learning objective can ensure that samples with\nthe same label are grouped together, while dissimilar instances are pushed\nfarther apart. Extensive experiments conducted on multiple CL datasets validate\nthe effectiveness of our proposed framework. Our method outperforms popular CL\napproaches by a significant margin, while maintaining competitive time-space\nefficiency, making our framework suitable for real-world applications. Code\nwill be available at https://github.com/xxxx/xxxx.",
            "author": [
                "Shilin Zhang",
                "Jiahui Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13623v1",
                "http://arxiv.org/pdf/2311.13623v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13254v1",
            "title": "DA-STC: Domain Adaptive Video Semantic Segmentation via Spatio-Temporal\n  Consistency",
            "updated": "2023-11-22T09:18:49Z",
            "published": "2023-11-22T09:18:49Z",
            "summary": "Video semantic segmentation is a pivotal aspect of video representation\nlearning. However, significant domain shifts present a challenge in effectively\nlearning invariant spatio-temporal features across the labeled source domain\nand unlabeled target domain for video semantic segmentation. To solve the\nchallenge, we propose a novel DA-STC method for domain adaptive video semantic\nsegmentation, which incorporates a bidirectional multi-level spatio-temporal\nfusion module and a category-aware spatio-temporal feature alignment module to\nfacilitate consistent learning for domain-invariant features. Firstly, we\nperform bidirectional spatio-temporal fusion at the image sequence level and\nshallow feature level, leading to the construction of two fused intermediate\nvideo domains. This prompts the video semantic segmentation model to\nconsistently learn spatio-temporal features of shared patch sequences which are\ninfluenced by domain-specific contexts, thereby mitigating the feature gap\nbetween the source and target domain. Secondly, we propose a category-aware\nfeature alignment module to promote the consistency of spatio-temporal\nfeatures, facilitating adaptation to the target domain. Specifically, we\nadaptively aggregate the domain-specific deep features of each category along\nspatio-temporal dimensions, which are further constrained to achieve\ncross-domain intra-class feature alignment and inter-class feature separation.\nExtensive experiments demonstrate the effectiveness of our method, which\nachieves state-of-the-art mIOUs on multiple challenging benchmarks.\nFurthermore, we extend the proposed DA-STC to the image domain, where it also\nexhibits superior performance for domain adaptive semantic segmentation. The\nsource code and models will be made available at\n\\url{https://github.com/ZHE-SAPI/DA-STC}.",
            "author": [
                "Zhe Zhang",
                "Gaochang Wu",
                "Jing Zhang",
                "Chunhua Shen",
                "Dacheng Tao",
                "Tianyou Chai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13254v1",
                "http://arxiv.org/pdf/2311.13254v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13250v1",
            "title": "Towards Hetero-Client Federated Multi-Task Learning",
            "updated": "2023-11-22T09:12:50Z",
            "published": "2023-11-22T09:12:50Z",
            "summary": "Federated Learning (FL) enables joint training across distributed clients\nusing their local data privately. Federated Multi-Task Learning (FMTL) builds\non FL to handle multiple tasks, assuming model congruity that identical model\narchitecture is deployed in each client. To relax this assumption and thus\nextend real-world applicability, we introduce a novel problem setting,\nHetero-Client Federated Multi-Task Learning (HC-FMTL), to accommodate diverse\ntask setups. The main challenge of HC-FMTL is the model incongruity issue that\ninvalidates conventional aggregation methods. It also escalates the\ndifficulties in accurate model aggregation to deal with data and task\nheterogeneity inherent in FMTL. To address these challenges, we propose the\nFedHCA$^2$ framework, which allows for federated training of personalized\nmodels by modeling relationships among heterogeneous clients. Drawing on our\ntheoretical insights into the difference between multi-task and federated\noptimization, we propose the Hyper Conflict-Averse Aggregation scheme to\nmitigate conflicts during encoder updates. Additionally, inspired by task\ninteraction in MTL, the Hyper Cross Attention Aggregation scheme uses\nlayer-wise cross attention to enhance decoder interactions while alleviating\nmodel incongruity. Moreover, we employ learnable Hyper Aggregation Weights for\neach client to customize personalized parameter updates. Extensive experiments\ndemonstrate the superior performance of FedHCA$^2$ in various HC-FMTL scenarios\ncompared to representative methods. Our code will be made publicly available.",
            "author": [
                "Yuxiang Lu",
                "Suizhi Huang",
                "Yuwen Yang",
                "Shalayiding Sirejiding",
                "Yue Ding",
                "Hongtao Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13250v1",
                "http://arxiv.org/pdf/2311.13250v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14741v1",
            "title": "@ve: A Chatbot for Latin",
            "updated": "2023-11-22T09:06:11Z",
            "published": "2023-11-22T09:06:11Z",
            "summary": "Dead, extinct, and endangered languages have been preserved primarily through\naudio conservation and the collection and digitization of scripts and have been\npromoted through targeted language acquisition efforts. Another possibility\nwould be to build conversational agents that can master these languages. This\nwould provide an artificial, active conversational partner which has knowledge\nof the vocabulary and grammar, and one learns with it in a different way. The\nchatbot @ve, with which one can communicate in Latin, was developed in\n2022/2023 based on GPT-3.0. It was additionally equipped with a manually\ncreated knowledge base. After conceptual groundwork, this paper presents the\npreparation and implementation of the project. In addition, it summarizes the\ntest that a Latin expert conducted with the chatbot. A critical discussion\nelaborates advantages and disadvantages. @ve could be a new tool for teaching\nLatin in a memorable and entertaining way through dialogue. However, the\npresent implementation is still too prone to glitches for stand-alone use -\ni.e., without the accompaniment of a teacher. The use of GPT-4 could be a\nsolution as well as the extension of the knowledge base. In conclusion, it can\nbe argued that conversational agents are an innovative approach to promoting\nand preserving languages.",
            "author": [
                "Oliver Bendel",
                "Karim N'diaye"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14741v1",
                "http://arxiv.org/pdf/2311.14741v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.RO",
                "I.2; K.3"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13247v1",
            "title": "A projected nonlinear state-space model for forecasting time series\n  signals",
            "updated": "2023-11-22T09:05:37Z",
            "published": "2023-11-22T09:05:37Z",
            "summary": "Learning and forecasting stochastic time series is essential in various\nscientific fields. However, despite the proposals of nonlinear filters and\ndeep-learning methods, it remains challenging to capture nonlinear dynamics\nfrom a few noisy samples and predict future trajectories with uncertainty\nestimates while maintaining computational efficiency. Here, we propose a fast\nalgorithm to learn and forecast nonlinear dynamics from noisy time series data.\nA key feature of the proposed model is kernel functions applied to projected\nlines, enabling fast and efficient capture of nonlinearities in the latent\ndynamics. Through empirical case studies and benchmarking, the model\ndemonstrates its effectiveness in learning and forecasting complex nonlinear\ndynamics, offering a valuable tool for researchers and practitioners in time\nseries analysis.",
            "author": [
                "Christian Donner",
                "Anuj Mishra",
                "Hideaki Shimazaki"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13247v1",
                "http://arxiv.org/pdf/2311.13247v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13246v1",
            "title": "Automatic Instruction Optimization for Open-source LLM Instruction\n  Tuning",
            "updated": "2023-11-22T09:04:57Z",
            "published": "2023-11-22T09:04:57Z",
            "summary": "Instruction tuning is crucial for enabling Language Learning Models (LLMs) in\nresponding to human instructions. The quality of instruction pairs used for\ntuning greatly affects the performance of LLMs. However, the manual creation of\nhigh-quality instruction datasets is costly, leading to the adoption of\nautomatic generation of instruction pairs by LLMs as a popular alternative in\nthe training of open-source LLMs. To ensure the high quality of LLM-generated\ninstruction datasets, several approaches have been proposed. Nevertheless,\nexisting methods either compromise dataset integrity by filtering a large\nproportion of samples, or are unsuitable for industrial applications. In this\npaper, instead of discarding low-quality samples, we propose CoachLM, a novel\napproach to enhance the quality of instruction datasets through automatic\nrevisions on samples in the dataset. CoachLM is trained from the samples\nrevised by human experts and significantly increases the proportion of\nhigh-quality samples in the dataset from 17.7% to 78.9%. The effectiveness of\nCoachLM is further assessed on various real-world instruction test sets. The\nresults show that CoachLM improves the instruction-following capabilities of\nthe instruction-tuned LLM by an average of 29.9%, which even surpasses larger\nLLMs with nearly twice the number of parameters. Furthermore, CoachLM is\nsuccessfully deployed in a data management system for LLMs at Huawei, resulting\nin an efficiency improvement of up to 20% in the cleaning of 40k real-world\ninstruction pairs. We release the training data and code of CoachLM\n(https://github.com/lunyiliu/CoachLM).",
            "author": [
                "Yilun Liu",
                "Shimin Tao",
                "Xiaofeng Zhao",
                "Ming Zhu",
                "Wenbing Ma",
                "Junhao Zhu",
                "Chang Su",
                "Yutai Hou",
                "Miao Zhang",
                "Min Zhang",
                "Hongxia Ma",
                "Li Zhang",
                "Hao Yang",
                "Yanfei Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13246v1",
                "http://arxiv.org/pdf/2311.13246v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13245v1",
            "title": "A model-free approach to fingertip slip and disturbance detection for\n  grasp stability inference",
            "updated": "2023-11-22T09:04:26Z",
            "published": "2023-11-22T09:04:26Z",
            "summary": "Robotic capacities in object manipulation are incomparable to those of\nhumans. Besides years of learning, humans rely heavily on the richness of\ninformation from physical interaction with the environment. In particular,\ntactile sensing is crucial in providing such rich feedback. Despite its\npotential contributions to robotic manipulation, tactile sensing is less\nexploited; mainly due to the complexity of the time series provided by tactile\nsensors. In this work, we propose a method for assessing grasp stability using\ntactile sensing. More specifically, we propose a methodology to extract\ntask-relevant features and design efficient classifiers to detect object\nslippage with respect to individual fingertips. We compare two classification\nmodels: support vector machine and logistic regression. We use highly sensitive\nUskin tactile sensors mounted on an Allegro hand to test and validate our\nmethod. Our results demonstrate that the proposed method is effective in\nslippage detection in an online fashion.",
            "author": [
                "Dounia Kitouni",
                "Mahdi Khoramshahi",
                "Veronique Perdereau"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13245v1",
                "http://arxiv.org/pdf/2311.13245v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "eess.SP",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13244v1",
            "title": "Hard Label Black Box Node Injection Attack on Graph Neural Networks",
            "updated": "2023-11-22T09:02:04Z",
            "published": "2023-11-22T09:02:04Z",
            "summary": "While graph neural networks have achieved state-of-the-art performances in\nmany real-world tasks including graph classification and node classification,\nrecent works have demonstrated they are also extremely vulnerable to\nadversarial attacks. Most previous works have focused on attacking node\nclassification networks under impractical white-box scenarios. In this work, we\nwill propose a non-targeted Hard Label Black Box Node Injection Attack on Graph\nNeural Networks, which to the best of our knowledge, is the first of its kind.\nUnder this setting, more real world tasks can be studied because our attack\nassumes no prior knowledge about (1): the model architecture of the GNN we are\nattacking; (2): the model's gradients; (3): the output logits of the target GNN\nmodel. Our attack is based on an existing edge perturbation attack, from which\nwe restrict the optimization process to formulate a node injection attack. In\nthe work, we will evaluate the performance of the attack using three datasets,\nCOIL-DEL, IMDB-BINARY, and NCI1.",
            "author": [
                "Yu Zhou",
                "Zihao Dong",
                "Guofeng Zhang",
                "Jingchen Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13244v1",
                "http://arxiv.org/pdf/2311.13244v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14740v1",
            "title": "AutoKG: Efficient Automated Knowledge Graph Generation for Language\n  Models",
            "updated": "2023-11-22T08:58:25Z",
            "published": "2023-11-22T08:58:25Z",
            "summary": "Traditional methods of linking large language models (LLMs) to knowledge\nbases via the semantic similarity search often fall short of capturing complex\nrelational dynamics. To address these limitations, we introduce AutoKG, a\nlightweight and efficient approach for automated knowledge graph (KG)\nconstruction. For a given knowledge base consisting of text blocks, AutoKG\nfirst extracts keywords using a LLM and then evaluates the relationship weight\nbetween each pair of keywords using graph Laplace learning. We employ a hybrid\nsearch scheme combining vector similarity and graph-based associations to\nenrich LLM responses. Preliminary experiments demonstrate that AutoKG offers a\nmore comprehensive and interconnected knowledge retrieval mechanism compared to\nthe semantic similarity search, thereby enhancing the capabilities of LLMs in\ngenerating more insightful and relevant outputs.",
            "author": [
                "Bohan Chen",
                "Andrea L. Bertozzi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14740v1",
                "http://arxiv.org/pdf/2311.14740v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.00037v1",
            "title": "Photonic Neural Networks and Optics-informed Deep Learning Fundamentals",
            "updated": "2023-11-22T08:46:34Z",
            "published": "2023-11-22T08:46:34Z",
            "summary": "The recent explosive compute growth, mainly fueled by the boost of AI and\nDNNs, is currently instigating the demand for a novel computing paradigm that\ncan overcome the insurmountable barriers imposed by conventional electronic\ncomputing architectures. PNNs implemented on silicon integration platforms\nstand out as a promising candidate to endow NN hardware, offering the potential\nfor energy efficient and ultra-fast computations through the utilization of the\nunique primitives of photonics i.e. energy efficiency, THz bandwidth and\nlow-latency. Thus far, several demonstrations have revealed the huge potential\nof PNNs in performing both linear and non-linear NN operations at unparalleled\nspeed and energy consumption metrics. Transforming this potential into a\ntangible reality for DL applications requires, however, a deep understanding of\nthe basic PNN principles, requirements and challenges across all constituent\narchitectural, technological and training aspects. In this tutorial, we,\ninitially, review the principles of DNNs along with their fundamental building\nblocks, analyzing also the key mathematical operations needed for their\ncomputation in a photonic hardware. Then, we investigate, through an intuitive\nmathematical analysis, the interdependence of bit precision and energy\nefficiency in analog photonic circuitry, discussing the opportunities and\nchallenges of PNNs. Followingly, a performance overview of PNN architectures,\nweight technologies and activation functions is presented, summarizing their\nimpact in speed, scalability and power consumption. Finally, we provide an\nholistic overview of the optics-informed NN training framework that\nincorporates the physical properties of photonic building blocks into the\ntraining process in order to improve the NN classification accuracy and\neffectively elevate neuromorphic photonic hardware into high-performance DL\ncomputational settings.",
            "author": [
                "A. Tsakyridis",
                "M. Moralis-Pegios",
                "G. Giamougiannis",
                "M. Kirtas",
                "N. Passalis",
                "A. Tefas",
                "N. Pleros"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00037v1",
                "http://arxiv.org/pdf/2312.00037v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics",
                "cs.ET"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13231v2",
            "title": "Using Human Feedback to Fine-tune Diffusion Models without Any Reward\n  Model",
            "updated": "2023-11-23T11:56:46Z",
            "published": "2023-11-22T08:42:46Z",
            "summary": "Using reinforcement learning with human feedback (RLHF) has shown significant\npromise in fine-tuning diffusion models. Previous methods start by training a\nreward model that aligns with human preferences, then leverage RL techniques to\nfine-tune the underlying models. However, crafting an efficient reward model\ndemands extensive datasets, optimal architecture, and manual hyperparameter\ntuning, making the process both time and cost-intensive. The direct preference\noptimization (DPO) method, effective in fine-tuning large language models,\neliminates the necessity for a reward model. However, the extensive GPU memory\nrequirement of the diffusion model's denoising process hinders the direct\napplication of the DPO method. To address this issue, we introduce the Direct\nPreference for Denoising Diffusion Policy Optimization (D3PO) method to\ndirectly fine-tune diffusion models. The theoretical analysis demonstrates that\nalthough D3PO omits training a reward model, it effectively functions as the\noptimal reward model trained using human feedback data to guide the learning\nprocess. This approach requires no training of a reward model, proving to be\nmore direct, cost-effective, and minimizing computational overhead. In\nexperiments, our method uses the relative scale of objectives as a proxy for\nhuman preference, delivering comparable results to methods using ground-truth\nrewards. Moreover, D3PO demonstrates the ability to reduce image distortion\nrates and generate safer images, overcoming challenges lacking robust reward\nmodels. Our code is publicly available in\nhttps://github.com/yk7333/D3PO/tree/main.",
            "author": [
                "Kai Yang",
                "Jian Tao",
                "Jiafei Lyu",
                "Chunjiang Ge",
                "Jiaxin Chen",
                "Qimai Li",
                "Weihan Shen",
                "Xiaolong Zhu",
                "Xiu Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13231v2",
                "http://arxiv.org/pdf/2311.13231v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13226v1",
            "title": "Robot at the Mirror: Learning to Imitate via Associating Self-supervised\n  Models",
            "updated": "2023-11-22T08:30:20Z",
            "published": "2023-11-22T08:30:20Z",
            "summary": "We introduce an approach to building a custom model from ready-made\nself-supervised models via their associating instead of training and\nfine-tuning. We demonstrate it with an example of a humanoid robot looking at\nthe mirror and learning to detect the 3D pose of its own body from the image it\nperceives. To build our model, we first obtain features from the visual input\nand the postures of the robot's body via models prepared before the robot's\noperation. Then, we map their corresponding latent spaces by a sample-efficient\nrobot's self-exploration at the mirror. In this way, the robot builds the\nsolicited 3D pose detector, which quality is immediately perfect on the\nacquired samples instead of obtaining the quality gradually. The mapping, which\nemploys associating the pairs of feature vectors, is then implemented in the\nsame way as the key-value mechanism of the famous transformer models. Finally,\ndeploying our model for imitation to a simulated robot allows us to study, tune\nup, and systematically evaluate its hyperparameters without the involvement of\nthe human counterpart, advancing our previous research.",
            "author": [
                "Andrej L\u00fa\u010dny",
                "Krist\u00edna Malinovsk\u00e1",
                "Igor Farka\u0161"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13226v1",
                "http://arxiv.org/pdf/2311.13226v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13225v1",
            "title": "NeutronOrch: Rethinking Sample-based GNN Training under CPU-GPU\n  Heterogeneous Environments",
            "updated": "2023-11-22T08:26:42Z",
            "published": "2023-11-22T08:26:42Z",
            "summary": "Graph Neural Networks (GNNs) have demonstrated outstanding performance in\nvarious applications. Existing frameworks utilize CPU-GPU heterogeneous\nenvironments to train GNN models and integrate mini-batch and sampling\ntechniques to overcome the GPU memory limitation. In CPU-GPU heterogeneous\nenvironments, we can divide sample-based GNN training into three steps: sample,\ngather, and train. Existing GNN systems use different task orchestrating\nmethods to employ each step on CPU or GPU. After extensive experiments and\nanalysis, we find that existing task orchestrating methods fail to fully\nutilize the heterogeneous resources, limited by inefficient CPU processing or\nGPU resource contention. In this paper, we propose NeutronOrch, a system for\nsample-based GNN training that incorporates a layer-based task orchestrating\nmethod and ensures balanced utilization of the CPU and GPU. NeutronOrch\ndecouples the training process by layer and pushes down the training task of\nthe bottom layer to the CPU. This significantly reduces the computational load\nand memory footprint of GPU training. To avoid inefficient CPU processing,\nNeutronOrch only offloads the training of frequently accessed vertices to the\nCPU and lets GPU reuse their embeddings with bounded staleness. Furthermore,\nNeutronOrch provides a fine-grained pipeline design for the layer-based task\norchestrating method, fully overlapping different tasks on heterogeneous\nresources while strictly guaranteeing bounded staleness. The experimental\nresults show that compared with the state-of-the-art GNN systems, NeutronOrch\ncan achieve up to 4.61x performance speedup.",
            "author": [
                "Xin Ai",
                "Qiange Wang",
                "Chunyu Cao",
                "Yanfeng Zhang",
                "Chaoyi Chen",
                "Hao Yuan",
                "Yu Gu",
                "Ge Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13225v1",
                "http://arxiv.org/pdf/2311.13225v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13222v1",
            "title": "Towards Detecting, Recognizing, and Parsing the Address Information from\n  Bangla Signboard: A Deep Learning-based Approach",
            "updated": "2023-11-22T08:25:15Z",
            "published": "2023-11-22T08:25:15Z",
            "summary": "Retrieving textual information from natural scene images is an active\nresearch area in the field of computer vision with numerous practical\napplications. Detecting text regions and extracting text from signboards is a\nchallenging problem due to special characteristics like reflecting lights,\nuneven illumination, or shadows found in real-life natural scene images. With\nthe advent of deep learning-based methods, different sophisticated techniques\nhave been proposed for text detection and text recognition from the natural\nscene. Though a significant amount of effort has been devoted to extracting\nnatural scene text for resourceful languages like English, little has been done\nfor low-resource languages like Bangla. In this research work, we have proposed\nan end-to-end system with deep learning-based models for efficiently detecting,\nrecognizing, correcting, and parsing address information from Bangla\nsignboards. We have created manually annotated datasets and synthetic datasets\nto train signboard detection, address text detection, address text recognition,\naddress text correction, and address text parser models. We have conducted a\ncomparative study among different CTC-based and Encoder-Decoder model\narchitectures for Bangla address text recognition. Moreover, we have designed a\nnovel address text correction model using a sequence-to-sequence\ntransformer-based network to improve the performance of Bangla address text\nrecognition model by post-correction. Finally, we have developed a Bangla\naddress text parser using the state-of-the-art transformer-based pre-trained\nlanguage model.",
            "author": [
                "Hasan Murad",
                "Mohammed Eunus Ali"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13222v1",
                "http://arxiv.org/pdf/2311.13222v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13218v2",
            "title": "Alleviating Barren Plateaus in Parameterized Quantum Machine Learning\n  Circuits: Investigating Advanced Parameter Initialization Strategies",
            "updated": "2023-12-05T07:17:51Z",
            "published": "2023-11-22T08:07:53Z",
            "summary": "Parameterized quantum circuits (PQCs) have emerged as a foundational element\nin the development and applications of quantum algorithms. However, when\ninitialized with random parameter values, PQCs often exhibit barren plateaus\n(BP). These plateaus, characterized by vanishing gradients with an increasing\nnumber of qubits, hinder optimization in quantum algorithms. In this paper, we\nanalyze the impact of state-of-the-art parameter initialization strategies from\nclassical machine learning in random PQCs from the aspect of BP phenomenon. Our\ninvestigation encompasses a spectrum of initialization techniques, including\nrandom, Xavier (both normal and uniform variants), He, LeCun, and Orthogonal\nmethods. Empirical assessment reveals a pronounced reduction in variance decay\nof gradients across all these methodologies compared to the randomly\ninitialized PQCs. Specifically, the Xavier initialization technique outperforms\nthe rest, showing a 62\\% improvement in variance decay compared to the random\ninitialization. The He, Lecun, and orthogonal methods also display\nimprovements, with respective enhancements of 32\\%, 28\\%, and 26\\%. This\ncompellingly suggests that the adoption of these existing initialization\ntechniques holds the potential to significantly amplify the training efficacy\nof Quantum Neural Networks (QNNs), a subclass of PQCs. Demonstrating this\neffect, we employ the identified techniques to train QNNs for learning the\nidentity function, effectively mitigating the adverse effects of BPs. The\ntraining performance, ranked from the best to the worst, aligns with the\nvariance decay enhancement as outlined above. This paper underscores the role\nof tailored parameter initialization in mitigating the BP problem and\neventually enhancing the training dynamics of QNNs.",
            "author": [
                "Muhammad Kashif",
                "Muhammad Rashid",
                "Saif Al-Kuwari",
                "Muhammad Shafique"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13218v2",
                "http://arxiv.org/pdf/2311.13218v2"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.03716v1",
            "title": "Co-guiding for Multi-intent Spoken Language Understanding",
            "updated": "2023-11-22T08:06:22Z",
            "published": "2023-11-22T08:06:22Z",
            "summary": "Recent graph-based models for multi-intent SLU have obtained promising\nresults through modeling the guidance from the prediction of intents to the\ndecoding of slot filling. However, existing methods (1) only model the\nunidirectional guidance from intent to slot, while there are bidirectional\ninter-correlations between intent and slot; (2) adopt homogeneous graphs to\nmodel the interactions between the slot semantics nodes and intent label nodes,\nwhich limit the performance. In this paper, we propose a novel model termed\nCo-guiding Net, which implements a two-stage framework achieving the mutual\nguidances between the two tasks. In the first stage, the initial estimated\nlabels of both tasks are produced, and then they are leveraged in the second\nstage to model the mutual guidances. Specifically, we propose two heterogeneous\ngraph attention networks working on the proposed two heterogeneous semantics\nlabel graphs, which effectively represent the relations among the semantics\nnodes and label nodes. Besides, we further propose Co-guiding-SCL Net, which\nexploits the single-task and dual-task semantics contrastive relations. For the\nfirst stage, we propose single-task supervised contrastive learning, and for\nthe second stage, we propose co-guiding supervised contrastive learning, which\nconsiders the two tasks' mutual guidances in the contrastive learning\nprocedure. Experiment results on multi-intent SLU show that our model\noutperforms existing models by a large margin, obtaining a relative improvement\nof 21.3% over the previous best model on MixATIS dataset in overall accuracy.\nWe also evaluate our model on the zero-shot cross-lingual scenario and the\nresults show that our model can relatively improve the state-of-the-art model\nby 33.5% on average in terms of overall accuracy for the total 9 languages.",
            "author": [
                "Bowen Xing",
                "Ivor W. Tsang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03716v1",
                "http://arxiv.org/pdf/2312.03716v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13213v1",
            "title": "Artificial Intelligence in the Service of Entrepreneurial Finance:\n  Knowledge Structure and the Foundational Algorithmic Paradigm",
            "updated": "2023-11-22T07:58:46Z",
            "published": "2023-11-22T07:58:46Z",
            "summary": "While the application of Artificial Intelligence in Finance has a long\ntradition, its potential in Entrepreneurship has been intensively explored only\nrecently. In this context, Entrepreneurial Finance is a particularly fertile\nground for future Artificial Intelligence proliferation. To support the latter,\nthe study provides a bibliometric review of Artificial Intelligence\napplications in (1) entrepreneurial finance literature, and (2) corporate\nfinance literature with implications for Entrepreneurship. Rigorous search and\nscreening procedures of the scientific database Web of Science Core Collection\nresulted in the identification of 1890 relevant journal articles subjected to\nanalysis. The bibliometric analysis gives a rich insight into the knowledge\nfield's conceptual, intellectual, and social structure, indicating nascent and\nunderdeveloped research directions. As far as we were able to identify, this is\nthe first study to map and bibliometrically analyze the academic field\nconcerning the relationship between Artificial Intelligence, Entrepreneurship,\nand Finance, and the first review that deals with Artificial Intelligence\nmethods in Entrepreneurship. According to the results, Artificial Neural\nNetwork, Deep Neural Network and Support Vector Machine are highly represented\nin almost all identified topic niches. At the same time, applying Topic\nModeling, Fuzzy Neural Network and Growing Hierarchical Self-organizing Map is\nquite rare. As an element of the research, and before final remarks, the\narticle deals as well with a discussion of certain gaps in the relationship\nbetween Computer Science and Economics. These gaps do represent problems in the\napplication of Artificial Intelligence in Economic Science. As a way to at\nleast in part remedy this situation, the foundational paradigm and the bespoke\ndemonstration of the Monte Carlo randomized algorithm are presented.",
            "author": [
                "Robert Kudeli\u0107",
                "Tamara \u0160maguc",
                "Sherry Robinson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13213v1",
                "http://arxiv.org/pdf/2311.13213v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13202v1",
            "title": "Robust Multi-Model Subset Selection",
            "updated": "2023-11-22T07:11:17Z",
            "published": "2023-11-22T07:11:17Z",
            "summary": "Modern datasets in biology and chemistry are often characterized by the\npresence of a large number of variables and outlying samples due to measurement\nerrors or rare biological and chemical profiles. To handle the characteristics\nof such datasets we introduce a method to learn a robust ensemble comprised of\na small number of sparse, diverse and robust models, the first of its kind in\nthe literature. The degree to which the models are sparse, diverse and\nresistant to data contamination is driven directly by the data based on a\ncross-validation criterion. We establish the finite-sample breakdown of the\nensembles and the models that comprise them, and we develop a tailored\ncomputing algorithm to learn the ensembles by leveraging recent developments in\nl0 optimization. Our extensive numerical experiments on synthetic and\nartificially contaminated real datasets from genomics and cheminformatics\ndemonstrate the competitive advantage of our method over state-of-the-art\nsparse and robust methods. We also demonstrate the applicability of our\nproposal on a cardiac allograft vasculopathy dataset.",
            "author": [
                "Anthony-Alexander Christidis",
                "Gabriela Cohen-Freue"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13202v1",
                "http://arxiv.org/pdf/2311.13202v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13200v1",
            "title": "Self-guided Few-shot Semantic Segmentation for Remote Sensing Imagery\n  Based on Large Vision Models",
            "updated": "2023-11-22T07:07:55Z",
            "published": "2023-11-22T07:07:55Z",
            "summary": "The Segment Anything Model (SAM) exhibits remarkable versatility and\nzero-shot learning abilities, owing largely to its extensive training data\n(SA-1B). Recognizing SAM's dependency on manual guidance given its\ncategory-agnostic nature, we identified unexplored potential within few-shot\nsemantic segmentation tasks for remote sensing imagery. This research\nintroduces a structured framework designed for the automation of few-shot\nsemantic segmentation. It utilizes the SAM model and facilitates a more\nefficient generation of semantically discernible segmentation outcomes. Central\nto our methodology is a novel automatic prompt learning approach, leveraging\nprior guided masks to produce coarse pixel-wise prompts for SAM. Extensive\nexperiments on the DLRSD datasets underline the superiority of our approach,\noutperforming other available few-shot methodologies.",
            "author": [
                "Xiyu Qi",
                "Yifan Wu",
                "Yongqiang Mao",
                "Wenhui Zhang",
                "Yidan Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13200v1",
                "http://arxiv.org/pdf/2311.13200v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13617v1",
            "title": "Boosting3D: High-Fidelity Image-to-3D by Boosting 2D Diffusion Prior to\n  3D Prior with Progressive Learning",
            "updated": "2023-11-22T06:50:52Z",
            "published": "2023-11-22T06:50:52Z",
            "summary": "We present Boosting3D, a multi-stage single image-to-3D generation method\nthat can robustly generate reasonable 3D objects in different data domains. The\npoint of this work is to solve the view consistency problem in single\nimage-guided 3D generation by modeling a reasonable geometric structure. For\nthis purpose, we propose to utilize better 3D prior to training the NeRF. More\nspecifically, we train an object-level LoRA for the target object using\noriginal image and the rendering output of NeRF. And then we train the LoRA and\nNeRF using a progressive training strategy. The LoRA and NeRF will boost each\nother while training. After the progressive training, the LoRA learns the 3D\ninformation of the generated object and eventually turns to an object-level 3D\nprior. In the final stage, we extract the mesh from the trained NeRF and use\nthe trained LoRA to optimize the structure and appearance of the mesh. The\nexperiments demonstrate the effectiveness of the proposed method. Boosting3D\nlearns object-specific 3D prior which is beyond the ability of pre-trained\ndiffusion priors and achieves state-of-the-art performance in the single\nimage-to-3d generation task.",
            "author": [
                "Kai Yu",
                "Jinlin Liu",
                "Mengyang Feng",
                "Miaomiao Cui",
                "Xuansong Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13617v1",
                "http://arxiv.org/pdf/2311.13617v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13188v1",
            "title": "Cracking the Code of Negative Transfer: A Cooperative Game Theoretic\n  Approach for Cross-Domain Sequential Recommendation",
            "updated": "2023-11-22T06:30:54Z",
            "published": "2023-11-22T06:30:54Z",
            "summary": "This paper investigates Cross-Domain Sequential Recommendation (CDSR), a\npromising method that uses information from multiple domains (more than three)\nto generate accurate and diverse recommendations, and takes into account the\nsequential nature of user interactions. The effectiveness of these systems\noften depends on the complex interplay among the multiple domains. In this\ndynamic landscape, the problem of negative transfer arises, where heterogeneous\nknowledge between dissimilar domains leads to performance degradation due to\ndifferences in user preferences across these domains. As a remedy, we propose a\nnew CDSR framework that addresses the problem of negative transfer by assessing\nthe extent of negative transfer from one domain to another and adaptively\nassigning low weight values to the corresponding prediction losses. To this\nend, the amount of negative transfer is estimated by measuring the marginal\ncontribution of each domain to model performance based on a cooperative game\ntheory. In addition, a hierarchical contrastive learning approach that\nincorporates information from the sequence of coarse-level categories into that\nof fine-level categories (e.g., item level) when implementing contrastive\nlearning was developed to mitigate negative transfer. Despite the potentially\nlow relevance between domains at the fine-level, there may be higher relevance\nat the category level due to its generalised and broader preferences. We show\nthat our model is superior to prior works in terms of model performance on two\nreal-world datasets across ten different domains.",
            "author": [
                "Chung Park",
                "Taesan Kim",
                "Taekyoon Choi",
                "Junui Hong",
                "Yelim Yu",
                "Mincheol Cho",
                "Kyunam Lee",
                "Sungil Ryu",
                "Hyungjun Yoon",
                "Minsung Choi",
                "Jaegul Choo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13188v1",
                "http://arxiv.org/pdf/2311.13188v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13184v1",
            "title": "AS-LLM: When Algorithm Selection Meets Large Language Model",
            "updated": "2023-11-22T06:23:18Z",
            "published": "2023-11-22T06:23:18Z",
            "summary": "Algorithm selection aims to identify the most suitable algorithm for solving\na specific problem before execution, which has become a critical process of the\nAutoML. Current mainstream algorithm selection techniques rely heavily on\nfeature representations of various problems and employ the performance of each\nalgorithm as supervised information. However, there is a significant research\ngap concerning the consideration of algorithm features. This gap is primarily\nattributed to the inherent complexity of algorithms, making it particularly\nchallenging to find a universally effective feature extraction method that is\napplicable across a diverse range of algorithms. Unfortunately, neglecting this\naspect undoubtedly impacts the accuracy of algorithm selection and indirectly\nnecessitates an increased volume of problem data for training purposes. This\npaper takes a significant stride towards addressing this gap by proposing an\napproach that integrates algorithm representation into the algorithm selection\nprocess. Specifically, our proposed model employs distinct modules to extract\nrepresentations of both problems and algorithms, where the algorithm\nrepresentation leverages the capabilities of pre-trained LLMs in the realm of\ncode comprehension. Following the extraction of embedding vectors for both\nalgorithms and problems, the most suitable algorithm is determined through\ncalculations of matching degrees. Our experiments not only validate the\neffectiveness of the proposed model but also showcase the performance of\ndifferent embedded pre-trained LLMs, which suggests that the proposed algorithm\nselection framework holds the potential to serve as a baseline task for\nevaluating the code representation capabilities of LLMs.",
            "author": [
                "Xingyu Wu",
                "Yan Zhong",
                "Jibin Wu",
                "Kay Chen Tan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13184v1",
                "http://arxiv.org/pdf/2311.13184v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13182v1",
            "title": "Differentiable Radio Frequency Ray Tracing for Millimeter-Wave Sensing",
            "updated": "2023-11-22T06:13:39Z",
            "published": "2023-11-22T06:13:39Z",
            "summary": "Millimeter wave (mmWave) sensing is an emerging technology with applications\nin 3D object characterization and environment mapping. However, realizing\nprecise 3D reconstruction from sparse mmWave signals remains challenging.\nExisting methods rely on data-driven learning, constrained by dataset\navailability and difficulty in generalization. We propose DiffSBR, a\ndifferentiable framework for mmWave-based 3D reconstruction. DiffSBR\nincorporates a differentiable ray tracing engine to simulate radar point clouds\nfrom virtual 3D models. A gradient-based optimizer refines the model parameters\nto minimize the discrepancy between simulated and real point clouds.\nExperiments using various radar hardware validate DiffSBR's capability for\nfine-grained 3D reconstruction, even for novel objects unseen by the radar\npreviously. By integrating physics-based simulation with gradient optimization,\nDiffSBR transcends the limitations of data-driven approaches and pioneers a new\nparadigm for mmWave sensing.",
            "author": [
                "Xingyu Chen",
                "Xinyu Zhang",
                "Qiyue Xia",
                "Xinmin Fang",
                "Chris Xiaoxuan Lu",
                "Zhengxiong Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13182v1",
                "http://arxiv.org/pdf/2311.13182v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13180v2",
            "title": "Provably Efficient High-Dimensional Bandit Learning with Batched\n  Feedbacks",
            "updated": "2023-11-24T18:31:21Z",
            "published": "2023-11-22T06:06:54Z",
            "summary": "We study high-dimensional multi-armed contextual bandits with batched\nfeedback where the $T$ steps of online interactions are divided into $L$\nbatches. In specific, each batch collects data according to a policy that\ndepends on previous batches and the rewards are revealed only at the end of the\nbatch. Such a feedback structure is popular in applications such as\npersonalized medicine and online advertisement, where the online data often do\nnot arrive in a fully serial manner. We consider high-dimensional and linear\nsettings where the reward function of the bandit model admits either a sparse\nor low-rank structure and ask how small a number of batches are needed for a\ncomparable performance with fully dynamic data in which $L = T$. For these\nsettings, we design a provably sample-efficient algorithm which achieves a $\n\\mathcal{\\tilde O}(s_0^2 \\log^2 T)$ regret in the sparse case and $\n\\mathcal{\\tilde O} ( r ^2 \\log^2 T)$ regret in the low-rank case, using only $L\n= \\mathcal{O}( \\log T)$ batches. Here $s_0$ and $r$ are the sparsity and rank\nof the reward parameter in sparse and low-rank cases, respectively, and $\n\\mathcal{\\tilde O}(\\cdot)$ omits logarithmic factors involving the feature\ndimensions. In other words, our algorithm achieves regret bounds comparable to\nthose in fully sequential setting with only $\\mathcal{O}( \\log T)$ batches. Our\nalgorithm features a novel batch allocation method that adjusts the batch sizes\naccording to the estimation accuracy within each batch and cumulative regret.\nFurthermore, we also conduct experiments with synthetic and real-world data to\nvalidate our theory.",
            "author": [
                "Jianqing Fan",
                "Zhaoran Wang",
                "Zhuoran Yang",
                "Chenlu Ye"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13180v2",
                "http://arxiv.org/pdf/2311.13180v2"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13174v1",
            "title": "SecureCut: Federated Gradient Boosting Decision Trees with Efficient\n  Machine Unlearning",
            "updated": "2023-11-22T05:38:53Z",
            "published": "2023-11-22T05:38:53Z",
            "summary": "In response to legislation mandating companies to honor the \\textit{right to\nbe forgotten} by erasing user data, it has become imperative to enable data\nremoval in Vertical Federated Learning (VFL) where multiple parties provide\nprivate features for model training. In VFL, data removal, i.e.,\n\\textit{machine unlearning}, often requires removing specific features across\nall samples under privacy guarentee in federated learning. To address this\nchallenge, we propose \\methname, a novel Gradient Boosting Decision Tree (GBDT)\nframework that effectively enables both \\textit{instance unlearning} and\n\\textit{feature unlearning} without the need for retraining from scratch.\nLeveraging a robust GBDT structure, we enable effective data deletion while\nreducing degradation of model performance. Extensive experimental results on\npopular datasets demonstrate that our method achieves superior model utility\nand forgetfulness compared to \\textit{state-of-the-art} methods. To our best\nknowledge, this is the first work that investigates machine unlearning in VFL\nscenarios.",
            "author": [
                "Jian Zhang",
                "Bowen Li Jie Li",
                "Chentao Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13174v1",
                "http://arxiv.org/pdf/2311.13174v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13172v1",
            "title": "Learning to Complement with Multiple Humans (LECOMH): Integrating\n  Multi-rater and Noisy-Label Learning into Human-AI Collaboration",
            "updated": "2023-11-22T05:31:06Z",
            "published": "2023-11-22T05:31:06Z",
            "summary": "The advent of learning with noisy labels (LNL), multi-rater learning, and\nhuman-AI collaboration has revolutionised the development of robust\nclassifiers, enabling them to address the challenges posed by different types\nof data imperfections and complex decision processes commonly encountered in\nreal-world applications. While each of these methodologies has individually\nmade significant strides in addressing their unique challenges, the development\nof techniques that can simultaneously tackle these three problems remains\nunderexplored. This paper addresses this research gap by integrating\nnoisy-label learning, multi-rater learning, and human-AI collaboration with new\nbenchmarks and the innovative Learning to Complement with Multiple Humans\n(LECOMH) approach. LECOMH optimises the level of human collaboration during\ntesting, aiming to optimise classification accuracy while minimising\ncollaboration costs that vary from 0 to M, where M is the maximum number of\nhuman collaborators. We quantitatively compare LECOMH with leading human-AI\ncollaboration methods using our proposed benchmarks. LECOMH consistently\noutperforms the competition, with accuracy improving as collaboration costs\nincrease. Notably, LECOMH is the only method enhancing human labeller\nperformance across all benchmarks.",
            "author": [
                "Zheng Zhang",
                "Kevin Wells",
                "Gustavo Carneiro"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13172v1",
                "http://arxiv.org/pdf/2311.13172v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13171v1",
            "title": "ComPEFT: Compression for Communicating Parameter Efficient Updates via\n  Sparsification and Quantization",
            "updated": "2023-11-22T05:28:59Z",
            "published": "2023-11-22T05:28:59Z",
            "summary": "Parameter-efficient fine-tuning (PEFT) techniques make it possible to\nefficiently adapt a language model to create \"expert\" models that specialize to\nnew tasks or domains. Recent techniques in model merging and compositional\ngeneralization leverage these expert models by dynamically composing modules to\nimprove zero/few-shot generalization. Despite the efficiency of PEFT methods,\nthe size of expert models can make it onerous to retrieve expert models per\nquery over high-latency networks like the Internet or serve multiple experts on\na single GPU. To address these issues, we present ComPEFT, a novel method for\ncompressing fine-tuning residuals (task vectors) of PEFT based models. ComPEFT\nemploys sparsification and ternary quantization to reduce the size of the PEFT\nmodule without performing any additional retraining while preserving or\nenhancing model performance. In extensive evaluation across T5, T0, and\nLLaMA-based models with 200M - 65B parameters, ComPEFT achieves compression\nratios of 8x - 50x. In particular, we show that ComPEFT improves with scale -\nstronger models exhibit higher compressibility and better performance. For\nexample, we show that ComPEFT applied to LLaMA outperforms QLoRA by 4.16% on\nMMLU with a storage size reduction of up to 26x. In addition, we show that the\ncompressed experts produced by ComPEFT maintain few-shot compositional\ngeneralization capabilities, facilitate efficient communication and\ncomputation, and exhibit enhanced performance when merged. Lastly, we provide\nan analysis of different method components, compare it with other PEFT methods,\nand test ComPEFT's efficacy for compressing the residual of full-finetuning.\nOur code is available at https://github.com/prateeky2806/compeft.",
            "author": [
                "Prateek Yadav",
                "Leshem Choshen",
                "Colin Raffel",
                "Mohit Bansal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13171v1",
                "http://arxiv.org/pdf/2311.13171v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13170v1",
            "title": "An iterative deep learning procedure for determining electron scattering\n  cross-sections from transport coefficients",
            "updated": "2023-11-22T05:28:02Z",
            "published": "2023-11-22T05:28:02Z",
            "summary": "We propose improvements to the Artificial Neural Network (ANN) method of\ndetermining electron scattering cross-sections from swarm data proposed by\ncoauthors. A limitation inherent to this problem, known as the inverse swarm\nproblem, is the non-unique nature of its solutions, particularly when there\nexists multiple cross-sections that each describe similar scattering processes.\nConsidering this, prior methods leveraged existing knowledge of a particular\ncross-section set to reduce the solution space of the problem. To reduce the\nneed for prior knowledge, we propose the following modifications to the ANN\nmethod. First, we propose a Multi-Branch ANN (MBANN) that assigns an\nindependent branch of hidden layers to each cross-section output. We show that\nin comparison with an equivalent conventional ANN, the MBANN architecture\nenables an efficient and physics informed feature map of each cross-section.\nAdditionally, we show that the MBANN solution can be improved upon by\nsuccessive networks that are each trained using perturbations of the previous\nregression. Crucially, the method requires much less input data and fewer\nrestrictive assumptions, and only assumes knowledge of energy loss thresholds\nand the number of cross-sections present.",
            "author": [
                "Dale L Muccignat",
                "Gregory G Boyle",
                "Nathan A Garland",
                "Peter W Stokes",
                "Ronald D White"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13170v1",
                "http://arxiv.org/pdf/2311.13170v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13169v1",
            "title": "SiGeo: Sub-One-Shot NAS via Information Theory and Geometry of Loss\n  Landscape",
            "updated": "2023-11-22T05:25:24Z",
            "published": "2023-11-22T05:25:24Z",
            "summary": "Neural Architecture Search (NAS) has become a widely used tool for automating\nneural network design. While one-shot NAS methods have successfully reduced\ncomputational requirements, they often require extensive training. On the other\nhand, zero-shot NAS utilizes training-free proxies to evaluate a candidate\narchitecture's test performance but has two limitations: (1) inability to use\nthe information gained as a network improves with training and (2) unreliable\nperformance, particularly in complex domains like RecSys, due to the\nmulti-modal data inputs and complex architecture configurations. To synthesize\nthe benefits of both methods, we introduce a \"sub-one-shot\" paradigm that\nserves as a bridge between zero-shot and one-shot NAS. In sub-one-shot NAS, the\nsupernet is trained using only a small subset of the training data, a phase we\nrefer to as \"warm-up.\" Within this framework, we present SiGeo, a proxy founded\non a novel theoretical framework that connects the supernet warm-up with the\nefficacy of the proxy. Extensive experiments have shown that SiGeo, with the\nbenefit of warm-up, consistently outperforms state-of-the-art NAS proxies on\nvarious established NAS benchmarks. When a supernet is warmed up, it can\nachieve comparable performance to weight-sharing one-shot NAS methods, but with\na significant reduction ($\\sim 60$\\%) in computational costs.",
            "author": [
                "Hua Zheng",
                "Kuang-Hung Liu",
                "Igor Fedorov",
                "Xin Zhang",
                "Wen-Yen Chen",
                "Wei Wen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13169v1",
                "http://arxiv.org/pdf/2311.13169v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13168v1",
            "title": "3D Face Style Transfer with a Hybrid Solution of NeRF and Mesh\n  Rasterization",
            "updated": "2023-11-22T05:24:35Z",
            "published": "2023-11-22T05:24:35Z",
            "summary": "Style transfer for human face has been widely researched in recent years.\nMajority of the existing approaches work in 2D image domain and have 3D\ninconsistency issue when applied on different viewpoints of the same face. In\nthis paper, we tackle the problem of 3D face style transfer which aims at\ngenerating stylized novel views of a 3D human face with multi-view consistency.\nWe propose to use a neural radiance field (NeRF) to represent 3D human face and\ncombine it with 2D style transfer to stylize the 3D face. We find that directly\ntraining a NeRF on stylized images from 2D style transfer brings in 3D\ninconsistency issue and causes blurriness. On the other hand, training a NeRF\njointly with 2D style transfer objectives shows poor convergence due to the\nidentity and head pose gap between style image and content image. It also poses\nchallenge in training time and memory due to the need of volume rendering for\nfull image to apply style transfer loss functions. We therefore propose a\nhybrid framework of NeRF and mesh rasterization to combine the benefits of high\nfidelity geometry reconstruction of NeRF and fast rendering speed of mesh. Our\nframework consists of three stages: 1. Training a NeRF model on input face\nimages to learn the 3D geometry; 2. Extracting a mesh from the trained NeRF\nmodel and optimizing it with style transfer objectives via differentiable\nrasterization; 3. Training a new color network in NeRF conditioned on a style\nembedding to enable arbitrary style transfer to the 3D face. Experiment results\nshow that our approach generates high quality face style transfer with great 3D\nconsistency, while also enabling a flexible style control.",
            "author": [
                "Jianwei Feng",
                "Prateek Singhal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13168v1",
                "http://arxiv.org/pdf/2311.13168v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13166v1",
            "title": "AdaptiveFL: Adaptive Heterogeneous Federated Learning for\n  Resource-Constrained AIoT Systems",
            "updated": "2023-11-22T05:17:42Z",
            "published": "2023-11-22T05:17:42Z",
            "summary": "Although Federated Learning (FL) is promising to enable collaborative\nlearning among Artificial Intelligence of Things (AIoT) devices, it suffers\nfrom the problem of low classification performance due to various heterogeneity\nfactors (e.g., computing capacity, memory size) of devices and uncertain\noperating environments. To address these issues, this paper introduces an\neffective FL approach named AdaptiveFL based on a novel fine-grained width-wise\nmodel pruning strategy, which can generate various heterogeneous local models\nfor heterogeneous AIoT devices. By using our proposed reinforcement\nlearning-based device selection mechanism, AdaptiveFL can adaptively dispatch\nsuitable heterogeneous models to corresponding AIoT devices on the fly based on\ntheir available resources for local training. Experimental results show that,\ncompared to state-of-the-art methods, AdaptiveFL can achieve up to 16.83%\ninference improvements for both IID and non-IID scenarios.",
            "author": [
                "Chentao Jia",
                "Ming Hu",
                "Zekai Chen",
                "Yanxin Yang",
                "Xiaofei Xie",
                "Yang Liu",
                "Mingsong Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13166v1",
                "http://arxiv.org/pdf/2311.13166v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13163v1",
            "title": "Have Your Cake and Eat It Too: Toward Efficient and Accurate Split\n  Federated Learning",
            "updated": "2023-11-22T05:09:50Z",
            "published": "2023-11-22T05:09:50Z",
            "summary": "Due to its advantages in resource constraint scenarios, Split Federated\nLearning (SFL) is promising in AIoT systems. However, due to data heterogeneity\nand stragglers, SFL suffers from the challenges of low inference accuracy and\nlow efficiency. To address these issues, this paper presents a novel SFL\napproach, named Sliding Split Federated Learning (S$^2$FL), which adopts an\nadaptive sliding model split strategy and a data balance-based training\nmechanism. By dynamically dispatching different model portions to AIoT devices\naccording to their computing capability, S$^2$FL can alleviate the low training\nefficiency caused by stragglers. By combining features uploaded by devices with\ndifferent data distributions to generate multiple larger batches with a uniform\ndistribution for back-propagation, S$^2$FL can alleviate the performance\ndegradation caused by data heterogeneity. Experimental results demonstrate\nthat, compared to conventional SFL, S$^2$FL can achieve up to 16.5\\% inference\naccuracy improvement and 3.54X training acceleration.",
            "author": [
                "Dengke Yan",
                "Ming Hu",
                "Zeke Xia",
                "Yanxin Yang",
                "Jun Xia",
                "Xiaofei Xie",
                "Mingsong Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13163v1",
                "http://arxiv.org/pdf/2311.13163v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13160v1",
            "title": "Large Language Models in Education: Vision and Opportunities",
            "updated": "2023-11-22T05:04:20Z",
            "published": "2023-11-22T05:04:20Z",
            "summary": "With the rapid development of artificial intelligence technology, large\nlanguage models (LLMs) have become a hot research topic. Education plays an\nimportant role in human social development and progress. Traditional education\nfaces challenges such as individual student differences, insufficient\nallocation of teaching resources, and assessment of teaching effectiveness.\nTherefore, the applications of LLMs in the field of digital/smart education\nhave broad prospects. The research on educational large models (EduLLMs) is\nconstantly evolving, providing new methods and approaches to achieve\npersonalized learning, intelligent tutoring, and educational assessment goals,\nthereby improving the quality of education and the learning experience. This\narticle aims to investigate and summarize the application of LLMs in smart\neducation. It first introduces the research background and motivation of LLMs\nand explains the essence of LLMs. It then discusses the relationship between\ndigital education and EduLLMs and summarizes the current research status of\neducational large models. The main contributions are the systematic summary and\nvision of the research background, motivation, and application of large models\nfor education (LLM4Edu). By reviewing existing research, this article provides\nguidance and insights for educators, researchers, and policy-makers to gain a\ndeep understanding of the potential and challenges of LLM4Edu. It further\nprovides guidance for further advancing the development and application of\nLLM4Edu, while still facing technical, ethical, and practical challenges\nrequiring further research and exploration.",
            "author": [
                "Wensheng Gan",
                "Zhenlian Qi",
                "Jiayang Wu",
                "Jerry Chun-Wei Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13160v1",
                "http://arxiv.org/pdf/2311.13160v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13614v1",
            "title": "HalluciDoctor: Mitigating Hallucinatory Toxicity in Visual Instruction\n  Data",
            "updated": "2023-11-22T04:52:58Z",
            "published": "2023-11-22T04:52:58Z",
            "summary": "Multi-modal Large Language Models (MLLMs) tuned on machine-generated\ninstruction-following data have demonstrated remarkable performance in various\nmulti-modal understanding and generation tasks. However, the hallucinations\ninherent in machine-generated data, which could lead to hallucinatory outputs\nin MLLMs, remain under-explored. This work aims to investigate various\nhallucinations (i.e., object, relation, attribute hallucinations) and mitigate\nthose hallucinatory toxicities in large-scale machine-generated visual\ninstruction datasets. Drawing on the human ability to identify factual errors,\nwe present a novel hallucination detection and elimination framework,\nHalluciDoctor, based on the cross-checking paradigm. We use our framework to\nidentify and eliminate hallucinations in the training data automatically.\nInterestingly, HalluciDoctor also indicates that spurious correlations arising\nfrom long-tail object co-occurrences contribute to hallucinations. Based on\nthat, we execute counterfactual visual instruction expansion to balance data\ndistribution, thereby enhancing MLLMs' resistance to hallucinations.\nComprehensive experiments on hallucination evaluation benchmarks show that our\nmethod successfully mitigates 44.6% hallucinations relatively and maintains\ncompetitive performance compared to LLaVA.The source code will be released at\n\\url{https://github.com/Yuqifan1117/HalluciDoctor}.",
            "author": [
                "Qifan Yu",
                "Juncheng Li",
                "Longhui Wei",
                "Liang Pang",
                "Wentao Ye",
                "Bosheng Qin",
                "Siliang Tang",
                "Qi Tian",
                "Yueting Zhuang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13614v1",
                "http://arxiv.org/pdf/2311.13614v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13159v1",
            "title": "Multi-Objective Optimization via Wasserstein-Fisher-Rao Gradient Flow",
            "updated": "2023-11-22T04:49:16Z",
            "published": "2023-11-22T04:49:16Z",
            "summary": "Multi-objective optimization (MOO) aims to optimize multiple, possibly\nconflicting objectives with widespread applications. We introduce a novel\ninteracting particle method for MOO inspired by molecular dynamics simulations.\nOur approach combines overdamped Langevin and birth-death dynamics,\nincorporating a \"dominance potential\" to steer particles toward global Pareto\noptimality. In contrast to previous methods, our method is able to relocate\ndominated particles, making it particularly adept at managing Pareto fronts of\ncomplicated geometries. Our method is also theoretically grounded as a\nWasserstein-Fisher-Rao gradient flow with convergence guarantees. Extensive\nexperiments confirm that our approach outperforms state-of-the-art methods on\nchallenging synthetic and real-world datasets.",
            "author": [
                "Yinuo Ren",
                "Tesi Xiao",
                "Tanmay Gangwani",
                "Anshuka Rangi",
                "Holakou Rahmanian",
                "Lexing Ying",
                "Subhajit Sanyal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13159v1",
                "http://arxiv.org/pdf/2311.13159v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13154v1",
            "title": "Testing Closeness of Multivariate Distributions via Ramsey Theory",
            "updated": "2023-11-22T04:34:09Z",
            "published": "2023-11-22T04:34:09Z",
            "summary": "We investigate the statistical task of closeness (or equivalence) testing for\nmultidimensional distributions. Specifically, given sample access to two\nunknown distributions $\\mathbf p, \\mathbf q$ on $\\mathbb R^d$, we want to\ndistinguish between the case that $\\mathbf p=\\mathbf q$ versus $\\|\\mathbf\np-\\mathbf q\\|_{A_k} > \\epsilon$, where $\\|\\mathbf p-\\mathbf q\\|_{A_k}$ denotes\nthe generalized ${A}_k$ distance between $\\mathbf p$ and $\\mathbf q$ --\nmeasuring the maximum discrepancy between the distributions over any collection\nof $k$ disjoint, axis-aligned rectangles. Our main result is the first\ncloseness tester for this problem with {\\em sub-learning} sample complexity in\nany fixed dimension and a nearly-matching sample complexity lower bound.\n  In more detail, we provide a computationally efficient closeness tester with\nsample complexity $O\\left((k^{6/7}/ \\mathrm{poly}_d(\\epsilon))\n\\log^d(k)\\right)$. On the lower bound side, we establish a qualitatively\nmatching sample complexity lower bound of\n$\\Omega(k^{6/7}/\\mathrm{poly}(\\epsilon))$, even for $d=2$. These sample\ncomplexity bounds are surprising because the sample complexity of the problem\nin the univariate setting is $\\Theta(k^{4/5}/\\mathrm{poly}(\\epsilon))$. This\nhas the interesting consequence that the jump from one to two dimensions leads\nto a substantial increase in sample complexity, while increases beyond that do\nnot.\n  As a corollary of our general $A_k$ tester, we obtain $d_{\\mathrm\nTV}$-closeness testers for pairs of $k$-histograms on $\\mathbb R^d$ over a\ncommon unknown partition, and pairs of uniform distributions supported on the\nunion of $k$ unknown disjoint axis-aligned rectangles.\n  Both our algorithm and our lower bound make essential use of tools from\nRamsey theory.",
            "author": [
                "Ilias Diakonikolas",
                "Daniel M. Kane",
                "Sihan Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13154v1",
                "http://arxiv.org/pdf/2311.13154v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.IT",
                "cs.LG",
                "math.IT",
                "math.ST",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13152v1",
            "title": "Test-Time Augmentation for 3D Point Cloud Classification and\n  Segmentation",
            "updated": "2023-11-22T04:31:09Z",
            "published": "2023-11-22T04:31:09Z",
            "summary": "Data augmentation is a powerful technique to enhance the performance of a\ndeep learning task but has received less attention in 3D deep learning. It is\nwell known that when 3D shapes are sparsely represented with low point density,\nthe performance of the downstream tasks drops significantly. This work explores\ntest-time augmentation (TTA) for 3D point clouds. We are inspired by the recent\nrevolution of learning implicit representation and point cloud upsampling,\nwhich can produce high-quality 3D surface reconstruction and\nproximity-to-surface, respectively. Our idea is to leverage the implicit field\nreconstruction or point cloud upsampling techniques as a systematic way to\naugment point cloud data. Mainly, we test both strategies by sampling points\nfrom the reconstructed results and using the sampled point cloud as test-time\naugmented data. We show that both strategies are effective in improving\naccuracy. We observed that point cloud upsampling for test-time augmentation\ncan lead to more significant performance improvement on downstream tasks such\nas object classification and segmentation on the ModelNet40, ShapeNet,\nScanObjectNN, and SemanticKITTI datasets, especially for sparse point clouds.",
            "author": [
                "Tuan-Anh Vu",
                "Srinjay Sarkar",
                "Zhiyuan Zhang",
                "Binh-Son Hua",
                "Sai-Kit Yeung"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13152v1",
                "http://arxiv.org/pdf/2311.13152v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13147v1",
            "title": "Optimal Transport with Cyclic Symmetry",
            "updated": "2023-11-22T04:18:23Z",
            "published": "2023-11-22T04:18:23Z",
            "summary": "We propose novel fast algorithms for optimal transport (OT) utilizing a\ncyclic symmetry structure of input data. Such OT with cyclic symmetry appears\nuniversally in various real-world examples: image processing, urban planning,\nand graph processing. Our main idea is to reduce OT to a small optimization\nproblem that has significantly fewer variables by utilizing cyclic symmetry and\nvarious optimization techniques. On the basis of this reduction, our algorithms\nsolve the small optimization problem instead of the original OT. As a result,\nour algorithms obtain the optimal solution and the objective function value of\nthe original OT faster than solving the original OT directly. In this paper,\nour focus is on two crucial OT formulations: the linear programming OT (LOT)\nand the strongly convex-regularized OT, which includes the well-known\nentropy-regularized OT (EROT). Experiments show the effectiveness of our\nalgorithms for LOT and EROT in synthetic/real-world data that has a\nstrict/approximate cyclic symmetry structure. Through theoretical and\nexperimental results, this paper successfully introduces the concept of\nsymmetry into the OT research field for the first time.",
            "author": [
                "Shoichiro Takeda",
                "Yasunori Akagi",
                "Naoki Marumo",
                "Kenta Niwa"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13147v1",
                "http://arxiv.org/pdf/2311.13147v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13144v1",
            "title": "Single Image Compressed Sensing MRI via a Self-Supervised Deep Denoising\n  Approach",
            "updated": "2023-11-22T04:14:42Z",
            "published": "2023-11-22T04:14:42Z",
            "summary": "Popular methods in compressed sensing (CS) are dependent on deep learning\n(DL), where large amounts of data are used to train non-linear reconstruction\nmodels. However, ensuring generalisability over and access to multiple datasets\nis challenging to realise for real-world applications. To address these\nconcerns, this paper proposes a single image, self-supervised (SS) CS-MRI\nframework that enables a joint deep and sparse regularisation of CS artefacts.\nThe approach effectively dampens structured CS artefacts, which can be\ndifficult to remove assuming sparse reconstruction, or relying solely on the\ninductive biases of CNN to produce noise-free images. Image quality is thereby\nimproved compared to either approach alone. Metrics are evaluated using\nCartesian 1D masks on a brain and knee dataset, with PSNR improving by 2-4dB on\naverage.",
            "author": [
                "Marlon Bran Lorenzana",
                "Feng Liu",
                "Shekhar S. Chandra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13144v1",
                "http://arxiv.org/pdf/2311.13144v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13613v1",
            "title": "Spanning Training Progress: Temporal Dual-Depth Scoring (TDDS) for\n  Enhanced Dataset Pruning",
            "updated": "2023-11-22T03:45:30Z",
            "published": "2023-11-22T03:45:30Z",
            "summary": "Dataset pruning aims to construct a coreset capable of achieving performance\ncomparable to the original, full dataset. Most existing dataset pruning methods\nrely on snapshot-based criteria to identify representative samples, often\nresulting in poor generalization across various pruning and cross-architecture\nscenarios. Recent studies have addressed this issue by expanding the scope of\ntraining dynamics considered, including factors such as forgetting event and\nprobability change, typically using an averaging approach. However, these works\nstruggle to integrate a broader range of training dynamics without overlooking\nwell-generalized samples, which may not be sufficiently highlighted in an\naveraging manner. In this study, we propose a novel dataset pruning method\ntermed as Temporal Dual-Depth Scoring (TDDS), to tackle this problem. TDDS\nutilizes a dual-depth strategy to achieve a balance between incorporating\nextensive training dynamics and identifying representative samples for dataset\npruning. In the first depth, we estimate the series of each sample's individual\ncontributions spanning the training progress, ensuring comprehensive\nintegration of training dynamics. In the second depth, we focus on the\nvariability of the sample-wise contributions identified in the first depth to\nhighlight well-generalized samples. Extensive experiments conducted on CIFAR\nand ImageNet datasets verify the superiority of TDDS over previous SOTA\nmethods. Specifically on CIFAR-100, our method achieves 54.51% accuracy with\nonly 10% training data, surpassing random selection by 7.83% and other\ncomparison methods by at least 12.69%.",
            "author": [
                "Xin Zhang",
                "Jiawei Du",
                "Yunsong Li",
                "Weiying Xie",
                "Joey Tianyi Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13613v1",
                "http://arxiv.org/pdf/2311.13613v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13133v1",
            "title": "LIMIT: Less Is More for Instruction Tuning Across Evaluation Paradigms",
            "updated": "2023-11-22T03:37:01Z",
            "published": "2023-11-22T03:37:01Z",
            "summary": "Large Language Models are traditionally finetuned on large instruction\ndatasets. However recent studies suggest that small, high-quality datasets can\nsuffice for general purpose instruction following. This lack of consensus\nsurrounding finetuning best practices is in part due to rapidly diverging\napproaches to LLM evaluation. In this study, we ask whether a small amount of\ndiverse finetuning samples can improve performance on both traditional\nperplexity-based NLP benchmarks, and on open-ended, model-based evaluation. We\nfinetune open-source MPT-7B and MPT-30B models on instruction finetuning\ndatasets of various sizes ranging from 1k to 60k samples. We find that subsets\nof 1k-6k instruction finetuning samples are sufficient to achieve good\nperformance on both (1) traditional NLP benchmarks and (2) model-based\nevaluation. Finally, we show that mixing textbook-style and open-ended QA\nfinetuning datasets optimizes performance on both evaluation paradigms.",
            "author": [
                "Aditi Jha",
                "Sam Havens",
                "Jeremey Dohmann",
                "Alex Trott",
                "Jacob Portes"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13133v1",
                "http://arxiv.org/pdf/2311.13133v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16173v2",
            "title": "Conditions for Length Generalization in Learning Reasoning Skills",
            "updated": "2023-12-06T16:31:50Z",
            "published": "2023-11-22T03:36:18Z",
            "summary": "Reasoning is a fundamental capability of AI agents. Recently, large language\nmodels (LLMs) have shown remarkable abilities to perform reasoning tasks.\nHowever, numerous evaluations of the reasoning capabilities of LLMs have also\nshowed some limitations. An outstanding limitation is length generalization,\nmeaning that when trained on reasoning problems of smaller lengths or sizes,\nthe resulting models struggle with problems of larger sizes or lengths. This\npotentially indicates some theoretical limitations of generalization in\nlearning reasoning skills. These evaluations and their observations motivated\nus to perform a theoretical study of the length generalization problem. This\nwork focuses on reasoning tasks that can be formulated as Markov dynamic\nprocesses (MDPs) and/or directed acyclic graphs (DAGs). It identifies and\nproves conditions that decide whether the length generalization problem can be\nsolved or not for a reasoning task in a particular representation. Experiments\nare also conducted to verify the theoretical results.",
            "author": [
                "Changnan Xiao",
                "Bing Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16173v2",
                "http://arxiv.org/pdf/2311.16173v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13128v1",
            "title": "P2RBox: A Single Point is All You Need for Oriented Object Detection",
            "updated": "2023-11-22T03:33:00Z",
            "published": "2023-11-22T03:33:00Z",
            "summary": "Oriented object detection, a specialized subfield in computer vision, finds\napplications across diverse scenarios, excelling particularly when dealing with\nobjects of arbitrary orientations. Conversely, point annotation, which treats\nobjects as single points, offers a cost-effective alternative to rotated and\nhorizontal bounding boxes but sacrifices performance due to the loss of size\nand orientation information. In this study, we introduce the P2RBox network,\nwhich leverages point annotations and a mask generator to create mask\nproposals, followed by filtration through our Inspector Module and Constrainer\nModule. This process selects high-quality masks, which are subsequently\nconverted into rotated box annotations for training a fully supervised\ndetector. Specifically, we've thoughtfully crafted an Inspector Module rooted\nin multi-instance learning principles to evaluate the semantic score of masks.\nWe've also proposed a more robust mask quality assessment in conjunction with\nthe Constrainer Module. Furthermore, we've introduced a Symmetry Axis\nEstimation (SAE) Module inspired by the spectral theorem for symmetric matrices\nto transform the top-performing mask proposal into rotated bounding boxes.\nP2RBox performs well with three fully supervised rotated object detectors:\nRetinaNet, Rotated FCOS, and Oriented R-CNN. By combining with Oriented R-CNN,\nP2RBox achieves 62.26% on DOTA-v1.0 test dataset. As far as we know, this is\nthe first attempt at training an oriented object detector with point\nsupervision.",
            "author": [
                "Guangming Cao",
                "Xuehui Yu",
                "Wenwen Yu",
                "Xumeng Han",
                "Xue Yang",
                "Guorong Li",
                "Jianbin Jiao",
                "Zhenjun Han"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13128v1",
                "http://arxiv.org/pdf/2311.13128v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13127v1",
            "title": "Toward Robust Imperceptible Perturbation against Unauthorized\n  Text-to-image Diffusion-based Synthesis",
            "updated": "2023-11-22T03:31:31Z",
            "published": "2023-11-22T03:31:31Z",
            "summary": "Text-to-image diffusion models allow seamless generation of personalized\nimages from scant reference photos. Yet, these tools, in the wrong hands, can\nfabricate misleading or harmful content, endangering individuals. To address\nthis problem, existing poisoning-based approaches perturb user images in an\nimperceptible way to render them \"unlearnable\" from malicious uses. We identify\ntwo limitations of these defending approaches: i) sub-optimal due to the\nhand-crafted heuristics for solving the intractable bilevel optimization and\nii) lack of robustness against simple data transformations like Gaussian\nfiltering. To solve these challenges, we propose MetaCloak, which solves the\nbi-level poisoning problem with a meta-learning framework with an additional\ntransformation sampling process to craft transferable and robust perturbation.\nSpecifically, we employ a pool of surrogate diffusion models to craft\ntransferable and model-agnostic perturbation. Furthermore, by incorporating an\nadditional transformation process, we design a simple denoising-error\nmaximization loss that is sufficient for causing transformation-robust semantic\ndistortion and degradation in a personalized generation. Extensive experiments\non the VGGFace2 and CelebA-HQ datasets show that MetaCloak outperforms existing\napproaches. Notably, MetaCloak can successfully fool online training services\nlike Replicate, in a black-box manner, demonstrating the effectiveness of\nMetaCloak in real-world scenarios. Our code is available at\nhttps://github.com/liuyixin-louis/MetaCloak.",
            "author": [
                "Yixin Liu",
                "Chenrui Fan",
                "Yutong Dai",
                "Xun Chen",
                "Pan Zhou",
                "Lichao Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13127v1",
                "http://arxiv.org/pdf/2311.13127v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13126v1",
            "title": "Towards Better Parameter-Efficient Fine-Tuning for Large Language\n  Models: A Position Paper",
            "updated": "2023-11-22T03:28:34Z",
            "published": "2023-11-22T03:28:34Z",
            "summary": "This paper delves into the pressing need in Parameter-Efficient Fine-Tuning\n(PEFT) for Large Language Models (LLMs). While LLMs possess remarkable\ncapabilities, their extensive parameter requirements and associated\ncomputational demands hinder their practicality and scalability for real-world\napplications. Our position paper highlights current states and the necessity of\nfurther studying into the topic, and recognizes significant challenges and open\nissues that must be addressed to fully harness the powerful abilities of LLMs.\nThese challenges encompass novel efficient PEFT architectures, PEFT for\ndifferent learning settings, PEFT combined with model compression techniques,\nand the exploration of PEFT for multi-modal LLMs. By presenting this position\npaper, we aim to stimulate further research and foster discussions surrounding\nmore efficient and accessible PEFT for LLMs.",
            "author": [
                "Chengyu Wang",
                "Junbing Yan",
                "Wei Zhang",
                "Jun Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13126v1",
                "http://arxiv.org/pdf/2311.13126v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13125v1",
            "title": "DAE-Net: Deforming Auto-Encoder for fine-grained shape co-segmentation",
            "updated": "2023-11-22T03:26:07Z",
            "published": "2023-11-22T03:26:07Z",
            "summary": "We present an unsupervised 3D shape co-segmentation method which learns a set\nof deformable part templates from a shape collection. To accommodate structural\nvariations in the collection, our network composes each shape by a selected\nsubset of template parts which are affine-transformed. To maximize the\nexpressive power of the part templates, we introduce a per-part deformation\nnetwork to enable the modeling of diverse parts with substantial geometry\nvariations, while imposing constraints on the deformation capacity to ensure\nfidelity to the originally represented parts. We also propose a training scheme\nto effectively overcome local minima. Architecturally, our network is a\nbranched autoencoder, with a CNN encoder taking a voxel shape as input and\nproducing per-part transformation matrices, latent codes, and part existence\nscores, and the decoder outputting point occupancies to define the\nreconstruction loss. Our network, coined DAE-Net for Deforming Auto-Encoder,\ncan achieve unsupervised 3D shape co-segmentation that yields fine-grained,\ncompact, and meaningful parts that are consistent across diverse shapes. We\nconduct extensive experiments on the ShapeNet Part dataset, DFAUST, and an\nanimal subset of Objaverse to show superior performance over prior methods.",
            "author": [
                "Zhiqin Chen",
                "Qimin Chen",
                "Hang Zhou",
                "Hao Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13125v1",
                "http://arxiv.org/pdf/2311.13125v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13123v1",
            "title": "Fast Parallel Algorithms for Submodular $p$-Superseparable Maximization",
            "updated": "2023-11-22T02:50:33Z",
            "published": "2023-11-22T02:50:33Z",
            "summary": "Maximizing a non-negative, monontone, submodular function $f$ over $n$\nelements under a cardinality constraint $k$ (SMCC) is a well-studied NP-hard\nproblem. It has important applications in, e.g., machine learning and influence\nmaximization. Though the theoretical problem admits polynomial-time\napproximation algorithms, solving it in practice often involves frequently\nquerying submodular functions that are expensive to compute. This has motivated\nsignificant research into designing parallel approximation algorithms in the\nadaptive complexity model; adaptive complexity (adaptivity) measures the number\nof sequential rounds of $\\text{poly}(n)$ function queries an algorithm\nrequires. The state-of-the-art algorithms can achieve\n$(1-\\frac{1}{e}-\\varepsilon)$-approximate solutions with\n$O(\\frac{1}{\\varepsilon^2}\\log n)$ adaptivity, which approaches the known\nadaptivity lower-bounds. However, the $O(\\frac{1}{\\varepsilon^2} \\log n)$\nadaptivity only applies to maximizing worst-case functions that are unlikely to\nappear in practice. Thus, in this paper, we consider the special class of\n$p$-superseparable submodular functions, which places a reasonable constraint\non $f$, based on the parameter $p$, and is more amenable to maximization, while\nalso having real-world applicability. Our main contribution is the algorithm\nLS+GS, a finer-grained version of the existing LS+PGB algorithm, designed for\ninstances of SMCC when $f$ is $p$-superseparable; it achieves an expected\n$(1-\\frac{1}{e}-\\varepsilon)$-approximate solution with\n$O(\\frac{1}{\\varepsilon^2}\\log(p k))$ adaptivity independent of $n$.\nAdditionally, unrelated to $p$-superseparability, our LS+GS algorithm uses only\n$O(\\frac{n}{\\varepsilon} + \\frac{\\log n}{\\varepsilon^2})$ oracle queries, which\nhas an improved dependence on $\\varepsilon^{-1}$ over the state-of-the-art\nLS+PGB; this is achieved through the design of a novel thresholding subroutine.",
            "author": [
                "Philip Cervenjak",
                "Junhao Gan",
                "Anthony Wirth"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13123v1",
                "http://arxiv.org/pdf/2311.13123v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13120v2",
            "title": "Multi-modal In-Context Learning Makes an Ego-evolving Scene Text\n  Recognizer",
            "updated": "2023-11-23T08:15:18Z",
            "published": "2023-11-22T02:46:57Z",
            "summary": "Scene text recognition (STR) in the wild frequently encounters challenges\nwhen coping with domain variations, font diversity, shape deformations, etc. A\nstraightforward solution is performing model fine-tuning tailored to a specific\nscenario, but it is computationally intensive and requires multiple model\ncopies for various scenarios. Recent studies indicate that large language\nmodels (LLMs) can learn from a few demonstration examples in a training-free\nmanner, termed \"In-Context Learning\" (ICL). Nevertheless, applying LLMs as a\ntext recognizer is unacceptably resource-consuming. Moreover, our pilot\nexperiments on LLMs show that ICL fails in STR, mainly attributed to the\ninsufficient incorporation of contextual information from diverse samples in\nthe training stage. To this end, we introduce E$^2$STR, a STR model trained\nwith context-rich scene text sequences, where the sequences are generated via\nour proposed in-context training strategy. E$^2$STR demonstrates that a\nregular-sized model is sufficient to achieve effective ICL capabilities in STR.\nExtensive experiments show that E$^2$STR exhibits remarkable training-free\nadaptation in various scenarios and outperforms even the fine-tuned\nstate-of-the-art approaches on public benchmarks.",
            "author": [
                "Zhen Zhao",
                "Jingqun Tang",
                "Chunhui Lin",
                "Binghong Wu",
                "Hao Liu",
                "Zhizhong Zhang",
                "Xin Tan",
                "Can Huang",
                "Yuan Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13120v2",
                "http://arxiv.org/pdf/2311.13120v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13118v1",
            "title": "Combatting Human Trafficking in the Cyberspace: A Natural Language\n  Processing-Based Methodology to Analyze the Language in Online Advertisements",
            "updated": "2023-11-22T02:45:01Z",
            "published": "2023-11-22T02:45:01Z",
            "summary": "This project tackles the pressing issue of human trafficking in online C2C\nmarketplaces through advanced Natural Language Processing (NLP) techniques. We\nintroduce a novel methodology for generating pseudo-labeled datasets with\nminimal supervision, serving as a rich resource for training state-of-the-art\nNLP models. Focusing on tasks like Human Trafficking Risk Prediction (HTRP) and\nOrganized Activity Detection (OAD), we employ cutting-edge Transformer models\nfor analysis. A key contribution is the implementation of an interpretability\nframework using Integrated Gradients, providing explainable insights crucial\nfor law enforcement. This work not only fills a critical gap in the literature\nbut also offers a scalable, machine learning-driven approach to combat human\nexploitation online. It serves as a foundation for future research and\npractical applications, emphasizing the role of machine learning in addressing\ncomplex social issues.",
            "author": [
                "Alejandro Rodriguez Perez",
                "Pablo Rivas"
            ],
            "link": [
                "http://dx.doi.org/10.6084/m9.figshare.24602823.v1",
                "http://arxiv.org/abs/2311.13118v1",
                "http://arxiv.org/pdf/2311.13118v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL",
                "cs.CY",
                "cs.SI",
                "68T50, 62H30, 91C99, 68T068T50, 62H30, 91C99, 68T01",
                "I.2.7; I.5.4; K.4.1; K.4.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13110v2",
            "title": "White-Box Transformers via Sparse Rate Reduction: Compression Is All\n  There Is?",
            "updated": "2023-11-24T09:18:44Z",
            "published": "2023-11-22T02:23:32Z",
            "summary": "In this paper, we contend that a natural objective of representation learning\nis to compress and transform the distribution of the data, say sets of tokens,\ntowards a low-dimensional Gaussian mixture supported on incoherent subspaces.\nThe goodness of such a representation can be evaluated by a principled measure,\ncalled sparse rate reduction, that simultaneously maximizes the intrinsic\ninformation gain and extrinsic sparsity of the learned representation. From\nthis perspective, popular deep network architectures, including transformers,\ncan be viewed as realizing iterative schemes to optimize this measure.\nParticularly, we derive a transformer block from alternating optimization on\nparts of this objective: the multi-head self-attention operator compresses the\nrepresentation by implementing an approximate gradient descent step on the\ncoding rate of the features, and the subsequent multi-layer perceptron\nsparsifies the features. This leads to a family of white-box transformer-like\ndeep network architectures, named CRATE, which are mathematically fully\ninterpretable. We show, by way of a novel connection between denoising and\ncompression, that the inverse to the aforementioned compressive encoding can be\nrealized by the same class of CRATE architectures. Thus, the so-derived\nwhite-box architectures are universal to both encoders and decoders.\nExperiments show that these networks, despite their simplicity, indeed learn to\ncompress and sparsify representations of large-scale real-world image and text\ndatasets, and achieve performance very close to highly engineered\ntransformer-based models: ViT, MAE, DINO, BERT, and GPT2. We believe the\nproposed computational framework demonstrates great potential in bridging the\ngap between theory and practice of deep learning, from a unified perspective of\ndata compression. Code is available at: https://ma-lab-berkeley.github.io/CRATE .",
            "author": [
                "Yaodong Yu",
                "Sam Buchanan",
                "Druv Pai",
                "Tianzhe Chu",
                "Ziyang Wu",
                "Shengbang Tong",
                "Hao Bai",
                "Yuexiang Zhai",
                "Benjamin D. Haeffele",
                "Yi Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13110v2",
                "http://arxiv.org/pdf/2311.13110v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13105v1",
            "title": "Perceptual Structure in the Absence of Grounding for LLMs: The Impact of\n  Abstractedness and Subjectivity in Color Language",
            "updated": "2023-11-22T02:12:36Z",
            "published": "2023-11-22T02:12:36Z",
            "summary": "The need for grounding in language understanding is an active research topic.\nPrevious work has suggested that color perception and color language appear as\na suitable test bed to empirically study the problem, given its cognitive\nsignificance and showing that there is considerable alignment between a defined\ncolor space and the feature space defined by a language model. To further study\nthis issue, we collect a large scale source of colors and their descriptions,\ncontaining almost a 1 million examples , and perform an empirical analysis to\ncompare two kinds of alignments: (i) inter-space, by learning a mapping between\nembedding space and color space, and (ii) intra-space, by means of prompting\ncomparatives between color descriptions. Our results show that while color\nspace alignment holds for monolexemic, highly pragmatic color descriptions,\nthis alignment drops considerably in the presence of examples that exhibit\nelements of real linguistic usage such as subjectivity and abstractedness,\nsuggesting that grounding may be required in such cases.",
            "author": [
                "Pablo Loyola",
                "Edison Marrese-Taylor",
                "Andres Hoyos-Idobro"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13105v1",
                "http://arxiv.org/pdf/2311.13105v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13104v1",
            "title": "AC Power Flow Informed Parameter Learning for DC Power Flow Network\n  Equivalents",
            "updated": "2023-11-22T02:10:39Z",
            "published": "2023-11-22T02:10:39Z",
            "summary": "This paper presents an algorithm to optimize the parameters of power systems\nequivalents to enhance the accuracy of the DC power flow approximation in\nreduced networks. Based on a zonal division of the network, the algorithm\nproduces a reduced power system equivalent that captures inter-zonal flows with\naggregated buses and equivalent transmission lines. The algorithm refines\ncoefficient and bias parameters for the DC power flow model of the reduced\nnetwork, aiming to minimize discrepancies between inter-zonal flows in DC and\nAC power flow results. Using optimization methods like BFGS, L-BFGS, and TNC in\nan offline training phase, these parameters boost the accuracy of online DC\npower flow computations. In contrast to existing network equivalencing methods,\nthe proposed algorithm optimizes accuracy over a specified range of operation\nas opposed to only considering a single nominal point. Numerical tests\ndemonstrate substantial accuracy improvements over traditional equivalencing\nand approximation methods.",
            "author": [
                "Babak Taheri",
                "Daniel K. Molzahn"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13104v1",
                "http://arxiv.org/pdf/2311.13104v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13102v1",
            "title": "Detecting out-of-distribution text using topological features of\n  transformer-based language models",
            "updated": "2023-11-22T02:04:35Z",
            "published": "2023-11-22T02:04:35Z",
            "summary": "We attempt to detect out-of-distribution (OOD) text samples though applying\nTopological Data Analysis (TDA) to attention maps in transformer-based language\nmodels. We evaluate our proposed TDA-based approach for out-of-distribution\ndetection on BERT, a transformer-based language model, and compare the to a\nmore traditional OOD approach based on BERT CLS embeddings. We found that our\nTDA approach outperforms the CLS embedding approach at distinguishing\nin-distribution data (politics and entertainment news articles from HuffPost)\nfrom far out-of-domain samples (IMDB reviews), but its effectiveness\ndeteriorates with near out-of-domain (CNN/Dailymail) or same-domain (business\nnews articles from HuffPost) datasets.",
            "author": [
                "Andres Pollano",
                "Anupam Chaudhuri",
                "Anj Simmons"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13102v1",
                "http://arxiv.org/pdf/2311.13102v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG",
                "math.AT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13099v1",
            "title": "PIE-NeRF: Physics-based Interactive Elastodynamics with NeRF",
            "updated": "2023-11-22T01:58:26Z",
            "published": "2023-11-22T01:58:26Z",
            "summary": "We show that physics-based simulations can be seamlessly integrated with NeRF\nto generate high-quality elastodynamics of real-world objects. Unlike existing\nmethods, we discretize nonlinear hyperelasticity in a meshless way, obviating\nthe necessity for intermediate auxiliary shape proxies like a tetrahedral mesh\nor voxel grid. A quadratic generalized moving least square (Q-GMLS) is employed\nto capture nonlinear dynamics and large deformation on the implicit model. Such\nmeshless integration enables versatile simulations of complex and codimensional\nshapes. We adaptively place the least-square kernels according to the NeRF\ndensity field to significantly reduce the complexity of the nonlinear\nsimulation. As a result, physically realistic animations can be conveniently\nsynthesized using our method for a wide range of hyperelastic materials at an\ninteractive rate. For more information, please visit our project page at\nhttps://fytalon.github.io/pienerf/.",
            "author": [
                "Yutao Feng",
                "Yintong Shang",
                "Xuan Li",
                "Tianjia Shao",
                "Chenfanfu Jiang",
                "Yin Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13099v1",
                "http://arxiv.org/pdf/2311.13099v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.GR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13095v1",
            "title": "Enhancing Logical Reasoning in Large Language Models to Facilitate Legal\n  Applications",
            "updated": "2023-11-22T01:51:50Z",
            "published": "2023-11-22T01:51:50Z",
            "summary": "Language serves as a vehicle for conveying thought, enabling communication\namong individuals. The ability to distinguish between diverse concepts,\nidentify fairness and injustice, and comprehend a range of legal notions\nfundamentally relies on logical reasoning. Large Language Models (LLMs) attempt\nto emulate human language understanding and generation, but their competency in\nlogical reasoning remains limited. This paper seeks to address the\nphilosophical question: How can we effectively teach logical reasoning to LLMs\nwhile maintaining a deep understanding of the intricate relationship between\nlanguage and logic? By focusing on bolstering LLMs' capabilities in logical\nreasoning, we aim to expand their applicability in law and other\nlogic-intensive disciplines. To this end, we propose a Reinforcement Learning\nfrom Logical Feedback (RLLF) approach, which serves as a potential framework\nfor refining LLMs' reasoning capacities. Through RLLF and a revised evaluation\nmethodology, we explore new avenues for research in this domain and contribute\nto the development of LLMs capable of handling complex legal reasoning tasks\nwhile acknowledging the fundamental connection between language and logic.",
            "author": [
                "Ha-Thanh Nguyen",
                "Wachara Fungwacharakorn",
                "Ken Satoh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13095v1",
                "http://arxiv.org/pdf/2311.13095v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13094v1",
            "title": "Newton-CG methods for nonconvex unconstrained optimization with H\u00f6lder\n  continuous Hessian",
            "updated": "2023-11-22T01:50:43Z",
            "published": "2023-11-22T01:50:43Z",
            "summary": "In this paper we consider a nonconvex unconstrained optimization problem\nminimizing a twice differentiable objective function with H\\\"older continuous\nHessian. Specifically, we first propose a Newton-conjugate gradient (Newton-CG)\nmethod for finding an approximate first-order stationary point (FOSP) of this\nproblem, assuming the associated the H\\\"older parameters are explicitly known.\nThen we develop a parameter-free Newton-CG method without requiring any prior\nknowledge of these parameters. To the best of our knowledge, this method is the\nfirst parameter-free second-order method achieving the best-known iteration and\noperation complexity for finding an approximate FOSP of this problem.\nFurthermore, we propose a Newton-CG method for finding an approximate\nsecond-order stationary point (SOSP) of the considered problem with high\nprobability and establish its iteration and operation complexity. Finally, we\npresent preliminary numerical results to demonstrate the superior practical\nperformance of our parameter-free Newton-CG method over a well-known\nregularized Newton method.",
            "author": [
                "Chuan He",
                "Zhaosong Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13094v1",
                "http://arxiv.org/pdf/2311.13094v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13091v1",
            "title": "Stable Unlearnable Example: Enhancing the Robustness of Unlearnable\n  Examples via Stable Error-Minimizing Noise",
            "updated": "2023-11-22T01:43:57Z",
            "published": "2023-11-22T01:43:57Z",
            "summary": "The open source of large amounts of image data promotes the development of\ndeep learning techniques. Along with this comes the privacy risk of these\nopen-source image datasets being exploited by unauthorized third parties to\ntrain deep learning models for commercial or illegal purposes. To avoid the\nabuse of public data, a poisoning-based technique, the unlearnable example, is\nproposed to significantly degrade the generalization performance of models by\nadding a kind of imperceptible noise to the data. To further enhance its\nrobustness against adversarial training, existing works leverage iterative\nadversarial training on both the defensive noise and the surrogate model.\nHowever, it still remains unknown whether the robustness of unlearnable\nexamples primarily comes from the effect of enhancement in the surrogate model\nor the defensive noise. Observing that simply removing the adversarial noise on\nthe training process of the defensive noise can improve the performance of\nrobust unlearnable examples, we identify that solely the surrogate model's\nrobustness contributes to the performance. Furthermore, we found a negative\ncorrelation exists between the robustness of defensive noise and the protection\nperformance, indicating defensive noise's instability issue. Motivated by this,\nto further boost the robust unlearnable example, we introduce stable\nerror-minimizing noise (SEM), which trains the defensive noise against random\nperturbation instead of the time-consuming adversarial perturbation to improve\nthe stability of defensive noise. Through extensive experiments, we demonstrate\nthat SEM achieves a new state-of-the-art performance on CIFAR-10, CIFAR-100,\nand ImageNet Subset in terms of both effectiveness and efficiency. The code is\navailable at https://github.com/liuyixin-louis/Stable-Unlearnable-Example.",
            "author": [
                "Yixin Liu",
                "Kaidi Xu",
                "Xun Chen",
                "Lichao Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13091v1",
                "http://arxiv.org/pdf/2311.13091v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13087v1",
            "title": "Predict-Then-Optimize by Proxy: Learning Joint Models of Prediction and\n  Optimization",
            "updated": "2023-11-22T01:32:06Z",
            "published": "2023-11-22T01:32:06Z",
            "summary": "Many real-world decision processes are modeled by optimization problems whose\ndefining parameters are unknown and must be inferred from observable data. The\nPredict-Then-Optimize framework uses machine learning models to predict unknown\nparameters of an optimization problem from features before solving. Recent\nworks show that decision quality can be improved in this setting by solving and\ndifferentiating the optimization problem in the training loop, enabling\nend-to-end training with loss functions defined directly on the resulting\ndecisions. However, this approach can be inefficient and requires handcrafted,\nproblem-specific rules for backpropagation through the optimization step. This\npaper proposes an alternative method, in which optimal solutions are learned\ndirectly from the observable features by predictive models. The approach is\ngeneric, and based on an adaptation of the Learning-to-Optimize paradigm, from\nwhich a rich variety of existing techniques can be employed. Experimental\nevaluations show the ability of several Learning-to-Optimize methods to provide\nefficient, accurate, and flexible solutions to an array of challenging\nPredict-Then-Optimize problems.",
            "author": [
                "James Kotary",
                "Vincenzo Di Vito",
                "Jacob Christopher",
                "Pascal Van Hentenryck",
                "Ferdinando Fioretto"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13087v1",
                "http://arxiv.org/pdf/2311.13087v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13081v1",
            "title": "Learning to Fly in Seconds",
            "updated": "2023-11-22T01:06:45Z",
            "published": "2023-11-22T01:06:45Z",
            "summary": "Learning-based methods, particularly Reinforcement Learning (RL), hold great\npromise for streamlining deployment, enhancing performance, and achieving\ngeneralization in the control of autonomous multirotor aerial vehicles. Deep RL\nhas been able to control complex systems with impressive fidelity and agility\nin simulation but the simulation-to-reality transfer often brings a\nhard-to-bridge reality gap. Moreover, RL is commonly plagued by prohibitively\nlong training times. In this work, we propose a novel asymmetric\nactor-critic-based architecture coupled with a highly reliable RL-based\ntraining paradigm for end-to-end quadrotor control. We show how curriculum\nlearning and a highly optimized simulator enhance sample complexity and lead to\nfast training times. To precisely discuss the challenges related to\nlow-level/end-to-end multirotor control, we also introduce a taxonomy that\nclassifies the existing levels of control abstractions as well as\nnon-linearities and domain parameters. Our framework enables\nSimulation-to-Reality (Sim2Real) transfer for direct RPM control after only 18\nseconds of training on a consumer-grade laptop as well as its deployment on\nmicrocontrollers to control a multirotor under real-time guarantees. Finally,\nour solution exhibits competitive performance in trajectory tracking, as\ndemonstrated through various experimental comparisons with existing\nstate-of-the-art control solutions using a real Crazyflie nano quadrotor. We\nopen source the code including a very fast multirotor dynamics simulator that\ncan simulate about 5 months of flight per second on a laptop GPU. The fast\ntraining times and deployment to a cheap, off-the-shelf quadrotor lower the\nbarriers to entry and help democratize the research and development of these\nsystems.",
            "author": [
                "Jonas Eschmann",
                "Dario Albani",
                "Giuseppe Loianno"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13081v1",
                "http://arxiv.org/pdf/2311.13081v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13080v1",
            "title": "High-Speed Voltage Control in Active Distribution Systems with Smart\n  Inverter Coordination and Deep Reinforcement Learning",
            "updated": "2023-11-22T00:58:16Z",
            "published": "2023-11-22T00:58:16Z",
            "summary": "The increasing penetration of renewable energy resources in distribution\nsystems necessitates high-speed monitoring and control of voltage for ensuring\nreliable system operation. However, existing voltage control algorithms often\nmake simplifying assumptions in their formulation, such as real-time\navailability of smart meter measurements (for monitoring), or real-time\nknowledge of every power injection information(for control).This paper\nleverages the recent advances made in highspeed state estimation for real-time\nunobservable distribution systems to formulate a deep reinforcement\nlearning-based control algorithm that utilizes the state estimates alone to\ncontrol the voltage of the entire system. The results obtained for a modified\n(renewable-rich) IEEE34-nodedistributionfeeder indicate that the proposed\napproach excels in monitoring and controlling voltage of active distribution\nsystems.",
            "author": [
                "Mohammad Golgol",
                "Anamitra Pal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13080v1",
                "http://arxiv.org/pdf/2311.13080v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14737v1",
            "title": "Positional Description Matters for Transformers Arithmetic",
            "updated": "2023-11-22T00:31:01Z",
            "published": "2023-11-22T00:31:01Z",
            "summary": "Transformers, central to the successes in modern Natural Language Processing,\noften falter on arithmetic tasks despite their vast capabilities --which\nparadoxically include remarkable coding abilities. We observe that a crucial\nchallenge is their naive reliance on positional information to solve arithmetic\nproblems with a small number of digits, leading to poor performance on larger\nnumbers. Herein, we delve deeper into the role of positional encoding, and\npropose several ways to fix the issue, either by modifying the positional\nencoding directly, or by modifying the representation of the arithmetic task to\nleverage standard positional encoding differently. We investigate the value of\nthese modifications for three tasks: (i) classical multiplication, (ii) length\nextrapolation in addition, and (iii) addition in natural language context. For\n(i) we train a small model on a small dataset (100M parameters and 300k\nsamples) with remarkable aptitude in (direct, no scratchpad) 15 digits\nmultiplication and essentially perfect up to 12 digits, while usual training in\nthis context would give a model failing at 4 digits multiplication. In the\nexperiments on addition, we use a mere 120k samples to demonstrate: for (ii)\nextrapolation from 10 digits to testing on 12 digits numbers while usual\ntraining would have no extrapolation, and for (iii) almost perfect accuracy up\nto 5 digits while usual training would be correct only up to 3 digits (which is\nessentially memorization with a training set of 120k samples).",
            "author": [
                "Ruoqi Shen",
                "S\u00e9bastien Bubeck",
                "Ronen Eldan",
                "Yin Tat Lee",
                "Yuanzhi Li",
                "Yi Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14737v1",
                "http://arxiv.org/pdf/2311.14737v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13073v1",
            "title": "FusionFrames: Efficient Architectural Aspects for Text-to-Video\n  Generation Pipeline",
            "updated": "2023-11-22T00:26:15Z",
            "published": "2023-11-22T00:26:15Z",
            "summary": "Multimedia generation approaches occupy a prominent place in artificial\nintelligence research. Text-to-image models achieved high-quality results over\nthe last few years. However, video synthesis methods recently started to\ndevelop. This paper presents a new two-stage latent diffusion text-to-video\ngeneration architecture based on the text-to-image diffusion model. The first\nstage concerns keyframes synthesis to figure the storyline of a video, while\nthe second one is devoted to interpolation frames generation to make movements\nof the scene and objects smooth. We compare several temporal conditioning\napproaches for keyframes generation. The results show the advantage of using\nseparate temporal blocks over temporal layers in terms of metrics reflecting\nvideo generation quality aspects and human preference. The design of our\ninterpolation model significantly reduces computational costs compared to other\nmasked frame interpolation approaches. Furthermore, we evaluate different\nconfigurations of MoVQ-based video decoding scheme to improve consistency and\nachieve higher PSNR, SSIM, MSE, and LPIPS scores. Finally, we compare our\npipeline with existing solutions and achieve top-2 scores overall and top-1\namong open-source solutions: CLIPSIM = 0.2976 and FVD = 433.054. Project page:\nhttps://ai-forever.github.io/kandinsky-video/",
            "author": [
                "Vladimir Arkhipkin",
                "Zein Shaheen",
                "Viacheslav Vasilev",
                "Elizaveta Dakhova",
                "Andrey Kuznetsov",
                "Denis Dimitrov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13073v1",
                "http://arxiv.org/pdf/2311.13073v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13069v1",
            "title": "FuseNet: Self-Supervised Dual-Path Network for Medical Image\n  Segmentation",
            "updated": "2023-11-22T00:03:16Z",
            "published": "2023-11-22T00:03:16Z",
            "summary": "Semantic segmentation, a crucial task in computer vision, often relies on\nlabor-intensive and costly annotated datasets for training. In response to this\nchallenge, we introduce FuseNet, a dual-stream framework for self-supervised\nsemantic segmentation that eliminates the need for manual annotation. FuseNet\nleverages the shared semantic dependencies between the original and augmented\nimages to create a clustering space, effectively assigning pixels to\nsemantically related clusters, and ultimately generating the segmentation map.\nAdditionally, FuseNet incorporates a cross-modal fusion technique that extends\nthe principles of CLIP by replacing textual data with augmented images. This\napproach enables the model to learn complex visual representations, enhancing\nrobustness against variations similar to CLIP's text invariance. To further\nimprove edge alignment and spatial consistency between neighboring pixels, we\nintroduce an edge refinement loss. This loss function considers edge\ninformation to enhance spatial coherence, facilitating the grouping of nearby\npixels with similar visual features. Extensive experiments on skin lesion and\nlung segmentation datasets demonstrate the effectiveness of our method.\n\\href{https://github.com/xmindflow/FuseNet}{Codebase.}",
            "author": [
                "Amirhossein Kazerouni",
                "Sanaz Karimijafarbigloo",
                "Reza Azad",
                "Yury Velichko",
                "Ulas Bagci",
                "Dorit Merhof"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13069v1",
                "http://arxiv.org/pdf/2311.13069v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13060v2",
            "title": "Training Deep 3D Convolutional Neural Networks to Extract BSM Physics\n  Parameters Directly from HEP Data: a Proof-of-Concept Study Using Monte Carlo\n  Simulations",
            "updated": "2023-12-07T17:11:58Z",
            "published": "2023-11-21T23:49:51Z",
            "summary": "We report on a novel application of computer vision techniques to extract\nbeyond the Standard Model (BSM) parameters directly from high energy physics\n(HEP) flavor data. We develop a method of transforming angular and kinematic\ndistributions into \"quasi-images\" that can be used to train a convolutional\nneural network to perform regression tasks, similar to fitting. This contrasts\nwith the usual classification functions performed using ML/AI in HEP. As a\nproof-of-concept, we train a 34-layer Residual Neural Network to regress on\nthese images and determine the Wilson Coefficient $C_{9}$ in MC (Monte Carlo)\nsimulations of $B \\rightarrow K^{*}\\mu^{+}\\mu^{-}$ decays. The technique\ndescribed here can be generalized and may find applicability across various HEP\nexperiments and elsewhere.",
            "author": [
                "S. Dubey",
                "T. E. Browder",
                "S. Kohani",
                "R. Mandal",
                "A. Sibidanov",
                "R. Sinha"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13060v2",
                "http://arxiv.org/pdf/2311.13060v2"
            ],
            "primary_category": "hep-ex",
            "category": [
                "hep-ex",
                "cs.LG",
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13059v1",
            "title": "A note on estimating the dimension from a random geometric graph",
            "updated": "2023-11-21T23:46:44Z",
            "published": "2023-11-21T23:46:44Z",
            "summary": "Let $G_n$ be a random geometric graph with vertex set $[n]$ based on $n$\ni.i.d.\\ random vectors $X_1,\\ldots,X_n$ drawn from an unknown density $f$ on\n$\\R^d$. An edge $(i,j)$ is present when $\\|X_i -X_j\\| \\le r_n$, for a given\nthreshold $r_n$ possibly depending upon $n$, where $\\| \\cdot \\|$ denotes\nEuclidean distance. We study the problem of estimating the dimension $d$ of the\nunderlying space when we have access to the adjacency matrix of the graph but\ndo not know $r_n$ or the vectors $X_i$. The main result of the paper is that\nthere exists an estimator of $d$ that converges to $d$ in probability as $n \\to\n\\infty$ for all densities with $\\int f^5 < \\infty$ whenever $n^{3/2} r_n^d \\to\n\\infty$ and $r_n = o(1)$. The conditions allow very sparse graphs since when\n$n^{3/2} r_n^d \\to 0$, the graph contains isolated edges only, with high\nprobability. We also show that, without any condition on the density, a\nconsistent estimator of $d$ exists when $n r_n^d \\to \\infty$ and $r_n = o(1)$.",
            "author": [
                "Caelan Atamanchuk",
                "Luc Devroye",
                "Gabor Lugosi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13059v1",
                "http://arxiv.org/pdf/2311.13059v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13058v1",
            "title": "Self-Supervised Music Source Separation Using Vector-Quantized Source\n  Category Estimates",
            "updated": "2023-11-21T23:45:36Z",
            "published": "2023-11-21T23:45:36Z",
            "summary": "Music source separation is focused on extracting distinct sonic elements from\ncomposite tracks. Historically, many methods have been grounded in supervised\nlearning, necessitating labeled data, which is occasionally constrained in its\ndiversity. More recent methods have delved into N-shot techniques that utilize\none or more audio samples to aid in the separation. However, a challenge with\nsome of these methods is the necessity for an audio query during inference,\nmaking them less suited for genres with varied timbres and effects. This paper\noffers a proof-of-concept for a self-supervised music source separation system\nthat eliminates the need for audio queries at inference time. In the training\nphase, while it adopts a query-based approach, we introduce a modification by\nsubstituting the continuous embedding of query audios with Vector Quantized\n(VQ) representations. Trained end-to-end with up to N classes as determined by\nthe VQ's codebook size, the model seeks to effectively categorise instrument\nclasses. During inference, the input is partitioned into N sources, with some\npotentially left unutilized based on the mix's instrument makeup. This\nmethodology suggests an alternative avenue for considering source separation\nacross diverse music genres. We provide examples and additional results online.",
            "author": [
                "Marco Pasini",
                "Stefan Lattner",
                "George Fazekas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13058v1",
                "http://arxiv.org/pdf/2311.13058v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13057v2",
            "title": "The HaLLMark Effect: Supporting Provenance and Transparent Use of Large\n  Language Models in Writing through Interactive Visualization",
            "updated": "2023-11-26T22:42:05Z",
            "published": "2023-11-21T23:42:55Z",
            "summary": "The use of Large Language Models (LLMs) for writing has sparked controversy\nboth among readers and writers. On one hand, writers are concerned that LLMs\nwill deprive them of agency and ownership, and readers are concerned about\nspending their time on text generated by soulless machines. On the other hand,\nwriters who genuinely want to use LLMs must conform to publisher policies for\nAI-assisted writing, and readers need assurance that a text has been verified\nby a human. We argue that a system that captures the provenance of interaction\nwith an LLM can help writers retain their agency, conform to policies, and\ncommunicate their use of AI to publishers and readers transparently. Thus we\npropose HaLLMark, a tool for facilitating and visualizing writers' interaction\nwith LLMs. We evaluated HaLLMark with 13 creative writers, and found that it\nhelped them retain a sense of control and ownership of the written text.",
            "author": [
                "Md Naimul Hoque",
                "Tasfia Mashiat",
                "Bhavya Ghai",
                "Cecilia Shelton",
                "Fanny Chevalier",
                "Kari Kraus",
                "Niklas Elmqvist"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13057v2",
                "http://arxiv.org/pdf/2311.13057v2"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13056v1",
            "title": "Composite Adaptive Lyapunov-Based Deep Neural Network (Lb-DNN)\n  Controller",
            "updated": "2023-11-21T23:41:07Z",
            "published": "2023-11-21T23:41:07Z",
            "summary": "Recent advancements in adaptive control have equipped deep neural network\n(DNN)-based controllers with Lyapunov-based adaptation laws that work across a\nrange of DNN architectures to uniquely enable online learning. However, the\nadaptation laws are based on tracking error, and offer convergence guarantees\non only the tracking error without providing conclusions on the parameter\nestimation performance. Motivated to provide guarantees on the DNN parameter\nestimation performance, this paper provides the first result on composite\nadaptation for adaptive Lyapunov-based DNN controllers, which uses the Jacobian\nof the DNN and a prediction error of the dynamics that is computed using a\nnovel method involving an observer of the dynamics. A Lyapunov-based stability\nanalysis is performed which guarantees the tracking, observer, and parameter\nestimation errors are uniformly ultimately bounded (UUB), with stronger\nperformance guarantees when the DNN's Jacobian satisfies the persistence of\nexcitation (PE) condition. Comparative simulation results demonstrate a\nsignificant performance improvement with the developed composite adaptive\nLb-DNN controller in comparison to the tracking error-based Lb-DNN.",
            "author": [
                "Omkar Sudhir Patil",
                "Emily J. Griffis",
                "Wanjiku A. Makumi",
                "Warren E. Dixon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13056v1",
                "http://arxiv.org/pdf/2311.13056v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13612v1",
            "title": "Descriptor and Word Soups: Overcoming the Parameter Efficiency Accuracy\n  Tradeoff for Out-of-Distribution Few-shot Learning",
            "updated": "2023-11-21T23:30:01Z",
            "published": "2023-11-21T23:30:01Z",
            "summary": "Over the past year, a large body of multimodal research has emerged around\nzero-shot evaluation using GPT descriptors. These studies boost the zero-shot\naccuracy of pretrained VL models with an ensemble of label-specific text\ngenerated by GPT. A recent study, WaffleCLIP, demonstrated that similar\nzero-shot accuracy can be achieved with an ensemble of random descriptors.\nHowever, both zero-shot methods are un-trainable and consequently sub-optimal\nwhen some few-shot out-of-distribution (OOD) training data is available.\nInspired by these prior works, we present two more flexible methods called\ndescriptor and word soups, which do not require an LLM at test time and can\nleverage training data to increase OOD target accuracy. Descriptor soup\ngreedily selects a small set of textual descriptors using generic few-shot\ntraining data, then calculates robust class embeddings using the selected\ndescriptors. Word soup greedily assembles a chain of words in a similar manner.\nCompared to existing few-shot soft prompt tuning methods, word soup requires\nfewer parameters by construction and less GPU memory, since it does not require\nbackpropagation. Both soups outperform current published few-shot methods, even\nwhen combined with SoTA zero-shot methods, on cross-dataset and domain\ngeneralization benchmarks. Compared with SoTA prompt and descriptor ensembling\nmethods, such as ProDA and WaffleCLIP, word soup achieves higher OOD accuracy\nwith fewer ensemble members. Please checkout our code:\ngithub.com/Chris210634/word_soups",
            "author": [
                "Christopher Liao",
                "Theodoros Tsiligkaridis",
                "Brian Kulis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13612v1",
                "http://arxiv.org/pdf/2311.13612v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13052v1",
            "title": "Novel OCT mosaicking pipeline with Feature- and Pixel-based registration",
            "updated": "2023-11-21T23:25:04Z",
            "published": "2023-11-21T23:25:04Z",
            "summary": "High-resolution Optical Coherence Tomography (OCT) images are crucial for\nophthalmology studies but are limited by their relatively narrow field of view\n(FoV). Image mosaicking is a technique for aligning multiple overlapping images\nto obtain a larger FoV. Current mosaicking pipelines often struggle with\nsubstantial noise and considerable displacement between the input sub-fields.\nIn this paper, we propose a versatile pipeline for stitching multi-view\nOCT/OCTA \\textit{en face} projection images. Our method combines the strengths\nof learning-based feature matching and robust pixel-based registration to align\nmultiple images effectively. Furthermore, we advance the application of a\ntrained foundational model, Segment Anything Model (SAM), to validate\nmosaicking results in an unsupervised manner. The efficacy of our pipeline is\nvalidated using an in-house dataset and a large public dataset, where our\nmethod shows superior performance in terms of both accuracy and computational\nefficiency. We also made our evaluation tool for image mosaicking and the\ncorresponding pipeline publicly available at\n\\url{https://github.com/MedICL-VU/OCT-mosaicking}.",
            "author": [
                "Jiacheng Wang",
                "Hao Li",
                "Dewei Hu",
                "Yuankai K. Tao",
                "Ipek Oguz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13052v1",
                "http://arxiv.org/pdf/2311.13052v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13050v1",
            "title": "Multi-fidelity Bayesian Optimization in Engineering Design",
            "updated": "2023-11-21T23:22:11Z",
            "published": "2023-11-21T23:22:11Z",
            "summary": "Resided at the intersection of multi-fidelity optimization (MFO) and Bayesian\noptimization (BO), MF BO has found a niche in solving expensive engineering\ndesign optimization problems, thanks to its advantages in incorporating\nphysical and mathematical understandings of the problems, saving resources,\naddressing exploitation-exploration trade-off, considering uncertainty, and\nprocessing parallel computing. The increasing number of works dedicated to MF\nBO suggests the need for a comprehensive review of this advanced optimization\ntechnique. In this paper, we survey recent developments of two essential\ningredients of MF BO: Gaussian process (GP) based MF surrogates and acquisition\nfunctions. We first categorize the existing MF modeling methods and MFO\nstrategies to locate MF BO in a large family of surrogate-based optimization\nand MFO algorithms. We then exploit the common properties shared between the\nmethods from each ingredient of MF BO to describe important GP-based MF\nsurrogate models and review various acquisition functions. By doing so, we\nexpect to provide a structured understanding of MF BO. Finally, we attempt to\nreveal important aspects that require further research for applications of MF\nBO in solving intricate yet important design optimization problems, including\nconstrained optimization, high-dimensional optimization, optimization under\nuncertainty, and multi-objective optimization.",
            "author": [
                "Bach Do",
                "Ruda Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13050v1",
                "http://arxiv.org/pdf/2311.13050v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE",
                "cs.LG",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13046v1",
            "title": "Do we listen to what we are told? An empirical study on human behaviour\n  during the COVID-19 pandemic: neural networks vs. regression analysis",
            "updated": "2023-11-21T23:14:47Z",
            "published": "2023-11-21T23:14:47Z",
            "summary": "In this work, we contribute the first visual open-source empirical study on\nhuman behaviour during the COVID-19 pandemic, in order to investigate how\ncompliant a general population is to mask-wearing-related public-health policy.\nObject-detection-based convolutional neural networks, regression analysis and\nmultilayer perceptrons are combined to analyse visual data of the Viennese\npublic during 2020. We find that mask-wearing-related government regulations\nand public-transport announcements encouraged correct mask-wearing-behaviours\nduring the COVID-19 pandemic. Importantly, changes in announcement and\nregulation contents led to heterogeneous effects on people's behaviour.\nComparing the predictive power of regression analysis and neural networks, we\ndemonstrate that the latter produces more accurate predictions of population\nreactions during the COVID-19 pandemic. Our use of regression modelling also\nallows us to unearth possible causal pathways underlying societal behaviour.\nSince our findings highlight the importance of appropriate communication\ncontents, our results will facilitate more effective non-pharmaceutical\ninterventions to be developed in future. Adding to the literature, we\ndemonstrate that regression modelling and neural networks are not mutually\nexclusive but instead complement each other.",
            "author": [
                "Yuxi Heluo",
                "Kexin Wang",
                "Charles W. Robson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13046v1",
                "http://arxiv.org/pdf/2311.13046v1"
            ],
            "primary_category": "econ.GN",
            "category": [
                "econ.GN",
                "cs.AI",
                "cs.LG",
                "q-fin.EC",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13045v1",
            "title": "Camera-Independent Single Image Depth Estimation from Defocus Blur",
            "updated": "2023-11-21T23:14:42Z",
            "published": "2023-11-21T23:14:42Z",
            "summary": "Monocular depth estimation is an important step in many downstream tasks in\nmachine vision. We address the topic of estimating monocular depth from defocus\nblur which can yield more accurate results than the semantic based depth\nestimation methods. The existing monocular depth from defocus techniques are\nsensitive to the particular camera that the images are taken from. We show how\nseveral camera-related parameters affect the defocus blur using optical physics\nequations and how they make the defocus blur depend on these parameters. The\nsimple correction procedure we propose can alleviate this problem which does\nnot require any retraining of the original model. We created a synthetic\ndataset which can be used to test the camera independent performance of depth\nfrom defocus blur models. We evaluate our model on both synthetic and real\ndatasets (DDFF12 and NYU depth V2) obtained with different cameras and show\nthat our methods are significantly more robust to the changes of cameras. Code:\nhttps://github.com/sleekEagle/defocus_camind.git",
            "author": [
                "Lahiru Wijayasingha",
                "Homa Alemzadeh",
                "John A. Stankovic"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13045v1",
                "http://arxiv.org/pdf/2311.13045v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13043v1",
            "title": "FedCPC: An Effective Federated Contrastive Learning Method for Privacy\n  Preserving Early-Stage Alzheimer's Speech Detection",
            "updated": "2023-11-21T23:08:06Z",
            "published": "2023-11-21T23:08:06Z",
            "summary": "The early-stage Alzheimer's disease (AD) detection has been considered an\nimportant field of medical studies. Like traditional machine learning methods,\nspeech-based automatic detection also suffers from data privacy risks because\nthe data of specific patients are exclusive to each medical institution. A\ncommon practice is to use federated learning to protect the patients' data\nprivacy. However, its distributed learning process also causes performance\nreduction. To alleviate this problem while protecting user privacy, we propose\na federated contrastive pre-training (FedCPC) performed before federated\ntraining for AD speech detection, which can learn a better representation from\nraw data and enables different clients to share data in the pre-training and\ntraining stages. Experimental results demonstrate that the proposed methods can\nachieve satisfactory performance while preserving data privacy.",
            "author": [
                "Wenqing Wei",
                "Zhengdong Yang",
                "Yuan Gao",
                "Jiyi Li",
                "Chenhui Chu",
                "Shogo Okada",
                "Sheng Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13043v1",
                "http://arxiv.org/pdf/2311.13043v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13038v1",
            "title": "Synaptic Sampling of Neural Networks",
            "updated": "2023-11-21T22:56:13Z",
            "published": "2023-11-21T22:56:13Z",
            "summary": "Probabilistic artificial neural networks offer intriguing prospects for\nenabling the uncertainty of artificial intelligence methods to be described\nexplicitly in their function; however, the development of techniques that\nquantify uncertainty by well-understood methods such as Monte Carlo sampling\nhas been limited by the high costs of stochastic sampling on deterministic\ncomputing hardware. Emerging computing systems that are amenable to\nhardware-level probabilistic computing, such as those that leverage stochastic\ndevices, may make probabilistic neural networks more feasible in the\nnot-too-distant future. This paper describes the scANN technique --\n\\textit{sampling (by coinflips) artificial neural networks} -- which enables\nneural networks to be sampled directly by treating the weights as Bernoulli\ncoin flips. This method is natively well suited for probabilistic computing\ntechniques that focus on tunable stochastic devices, nearly matches fully\ndeterministic performance while also describing the uncertainty of correct and\nincorrect neural network outputs.",
            "author": [
                "James B. Aimone",
                "William Severa",
                "J. Darby Smith"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13038v1",
                "http://arxiv.org/pdf/2311.13038v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13036v1",
            "title": "Favour: FAst Variance Operator for Uncertainty Rating",
            "updated": "2023-11-21T22:53:20Z",
            "published": "2023-11-21T22:53:20Z",
            "summary": "Bayesian Neural Networks (BNN) have emerged as a crucial approach for\ninterpreting ML predictions. By sampling from the posterior distribution, data\nscientists may estimate the uncertainty of an inference. Unfortunately many\ninference samples are often needed, the overhead of which greatly hinder BNN's\nwide adoption. To mitigate this, previous work proposed propagating the first\nand second moments of the posterior directly through the network. However, on\nits own this method is even slower than sampling, so the propagated variance\nneeds to be approximated such as assuming independence between neural nodes.\nThe resulting trade-off between quality and inference time did not match even\nplain Monte Carlo sampling.\n  Our contribution is a more principled variance propagation framework based on\n\"spiked covariance matrices\", which smoothly interpolates between quality and\ninference time. This is made possible by a new fast algorithm for updating a\ndiagonal-plus-low-rank matrix approximation under various operations. We tested\nour algorithm against sampling based MC Dropout and Variational Inference on a\nnumber of downstream uncertainty themed tasks, such as calibration and\nout-of-distribution testing. We find that Favour is as fast as performing 2-3\ninference samples, while matching the performance of 10-100 samples.\n  In summary, this work enables the use of BNN in the realm of performance\ncritical tasks where they have previously been out of reach.",
            "author": [
                "Thomas D. Ahle",
                "Sahar Karimi",
                "Peter Tak Peter Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13036v1",
                "http://arxiv.org/pdf/2311.13036v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13029v1",
            "title": "Systematic word meta-sense extension",
            "updated": "2023-11-21T22:30:37Z",
            "published": "2023-11-21T22:30:37Z",
            "summary": "The meaning of polysemous words often varies in a highly productive yet\npredictable way. Generalizing the regularity between conventional senses to\nderive novel word meaning is crucial for automated processing of non-literal\nlanguage uses such as figurative expressions. We introduce a novel task called\nsystematic word meta-sense extension (SWORME) to test and improve language\nmodels' ability to extend word meaning to denote new semantic domains (also\ncalled meta-senses) that bear regular semantic relations with existing senses.\nWe found that language models prefer incremental lexical semantic change toward\nconceptually similar meta-senses such as logical metonymy, and are much worse\nat predicting highly non-literal meaning extensions such as metaphors. We\npropose a novel analogy-based method of word meaning extension, and show that\nit effectively improves language model systematicity in making both gradual and\nradical types of meta-sense extension. We further demonstrate that learning\nsystematic meta-sense extensions benefits language models on multiple\nbenchmarks of figurative language understanding.",
            "author": [
                "Lei Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13029v1",
                "http://arxiv.org/pdf/2311.13029v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13028v1",
            "title": "DMLR: Data-centric Machine Learning Research -- Past, Present and Future",
            "updated": "2023-11-21T22:29:25Z",
            "published": "2023-11-21T22:29:25Z",
            "summary": "Drawing from discussions at the inaugural DMLR workshop at ICML 2023 and\nmeetings prior, in this report we outline the relevance of community engagement\nand infrastructure development for the creation of next-generation public\ndatasets that will advance machine learning science. We chart a path forward as\na collective effort to sustain the creation and maintenance of these datasets\nand methods towards positive scientific, societal and business impact.",
            "author": [
                "Luis Oala",
                "Manil Maskey",
                "Lilith Bat-Leah",
                "Alicia Parrish",
                "Nezihe Merve G\u00fcrel",
                "Tzu-Sheng Kuo",
                "Yang Liu",
                "Rotem Dror",
                "Danilo Brajovic",
                "Xiaozhe Yao",
                "Max Bartolo",
                "William A Gaviria Rojas",
                "Ryan Hileman",
                "Rainier Aliment",
                "Michael W. Mahoney",
                "Meg Risdal",
                "Matthew Lease",
                "Wojciech Samek",
                "Debojyoti Dutta",
                "Curtis G Northcutt",
                "Cody Coleman",
                "Braden Hancock",
                "Bernard Koch",
                "Girmaw Abebe Tadesse",
                "Bojan Karla\u0161",
                "Ahmed Alaa",
                "Adji Bousso Dieng",
                "Natasha Noy",
                "Vijay Janapa Reddi",
                "James Zou",
                "Praveen Paritosh",
                "Mihaela van der Schaar",
                "Kurt Bollacker",
                "Lora Aroyo",
                "Ce Zhang",
                "Joaquin Vanschoren",
                "Isabelle Guyon",
                "Peter Mattson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13028v1",
                "http://arxiv.org/pdf/2311.13028v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DC",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13611v1",
            "title": "Computational-design Enabled Wearable and Tunable Metamaterials via\n  Freeform Auxetics for Magnetic Resonance Imaging",
            "updated": "2023-11-21T22:10:03Z",
            "published": "2023-11-21T22:10:03Z",
            "summary": "Metamaterials hold significant promise for enhancing the imaging capabilities\nof MRI machines as an additive technology, due to their unique ability to\nenhance local magnetic fields. However, despite their potential, the\nmetamaterials reported in the context of MRI applications have often been\nimpractical. This impracticality arises from their predominantly flat\nconfigurations and their susceptibility to shifts in resonance frequencies,\npreventing them from realizing their optimal performance. Here, we introduce a\ncomputational method for designing wearable and tunable metamaterials via\nfreeform auxetics. The proposed computational-design tools yield an approach to\nsolving the complex circle packing problems in an interactive and efficient\nmanner, thus facilitating the development of deployable metamaterials\nconfigured in freeform shapes. With such tools, the developed metamaterials may\nreadily conform to a patient's kneecap, ankle, head, or any part of the body in\nneed of imaging, and while ensuring an optimal resonance frequency, thereby\npaving the way for the widespread adoption of metamaterials in clinical MRI\napplications.",
            "author": [
                "Ke Wu",
                "Xia Zhu",
                "Thomas G. Bifano",
                "Stephan W. Anderson",
                "Xin Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13611v1",
                "http://arxiv.org/pdf/2311.13611v1"
            ],
            "primary_category": "physics.med-ph",
            "category": [
                "physics.med-ph",
                "physics.ins-det"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13022v1",
            "title": "Unsupervised Multimodal Surface Registration with Geometric Deep\n  Learning",
            "updated": "2023-11-21T22:05:00Z",
            "published": "2023-11-21T22:05:00Z",
            "summary": "This paper introduces GeoMorph, a novel geometric deep-learning framework\ndesigned for image registration of cortical surfaces. The registration process\nconsists of two main steps. First, independent feature extraction is performed\non each input surface using graph convolutions, generating low-dimensional\nfeature representations that capture important cortical surface\ncharacteristics. Subsequently, features are registered in a deep-discrete\nmanner to optimize the overlap of common structures across surfaces by learning\ndisplacements of a set of control points. To ensure smooth and biologically\nplausible deformations, we implement regularization through a deep conditional\nrandom field implemented with a recurrent neural network. Experimental results\ndemonstrate that GeoMorph surpasses existing deep-learning methods by achieving\nimproved alignment with smoother deformations. Furthermore, GeoMorph exhibits\ncompetitive performance compared to classical frameworks. Such versatility and\nrobustness suggest strong potential for various neuroscience applications.",
            "author": [
                "Mohamed A. Suliman",
                "Logan Z. J. Williams",
                "Abdulah Fawaz",
                "Emma C. Robinson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13022v1",
                "http://arxiv.org/pdf/2311.13022v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13021v1",
            "title": "A Study of Human-Robot Handover through Human-Human Object Transfer",
            "updated": "2023-11-21T21:57:43Z",
            "published": "2023-11-21T21:57:43Z",
            "summary": "In this preliminary study, we investigate changes in handover behaviour when\ntransferring hazardous objects with the help of a high-resolution touch sensor.\nParticipants were asked to hand over a safe and hazardous object (a full cup\nand an empty cup) while instrumented with a modified STS sensor. Our data shows\na clear distinction in the length of handover for the full cup vs the empty\none, with the former being slower. Sensor data further suggests a change in\ntactile behaviour dependent on the object's risk factor. The results of this\npaper motivate a deeper study of tactile factors which could characterize a\nrisky handover, allowing for safer human-robot interactions in the future.",
            "author": [
                "Charlotte Morissette",
                "Bobak H. Baghi",
                "Francois R. Hogan",
                "Gregory Dudek"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13021v1",
                "http://arxiv.org/pdf/2311.13021v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17894v1",
            "title": "Learning and Controlling Silicon Dopant Transitions in Graphene using\n  Scanning Transmission Electron Microscopy",
            "updated": "2023-11-21T21:51:00Z",
            "published": "2023-11-21T21:51:00Z",
            "summary": "We introduce a machine learning approach to determine the transition dynamics\nof silicon atoms on a single layer of carbon atoms, when stimulated by the\nelectron beam of a scanning transmission electron microscope (STEM). Our method\nis data-centric, leveraging data collected on a STEM. The data samples are\nprocessed and filtered to produce symbolic representations, which we use to\ntrain a neural network to predict transition probabilities. These learned\ntransition dynamics are then leveraged to guide a single silicon atom\nthroughout the lattice to pre-determined target destinations. We present\nempirical analyses that demonstrate the efficacy and generality of our\napproach.",
            "author": [
                "Max Schwarzer",
                "Jesse Farebrother",
                "Joshua Greaves",
                "Ekin Dogus Cubuk",
                "Rishabh Agarwal",
                "Aaron Courville",
                "Marc G. Bellemare",
                "Sergei Kalinin",
                "Igor Mordatch",
                "Pablo Samuel Castro",
                "Kevin M. Roccapriore"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17894v1",
                "http://arxiv.org/pdf/2311.17894v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall",
                "cond-mat.mtrl-sci",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13017v1",
            "title": "W-kernel and essential subspace for frequencist's evaluation of Bayesian\n  estimators",
            "updated": "2023-11-21T21:46:04Z",
            "published": "2023-11-21T21:46:04Z",
            "summary": "The posterior covariance matrix W defined by the log-likelihood of each\nobservation plays important roles both in the sensitivity analysis and\nfrequencist's evaluation of the Bayesian estimators. This study focused on the\nmatrix W and its principal space; we term the latter as an essential subspace.\nFirst, it is shown that they appear in various statistical settings, such as\nthe evaluation of the posterior sensitivity, assessment of the frequencist's\nuncertainty from posterior samples, and stochastic expansion of the loss; a key\ntool to treat frequencist's properties is the recently proposed Bayesian\ninfinitesimal jackknife approximation (Giordano and Broderick (2023)). In the\nfollowing part, we show that the matrix W can be interpreted as a reproducing\nkernel; it is named as W-kernel. Using the W-kernel, the essential subspace is\nexpressed as a principal space given by the kernel PCA. A relation to the\nFisher kernel and neural tangent kernel is established, which elucidates the\nconnection to the classical asymptotic theory; it also leads to a sort of\nBayesian-frequencist's duality. Finally, two applications, selection of a\nrepresentative set of observations and dimensional reduction in the approximate\nbootstrap, are discussed. In the former, incomplete Cholesky decomposition is\nintroduced as an efficient method to compute the essential subspace. In the\nlatter, different implementations of the approximate bootstrap for posterior\nmeans are compared.",
            "author": [
                "Yukito Iba"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13017v1",
                "http://arxiv.org/pdf/2311.13017v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "cond-mat.stat-mech",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13016v1",
            "title": "Image-Based Soil Organic Carbon Remote Sensing from Satellite Images\n  with Fourier Neural Operator and Structural Similarity",
            "updated": "2023-11-21T21:44:45Z",
            "published": "2023-11-21T21:44:45Z",
            "summary": "Soil organic carbon (SOC) sequestration is the transfer and storage of\natmospheric carbon dioxide in soils, which plays an important role in climate\nchange mitigation. SOC concentration can be improved by proper land use, thus\nit is beneficial if SOC can be estimated at a regional or global scale. As\nmultispectral satellite data can provide SOC-related information such as\nvegetation and soil properties at a global scale, estimation of SOC through\nsatellite data has been explored as an alternative to manual soil sampling.\nAlthough existing studies show promising results, they are mainly based on\npixel-based approaches with traditional machine learning methods, and\nconvolutional neural networks (CNNs) are uncommon. To study the use of CNNs on\nSOC remote sensing, here we propose the FNO-DenseNet based on the Fourier\nneural operator (FNO). By combining the advantages of the FNO and DenseNet, the\nFNO-DenseNet outperformed the FNO in our experiments with hundreds of times\nfewer parameters. The FNO-DenseNet also outperformed a pixel-based random\nforest by 18% in the mean absolute percentage error.",
            "author": [
                "Ken C. L. Wong",
                "Levente Klein",
                "Ademir Ferreira da Silva",
                "Hongzhi Wang",
                "Jitendra Singh",
                "Tanveer Syeda-Mahmood"
            ],
            "link": [
                "http://dx.doi.org/10.1109/IGARSS52108.2023.10281551",
                "http://arxiv.org/abs/2311.13016v1",
                "http://arxiv.org/pdf/2311.13016v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13015v1",
            "title": "Fast and Interpretable Mortality Risk Scores for Critical Care Patients",
            "updated": "2023-11-21T21:44:28Z",
            "published": "2023-11-21T21:44:28Z",
            "summary": "Prediction of mortality in intensive care unit (ICU) patients is an important\ntask in critical care medicine. Prior work in creating mortality risk models\nfalls into two major categories: domain-expert-created scoring systems, and\nblack box machine learning (ML) models. Both of these have disadvantages: black\nbox models are unacceptable for use in hospitals, whereas manual creation of\nmodels (including hand-tuning of logistic regression parameters) relies on\nhumans to perform high-dimensional constrained optimization, which leads to a\nloss in performance. In this work, we bridge the gap between accurate black box\nmodels and hand-tuned interpretable models. We build on modern interpretable ML\ntechniques to design accurate and interpretable mortality risk scores. We\nleverage the largest existing public ICU monitoring datasets, namely the MIMIC\nIII and eICU datasets. By evaluating risk across medical centers, we are able\nto study generalization across domains. In order to customize our risk score\nmodels, we develop a new algorithm, GroupFasterRisk, which has several\nimportant benefits: (1) it uses hard sparsity constraint, allowing users to\ndirectly control the number of features; (2) it incorporates group sparsity to\nallow more cohesive models; (3) it allows for monotonicity correction on models\nfor including domain knowledge; (4) it produces many equally-good models at\nonce, which allows domain experts to choose among them. GroupFasterRisk creates\nits risk scores within hours, even on the large datasets we study here.\nGroupFasterRisk's risk scores perform better than risk scores currently used in\nhospitals, and have similar prediction performance to black box ML models\n(despite being much sparser). Because GroupFasterRisk produces a variety of\nrisk scores and handles constraints, it allows design flexibility, which is the\nkey enabler of practical and trustworthy model creation.",
            "author": [
                "Chloe Qinyu Zhu",
                "Muhang Tian",
                "Lesia Semenova",
                "Jiachang Liu",
                "Jack Xu",
                "Joseph Scarpa",
                "Cynthia Rudin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13015v1",
                "http://arxiv.org/pdf/2311.13015v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13014v1",
            "title": "Neural Graph Control Barrier Functions Guided Distributed\n  Collision-avoidance Multi-agent Control",
            "updated": "2023-11-21T21:43:18Z",
            "published": "2023-11-21T21:43:18Z",
            "summary": "We consider the problem of designing distributed collision-avoidance\nmulti-agent control in large-scale environments with potentially moving\nobstacles, where a large number of agents are required to maintain safety using\nonly local information and reach their goals. This paper addresses the problem\nof collision avoidance, scalability, and generalizability by introducing graph\ncontrol barrier functions (GCBFs) for distributed control. The newly introduced\nGCBF is based on the well-established CBF theory for safety guarantees but\nutilizes a graph structure for scalable and generalizable decentralized\ncontrol. We use graph neural networks to learn both neural a GCBF certificate\nand distributed control. We also extend the framework from handling state-based\nmodels to directly taking point clouds from LiDAR for more practical robotics\nsettings. We demonstrated the efficacy of GCBF in a variety of numerical\nexperiments, where the number, density, and traveling distance of agents, as\nwell as the number of unseen and uncontrolled obstacles increase. Empirical\nresults show that GCBF outperforms leading methods such as MAPPO and\nmulti-agent distributed CBF (MDCBF). Trained with only 16 agents, GCBF can\nachieve up to 3 times improvement of success rate (agents reach goals and never\nencountered in any collisions) on <500 agents, and still maintain more than 50%\nsuccess rates for >1000 agents when other methods completely fail.",
            "author": [
                "Songyuan Zhang",
                "Kunal Garg",
                "Chuchu Fan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13014v1",
                "http://arxiv.org/pdf/2311.13014v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13013v1",
            "title": "Variability in Protoplanetary Nebulae: X. Multi-year Periods as an\n  Indicator of Potential Binaries",
            "updated": "2023-11-21T21:42:29Z",
            "published": "2023-11-21T21:42:29Z",
            "summary": "New observations are presented of four evolved objects that display long,\nmulti-year variations in their light curves. These are interpreted as good\nevidence of their binary nature, with the modulation caused by the barycenter\nmotion of the evolved star resulting in a periodic obscuration by a\ncircumbinary disk. Although protoplanetary nebulae (PPNe) commonly possess\nbipolar nebulae, which are thought to be shaped by a binary companion, there\nare very few PPNe in which a binary companion has been found. Three of the\nobjects in this study appear to be PPNe, IRAS 07253-2001, 08005-2356, and\n17542-0603, with long periods of 5.2, 6.9, and 8.2 yrs, respectively. The\nbinary nature of IRAS 08005-2356 has recently been confirmed by a radial\nvelocity study. Two samples, one of PPNe and the other of post-AGB star\ncandidates, are investigated for further evidence on how common is a\nlong-period light curve variation. Both samples suggest such light variations\nare not common. The fourth object, IRAS 20056+1834 (QY Sge), is an obscured RV\nTau variable of the RVb subclass, with a long period of 3.9 yrs and pulsation\nperiods of 102.9 and 51.5 days. The period of this object is seen to vary by\n2%. Evidence is presented for a recent mass ejection in IRAS 17542-0603.",
            "author": [
                "Bruce J. Hrivnak",
                "Wenxian Lu",
                "Gary Henson",
                "Todd C. Hillwig"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13013v1",
                "http://arxiv.org/pdf/2311.13013v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13006v1",
            "title": "Learning-Augmented Dynamic Submodular Maximization",
            "updated": "2023-11-21T21:32:05Z",
            "published": "2023-11-21T21:32:05Z",
            "summary": "In dynamic submodular maximization, the goal is to maintain a high-value\nsolution over a sequence of element insertions and deletions with a fast update\ntime. Motivated by large-scale applications and the fact that dynamic data\noften exhibits patterns, we ask the following question: can predictions be used\nto accelerate the update time of dynamic submodular maximization algorithms?\n  We consider the model for dynamic algorithms with predictions where\npredictions regarding the insertion and deletion times of elements can be used\nfor preprocessing. Our main result is an algorithm with an $O(poly(\\log \\eta,\n\\log w, \\log k))$ amortized update time over the sequence of updates that\nachieves a $1/2 - \\epsilon$ approximation in expectation for dynamic monotone\nsubmodular maximization under a cardinality constraint $k$, where the\nprediction error $\\eta$ is the number of elements that are not inserted and\ndeleted within $w$ time steps of their predicted insertion and deletion times.\nThis amortized update time is independent of the length of the stream and\ninstead depends on the prediction error.",
            "author": [
                "Arpit Agarwal",
                "Eric Balkanski"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13006v1",
                "http://arxiv.org/pdf/2311.13006v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12999v1",
            "title": "CovarNav: Machine Unlearning via Model Inversion and Covariance\n  Navigation",
            "updated": "2023-11-21T21:19:59Z",
            "published": "2023-11-21T21:19:59Z",
            "summary": "The rapid progress of AI, combined with its unprecedented public adoption and\nthe propensity of large neural networks to memorize training data, has given\nrise to significant data privacy concerns. To address these concerns, machine\nunlearning has emerged as an essential technique to selectively remove the\ninfluence of specific training data points on trained models. In this paper, we\napproach the machine unlearning problem through the lens of continual learning.\nGiven a trained model and a subset of training data designated to be forgotten\n(i.e., the \"forget set\"), we introduce a three-step process, named CovarNav, to\nfacilitate this forgetting. Firstly, we derive a proxy for the model's training\ndata using a model inversion attack. Secondly, we mislabel the forget set by\nselecting the most probable class that deviates from the actual ground truth.\nLastly, we deploy a gradient projection method to minimize the cross-entropy\nloss on the modified forget set (i.e., learn incorrect labels for this set)\nwhile preventing forgetting of the inverted samples. We rigorously evaluate\nCovarNav on the CIFAR-10 and Vggface2 datasets, comparing our results with\nrecent benchmarks in the field and demonstrating the efficacy of our proposed\napproach.",
            "author": [
                "Ali Abbasi",
                "Chayne Thrash",
                "Elaheh Akbari",
                "Daniel Zhang",
                "Soheil Kolouri"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12999v1",
                "http://arxiv.org/pdf/2311.12999v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12997v1",
            "title": "How Capable Can a Transformer Become? A Study on Synthetic,\n  Interpretable Tasks",
            "updated": "2023-11-21T21:16:54Z",
            "published": "2023-11-21T21:16:54Z",
            "summary": "Transformers trained on huge text corpora exhibit a remarkable set of\ncapabilities, e.g., performing simple logical operations. Given the inherent\ncompositional nature of language, one can expect the model to learn to compose\nthese capabilities, potentially yielding a combinatorial explosion of what\noperations it can perform on an input. Motivated by the above, we aim to assess\nin this paper \"how capable can a transformer become?\". Specifically, we train\nautoregressive Transformer models on a data-generating process that involves\ncompositions of a set of well-defined monolithic capabilities. Through a series\nof extensive and systematic experiments on this data-generating process, we\nshow that: (1) autoregressive Transformers can learn compositional structures\nfrom the training data and generalize to exponentially or even combinatorially\nmany functions; (2) composing functions by generating intermediate outputs is\nmore effective at generalizing to unseen compositions, compared to generating\nno intermediate outputs; (3) the training data has a significant impact on the\nmodel's ability to compose unseen combinations of functions; and (4) the\nattention layers in the latter half of the model are critical to\ncompositionality.",
            "author": [
                "Rahul Ramesh",
                "Mikail Khona",
                "Robert P. Dick",
                "Hidenori Tanaka",
                "Ekdeep Singh Lubana"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12997v1",
                "http://arxiv.org/pdf/2311.12997v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12996v1",
            "title": "RLIF: Interactive Imitation Learning as Reinforcement Learning",
            "updated": "2023-11-21T21:05:21Z",
            "published": "2023-11-21T21:05:21Z",
            "summary": "Although reinforcement learning methods offer a powerful framework for\nautomatic skill acquisition, for practical learning-based control problems in\ndomains such as robotics, imitation learning often provides a more convenient\nand accessible alternative. In particular, an interactive imitation learning\nmethod such as DAgger, which queries a near-optimal expert to intervene online\nto collect correction data for addressing the distributional shift challenges\nthat afflict na\\\"ive behavioral cloning, can enjoy good performance both in\ntheory and practice without requiring manually specified reward functions and\nother components of full reinforcement learning methods. In this paper, we\nexplore how off-policy reinforcement learning can enable improved performance\nunder assumptions that are similar but potentially even more practical than\nthose of interactive imitation learning. Our proposed method uses reinforcement\nlearning with user intervention signals themselves as rewards. This relaxes the\nassumption that intervening experts in interactive imitation learning should be\nnear-optimal and enables the algorithm to learn behaviors that improve over the\npotential suboptimal human expert. We also provide a unified framework to\nanalyze our RL method and DAgger; for which we present the asymptotic analysis\nof the suboptimal gap for both methods as well as the non-asymptotic sample\ncomplexity bound of our method. We then evaluate our method on challenging\nhigh-dimensional continuous control simulation benchmarks as well as real-world\nrobotic vision-based manipulation tasks. The results show that it strongly\noutperforms DAgger-like approaches across the different tasks, especially when\nthe intervening experts are suboptimal. Code and videos can be found on the\nproject website: rlif-page.github.io",
            "author": [
                "Jianlan Luo",
                "Perry Dong",
                "Yuexiang Zhai",
                "Yi Ma",
                "Sergey Levine"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12996v1",
                "http://arxiv.org/pdf/2311.12996v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12993v1",
            "title": "AI for Agriculture: the Comparison of Semantic Segmentation Methods for\n  Crop Mapping with Sentinel-2 Imagery",
            "updated": "2023-11-21T21:00:42Z",
            "published": "2023-11-21T21:00:42Z",
            "summary": "Crop mapping is one of the most common tasks in artificial intelligence for\nagriculture due to higher food demands from a growing population and increased\nawareness of climate change. In case of vineyards, the texture is very\nimportant for crop segmentation: with higher resolution satellite imagery the\ntexture is easily detected by majority of state-of-the-art algorithms. However,\nthis task becomes increasingly more difficult as the resolution of satellite\nimagery decreases and the information about the texture becomes unavailable. In\nthis paper we aim to explore the main machine learning methods that can be used\nwith freely available satellite imagery and discuss how and when they can be\napplied for vineyard segmentation problem. We assess the effectiveness of\nvarious widely-used machine learning techniques and offer guidance on selecting\nthe most suitable model for specific scenarios.",
            "author": [
                "Irina Korotkova",
                "Natalia Efremova"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12993v1",
                "http://arxiv.org/pdf/2311.12993v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12992v1",
            "title": "FollowMe: a Robust Person Following Framework Based on Re-Identification\n  and Gestures",
            "updated": "2023-11-21T20:59:27Z",
            "published": "2023-11-21T20:59:27Z",
            "summary": "Human-robot interaction (HRI) has become a crucial enabler in houses and\nindustries for facilitating operational flexibility. When it comes to mobile\ncollaborative robots, this flexibility can be further increased due to the\nautonomous mobility and navigation capacity of the robotic agents, expanding\ntheir workspace and consequently, the personalizable assistance they can\nprovide to the human operators. This however requires that the robot is capable\nof detecting and identifying the human counterpart in all stages of the\ncollaborative task, and in particular while following a human in crowded\nworkplaces. To respond to this need, we developed a unified perception and\nnavigation framework, which enables the robot to identify and follow a target\nperson using a combination of visual Re-Identification (Re-ID), hand gestures\ndetection, and collision-free navigation. The Re-ID module can autonomously\nlearn the features of a target person and use the acquired knowledge to\nvisually re-identify the target. The navigation stack is used to follow the\ntarget avoiding obstacles and other individuals in the environment. Experiments\nare conducted with few subjects in a laboratory setting where some unknown\ndynamic obstacles are introduced.",
            "author": [
                "Federico Rollo",
                "Andrea Zunino",
                "Gennaro Raiola",
                "Fabio Amadio",
                "Arash Ajoudani",
                "Nikolaos Tsagarakis"
            ],
            "link": [
                "http://dx.doi.org/10.1109/ARSO56563.2023.10187536",
                "http://arxiv.org/abs/2311.12992v1",
                "http://arxiv.org/pdf/2311.12992v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12990v1",
            "title": "NERIF: GPT-4V for Automatic Scoring of Drawn Models",
            "updated": "2023-11-21T20:52:04Z",
            "published": "2023-11-21T20:52:04Z",
            "summary": "Scoring student-drawn models is time-consuming. Recently released GPT-4V\nprovides a unique opportunity to advance scientific modeling practices by\nleveraging the powerful image processing capability. To test this ability\nspecifically for automatic scoring, we developed a method NERIF\n(Notation-Enhanced Rubric Instruction for Few-shot Learning) employing\ninstructional note and rubrics to prompt GPT-4V to score students' drawn models\nfor science phenomena. We randomly selected a set of balanced data (N = 900)\nthat includes student-drawn models for six modeling assessment tasks. Each\nmodel received a score from GPT-4V ranging at three levels: 'Beginning,'\n'Developing,' or 'Proficient' according to scoring rubrics. GPT-4V scores were\ncompared with human experts' scores to calculate scoring accuracy. Results show\nthat GPT-4V's average scoring accuracy was mean =.51, SD = .037. Specifically,\naverage scoring accuracy was .64 for the 'Beginning' class, .62 for the\n'Developing' class, and .26 for the 'Proficient' class, indicating that more\nproficient models are more challenging to score. Further qualitative study\nreveals how GPT-4V retrieves information from image input, including problem\ncontext, example evaluations provided by human coders, and students' drawing\nmodels. We also uncovered how GPT-4V catches the characteristics of\nstudent-drawn models and narrates them in natural language. At last, we\ndemonstrated how GPT-4V assigns scores to student-drawn models according to the\ngiven scoring rubric and instructional notes. Our findings suggest that the\nNERIF is an effective approach for employing GPT-4V to score drawn models. Even\nthough there is space for GPT-4V to improve scoring accuracy, some mis-assigned\nscores seemed interpretable to experts. The results of this study show that\nutilizing GPT-4V for automatic scoring of student-drawn models is promising.",
            "author": [
                "Gyeong-Geon Lee",
                "Xiaoming Zhai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12990v1",
                "http://arxiv.org/pdf/2311.12990v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12987v1",
            "title": "Volatility and irregularity Capturing in stock price indices using time\n  series Generative adversarial networks (TimeGAN)",
            "updated": "2023-11-21T20:46:08Z",
            "published": "2023-11-21T20:46:08Z",
            "summary": "This paper captures irregularities in financial time series data,\nparticularly stock prices, in the presence of COVID-19 shock. We conjectured\nthat jumps and irregularities are embedded in stock data due to the pandemic\nshock, which brings forth irregular trends in the time series data. We put\nforward that efficient and robust forecasting methods are needed to predict\nstock closing prices in the presence of the pandemic shock. This piece of\ninformation is helpful to investors as far as confidence risk and return boost\nare concerned. Generative adversarial networks of a time series nature are used\nto provide new ways of modeling and learning the proper and suitable\ndistribution for the financial time series data under complex setups. Ideally,\nthese traditional models are liable to producing high forecasting errors, and\nthey need to be more robust to capture dependency structures and other stylized\nfacts like volatility in stock markets. The TimeGAN model is used, effectively\ndealing with this risk of poor forecasts. Using the DAX stock index from\nJanuary 2010 to November 2022, we trained the LSTM, GRU, WGAN, and TimeGAN\nmodels as benchmarks and forecasting errors were noted, and our TimeGAN\noutperformed them all as indicated by a small forecasting error.",
            "author": [
                "Leonard Mushunje",
                "David Allen",
                "Shelton Peiris"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12987v1",
                "http://arxiv.org/pdf/2311.12987v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12986v2",
            "title": "Unsupervised Graph Attention Autoencoder for Attributed Networks using\n  K-means Loss",
            "updated": "2023-11-24T22:24:50Z",
            "published": "2023-11-21T20:45:55Z",
            "summary": "Several natural phenomena and complex systems are often represented as\nnetworks. Discovering their community structure is a fundamental task for\nunderstanding these networks. Many algorithms have been proposed, but recently,\nGraph Neural Networks (GNN) have emerged as a compelling approach for enhancing\nthis task.In this paper, we introduce a simple, efficient, and\nclustering-oriented model based on unsupervised \\textbf{G}raph Attention\n\\textbf{A}uto\\textbf{E}ncoder for community detection in attributed networks\n(GAECO). The proposed model adeptly learns representations from both the\nnetwork's topology and attribute information, simultaneously addressing dual\nobjectives: reconstruction and community discovery. It places a particular\nemphasis on discovering compact communities by robustly minimizing clustering\nerrors. The model employs k-means as an objective function and utilizes a\nmulti-head Graph Attention Auto-Encoder for decoding the representations.\nExperiments conducted on three datasets of attributed networks show that our\nmethod surpasses state-of-the-art algorithms in terms of NMI and ARI.\nAdditionally, our approach scales effectively with the size of the network,\nmaking it suitable for large-scale applications. The implications of our\nfindings extend beyond biological network interpretation and social network\nanalysis, where knowledge of the fundamental community structure is essential.",
            "author": [
                "Abdelfateh Bekkaira",
                "Slimane Bellaouar",
                "Slimane Oulad-Naoui"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12986v2",
                "http://arxiv.org/pdf/2311.12986v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "68T07",
                "I.2.4"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12981v1",
            "title": "SD-NAE: Generating Natural Adversarial Examples with Stable Diffusion",
            "updated": "2023-11-21T20:33:17Z",
            "published": "2023-11-21T20:33:17Z",
            "summary": "Robustly evaluating deep learning image classifiers is challenging due to\nsome limitations of standard datasets. Natural Adversarial Examples (NAEs),\narising naturally from the environment and capable of deceiving classifiers,\nare instrumental in identifying vulnerabilities in trained models. Existing\nworks collect such NAEs by filtering from a huge set of real images, a process\nthat is passive and lacks control. In this work, we propose to actively\nsynthesize NAEs with the state-of-the-art Stable Diffusion. Specifically, our\nmethod formulates a controlled optimization process, where we perturb the token\nembedding that corresponds to a specified class to synthesize NAEs. The\ngeneration is guided by the gradient of loss from the target classifier so that\nthe created image closely mimics the ground-truth class yet fools the\nclassifier. Named SD-NAE (Stable Diffusion for Natural Adversarial Examples),\nour innovative method is effective in producing valid and useful NAEs, which is\ndemonstrated through a meticulously designed experiment. Our work thereby\nprovides a valuable method for obtaining challenging evaluation data, which in\nturn can potentially advance the development of more robust deep learning\nmodels. Code is available at https://github.com/linyueqian/SD-NAE.",
            "author": [
                "Yueqian Lin",
                "Jingyang Zhang",
                "Yiran Chen",
                "Hai Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12981v1",
                "http://arxiv.org/pdf/2311.12981v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12978v1",
            "title": "Physics-Informed Priors with Application to Boundary Layer Velocity",
            "updated": "2023-11-21T20:25:50Z",
            "published": "2023-11-21T20:25:50Z",
            "summary": "One of the most popular recent areas of machine learning predicates the use\nof neural networks augmented by information about the underlying process in the\nform of Partial Differential Equations (PDEs). These physics-informed neural\nnetworks are obtained by penalizing the inference with a PDE, and have been\ncast as a minimization problem currently lacking a formal approach to quantify\nthe uncertainty. In this work, we propose a novel model-based framework which\nregards the PDE as a prior information of a deep Bayesian neural network. The\nprior is calibrated without data to resemble the PDE solution in the prior\nmean, while our degree in confidence on the PDE with respect to the data is\nexpressed in terms of the prior variance. The information embedded in the PDE\nis then propagated to the posterior yielding physics-informed forecasts with\nuncertainty quantification. We apply our approach to a simulated viscous fluid\nand to experimentally-obtained turbulent boundary layer velocity in a wind\ntunnel using an appropriately simplified Navier-Stokes equation. Our approach\nrequires very few observations to produce physically-consistent forecasts as\nopposed to non-physical forecasts stemming from non-informed priors, thereby\nallowing forecasting complex systems where some amount of data as well as some\ncontextual knowledge is available.",
            "author": [
                "Luca Menicali",
                "David H. Richter",
                "Stefano Castruccio"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12978v1",
                "http://arxiv.org/pdf/2311.12978v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12975v1",
            "title": "Neural Approximate Dynamic Programming for the Ultra-fast Order\n  Dispatching Problem",
            "updated": "2023-11-21T20:23:58Z",
            "published": "2023-11-21T20:23:58Z",
            "summary": "Same-Day Delivery (SDD) services aim to maximize the fulfillment of online\norders while minimizing delivery delays but are beset by operational\nuncertainties such as those in order volumes and courier planning. Our work\naims to enhance the operational efficiency of SDD by focusing on the ultra-fast\nOrder Dispatching Problem (ODP), which involves matching and dispatching orders\nto couriers within a centralized warehouse setting, and completing the delivery\nwithin a strict timeline (e.g., within minutes). We introduce important\nextensions to ultra-fast ODP such as order batching and explicit courier\nassignments to provide a more realistic representation of dispatching\noperations and improve delivery efficiency. As a solution method, we primarily\nfocus on NeurADP, a methodology that combines Approximate Dynamic Programming\n(ADP) and Deep Reinforcement Learning (DRL), and our work constitutes the first\napplication of NeurADP outside of the ride-pool matching problem. NeurADP is\nparticularly suitable for ultra-fast ODP as it addresses complex one-to-many\nmatching and routing intricacies through a neural network-based VFA that\ncaptures high-dimensional problem dynamics without requiring manual feature\nengineering as in generic ADP methods. We test our proposed approach using four\ndistinct realistic datasets tailored for ODP and compare the performance of\nNeurADP against myopic and DRL baselines by also making use of non-trivial\nbounds to assess the quality of the policies. Our numerical results indicate\nthat the inclusion of order batching and courier queues enhances the efficiency\nof delivery operations and that NeurADP significantly outperforms other\nmethods. Detailed sensitivity analysis with important parameters confirms the\nrobustness of NeurADP under different scenarios, including variations in\ncourier numbers, spatial setup, vehicle capacity, and permitted delay time.",
            "author": [
                "Arash Dehghan",
                "Mucahit Cevik",
                "Merve Bodur"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12975v1",
                "http://arxiv.org/pdf/2311.12975v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12970v1",
            "title": "Clustered Policy Decision Ranking",
            "updated": "2023-11-21T20:16:02Z",
            "published": "2023-11-21T20:16:02Z",
            "summary": "Policies trained via reinforcement learning (RL) are often very complex even\nfor simple tasks. In an episode with n time steps, a policy will make n\ndecisions on actions to take, many of which may appear non-intuitive to the\nobserver. Moreover, it is not clear which of these decisions directly\ncontribute towards achieving the reward and how significant their contribution\nis. Given a trained policy, we propose a black-box method based on statistical\ncovariance estimation that clusters the states of the environment and ranks\neach cluster according to the importance of decisions made in its states. We\ncompare our measure against a previous statistical fault localization based\nranking procedure.",
            "author": [
                "Mark Levin",
                "Hana Chockler"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12970v1",
                "http://arxiv.org/pdf/2311.12970v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12956v1",
            "title": "Innovative Horizons in Aerial Imagery: LSKNet Meets DiffusionDet for\n  Advanced Object Detection",
            "updated": "2023-11-21T19:49:13Z",
            "published": "2023-11-21T19:49:13Z",
            "summary": "In the realm of aerial image analysis, object detection plays a pivotal role,\nwith significant implications for areas such as remote sensing, urban planning,\nand disaster management. This study addresses the inherent challenges in this\ndomain, notably the detection of small objects, managing densely packed\nelements, and accounting for diverse orientations. We present an in-depth\nevaluation of an object detection model that integrates the Large Selective\nKernel Network (LSKNet)as its backbone with the DiffusionDet head, utilizing\nthe iSAID dataset for empirical analysis. Our approach encompasses the\nintroduction of novel methodologies and extensive ablation studies. These\nstudies critically assess various aspects such as loss functions, box\nregression techniques, and classification strategies to refine the model's\nprecision in object detection. The paper details the experimental application\nof the LSKNet backbone in synergy with the DiffusionDet heads, a combination\ntailored to meet the specific challenges in aerial image object detection. The\nfindings of this research indicate a substantial enhancement in the model's\nperformance, especially in the accuracy-time tradeoff. The proposed model\nachieves a mean average precision (MAP) of approximately 45.7%, which is a\nsignificant improvement, outperforming the RCNN model by 4.7% on the same\ndataset. This advancement underscores the effectiveness of the proposed\nmodifications and sets a new benchmark in aerial image analysis, paving the way\nfor more accurate and efficient object detection methodologies. The code is\npublicly available at https://github.com/SashaMatsun/LSKDiffDet",
            "author": [
                "Ahmed Sharshar",
                "Aleksandr Matsun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12956v1",
                "http://arxiv.org/pdf/2311.12956v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12955v1",
            "title": "Don't forget private retrieval: distributed private similarity search\n  for large language models",
            "updated": "2023-11-21T19:41:46Z",
            "published": "2023-11-21T19:41:46Z",
            "summary": "While the flexible capabilities of large language models (LLMs) allow them to\nanswer a range of queries based on existing learned knowledge, information\nretrieval to augment generation is an important tool to allow LLMs to answer\nquestions on information not included in pre-training data. Such private\ninformation is increasingly being generated in a wide array of distributed\ncontexts by organizations and individuals. Performing such information\nretrieval using neural embeddings of queries and documents always leaked\ninformation about queries and database content unless both were stored locally.\nWe present Private Retrieval Augmented Generation (PRAG), an approach that uses\nmulti-party computation (MPC) to securely transmit queries to a distributed set\nof servers containing a privately constructed database to return top-k and\napproximate top-k documents. This is a first-of-its-kind approach to dense\ninformation retrieval that ensures no server observes a client's query or can\nsee the database content. The approach introduces a novel MPC friendly protocol\nfor inverted file approximate search (IVF) that allows for fast document search\nover distributed and private data in sublinear communication complexity. This\nwork presents new avenues through which data for use in LLMs can be accessed\nand used without needing to centralize or forgo privacy.",
            "author": [
                "Guy Zyskind",
                "Tobin South",
                "Alex Pentland"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12955v1",
                "http://arxiv.org/pdf/2311.12955v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12947v1",
            "title": "PINNs-Based Uncertainty Quantification for Transient Stability Analysis",
            "updated": "2023-11-21T19:21:49Z",
            "published": "2023-11-21T19:21:49Z",
            "summary": "This paper addresses the challenge of transient stability in power systems\nwith missing parameters and uncertainty propagation in swing equations. We\nintroduce a novel application of Physics-Informed Neural Networks (PINNs),\nspecifically an Ensemble of PINNs (E-PINNs), to estimate critical parameters\nlike rotor angle and inertia coefficient with enhanced accuracy and reduced\ncomputational load. E-PINNs capitalize on the underlying physical principles of\nswing equations to provide a robust solution. Our approach not only facilitates\nefficient parameter estimation but also quantifies uncertainties, delivering\nprobabilistic insights into the system behavior. The efficacy of E-PINNs is\ndemonstrated through the analysis of $1$-bus and $2$-bus systems, highlighting\nthe model's ability to handle parameter variability and data scarcity. The\nstudy advances the application of machine learning in power system stability,\npaving the way for reliable and computationally efficient transient stability\nanalysis.",
            "author": [
                "Ren Wang",
                "Ming Zhong",
                "Kaidi Xu",
                "Lola Gir\u00e1ldez S\u00e1nchez-Cort\u00e9s",
                "Ignacio de Cominges Guerra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12947v1",
                "http://arxiv.org/pdf/2311.12947v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12944v1",
            "title": "DroneOptiNet: A Framework for Optimal Drone-based Load Redistribution\n  Mechanism for 5G and Beyond Solar Small Cell Networks",
            "updated": "2023-11-21T19:17:39Z",
            "published": "2023-11-21T19:17:39Z",
            "summary": "The power requirements posed by the fifth-generation and beyond cellular\nnetworks are an important constraint in network deployment and require\nenergy-efficient solutions. In this work, we propose a novel user load transfer\napproach using airborne base stations (BS), mounted on drones, for reliable and\nsecure power redistribution across the micro-grid network comprising green\nsmall cell BSs. Depending on the user density and the availability of an aerial\nBS, the energy requirement of a cell with an energy deficit is accommodated by\nmigrating the aerial BS from a high-energy to a low-energy cell. The proposed\nhybrid drone-based framework integrates long short-term memory with unique cost\nfunctions using an evolutionary neural network for drones and BSs, and\nefficiently manages energy and load redistribution. The proposed algorithm\nreduces power outages at BSs and maintains consistent throughput stability,\nthereby demonstrating its capability to boost the reliability and robustness of\nwireless communication systems.",
            "author": [
                "Daksh Dave",
                "Vinay Chamola",
                "Sandeep Joshi",
                "Sherali Zeadally"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12944v1",
                "http://arxiv.org/pdf/2311.12944v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.AI",
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12943v1",
            "title": "InteRACT: Transformer Models for Human Intent Prediction Conditioned on\n  Robot Actions",
            "updated": "2023-11-21T19:15:17Z",
            "published": "2023-11-21T19:15:17Z",
            "summary": "In collaborative human-robot manipulation, a robot must predict human intents\nand adapt its actions accordingly to smoothly execute tasks. However, the\nhuman's intent in turn depends on actions the robot takes, creating a\nchicken-or-egg problem. Prior methods ignore such inter-dependency and instead\ntrain marginal intent prediction models independent of robot actions. This is\nbecause training conditional models is hard given a lack of paired human-robot\ninteraction datasets.\n  Can we instead leverage large-scale human-human interaction data that is more\neasily accessible? Our key insight is to exploit a correspondence between human\nand robot actions that enables transfer learning from human-human to\nhuman-robot data. We propose a novel architecture, InteRACT, that pre-trains a\nconditional intent prediction model on large human-human datasets and\nfine-tunes on a small human-robot dataset. We evaluate on a set of real-world\ncollaborative human-robot manipulation tasks and show that our conditional\nmodel improves over various marginal baselines. We also introduce new\ntechniques to tele-operate a 7-DoF robot arm and collect a diverse range of\nhuman-robot collaborative manipulation data, which we open-source.",
            "author": [
                "Kushal Kedia",
                "Atiksh Bhardwaj",
                "Prithwish Dan",
                "Sanjiban Choudhury"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12943v1",
                "http://arxiv.org/pdf/2311.12943v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14736v1",
            "title": "Data Diversity Matters for Robust Instruction Tuning",
            "updated": "2023-11-21T19:12:18Z",
            "published": "2023-11-21T19:12:18Z",
            "summary": "Instruction tuning has emerged as a key step in aligning large language\nmodels. One of the central challenges of instruction tuning is dataset\nselection, as the composition of the instruction tuning dataset can\nsignificantly impact downstream performance. In particular, researchers have\nhypothesized that dataset diversity and dataset quality are important\nindicators of downstream performance. However, it is not clear how to\nautomatically select high quality and diverse data or how exactly quality and\ndiversity affect instruction following ability. To resolve these issues, we\npropose a new algorithm, Quality-Diversity Instruction Tuning (QDIT). QDIT\nprovides a principled algorithm to control dataset diversity and quality,\nallowing us to conduct an in depth study on the effect of diversity and quality\non instruction tuning performance. From this study we draw two key insights (1)\nthere is a natural tradeoff between dataset diversity and quality and (2)\nincreasing dataset diversity significantly improves the worst case instruction\nfollowing performance, therefore improving robustness. We validate the\nperformance of QDIT on several large scale instruction tuning datasets, where\nwe find it can improve worst case performance by 18% while maintaining or\nimproving average performance compared to quality driven baselines.",
            "author": [
                "Alexander Bukharin",
                "Tuo Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14736v1",
                "http://arxiv.org/pdf/2311.14736v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12929v1",
            "title": "Hierarchical Learning for Quantum ML: Novel Training Technique for\n  Large-Scale Variational Quantum Circuits",
            "updated": "2023-11-21T19:00:03Z",
            "published": "2023-11-21T19:00:03Z",
            "summary": "We present hierarchical learning, a novel variational architecture for\nefficient training of large-scale variational quantum circuits. We test and\nbenchmark our technique for distribution loading with quantum circuit born\nmachines (QCBMs). With QCBMs, probability distributions are loaded into the\nsquared amplitudes of computational basis vectors represented by bitstrings.\nOur key insight is to take advantage of the fact that the most significant\n(qu)bits have a greater effect on the final distribution and can be learned\nfirst. One can think of it as a generalization of layerwise learning, where\nsome parameters of the variational circuit are learned first to prevent the\nphenomena of barren plateaus. We briefly review adjoint methods for computing\nthe gradient, in particular for loss functions that are not expectation values\nof observables. We first compare the role of connectivity in the variational\nansatz for the task of loading a Gaussian distribution on nine qubits, finding\nthat 2D connectivity greatly outperforms qubits arranged on a line. Based on\nour observations, we then implement this strategy on large-scale numerical\nexperiments with GPUs, training a QCBM to reproduce a 3-dimensional\nmultivariate Gaussian distribution on 27 qubits up to $\\sim4\\%$ total variation\ndistance. Though barren plateau arguments do not strictly apply here due to the\nobjective function not being tied to an observable, this is to our knowledge\nthe first practical demonstration of variational learning on large numbers of\nqubits. We also demonstrate hierarchical learning as a resource-efficient way\nto load distributions for existing quantum hardware (IBM's 7 and 27 qubit\ndevices) in tandem with Fire Opal optimizations.",
            "author": [
                "Hrant Gharibyan",
                "Vincent Su",
                "Hayk Tepanyan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12929v1",
                "http://arxiv.org/pdf/2311.12929v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12924v1",
            "title": "Non-resonant Anomaly Detection with Background Extrapolation",
            "updated": "2023-11-21T19:00:01Z",
            "published": "2023-11-21T19:00:01Z",
            "summary": "Complete anomaly detection strategies that are both signal sensitive and\ncompatible with background estimation have largely focused on resonant signals.\nNon-resonant new physics scenarios are relatively under-explored and may arise\nfrom off-shell effects or final states with significant missing energy. In this\npaper, we extend a class of weakly supervised anomaly detection strategies\ndeveloped for resonant physics to the non-resonant case. Machine learning\nmodels are trained to reweight, generate, or morph the background, extrapolated\nfrom a control region. A classifier is then trained in a signal region to\ndistinguish the estimated background from the data. The new methods are\ndemonstrated using a semi-visible jet signature as a benchmark signal model,\nand are shown to automatically identify the anomalous events without specifying\nthe signal ahead of time.",
            "author": [
                "Kehang Bai",
                "Radha Mastandrea",
                "Benjamin Nachman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12924v1",
                "http://arxiv.org/pdf/2311.12924v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-ex",
                "physics.data-an"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12796v1",
            "title": "Physics-guided Shape-from-Template: Monocular Video Perception through\n  Neural Surrogate Models",
            "updated": "2023-11-21T18:59:58Z",
            "published": "2023-11-21T18:59:58Z",
            "summary": "3D reconstruction of dynamic scenes is a long-standing problem in computer\ngraphics and increasingly difficult the less information is available.\nShape-from-Template (SfT) methods aim to reconstruct a template-based geometry\nfrom RGB images or video sequences, often leveraging just a single monocular\ncamera without depth information, such as regular smartphone recordings.\nUnfortunately, existing reconstruction methods are either unphysical and noisy\nor slow in optimization. To solve this problem, we propose a novel SfT\nreconstruction algorithm for cloth using a pre-trained neural surrogate model\nthat is fast to evaluate, stable, and produces smooth reconstructions due to a\nregularizing physics simulation. Differentiable rendering of the simulated mesh\nenables pixel-wise comparisons between the reconstruction and a target video\nsequence that can be used for a gradient-based optimization procedure to\nextract not only shape information but also physical parameters such as\nstretching, shearing, or bending stiffness of the cloth. This allows to retain\na precise, stable, and smooth reconstructed geometry while reducing the runtime\nby a factor of 400-500 compared to $\\phi$-SfT, a state-of-the-art physics-based\nSfT approach.",
            "author": [
                "David Stotko",
                "Nils Wandel",
                "Reinhard Klein"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12796v1",
                "http://arxiv.org/pdf/2311.12796v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12792v1",
            "title": "Intrinsic Image Decomposition via Ordinal Shading",
            "updated": "2023-11-21T18:58:01Z",
            "published": "2023-11-21T18:58:01Z",
            "summary": "Intrinsic decomposition is a fundamental mid-level vision problem that plays\na crucial role in various inverse rendering and computational photography\npipelines. Generating highly accurate intrinsic decompositions is an inherently\nunder-constrained task that requires precisely estimating continuous-valued\nshading and albedo. In this work, we achieve high-resolution intrinsic\ndecomposition by breaking the problem into two parts. First, we present a dense\nordinal shading formulation using a shift- and scale-invariant loss in order to\nestimate ordinal shading cues without restricting the predictions to obey the\nintrinsic model. We then combine low- and high-resolution ordinal estimations\nusing a second network to generate a shading estimate with both global\ncoherency and local details. We encourage the model to learn an accurate\ndecomposition by computing losses on the estimated shading as well as the\nalbedo implied by the intrinsic model. We develop a straightforward method for\ngenerating dense pseudo ground truth using our model's predictions and\nmulti-illumination data, enabling generalization to in-the-wild imagery. We\npresent an exhaustive qualitative and quantitative analysis of our predicted\nintrinsic components against state-of-the-art methods. Finally, we demonstrate\nthe real-world applicability of our estimations by performing otherwise\ndifficult editing tasks such as recoloring and relighting.",
            "author": [
                "Chris Careaga",
                "Ya\u011f\u0131z Aksoy"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3630750",
                "http://arxiv.org/abs/2311.12792v1",
                "http://arxiv.org/pdf/2311.12792v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12786v1",
            "title": "Mechanistically analyzing the effects of fine-tuning on procedurally\n  defined tasks",
            "updated": "2023-11-21T18:51:04Z",
            "published": "2023-11-21T18:51:04Z",
            "summary": "Fine-tuning large pre-trained models has become the de facto strategy for\ndeveloping both task-specific and general-purpose machine learning systems,\nincluding developing models that are safe to deploy. Despite its clear\nimportance, there has been minimal work that explains how fine-tuning alters\nthe underlying capabilities learned by a model during pretraining: does\nfine-tuning yield entirely novel capabilities or does it just modulate existing\nones? We address this question empirically in synthetic, controlled settings\nwhere we can use mechanistic interpretability tools (e.g., network pruning and\nprobing) to understand how the model's underlying capabilities are changing. We\nperform an extensive analysis of the effects of fine-tuning in these settings,\nand show that: (i) fine-tuning rarely alters the underlying model capabilities;\n(ii) a minimal transformation, which we call a 'wrapper', is typically learned\non top of the underlying model capabilities, creating the illusion that they\nhave been modified; and (iii) further fine-tuning on a task where such hidden\ncapabilities are relevant leads to sample-efficient 'revival' of the\ncapability, i.e., the model begins reusing these capability after only a few\ngradient steps. This indicates that practitioners can unintentionally remove a\nmodel's safety wrapper merely by fine-tuning it on a, e.g., superficially\nunrelated, downstream task. We additionally perform analysis on language models\ntrained on the TinyStories dataset to support our claims in a more realistic\nsetup.",
            "author": [
                "Samyak Jain",
                "Robert Kirk",
                "Ekdeep Singh Lubana",
                "Robert P. Dick",
                "Hidenori Tanaka",
                "Edward Grefenstette",
                "Tim Rockt\u00e4schel",
                "David Scott Krueger"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12786v1",
                "http://arxiv.org/pdf/2311.12786v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12784v1",
            "title": "Optimality in Mean Estimation: Beyond Worst-Case, Beyond Sub-Gaussian,\n  and Beyond $1+\u03b1$ Moments",
            "updated": "2023-11-21T18:50:38Z",
            "published": "2023-11-21T18:50:38Z",
            "summary": "There is growing interest in improving our algorithmic understanding of\nfundamental statistical problems such as mean estimation, driven by the goal of\nunderstanding the limits of what we can extract from valuable data. The state\nof the art results for mean estimation in $\\mathbb{R}$ are 1) the optimal\nsub-Gaussian mean estimator by [LV22], with the tight sub-Gaussian constant for\nall distributions with finite but unknown variance, and 2) the analysis of the\nmedian-of-means algorithm by [BCL13] and a lower bound by [DLLO16],\ncharacterizing the big-O optimal errors for distributions for which only a\n$1+\\alpha$ moment exists for $\\alpha \\in (0,1)$. Both results, however, are\noptimal only in the worst case. We initiate the fine-grained study of the mean\nestimation problem: Can algorithms leverage useful features of the input\ndistribution to beat the sub-Gaussian rate, without explicit knowledge of such\nfeatures?\n  We resolve this question with an unexpectedly nuanced answer: \"Yes in limited\nregimes, but in general no\". For any distribution $p$ with a finite mean, we\nconstruct a distribution $q$ whose mean is well-separated from $p$'s, yet $p$\nand $q$ are not distinguishable with high probability, and $q$ further\npreserves $p$'s moments up to constants. The main consequence is that no\nreasonable estimator can asymptotically achieve better than the sub-Gaussian\nerror rate for any distribution, matching the worst-case result of [LV22]. More\ngenerally, we introduce a new definitional framework to analyze the\nfine-grained optimality of algorithms, which we call \"neighborhood optimality\",\ninterpolating between the unattainably strong \"instance optimality\" and the\ntrivially weak \"admissibility\" definitions. Applying the new framework, we show\nthat median-of-means is neighborhood optimal, up to constant factors. It is\nopen to find a neighborhood-optimal estimator without constant factor\nslackness.",
            "author": [
                "Trung Dang",
                "Jasper C. H. Lee",
                "Maoyuan Song",
                "Paul Valiant"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12784v1",
                "http://arxiv.org/pdf/2311.12784v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "cs.IT",
                "cs.LG",
                "math.IT",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12781v1",
            "title": "Quantifying Impairment and Disease Severity Using AI Models Trained on\n  Healthy Subjects",
            "updated": "2023-11-21T18:45:52Z",
            "published": "2023-11-21T18:45:52Z",
            "summary": "Automatic assessment of impairment and disease severity is a key challenge in\ndata-driven medicine. We propose a novel framework to address this challenge,\nwhich leverages AI models trained exclusively on healthy individuals. The\nCOnfidence-Based chaRacterization of Anomalies (COBRA) score exploits the\ndecrease in confidence of these models when presented with impaired or diseased\npatients to quantify their deviation from the healthy population. We applied\nthe COBRA score to address a key limitation of current clinical evaluation of\nupper-body impairment in stroke patients. The gold-standard Fugl-Meyer\nAssessment (FMA) requires in-person administration by a trained assessor for\n30-45 minutes, which restricts monitoring frequency and precludes physicians\nfrom adapting rehabilitation protocols to the progress of each patient. The\nCOBRA score, computed automatically in under one minute, is shown to be\nstrongly correlated with the FMA on an independent test cohort for two\ndifferent data modalities: wearable sensors ($\\rho = 0.845$, 95% CI\n[0.743,0.908]) and video ($\\rho = 0.746$, 95% C.I [0.594, 0.847]). To\ndemonstrate the generalizability of the approach to other conditions, the COBRA\nscore was also applied to quantify severity of knee osteoarthritis from\nmagnetic-resonance imaging scans, again achieving significant correlation with\nan independent clinical assessment ($\\rho = 0.644$, 95% C.I [0.585,0.696]).",
            "author": [
                "Boyang Yu",
                "Aakash Kaku",
                "Kangning Liu",
                "Avinash Parnandi",
                "Emily Fokas",
                "Anita Venkatesan",
                "Natasha Pandit",
                "Rajesh Ranganath",
                "Heidi Schambra",
                "Carlos Fernandez-Granda"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12781v1",
                "http://arxiv.org/pdf/2311.12781v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12919v2",
            "title": "SPOT! Revisiting Video-Language Models for Event Understanding",
            "updated": "2023-12-01T17:33:55Z",
            "published": "2023-11-21T18:43:07Z",
            "summary": "Understanding videos is an important research topic for multimodal learning.\nLeveraging large-scale datasets of web-crawled video-text pairs as weak\nsupervision has become a pre-training paradigm for learning joint\nrepresentations and showcased remarkable potential in video understanding\ntasks. However, videos can be multi-event and multi-grained, while these\nvideo-text pairs usually contain only broad-level video captions. This raises a\nquestion: with such weak supervision, can video representation in\nvideo-language models gain the ability to distinguish even factual\ndiscrepancies in textual description and understand fine-grained events? To\naddress this, we introduce SPOT Prober, to benchmark existing video-language\nmodels's capacities of distinguishing event-level discrepancies as an indicator\nof models' event understanding ability. Our approach involves extracting events\nas tuples (<Subject, Predicate, Object, Attribute, Timestamps>) from videos and\ngenerating false event tuples by manipulating tuple components systematically.\nWe reevaluate the existing video-language models with these positive and\nnegative captions and find they fail to distinguish most of the manipulated\nevents. Based on our findings, we propose to plug in these manipulated event\ncaptions as hard negative samples and find them effective in enhancing models\nfor event understanding.",
            "author": [
                "Gengyuan Zhang",
                "Jinhe Bi",
                "Jindong Gu",
                "Yanyu Chen",
                "Volker Tresp"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12919v2",
                "http://arxiv.org/pdf/2311.12919v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14735v1",
            "title": "Generative Machine Learning for Multivariate Equity Returns",
            "updated": "2023-11-21T18:41:48Z",
            "published": "2023-11-21T18:41:48Z",
            "summary": "The use of machine learning to generate synthetic data has grown in\npopularity with the proliferation of text-to-image models and especially large\nlanguage models. The core methodology these models use is to learn the\ndistribution of the underlying data, similar to the classical methods common in\nfinance of fitting statistical models to data. In this work, we explore the\nefficacy of using modern machine learning methods, specifically conditional\nimportance weighted autoencoders (a variant of variational autoencoders) and\nconditional normalizing flows, for the task of modeling the returns of\nequities. The main problem we work to address is modeling the joint\ndistribution of all the members of the S&P 500, or, in other words, learning a\n500-dimensional joint distribution. We show that this generative model has a\nbroad range of applications in finance, including generating realistic\nsynthetic data, volatility and correlation estimation, risk analysis (e.g.,\nvalue at risk, or VaR, of portfolios), and portfolio optimization.",
            "author": [
                "Ruslan Tepelyan",
                "Achintya Gopal"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3604237.3626884",
                "http://arxiv.org/abs/2311.14735v1",
                "http://arxiv.org/pdf/2311.14735v1"
            ],
            "primary_category": "q-fin.ST",
            "category": [
                "q-fin.ST",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14743v4",
            "title": "A Baseline Analysis of Reward Models' Ability To Accurately Analyze\n  Foundation Models Under Distribution Shift",
            "updated": "2023-12-04T16:31:30Z",
            "published": "2023-11-21T18:41:26Z",
            "summary": "Foundation models, specifically Large Language Models (LLM's), have lately\ngained wide-spread attention and adoption. Reinforcement Learning with Human\nFeedback (RLHF) involves training a reward model to capture desired behaviors,\nwhich is then used to align LLM's. These reward models are additionally used at\ninference-time to estimate LLM responses' adherence to those desired behaviors.\nHowever, there is little work measuring how robust these reward models are to\ndistribution shifts. In this work, we evaluate how reward model performance -\nmeasured via accuracy and calibration (i.e. alignment between accuracy and\nconfidence) - is affected by distribution shift. We show novel calibration\npatterns and accuracy drops due to OOD prompts and responses, and that the\nreward model is more sensitive to shifts in responses than prompts.\nAdditionally, we adapt an OOD detection technique commonly used in\nclassification to the reward model setting to detect these distribution shifts\nin prompts and responses.",
            "author": [
                "Ben Pikus",
                "Will LeVine",
                "Tony Chen",
                "Sean Hendryx"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14743v4",
                "http://arxiv.org/pdf/2311.14743v4"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12776v1",
            "title": "Polarization-driven band topology evolution in twisted MoTe$_2$ and\n  WSe$_2$",
            "updated": "2023-11-21T18:38:10Z",
            "published": "2023-11-21T18:38:10Z",
            "summary": "Motivated by recent experimental observations of opposite Chern numbers in\n$R$-type twisted MoTe$_2$ and WSe$_2$ homobilayers, we perform large-scale\ndensity-functional-theory (DFT) calculations with machine learning force fields\nto investigate moir\\'e band topology from large to small twist angels in both\nmaterials. We find that the Chern numbers of the moir\\'e frontier bands change\nsign as a function of twist angle, and this change is driven by the competition\nbetween the in-plane piezoelectricity and the out-of-plane ferroelectricity.\nOur large-scale calculations, enabled by machine learning methods, reveal\ncrucial insights into interactions across different scales in twisted bilayer\nsystems. The interplay between atomic-level relaxation effects and\nmoir\\'e-scale electrostatic potential variation opens new avenues for the\ndesign of intertwined topological and correlated states.",
            "author": [
                "Xiao-Wei Zhang",
                "Chong Wang",
                "Xiaoyu Liu",
                "Yueyao Fan",
                "Ting Cao",
                "Di Xiao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12776v1",
                "http://arxiv.org/pdf/2311.12776v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cond-mat.mes-hall"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12918v1",
            "title": "Deep Learning-Based Real-Time Quality Control of Standard Video\n  Compression for Live Streaming",
            "updated": "2023-11-21T18:28:35Z",
            "published": "2023-11-21T18:28:35Z",
            "summary": "Ensuring high-quality video content for wireless users has become\nincreasingly vital. Nevertheless, maintaining a consistent level of video\nquality faces challenges due to the fluctuating encoded bitrate, primarily\ncaused by dynamic video content, especially in live streaming scenarios. Video\ncompression is typically employed to eliminate unnecessary redundancies within\nand between video frames, thereby reducing the required bandwidth for video\ntransmission. The encoded bitrate and the quality of the compressed video\ndepend on encoder parameters, specifically, the quantization parameter (QP).\nPoor choices of encoder parameters can result in reduced bandwidth efficiency\nand high likelihood of non-conformance. Non-conformance refers to the violation\nof the peak signal-to-noise ratio (PSNR) constraint for an encoded video\nsegment. To address these issues, a real-time deep learning-based H.264\ncontroller is proposed. This controller dynamically estimates the optimal\nencoder parameters based on the content of a video chunk with minimal delay.\nThe objective is to maintain video quality in terms of PSNR above a specified\nthreshold while minimizing the average bitrate of the compressed video.\nExperimental results, conducted on both QCIF dataset and a diverse range of\nrandom videos from public datasets, validate the effectiveness of this\napproach. Notably, it achieves improvements of up to 2.5 times in average\nbandwidth usage compared to the state-of-the-art adaptive bitrate video\nstreaming, with a negligible non-conformance probability below $10^{-2}$.",
            "author": [
                "Matin Mortaheb",
                "Mohammad A. Amir Khojastepour",
                "Srimat T. Chakradhar",
                "Sennur Ulukus"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12918v1",
                "http://arxiv.org/pdf/2311.12918v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.IT",
                "cs.LG",
                "cs.NI",
                "cs.SY",
                "eess.SY",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12917v1",
            "title": "Orchard: building large cancer phylogenies using stochastic\n  combinatorial search",
            "updated": "2023-11-21T18:25:23Z",
            "published": "2023-11-21T18:25:23Z",
            "summary": "Phylogenies depicting the evolutionary history of genetically heterogeneous\nsubpopulations of cells from the same cancer i.e., cancer phylogenies, provide\nuseful insights about cancer development and inform treatment. Cancer\nphylogenies can be reconstructed using data obtained from bulk DNA sequencing\nof multiple tissue samples from the same cancer. We introduce Orchard, a fast\nalgorithm that reconstructs cancer phylogenies using point mutations detected\nin bulk DNA sequencing data. Orchard constructs cancer phylogenies\nprogressively, one point mutation at a time, ultimately sampling complete\nphylogenies from a posterior distribution implied by the bulk DNA data. Orchard\nreconstructs more plausible phylogenies than state-of-the-art cancer phylogeny\nreconstruction methods on 90 simulated cancers and 14 B-progenitor acute\nlymphoblastic leukemias (B-ALLs). These results demonstrate that Orchard\naccurately reconstructs cancer phylogenies with up to 300 mutations. We then\nintroduce a simple graph based clustering algorithm that uses a reconstructed\nphylogeny to infer unique groups of mutations i.e., mutation clusters, that\ncharacterize the genetic differences between cancer cell populations, and show\nthat this approach is competitive with state-of-the-art mutation clustering\nmethods.",
            "author": [
                "E. Kulman",
                "R. Kuang",
                "Q. Morris"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12917v1",
                "http://arxiv.org/pdf/2311.12917v1"
            ],
            "primary_category": "q-bio.PE",
            "category": [
                "q-bio.PE",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12764v2",
            "title": "Investigating Weight-Perturbed Deep Neural Networks With Application in\n  Iris Presentation Attack Detection",
            "updated": "2023-11-22T18:52:11Z",
            "published": "2023-11-21T18:18:50Z",
            "summary": "Deep neural networks (DNNs) exhibit superior performance in various machine\nlearning tasks, e.g., image classification, speech recognition, biometric\nrecognition, object detection, etc. However, it is essential to analyze their\nsensitivity to parameter perturbations before deploying them in real-world\napplications. In this work, we assess the sensitivity of DNNs against\nperturbations to their weight and bias parameters. The sensitivity analysis\ninvolves three DNN architectures (VGG, ResNet, and DenseNet), three types of\nparameter perturbations (Gaussian noise, weight zeroing, and weight scaling),\nand two settings (entire network and layer-wise). We perform experiments in the\ncontext of iris presentation attack detection and evaluate on two publicly\navailable datasets: LivDet-Iris-2017 and LivDet-Iris-2020. Based on the\nsensitivity analysis, we propose improved models simply by perturbing\nparameters of the network without undergoing training. We further combine these\nperturbed models at the score-level and at the parameter-level to improve the\nperformance over the original model. The ensemble at the parameter-level shows\nan average improvement of 43.58% on the LivDet-Iris-2017 dataset and 9.25% on\nthe LivDet-Iris-2020 dataset. The source code is available at\nhttps://github.com/redwankarimsony/WeightPerturbation-MSU.",
            "author": [
                "Renu Sharma",
                "Redwan Sony",
                "Arun Ross"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12764v2",
                "http://arxiv.org/pdf/2311.12764v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12760v1",
            "title": "High-resolution Image-based Malware Classification using Multiple\n  Instance Learning",
            "updated": "2023-11-21T18:11:26Z",
            "published": "2023-11-21T18:11:26Z",
            "summary": "This paper proposes a novel method of classifying malware into families using\nhigh-resolution greyscale images and multiple instance learning to overcome\nadversarial binary enlargement. Current methods of visualisation-based malware\nclassification largely rely on lossy transformations of inputs such as resizing\nto handle the large, variable-sized images. Through empirical analysis and\nexperimentation, it is shown that these approaches cause crucial information\nloss that can be exploited. The proposed solution divides the images into\npatches and uses embedding-based multiple instance learning with a\nconvolutional neural network and an attention aggregation function for\nclassification. The implementation is evaluated on the Microsoft Malware\nClassification dataset and achieves accuracies of up to $96.6\\%$ on\nadversarially enlarged samples compared to the baseline of $22.8\\%$. The Python\ncode is available online at https://github.com/timppeters/MIL-Malware-Images .",
            "author": [
                "Tim Peters",
                "Hikmat Farhat"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12760v1",
                "http://arxiv.org/pdf/2311.12760v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13608v1",
            "title": "Breathing Life Into Sketches Using Text-to-Video Priors",
            "updated": "2023-11-21T18:09:30Z",
            "published": "2023-11-21T18:09:30Z",
            "summary": "A sketch is one of the most intuitive and versatile tools humans use to\nconvey their ideas visually. An animated sketch opens another dimension to the\nexpression of ideas and is widely used by designers for a variety of purposes.\nAnimating sketches is a laborious process, requiring extensive experience and\nprofessional design skills. In this work, we present a method that\nautomatically adds motion to a single-subject sketch (hence, \"breathing life\ninto it\"), merely by providing a text prompt indicating the desired motion. The\noutput is a short animation provided in vector representation, which can be\neasily edited. Our method does not require extensive training, but instead\nleverages the motion prior of a large pretrained text-to-video diffusion model\nusing a score-distillation loss to guide the placement of strokes. To promote\nnatural and smooth motion and to better preserve the sketch's appearance, we\nmodel the learned motion through two components. The first governs small local\ndeformations and the second controls global affine transformations.\nSurprisingly, we find that even models that struggle to generate sketch videos\non their own can still serve as a useful backbone for animating abstract\nrepresentations.",
            "author": [
                "Rinon Gal",
                "Yael Vinker",
                "Yuval Alaluf",
                "Amit H. Bermano",
                "Daniel Cohen-Or",
                "Ariel Shamir",
                "Gal Chechik"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13608v1",
                "http://arxiv.org/pdf/2311.13608v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12755v1",
            "title": "Digital Twin Framework for Optimal and Autonomous Decision-Making in\n  Cyber-Physical Systems: Enhancing Reliability and Adaptability in the Oil and\n  Gas Industry",
            "updated": "2023-11-21T18:02:52Z",
            "published": "2023-11-21T18:02:52Z",
            "summary": "The concept of creating a virtual copy of a complete Cyber-Physical System\nopens up numerous possibilities, including real-time assessments of the\nphysical environment and continuous learning from the system to provide\nreliable and precise information. This process, known as the twinning process\nor the development of a digital twin (DT), has been widely adopted across\nvarious industries. However, challenges arise when considering the\ncomputational demands of implementing AI models, such as those employed in\ndigital twins, in real-time information exchange scenarios. This work proposes\na digital twin framework for optimal and autonomous decision-making applied to\na gas-lift process in the oil and gas industry, focusing on enhancing the\nrobustness and adaptability of the DT. The framework combines Bayesian\ninference, Monte Carlo simulations, transfer learning, online learning, and\nnovel strategies to confer cognition to the DT, including model\nhyperdimensional reduction and cognitive tack. Consequently, creating a\nframework for efficient, reliable, and trustworthy DT identification was\npossible. The proposed approach addresses the current gap in the literature\nregarding integrating various learning techniques and uncertainty management in\ndigital twin strategies. This digital twin framework aims to provide a reliable\nand efficient system capable of adapting to changing environments and\nincorporating prediction uncertainty, thus enhancing the overall\ndecision-making process in complex, real-world scenarios. Additionally, this\nwork lays the foundation for further developments in digital twins for process\nsystems engineering, potentially fostering new advancements and applications\nacross various industrial sectors.",
            "author": [
                "Carine Menezes Rebello",
                "Johannes J\u00e4schkea",
                "Idelfonso B. R. Nogueira"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12755v1",
                "http://arxiv.org/pdf/2311.12755v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12754v2",
            "title": "SelfOcc: Self-Supervised Vision-Based 3D Occupancy Prediction",
            "updated": "2023-11-29T15:19:38Z",
            "published": "2023-11-21T17:59:14Z",
            "summary": "3D occupancy prediction is an important task for the robustness of\nvision-centric autonomous driving, which aims to predict whether each point is\noccupied in the surrounding 3D space. Existing methods usually require 3D\noccupancy labels to produce meaningful results. However, it is very laborious\nto annotate the occupancy status of each voxel. In this paper, we propose\nSelfOcc to explore a self-supervised way to learn 3D occupancy using only video\nsequences. We first transform the images into the 3D space (e.g., bird's eye\nview) to obtain 3D representation of the scene. We directly impose constraints\non the 3D representations by treating them as signed distance fields. We can\nthen render 2D images of previous and future frames as self-supervision signals\nto learn the 3D representations. We propose an MVS-embedded strategy to\ndirectly optimize the SDF-induced weights with multiple depth proposals. Our\nSelfOcc outperforms the previous best method SceneRF by 58.7% using a single\nframe as input on SemanticKITTI and is the first self-supervised work that\nproduces reasonable 3D occupancy for surround cameras on nuScenes. SelfOcc\nproduces high-quality depth and achieves state-of-the-art results on novel\ndepth synthesis, monocular depth estimation, and surround-view depth estimation\non the SemanticKITTI, KITTI-2015, and nuScenes, respectively. Code:\nhttps://github.com/huang-yh/SelfOcc.",
            "author": [
                "Yuanhui Huang",
                "Wenzhao Zheng",
                "Borui Zhang",
                "Jie Zhou",
                "Jiwen Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12754v2",
                "http://arxiv.org/pdf/2311.12754v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12915v1",
            "title": "Neural-Integrated Meshfree (NIM) Method: A differentiable\n  programming-based hybrid solver for computational mechanics",
            "updated": "2023-11-21T17:57:12Z",
            "published": "2023-11-21T17:57:12Z",
            "summary": "We present the neural-integrated meshfree (NIM) method, a differentiable\nprogramming-based hybrid meshfree approach within the field of computational\nmechanics. NIM seamlessly integrates traditional physics-based meshfree\ndiscretization techniques with deep learning architectures. It employs a hybrid\napproximation scheme, NeuroPU, to effectively represent the solution by\ncombining continuous DNN representations with partition of unity (PU) basis\nfunctions associated with the underlying spatial discretization. This\nneural-numerical hybridization not only enhances the solution representation\nthrough functional space decomposition but also reduces both the size of DNN\nmodel and the need for spatial gradient computations based on automatic\ndifferentiation, leading to a significant improvement in training efficiency.\nUnder the NIM framework, we propose two truly meshfree solvers: the strong\nform-based NIM (S-NIM) and the local variational form-based NIM (V-NIM). In the\nS-NIM solver, the strong-form governing equation is directly considered in the\nloss function, while the V-NIM solver employs a local Petrov-Galerkin approach\nthat allows the construction of variational residuals based on arbitrary\noverlapping subdomains. This ensures both the satisfaction of underlying\nphysics and the preservation of meshfree property. We perform extensive\nnumerical experiments on both stationary and transient benchmark problems to\nassess the effectiveness of the proposed NIM methods in terms of accuracy,\nscalability, generalizability, and convergence properties. Moreover,\ncomparative analysis with other physics-informed machine learning methods\ndemonstrates that NIM, especially V-NIM, significantly enhances both accuracy\nand efficiency in end-to-end predictive capabilities.",
            "author": [
                "Honghui Du",
                "QiZhi He"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12915v1",
                "http://arxiv.org/pdf/2311.12915v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12750v1",
            "title": "Learning to Optimise Wind Farms with Graph Transformers",
            "updated": "2023-11-21T17:51:30Z",
            "published": "2023-11-21T17:51:30Z",
            "summary": "This work proposes a novel data-driven model capable of providing accurate\npredictions for the power generation of all wind turbines in wind farms of\narbitrary layout, yaw angle configurations and wind conditions. The proposed\nmodel functions by encoding a wind farm into a fully-connected graph and\nprocessing the graph representation through a graph transformer. The graph\ntransformer surrogate is shown to generalise well and is able to uncover latent\nstructural patterns within the graph representation of wind farms. It is\ndemonstrated how the resulting surrogate model can be used to optimise yaw\nangle configurations using genetic algorithms, achieving similar levels of\naccuracy to industrially-standard wind farm simulation tools while only taking\na fraction of the computational cost.",
            "author": [
                "Siyi Li",
                "Arnaud Robert",
                "A. Aldo Faisal",
                "Matthew D. Piggott"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12750v1",
                "http://arxiv.org/pdf/2311.12750v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12913v1",
            "title": "Marietta Blau and the photographic method of particle detection",
            "updated": "2023-11-21T17:35:39Z",
            "published": "2023-11-21T17:35:39Z",
            "summary": "Marietta Blau was a Vienna born nuclear physicist who eventually became the\nleading expert in the photographic detection of ionizing particles. She studied\nphysics at the University of Vienna, graduated in 1919. As of 1924, she adapted\nthe technique of photography for the detection of nuclear particles at the\nVienna Institute for Radium Research. When after years of painstaking\nmethodical development Blau succeeded in registering tracks of particles, she\nand her collaborator Hertha Wambacher further refined the technique and by its\nuse discovered the star-shaped tracks of reaction fragments from the\ninteraction of cosmic-ray particles in photographic emulsions, the\ndisintegration stars, in 1937. Due to her Jewish descent, Blau emigrated in\n1938, first to Mexico, later to the U.S. where she had access to scientific\nresearch again in 1948. At Brookhaven National Laboratory and Miami University\nshe applied the photographic method to reactions induced by high-energy\nparticles from accelerating machines rather than cosmic rays. When she returned\nto Vienna in 1960, she supervised the evaluation of photographic plates from\nCERN experiments.",
            "author": [
                "Brigitte Strohmaier"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12913v1",
                "http://arxiv.org/pdf/2311.12913v1"
            ],
            "primary_category": "physics.hist-ph",
            "category": [
                "physics.hist-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12745v1",
            "title": "Learn to Augment Network Simulators Towards Digital Network Twins",
            "updated": "2023-11-21T17:32:42Z",
            "published": "2023-11-21T17:32:42Z",
            "summary": "Digital network twin (DNT) is a promising paradigm to replicate real-world\ncellular networks toward continual assessment, proactive management, and\nwhat-if analysis. Existing discussions have been focusing on using only deep\nlearning techniques to build DNTs, which raises widespread concerns regarding\ntheir generalization, explainability, and transparency. In this paper, we\nexplore an alternative approach to augment network simulators with\ncontext-aware neural agents. The main challenge lies in the non-trivial\nsimulation-to-reality (sim-to-real) discrepancy between offline simulators and\nreal-world networks. To solve the challenge, we propose a new learn-to-bridge\nalgorithm to cost-efficiently bridge the sim-to-real discrepancy in two\nalternative stages. In the first stage, we select states to query performances\nin real-world networks by using newly-designed cost-aware Bayesian\noptimization. In the second stage, we train the neural agent to learn the state\ncontext and bridge the probabilistic discrepancy based on Bayesian neural\nnetworks (BNN). In addition, we build a small-scale end-to-end network testbed\nbased on OpenAirInterface RAN and Core with USRP B210 and a smartphone, and\nreplicate the network in NS-3. The evaluation results show that, our proposed\nsolution substantially outperforms existing methods, with more than 92\\%\nreduction in the sim-to-real discrepancy.",
            "author": [
                "Yuru Zhang",
                "Ming Zhao",
                "Qiang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12745v1",
                "http://arxiv.org/pdf/2311.12745v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12742v1",
            "title": "Image Transformation for IoT Time-Series Data: A Review",
            "updated": "2023-11-21T17:31:10Z",
            "published": "2023-11-21T17:31:10Z",
            "summary": "In the era of the Internet of Things (IoT), where smartphones, built-in\nsystems, wireless sensors, and nearly every smart device connect through local\nnetworks or the internet, billions of smart things communicate with each other\nand generate vast amounts of time-series data. As IoT time-series data is\nhigh-dimensional and high-frequency, time-series classification or regression\nhas been a challenging issue in IoT. Recently, deep learning algorithms have\ndemonstrated superior performance results in time-series data classification in\nmany smart and intelligent IoT applications. However, it is hard to explore the\nhidden dynamic patterns and trends in time-series. Recent studies show that\ntransforming IoT data into images improves the performance of the learning\nmodel. In this paper, we present a review of these studies which use image\ntransformation/encoding techniques in IoT domain. We examine the studies\naccording to their encoding techniques, data types, and application areas.\nLastly, we emphasize the challenges and future dimensions of image\ntransformation.",
            "author": [
                "Duygu Altunkaya",
                "Feyza Yildirim Okay",
                "Suat Ozdemir"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12742v1",
                "http://arxiv.org/pdf/2311.12742v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12741v1",
            "title": "Content Augmented Graph Neural Networks",
            "updated": "2023-11-21T17:30:57Z",
            "published": "2023-11-21T17:30:57Z",
            "summary": "In recent years, graph neural networks (GNNs) have become a popular tool for\nsolving various problems over graphs. In these models, the link structure of\nthe graph is typically exploited and nodes' embeddings are iteratively updated\nbased on adjacent nodes. Nodes' contents are used solely in the form of feature\nvectors, served as nodes' first-layer embeddings. However, the filters or\nconvolutions, applied during iterations/layers to these initial embeddings lead\nto their impact diminish and contribute insignificantly to the final\nembeddings. In order to address this issue, in this paper we propose augmenting\nnodes' embeddings by embeddings generating from their content, at higher GNN\nlayers. More precisely, we propose models wherein a structural embedding using\na GNN and a content embedding are computed for each node. These two are\ncombined using a combination layer to form the embedding of a node at a given\nlayer. We suggest methods such as using an auto-encoder or building a content\ngraph, to generate content embeddings. In the end, by conducting experiments\nover several real-world datasets, we demonstrate the high accuracy and\nperformance of our models.",
            "author": [
                "Fatemeh Gholamzadeh Nasrabadi",
                "AmirHossein Kashani",
                "Pegah Zahedi",
                "Mostafa Haghir Chehreghani"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12741v1",
                "http://arxiv.org/pdf/2311.12741v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12912v2",
            "title": "Q-Seg: Quantum Annealing-based Unsupervised Image Segmentation",
            "updated": "2023-11-30T11:38:07Z",
            "published": "2023-11-21T17:27:20Z",
            "summary": "In this study, we present Q-Seg, a novel unsupervised image segmentation\nmethod based on quantum annealing, tailored for existing quantum hardware. We\nformulate the pixel-wise segmentation problem, which assimilates spectral and\nspatial information of the image, as a graph-cut optimization task. Our method\nefficiently leverages the interconnected qubit topology of the D-Wave Advantage\ndevice, offering superior scalability over existing quantum approaches and\noutperforming state-of-the-art classical methods. Our empirical evaluations on\nsynthetic datasets reveal that Q-Seg offers better runtime performance against\nthe classical optimizer Gurobi. Furthermore, we evaluate our method on\nsegmentation of Earth Observation images, an area of application where the\namount of labeled data is usually very limited. In this case, Q-Seg\ndemonstrates near-optimal results in flood mapping detection with respect to\nclassical supervised state-of-the-art machine learning methods. Also, Q-Seg\nprovides enhanced segmentation for forest coverage compared to existing\nannotated masks. Thus, Q-Seg emerges as a viable alternative for real-world\napplications using available quantum hardware, particularly in scenarios where\nthe lack of labeled data and computational runtime are critical.",
            "author": [
                "Supreeth Mysore Venkatesh",
                "Antonio Macaluso",
                "Marlon Nuske",
                "Matthias Klusch",
                "Andreas Dengel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12912v2",
                "http://arxiv.org/pdf/2311.12912v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12737v1",
            "title": "Exploring Graph Classification Techniques Under Low Data Constraints: A\n  Comprehensive Study",
            "updated": "2023-11-21T17:23:05Z",
            "published": "2023-11-21T17:23:05Z",
            "summary": "This survey paper presents a brief overview of recent research on graph data\naugmentation and few-shot learning. It covers various techniques for graph data\naugmentation, including node and edge perturbation, graph coarsening, and graph\ngeneration, as well as the latest developments in few-shot learning, such as\nmeta-learning and model-agnostic meta-learning. The paper explores these areas\nin depth and delves into further sub classifications. Rule based approaches and\nlearning based approaches are surveyed under graph augmentation techniques.\nFew-Shot Learning on graphs is also studied in terms of metric learning\ntechniques and optimization-based techniques. In all, this paper provides an\nextensive array of techniques that can be employed in solving graph processing\nproblems faced in low-data scenarios.",
            "author": [
                "Kush Kothari",
                "Bhavya Mehta",
                "Reshmika Nambiar",
                "Seema Shrawne"
            ],
            "link": [
                "http://dx.doi.org/10.1109/ICCCNT56998.2023.10307388",
                "http://arxiv.org/abs/2311.12737v1",
                "http://arxiv.org/pdf/2311.12737v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12736v1",
            "title": "Spatio-Temporal Modeling of Surface Water Quality Distribution in\n  California (1956-2023)",
            "updated": "2023-11-21T17:21:45Z",
            "published": "2023-11-21T17:21:45Z",
            "summary": "Surface water quality has a direct impact on public health, ecosystems, and\nagriculture, in addition to being an important indicator of the overall health\nof the environment. California's diverse climate, extensive coastline, and\nvaried topography lead to distinct spatial and temporal patterns in surface\nwater. This study offers a comprehensive assessment of these patterns by\nleveraging around 70 years of data, taking into account climate zones and\ngeographical types. We analyzed surface water quality indicators, including pH,\ndissolved oxygen, specific conductance, and water temperature, based on field\nresults from approximately 5,000 water quality stations in California Water\nQuality Data (CWQD). Machine learning (ML) models were developed to establish\nrelationships between spatial and temporal variables, climate zones,\ngeographical types, and water quality indicators. Applying these models to\nspatially interpolate and temporally predict the four water quality indicators\nover California for the next 50 years, the research results indicate an uneven\ndistribution of water quality indicators in California, suggesting the presence\nof potential pollution zones, seawater erosion, and effects of climate change.",
            "author": [
                "Houlin Chen",
                "Meredith Franklin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12736v1",
                "http://arxiv.org/pdf/2311.12736v1"
            ],
            "primary_category": "stat.AP",
            "category": [
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12733v1",
            "title": "Not Just Training, Also Testing: High School Youths' Perspective-Taking\n  through Peer Testing Machine Learning-Powered Applications",
            "updated": "2023-11-21T17:15:43Z",
            "published": "2023-11-21T17:15:43Z",
            "summary": "Most attention in K-12 artificial intelligence and machine learning (AI/ML)\neducation has been given to having youths train models, with much less\nattention to the equally important testing of models when creating machine\nlearning applications. Testing ML applications allows for the evaluation of\nmodels against predictions and can help creators of applications identify and\naddress failure and edge cases that could negatively impact user experiences.\nWe investigate how testing each other's projects supported youths to take\nperspective about functionality, performance, and potential issues in their own\nprojects. We analyzed testing worksheets, audio and video recordings collected\nduring a two week workshop in which 11 high school youths created physical\ncomputing projects that included (audio, pose, and image) ML classifiers. We\nfound that through peer-testing youths reflected on the size of their training\ndatasets, the diversity of their training data, the design of their classes and\nthe contexts in which they produced training data. We discuss future directions\nfor research on peer-testing in AI/ML education and current limitations for\nthese kinds of activities.",
            "author": [
                "L. Morales-Navarro",
                "M. Shah",
                "Y. B. Kafai"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3626252.3630899",
                "http://arxiv.org/abs/2311.12733v1",
                "http://arxiv.org/pdf/2311.12733v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.HC",
                "K.3.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12727v2",
            "title": "Soft Random Sampling: A Theoretical and Empirical Analysis",
            "updated": "2023-11-24T03:27:31Z",
            "published": "2023-11-21T17:03:21Z",
            "summary": "Soft random sampling (SRS) is a simple yet effective approach for efficient\ntraining of large-scale deep neural networks when dealing with massive data.\nSRS selects a subset uniformly at random with replacement from the full data\nset in each epoch. In this paper, we conduct a theoretical and empirical\nanalysis of SRS. First, we analyze its sampling dynamics including data\ncoverage and occupancy. Next, we investigate its convergence with non-convex\nobjective functions and give the convergence rate. Finally, we provide its\ngeneralization performance. We empirically evaluate SRS for image recognition\non CIFAR10 and automatic speech recognition on Librispeech and an in-house\npayload dataset to demonstrate its effectiveness. Compared to existing\ncoreset-based data selection methods, SRS offers a better accuracy-efficiency\ntrade-off. Especially on real-world industrial scale data sets, it is shown to\nbe a powerful training strategy with significant speedup and competitive\nperformance with almost no additional computing cost.",
            "author": [
                "Xiaodong Cui",
                "Ashish Mittal",
                "Songtao Lu",
                "Wei Zhang",
                "George Saon",
                "Brian Kingsbury"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12727v2",
                "http://arxiv.org/pdf/2311.12727v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12726v1",
            "title": "Nonparametric variable importance for time-to-event outcomes with\n  application to prediction of HIV infection",
            "updated": "2023-11-21T17:02:11Z",
            "published": "2023-11-21T17:02:11Z",
            "summary": "In survival analysis, complex machine learning algorithms have been\nincreasingly used for predictive modeling. Given a collection of features\navailable for inclusion in a predictive model, it may be of interest to\nquantify the relative importance of a subset of features for the prediction\ntask at hand. In particular, in HIV vaccine trials, participant baseline\ncharacteristics are used to predict the probability of infection over the\nintended follow-up period, and investigators may wish to understand how much\ncertain types of predictors, such as behavioral factors, contribute toward\noverall predictiveness. Time-to-event outcomes such as time to infection are\noften subject to right censoring, and existing methods for assessing variable\nimportance are typically not intended to be used in this setting. We describe a\nbroad class of algorithm-agnostic variable importance measures for prediction\nin the context of survival data. We propose a nonparametric efficient\nestimation procedure that incorporates flexible learning of nuisance\nparameters, yields asymptotically valid inference, and enjoys\ndouble-robustness. We assess the performance of our proposed procedure via\nnumerical simulations and analyze data from the HVTN 702 study to inform\nenrollment strategies for future HIV vaccine trials.",
            "author": [
                "Charles J. Wolock",
                "Peter B. Gilbert",
                "Noah Simon",
                "Marco Carone"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12726v1",
                "http://arxiv.org/pdf/2311.12726v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12722v1",
            "title": "Attacking Motion Planners Using Adversarial Perception Errors",
            "updated": "2023-11-21T16:51:33Z",
            "published": "2023-11-21T16:51:33Z",
            "summary": "Autonomous driving (AD) systems are often built and tested in a modular\nfashion, where the performance of different modules is measured using\ntask-specific metrics. These metrics should be chosen so as to capture the\ndownstream impact of each module and the performance of the system as a whole.\nFor example, high perception quality should enable prediction and planning to\nbe performed safely. Even though this is true in general, we show here that it\nis possible to construct planner inputs that score very highly on various\nperception quality metrics but still lead to planning failures. In an analogy\nto adversarial attacks on image classifiers, we call such inputs\n\\textbf{adversarial perception errors} and show they can be systematically\nconstructed using a simple boundary-attack algorithm. We demonstrate the\neffectiveness of this algorithm by finding attacks for two different black-box\nplanners in several urban and highway driving scenarios using the CARLA\nsimulator. Finally, we analyse the properties of these attacks and show that\nthey are isolated in the input space of the planner, and discuss their\nimplications for AD system deployment and testing.",
            "author": [
                "Jonathan Sadeghi",
                "Nicholas A. Lord",
                "John Redford",
                "Romain Mueller"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12722v1",
                "http://arxiv.org/pdf/2311.12722v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CR",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12720v1",
            "title": "LiFi: Learn to Incentivize Federated Learning in Automotive Edge\n  Computing",
            "updated": "2023-11-21T16:49:15Z",
            "published": "2023-11-21T16:49:15Z",
            "summary": "Federated learning (FL) is the promising privacy-preserve approach to\ncontinually update the central machine learning (ML) model (e.g., object\ndetectors in edge servers) by aggregating the gradients obtained from local\nobservation data in distributed connected and automated vehicles (CAVs). The\nincentive mechanism is to incentivize individual selfish CAVs to participate in\nFL towards the improvement of overall model accuracy. It is, however,\nchallenging to design the incentive mechanism, due to the complex correlation\nbetween the overall model accuracy and unknown incentive sensitivity of CAVs,\nespecially under the non-independent and identically distributed (Non-IID) data\nof individual CAVs. In this paper, we propose a new learn-to-incentivize\nalgorithm to adaptively allocate rewards to individual CAVs under unknown\nsensitivity functions. First, we gradually learn the unknown sensitivity\nfunction of individual CAVs with accumulative observations, by using\ncompute-efficient Gaussian process regression (GPR). Second, we iteratively\nupdate the reward allocation to individual CAVs with new sampled gradients,\nderived from GPR. Third, we project the updated reward allocations to comply\nwith the total budget. We evaluate the performance of extensive simulations,\nwhere the simulation parameters are obtained from realistic profiling of the\nCIFAR-10 dataset and NVIDIA RTX 3080 GPU. The results show that our proposed\nalgorithm substantially outperforms existing solutions, in terms of accuracy,\nscalability, and adaptability.",
            "author": [
                "Ming Zhao",
                "Yuru Zhang",
                "Qiang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12720v1",
                "http://arxiv.org/pdf/2311.12720v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12716v2",
            "title": "minimax: Efficient Baselines for Autocurricula in JAX",
            "updated": "2023-11-23T19:12:07Z",
            "published": "2023-11-21T16:43:13Z",
            "summary": "Unsupervised environment design (UED) is a form of automatic curriculum\nlearning for training robust decision-making agents to zero-shot transfer into\nunseen environments. Such autocurricula have received much interest from the RL\ncommunity. However, UED experiments, based on CPU rollouts and GPU model\nupdates, have often required several weeks of training. This compute\nrequirement is a major obstacle to rapid innovation for the field. This work\nintroduces the minimax library for UED training on accelerated hardware. Using\nJAX to implement fully-tensorized environments and autocurriculum algorithms,\nminimax allows the entire training loop to be compiled for hardware\nacceleration. To provide a petri dish for rapid experimentation, minimax\nincludes a tensorized grid-world based on MiniGrid, in addition to reusable\nabstractions for conducting autocurricula in procedurally-generated\nenvironments. With these components, minimax provides strong UED baselines,\nincluding new parallelized variants, which achieve over 120$\\times$ speedups in\nwall time compared to previous implementations when training with equal batch\nsizes. The minimax library is available under the Apache 2.0 license at\nhttps://github.com/facebookresearch/minimax.",
            "author": [
                "Minqi Jiang",
                "Michael Dennis",
                "Edward Grefenstette",
                "Tim Rockt\u00e4schel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12716v2",
                "http://arxiv.org/pdf/2311.12716v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12909v1",
            "title": "Non-Sequential Ensemble Kalman Filtering using Distributed Arrays",
            "updated": "2023-11-21T16:42:26Z",
            "published": "2023-11-21T16:42:26Z",
            "summary": "This work introduces a new, distributed implementation of the Ensemble Kalman\nFilter (EnKF) that allows for non-sequential assimilation of large datasets in\nhigh-dimensional problems. The traditional EnKF algorithm is computationally\nintensive and exhibits difficulties in applications requiring interaction with\nthe background covariance matrix, prompting the use of methods like sequential\nassimilation which can introduce unwanted consequences, such as dependency on\nobservation ordering. Our implementation leverages recent advancements in\ndistributed computing to enable the construction and use of the full model\nerror covariance matrix in distributed memory, allowing for single-batch\nassimilation of all observations and eliminating order dependencies.\nComparative performance assessments, involving both synthetic and real-world\npaleoclimatic reconstruction applications, indicate that the new,\nnon-sequential implementation outperforms the traditional, sequential one.",
            "author": [
                "C\u00e9dric Travelletti",
                "J\u00f6rg Franke",
                "David Ginsbourger",
                "Stefan Br\u00f6nnimann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12909v1",
                "http://arxiv.org/pdf/2311.12909v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12715v1",
            "title": "Attacks of fairness in Federated Learning",
            "updated": "2023-11-21T16:42:03Z",
            "published": "2023-11-21T16:42:03Z",
            "summary": "Federated Learning is an important emerging distributed training paradigm\nthat keeps data private on clients. It is now well understood that by\ncontrolling only a small subset of FL clients, it is possible to introduce a\nbackdoor to a federated learning model, in the presence of certain attributes.\nIn this paper, we present a new type of attack that compromises the fairness of\nthe trained model. Fairness is understood to be the attribute-level performance\ndistribution of a trained model. It is particularly salient in domains where,\nfor example, skewed accuracy discrimination between subpopulations could have\ndisastrous consequences. We find that by employing a threat model similar to\nthat of a backdoor attack, an attacker is able to influence the aggregated\nmodel to have an unfair performance distribution between any given set of\nattributes. Furthermore, we find that this attack is possible by controlling\nonly a single client. While combating naturally induced unfairness in FL has\npreviously been discussed in depth, its artificially induced kind has been\nneglected. We show that defending against attacks on fairness should be a\ncritical consideration in any situation where unfairness in a trained model\ncould benefit a user who participated in its training.",
            "author": [
                "Joseph Rance",
                "Filip Svoboda"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12715v1",
                "http://arxiv.org/pdf/2311.12715v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12714v1",
            "title": "Decrypting Nonlinearity: Koopman Interpretation and Analysis of\n  Cryptosystems",
            "updated": "2023-11-21T16:38:48Z",
            "published": "2023-11-21T16:38:48Z",
            "summary": "Public-key cryptosystems rely on computationally difficult problems for\nsecurity, traditionally analyzed using number theory methods. In this paper, we\nintroduce a novel perspective on cryptosystems by viewing the Diffie-Hellman\nkey exchange and the Rivest-Shamir-Adleman cryptosystem as nonlinear dynamical\nsystems. By applying Koopman theory, we transform these dynamical systems into\nhigher-dimensional spaces and analytically derive equivalent purely linear\nsystems. This formulation allows us to reconstruct the secret integers of the\ncryptosystems through straightforward manipulations, leveraging the tools\navailable for linear systems analysis. Additionally, we establish an upper\nbound on the minimum lifting dimension required to achieve perfect accuracy.\nOur results on the required lifting dimension are in line with the\nintractability of brute-force attacks. To showcase the potential of our\napproach, we establish connections between our findings and existing results on\nalgorithmic complexity. Furthermore, we extend this methodology to a\ndata-driven context, where the Koopman representation is learned from data\nsamples of the cryptosystems.",
            "author": [
                "Robin Str\u00e4sser",
                "Sebastian Schlor",
                "Frank Allg\u00f6wer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12714v1",
                "http://arxiv.org/pdf/2311.12714v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.CR",
                "cs.SY",
                "math.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12713v2",
            "title": "Alpha Zero for Physics: Application of Symbolic Regression with Alpha\n  Zero to find the analytical methods in physics",
            "updated": "2023-12-04T15:01:58Z",
            "published": "2023-11-21T16:38:10Z",
            "summary": "Machine learning with neural networks is now becoming a more and more\npowerful tool for various tasks, such as natural language processing, image\nrecognition, winning the game, and even for the issues of physics. Although\nthere are many studies on the application of machine learning to numerical\ncalculation and assistance of experiments, the methods of applying machine\nlearning to find the analytical method are poorly studied. In this paper, we\npropose the frameworks of developing analytical methods in physics by using the\nsymbolic regression with the Alpha Zero algorithm, that is Alpha Zero for\nphysics (AZfP). As a demonstration, we show that AZfP can derive the\nhigh-frequency expansion in the Floquet systems. AZfP may have the possibility\nof developing a new theoretical framework in physics.",
            "author": [
                "Yoshihiro Michishita"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12713v2",
                "http://arxiv.org/pdf/2311.12713v2"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph",
                "cond-mat.dis-nn",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12711v1",
            "title": "Regression-Based Analysis of Multimodal Single-Cell Data Integration\n  Strategies",
            "updated": "2023-11-21T16:31:27Z",
            "published": "2023-11-21T16:31:27Z",
            "summary": "Multimodal single-cell technologies enable the simultaneous collection of\ndiverse data types from individual cells, enhancing our understanding of\ncellular states. However, the integration of these datatypes and modeling the\ninterrelationships between modalities presents substantial computational and\nanalytical challenges in disease biomarker detection and drug discovery.\nEstablished practices rely on isolated methodologies to investigate individual\nmolecular aspects separately, often resulting in inaccurate analyses. To\naddress these obstacles, distinct Machine Learning Techniques are leveraged,\neach of its own kind to model the co-variation of DNA to RNA, and finally to\nsurface proteins in single cells during hematopoietic stem cell development,\nwhich simplifies understanding of underlying cellular mechanisms and immune\nresponses. Experiments conducted on a curated subset of a 300,000-cell time\ncourse dataset, highlights the exceptional performance of Echo State Networks,\nboasting a remarkable state-of-the-art correlation score of 0.94 and 0.895 on\nMulti-omic and CiteSeq datasets. Beyond the confines of this study, these\nfindings hold promise for advancing comprehension of cellular differentiation\nand function, leveraging the potential of Machine Learning.",
            "author": [
                "Bhavya Mehta",
                "Nirmit Deliwala",
                "Madhav Chandane"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12711v1",
                "http://arxiv.org/pdf/2311.12711v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.GN"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12706v1",
            "title": "Learning-based Array Configuration-Independent Binaural Audio\n  Telepresence with Scalable Signal Enhancement and Ambience Preservation",
            "updated": "2023-11-21T16:19:40Z",
            "published": "2023-11-21T16:19:40Z",
            "summary": "Audio Telepresence (AT) aims to create an immersive experience of the audio\nscene at the far end for the user(s) at the near end. The application of AT\ncould encompass scenarios with varying degrees of emphasis on signal\nenhancement and ambience preservation. It is desirable for an AT system to be\nscalable between these two extremes. To this end, we propose an array-based\nBinaural AT (BAT) system using the DeepFilterNet as the backbone to convert the\narray microphone signals into the Head-Related Transfer Function\n(HRTF)-filtered signals, with a tunable weighting between signal enhancement\nand ambience preservation. An array configuration-independent Spatial COherence\nREpresentation (SCORE) feature is proposed for the model training so that the\nnetwork remains robust to different array geometries and sensor counts.\nmagnitude-weighted Interaural Phase Difference error (mw-IPDe),\nmagnitude-weighted Interaural Level Difference error (mw-ILDe), and modified\nScale-Invariant Signal-to-Distortion Ratio (mSI-SDR) are defined as performance\nmetrics for objective evaluation. Subjective listening tests were also\nperformed to validate the proposed BAT system. The results have shown that the\nproposed BAT system can achieve superior telepresence performance with the\ndesired balance between signal enhancement and ambience preservation, even when\nthe array configurations are unseen in the training phase.",
            "author": [
                "Yicheng Hsu",
                "Mingsian R. Bai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12706v1",
                "http://arxiv.org/pdf/2311.12706v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12704v2",
            "title": "Cascade Learning Localises Discriminant Features in Visual Scene\n  Classification",
            "updated": "2023-11-30T12:07:23Z",
            "published": "2023-11-21T16:19:14Z",
            "summary": "Lack of interpretability of deep convolutional neural networks (DCNN) is a\nwell-known problem particularly in the medical domain as clinicians want\ntrustworthy automated decisions. One way to improve trust is to demonstrate the\nlocalisation of feature representations with respect to expert labeled regions\nof interest. In this work, we investigate the localisation of features learned\nvia two varied learning paradigms and demonstrate the superiority of one\nlearning approach with respect to localisation. Our analysis on medical and\nnatural datasets show that the traditional end-to-end (E2E) learning strategy\nhas a limited ability to localise discriminative features across multiple\nnetwork layers. We show that a layer-wise learning strategy, namely cascade\nlearning (CL), results in more localised features. Considering localisation\naccuracy, we not only show that CL outperforms E2E but that it is a promising\nmethod of predicting regions. On the YOLO object detection framework, our best\nresult shows that CL outperforms the E2E scheme by $2\\%$ in mAP.",
            "author": [
                "Junwen Wang",
                "Katayoun Farrahi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12704v2",
                "http://arxiv.org/pdf/2311.12704v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12702v2",
            "title": "\"There Has To Be a Lot That We're Missing\": Moderating AI-Generated\n  Content on Reddit",
            "updated": "2023-11-27T21:52:23Z",
            "published": "2023-11-21T16:15:21Z",
            "summary": "Generative AI threatens to disrupt how we work, learn, communicate, and\nparticipate in online communities. We performed a qualitative interview study\nto understand how online communities on the social sharing site Reddit are\nchallenged by AI-generated content (AIGC) and how they are adapting. We\nconducted fifteen in-depth, semi-structured interviews with subreddit\nmoderators about their experiences moderating AIGC. Though our participants see\nboth legitimate and illegitimate motivations for using AIGC, on the whole they\nview it as detrimental to their communities, with a level of concern that is\ndependent on the purpose and size of their subreddits. Moderators reported\ndeveloping rules and using a variety of strategies that may help communities\nprevent or curb AIGC, but without foolproof detection tools, enforcement is\nchallenging and relies on heuristics. Overall, for online communities, the\nthreat of Generative AI is not speculative: the disruption has already begun.",
            "author": [
                "Travis Lloyd",
                "Joseph Reagle",
                "Mor Naaman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12702v2",
                "http://arxiv.org/pdf/2311.12702v2"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12699v1",
            "title": "Can Large Language Models Understand Content and Propagation for\n  Misinformation Detection: An Empirical Study",
            "updated": "2023-11-21T16:03:51Z",
            "published": "2023-11-21T16:03:51Z",
            "summary": "Large Language Models (LLMs) have garnered significant attention for their\npowerful ability in natural language understanding and reasoning. In this\npaper, we present a comprehensive empirical study to explore the performance of\nLLMs on misinformation detection tasks. This study stands as the pioneering\ninvestigation into the understanding capabilities of multiple LLMs regarding\nboth content and propagation across social media platforms. Our empirical\nstudies on five misinformation detection datasets show that LLMs with diverse\nprompts achieve comparable performance in text-based misinformation detection\nbut exhibit notably constrained capabilities in comprehending propagation\nstructure compared to existing models in propagation-based misinformation\ndetection. Besides, we further design four instruction-tuned strategies to\nenhance LLMs for both content and propagation-based misinformation detection.\nThese strategies boost LLMs to actively learn effective features from multiple\ninstances or hard instances, and eliminate irrelevant propagation structures,\nthereby achieving better detection performance. Extensive experiments further\ndemonstrate LLMs would play a better capacity in content and propagation\nstructure under these proposed strategies and achieve promising detection\nperformance. These findings highlight the potential ability of LLMs to detect\nmisinformation.",
            "author": [
                "Mengyang Chen",
                "Lingwei Wei",
                "Han Cao",
                "Wei Zhou",
                "Songlin Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12699v1",
                "http://arxiv.org/pdf/2311.12699v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12689v1",
            "title": "Fair Text Classification with Wasserstein Independence",
            "updated": "2023-11-21T15:51:06Z",
            "published": "2023-11-21T15:51:06Z",
            "summary": "Group fairness is a central research topic in text classification, where\nreaching fair treatment between sensitive groups (e.g. women vs. men) remains\nan open challenge. This paper presents a novel method for mitigating biases in\nneural text classification, agnostic to the model architecture. Considering the\ndifficulty to distinguish fair from unfair information in a text encoder, we\ntake inspiration from adversarial training to induce Wasserstein independence\nbetween representations learned to predict our target label and the ones\nlearned to predict some sensitive attribute. Our approach provides two\nsignificant advantages. Firstly, it does not require annotations of sensitive\nattributes in both testing and training data. This is more suitable for\nreal-life scenarios compared to existing methods that require annotations of\nsensitive attributes at train time. Second, our approach exhibits a comparable\nor better fairness-accuracy trade-off compared to existing methods.",
            "author": [
                "Thibaud Leteno",
                "Antoine Gourru",
                "Charlotte Laclau",
                "R\u00e9mi Emonet",
                "Christophe Gravier"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12689v1",
                "http://arxiv.org/pdf/2311.12689v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CY",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12688v1",
            "title": "On the Out-of-Distribution Coverage of Combining Split Conformal\n  Prediction and Bayesian Deep Learning",
            "updated": "2023-11-21T15:50:37Z",
            "published": "2023-11-21T15:50:37Z",
            "summary": "Bayesian deep learning and conformal prediction are two methods that have\nbeen used to convey uncertainty and increase safety in machine learning\nsystems. We focus on combining Bayesian deep learning with split conformal\nprediction and how this combination effects out-of-distribution coverage;\nparticularly in the case of multiclass image classification. We suggest that if\nthe model is generally underconfident on the calibration set, then the\nresultant conformal sets may exhibit worse out-of-distribution coverage\ncompared to simple predictive credible sets. Conversely, if the model is\noverconfident on the calibration set, the use of conformal prediction may\nimprove out-of-distribution coverage. We evaluate prediction sets as a result\nof combining split conformal methods and neural networks trained with (i)\nstochastic gradient descent, (ii) deep ensembles, and (iii) mean-field\nvariational inference. Our results suggest that combining Bayesian deep\nlearning models with split conformal prediction can, in some cases, cause\nunintended consequences such as reducing out-of-distribution coverage.",
            "author": [
                "Paul Scemama",
                "Ariel Kapusta"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12688v1",
                "http://arxiv.org/pdf/2311.12688v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12687v1",
            "title": "Virtual potential created by a feedback loop: taming the feedback demon\n  to explore stochastic thermodynamics of underdamped systems",
            "updated": "2023-11-21T15:49:42Z",
            "published": "2023-11-21T15:49:42Z",
            "summary": "Virtual potentials are an elegant, precise and flexible tool to manipulate\nsmall systems and explore fundamental questions in stochastic thermodynamics.\nIn particular double-well potentials have applications in information\nprocessing, such as the demonstration of Landauer's principle. In this chapter,\nwe detail the implementation of a feedback loop for an underdamped system, in\norder to build a tunable virtual double-well potential. This feedback behaves\nas a demon acting on the system depending on the outcome of a continuously\nrunning measurement. It can thus modify the energy exchanges with the\nthermostat and create an out-of-equilibrium state. To create a bi-stable\npotential, the feedback consists only in switching an external force between\ntwo steady values when the measured position crosses a threshold. We show that\na small delay of the feedback loop in the switches between the two wells\nresults in a modified velocity distribution. The latter can be interpreted as a\ncooling of the kinetic temperature of the system. Using a fast digital\nfeedback, we successfully address all experimental issues to create a virtual\npotential that is statistically indistinguishable from a physical one, with a\ntunable barrier height and energy step between the two wells.",
            "author": [
                "Salamb\u00f4 Dago",
                "Nicolas Barros",
                "Jorge Pereda",
                "Sergio Ciliberto",
                "Ludovic Bellon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12687v1",
                "http://arxiv.org/pdf/2311.12687v1"
            ],
            "primary_category": "cond-mat.stat-mech",
            "category": [
                "cond-mat.stat-mech",
                "cond-mat.mes-hall"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12686v1",
            "title": "Managing ML-Based Application Non-Functional Behavior: A Multi-Model\n  Approach",
            "updated": "2023-11-21T15:47:06Z",
            "published": "2023-11-21T15:47:06Z",
            "summary": "Modern applications are increasingly driven by Machine Learning (ML) models\nwhose non-deterministic behavior is affecting the entire application life cycle\nfrom design to operation. The pervasive adoption of ML is urgently calling for\napproaches that guarantee a stable non-functional behavior of ML-based\napplications over time and across model changes. To this aim, non-functional\nproperties of ML models, such as privacy, confidentiality, fairness, and\nexplainability, must be monitored, verified, and maintained. This need is even\nmore pressing when modern applications operate in the edge-cloud continuum,\nincreasing their complexity and dynamicity. Existing approaches mostly focus on\ni) implementing classifier selection solutions according to the functional\nbehavior of ML models, ii) finding new algorithmic solutions to this need, such\nas continuous re-training. In this paper, we propose a multi-model approach\nbuilt on dynamic classifier selection, where multiple ML models showing similar\nnon-functional properties are made available to the application and one model\nis selected over time according to (dynamic and unpredictable) contextual\nchanges. Our solution goes beyond the state of the art by providing an\narchitectural and methodological approach that continuously guarantees a stable\nnon-functional behavior of ML-based applications, is applicable to different ML\nmodels, and is driven by non-functional properties assessed on the models\nthemselves. It consists of a two-step process working during application\noperation, where model assessment verifies non-functional properties of ML\nmodels trained and selected at development time, and model substitution\nguarantees a continuous and stable support of non-functional properties. We\nexperimentally evaluate our solution in a real-world scenario focusing on\nnon-functional property fairness.",
            "author": [
                "Marco Anisetti",
                "Claudio A. Ardagna",
                "Nicola Bena",
                "Ernesto Damiani",
                "Paolo G. Panero"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12686v1",
                "http://arxiv.org/pdf/2311.12686v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12684v1",
            "title": "Adversarial Reweighting Guided by Wasserstein Distance for Bias\n  Mitigation",
            "updated": "2023-11-21T15:46:11Z",
            "published": "2023-11-21T15:46:11Z",
            "summary": "The unequal representation of different groups in a sample population can\nlead to discrimination of minority groups when machine learning models make\nautomated decisions. To address these issues, fairness-aware machine learning\njointly optimizes two (or more) metrics aiming at predictive effectiveness and\nlow unfairness. However, the inherent under-representation of minorities in the\ndata makes the disparate treatment of subpopulations less noticeable and\ndifficult to deal with during learning. In this paper, we propose a novel\nadversarial reweighting method to address such \\emph{representation bias}. To\nbalance the data distribution between the majority and the minority groups, our\napproach deemphasizes samples from the majority group. To minimize empirical\nrisk, our method prefers samples from the majority group that are close to the\nminority group as evaluated by the Wasserstein distance. Our theoretical\nanalysis shows the effectiveness of our adversarial reweighting approach.\nExperiments demonstrate that our approach mitigates bias without sacrificing\nclassification accuracy, outperforming related state-of-the-art methods on\nimage and tabular benchmark datasets.",
            "author": [
                "Xuan Zhao",
                "Simone Fabbrizzi",
                "Paula Reyero Lobo",
                "Siamak Ghodsi",
                "Klaus Broelemann",
                "Steffen Staab",
                "Gjergji Kasneci"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12684v1",
                "http://arxiv.org/pdf/2311.12684v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12682v1",
            "title": "Transferring to Real-World Layouts: A Depth-aware Framework for Scene\n  Adaptation",
            "updated": "2023-11-21T15:39:21Z",
            "published": "2023-11-21T15:39:21Z",
            "summary": "Scene segmentation via unsupervised domain adaptation (UDA) enables the\ntransfer of knowledge acquired from source synthetic data to real-world target\ndata, which largely reduces the need for manual pixel-level annotations in the\ntarget domain. To facilitate domain-invariant feature learning, existing\nmethods typically mix data from both the source domain and target domain by\nsimply copying and pasting the pixels. Such vanilla methods are usually\nsub-optimal since they do not take into account how well the mixed layouts\ncorrespond to real-world scenarios. Real-world scenarios are with an inherent\nlayout. We observe that semantic categories, such as sidewalks, buildings, and\nsky, display relatively consistent depth distributions, and could be clearly\ndistinguished in a depth map. Based on such observation, we propose a\ndepth-aware framework to explicitly leverage depth estimation to mix the\ncategories and facilitate the two complementary tasks, i.e., segmentation and\ndepth learning in an end-to-end manner. In particular, the framework contains a\nDepth-guided Contextual Filter (DCF) forndata augmentation and a cross-task\nencoder for contextual learning. DCF simulates the real-world layouts, while\nthe cross-task encoder further adaptively fuses the complementing features\nbetween two tasks. Besides, it is worth noting that several public datasets do\nnot provide depth annotation. Therefore, we leverage the off-the-shelf depth\nestimation network to generate the pseudo depth. Extensive experiments show\nthat our proposed methods, even with pseudo depth, achieve competitive\nperformance on two widely-used bench-marks, i.e. 77.7 mIoU on GTA to Cityscapes\nand 69.3 mIoU on Synthia to Cityscapes.",
            "author": [
                "Mu Chen",
                "Zhedong Zheng",
                "Yi Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12682v1",
                "http://arxiv.org/pdf/2311.12682v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12679v1",
            "title": "BundleMoCap: Efficient, Robust and Smooth Motion Capture from Sparse\n  Multiview Videos",
            "updated": "2023-11-21T15:37:19Z",
            "published": "2023-11-21T15:37:19Z",
            "summary": "Capturing smooth motions from videos using markerless techniques typically\ninvolves complex processes such as temporal constraints, multiple stages with\ndata-driven regression and optimization, and bundle solving over temporal\nwindows. These processes can be inefficient and require tuning multiple\nobjectives across stages. In contrast, BundleMoCap introduces a novel and\nefficient approach to this problem. It solves the motion capture task in a\nsingle stage, eliminating the need for temporal smoothness objectives while\nstill delivering smooth motions. BundleMoCap outperforms the state-of-the-art\nwithout increasing complexity. The key concept behind BundleMoCap is manifold\ninterpolation between latent keyframes. By relying on a local manifold\nsmoothness assumption, we can efficiently solve a bundle of frames using a\nsingle code. Additionally, the method can be implemented as a sliding window\noptimization and requires only the first frame to be properly initialized,\nreducing the overall computational burden. BundleMoCap's strength lies in its\nability to achieve high-quality motion capture results with simplicity and\nefficiency. More details can be found at https://moverseai.github.io/bundle/.",
            "author": [
                "Georgios Albanis",
                "Nikolaos Zioulis",
                "Kostas Kolomvatsos"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3626495.3626511",
                "http://arxiv.org/abs/2311.12679v1",
                "http://arxiv.org/pdf/2311.12679v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12678v1",
            "title": "Interpretation of the Transformer and Improvement of the Extractor",
            "updated": "2023-11-21T15:36:20Z",
            "published": "2023-11-21T15:36:20Z",
            "summary": "It has been over six years since the Transformer architecture was put\nforward. Surprisingly, the vanilla Transformer architecture is still widely\nused today. One reason is that the lack of deep understanding and comprehensive\ninterpretation of the Transformer architecture makes it more challenging to\nimprove the Transformer architecture. In this paper, we first interpret the\nTransformer architecture comprehensively in plain words based on our\nunderstanding and experiences. The interpretations are further proved and\nverified. These interpretations also cover the Extractor, a family of drop-in\nreplacements for the multi-head self-attention in the Transformer architecture.\nThen, we propose an improvement on a type of the Extractor that outperforms the\nself-attention, without introducing additional trainable parameters.\nExperimental results demonstrate that the improved Extractor performs even\nbetter, showing a way to improve the Transformer architecture.",
            "author": [
                "Zhe Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12678v1",
                "http://arxiv.org/pdf/2311.12678v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12674v1",
            "title": "Contrastive Left-Right Wearable Sensors (IMUs) Consistency Matching for\n  HAR",
            "updated": "2023-11-21T15:31:16Z",
            "published": "2023-11-21T15:31:16Z",
            "summary": "Machine learning algorithms are improving rapidly, but annotating training\ndata remains a bottleneck for many applications. In this paper, we show how\nreal data can be used for self-supervised learning without any transformations\nby taking advantage of the symmetry present in the activities. Our approach\ninvolves contrastive matching of two different sensors (left and right wrist or\nleg-worn IMUs) to make representations of co-occurring sensor data more similar\nand those of non-co-occurring sensor data more different. We test our approach\non the Opportunity and MM-Fit datasets. In MM-Fit we show significant\nimprovement over the baseline supervised and self-supervised method SimCLR,\nwhile for Opportunity there is significant improvement over the supervised\nbaseline and slight improvement when compared to SimCLR. Moreover, our method\nimproves supervised baselines even when using only a small amount of the data\nfor training. Future work should explore under which conditions our method is\nbeneficial for human activity recognition systems and other related\napplications.",
            "author": [
                "Dominique Nshimyimana",
                "Vitor Fortes Rey",
                "Paul Lukowic"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12674v1",
                "http://arxiv.org/pdf/2311.12674v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12671v1",
            "title": "Predictive Density Combination Using a Tree-Based Synthesis Function",
            "updated": "2023-11-21T15:29:09Z",
            "published": "2023-11-21T15:29:09Z",
            "summary": "Bayesian predictive synthesis (BPS) provides a method for combining multiple\npredictive distributions based on agent/expert opinion analysis theory and\nencompasses a range of existing density forecast pooling methods. The key\ningredient in BPS is a ``synthesis'' function. This is typically specified\nparametrically as a dynamic linear regression. In this paper, we develop a\nnonparametric treatment of the synthesis function using regression trees. We\nshow the advantages of our tree-based approach in two macroeconomic forecasting\napplications. The first uses density forecasts for GDP growth from the euro\narea's Survey of Professional Forecasters. The second combines density\nforecasts of US inflation produced by many regression models involving\ndifferent predictors. Both applications demonstrate the benefits -- in terms of\nimproved forecast accuracy and interpretability -- of modeling the synthesis\nfunction nonparametrically.",
            "author": [
                "Tony Chernis",
                "Niko Hauzenberger",
                "Florian Huber",
                "Gary Koop",
                "James Mitchell"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12671v1",
                "http://arxiv.org/pdf/2311.12671v1"
            ],
            "primary_category": "econ.EM",
            "category": [
                "econ.EM",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12670v2",
            "title": "Towards a more inductive world for drug repurposing approaches",
            "updated": "2023-11-24T10:49:50Z",
            "published": "2023-11-21T15:28:44Z",
            "summary": "Drug-target interaction (DTI) prediction is a challenging, albeit essential\ntask in drug repurposing. Learning on graph models have drawn special attention\nas they can significantly reduce drug repurposing costs and time commitment.\nHowever, many current approaches require high-demanding additional information\nbesides DTIs that complicates their evaluation process and usability.\nAdditionally, structural differences in the learning architecture of current\nmodels hinder their fair benchmarking. In this work, we first perform an\nin-depth evaluation of current DTI datasets and prediction models through a\nrobust benchmarking process, and show that DTI prediction methods based on\ntransductive models lack generalization and lead to inflated performance when\nevaluated as previously done in the literature, hence not being suited for drug\nrepurposing approaches. We then propose a novel biologically-driven strategy\nfor negative edge subsampling and show through in vitro validation that newly\ndiscovered interactions are indeed true. We envision this work as the\nunderpinning for future fair benchmarking and robust model design. All\ngenerated resources and tools are publicly available as a python package.",
            "author": [
                "Jesus de la Fuente",
                "Guillermo Serrano",
                "Ux\u00eda Veleiro",
                "Mikel Casals",
                "Laura Vera",
                "Marija Pizurica",
                "Antonio Pineda-Lucena",
                "Idoia Ochoa",
                "Silve Vicent",
                "Olivier Gevaert",
                "Mikel Hernaez"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12670v2",
                "http://arxiv.org/pdf/2311.12670v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12908v1",
            "title": "Diffusion Model Alignment Using Direct Preference Optimization",
            "updated": "2023-11-21T15:24:05Z",
            "published": "2023-11-21T15:24:05Z",
            "summary": "Large language models (LLMs) are fine-tuned using human comparison data with\nReinforcement Learning from Human Feedback (RLHF) methods to make them better\naligned with users' preferences. In contrast to LLMs, human preference learning\nhas not been widely explored in text-to-image diffusion models; the best\nexisting approach is to fine-tune a pretrained model using carefully curated\nhigh quality images and captions to improve visual appeal and text alignment.\nWe propose Diffusion-DPO, a method to align diffusion models to human\npreferences by directly optimizing on human comparison data. Diffusion-DPO is\nadapted from the recently developed Direct Preference Optimization (DPO), a\nsimpler alternative to RLHF which directly optimizes a policy that best\nsatisfies human preferences under a classification objective. We re-formulate\nDPO to account for a diffusion model notion of likelihood, utilizing the\nevidence lower bound to derive a differentiable objective. Using the Pick-a-Pic\ndataset of 851K crowdsourced pairwise preferences, we fine-tune the base model\nof the state-of-the-art Stable Diffusion XL (SDXL)-1.0 model with\nDiffusion-DPO. Our fine-tuned base model significantly outperforms both base\nSDXL-1.0 and the larger SDXL-1.0 model consisting of an additional refinement\nmodel in human evaluation, improving visual appeal and prompt alignment. We\nalso develop a variant that uses AI feedback and has comparable performance to\ntraining on human preferences, opening the door for scaling of diffusion model\nalignment methods.",
            "author": [
                "Bram Wallace",
                "Meihua Dang",
                "Rafael Rafailov",
                "Linqi Zhou",
                "Aaron Lou",
                "Senthil Purushwalkam",
                "Stefano Ermon",
                "Caiming Xiong",
                "Shafiq Joty",
                "Nikhil Naik"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12908v1",
                "http://arxiv.org/pdf/2311.12908v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.GR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12666v1",
            "title": "SSVEP-DAN: A Data Alignment Network for SSVEP-based Brain Computer\n  Interfaces",
            "updated": "2023-11-21T15:18:29Z",
            "published": "2023-11-21T15:18:29Z",
            "summary": "Steady-state visual-evoked potential (SSVEP)-based brain-computer interfaces\n(BCIs) offer a non-invasive means of communication through high-speed speller\nsystems. However, their efficiency heavily relies on individual training data\nobtained during time-consuming calibration sessions. To address the challenge\nof data insufficiency in SSVEP-based BCIs, we present SSVEP-DAN, the first\ndedicated neural network model designed for aligning SSVEP data across\ndifferent domains, which can encompass various sessions, subjects, or devices.\nOur experimental results across multiple cross-domain scenarios demonstrate\nSSVEP-DAN's capability to transform existing source SSVEP data into\nsupplementary calibration data, significantly enhancing SSVEP decoding accuracy\nin scenarios with limited calibration data. We envision SSVEP-DAN as a catalyst\nfor practical SSVEP-based BCI applications with minimal calibration. The source\ncodes in this work are available at: https://github.com/CECNL/SSVEP-DAN.",
            "author": [
                "Sung-Yu Chen",
                "Chi-Min Chang",
                "Kuan-Jung Chiang",
                "Chun-Shu Wei"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12666v1",
                "http://arxiv.org/pdf/2311.12666v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12657v1",
            "title": "Carbohydrate NMR chemical shift predictions using E(3) equivariant graph\n  neural networks",
            "updated": "2023-11-21T15:01:14Z",
            "published": "2023-11-21T15:01:14Z",
            "summary": "Carbohydrates, vital components of biological systems, are well-known for\ntheir structural diversity. Nuclear Magnetic Resonance (NMR) spectroscopy plays\na crucial role in understanding their intricate molecular arrangements and is\nessential in assessing and verifying the molecular structure of organic\nmolecules. An important part of this process is to predict the NMR chemical\nshift from the molecular structure. This work introduces a novel approach that\nleverages E(3) equivariant graph neural networks to predict carbohydrate NMR\nspectra. Notably, our model achieves a substantial reduction in mean absolute\nerror, up to threefold, compared to traditional models that rely solely on\ntwo-dimensional molecular structure. Even with limited data, the model excels,\nhighlighting its robustness and generalization capabilities. The implications\nare far-reaching and go beyond an advanced understanding of carbohydrate\nstructures and spectral interpretation. For example, it could accelerate\nresearch in pharmaceutical applications, biochemistry, and structural biology,\noffering a faster and more reliable analysis of molecular structures.\nFurthermore, our approach is a key step towards a new data-driven era in\nspectroscopy, potentially influencing spectroscopic techniques beyond NMR.",
            "author": [
                "Maria B\u00e5nkestad",
                "Keven M. Dorst",
                "G\u00f6ran Widmalm",
                "Jerk R\u00f6nnols"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12657v1",
                "http://arxiv.org/pdf/2311.12657v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12652v1",
            "title": "FedDRO: Federated Compositional Optimization for Distributionally Robust\n  Learning",
            "updated": "2023-11-21T14:53:39Z",
            "published": "2023-11-21T14:53:39Z",
            "summary": "Recently, compositional optimization (CO) has gained popularity because of\nits applications in distributionally robust optimization (DRO) and many other\nmachine learning problems. Large-scale and distributed availability of data\ndemands the development of efficient federated learning (FL) algorithms for\nsolving CO problems. Developing FL algorithms for CO is particularly\nchallenging because of the compositional nature of the objective. Moreover,\ncurrent state-of-the-art methods to solve such problems rely on large batch\ngradients (depending on the solution accuracy) not feasible for most practical\nsettings. To address these challenges, in this work, we propose efficient\nFedAvg-type algorithms for solving non-convex CO in the FL setting. We first\nestablish that vanilla FedAvg is not suitable to solve distributed CO problems\nbecause of the data heterogeneity in the compositional objective at each client\nwhich leads to the amplification of bias in the local compositional gradient\nestimates. To this end, we propose a novel FL framework FedDRO that utilizes\nthe DRO problem structure to design a communication strategy that allows FedAvg\nto control the bias in the estimation of the compositional gradient. A key\nnovelty of our work is to develop solution accuracy-independent algorithms that\ndo not require large batch gradients (and function evaluations) for solving\nfederated CO problems. We establish $\\mathcal{O}(\\epsilon^{-2})$ sample and\n$\\mathcal{O}(\\epsilon^{-3/2})$ communication complexity in the FL setting while\nachieving linear speedup with the number of clients. We corroborate our\ntheoretical findings with empirical studies on large-scale DRO problems.",
            "author": [
                "Prashant Khanduri",
                "Chengyin Li",
                "Rafi Ibn Sultan",
                "Yao Qiang",
                "Joerg Kliewer",
                "Dongxiao Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12652v1",
                "http://arxiv.org/pdf/2311.12652v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12651v2",
            "title": "Mobile-Seed: Joint Semantic Segmentation and Boundary Detection for\n  Mobile Robots",
            "updated": "2023-11-23T16:38:00Z",
            "published": "2023-11-21T14:53:02Z",
            "summary": "Precise and rapid delineation of sharp boundaries and robust semantics is\nessential for numerous downstream robotic tasks, such as robot grasping and\nmanipulation, real-time semantic mapping, and online sensor calibration\nperformed on edge computing units. Although boundary detection and semantic\nsegmentation are complementary tasks, most studies focus on lightweight models\nfor semantic segmentation but overlook the critical role of boundary detection.\nIn this work, we introduce Mobile-Seed, a lightweight, dual-task framework\ntailored for simultaneous semantic segmentation and boundary detection. Our\nframework features a two-stream encoder, an active fusion decoder (AFD) and a\ndual-task regularization approach. The encoder is divided into two pathways:\none captures category-aware semantic information, while the other discerns\nboundaries from multi-scale features. The AFD module dynamically adapts the\nfusion of semantic and boundary information by learning channel-wise\nrelationships, allowing for precise weight assignment of each channel.\nFurthermore, we introduce a regularization loss to mitigate the conflicts in\ndual-task learning and deep diversity supervision. Compared to existing\nmethods, the proposed Mobile-Seed offers a lightweight framework to\nsimultaneously improve semantic segmentation performance and accurately locate\nobject boundaries. Experiments on the Cityscapes dataset have shown that\nMobile-Seed achieves notable improvement over the state-of-the-art (SOTA)\nbaseline by 2.2 percentage points (pp) in mIoU and 4.2 pp in mF-score, while\nmaintaining an online inference speed of 23.9 frames-per-second (FPS) with\n1024x2048 resolution input on an RTX 2080 Ti GPU. Additional experiments on\nCamVid and PASCAL Context datasets confirm our method's generalizability. Code\nand additional results are publicly available at\nhttps://whu-usi3dv.github.io/Mobile-Seed/.",
            "author": [
                "Youqi Liao",
                "Shuhao Kang",
                "Jianping Li",
                "Yang Liu",
                "Yun Liu",
                "Zhen Dong",
                "Bisheng Yang",
                "Xieyuanli Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12651v2",
                "http://arxiv.org/pdf/2311.12651v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12649v1",
            "title": "MathGloss: Building mathematical glossaries from text",
            "updated": "2023-11-21T14:49:00Z",
            "published": "2023-11-21T14:49:00Z",
            "summary": "MathGloss is a project to create a knowledge graph (KG) for undergraduate\nmathematics from text, automatically, using modern natural language processing\n(NLP) tools and resources already available on the web. MathGloss is a linked\ndatabase of undergraduate concepts in mathematics. So far, it combines five\nresources: (i) Wikidata, a collaboratively edited, multilingual knowledge graph\nhosted by the Wikimedia Foundation, (ii) terms covered in mathematics courses\nat the University of Chicago, (iii) the syllabus of the French undergraduate\nmathematics curriculum which includes hyperlinks to the automated theorem\nprover Lean 4, (iv) MuLiMa, a multilingual dictionary of mathematics curated by\nmathematicians, and (v) the nLab, a wiki for category theory also curated by\nmathematicians. MathGloss's goal is to bring together resources for learning\nmathematics and to allow every mathematician to tailor their learning to their\nown preferences. Moreover, by organizing different resources for learning\nundergraduate mathematics alongside those for learning formal mathematics, we\nhope to make it easier for mathematicians and formal tools (theorem provers,\ncomputer algebra systems, etc) experts to \"understand\" each other and break\ndown some of the barriers to formal math.",
            "author": [
                "Lucy Horowitz",
                "Valeria de Paiva"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12649v1",
                "http://arxiv.org/pdf/2311.12649v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12644v1",
            "title": "Careful Selection and Thoughtful Discarding: Graph Explicit Pooling\n  Utilizing Discarded Nodes",
            "updated": "2023-11-21T14:44:51Z",
            "published": "2023-11-21T14:44:51Z",
            "summary": "Graph pooling has been increasingly recognized as crucial for Graph Neural\nNetworks (GNNs) to facilitate hierarchical graph representation learning.\nExisting graph pooling methods commonly consist of two stages: selecting\ntop-ranked nodes and discarding the remaining to construct coarsened graph\nrepresentations. However, this paper highlights two key issues with these\nmethods: 1) The process of selecting nodes to discard frequently employs\nadditional Graph Convolutional Networks or Multilayer Perceptrons, lacking a\nthorough evaluation of each node's impact on the final graph representation and\nsubsequent prediction tasks. 2) Current graph pooling methods tend to directly\ndiscard the noise segment (dropped) of the graph without accounting for the\nlatent information contained within these elements. To address the first issue,\nwe introduce a novel Graph Explicit Pooling (GrePool) method, which selects\nnodes by explicitly leveraging the relationships between the nodes and final\nrepresentation vectors crucial for classification. The second issue is\naddressed using an extended version of GrePool (i.e., GrePool+), which applies\na uniform loss on the discarded nodes. This addition is designed to augment the\ntraining process and improve classification accuracy. Furthermore, we conduct\ncomprehensive experiments across 12 widely used datasets to validate our\nproposed method's effectiveness, including the Open Graph Benchmark datasets.\nOur experimental results uniformly demonstrate that GrePool outperforms 14\nbaseline methods for most datasets. Likewise, implementing GrePool+ enhances\nGrePool's performance without incurring additional computational costs.",
            "author": [
                "Chuang Liu",
                "Wenhang Yu",
                "Kuang Gao",
                "Xueqi Ma",
                "Yibing Zhan",
                "Jia Wu",
                "Bo Du",
                "Wenbin Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12644v1",
                "http://arxiv.org/pdf/2311.12644v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12642v1",
            "title": "Ab initio framework for deciphering trade-off relationships in\n  multi-component alloys",
            "updated": "2023-11-21T14:42:29Z",
            "published": "2023-11-21T14:42:29Z",
            "summary": "While first-principles methods have been successfully applied to characterize\nindividual properties of multi-principal element alloys (MPEA), their use to\nsearch for optimal trade-offs between competing properties is hampered by high\ncomputational demands. In this work, we present a novel framework to explore\nPareto-optimal compositions by integrating advanced ab-initio-based techniques\ninto a Bayesian multi-objective optimization method. We benchmark the framework\nby applying it to solid solution strengthening and ductility of refractory\nMPEAs, with the parameters of the strengthening and ductility models being\nefficiently computed using a combination of the coherent-potential\napproximation method, accounting for finite-temperature effects, and\nactively-learned moment-tensor potentials parameterized with ab initio data.\nAdditionally, we introduce an analytical model that captures the concentration\ndependence of all relevant material properties, relying on a few\nelement-specific parameters and universal functions that describe bonding\nbetween elements. Our findings offer new crucial insights into the traditional\nstrength-vs-ductility dilemma of refractory MPEAs. The proposed framework is\nversatile and can be extended to other materials and properties of interest,\nenabling a predictive and tractable high-throughput screening of Pareto-optimal\nMPEAs over the entire composition space.",
            "author": [
                "Franco Moitzi",
                "Lorenz Romaner",
                "Max Hodapp",
                "Andrei V. Ruban",
                "Oleg E. Peil"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12642v1",
                "http://arxiv.org/pdf/2311.12642v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12630v2",
            "title": "Hierarchical Joint Graph Learning and Multivariate Time Series\n  Forecasting",
            "updated": "2023-11-30T13:44:21Z",
            "published": "2023-11-21T14:24:21Z",
            "summary": "Multivariate time series is prevalent in many scientific and industrial\ndomains. Modeling multivariate signals is challenging due to their long-range\ntemporal dependencies and intricate interactions--both direct and indirect. To\nconfront these complexities, we introduce a method of representing multivariate\nsignals as nodes in a graph with edges indicating interdependency between them.\nSpecifically, we leverage graph neural networks (GNN) and attention mechanisms\nto efficiently learn the underlying relationships within the time series data.\nMoreover, we suggest employing hierarchical signal decompositions running over\nthe graphs to capture multiple spatial dependencies. The effectiveness of our\nproposed model is evaluated across various real-world benchmark datasets\ndesigned for long-term forecasting tasks. The results consistently showcase the\nsuperiority of our model, achieving an average 23\\% reduction in mean squared\nerror (MSE) compared to existing models.",
            "author": [
                "Juhyeon Kim",
                "Hyungeun Lee",
                "Seungwon Yu",
                "Ung Hwang",
                "Wooyul Jung",
                "Miseon Park",
                "Kijung Yoon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12630v2",
                "http://arxiv.org/pdf/2311.12630v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12624v1",
            "title": "Bridging Algorithmic Information Theory and Machine Learning: A New\n  Approach to Kernel Learning",
            "updated": "2023-11-21T14:18:28Z",
            "published": "2023-11-21T14:18:28Z",
            "summary": "Machine Learning (ML) and Algorithmic Information Theory (AIT) look at\nComplexity from different points of view. We explore the interface between AIT\nand Kernel Methods (that are prevalent in ML) by adopting an AIT perspective on\nthe problem of learning kernels from data, in kernel ridge regression, through\nthe method of Sparse Kernel Flows. In particular, by looking at the differences\nand commonalities between Minimal Description Length (MDL) and Regularization\nin Machine Learning (RML), we prove that the method of Sparse Kernel Flows is\nthe natural approach to adopt to learn kernels from data. This paper shows that\nit is not necessary to use the statistical route to derive Sparse Kernel Flows\nand that one can directly work with code-lengths and complexities that are\nconcepts that show up in AIT.",
            "author": [
                "Boumediene Hamzi",
                "Marcus Hutter",
                "Houman Owhadi"
            ],
            "link": [
                "http://dx.doi.org/10.13140/RG.2.2.36344.01285",
                "http://arxiv.org/abs/2311.12624v1",
                "http://arxiv.org/pdf/2311.12624v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IT",
                "math.IT",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12623v1",
            "title": "Bridging Generalization Gaps in High Content Imaging Through Online\n  Self-Supervised Domain Adaptation",
            "updated": "2023-11-21T14:16:57Z",
            "published": "2023-11-21T14:16:57Z",
            "summary": "High Content Imaging (HCI) plays a vital role in modern drug discovery and\ndevelopment pipelines, facilitating various stages from hit identification to\ncandidate drug characterization. Applying machine learning models to these\ndatasets can prove challenging as they typically consist of multiple batches,\naffected by experimental variation, especially if different imaging equipment\nhave been used. Moreover, as new data arrive, it is preferable that they are\nanalyzed in an online fashion. To overcome this, we propose CODA, an online\nself-supervised domain adaptation approach. CODA divides the classifier's role\ninto a generic feature extractor and a task-specific model. We adapt the\nfeature extractor's weights to the new domain using cross-batch\nself-supervision while keeping the task-specific model unchanged. Our results\ndemonstrate that this strategy significantly reduces the generalization gap,\nachieving up to a 300% improvement when applied to data from different labs\nutilizing different microscopes. CODA can be applied to new, unlabeled\nout-of-domain data sources of different sizes, from a single plate to multiple\nexperimental batches.",
            "author": [
                "Johan Fredin Haslum",
                "Christos Matsoukas",
                "Karl-Johan Leuchowius",
                "Kevin Smith"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12623v1",
                "http://arxiv.org/pdf/2311.12623v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12621v1",
            "title": "Crowd management, crime detection, work monitoring using aiml",
            "updated": "2023-11-21T14:12:17Z",
            "published": "2023-11-21T14:12:17Z",
            "summary": "This research endeavors to harness the potential of existing Closed-Circuit\nTelevision (CCTV) networks for a comprehensive approach to crowd management,\ncrime prevention, and workplace monitoring through the integration of\nArtificial Intelligence (AI) and Machine Learning (ML) technologies. The\nprimary objective is to develop and implement advanced algorithms capable of\nreal-time analysis of video feeds, enabling the identification and assessment\nof crowd dynamics, early detection of potential criminal activities, and\ncontinuous monitoring of workplace environments. By leveraging AI/ML, the\nproject aims to optimize surveillance capabilities, thereby enhancing public\nsafety measures and improving organizational productivity. This initiative\nunderscores the transformative impact that intelligent video analytics can have\non existing infrastructure, mitigating the need for extensive system overhauls\nwhile significantly advancing security and operational efficiency.",
            "author": [
                "P. R. Adithya",
                "Dheepak. S",
                "B. Akash",
                "Harshini. V",
                "Sai Lakshana"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12621v1",
                "http://arxiv.org/pdf/2311.12621v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12618v1",
            "title": "Limitations of measure-first protocols in quantum machine learning",
            "updated": "2023-11-21T14:03:29Z",
            "published": "2023-11-21T14:03:29Z",
            "summary": "In recent works, much progress has been made with regards to so-called\nrandomized measurement strategies, which include the famous methods of\nclassical shadows and shadow tomography. In such strategies, unknown quantum\nstates are first measured (or ``learned''), to obtain classical data that can\nbe used to later infer (or ``predict'') some desired properties of the quantum\nstates. Even if the used measurement procedure is fixed, surprisingly,\nestimations of an exponential number of vastly different quantities can be\nobtained from a polynomial amount of measurement data. This raises the question\nof just how powerful ``measure-first'' strategies are, and in particular, if\nall quantum machine learning problems can be solved with a measure-first,\nanalyze-later scheme. This paper explores the potential and limitations of\nthese measure-first protocols in learning from quantum data. We study a natural\nsupervised learning setting where quantum states constitute data points, and\nthe labels stem from an unknown measurement. We examine two types of machine\nlearning protocols: ``measure-first'' protocols, where all the quantum data is\nfirst measured using a fixed measurement strategy, and ``fully-quantum''\nprotocols where the measurements are adapted during the training process. Our\nmain result is a proof of separation. We prove that there exist learning\nproblems that can be efficiently learned by fully-quantum protocols but which\nrequire exponential resources for measure-first protocols. Moreover, we show\nthat this separation persists even for quantum data that can be prepared by a\npolynomial-time quantum process, such as a polynomially-sized quantum circuit.\nOur proofs combine methods from one-way communication complexity and\npseudorandom quantum states. Our result underscores the role of quantum data\nprocessing in machine learning and highlights scenarios where quantum\nadvantages appear.",
            "author": [
                "Casper Gyurik",
                "Riccardo Molteni",
                "Vedran Dunjko"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12618v1",
                "http://arxiv.org/pdf/2311.12618v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12617v1",
            "title": "Leveraging Unlabeled Data for 3D Medical Image Segmentation through\n  Self-Supervised Contrastive Learning",
            "updated": "2023-11-21T14:03:16Z",
            "published": "2023-11-21T14:03:16Z",
            "summary": "Current 3D semi-supervised segmentation methods face significant challenges\nsuch as limited consideration of contextual information and the inability to\ngenerate reliable pseudo-labels for effective unsupervised data use. To address\nthese challenges, we introduce two distinct subnetworks designed to explore and\nexploit the discrepancies between them, ultimately correcting the erroneous\nprediction results. More specifically, we identify regions of inconsistent\npredictions and initiate a targeted verification training process. This\nprocedure strategically fine-tunes and harmonizes the predictions of the\nsubnetworks, leading to enhanced utilization of contextual information.\nFurthermore, to adaptively fine-tune the network's representational capacity\nand reduce prediction uncertainty, we employ a self-supervised contrastive\nlearning paradigm. For this, we use the network's confidence to distinguish\nbetween reliable and unreliable predictions. The model is then trained to\neffectively minimize unreliable predictions. Our experimental results for organ\nsegmentation, obtained from clinical MRI and CT scans, demonstrate the\neffectiveness of our approach when compared to state-of-the-art methods. The\ncodebase is accessible on\n\\href{https://github.com/xmindflow/SSL-contrastive}{GitHub}.",
            "author": [
                "Sanaz Karimijafarbigloo",
                "Reza Azad",
                "Yury Velichko",
                "Ulas Bagci",
                "Dorit Merhof"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12617v1",
                "http://arxiv.org/pdf/2311.12617v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12615v1",
            "title": "Koopman Learning with Episodic Memory",
            "updated": "2023-11-21T13:59:00Z",
            "published": "2023-11-21T13:59:00Z",
            "summary": "Koopman operator theory, a data-driven dynamical systems framework, has found\nsignificant success in learning models from complex, real-world data sets,\nenabling state-of-the-art prediction and control. The greater interpretability\nand lower computational costs of these models, compared to traditional machine\nlearning methodologies, make Koopman learning an especially appealing approach.\nDespite this, little work has been performed on endowing Koopman learning with\nthe ability to learn from its own mistakes. To address this, we equip Koopman\nmethods - developed for predicting non-stationary time-series - with an\nepisodic memory mechanism, enabling global recall of (or attention to) periods\nin time where similar dynamics previously occurred. We find that a basic\nimplementation of Koopman learning with episodic memory leads to significant\nimprovements in prediction on synthetic and real-world data. Our framework has\nconsiderable potential for expansion, allowing for future advances, and opens\nexciting new directions for Koopman learning.",
            "author": [
                "William T. Redman",
                "Dean Huang",
                "Maria Fonoberova",
                "Igor Mezi\u0107"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12615v1",
                "http://arxiv.org/pdf/2311.12615v1"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12613v1",
            "title": "Decentralised Q-Learning for Multi-Agent Markov Decision Processes with\n  a Satisfiability Criterion",
            "updated": "2023-11-21T13:56:44Z",
            "published": "2023-11-21T13:56:44Z",
            "summary": "In this paper, we propose a reinforcement learning algorithm to solve a\nmulti-agent Markov decision process (MMDP). The goal, inspired by Blackwell's\nApproachability Theorem, is to lower the time average cost of each agent to\nbelow a pre-specified agent-specific bound. For the MMDP, we assume the state\ndynamics to be controlled by the joint actions of agents, but the per-stage\ncosts to only depend on the individual agent's actions. We combine the\nQ-learning algorithm for a weighted combination of the costs of each agent,\nobtained by a gossip algorithm with the Metropolis-Hastings or Multiplicative\nWeights formalisms to modulate the averaging matrix of the gossip. We use\nmultiple timescales in our algorithm and prove that under mild conditions, it\napproximately achieves the desired bounds for each of the agents. We also\ndemonstrate the empirical performance of this algorithm in the more general\nsetting of MMDPs having jointly controlled per-stage costs.",
            "author": [
                "Keshav P. Keval",
                "Vivek S. Borkar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12613v1",
                "http://arxiv.org/pdf/2311.12613v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.MA",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12612v3",
            "title": "A New Type Of Upper And Lower Bounds On Right-Tail Probabilities Of\n  Continuous Random Variables",
            "updated": "2023-11-27T07:41:06Z",
            "published": "2023-11-21T13:54:08Z",
            "summary": "In this paper, I present a completely new type of upper and lower bounds on\nthe right-tail probabilities of continuous random variables with unbounded\nsupport and with semi-bounded support from the left. The presented upper and\nlower right-tail bounds depend only on the probability density function (PDF),\nits first derivative, and two parameters that are used for tightening the\nbounds. These tail bounds hold under certain conditions that depend on the PDF,\nits first and second derivatives, and the two parameters. The new tail bounds\nare shown to be tight for a wide range of continuous random variables via\nnumerical examples.",
            "author": [
                "Nikola Zlatanov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12612v3",
                "http://arxiv.org/pdf/2311.12612v3"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "cs.IT",
                "cs.LG",
                "math.IT",
                "math.ST",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12610v1",
            "title": "ChessVision -- A Dataset for Logically Coherent Multi-label\n  Classification",
            "updated": "2023-11-21T13:52:31Z",
            "published": "2023-11-21T13:52:31Z",
            "summary": "Starting with early successes in computer vision tasks, deep learning based\ntechniques have since overtaken state of the art approaches in a multitude of\ndomains. However, it has been demonstrated time and again that these techniques\nfail to capture semantic context and logical constraints, instead often relying\non spurious correlations to arrive at the answer. Since application of deep\nlearning techniques to critical scenarios are dependent on adherence to domain\nspecific constraints, several attempts have been made to address this issue.\nOne limitation holding back a thorough exploration of this area, is a lack of\nsuitable datasets which feature a rich set of rules. In order to address this,\nwe present the ChessVision Dataset, consisting of 200,000+ images of annotated\nchess games in progress, requiring recreation of the game state from its\ncorresponding image. This is accompanied by a curated set of rules which\nconstrains the set of predictions to \"reasonable\" game states, and are designed\nto probe key semantic abilities like localization and enumeration. Alongside\nstandard metrics, additional metrics to measure performance with regards to\nlogical consistency is presented. We analyze several popular and state of the\nart vision models on this task, and show that, although their performance on\nstandard metrics are laudable, they produce a plethora of incoherent results,\nindicating that this dataset presents a significant challenge for future works.",
            "author": [
                "Soumadeep Saha",
                "Utpal Garain"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12610v1",
                "http://arxiv.org/pdf/2311.12610v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12609v2",
            "title": "Reinforcement Learning for the Near-Optimal Design of Zero-Delay Codes\n  for Markov Sources",
            "updated": "2023-11-28T14:51:06Z",
            "published": "2023-11-21T13:52:20Z",
            "summary": "In the classical lossy source coding problem, one encodes long blocks of\nsource symbols that enables the distortion to approach the ultimate Shannon\nlimit. Such a block-coding approach introduces large delays, which is\nundesirable in many delay-sensitive applications. We consider the zero-delay\ncase, where the goal is to encode and decode a finite-alphabet Markov source\nwithout any delay. It has been shown that this problem lends itself to\nstochastic control techniques, which lead to existence, structural, and general\nstructural approximation results. However, these techniques so far have\nresulted only in computationally prohibitive algorithmic implementations for\ncode design. To address this problem, we present a reinforcement learning\ndesign algorithm and rigorously prove its asymptotic optimality. In particular,\nwe show that a quantized Q-learning algorithm can be used to obtain a\nnear-optimal coding policy for this problem. The proof builds on recent results\non quantized Q-learning for weakly Feller controlled Markov chains whose\napplication necessitates the development of supporting technical results on\nregularity and stability properties, and relating the optimal solutions for\ndiscounted and average cost infinite horizon criteria problems. These\ntheoretical results are supported by simulations.",
            "author": [
                "Liam Cregg",
                "Tamas Linder",
                "Serdar Yuksel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12609v2",
                "http://arxiv.org/pdf/2311.12609v2"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "math.IT",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14733v1",
            "title": "Thinking Outside the Box: Orthogonal Approach to Equalizing Protected\n  Attributes",
            "updated": "2023-11-21T13:48:56Z",
            "published": "2023-11-21T13:48:56Z",
            "summary": "There is growing concern that the potential of black box AI may exacerbate\nhealth-related disparities and biases such as gender and ethnicity in clinical\ndecision-making. Biased decisions can arise from data availability and\ncollection processes, as well as from the underlying confounding effects of the\nprotected attributes themselves. This work proposes a machine learning-based\northogonal approach aiming to analyze and suppress the effect of the confounder\nthrough discriminant dimensionality reduction and orthogonalization of the\nprotected attributes against the primary attribute information. By doing so,\nthe impact of the protected attributes on disease diagnosis can be realized,\nundesirable feature correlations can be mitigated, and the model prediction\nperformance can be enhanced.",
            "author": [
                "Jiahui Liu",
                "Xiaohao Cai",
                "Mahesan Niranjan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14733v1",
                "http://arxiv.org/pdf/2311.14733v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12602v1",
            "title": "TouchSDF: A DeepSDF Approach for 3D Shape Reconstruction using\n  Vision-Based Tactile Sensing",
            "updated": "2023-11-21T13:43:06Z",
            "published": "2023-11-21T13:43:06Z",
            "summary": "Humans rely on their visual and tactile senses to develop a comprehensive 3D\nunderstanding of their physical environment. Recently, there has been a growing\ninterest in exploring and manipulating objects using data-driven approaches\nthat utilise high-resolution vision-based tactile sensors. However, 3D shape\nreconstruction using tactile sensing has lagged behind visual shape\nreconstruction because of limitations in existing techniques, including the\ninability to generalise over unseen shapes, the absence of real-world testing,\nand limited expressive capacity imposed by discrete representations. To address\nthese challenges, we propose TouchSDF, a Deep Learning approach for tactile 3D\nshape reconstruction that leverages the rich information provided by a\nvision-based tactile sensor and the expressivity of the implicit neural\nrepresentation DeepSDF. Our technique consists of two components: (1) a\nConvolutional Neural Network that maps tactile images into local meshes\nrepresenting the surface at the touch location, and (2) an implicit neural\nfunction that predicts a signed distance function to extract the desired 3D\nshape. This combination allows TouchSDF to reconstruct smooth and continuous 3D\nshapes from tactile inputs in simulation and real-world settings, opening up\nresearch avenues for robust 3D-aware representations and improved multimodal\nperception in robotics. Code and supplementary material are available at:\nhttps://touchsdf.github.io/",
            "author": [
                "Mauro Comi",
                "Yijiong Lin",
                "Alex Church",
                "Alessio Tonioni",
                "Laurence Aitchison",
                "Nathan F. Lepora"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12602v1",
                "http://arxiv.org/pdf/2311.12602v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12601v1",
            "title": "Deep learning-based detection of morphological features associated with\n  hypoxia in H&E breast cancer whole slide images",
            "updated": "2023-11-21T13:42:40Z",
            "published": "2023-11-21T13:42:40Z",
            "summary": "Hypoxia occurs when tumour cells outgrow their blood supply, leading to\nregions of low oxygen levels within the tumour. Calculating hypoxia levels can\nbe an important step in understanding the biology of tumours, their clinical\nprogression and response to treatment. This study demonstrates a novel\napplication of deep learning to evaluate hypoxia in the context of breast\ncancer histomorphology. More precisely, we show that Weakly Supervised Deep\nLearning (WSDL) models can accurately detect hypoxia associated features in\nroutine Hematoxylin and Eosin (H&E) whole slide images (WSI). We trained and\nevaluated a deep Multiple Instance Learning model on tiles from WSI H&E tissue\nfrom breast cancer primary sites (n=240) obtaining on average an AUC of 0.87 on\na left-out test set. We also showed significant differences between features of\nhypoxic and normoxic tissue regions as distinguished by the WSDL models. Such\nDL hypoxia H&E WSI detection models could potentially be extended to other\ntumour types and easily integrated into the pathology workflow without\nrequiring additional costly assays.",
            "author": [
                "Petru Manescu",
                "Joseph Geradts",
                "Delmiro Fernandez-Reyes"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12601v1",
                "http://arxiv.org/pdf/2311.12601v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "q-bio.TO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12590v1",
            "title": "ChronoPscychosis: Temporal Segmentation and Its Impact on Schizophrenia\n  Classification Using Motor Activity Data",
            "updated": "2023-11-21T13:26:33Z",
            "published": "2023-11-21T13:26:33Z",
            "summary": "Schizophrenia is a complicated mental illness characterized by a broad\nspectrum of symptoms affecting cognition, behavior, and emotion. The task of\nidentifying reliable biomarkers to classify Schizophrenia accurately continues\nto be a challenge in the field of psychiatry. We investigate the temporal\npatterns within the motor activity data as a potential key to enhancing the\ncategorization of individuals with Schizophrenia, using the dataset having\nmotor activity recordings of 22 Schizophrenia patients and 32 control subjects.\nThe dataset contains per-minute motor activity measurements collected for an\naverage of 12.7 days in a row for each participant. We dissect each day into\nsegments (Twelve, Eight, six, four, three, and two parts) and evaluate their\nimpact on classification. We employ sixteen statistical features within these\ntemporal segments and train them on Seven machine learning models to get deeper\ninsights. LightGBM model outperforms the other six models. Our results indicate\nthat the temporal segmentation significantly improves the classification, with\nAUC-ROC = 0.93, F1 score = 0.84( LightGBM- without any segmentation) and\nAUC-ROC = 0.98, F1 score = 0.93( LightGBM- with segmentation). Distinguishing\nbetween diurnal and nocturnal segments amplifies the differences between\nSchizophrenia patients and controls. However, further subdivisions into smaller\ntime segments do not affect the AUC- ROC significantly. Morning, afternoon,\nevening, and night partitioning gives similar classification performance to\nday-night partitioning. These findings are valuable as they indicate that\nextensive temporal classification beyond distinguishing between day and night\ndoes not yield substantial results, offering an efficient approach for further\nclassification, early diagnosis, and monitoring of Schizophrenia.",
            "author": [
                "Pradnya Rajendra Jadhav",
                "Raviprasad Aduri"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12590v1",
                "http://arxiv.org/pdf/2311.12590v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12589v2",
            "title": "Improving Source-Free Target Adaptation with Vision Transformers\n  Leveraging Domain Representation Images",
            "updated": "2023-12-02T11:01:26Z",
            "published": "2023-11-21T13:26:13Z",
            "summary": "Unsupervised Domain Adaptation (UDA) methods facilitate knowledge transfer\nfrom a labeled source domain to an unlabeled target domain, navigating the\nobstacle of domain shift. While Convolutional Neural Networks (CNNs) are a\nstaple in UDA, the rise of Vision Transformers (ViTs) provides new avenues for\ndomain generalization. This paper presents an innovative method to bolster ViT\nperformance in source-free target adaptation, beginning with an evaluation of\nhow key, query, and value elements affect ViT outcomes. Experiments indicate\nthat altering the key component has negligible effects on Transformer\nperformance. Leveraging this discovery, we introduce Domain Representation\nImages (DRIs), feeding embeddings through the key element. DRIs act as\ndomain-specific markers, effortlessly merging with the training regimen. To\nassess our method, we perform target adaptation tests on the Cross Instance DRI\nsource-only (SO) control. We measure the efficacy of target adaptation with and\nwithout DRIs, against existing benchmarks like SHOT-B* and adaptations via\nCDTrans. Findings demonstrate that excluding DRIs offers limited gains over\nSHOT-B*, while their inclusion in the key segment boosts average precision\npromoting superior domain generalization. This research underscores the vital\nrole of DRIs in enhancing ViT efficiency in UDA scenarios, setting a precedent\nfor further domain adaptation explorations.",
            "author": [
                "Gauransh Sawhney",
                "Daksh Dave",
                "Adeel Ahmed",
                "Jiechao Gao",
                "Khalid Saleem"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12589v2",
                "http://arxiv.org/pdf/2311.12589v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12906v1",
            "title": "Nonlinear System Identification of Swarm of UAVs Using Deep Learning\n  Methods",
            "updated": "2023-11-21T13:13:12Z",
            "published": "2023-11-21T13:13:12Z",
            "summary": "This study designs and evaluates multiple nonlinear system identification\ntechniques for modeling the UAV swarm system in planar space. learning methods\nsuch as RNNs, CNNs, and Neural ODE are explored and compared. The objective is\nto forecast future swarm trajectories by accurately approximating the nonlinear\ndynamics of the swarm model. The modeling process is performed using both\ntransient and steady-state data from swarm simulations. Results show that the\ncombination of Neural ODE with a well-trained model using transient data is\nrobust for varying initial conditions and outperforms other learning methods in\naccurately predicting swarm stability.",
            "author": [
                "Saman Yazdannik",
                "Morteza Tayefi",
                "Mojtaba Farrokh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12906v1",
                "http://arxiv.org/pdf/2311.12906v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12905v1",
            "title": "Revisiting the Domain Shift and Sample Uncertainty in Multi-source\n  Active Domain Transfer",
            "updated": "2023-11-21T13:12:21Z",
            "published": "2023-11-21T13:12:21Z",
            "summary": "Active Domain Adaptation (ADA) aims to maximally boost model adaptation in a\nnew target domain by actively selecting a limited number of target data to\nannotate.This setting neglects the more practical scenario where training data\nare collected from multiple sources. This motivates us to target a new and\nchallenging setting of knowledge transfer that extends ADA from a single source\ndomain to multiple source domains, termed Multi-source Active Domain Adaptation\n(MADA). Not surprisingly, we find that most traditional ADA methods cannot work\ndirectly in such a setting, mainly due to the excessive domain gap introduced\nby all the source domains and thus their uncertainty-aware sample selection can\neasily become miscalibrated under the multi-domain shifts. Considering this, we\npropose a Dynamic integrated uncertainty valuation framework(Detective) that\ncomprehensively consider the domain shift between multi-source domains and\ntarget domain to detect the informative target samples. Specifically, the\nleverages a dynamic Domain Adaptation(DA) model that learns how to adapt the\nmodel's parameters to fit the union of multi-source domains. This enables an\napproximate single-source domain modeling by the dynamic model. We then\ncomprehensively measure both domain uncertainty and predictive uncertainty in\nthe target domain to detect informative target samples using evidential deep\nlearning, thereby mitigating uncertainty miscalibration. Furthermore, we\nintroduce a contextual diversity-aware calculator to enhance the diversity of\nthe selected samples. Experiments demonstrate that our solution outperforms\nexisting methods by a considerable margin on three domain adaptation\nbenchmarks.",
            "author": [
                "Wenqiao Zhang",
                "Zheqi Lv",
                "Hao Zhou",
                "Jia-Wei Liu",
                "Juncheng Li",
                "Mengze Li",
                "Siliang Tang",
                "Yueting Zhuang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12905v1",
                "http://arxiv.org/pdf/2311.12905v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12582v1",
            "title": "Echocardiogram Foundation Model -- Application 1: Estimating Ejection\n  Fraction",
            "updated": "2023-11-21T13:00:03Z",
            "published": "2023-11-21T13:00:03Z",
            "summary": "Cardiovascular diseases stand as the primary global cause of mortality. Among\nthe various imaging techniques available for visualising the heart and\nevaluating its function, echocardiograms emerge as the preferred choice due to\ntheir safety and low cost. Quantifying cardiac function based on\nechocardiograms is very laborious, time-consuming and subject to high\ninteroperator variability. In this work, we introduce EchoAI, an echocardiogram\nfoundation model, that is trained using self-supervised learning (SSL) on 1.5\nmillion echocardiograms. We evaluate our approach by fine-tuning EchoAI to\nestimate the ejection fraction achieving a mean absolute percentage error of\n9.40%. This level of accuracy aligns with the performance of expert\nsonographers.",
            "author": [
                "Adil Dahlan",
                "Cyril Zakka",
                "Abhinav Kumar",
                "Laura Tang",
                "Rohan Shad",
                "Robyn Fong",
                "William Hiesinger"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12582v1",
                "http://arxiv.org/pdf/2311.12582v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12581v1",
            "title": "A Region of Interest Focused Triple UNet Architecture for Skin Lesion\n  Segmentation",
            "updated": "2023-11-21T12:56:42Z",
            "published": "2023-11-21T12:56:42Z",
            "summary": "Skin lesion segmentation is of great significance for skin lesion analysis\nand subsequent treatment. It is still a challenging task due to the irregular\nand fuzzy lesion borders, and diversity of skin lesions. In this paper, we\npropose Triple-UNet to automatically segment skin lesions. It is an organic\ncombination of three UNet architectures with suitable modules. In order to\nconcatenate the first and second sub-networks more effectively, we design a\nregion of interest enhancement module (ROIE). The ROIE enhances the target\nobject region of the image by using the predicted score map of the first UNet.\nThe features learned by the first UNet and the enhanced image help the second\nUNet obtain a better score map. Finally, the results are fine-tuned by the\nthird UNet. We evaluate our algorithm on a publicly available dataset of skin\nlesion segmentation. Experiments show that Triple-UNet outperforms the\nstate-of-the-art on skin lesion segmentation.",
            "author": [
                "Guoqing Liu",
                "Yu Guo",
                "Caiying Wu",
                "Guoqing Chen",
                "Barintag Saheya",
                "Qiyu Jin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12581v1",
                "http://arxiv.org/pdf/2311.12581v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12579v1",
            "title": "Machine-Guided Discovery of a Real-World Rogue Wave Model",
            "updated": "2023-11-21T12:50:24Z",
            "published": "2023-11-21T12:50:24Z",
            "summary": "Big data and large-scale machine learning have had a profound impact on\nscience and engineering, particularly in fields focused on forecasting and\nprediction. Yet, it is still not clear how we can use the superior pattern\nmatching abilities of machine learning models for scientific discovery. This is\nbecause the goals of machine learning and science are generally not aligned. In\naddition to being accurate, scientific theories must also be causally\nconsistent with the underlying physical process and allow for human analysis,\nreasoning, and manipulation to advance the field. In this paper, we present a\ncase study on discovering a new symbolic model for oceanic rogue waves from\ndata using causal analysis, deep learning, parsimony-guided model selection,\nand symbolic regression. We train an artificial neural network on causal\nfeatures from an extensive dataset of observations from wave buoys, while\nselecting for predictive performance and causal invariance. We apply symbolic\nregression to distill this black-box model into a mathematical equation that\nretains the neural network's predictive capabilities, while allowing for\ninterpretation in the context of existing wave theory. The resulting model\nreproduces known behavior, generates well-calibrated probabilities, and\nachieves better predictive scores on unseen data than current theory. This\nshowcases how machine learning can facilitate inductive scientific discovery,\nand paves the way for more accurate rogue wave forecasting.",
            "author": [
                "Dion H\u00e4fner",
                "Johannes Gemmrich",
                "Markus Jochum"
            ],
            "link": [
                "http://dx.doi.org/10.1073/pnas.2306275120",
                "http://arxiv.org/abs/2311.12579v1",
                "http://arxiv.org/pdf/2311.12579v1"
            ],
            "primary_category": "physics.geo-ph",
            "category": [
                "physics.geo-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12577v2",
            "title": "Characterising TOI-732 b and c: New insights into the M-dwarf radius and\n  density valley",
            "updated": "2023-11-30T09:28:01Z",
            "published": "2023-11-21T12:43:39Z",
            "summary": "TOI-732 is an M dwarf hosting two transiting planets that are located on the\ntwo opposite sides of the radius valley. By doubling the number of available\nspace-based observations and increasing the number of radial velocity (RV)\nmeasurements, we aim at refining the parameters of TOI-732 b and c. We also use\nthe results to study the slope of the radius valley and the density valley for\na well-characterised sample of M-dwarf exoplanets. We performed a global MCMC\nanalysis by jointly modelling ground-based light curves and CHEOPS and TESS\nobservations, along with RV time series both taken from the literature and\nobtained with the MAROON-X spectrograph. The slopes of the M-dwarf valleys were\nquantified via a Support Vector Machine (SVM) procedure. TOI-732 b is an\nultrashort-period planet ($P\\sim0.77$ d) with a radius\n$R_b=1.325_{-0.058}^{+0.057}$ $R_{\\oplus}$ and a mass $M_b=2.46\\pm0.19$\n$M_{\\oplus}$ (mean density $\\rho_b=5.8_{-0.8}^{+1.0}$ g cm$^{-3}$), while the\nouter planet at $P\\sim12.25$ d has $R_c=2.39_{-0.11}^{+0.10}$ $R_{\\oplus}$,\n$M_c=8.04_{-0.48}^{+0.50}$ $M_{\\oplus}$, and thus $\\rho_c=3.24_{-0.43}^{+0.55}$\ng cm$^{-3}$. Also taking into account our interior structure calculations,\nTOI-732 b is a super-Earth and TOI-732 c is a mini-Neptune. Following the SVM\napproach, we quantified\n$\\mathrm{d}\\log{R_{p,{\\mathrm{valley}}}}/\\mathrm{d}\\log{P}=-0.065_{-0.013}^{+0.024}$,\nwhich is flatter than for Sun-like stars. In line with former analyses, we note\nthat the radius valley for M-dwarf planets is more densely populated, and we\nfurther quantify the slope of the density valley as\n$\\mathrm{d}\\log{\\hat{\\rho}_{\\mathrm{valley}}}/\\mathrm{d}\\log{P}=-0.02_{-0.04}^{+0.12}$.\nCompared to FGK stars, the weaker dependence of the position of the radius\nvalley on the orbital period might indicate that the formation shapes the\nradius valley around M dwarfs more strongly than the evolution mechanisms.",
            "author": [
                "A. Bonfanti",
                "M. Brady",
                "T. G. Wilson",
                "J. Venturini",
                "J. A. Egger",
                "A. Brandeker",
                "S. G. Sousa",
                "M. Lendl",
                "A. E. Simon",
                "D. Queloz",
                "G. Olofsson",
                "V. Adibekyan",
                "Y. Alibert",
                "L. Fossati",
                "M. J. Hooton",
                "D. Kubyshkina",
                "R. Luque",
                "F. Murgas",
                "A. J. Mustill",
                "N. C. Santos",
                "V. Van Grootel",
                "R. Alonso",
                "J. Asquier",
                "T. Bandy",
                "T. B\u00e1rczy",
                "D. Barrado Navascues",
                "S. C. C. Barros",
                "W. Baumjohann",
                "J. Bean",
                "M. Beck",
                "T. Beck",
                "W. Benz",
                "M. Bergomi",
                "N. Billot",
                "L. Borsato",
                "C. Broeg",
                "A. Collier Cameron",
                "Sz. Csizmadia",
                "P. E. Cubillos",
                "M. B. Davies",
                "M. Deleuil",
                "A. Deline",
                "L. Delrez",
                "O. D. S. Demangeon",
                "B. -O. Demory",
                "D. Ehrenreich",
                "A. Erikson",
                "A. Fortier",
                "M. Fridlund",
                "D. Gandolfi",
                "M. Gillon",
                "M. G\u00fcdel",
                "M. N. G\u00fcnther",
                "A. Heitzmann",
                "Ch. Helling",
                "S. Hoyer",
                "K. G. Isaak",
                "D. Kasper",
                "L. L. Kiss",
                "K. W. F. Lam",
                "J. Laskar",
                "A. Lecavelier des Etangs",
                "D. Magrin",
                "P. F. L. Maxted",
                "C. Mordasini",
                "V. Nascimbeni",
                "R. Ottensamer",
                "I. Pagano",
                "E. Pall\u00e9",
                "G. Peter",
                "G. Piotto",
                "D. Pollacco",
                "R. Ragazzoni",
                "N. Rando",
                "H. Rauer",
                "I. Ribas",
                "G. Scandariato",
                "D. S\u00e9gransan",
                "A. Seifahrt",
                "A. M. S. Smith",
                "M. Stalport",
                "G. Stef\u00e1nsson",
                "M. Steinberger",
                "J. St\u00fcrmer",
                "Gy. M. Szab\u00f3",
                "N. Thomas",
                "S. Udry",
                "E. Villaver",
                "N. A. Walton",
                "K. Westerdorff",
                "T. Zingales"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12577v2",
                "http://arxiv.org/pdf/2311.12577v2"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12574v1",
            "title": "IMGTB: A Framework for Machine-Generated Text Detection Benchmarking",
            "updated": "2023-11-21T12:40:01Z",
            "published": "2023-11-21T12:40:01Z",
            "summary": "In the era of large language models generating high quality texts, it is a\nnecessity to develop methods for detection of machine-generated text to avoid\nharmful use or simply due to annotation purposes. It is, however, also\nimportant to properly evaluate and compare such developed methods. Recently, a\nfew benchmarks have been proposed for this purpose; however, integration of\nnewest detection methods is rather challenging, since new methods appear each\nmonth and provide slightly different evaluation pipelines. In this paper, we\npresent the IMGTB framework, which simplifies the benchmarking of\nmachine-generated text detection methods by easy integration of custom (new)\nmethods and evaluation datasets. Its configurability and flexibility makes\nresearch and development of new detection methods easier, especially their\ncomparison to the existing state-of-the-art detectors. The default set of\nanalyses, metrics and visualizations offered by the tool follows the\nestablished practices of machine-generated text detection benchmarking found in\nstate-of-the-art literature.",
            "author": [
                "Michal Spiegel",
                "Dominik Macko"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12574v1",
                "http://arxiv.org/pdf/2311.12574v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12573v1",
            "title": "Moderating Model Marketplaces: Platform Governance Puzzles for AI\n  Intermediaries",
            "updated": "2023-11-21T12:38:05Z",
            "published": "2023-11-21T12:38:05Z",
            "summary": "The AI development community is increasingly making use of hosting\nintermediaries such as Hugging Face provide easy access to user-uploaded models\nand training data. These model marketplaces lower technical deployment barriers\nfor hundreds of thousands of users, yet can be used in numerous potentially\nharmful and illegal ways. In this article, we explain ways in which AI systems,\nwhich can both `contain' content and be open-ended tools, present one of the\ntrickiest platform governance challenges seen to date. We provide case studies\nof several incidents across three illustrative platforms -- Hugging Face,\nGitHub and Civitai -- to examine how model marketplaces moderate models.\nBuilding on this analysis, we outline important (and yet nevertheless limited)\npractices that industry has been developing to respond to moderation demands:\nlicensing, access and use restrictions, automated content moderation, and open\npolicy development. While the policy challenge at hand is a considerable one,\nwe conclude with some ideas as to how platforms could better mobilize resources\nto act as a careful, fair, and proportionate regulatory access point.",
            "author": [
                "Robert Gorwa",
                "Michael Veale"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12573v1",
                "http://arxiv.org/pdf/2311.12573v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12572v1",
            "title": "Scheduling Distributed Flexible Assembly Lines using Safe Reinforcement\n  Learning with Soft Shielding",
            "updated": "2023-11-21T12:34:46Z",
            "published": "2023-11-21T12:34:46Z",
            "summary": "Highly automated assembly lines enable significant productivity gains in the\nmanufacturing industry, particularly in mass production condition. Nonetheless,\nchallenges persist in job scheduling for make-to-job and mass customization,\nnecessitating further investigation to improve efficiency, reduce tardiness,\npromote safety and reliability. In this contribution, an advantage actor-critic\nbased reinforcement learning method is proposed to address scheduling problems\nof distributed flexible assembly lines in a real-time manner. To enhance the\nperformance, a more condensed environment representation approach is proposed,\nwhich is designed to work with the masks made by priority dispatching rules to\ngenerate fixed and advantageous action space. Moreover, a Monte-Carlo tree\nsearch based soft shielding component is developed to help address\nlong-sequence dependent unsafe behaviors and monitor the risk of overdue\nscheduling. Finally, the proposed algorithm and its soft shielding component\nare validated in performance evaluation.",
            "author": [
                "Lele Li",
                "Liyong Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12572v1",
                "http://arxiv.org/pdf/2311.12572v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.AI",
                "68T20, 68T07",
                "I.2.8; F.2.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12570v2",
            "title": "BEND: Benchmarking DNA Language Models on biologically meaningful tasks",
            "updated": "2023-11-25T07:24:40Z",
            "published": "2023-11-21T12:34:00Z",
            "summary": "The genome sequence contains the blueprint for governing cellular processes.\nWhile the availability of genomes has vastly increased over the last decades,\nexperimental annotation of the various functional, non-coding and regulatory\nelements encoded in the DNA sequence remains both expensive and challenging.\nThis has sparked interest in unsupervised language modeling of genomic DNA, a\nparadigm that has seen great success for protein sequence data. Although\nvarious DNA language models have been proposed, evaluation tasks often differ\nbetween individual works, and might not fully recapitulate the fundamental\nchallenges of genome annotation, including the length, scale and sparsity of\nthe data. In this study, we introduce BEND, a Benchmark for DNA language\nmodels, featuring a collection of realistic and biologically meaningful\ndownstream tasks defined on the human genome. We find that embeddings from\ncurrent DNA LMs can approach performance of expert methods on some tasks, but\nonly capture limited information about long-range features. BEND is available\nat https://github.com/frederikkemarin/BEND.",
            "author": [
                "Frederikke Isa Marin",
                "Felix Teufel",
                "Marc Horlacher",
                "Dennis Madsen",
                "Dennis Pultz",
                "Ole Winther",
                "Wouter Boomsma"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12570v2",
                "http://arxiv.org/pdf/2311.12570v2"
            ],
            "primary_category": "q-bio.GN",
            "category": [
                "q-bio.GN",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12569v1",
            "title": "Differentiable Sampling of Categorical Distributions Using the\n  CatLog-Derivative Trick",
            "updated": "2023-11-21T12:32:38Z",
            "published": "2023-11-21T12:32:38Z",
            "summary": "Categorical random variables can faithfully represent the discrete and\nuncertain aspects of data as part of a discrete latent variable model. Learning\nin such models necessitates taking gradients with respect to the parameters of\nthe categorical probability distributions, which is often intractable due to\ntheir combinatorial nature. A popular technique to estimate these otherwise\nintractable gradients is the Log-Derivative trick. This trick forms the basis\nof the well-known REINFORCE gradient estimator and its many extensions. While\nthe Log-Derivative trick allows us to differentiate through samples drawn from\ncategorical distributions, it does not take into account the discrete nature of\nthe distribution itself. Our first contribution addresses this shortcoming by\nintroducing the CatLog-Derivative trick - a variation of the Log-Derivative\ntrick tailored towards categorical distributions. Secondly, we use the\nCatLog-Derivative trick to introduce IndeCateR, a novel and unbiased gradient\nestimator for the important case of products of independent categorical\ndistributions with provably lower variance than REINFORCE. Thirdly, we\nempirically show that IndeCateR can be efficiently implemented and that its\ngradient estimates have significantly lower bias and variance for the same\nnumber of samples compared to the state of the art.",
            "author": [
                "Lennert De Smet",
                "Emanuele Sansone",
                "Pedro Zuidberg Dos Martires"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12569v1",
                "http://arxiv.org/pdf/2311.12569v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML",
                "68T05",
                "G.3; G.4; I.2.6"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12566v1",
            "title": "Variational Elliptical Processes",
            "updated": "2023-11-21T12:26:14Z",
            "published": "2023-11-21T12:26:14Z",
            "summary": "We present elliptical processes, a family of non-parametric probabilistic\nmodels that subsume Gaussian processes and Student's t processes. This\ngeneralization includes a range of new heavy-tailed behaviors while retaining\ncomputational tractability. Elliptical processes are based on a representation\nof elliptical distributions as a continuous mixture of Gaussian distributions.\nWe parameterize this mixture distribution as a spline normalizing flow, which\nwe train using variational inference. The proposed form of the variational\nposterior enables a sparse variational elliptical process applicable to\nlarge-scale problems. We highlight advantages compared to Gaussian processes\nthrough regression and classification experiments. Elliptical processes can\nsupersede Gaussian processes in several settings, including cases where the\nlikelihood is non-Gaussian or when accurate tail modeling is essential.",
            "author": [
                "Maria B\u00e5nkestad",
                "Jens Sj\u00f6lund",
                "Jalil Taghia",
                "Thomas B. Sch\u00f6on"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12566v1",
                "http://arxiv.org/pdf/2311.12566v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12564v2",
            "title": "Summary of the DISPLACE Challenge 2023 -- DIarization of SPeaker and\n  LAnguage in Conversational Environments",
            "updated": "2023-11-23T07:57:16Z",
            "published": "2023-11-21T12:23:58Z",
            "summary": "In multi-lingual societies, where multiple languages are spoken in a small\ngeographic vicinity, informal conversations often involve mix of languages.\nExisting speech technologies may be inefficient in extracting information from\nsuch conversations, where the speech data is rich in diversity with multiple\nlanguages and speakers. The DISPLACE (DIarization of SPeaker and LAnguage in\nConversational Environments) challenge constitutes an open-call for evaluating\nand bench-marking the speaker and language diarization technologies on this\nchallenging condition. The challenge entailed two tracks: Track-1 focused on\nspeaker diarization (SD) in multilingual situations while, Track-2 addressed\nthe language diarization (LD) in a multi-speaker scenario. Both the tracks were\nevaluated using the same underlying audio data. To facilitate this evaluation,\na real-world dataset featuring multilingual, multi-speaker conversational\nfar-field speech was recorded and distributed. Furthermore, a baseline system\nwas made available for both SD and LD task which mimicked the state-of-art in\nthese tasks. The challenge garnered a total of $42$ world-wide registrations\nand received a total of $19$ combined submissions for Track-1 and Track-2. This\npaper describes the challenge, details of the datasets, tasks, and the baseline\nsystem. Additionally, the paper provides a concise overview of the submitted\nsystems in both tracks, with an emphasis given to the top performing systems.\nThe paper also presents insights and future perspectives for SD and LD tasks,\nfocusing on the key challenges that the systems need to overcome before\nwide-spread commercial deployment on such conversations.",
            "author": [
                "Shikha Baghel",
                "Shreyas Ramoji",
                "Somil Jain",
                "Pratik Roy Chowdhuri",
                "Prachi Singh",
                "Deepu Vijayasenan",
                "Sriram Ganapathy"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12564v2",
                "http://arxiv.org/pdf/2311.12564v2"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12561v1",
            "title": "Convolutional Neural Networks for Neuroimaging in Parkinson's Disease:\n  Is Preprocessing Needed?",
            "updated": "2023-11-21T12:15:28Z",
            "published": "2023-11-21T12:15:28Z",
            "summary": "Spatial and intensity normalization are nowadays a prerequisite for\nneuroimaging analysis. Influenced by voxel-wise and other univariate\ncomparisons, where these corrections are key, they are commonly applied to any\ntype of analysis and imaging modalities. Nuclear imaging modalities such as\nPET-FDG or FP-CIT SPECT, a common modality used in Parkinson's Disease\ndiagnosis, are especially dependent on intensity normalization. However, these\nsteps are computationally expensive and furthermore, they may introduce\ndeformations in the images, altering the information contained in them.\nConvolutional Neural Networks (CNNs), for their part, introduce position\ninvariance to pattern recognition, and have been proven to classify objects\nregardless of their orientation, size, angle, etc. Therefore, a question\narises: how well can CNNs account for spatial and intensity differences when\nanalysing nuclear brain imaging? Are spatial and intensity normalization still\nneeded? To answer this question, we have trained four different CNN models\nbased on well-established architectures, using or not different spatial and\nintensity normalization preprocessing. The results show that a sufficiently\ncomplex model such as our three-dimensional version of the ALEXNET can\neffectively account for spatial differences, achieving a diagnosis accuracy of\n94.1% with an area under the ROC curve of 0.984. The visualization of the\ndifferences via saliency maps shows that these models are correctly finding\npatterns that match those found in the literature, without the need of applying\nany complex spatial normalization procedure. However, the intensity\nnormalization -- and its type -- is revealed as very influential in the results\nand accuracy of the trained model, and therefore must be well accounted.",
            "author": [
                "Francisco J. Martinez-Murcia",
                "Juan M. G\u00f3rriz",
                "Javier Ram\u00edrez",
                "Andr\u00e9s Ortiz"
            ],
            "link": [
                "http://dx.doi.org/10.1142/S0129065718500351",
                "http://arxiv.org/abs/2311.12561v1",
                "http://arxiv.org/pdf/2311.12561v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12551v1",
            "title": "Distilling particle knowledge for fast reconstruction at high-energy\n  physics experiments",
            "updated": "2023-11-21T12:02:14Z",
            "published": "2023-11-21T12:02:14Z",
            "summary": "Knowledge distillation is a form of model compression that allows to transfer\nknowledge between intelligent algorithms. Its main application is the\ncompactification of large deep neural networks to free up computational\nresources, in particular on edge devices. In this article, we consider\nproton-proton collisions at the High-Luminosity LHC (HL-LHC) and demonstrate a\nsuccessful knowledge transfer from an event-level graph neural network (GNN) to\na particle-level small deep neural network (DNN). Our algorithm, DistillNet, is\na DNN that is trained to learn about the provenance of particles, as provided\nby the soft labels that are the GNN outputs, to predict whether or not a\nparticle originates from the primary interaction vertex. The results indicate\nthat for this problem, which is one of the main challenges at the HL-LHC, there\nis minimal loss during the transfer of knowledge to the small student network,\nwhile improving significantly the computational resource needs compared to the\nteacher. This is demonstrated for the distilled student network on a CPU, as\nwell as for a quantized and pruned student network deployed on an FPGA. Our\nstudy proves that knowledge transfer between networks of different complexity\ncan be used for fast artificial intelligence (AI) in high-energy physics that\nimproves the expressiveness of observables over non-AI-based reconstruction\nalgorithms. Such an approach can become essential at the HL-LHC experiments,\ne.g., to comply with the resource budget of their trigger stages.",
            "author": [
                "Aritra Bal",
                "Tristan Brandes",
                "Fabio Iemmi",
                "Markus Klute",
                "Benedikt Maier",
                "Vinicius Mikuni",
                "Thea Aarrestad"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12551v1",
                "http://arxiv.org/pdf/2311.12551v1"
            ],
            "primary_category": "hep-ex",
            "category": [
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12550v2",
            "title": "Explainable Anomaly Detection using Masked Latent Generative Modeling",
            "updated": "2023-11-22T09:45:11Z",
            "published": "2023-11-21T11:59:16Z",
            "summary": "We present a novel time series anomaly detection method that achieves\nexcellent detection accuracy while offering a superior level of explainability.\nOur proposed method, TimeVQVAE-AD, leverages masked generative modeling adapted\nfrom the cutting-edge time series generation method known as TimeVQVAE. The\nprior model is trained on the discrete latent space of a time-frequency domain.\nNotably, the dimensional semantics of the time-frequency domain are preserved\nin the latent space, enabling us to compute anomaly scores across different\nfrequency bands, which provides a better insight into the detected anomalies.\nAdditionally, the generative nature of the prior model allows for sampling\nlikely normal states for detected anomalies, enhancing the explainability of\nthe detected anomalies through counterfactuals. Our experimental evaluation on\nthe UCR Time Series Anomaly archive demonstrates that TimeVQVAE-AD\nsignificantly surpasses the existing methods in terms of detection accuracy and\nexplainability.",
            "author": [
                "Daesoo Lee",
                "Sara Malacarne",
                "Erlend Aune"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12550v2",
                "http://arxiv.org/pdf/2311.12550v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12548v1",
            "title": "Multi-Session Budget Optimization for Forward Auction-based Federated\n  Learning",
            "updated": "2023-11-21T11:57:41Z",
            "published": "2023-11-21T11:57:41Z",
            "summary": "Auction-based Federated Learning (AFL) has emerged as an important research\nfield in recent years. The prevailing strategies for FL model users (MUs)\nassume that the entire team of the required data owners (DOs) for an FL task\nmust be assembled before training can commence. In practice, an MU can trigger\nthe FL training process multiple times. DOs can thus be gradually recruited\nover multiple FL model training sessions. Existing bidding strategies for AFL\nMUs are not designed to handle such scenarios. Therefore, the problem of\nmulti-session AFL remains open. To address this problem, we propose the\nMulti-session Budget Optimization Strategy for forward Auction-based Federated\nLearning (MultiBOS-AFL). Based on hierarchical reinforcement learning,\nMultiBOS-AFL jointly optimizes inter-session budget pacing and intra-session\nbidding for AFL MUs, with the objective of maximizing the total utility.\nExtensive experiments on six benchmark datasets show that it significantly\noutperforms seven state-of-the-art approaches. On average, MultiBOS-AFL\nachieves 12.28% higher utility, 14.52% more data acquired through auctions for\na given budget, and 1.23% higher test accuracy achieved by the resulting FL\nmodel compared to the best baseline. To the best of our knowledge, it is the\nfirst budget optimization decision support method with budget pacing capability\ndesigned for MUs in multi-session forward auction-based federated learning",
            "author": [
                "Xiaoli Tang",
                "Han Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12548v1",
                "http://arxiv.org/pdf/2311.12548v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12904v1",
            "title": "Learning to Compute Gr\u00f6bner Bases",
            "updated": "2023-11-21T11:54:21Z",
            "published": "2023-11-21T11:54:21Z",
            "summary": "Solving a polynomial system, or computing an associated Gr\\\"obner basis, has\nbeen a fundamental task in computational algebra. However, it is also known for\nits notoriously expensive computational cost -- doubly exponential time\ncomplexity in the number of variables in the worst case. In this paper, we\nachieve for the first time Gr\\\"obner basis computation through the training of\na transformer. The training requires many pairs of a polynomial system and the\nassociated Gr\\\"obner basis, thus motivating us to address two novel algebraic\nproblems: random generation of Gr\\\"obner bases and the transformation of them\ninto non-Gr\\\"obner polynomial systems, termed as \\textit{backward Gr\\\"obner\nproblem}. We resolve these problems with zero-dimensional radical ideals, the\nideals appearing in various applications. The experiments show that in the\nfive-variate case, the proposed dataset generation method is five orders of\nmagnitude faster than a naive approach, overcoming a crucial challenge in\nlearning to compute Gr\\\"obner bases.",
            "author": [
                "Hiroshi Kera",
                "Yuki Ishihara",
                "Yuta Kambe",
                "Tristan Vaccon",
                "Kazuhiro Yokoyama"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12904v1",
                "http://arxiv.org/pdf/2311.12904v1"
            ],
            "primary_category": "math.AC",
            "category": [
                "math.AC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12544v1",
            "title": "Learning optimal smooth invariant subspaces for data approximation",
            "updated": "2023-11-21T11:49:13Z",
            "published": "2023-11-21T11:49:13Z",
            "summary": "In this article, we consider the problem of approximating a finite set of\ndata (usually huge in applications) by invariant subspaces generated through a\nsmall set of smooth functions. The invariance is either by translations under a\nfull-rank lattice or through the action of crystallographic groups. Smoothness\nis ensured by stipulating that the generators belong to a Paley-Wiener space,\nthat is selected in an optimal way based on the characteristics of the given\ndata. To complete our investigation, we analyze the fundamental role played by\nthe lattice in the process of approximation.",
            "author": [
                "Davide Barbieri",
                "Eugenio Hern\u00e1ndez",
                "Carlos Cabrelli",
                "Ursula Molter"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12544v1",
                "http://arxiv.org/pdf/2311.12544v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "math.FA",
                "stat.ML",
                "41A65, 43A70"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12539v1",
            "title": "GMISeg: General Medical Image Segmentation without Re-Training",
            "updated": "2023-11-21T11:33:15Z",
            "published": "2023-11-21T11:33:15Z",
            "summary": "Although deep learning models have become the main method for medical image\nsegmentation, they often cannot be extended to unknown segmentation tasks\ninvolving new anatomical structures, image shapes, or labels. For new\nsegmentation tasks, researchers often have to retrain or fine-tune the model,\nwhich is time-consuming and poses a significant obstacle to clinical\nresearchers, who often lack the resources and professional knowledge to train\nneural networks. Therefore, we proposed a general method that can solve unknown\nmedical image segmentation tasks without requiring additional training. Given\nan example set of images and prompts for defining new segmentation tasks,\nGMISeg applies a novel low-rank fine-tuning strategy based on the proposed\napproach to the SAM (Segment Anything Model) image encoder, and works with the\nprompt encoder and mask decoder to fine-tune the labeled dataset without the\nneed for additional training. To achieve generalization of new tasks, we used\nmedical image datasets with different imaging modes for different parts. We\ntrained and generalized GMISeg on a different set of anatomical and imaging\nmodes using cardiac images on other site datasets. We have demonstrated that\nGMISeg outperforms the latest methods on unknown tasks and have conducted a\ncomprehensive analysis and summary of the important performance of the proposed\nmethod.",
            "author": [
                "Jing Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12539v1",
                "http://arxiv.org/pdf/2311.12539v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12538v2",
            "title": "In-Context Learning Functions with Varying Number of Minima",
            "updated": "2023-11-22T08:44:34Z",
            "published": "2023-11-21T11:33:03Z",
            "summary": "Large Language Models (LLMs) have proven effective at In-Context Learning\n(ICL), an ability that allows them to create predictors from labeled examples.\nFew studies have explored the interplay between ICL and specific properties of\nfunctions it attempts to approximate. In our study, we use a formal framework\nto explore ICL and propose a new task of approximating functions with varying\nnumber of minima. We implement a method that allows for producing functions\nwith given inputs as minima. We find that increasing the number of minima\ndegrades ICL performance. At the same time, our evaluation shows that ICL\noutperforms 2-layer Neural Network (2NN) model. Furthermore, ICL learns faster\nthan 2NN in all settings. We validate the findings through a set of few-shot\nexperiments across various hyperparameter configurations.",
            "author": [
                "David Oniani",
                "Yanshan Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12538v2",
                "http://arxiv.org/pdf/2311.12538v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12530v2",
            "title": "An efficient likelihood-free Bayesian inference method based on\n  sequential neural posterior estimation",
            "updated": "2023-11-27T11:28:21Z",
            "published": "2023-11-21T11:21:53Z",
            "summary": "Sequential neural posterior estimation (SNPE) techniques have been recently\nproposed for dealing with simulation-based models with intractable likelihoods.\nUnlike approximate Bayesian computation, SNPE techniques learn the posterior\nfrom sequential simulation using neural network-based conditional density\nestimators by minimizing a specific loss function. The SNPE method proposed by\nLueckmann et al. (2017) used a calibration kernel to boost the sample weights\naround the observed data, resulting in a concentrated loss function. However,\nthe use of calibration kernels may increase the variances of both the empirical\nloss and its gradient, making the training inefficient. To improve the\nstability of SNPE, this paper proposes to use an adaptive calibration kernel\nand several variance reduction techniques. The proposed method greatly speeds\nup the process of training, and provides a better approximation of the\nposterior than the original SNPE method and some existing competitors as\nconfirmed by numerical experiments.",
            "author": [
                "Yifei Xiong",
                "Xiliang Yang",
                "Sanguo Zhang",
                "Zhijian He"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12530v2",
                "http://arxiv.org/pdf/2311.12530v2"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "stat.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12528v1",
            "title": "Inverse Problems with Learned Forward Operators",
            "updated": "2023-11-21T11:15:14Z",
            "published": "2023-11-21T11:15:14Z",
            "summary": "Solving inverse problems requires knowledge of the forward operator, but\naccurate models can be computationally expensive and hence cheaper variants are\ndesired that do not compromise reconstruction quality. This chapter reviews\nreconstruction methods in inverse problems with learned forward operators that\nfollow two different paradigms. The first one is completely agnostic to the\nforward operator and learns its restriction to the subspace spanned by the\ntraining data. The framework of regularisation by projection is then used to\nfind a reconstruction. The second one uses a simplified model of the physics of\nthe measurement process and only relies on the training data to learn a model\ncorrection. We present the theory of these two approaches and compare them\nnumerically. A common theme emerges: both methods require, or at least benefit\nfrom, training data not only for the forward operator, but also for its\nadjoint.",
            "author": [
                "Simon Arridge",
                "Andreas Hauptmann",
                "Yury Korolev"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12528v1",
                "http://arxiv.org/pdf/2311.12528v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.LG",
                "cs.NA",
                "65J22, 47A52, 35R30, 74J25"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12526v2",
            "title": "Neural Network Pruning by Gradient Descent",
            "updated": "2023-11-22T09:39:02Z",
            "published": "2023-11-21T11:12:03Z",
            "summary": "The rapid increase in the parameters of deep learning models has led to\nsignificant costs, challenging computational efficiency and model\ninterpretability. In this paper, we introduce a novel and straightforward\nneural network pruning framework that incorporates the Gumbel-Softmax\ntechnique. This framework enables the simultaneous optimization of a network's\nweights and topology in an end-to-end process using stochastic gradient\ndescent. Empirical results demonstrate its exceptional compression capability,\nmaintaining high accuracy on the MNIST dataset with only 0.15\\% of the original\nnetwork parameters. Moreover, our framework enhances neural network\ninterpretability, not only by allowing easy extraction of feature importance\ndirectly from the pruned network but also by enabling visualization of feature\nsymmetry and the pathways of information propagation from features to outcomes.\nAlthough the pruning strategy is learned through deep learning, it is\nsurprisingly intuitive and understandable, focusing on selecting key\nrepresentative features and exploiting data patterns to achieve extreme sparse\npruning. We believe our method opens a promising new avenue for deep learning\npruning and the creation of interpretable machine learning systems.",
            "author": [
                "Zhang Zhang",
                "Ruyi Tao",
                "Jiang Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12526v2",
                "http://arxiv.org/pdf/2311.12526v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12524v1",
            "title": "ALPHA: AnomaLous Physiological Health Assessment Using Large Language\n  Models",
            "updated": "2023-11-21T11:09:57Z",
            "published": "2023-11-21T11:09:57Z",
            "summary": "This study concentrates on evaluating the efficacy of Large Language Models\n(LLMs) in healthcare, with a specific focus on their application in personal\nanomalous health monitoring. Our research primarily investigates the\ncapabilities of LLMs in interpreting and analyzing physiological data obtained\nfrom FDA-approved devices. We conducted an extensive analysis using anomalous\nphysiological data gathered in a simulated low-air-pressure plateau\nenvironment. This allowed us to assess the precision and reliability of LLMs in\nunderstanding and evaluating users' health status with notable specificity. Our\nfindings reveal that LLMs exhibit exceptional performance in determining\nmedical indicators, including a Mean Absolute Error (MAE) of less than 1 beat\nper minute for heart rate and less than 1% for oxygen saturation (SpO2).\nFurthermore, the Mean Absolute Percentage Error (MAPE) for these evaluations\nremained below 1%, with the overall accuracy of health assessments surpassing\n85%. In image analysis tasks, such as interpreting photoplethysmography (PPG)\ndata, our specially adapted GPT models demonstrated remarkable proficiency,\nachieving less than 1 bpm error in cycle count and 7.28 MAE for heart rate\nestimation. This study highlights LLMs' dual role as health data analysis tools\nand pivotal elements in advanced AI health assistants, offering personalized\nhealth insights and recommendations within the future health assistant\nframework.",
            "author": [
                "Jiankai Tang",
                "Kegang Wang",
                "Hongming Hu",
                "Xiyuxing Zhang",
                "Peiyu Wang",
                "Xin Liu",
                "Yuntao Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12524v1",
                "http://arxiv.org/pdf/2311.12524v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12902v1",
            "title": "Local Convolution Enhanced Global Fourier Neural Operator For Multiscale\n  Dynamic Spaces Prediction",
            "updated": "2023-11-21T11:04:13Z",
            "published": "2023-11-21T11:04:13Z",
            "summary": "Neural operators extend the capabilities of traditional neural networks by\nallowing them to handle mappings between function spaces for the purpose of\nsolving partial differential equations (PDEs). One of the most notable methods\nis the Fourier Neural Operator (FNO), which is inspired by Green's function\nmethod and approximate operator kernel directly in the frequency domain. In\nthis work, we focus on predicting multiscale dynamic spaces, which is\nequivalent to solving multiscale PDEs. Multiscale PDEs are characterized by\nrapid coefficient changes and solution space oscillations, which are crucial\nfor modeling atmospheric convection and ocean circulation. To solve this\nproblem, models should have the ability to capture rapid changes and process\nthem at various scales. However, the FNO only approximates kernels in the\nlow-frequency domain, which is insufficient when solving multiscale PDEs. To\naddress this challenge, we propose a novel hierarchical neural operator that\nintegrates improved Fourier layers with attention mechanisms, aiming to capture\nall details and handle them at various scales. These mechanisms complement each\nother in the frequency domain and encourage the model to solve multiscale\nproblems. We perform experiments on dynamic spaces governed by forward and\nreverse problems of multiscale elliptic equations, Navier-Stokes equations and\nsome other physical scenarios, and reach superior performance in existing PDE\nbenchmarks, especially equations characterized by rapid coefficient variations.",
            "author": [
                "Xuanle Zhao",
                "Yue Sun",
                "Tielin Zhang",
                "Bo Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12902v1",
                "http://arxiv.org/pdf/2311.12902v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NA",
                "math.DS",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12901v1",
            "title": "From Microbes to Methane: AI-Based Predictive Modeling of Feed Additive\n  Efficacy in Dairy Cows",
            "updated": "2023-11-21T10:57:28Z",
            "published": "2023-11-21T10:57:28Z",
            "summary": "In an era of increasing pressure to achieve sustainable agriculture, the\noptimization of livestock feed for enhancing yield and minimizing environmental\nimpact is a paramount objective. This study presents a pioneering approach\ntowards this goal, using rumen microbiome data to predict the efficacy of feed\nadditives in dairy cattle.\n  We collected an extensive dataset that includes methane emissions from 2,190\nHolstein cows distributed across 34 distinct sites. The cows were divided into\ncontrol and experimental groups in a double-blind, unbiased manner, accounting\nfor variables such as age, days in lactation, and average milk yield. The\nexperimental groups were administered one of four leading commercial feed\nadditives: Agolin, Kexxtone, Allimax, and Relyon. Methane emissions were\nmeasured individually both before the administration of additives and over a\nsubsequent 12-week period. To develop our predictive model for additive\nefficacy, rumen microbiome samples were collected from 510 cows from the same\nherds prior to the study's onset. These samples underwent deep metagenomic\nshotgun sequencing, yielding an average of 15.7 million reads per sample.\nUtilizing innovative artificial intelligence techniques we successfully\nestimated the efficacy of these feed additives across different farms. The\nmodel's robustness was further confirmed through validation with independent\ncohorts, affirming its generalizability and reliability.\n  Our results underscore the transformative capability of using targeted feed\nadditive strategies to both optimize dairy yield and milk composition, and to\nsignificantly reduce methane emissions. Specifically, our predictive model\ndemonstrates a scenario where its application could guide the assignment of\nadditives to farms where they are most effective. In doing so, we could achieve\nan average potential reduction of over 27\\% in overall emissions.",
            "author": [
                "Yaniv Altshuler",
                "Tzruya Calvao Chebach",
                "Shalom Cohen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12901v1",
                "http://arxiv.org/pdf/2311.12901v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12509v1",
            "title": "Towards Faster Reinforcement Learning of Quantum Circuit Optimization:\n  Exponential Reward Functions",
            "updated": "2023-11-21T10:33:26Z",
            "published": "2023-11-21T10:33:26Z",
            "summary": "Reinforcement learning for the optimization of quantum circuits uses an agent\nwhose goal is to maximize the value of a reward function that decides what is\ncorrect and what is wrong during the exploration of the search space. It is an\nopen problem how to formulate reward functions that lead to fast and efficient\nlearning. We propose an exponential reward function which is sensitive to\nstructural properties of the circuit. We benchmark our function on circuits\nwith known optimal depths, and conclude that our function is reducing the\nlearning time and improves the optimization. Our results are a next step\ntowards fast, large scale optimization of quantum circuits.",
            "author": [
                "Ioana Moflic",
                "Alexandru Paler"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3611315.3633259",
                "http://arxiv.org/abs/2311.12509v1",
                "http://arxiv.org/pdf/2311.12509v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12502v1",
            "title": "Framework for continuous transition to Agile Systems Engineering in the\n  Automotive Industry",
            "updated": "2023-11-21T10:21:47Z",
            "published": "2023-11-21T10:21:47Z",
            "summary": "The increasing pressure within VUCA (volatility, uncertainty, complexity and\nambiguity) driven environments causes traditional, plan-driven Systems\nEngineering approaches to no longer suffice. Agility is then changing from a\n\"nice-to-have\" to a \"must-have\" capability for successful system developing\norganisations. The current state of the art, however, does not provide clear\nanswers on how to map this need in terms of processes, methods, tools and\ncompetencies (PMTC) and how to successfully manage the transition within\nestablished industries. In this paper, we propose an agile Systems Engineering\n(SE) Framework for the automotive industry to meet the new agility demand. In\naddition to the methodological background, we present results of a pilot\nproject in the chassis development department of a German automotive\nmanufacturer and demonstrate the effectiveness of the newly proposed framework.\nBy adopting the described agile SE Framework, companies can foster innovation\nand collaboration based on a learning, continuous improvement and\nself-reinforcing base.",
            "author": [
                "Jan Heine",
                "Herbert Palm"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12502v1",
                "http://arxiv.org/pdf/2311.12502v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.SY",
                "eess.SY",
                "A.m"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12501v1",
            "title": "Fair Polylog-Approximate Low-Cost Hierarchical Clustering",
            "updated": "2023-11-21T10:20:34Z",
            "published": "2023-11-21T10:20:34Z",
            "summary": "Research in fair machine learning, and particularly clustering, has been\ncrucial in recent years given the many ethical controversies that modern\nintelligent systems have posed. Ahmadian et al. [2020] established the study of\nfairness in \\textit{hierarchical} clustering, a stronger, more structured\nvariant of its well-known flat counterpart, though their proposed algorithm\nthat optimizes for Dasgupta's [2016] famous cost function was highly\ntheoretical. Knittel et al. [2023] then proposed the first practical fair\napproximation for cost, however they were unable to break the\npolynomial-approximate barrier they posed as a hurdle of interest. We break\nthis barrier, proposing the first truly polylogarithmic-approximate low-cost\nfair hierarchical clustering, thus greatly bridging the gap between the best\nfair and vanilla hierarchical clustering approximations.",
            "author": [
                "Marina Knittel",
                "Max Springer",
                "John Dickerson",
                "MohammadTaghi Hajiaghayi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12501v1",
                "http://arxiv.org/pdf/2311.12501v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12498v1",
            "title": "Cost Explosion for Efficient Reinforcement Learning Optimisation of\n  Quantum Circuits",
            "updated": "2023-11-21T10:16:03Z",
            "published": "2023-11-21T10:16:03Z",
            "summary": "Large scale optimisation of quantum circuits is a computationally challenging\nproblem. Reinforcement Learning (RL) is a recent approach for learning\nstrategies to optimise quantum circuits by increasing the reward of an\noptimisation agent. The reward is a function of the quantum circuit costs, such\nas gate and qubit counts, or circuit depth. Our goal is to improve the agent's\noptimization strategy, by including hints about how quantum circuits are\noptimized manually: there are situations when the cost of a circuit should be\nallowed to temporary explode, before applying optimisations which significantly\nreduce the circuit's cost. We bring numerical evidence, using\nBernstein-Vazirani circuits, to support the advantage of this strategy. Our\nresults are preliminary, and show that allowing cost explosions offers\nsignificant advantages for RL training, such as reaching optimum circuits. Cost\nexplosion strategies have the potential to be an essential tool for RL of\nlarge-scale quantum circuit optimisation.",
            "author": [
                "Ioana Moflic",
                "Alexandru Paler"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12498v1",
                "http://arxiv.org/pdf/2311.12498v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12495v1",
            "title": "Multi-Objective Reinforcement Learning based on Decomposition: A\n  taxonomy and framework",
            "updated": "2023-11-21T10:11:19Z",
            "published": "2023-11-21T10:11:19Z",
            "summary": "Multi-objective reinforcement learning (MORL) extends traditional RL by\nseeking policies making different compromises among conflicting objectives. The\nrecent surge of interest in MORL has led to diverse studies and solving\nmethods, often drawing from existing knowledge in multi-objective optimization\nbased on decomposition (MOO/D). Yet, a clear categorization based on both RL\nand MOO/D is lacking in the existing literature. Consequently, MORL researchers\nface difficulties when trying to classify contributions within a broader\ncontext due to the absence of a standardized taxonomy. To tackle such an issue,\nthis paper introduces Multi-Objective Reinforcement Learning based on\nDecomposition (MORL/D), a novel methodology bridging RL and MOO literature. A\ncomprehensive taxonomy for MORL/D is presented, providing a structured\nfoundation for categorizing existing and potential MORL works. The introduced\ntaxonomy is then used to scrutinize MORL research, enhancing clarity and\nconciseness through well-defined categorization. Moreover, a flexible framework\nderived from the taxonomy is introduced. This framework accommodates diverse\ninstantiations using tools from both RL and MOO/D. Implementation across\nvarious configurations demonstrates its versatility, assessed against benchmark\nproblems. Results indicate MORL/D instantiations achieve comparable performance\nwith significantly greater versatility than current state-of-the-art\napproaches. By presenting the taxonomy and framework, this paper offers a\ncomprehensive perspective and a unified vocabulary for MORL. This not only\nfacilitates the identification of algorithmic contributions but also lays the\ngroundwork for novel research avenues in MORL, contributing to the continued\nadvancement of this field.",
            "author": [
                "Florian Felten",
                "El-Ghazali Talbi",
                "Gr\u00e9goire Danoy"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12495v1",
                "http://arxiv.org/pdf/2311.12495v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12491v1",
            "title": "Heuristics for Detecting CoinJoin Transactions on the Bitcoin Blockchain",
            "updated": "2023-11-21T10:05:32Z",
            "published": "2023-11-21T10:05:32Z",
            "summary": "This research delves into the intricacies of Bitcoin, a decentralized\npeer-to-peer network, and its associated blockchain, which records all\ntransactions since its inception. While this ensures integrity and\ntransparency, the transparent nature of Bitcoin potentially compromises users'\nprivacy rights. To address this concern, users have adopted CoinJoin, a method\nthat amalgamates multiple transaction intents into a single, larger transaction\nto bolster transactional privacy. This process complicates individual\ntransaction tracing and disrupts many established blockchain analysis\nheuristics. Despite its significance, limited research has been conducted on\nidentifying CoinJoin transactions. Particularly noteworthy are varied CoinJoin\nimplementations such as JoinMarket, Wasabi, and Whirlpool, each presenting\ndistinct challenges due to their unique transaction structures. This study\ndelves deeply into the open-source implementations of these protocols, aiming\nto develop refined heuristics for identifying their transactions on the\nblockchain. Our exhaustive analysis covers transactions up to block 760,000,\noffering a comprehensive insight into CoinJoin transactions and their\nimplications for Bitcoin blockchain analysis.",
            "author": [
                "Hugo Schnoering",
                "Michalis Vazirgiannis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12491v1",
                "http://arxiv.org/pdf/2311.12491v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.DC",
                "cs.LG",
                "q-fin.GN"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12490v1",
            "title": "Hyb-NeRF: A Multiresolution Hybrid Encoding for Neural Radiance Fields",
            "updated": "2023-11-21T10:01:08Z",
            "published": "2023-11-21T10:01:08Z",
            "summary": "Recent advances in Neural radiance fields (NeRF) have enabled high-fidelity\nscene reconstruction for novel view synthesis. However, NeRF requires hundreds\nof network evaluations per pixel to approximate a volume rendering integral,\nmaking it slow to train. Caching NeRFs into explicit data structures can\neffectively enhance rendering speed but at the cost of higher memory usage. To\naddress these issues, we present Hyb-NeRF, a novel neural radiance field with a\nmulti-resolution hybrid encoding that achieves efficient neural modeling and\nfast rendering, which also allows for high-quality novel view synthesis. The\nkey idea of Hyb-NeRF is to represent the scene using different encoding\nstrategies from coarse-to-fine resolution levels. Hyb-NeRF exploits\nmemory-efficiency learnable positional features at coarse resolutions and the\nfast optimization speed and local details of hash-based feature grids at fine\nresolutions. In addition, to further boost performance, we embed cone\ntracing-based features in our learnable positional encoding that eliminates\nencoding ambiguity and reduces aliasing artifacts. Extensive experiments on\nboth synthetic and real-world datasets show that Hyb-NeRF achieves faster\nrendering speed with better rending quality and even a lower memory footprint\nin comparison to previous state-of-the-art methods.",
            "author": [
                "Yifan Wang",
                "Yi Gong",
                "Yuan Zeng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12490v1",
                "http://arxiv.org/pdf/2311.12490v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12486v1",
            "title": "HCA-Net: Hierarchical Context Attention Network for Intervertebral Disc\n  Semantic Labeling",
            "updated": "2023-11-21T09:58:39Z",
            "published": "2023-11-21T09:58:39Z",
            "summary": "Accurate and automated segmentation of intervertebral discs (IVDs) in medical\nimages is crucial for assessing spine-related disorders, such as osteoporosis,\nvertebral fractures, or IVD herniation. We present HCA-Net, a novel contextual\nattention network architecture for semantic labeling of IVDs, with a special\nfocus on exploiting prior geometric information. Our approach excels at\nprocessing features across different scales and effectively consolidating them\nto capture the intricate spatial relationships within the spinal cord. To\nachieve this, HCA-Net models IVD labeling as a pose estimation problem, aiming\nto minimize the discrepancy between each predicted IVD location and its\ncorresponding actual joint location. In addition, we introduce a skeletal loss\nterm to reinforce the model's geometric dependence on the spine. This loss\nfunction is designed to constrain the model's predictions to a range that\nmatches the general structure of the human vertebral skeleton. As a result, the\nnetwork learns to reduce the occurrence of false predictions and adaptively\nimproves the accuracy of IVD location estimation. Through extensive\nexperimental evaluation on multi-center spine datasets, our approach\nconsistently outperforms previous state-of-the-art methods on both MRI T1w and\nT2w modalities. The codebase is accessible to the public on\n\\href{https://github.com/xmindflow/HCA-Net}{GitHub}.",
            "author": [
                "Afshin Bozorgpour",
                "Bobby Azad",
                "Reza Azad",
                "Yury Velichko",
                "Ulas Bagci",
                "Dorit Merhof"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12486v1",
                "http://arxiv.org/pdf/2311.12486v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12476v1",
            "title": "MaskFlow: Object-Aware Motion Estimation",
            "updated": "2023-11-21T09:37:49Z",
            "published": "2023-11-21T09:37:49Z",
            "summary": "We introduce a novel motion estimation method, MaskFlow, that is capable of\nestimating accurate motion fields, even in very challenging cases with small\nobjects, large displacements and drastic appearance changes. In addition to\nlower-level features, that are used in other Deep Neural Network (DNN)-based\nmotion estimation methods, MaskFlow draws from object-level features and\nsegmentations. These features and segmentations are used to approximate the\nobjects' translation motion field. We propose a novel and effective way of\nincorporating the incomplete translation motion field into a subsequent motion\nestimation network for refinement and completion. We also produced a new\nchallenging synthetic dataset with motion field ground truth, and also provide\nextra ground truth for the object-instance matchings and corresponding\nsegmentation masks. We demonstrate that MaskFlow outperforms state of the art\nmethods when evaluated on our new challenging dataset, whilst still producing\ncomparable results on the popular FlyingThings3D benchmark dataset.",
            "author": [
                "Aria Ahmadi",
                "David R. Walton",
                "Tim Atherton",
                "Cagatay Dikici"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12476v1",
                "http://arxiv.org/pdf/2311.12476v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12474v1",
            "title": "CSMeD: Bridging the Dataset Gap in Automated Citation Screening for\n  Systematic Literature Reviews",
            "updated": "2023-11-21T09:36:11Z",
            "published": "2023-11-21T09:36:11Z",
            "summary": "Systematic literature reviews (SLRs) play an essential role in summarising,\nsynthesising and validating scientific evidence. In recent years, there has\nbeen a growing interest in using machine learning techniques to automate the\nidentification of relevant studies for SLRs. However, the lack of standardised\nevaluation datasets makes comparing the performance of such automated\nliterature screening systems difficult. In this paper, we analyse the citation\nscreening evaluation datasets, revealing that many of the available datasets\nare either too small, suffer from data leakage or have limited applicability to\nsystems treating automated literature screening as a classification task, as\nopposed to, for example, a retrieval or question-answering task. To address\nthese challenges, we introduce CSMeD, a meta-dataset consolidating nine\npublicly released collections, providing unified access to 325 SLRs from the\nfields of medicine and computer science. CSMeD serves as a comprehensive\nresource for training and evaluating the performance of automated citation\nscreening models. Additionally, we introduce CSMeD-FT, a new dataset designed\nexplicitly for evaluating the full text publication screening task. To\ndemonstrate the utility of CSMeD, we conduct experiments and establish\nbaselines on new datasets.",
            "author": [
                "Wojciech Kusa",
                "Oscar E. Mendoza",
                "Matthias Samwald",
                "Petr Knoth",
                "Allan Hanbury"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12474v1",
                "http://arxiv.org/pdf/2311.12474v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12472v1",
            "title": "Self-Supervised Deconfounding Against Spatio-Temporal Shifts: Theory and\n  Modeling",
            "updated": "2023-11-21T09:33:13Z",
            "published": "2023-11-21T09:33:13Z",
            "summary": "As an important application of spatio-temporal (ST) data, ST traffic\nforecasting plays a crucial role in improving urban travel efficiency and\npromoting sustainable development. In practice, the dynamics of traffic data\nfrequently undergo distributional shifts attributed to external factors such as\ntime evolution and spatial differences. This entails forecasting models to\nhandle the out-of-distribution (OOD) issue where test data is distributed\ndifferently from training data. In this work, we first formalize the problem by\nconstructing a causal graph of past traffic data, future traffic data, and\nexternal ST contexts. We reveal that the failure of prior arts in OOD traffic\ndata is due to ST contexts acting as a confounder, i.e., the common cause for\npast data and future ones. Then, we propose a theoretical solution named\nDisentangled Contextual Adjustment (DCA) from a causal lens. It differentiates\ninvariant causal correlations against variant spurious ones and deconfounds the\neffect of ST contexts. On top of that, we devise a Spatio-Temporal\nsElf-superVised dEconfounding (STEVE) framework. It first encodes traffic data\ninto two disentangled representations for associating invariant and variant ST\ncontexts. Then, we use representative ST contexts from three conceptually\ndifferent perspectives (i.e., temporal, spatial, and semantic) as\nself-supervised signals to inject context information into both\nrepresentations. In this way, we improve the generalization ability of the\nlearned context-oriented representations to OOD ST traffic forecasting.\nComprehensive experiments on four large-scale benchmark datasets demonstrate\nthat our STEVE consistently outperforms the state-of-the-art baselines across\nvarious ST OOD scenarios.",
            "author": [
                "Jiahao Ji",
                "Wentao Zhang",
                "Jingyuan Wang",
                "Yue He",
                "Chao Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12472v1",
                "http://arxiv.org/pdf/2311.12472v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12467v2",
            "title": "GLAD: Global-Local View Alignment and Background Debiasing for\n  Unsupervised Video Domain Adaptation with Large Domain Gap",
            "updated": "2023-11-22T06:01:46Z",
            "published": "2023-11-21T09:27:30Z",
            "summary": "In this work, we tackle the challenging problem of unsupervised video domain\nadaptation (UVDA) for action recognition. We specifically focus on scenarios\nwith a substantial domain gap, in contrast to existing works primarily deal\nwith small domain gaps between labeled source domains and unlabeled target\ndomains. To establish a more realistic setting, we introduce a novel UVDA\nscenario, denoted as Kinetics->BABEL, with a more considerable domain gap in\nterms of both temporal dynamics and background shifts. To tackle the temporal\nshift, i.e., action duration difference between the source and target domains,\nwe propose a global-local view alignment approach. To mitigate the background\nshift, we propose to learn temporal order sensitive representations by temporal\norder learning and background invariant representations by background\naugmentation. We empirically validate that the proposed method shows\nsignificant improvement over the existing methods on the Kinetics->BABEL\ndataset with a large domain gap. The code is available at\nhttps://github.com/KHUVLL/GLAD.",
            "author": [
                "Hyogun Lee",
                "Kyungho Bae",
                "Seong Jong Ha",
                "Yumin Ko",
                "Gyeong-Moon Park",
                "Jinwoo Choi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12467v2",
                "http://arxiv.org/pdf/2311.12467v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12465v1",
            "title": "Towards a Gateway for Knowledge Graph Schemas Collection, Analysis, and\n  Embedding",
            "updated": "2023-11-21T09:22:02Z",
            "published": "2023-11-21T09:22:02Z",
            "summary": "One of the significant barriers to the training of statistical models on\nknowledge graphs is the difficulty that scientists have in finding the best\ninput data to address their prediction goal. In addition to this, a key\nchallenge is to determine how to manipulate these relational data, which are\noften in the form of particular triples (i.e., subject, predicate, object), to\nenable the learning process. Currently, many high-quality catalogs of knowledge\ngraphs, are available. However, their primary goal is the re-usability of these\nresources, and their interconnection, in the context of the Semantic Web. This\npaper describes the LiveSchema initiative, namely, a first version of a gateway\nthat has the main scope of leveraging the gold mine of data collected by many\nexisting catalogs collecting relational data like ontologies and knowledge\ngraphs. At the current state, LiveSchema contains - 1000 datasets from 4 main\nsources and offers some key facilities, which allow to: i) evolving LiveSchema,\nby aggregating other source catalogs and repositories as input sources; ii)\nquerying all the collected resources; iii) transforming each given dataset into\nformal concept analysis matrices that enable analysis and visualization\nservices; iv) generating models and tensors from each given dataset.",
            "author": [
                "Mattia Fumagalli",
                "Marco Boffo",
                "Daqian Shi",
                "Mayukh Bagchi",
                "Fausto Giunchiglia"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12465v1",
                "http://arxiv.org/pdf/2311.12465v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12457v1",
            "title": "LIP-RTVE: An Audiovisual Database for Continuous Spanish in the Wild",
            "updated": "2023-11-21T09:12:21Z",
            "published": "2023-11-21T09:12:21Z",
            "summary": "Speech is considered as a multi-modal process where hearing and vision are\ntwo fundamentals pillars. In fact, several studies have demonstrated that the\nrobustness of Automatic Speech Recognition systems can be improved when audio\nand visual cues are combined to represent the nature of speech. In addition,\nVisual Speech Recognition, an open research problem whose purpose is to\ninterpret speech by reading the lips of the speaker, has been a focus of\ninterest in the last decades. Nevertheless, in order to estimate these systems\nin the currently Deep Learning era, large-scale databases are required. On the\nother hand, while most of these databases are dedicated to English, other\nlanguages lack sufficient resources. Thus, this paper presents a\nsemi-automatically annotated audiovisual database to deal with unconstrained\nnatural Spanish, providing 13 hours of data extracted from Spanish television.\nFurthermore, baseline results for both speaker-dependent and\nspeaker-independent scenarios are reported using Hidden Markov Models, a\ntraditional paradigm that has been widely used in the field of Speech\nTechnologies.",
            "author": [
                "David Gimeno-G\u00f3mez",
                "Carlos-D. Mart\u00ednez-Hinarejos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12457v1",
                "http://arxiv.org/pdf/2311.12457v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12439v1",
            "title": "Harnessing FPGA Technology for Enhanced Biomedical Computation",
            "updated": "2023-11-21T08:51:58Z",
            "published": "2023-11-21T08:51:58Z",
            "summary": "This research delves into sophisticated neural network frameworks like\nConvolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), Long\nShort-Term Memory Networks (LSTMs), and Deep Belief Networks (DBNs) for\nimproved analysis of ECG signals via Field Programmable Gate Arrays (FPGAs).\nThe MIT-BIH Arrhythmia Database serves as the foundation for training and\nevaluating our models, with added Gaussian noise to heighten the algorithms'\nresilience. The developed architectures incorporate various layers for specific\nprocessing and categorization functions, employing strategies such as the\nEarlyStopping callback and Dropout layer to prevent overfitting. Additionally,\nthis paper details the creation of a tailored Tensor Compute Unit (TCU)\naccelerator for the PYNQ Z1 platform. It provides a thorough methodology for\nimplementing FPGA-based machine learning, encompassing the configuration of the\nTensil toolchain in Docker, selection of architectures, PS-PL configuration,\nand the compilation and deployment of models. By evaluating performance\nindicators like latency and throughput, we showcase the efficacy of FPGAs in\nadvanced biomedical computing. This study ultimately serves as a comprehensive\nguide to optimizing neural network operations on FPGAs across various fields.",
            "author": [
                "Nisanur Alici",
                "Kayode Inadagbo",
                "Murat Isik"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12439v1",
                "http://arxiv.org/pdf/2311.12439v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14731v1",
            "title": "Deep State-Space Model for Predicting Cryptocurrency Price",
            "updated": "2023-11-21T08:49:55Z",
            "published": "2023-11-21T08:49:55Z",
            "summary": "Our work presents two fundamental contributions. On the application side, we\ntackle the challenging problem of predicting day-ahead crypto-currency prices.\nOn the methodological side, a new dynamical modeling approach is proposed. Our\napproach keeps the probabilistic formulation of the state-space model, which\nprovides uncertainty quantification on the estimates, and the function\napproximation ability of deep neural networks. We call the proposed approach\nthe deep state-space model. The experiments are carried out on established\ncryptocurrencies (obtained from Yahoo Finance). The goal of the work has been\nto predict the price for the next day. Benchmarking has been done with both\nstate-of-the-art and classical dynamical modeling techniques. Results show that\nthe proposed approach yields the best overall results in terms of accuracy.",
            "author": [
                "Shalini Sharma",
                "Angshul Majumdar",
                "Emilie Chouzenoux",
                "Victor Elvira"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14731v1",
                "http://arxiv.org/pdf/2311.14731v1"
            ],
            "primary_category": "q-fin.ST",
            "category": [
                "q-fin.ST",
                "cs.LG",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12437v2",
            "title": "Learning Site-specific Styles for Multi-institutional Unsupervised\n  Cross-modality Domain Adaptation",
            "updated": "2023-11-22T11:38:46Z",
            "published": "2023-11-21T08:47:08Z",
            "summary": "Unsupervised cross-modality domain adaptation is a challenging task in\nmedical image analysis, and it becomes more challenging when source and target\ndomain data are collected from multiple institutions. In this paper, we present\nour solution to tackle the multi-institutional unsupervised domain adaptation\nfor the crossMoDA 2023 challenge. First, we perform unpaired image translation\nto translate the source domain images to the target domain, where we design a\ndynamic network to generate synthetic target domain images with controllable,\nsite-specific styles. Afterwards, we train a segmentation model using the\nsynthetic images and further reduce the domain gap by self-training. Our\nsolution achieved the 1st place during both the validation and testing phases\nof the challenge. The code repository is publicly available at\nhttps://github.com/MedICL-VU/crossmoda2023.",
            "author": [
                "Han Liu",
                "Yubo Fan",
                "Zhoubing Xu",
                "Benoit M. Dawant",
                "Ipek Oguz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12437v2",
                "http://arxiv.org/pdf/2311.12437v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12436v1",
            "title": "Classifier Calibration with ROC-Regularized Isotonic Regression",
            "updated": "2023-11-21T08:45:09Z",
            "published": "2023-11-21T08:45:09Z",
            "summary": "Calibration of machine learning classifiers is necessary to obtain reliable\nand interpretable predictions, bridging the gap between model confidence and\nactual probabilities. One prominent technique, isotonic regression (IR), aims\nat calibrating binary classifiers by minimizing the cross entropy on a\ncalibration set via monotone transformations. IR acts as an adaptive binning\nprocedure, which allows achieving a calibration error of zero, but leaves open\nthe issue of the effect on performance. In this paper, we first prove that IR\npreserves the convex hull of the ROC curve -- an essential performance metric\nfor binary classifiers. This ensures that a classifier is calibrated while\ncontrolling for overfitting of the calibration set. We then present a novel\ngeneralization of isotonic regression to accommodate classifiers with K\nclasses. Our method constructs a multidimensional adaptive binning scheme on\nthe probability simplex, again achieving a multi-class calibration error equal\nto zero. We regularize this algorithm by imposing a form of monotony that\npreserves the K-dimensional ROC surface of the classifier. We show empirically\nthat this general monotony criterion is effective in striking a balance between\nreducing cross entropy loss and avoiding overfitting of the calibration set.",
            "author": [
                "Eugene Berta",
                "Francis Bach",
                "Michael Jordan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12436v1",
                "http://arxiv.org/pdf/2311.12436v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12435v1",
            "title": "Fair Enough? A map of the current limitations of the requirements to\n  have \"fair'' algorithms",
            "updated": "2023-11-21T08:44:38Z",
            "published": "2023-11-21T08:44:38Z",
            "summary": "In the recent years, the raise in the usage and efficiency of Artificial\nIntelligence and, more in general, of Automated Decision-Making systems has\nbrought with it an increasing and welcome awareness of the risks associated\nwith such systems. One of such risks is that of perpetuating or even amplifying\nbias and unjust disparities present in the data from which many of these\nsystems learn to adjust and optimise their decisions. This awareness has on one\nside encouraged several scientific communities to come up with more and more\nappropriate ways and methods to assess, quantify, and possibly mitigate such\nbiases and disparities. On the other hand, it has prompted more and more layers\nof society, including policy makers, to call for ``fair'' algorithms. We\nbelieve that while a lot of excellent and multidisciplinary research is\ncurrently being conducted, what is still fundamentally missing is the awareness\nthat having ``fair'' algorithms is per s\\'e a nearly meaningless requirement,\nthat needs to be complemented with a lot of additional societal choices to\nbecome actionable. Namely, there is a hiatus between what the society is\ndemanding from Automated Decision-Making systems, and what this demand actually\nmeans in real-world scenarios. In this work, we outline the key features of\nsuch a hiatus, and pinpoint a list of fundamental ambiguities and attention\npoints that we as a society must address in order to give a concrete meaning to\nthe increasing demand of fairness in Automated Decision-Making systems.",
            "author": [
                "Alessandro Castelnovo",
                "Nicole Inverardi",
                "Gabriele Nanino",
                "Ilaria Giuseppina Penco",
                "Daniele Regoli"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12435v1",
                "http://arxiv.org/pdf/2311.12435v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CY",
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12426v1",
            "title": "Autoencoder-assisted study of directed percolation with spatial\n  long-range interactions",
            "updated": "2023-11-21T08:38:00Z",
            "published": "2023-11-21T08:38:00Z",
            "summary": "Spatial L{\\'{e}}vy-like flights are introduced as a way to absorbing phase\ntransitions to produce non-local interactions. We utilize the autoencoder, an\nunsupervised learning method, to predict the critical points for $(1+1)$-d\ndirected percolation with such spatial long-range interactions. After making a\nglobal coverage of the reaction-diffusion distance and taking a series of\ndifferent values for the parameter \\;${\\beta}$\\; in the distribution\n\\;$P(r){\\sim}1/r^{\\beta}$\\;, the critical points $P_c$ that can be continuously\nvaried are obtained. And the dynamic decay of the particle density under the\ncritical points was counted as a way to determine the critical exponent\n\\;${\\delta}$\\; of the survival rate. We also investigate the active behavior of\nthe system's particles under the critical point with increasing time steps,\nwhich allows us to determine the characteristic time $t_f$ of the finite-scale\nsystems. And the dynamic exponents \\;$z$\\; are obtained using the scaling\nrelation \\;$t_f{\\sim}L^{z}$\\;. We find that the autoencoder can well identify\nthis characteristic evolutionary behavior of particles. Finally, we discuss the\ncompliance of the scaling form \\;$1/{\\delta}-({\\beta}-2)/{\\delta}z=2$\\; in\ndifferent \\;${\\beta}$\\; intervals as well as a method to introduce a global\nscaling mechanism by generating a random walking step using the L{\\'{e}}vy\ndistribution.",
            "author": [
                "Yanyang Wang",
                "Yuxiang Yang",
                "Wei Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12426v1",
                "http://arxiv.org/pdf/2311.12426v1"
            ],
            "primary_category": "cond-mat.stat-mech",
            "category": [
                "cond-mat.stat-mech",
                "cond-mat.dis-nn",
                "nlin.CG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12424v1",
            "title": "Looped Transformers are Better at Learning Learning Algorithms",
            "updated": "2023-11-21T08:32:38Z",
            "published": "2023-11-21T08:32:38Z",
            "summary": "Transformers have demonstrated effectiveness in \\emph{in-context solving}\ndata-fitting problems from various (latent) models, as reported by Garg et al.\nHowever, the absence of an inherent iterative structure in the transformer\narchitecture presents a challenge in emulating the iterative algorithms, which\nare commonly employed in traditional machine learning methods. To address this,\nwe propose the utilization of \\emph{looped} transformer architecture and its\nassociated training methodology, with the aim of incorporating iterative\ncharacteristics into the transformer architectures. Experimental results\nsuggest that the looped transformer achieves performance comparable to the\nstandard transformer in solving various data-fitting problems, while utilizing\nless than 10\\% of the parameter count.",
            "author": [
                "Liu Yang",
                "Kangwook Lee",
                "Robert Nowak",
                "Dimitris Papailiopoulos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12424v1",
                "http://arxiv.org/pdf/2311.12424v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12420v1",
            "title": "How Far Have We Gone in Vulnerability Detection Using Large Language\n  Models",
            "updated": "2023-11-21T08:20:39Z",
            "published": "2023-11-21T08:20:39Z",
            "summary": "As software becomes increasingly complex and prone to vulnerabilities,\nautomated vulnerability detection is critically important, yet challenging.\nGiven the significant successes of Large Language Models (LLMs) in various\ntasks, there is growing anticipation of their efficacy in vulnerability\ndetection. However, a quantitative understanding of their potential in\nvulnerability detection is still missing. To bridge this gap, we introduce a\ncomprehensive vulnerability benchmark VulBench. This benchmark aggregates\nhigh-quality data from a wide range of CTF (Capture-the-Flag) challenges and\nreal-world applications, with annotations for each vulnerable function\ndetailing the vulnerability type and its root cause. Through our experiments\nencompassing 16 LLMs and 6 state-of-the-art (SOTA) deep learning-based models\nand static analyzers, we find that several LLMs outperform traditional deep\nlearning approaches in vulnerability detection, revealing an untapped potential\nin LLMs. This work contributes to the understanding and utilization of LLMs for\nenhanced software security.",
            "author": [
                "Zeyu Gao",
                "Hao Wang",
                "Yuchen Zhou",
                "Wenyu Zhu",
                "Chao Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12420v1",
                "http://arxiv.org/pdf/2311.12420v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12894v1",
            "title": "Attribute-Aware Deep Hashing with Self-Consistency for Large-Scale\n  Fine-Grained Image Retrieval",
            "updated": "2023-11-21T08:20:38Z",
            "published": "2023-11-21T08:20:38Z",
            "summary": "Our work focuses on tackling large-scale fine-grained image retrieval as\nranking the images depicting the concept of interests (i.e., the same\nsub-category labels) highest based on the fine-grained details in the query. It\nis desirable to alleviate the challenges of both fine-grained nature of small\ninter-class variations with large intra-class variations and explosive growth\nof fine-grained data for such a practical task. In this paper, we propose\nattribute-aware hashing networks with self-consistency for generating\nattribute-aware hash codes to not only make the retrieval process efficient,\nbut also establish explicit correspondences between hash codes and visual\nattributes. Specifically, based on the captured visual representations by\nattention, we develop an encoder-decoder structure network of a reconstruction\ntask to unsupervisedly distill high-level attribute-specific vectors from the\nappearance-specific visual representations without attribute annotations. Our\nmodels are also equipped with a feature decorrelation constraint upon these\nattribute vectors to strengthen their representative abilities. Then, driven by\npreserving original entities' similarity, the required hash codes can be\ngenerated from these attribute-specific vectors and thus become\nattribute-aware. Furthermore, to combat simplicity bias in deep hashing, we\nconsider the model design from the perspective of the self-consistency\nprinciple and propose to further enhance models' self-consistency by equipping\nan additional image reconstruction path. Comprehensive quantitative experiments\nunder diverse empirical settings on six fine-grained retrieval datasets and two\ngeneric retrieval datasets show the superiority of our models over competing\nmethods.",
            "author": [
                "Xiu-Shen Wei",
                "Yang Shen",
                "Xuhao Sun",
                "Peng Wang",
                "Yuxin Peng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12894v1",
                "http://arxiv.org/pdf/2311.12894v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.CV",
                "cs.LG",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12419v1",
            "title": "Board-to-Board: Evaluating Moonboard Grade Prediction Generalization",
            "updated": "2023-11-21T08:16:01Z",
            "published": "2023-11-21T08:16:01Z",
            "summary": "Bouldering is a sport where athletes aim to climb up an obstacle using a set\nof defined holds called a route. Typically routes are assigned a grade to\ninform climbers of its difficulty and allow them to more easily track their\nprogression. However, the variation in individual climbers technical and\nphysical attributes and many nuances of an individual route make grading a\ndifficult and often biased task. In this work, we apply classical and\ndeep-learning modelling techniques to the 2016, 2017 and 2019 Moonboard\ndatasets, achieving state of the art grade prediction performance with 0.87 MAE\nand 1.12 RMSE. We achieve this performance on a feature-set that does not\nrequire decomposing routes into individual moves, which is a method common in\nliterature and introduces bias. We also demonstrate the generalization\ncapability of this model between editions and introduce a novel vision-based\nmethod of grade prediction. While the generalization performance of these\ntechniques is below human level performance currently, we propose these methods\nas a basis for future work. Such a tool could be implemented in pre-existing\nmobile applications and would allow climbers to better track their progress and\nassess new routes with reduced bias.",
            "author": [
                "Daniel Petashvili",
                "Matthew Rodda"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12419v1",
                "http://arxiv.org/pdf/2311.12419v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12893v1",
            "title": "A Safer Vision-based Autonomous Planning System for Quadrotor UAVs with\n  Dynamic Obstacle Trajectory Prediction and Its Application with LLMs",
            "updated": "2023-11-21T08:09:00Z",
            "published": "2023-11-21T08:09:00Z",
            "summary": "For intelligent quadcopter UAVs, a robust and reliable autonomous planning\nsystem is crucial. Most current trajectory planning methods for UAVs are\nsuitable for static environments but struggle to handle dynamic obstacles,\nwhich can pose challenges and even dangers to flight. To address this issue,\nthis paper proposes a vision-based planning system that combines tracking and\ntrajectory prediction of dynamic obstacles to achieve efficient and reliable\nautonomous flight. We use a lightweight object detection algorithm to identify\ndynamic obstacles and then use Kalman Filtering to track and estimate their\nmotion states. During the planning phase, we not only consider static obstacles\nbut also account for the potential movements of dynamic obstacles. For\ntrajectory generation, we use a B-spline-based trajectory search algorithm,\nwhich is further optimized with various constraints to enhance safety and\nalignment with the UAV's motion characteristics. We conduct experiments in both\nsimulation and real-world environments, and the results indicate that our\napproach can successfully detect and avoid obstacles in dynamic environments in\nreal-time, offering greater reliability compared to existing approaches.\nFurthermore, with the advancements in Natural Language Processing (NLP)\ntechnology demonstrating exceptional zero-shot generalization capabilities,\nmore user-friendly human-machine interactions have become feasible, and this\nstudy also explores the integration of autonomous planning systems with Large\nLanguage Models (LLMs).",
            "author": [
                "Jiageng Zhong",
                "Ming Li",
                "Yinliang Chen",
                "Zihang Wei",
                "Fan Yang",
                "Haoran Shen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12893v1",
                "http://arxiv.org/pdf/2311.12893v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CV"
            ]
        }
    }
]